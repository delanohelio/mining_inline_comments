{"pr_number": 1870, "pr_title": "Iceberg Jdbc Catalog Implementation", "pr_createdAt": "2020-12-03T15:27:01Z", "pr_url": "https://github.com/apache/iceberg/pull/1870", "timeline": [{"oid": "60fafc3ab4fead0af10a3152ac08f773312412c1", "url": "https://github.com/apache/iceberg/commit/60fafc3ab4fead0af10a3152ac08f773312412c1", "message": "review fixes\n\nreview fixes\n\nreview fixes", "committedDate": "2021-04-18T06:56:42Z", "type": "commit"}, {"oid": "af3937ea443ee3a3f6db701f7aaba2203fa7bdff", "url": "https://github.com/apache/iceberg/commit/af3937ea443ee3a3f6db701f7aaba2203fa7bdff", "message": "update spark3 catalog change", "committedDate": "2021-04-18T06:56:42Z", "type": "commit"}, {"oid": "ef240b2087b37c70a4e4ec6643d08b95ce24aa6f", "url": "https://github.com/apache/iceberg/commit/ef240b2087b37c70a4e4ec6643d08b95ce24aa6f", "message": "fix catalog class name", "committedDate": "2021-04-18T06:56:42Z", "type": "commit"}, {"oid": "5386846207d96c5067c8e139fc9423da50ec9b38", "url": "https://github.com/apache/iceberg/commit/5386846207d96c5067c8e139fc9423da50ec9b38", "message": "review updates", "committedDate": "2021-04-18T06:56:42Z", "type": "commit"}, {"oid": "a0d6f9497a6253dd07dc79f1600f84aadcf25e4d", "url": "https://github.com/apache/iceberg/commit/a0d6f9497a6253dd07dc79f1600f84aadcf25e4d", "message": "add method defaultNamespaceLocation(namespace)", "committedDate": "2021-04-18T06:56:42Z", "type": "commit"}, {"oid": "aaea91cdd45414d49613dafe4cb10869ffd36502", "url": "https://github.com/apache/iceberg/commit/aaea91cdd45414d49613dafe4cb10869ffd36502", "message": "move sql statements to JdbcUtil", "committedDate": "2021-04-18T06:56:42Z", "type": "commit"}, {"oid": "428e57a5f1e4c00e811d500a36665222b97866f5", "url": "https://github.com/apache/iceberg/commit/428e57a5f1e4c00e811d500a36665222b97866f5", "message": "use protected for sql constants", "committedDate": "2021-04-18T06:56:42Z", "type": "commit"}, {"oid": "7ac78fa0ed1a732e5dda152030ace826903fdfbf", "url": "https://github.com/apache/iceberg/commit/7ac78fa0ed1a732e5dda152030ace826903fdfbf", "message": "address review notes", "committedDate": "2021-04-18T06:56:42Z", "type": "commit"}, {"oid": "699047429aa823bf0390857b47ee7c5bd1d49b1e", "url": "https://github.com/apache/iceberg/commit/699047429aa823bf0390857b47ee7c5bd1d49b1e", "message": "moved UncheckedSQLException to org.apache.iceberg.jdbc", "committedDate": "2021-04-18T06:56:42Z", "type": "commit"}, {"oid": "9d68634cf2656cdf52757bde1a2e6793e4c476cc", "url": "https://github.com/apache/iceberg/commit/9d68634cf2656cdf52757bde1a2e6793e4c476cc", "message": "update messages", "committedDate": "2021-04-18T06:56:42Z", "type": "commit"}, {"oid": "f2c9e850ff73e735e4083319d41ccb3690330bdc", "url": "https://github.com/apache/iceberg/commit/f2c9e850ff73e735e4083319d41ccb3690330bdc", "message": "fix test", "committedDate": "2021-04-18T06:56:42Z", "type": "commit"}, {"oid": "1c4bcc0df62193059704c1857a31556dab85878d", "url": "https://github.com/apache/iceberg/commit/1c4bcc0df62193059704c1857a31556dab85878d", "message": "review updates", "committedDate": "2021-04-18T06:56:42Z", "type": "commit"}, {"oid": "dd8d14a8a481f04601b1adbcae553f179ffc6e6d", "url": "https://github.com/apache/iceberg/commit/dd8d14a8a481f04601b1adbcae553f179ffc6e6d", "message": "move column names to constants", "committedDate": "2021-04-18T06:56:42Z", "type": "commit"}, {"oid": "5617a8280095e60a1540152fe1d8af81536b51d1", "url": "https://github.com/apache/iceberg/commit/5617a8280095e60a1540152fe1d8af81536b51d1", "message": "fix concurrent tests and db url", "committedDate": "2021-04-18T06:56:42Z", "type": "commit"}, {"oid": "87ffe6d3afc0c8b75b7d1b3a4d499185f8c767e7", "url": "https://github.com/apache/iceberg/commit/87ffe6d3afc0c8b75b7d1b3a4d499185f8c767e7", "message": "review fixes", "committedDate": "2021-04-18T06:56:42Z", "type": "commit"}, {"oid": "d4d96870eeea74b0769e1eaf7855e2c5c34436c2", "url": "https://github.com/apache/iceberg/commit/d4d96870eeea74b0769e1eaf7855e2c5c34436c2", "message": "update HIVE_URI to URI", "committedDate": "2021-04-18T06:56:42Z", "type": "commit"}, {"oid": "a63cc091856fc17d3f5d0d1351388a7efad789a3", "url": "https://github.com/apache/iceberg/commit/a63cc091856fc17d3f5d0d1351388a7efad789a3", "message": "update HIVE_URI to URI", "committedDate": "2021-04-18T06:56:42Z", "type": "commit"}, {"oid": "d60f43581132fa9d2c30bc06f35d96a39e879fdc", "url": "https://github.com/apache/iceberg/commit/d60f43581132fa9d2c30bc06f35d96a39e879fdc", "message": "Address review comments", "committedDate": "2021-04-18T06:56:42Z", "type": "commit"}, {"oid": "ebb2de34a4e3e22473dc8d8882c1c2f248c46c57", "url": "https://github.com/apache/iceberg/commit/ebb2de34a4e3e22473dc8d8882c1c2f248c46c57", "message": "moved initializeConnection to initialize", "committedDate": "2021-04-18T06:56:42Z", "type": "commit"}, {"oid": "75aa896fea43ed1c56a94eb4d25d7232692d2c01", "url": "https://github.com/apache/iceberg/commit/75aa896fea43ed1c56a94eb4d25d7232692d2c01", "message": "move ClientPoolImpl to core", "committedDate": "2021-04-18T07:00:38Z", "type": "commit"}, {"oid": "706715b70feabe205f293a7dc2476d8ceaad12b9", "url": "https://github.com/apache/iceberg/commit/706715b70feabe205f293a7dc2476d8ceaad12b9", "message": "minor improvements", "committedDate": "2021-04-18T07:00:39Z", "type": "commit"}, {"oid": "d683f7664f2c595570153edcfa0c9520d8e922ca", "url": "https://github.com/apache/iceberg/commit/d683f7664f2c595570153edcfa0c9520d8e922ca", "message": "minor improvements", "committedDate": "2021-04-18T07:00:39Z", "type": "commit"}, {"oid": "4e53dd02075ae619ba86b0d0d7a2ffc0e66126b9", "url": "https://github.com/apache/iceberg/commit/4e53dd02075ae619ba86b0d0d7a2ffc0e66126b9", "message": "minor improvements", "committedDate": "2021-04-18T07:00:39Z", "type": "commit"}, {"oid": "4e53dd02075ae619ba86b0d0d7a2ffc0e66126b9", "url": "https://github.com/apache/iceberg/commit/4e53dd02075ae619ba86b0d0d7a2ffc0e66126b9", "message": "minor improvements", "committedDate": "2021-04-18T07:00:39Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzMjAzNjY5NA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r632036694", "bodyText": "Nit: Missing space before opening parens of (if missing).", "author": "kbendick", "createdAt": "2021-05-13T19:02:39Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,394 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    String uri = properties.get(CatalogProperties.URI);\n+    Preconditions.checkNotNull(uri, \"JDBC connection URI is required\");\n+\n+    String warehouse = properties.get(CatalogProperties.WAREHOUSE_LOCATION);\n+    Preconditions.checkNotNull(warehouse, \"JDBC warehouse location is required\");\n+    this.warehouseLocation = warehouse.replaceAll(\"/$\", \"\");\n+\n+    if (name != null) {\n+      this.catalogName = name;\n+    }\n+\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.io = fileIOImpl == null ?\n+        new HadoopFileIO(conf) :\n+        CatalogUtil.loadFileIO(fileIOImpl, properties, conf);\n+\n+    try {\n+      LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.URI));\n+      connections = new JdbcClientPool(uri, properties);\n+      initializeCatalogTables();\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(\"Database Connection timeout\", e);\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(\"Database Connection failed\", e);\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(\"Failed to initialize catalog\", e);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to initialize\", e);\n+    }\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    LOG.trace(\"Creating tables(if missing) to store iceberg catalog\");", "originalCommit": "4e53dd02075ae619ba86b0d0d7a2ffc0e66126b9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNjYwOTIxOA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r636609218", "bodyText": "I don't think we need all the logic in this file, it's much cleaner for everything other than hive and hadoop to be loaded through impl. It makes the user experience much more consistent, and we don't need to keep updating the list of types in documentation.", "author": "jackye1995", "createdAt": "2021-05-21T03:24:02Z", "path": "core/src/main/java/org/apache/iceberg/CatalogUtil.java", "diffHunk": "@@ -48,8 +48,10 @@\n   public static final String ICEBERG_CATALOG_TYPE = \"type\";\n   public static final String ICEBERG_CATALOG_TYPE_HADOOP = \"hadoop\";\n   public static final String ICEBERG_CATALOG_TYPE_HIVE = \"hive\";\n+  public static final String ICEBERG_CATALOG_TYPE_JDBC = \"jdbc\";", "originalCommit": "4e53dd02075ae619ba86b0d0d7a2ffc0e66126b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNzQwMjI2Mg==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r637402262", "bodyText": "makes sense, rolled the change back", "author": "ismailsimsek", "createdAt": "2021-05-22T13:09:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNjYwOTIxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNjYxMDk5MQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r636610991", "bodyText": "nit: no need for newline here", "author": "jackye1995", "createdAt": "2021-05-21T03:29:22Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,394 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    String uri = properties.get(CatalogProperties.URI);\n+    Preconditions.checkNotNull(uri, \"JDBC connection URI is required\");\n+\n+    String warehouse = properties.get(CatalogProperties.WAREHOUSE_LOCATION);\n+    Preconditions.checkNotNull(warehouse, \"JDBC warehouse location is required\");\n+    this.warehouseLocation = warehouse.replaceAll(\"/$\", \"\");\n+\n+    if (name != null) {\n+      this.catalogName = name;\n+    }\n+\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.io = fileIOImpl == null ?\n+        new HadoopFileIO(conf) :", "originalCommit": "4e53dd02075ae619ba86b0d0d7a2ffc0e66126b9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNjYxMTE0Ng==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r636611146", "bodyText": "nit: error message should follow format \"Cannot xxx: reason\"", "author": "jackye1995", "createdAt": "2021-05-21T03:29:58Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,394 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    String uri = properties.get(CatalogProperties.URI);\n+    Preconditions.checkNotNull(uri, \"JDBC connection URI is required\");\n+\n+    String warehouse = properties.get(CatalogProperties.WAREHOUSE_LOCATION);\n+    Preconditions.checkNotNull(warehouse, \"JDBC warehouse location is required\");\n+    this.warehouseLocation = warehouse.replaceAll(\"/$\", \"\");\n+\n+    if (name != null) {\n+      this.catalogName = name;\n+    }\n+\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.io = fileIOImpl == null ?\n+        new HadoopFileIO(conf) :\n+        CatalogUtil.loadFileIO(fileIOImpl, properties, conf);\n+\n+    try {\n+      LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.URI));\n+      connections = new JdbcClientPool(uri, properties);\n+      initializeCatalogTables();\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(\"Database Connection timeout\", e);", "originalCommit": "4e53dd02075ae619ba86b0d0d7a2ffc0e66126b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNzQwMjYxOQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r637402619", "bodyText": "changed to Cannot initialize jdbc catalog: Query timed out", "author": "ismailsimsek", "createdAt": "2021-05-22T13:12:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNjYxMTE0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNjYxMTY3Nw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r636611677", "bodyText": "no need for if condition.", "author": "jackye1995", "createdAt": "2021-05-21T03:32:01Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,394 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    String uri = properties.get(CatalogProperties.URI);\n+    Preconditions.checkNotNull(uri, \"JDBC connection URI is required\");\n+\n+    String warehouse = properties.get(CatalogProperties.WAREHOUSE_LOCATION);\n+    Preconditions.checkNotNull(warehouse, \"JDBC warehouse location is required\");\n+    this.warehouseLocation = warehouse.replaceAll(\"/$\", \"\");\n+\n+    if (name != null) {\n+      this.catalogName = name;\n+    }\n+\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.io = fileIOImpl == null ?\n+        new HadoopFileIO(conf) :\n+        CatalogUtil.loadFileIO(fileIOImpl, properties, conf);\n+\n+    try {\n+      LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.URI));\n+      connections = new JdbcClientPool(uri, properties);\n+      initializeCatalogTables();\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(\"Database Connection timeout\", e);\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(\"Database Connection failed\", e);\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(\"Failed to initialize catalog\", e);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to initialize\", e);\n+    }\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    LOG.trace(\"Creating tables(if missing) to store iceberg catalog\");\n+    connections.run(conn -> {\n+      DatabaseMetaData dbMeta = conn.getMetaData();\n+      ResultSet tableExists = dbMeta.getTables(null, null, JdbcUtil.CATALOG_TABLE_NAME, null);\n+\n+      if (tableExists.next()) {\n+        return true;\n+      }\n+\n+      LOG.debug(\"Creating table {} to store iceberg catalog!\", JdbcUtil.CATALOG_TABLE_NAME);\n+      return conn.prepareStatement(JdbcUtil.CREATE_CATALOG_TABLE).execute();\n+    });\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    return new JdbcTableOperations(connections, io, catalogName, tableIdentifier);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {", "originalCommit": "4e53dd02075ae619ba86b0d0d7a2ffc0e66126b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNzQwMjMzNQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r637402335", "bodyText": "good pint, removed if condition", "author": "ismailsimsek", "createdAt": "2021-05-22T13:09:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNjYxMTY3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNjYxMjg3Nw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r636612877", "bodyText": "should add format constructors following the pattern of other Iceberg exceptions, see ValidationException for more details.", "author": "jackye1995", "createdAt": "2021-05-21T03:36:56Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/UncheckedSQLException.java", "diffHunk": "@@ -0,0 +1,29 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.sql.SQLException;\n+\n+public class UncheckedSQLException extends RuntimeException {\n+\n+  public UncheckedSQLException(String message, SQLException cause) {", "originalCommit": "4e53dd02075ae619ba86b0d0d7a2ffc0e66126b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNzQwMjU1MA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r637402550", "bodyText": "applied", "author": "ismailsimsek", "createdAt": "2021-05-22T13:11:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNjYxMjg3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNjYxMzg5NA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r636613894", "bodyText": "will the test fail if we don't set it back? If not we can remove it, if so we should have a @After to clean this up.", "author": "jackye1995", "createdAt": "2021-05-21T03:41:15Z", "path": "spark3/src/test/java/org/apache/iceberg/actions/TestRemoveOrphanFilesAction3.java", "diffHunk": "@@ -165,4 +165,64 @@ public void testSparkSessionCatalogHiveTable() throws Exception {\n     spark.conf().unset(\"spark.sql.catalog.spark_catalog.type\");\n   }\n \n+  @Test\n+  public void testSparkCatalogNamedJdbcTable() throws Exception {\n+    spark.conf().set(\"spark.sql.catalog.jdbc\", \"org.apache.iceberg.spark.SparkCatalog\");\n+    spark.conf().set(\"spark.sql.catalog.jdbc.type\", \"jdbc\");\n+    spark.conf().set(\"spark.sql.catalog.jdbc.warehouse\", tableLocation);\n+    spark.conf().set(\"spark.sql.catalog.jdbc.uri\", \"jdbc:sqlite:file::memory:?icsparkjdbctestcat;\");\n+    spark.conf().set(\"spark.sql.catalog.jdbc.connection.parameter.user\", \"testuser\");\n+    spark.conf().set(\"spark.sql.catalog.jdbc.connection.parameter.password\", \"testpassword\");\n+    SparkCatalog cat = (SparkCatalog) spark.sessionState().catalogManager().catalog(\"jdbc\");\n+\n+    String[] database = {\"default\"};\n+    Identifier id = Identifier.of(database, \"table\");\n+    Map<String, String> options = Maps.newHashMap();\n+    Transform[] transforms = {};\n+    cat.createTable(id, SparkSchemaUtil.convert(SCHEMA), transforms, options);\n+    SparkTable table = cat.loadTable(id);\n+\n+    spark.sql(\"INSERT INTO jdbc.default.table VALUES (1,1,1)\");\n+\n+    String location = table.table().location().replaceFirst(\"file:\", \"\");\n+    new File(location + \"/data/trashfile\").createNewFile();\n+\n+    List<String> results = Actions.forTable(table.table()).removeOrphanFiles()\n+        .olderThan(System.currentTimeMillis() + 1000).execute();\n+    Assert.assertTrue(\"trash file should be removed\",\n+        results.contains(\"file:\" + location + \"/data/trashfile\"));\n+  }\n+\n+  @Test\n+  public void testSparkSessionCatalogJdbcTable() throws Exception {\n+    spark.conf().set(\"spark.sql.catalog.spark_catalog\", \"org.apache.iceberg.spark.SparkSessionCatalog\");\n+    spark.conf().set(\"spark.sql.catalog.spark_catalog.type\", \"jdbc\");\n+    spark.conf().set(\"spark.sql.catalog.spark_catalog.warehouse\", tableLocation);\n+    spark.conf().set(\"spark.sql.catalog.spark_catalog.uri\", \"jdbc:sqlite:file::memory:?icsparktestcat;\");\n+    spark.conf().set(\"spark.sql.catalog.spark_catalog.connection.parameter.user\", \"testuser\");\n+    spark.conf().set(\"spark.sql.catalog.spark_catalog.connection.parameter.password\", \"testpassword\");\n+    SparkSessionCatalog cat = (SparkSessionCatalog) spark.sessionState().catalogManager().v2SessionCatalog();\n+\n+    String[] database = {\"default\"};\n+    Identifier id = Identifier.of(database, \"sessioncattest\");\n+    Map<String, String> options = Maps.newHashMap();\n+    Transform[] transforms = {};\n+    cat.dropTable(id);\n+    cat.createTable(id, SparkSchemaUtil.convert(SCHEMA), transforms, options);\n+    SparkTable table = (SparkTable) cat.loadTable(id);\n+\n+    spark.sql(\"INSERT INTO default.sessioncattest VALUES (1,1,1)\");\n+\n+    String location = table.table().location().replaceFirst(\"file:\", \"\");\n+    new File(location + \"/data/trashfile\").createNewFile();\n+\n+    List<String> results = Actions.forTable(table.table()).removeOrphanFiles()\n+        .olderThan(System.currentTimeMillis() + 1000).execute();\n+    Assert.assertTrue(\"trash file should be removed\",\n+        results.contains(\"file:\" + location + \"/data/trashfile\"));\n+    // reset spark_catalog to default", "originalCommit": "4e53dd02075ae619ba86b0d0d7a2ffc0e66126b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNzQwMzY3Ng==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r637403676", "bodyText": "after rolling back CatalogUtil change i believe jdbc related test are not necessary, so rolled back the changes, it was duplication of existing tests, probably we could add better spark-jdbc-catalog tests with new PR? what do you think?\nmoved reset...xxx section to resetSparkSessionCatalog using @After", "author": "ismailsimsek", "createdAt": "2021-05-22T13:23:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNjYxMzg5NA=="}], "type": "inlineReview"}, {"oid": "fc9446405e27bbf8d4487dd4142079d5265c7336", "url": "https://github.com/apache/iceberg/commit/fc9446405e27bbf8d4487dd4142079d5265c7336", "message": "implement review changes", "committedDate": "2021-05-22T10:23:16Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNzYxNjA5Mg==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r637616092", "bodyText": "We may want to consider an UncheckedInterruptedException like UncheckedIOException and UncheckedSQLException.", "author": "rdblue", "createdAt": "2021-05-23T23:27:17Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,388 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    String uri = properties.get(CatalogProperties.URI);\n+    Preconditions.checkNotNull(uri, \"JDBC connection URI is required\");\n+\n+    String warehouse = properties.get(CatalogProperties.WAREHOUSE_LOCATION);\n+    Preconditions.checkNotNull(warehouse, \"JDBC warehouse location is required\");\n+    this.warehouseLocation = warehouse.replaceAll(\"/$\", \"\");\n+\n+    if (name != null) {\n+      this.catalogName = name;\n+    }\n+\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.io = fileIOImpl == null ? new HadoopFileIO(conf) : CatalogUtil.loadFileIO(fileIOImpl, properties, conf);\n+\n+    try {\n+      LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.URI));\n+      connections = new JdbcClientPool(uri, properties);\n+      initializeCatalogTables();\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog: Query timed out\");\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog: Connection failed\");\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog\");\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to initialize\", e);", "originalCommit": "fc9446405e27bbf8d4487dd4142079d5265c7336", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0MTU2NzMyOA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r641567328", "bodyText": "created UncheckedInterruptedException and replaced all", "author": "ismailsimsek", "createdAt": "2021-05-28T13:51:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNzYxNjA5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNzYxNjI5Mg==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r637616292", "bodyText": "Nit: in other log messages and errors, JDBC is in all caps. I think we should use JDBC in messages for consistency, rather than Jdbc.", "author": "rdblue", "createdAt": "2021-05-23T23:28:45Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,388 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    String uri = properties.get(CatalogProperties.URI);\n+    Preconditions.checkNotNull(uri, \"JDBC connection URI is required\");\n+\n+    String warehouse = properties.get(CatalogProperties.WAREHOUSE_LOCATION);\n+    Preconditions.checkNotNull(warehouse, \"JDBC warehouse location is required\");\n+    this.warehouseLocation = warehouse.replaceAll(\"/$\", \"\");\n+\n+    if (name != null) {\n+      this.catalogName = name;\n+    }\n+\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.io = fileIOImpl == null ? new HadoopFileIO(conf) : CatalogUtil.loadFileIO(fileIOImpl, properties, conf);\n+\n+    try {\n+      LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.URI));", "originalCommit": "fc9446405e27bbf8d4487dd4142079d5265c7336", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNzYxNjM2NQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r637616365", "bodyText": "While I appreciate enthusiasm, there's no need for extra characters like ! in log messages.", "author": "rdblue", "createdAt": "2021-05-23T23:29:24Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,388 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    String uri = properties.get(CatalogProperties.URI);\n+    Preconditions.checkNotNull(uri, \"JDBC connection URI is required\");\n+\n+    String warehouse = properties.get(CatalogProperties.WAREHOUSE_LOCATION);\n+    Preconditions.checkNotNull(warehouse, \"JDBC warehouse location is required\");\n+    this.warehouseLocation = warehouse.replaceAll(\"/$\", \"\");\n+\n+    if (name != null) {\n+      this.catalogName = name;\n+    }\n+\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.io = fileIOImpl == null ? new HadoopFileIO(conf) : CatalogUtil.loadFileIO(fileIOImpl, properties, conf);\n+\n+    try {\n+      LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.URI));\n+      connections = new JdbcClientPool(uri, properties);\n+      initializeCatalogTables();\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog: Query timed out\");\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog: Connection failed\");\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog\");\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to initialize\", e);\n+    }\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    LOG.trace(\"Creating database tables (if missing) to store iceberg catalog\");\n+    connections.run(conn -> {\n+      DatabaseMetaData dbMeta = conn.getMetaData();\n+      ResultSet tableExists = dbMeta.getTables(null, null, JdbcUtil.CATALOG_TABLE_NAME, null);\n+\n+      if (tableExists.next()) {\n+        return true;\n+      }\n+\n+      LOG.debug(\"Creating table {} to store iceberg catalog!\", JdbcUtil.CATALOG_TABLE_NAME);", "originalCommit": "fc9446405e27bbf8d4487dd4142079d5265c7336", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0MTQ5OTU1Nw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r641499557", "bodyText": "aligned log messages with hive and removed !", "author": "ismailsimsek", "createdAt": "2021-05-28T12:10:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNzYxNjM2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNzYxNjU5OQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r637616599", "bodyText": "In HadoopCatalog, this is /*$. Maybe we should do the same here?", "author": "rdblue", "createdAt": "2021-05-23T23:31:16Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,388 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    String uri = properties.get(CatalogProperties.URI);\n+    Preconditions.checkNotNull(uri, \"JDBC connection URI is required\");\n+\n+    String warehouse = properties.get(CatalogProperties.WAREHOUSE_LOCATION);\n+    Preconditions.checkNotNull(warehouse, \"JDBC warehouse location is required\");\n+    this.warehouseLocation = warehouse.replaceAll(\"/$\", \"\");", "originalCommit": "fc9446405e27bbf8d4487dd4142079d5265c7336", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNzYxNjY4Mg==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r637616682", "bodyText": "Nit: we don't typically start a method with an empty line.", "author": "rdblue", "createdAt": "2021-05-23T23:31:45Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,388 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    String uri = properties.get(CatalogProperties.URI);\n+    Preconditions.checkNotNull(uri, \"JDBC connection URI is required\");\n+\n+    String warehouse = properties.get(CatalogProperties.WAREHOUSE_LOCATION);\n+    Preconditions.checkNotNull(warehouse, \"JDBC warehouse location is required\");\n+    this.warehouseLocation = warehouse.replaceAll(\"/$\", \"\");\n+\n+    if (name != null) {\n+      this.catalogName = name;\n+    }\n+\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.io = fileIOImpl == null ? new HadoopFileIO(conf) : CatalogUtil.loadFileIO(fileIOImpl, properties, conf);\n+\n+    try {\n+      LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.URI));\n+      connections = new JdbcClientPool(uri, properties);\n+      initializeCatalogTables();\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog: Query timed out\");\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog: Connection failed\");\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog\");\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to initialize\", e);\n+    }\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    LOG.trace(\"Creating database tables (if missing) to store iceberg catalog\");\n+    connections.run(conn -> {\n+      DatabaseMetaData dbMeta = conn.getMetaData();\n+      ResultSet tableExists = dbMeta.getTables(null, null, JdbcUtil.CATALOG_TABLE_NAME, null);\n+\n+      if (tableExists.next()) {\n+        return true;\n+      }\n+\n+      LOG.debug(\"Creating table {} to store iceberg catalog!\", JdbcUtil.CATALOG_TABLE_NAME);\n+      return conn.prepareStatement(JdbcUtil.CREATE_CATALOG_TABLE).execute();\n+    });\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    return new JdbcTableOperations(connections, io, catalogName, tableIdentifier);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    return SLASH.join(defaultNamespaceLocation(table.namespace()), table.name());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+", "originalCommit": "fc9446405e27bbf8d4487dd4142079d5265c7336", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNzYxNzA1OQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r637617059", "bodyText": "Nit: unnecessary newline at the end of the method.", "author": "rdblue", "createdAt": "2021-05-23T23:34:56Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,388 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    String uri = properties.get(CatalogProperties.URI);\n+    Preconditions.checkNotNull(uri, \"JDBC connection URI is required\");\n+\n+    String warehouse = properties.get(CatalogProperties.WAREHOUSE_LOCATION);\n+    Preconditions.checkNotNull(warehouse, \"JDBC warehouse location is required\");\n+    this.warehouseLocation = warehouse.replaceAll(\"/$\", \"\");\n+\n+    if (name != null) {\n+      this.catalogName = name;\n+    }\n+\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.io = fileIOImpl == null ? new HadoopFileIO(conf) : CatalogUtil.loadFileIO(fileIOImpl, properties, conf);\n+\n+    try {\n+      LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.URI));\n+      connections = new JdbcClientPool(uri, properties);\n+      initializeCatalogTables();\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog: Query timed out\");\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog: Connection failed\");\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog\");\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to initialize\", e);\n+    }\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    LOG.trace(\"Creating database tables (if missing) to store iceberg catalog\");\n+    connections.run(conn -> {\n+      DatabaseMetaData dbMeta = conn.getMetaData();\n+      ResultSet tableExists = dbMeta.getTables(null, null, JdbcUtil.CATALOG_TABLE_NAME, null);\n+\n+      if (tableExists.next()) {\n+        return true;\n+      }\n+\n+      LOG.debug(\"Creating table {} to store iceberg catalog!\", JdbcUtil.CATALOG_TABLE_NAME);\n+      return conn.prepareStatement(JdbcUtil.CREATE_CATALOG_TABLE).execute();\n+    });\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    return new JdbcTableOperations(connections, io, catalogName, tableIdentifier);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    return SLASH.join(defaultNamespaceLocation(table.namespace()), table.name());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+\n+    int deletedRecords;\n+    try {\n+      deletedRecords = connections.run(conn -> {\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.DROP_TABLE_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(identifier.namespace()));\n+          sql.setString(3, identifier.name());\n+          return sql.executeUpdate();\n+        }\n+      });\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to drop %s\", identifier);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to dropTable\", e);\n+    }\n+\n+    if (deletedRecords > 0) {\n+      LOG.info(\"Successfully dropped table {}.\", identifier);\n+    } else {\n+      LOG.info(\"Cannot drop table: {}! table not found in the catalog.\", identifier);\n+      return false;\n+    }\n+\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata = ops.current();\n+\n+    if (purge && lastMetadata != null) {\n+      CatalogUtil.dropTableData(ops.io(), lastMetadata);\n+      LOG.info(\"Table {} data purged!\", identifier);\n+    }\n+\n+    return true;\n+", "originalCommit": "fc9446405e27bbf8d4487dd4142079d5265c7336", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNzYxNzMwNA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r637617304", "bodyText": "I think we should base logging on what's done in the HiveCatalog. That way it is consistent. Here's the log for drop table: https://github.com/apache/iceberg/blob/master/hive-metastore/src/main/java/org/apache/iceberg/hive/HiveCatalog.java#L175\nThat also doesn't log if no table was dropped because it doesn't exist. I think that's the right call because we don't want to overwhelm the log with what didn't happen. At most that information should be logged at debug.", "author": "rdblue", "createdAt": "2021-05-23T23:36:53Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,388 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    String uri = properties.get(CatalogProperties.URI);\n+    Preconditions.checkNotNull(uri, \"JDBC connection URI is required\");\n+\n+    String warehouse = properties.get(CatalogProperties.WAREHOUSE_LOCATION);\n+    Preconditions.checkNotNull(warehouse, \"JDBC warehouse location is required\");\n+    this.warehouseLocation = warehouse.replaceAll(\"/$\", \"\");\n+\n+    if (name != null) {\n+      this.catalogName = name;\n+    }\n+\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.io = fileIOImpl == null ? new HadoopFileIO(conf) : CatalogUtil.loadFileIO(fileIOImpl, properties, conf);\n+\n+    try {\n+      LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.URI));\n+      connections = new JdbcClientPool(uri, properties);\n+      initializeCatalogTables();\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog: Query timed out\");\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog: Connection failed\");\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog\");\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to initialize\", e);\n+    }\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    LOG.trace(\"Creating database tables (if missing) to store iceberg catalog\");\n+    connections.run(conn -> {\n+      DatabaseMetaData dbMeta = conn.getMetaData();\n+      ResultSet tableExists = dbMeta.getTables(null, null, JdbcUtil.CATALOG_TABLE_NAME, null);\n+\n+      if (tableExists.next()) {\n+        return true;\n+      }\n+\n+      LOG.debug(\"Creating table {} to store iceberg catalog!\", JdbcUtil.CATALOG_TABLE_NAME);\n+      return conn.prepareStatement(JdbcUtil.CREATE_CATALOG_TABLE).execute();\n+    });\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    return new JdbcTableOperations(connections, io, catalogName, tableIdentifier);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    return SLASH.join(defaultNamespaceLocation(table.namespace()), table.name());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+\n+    int deletedRecords;\n+    try {\n+      deletedRecords = connections.run(conn -> {\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.DROP_TABLE_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(identifier.namespace()));\n+          sql.setString(3, identifier.name());\n+          return sql.executeUpdate();\n+        }\n+      });\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to drop %s\", identifier);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to dropTable\", e);\n+    }\n+\n+    if (deletedRecords > 0) {\n+      LOG.info(\"Successfully dropped table {}.\", identifier);", "originalCommit": "fc9446405e27bbf8d4487dd4142079d5265c7336", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0MTU0MTY1NA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r641541654", "bodyText": "aligned logs with hive,\nit seems when table not exists hive throws exception then its handled in catch section, on jdbc case there is no exception thrown but deletedRecords=0 , what do you think changing loglevel to debug and keeping retun false ?\n} catch (NoSuchTableException | NoSuchObjectException e) {\nLOG.info(\"Skipping drop, table does not exist: {}\", identifier, e);\n<span class=\"pl-k\">return</span> <span class=\"pl-c1\">false</span>;", "author": "ismailsimsek", "createdAt": "2021-05-28T13:18:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNzYxNzMwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NDA1MTY3Mg==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r654051672", "bodyText": "I'm okay with either debug or info for this one.", "author": "rdblue", "createdAt": "2021-06-17T23:42:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNzYxNzMwNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNzYxNzU0MQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r637617541", "bodyText": "I think this should be info. And we should follow the conventions in the HiveCatalog: https://github.com/apache/iceberg/blob/master/hive-metastore/src/main/java/org/apache/iceberg/hive/HiveCatalog.java#L216", "author": "rdblue", "createdAt": "2021-05-23T23:39:07Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,388 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    String uri = properties.get(CatalogProperties.URI);\n+    Preconditions.checkNotNull(uri, \"JDBC connection URI is required\");\n+\n+    String warehouse = properties.get(CatalogProperties.WAREHOUSE_LOCATION);\n+    Preconditions.checkNotNull(warehouse, \"JDBC warehouse location is required\");\n+    this.warehouseLocation = warehouse.replaceAll(\"/$\", \"\");\n+\n+    if (name != null) {\n+      this.catalogName = name;\n+    }\n+\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.io = fileIOImpl == null ? new HadoopFileIO(conf) : CatalogUtil.loadFileIO(fileIOImpl, properties, conf);\n+\n+    try {\n+      LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.URI));\n+      connections = new JdbcClientPool(uri, properties);\n+      initializeCatalogTables();\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog: Query timed out\");\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog: Connection failed\");\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog\");\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to initialize\", e);\n+    }\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    LOG.trace(\"Creating database tables (if missing) to store iceberg catalog\");\n+    connections.run(conn -> {\n+      DatabaseMetaData dbMeta = conn.getMetaData();\n+      ResultSet tableExists = dbMeta.getTables(null, null, JdbcUtil.CATALOG_TABLE_NAME, null);\n+\n+      if (tableExists.next()) {\n+        return true;\n+      }\n+\n+      LOG.debug(\"Creating table {} to store iceberg catalog!\", JdbcUtil.CATALOG_TABLE_NAME);\n+      return conn.prepareStatement(JdbcUtil.CREATE_CATALOG_TABLE).execute();\n+    });\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    return new JdbcTableOperations(connections, io, catalogName, tableIdentifier);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    return SLASH.join(defaultNamespaceLocation(table.namespace()), table.name());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+\n+    int deletedRecords;\n+    try {\n+      deletedRecords = connections.run(conn -> {\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.DROP_TABLE_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(identifier.namespace()));\n+          sql.setString(3, identifier.name());\n+          return sql.executeUpdate();\n+        }\n+      });\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to drop %s\", identifier);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to dropTable\", e);\n+    }\n+\n+    if (deletedRecords > 0) {\n+      LOG.info(\"Successfully dropped table {}.\", identifier);\n+    } else {\n+      LOG.info(\"Cannot drop table: {}! table not found in the catalog.\", identifier);\n+      return false;\n+    }\n+\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata = ops.current();\n+\n+    if (purge && lastMetadata != null) {\n+      CatalogUtil.dropTableData(ops.io(), lastMetadata);\n+      LOG.info(\"Table {} data purged!\", identifier);\n+    }\n+\n+    return true;\n+\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    if (!namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Namespace does not exist: %s\", namespace);\n+    }\n+\n+    try {\n+      return connections.run(conn -> {\n+        List<TableIdentifier> results = Lists.newArrayList();\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.LIST_TABLES_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(namespace));\n+\n+          ResultSet rs = sql.executeQuery();\n+          while (rs.next()) {\n+            results.add(JdbcUtil.stringToTableIdentifier(rs.getString(JdbcUtil.TABLE_NAMESPACE), rs.getString(\n+                JdbcUtil.TABLE_NAME)));\n+          }\n+\n+          return results;\n+        }\n+      });\n+\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to list tables in namespace: %s\", namespace);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted during JDBC operation\", e);\n+    }\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier to) {\n+    try {\n+      int updatedRecords = connections.run(conn -> {\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.RENAME_TABLE_SQL)) {\n+          // SET\n+          sql.setString(1, JdbcUtil.namespaceToString(to.namespace()));\n+          sql.setString(2, to.name());\n+          // WHERE\n+          sql.setString(3, catalogName);\n+          sql.setString(4, JdbcUtil.namespaceToString(from.namespace()));\n+          sql.setString(5, from.name());\n+          return sql.executeUpdate();\n+        }\n+      });\n+\n+      if (updatedRecords == 1) {\n+        LOG.debug(\"Successfully renamed table from {} to {}!\", from, to);", "originalCommit": "fc9446405e27bbf8d4487dd4142079d5265c7336", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNzYxNzk4MQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r637617981", "bodyText": "This violates our assumption about tables, but it doesn't mean the operation failed. Javadoc states that this will return the number of affected rows or 0. So if this isn't 0 or 1, then it means that more than 1 row was affected and our underlying primary key assumption is violated. I think in that case we want an error message that highlights the problem at WARNING: \"Rename operation affected %s rows: the catalog table's primary key assumption has been violated\"", "author": "rdblue", "createdAt": "2021-05-23T23:42:17Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,388 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    String uri = properties.get(CatalogProperties.URI);\n+    Preconditions.checkNotNull(uri, \"JDBC connection URI is required\");\n+\n+    String warehouse = properties.get(CatalogProperties.WAREHOUSE_LOCATION);\n+    Preconditions.checkNotNull(warehouse, \"JDBC warehouse location is required\");\n+    this.warehouseLocation = warehouse.replaceAll(\"/$\", \"\");\n+\n+    if (name != null) {\n+      this.catalogName = name;\n+    }\n+\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.io = fileIOImpl == null ? new HadoopFileIO(conf) : CatalogUtil.loadFileIO(fileIOImpl, properties, conf);\n+\n+    try {\n+      LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.URI));\n+      connections = new JdbcClientPool(uri, properties);\n+      initializeCatalogTables();\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog: Query timed out\");\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog: Connection failed\");\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog\");\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to initialize\", e);\n+    }\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    LOG.trace(\"Creating database tables (if missing) to store iceberg catalog\");\n+    connections.run(conn -> {\n+      DatabaseMetaData dbMeta = conn.getMetaData();\n+      ResultSet tableExists = dbMeta.getTables(null, null, JdbcUtil.CATALOG_TABLE_NAME, null);\n+\n+      if (tableExists.next()) {\n+        return true;\n+      }\n+\n+      LOG.debug(\"Creating table {} to store iceberg catalog!\", JdbcUtil.CATALOG_TABLE_NAME);\n+      return conn.prepareStatement(JdbcUtil.CREATE_CATALOG_TABLE).execute();\n+    });\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    return new JdbcTableOperations(connections, io, catalogName, tableIdentifier);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    return SLASH.join(defaultNamespaceLocation(table.namespace()), table.name());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+\n+    int deletedRecords;\n+    try {\n+      deletedRecords = connections.run(conn -> {\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.DROP_TABLE_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(identifier.namespace()));\n+          sql.setString(3, identifier.name());\n+          return sql.executeUpdate();\n+        }\n+      });\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to drop %s\", identifier);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to dropTable\", e);\n+    }\n+\n+    if (deletedRecords > 0) {\n+      LOG.info(\"Successfully dropped table {}.\", identifier);\n+    } else {\n+      LOG.info(\"Cannot drop table: {}! table not found in the catalog.\", identifier);\n+      return false;\n+    }\n+\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata = ops.current();\n+\n+    if (purge && lastMetadata != null) {\n+      CatalogUtil.dropTableData(ops.io(), lastMetadata);\n+      LOG.info(\"Table {} data purged!\", identifier);\n+    }\n+\n+    return true;\n+\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    if (!namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Namespace does not exist: %s\", namespace);\n+    }\n+\n+    try {\n+      return connections.run(conn -> {\n+        List<TableIdentifier> results = Lists.newArrayList();\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.LIST_TABLES_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(namespace));\n+\n+          ResultSet rs = sql.executeQuery();\n+          while (rs.next()) {\n+            results.add(JdbcUtil.stringToTableIdentifier(rs.getString(JdbcUtil.TABLE_NAMESPACE), rs.getString(\n+                JdbcUtil.TABLE_NAME)));\n+          }\n+\n+          return results;\n+        }\n+      });\n+\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to list tables in namespace: %s\", namespace);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted during JDBC operation\", e);\n+    }\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier to) {\n+    try {\n+      int updatedRecords = connections.run(conn -> {\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.RENAME_TABLE_SQL)) {\n+          // SET\n+          sql.setString(1, JdbcUtil.namespaceToString(to.namespace()));\n+          sql.setString(2, to.name());\n+          // WHERE\n+          sql.setString(3, catalogName);\n+          sql.setString(4, JdbcUtil.namespaceToString(from.namespace()));\n+          sql.setString(5, from.name());\n+          return sql.executeUpdate();\n+        }\n+      });\n+\n+      if (updatedRecords == 1) {\n+        LOG.debug(\"Successfully renamed table from {} to {}!\", from, to);\n+      } else if (updatedRecords == 0) {\n+        throw new NoSuchTableException(\"Failed to rename table! Table '%s' not found in the catalog!\", from);\n+      } else {\n+        throw new RuntimeException(\"Failed to rename table! Rename operation Failed\");", "originalCommit": "fc9446405e27bbf8d4487dd4142079d5265c7336", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNzYxODAzNw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r637618037", "bodyText": "We should also mimic the error messages from HiveCatalog: https://github.com/apache/iceberg/blob/master/hive-metastore/src/main/java/org/apache/iceberg/hive/HiveCatalog.java#L222", "author": "rdblue", "createdAt": "2021-05-23T23:42:58Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,388 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    String uri = properties.get(CatalogProperties.URI);\n+    Preconditions.checkNotNull(uri, \"JDBC connection URI is required\");\n+\n+    String warehouse = properties.get(CatalogProperties.WAREHOUSE_LOCATION);\n+    Preconditions.checkNotNull(warehouse, \"JDBC warehouse location is required\");\n+    this.warehouseLocation = warehouse.replaceAll(\"/$\", \"\");\n+\n+    if (name != null) {\n+      this.catalogName = name;\n+    }\n+\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.io = fileIOImpl == null ? new HadoopFileIO(conf) : CatalogUtil.loadFileIO(fileIOImpl, properties, conf);\n+\n+    try {\n+      LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.URI));\n+      connections = new JdbcClientPool(uri, properties);\n+      initializeCatalogTables();\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog: Query timed out\");\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog: Connection failed\");\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog\");\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to initialize\", e);\n+    }\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    LOG.trace(\"Creating database tables (if missing) to store iceberg catalog\");\n+    connections.run(conn -> {\n+      DatabaseMetaData dbMeta = conn.getMetaData();\n+      ResultSet tableExists = dbMeta.getTables(null, null, JdbcUtil.CATALOG_TABLE_NAME, null);\n+\n+      if (tableExists.next()) {\n+        return true;\n+      }\n+\n+      LOG.debug(\"Creating table {} to store iceberg catalog!\", JdbcUtil.CATALOG_TABLE_NAME);\n+      return conn.prepareStatement(JdbcUtil.CREATE_CATALOG_TABLE).execute();\n+    });\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    return new JdbcTableOperations(connections, io, catalogName, tableIdentifier);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    return SLASH.join(defaultNamespaceLocation(table.namespace()), table.name());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+\n+    int deletedRecords;\n+    try {\n+      deletedRecords = connections.run(conn -> {\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.DROP_TABLE_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(identifier.namespace()));\n+          sql.setString(3, identifier.name());\n+          return sql.executeUpdate();\n+        }\n+      });\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to drop %s\", identifier);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to dropTable\", e);\n+    }\n+\n+    if (deletedRecords > 0) {\n+      LOG.info(\"Successfully dropped table {}.\", identifier);\n+    } else {\n+      LOG.info(\"Cannot drop table: {}! table not found in the catalog.\", identifier);\n+      return false;\n+    }\n+\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata = ops.current();\n+\n+    if (purge && lastMetadata != null) {\n+      CatalogUtil.dropTableData(ops.io(), lastMetadata);\n+      LOG.info(\"Table {} data purged!\", identifier);\n+    }\n+\n+    return true;\n+\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    if (!namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Namespace does not exist: %s\", namespace);\n+    }\n+\n+    try {\n+      return connections.run(conn -> {\n+        List<TableIdentifier> results = Lists.newArrayList();\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.LIST_TABLES_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(namespace));\n+\n+          ResultSet rs = sql.executeQuery();\n+          while (rs.next()) {\n+            results.add(JdbcUtil.stringToTableIdentifier(rs.getString(JdbcUtil.TABLE_NAMESPACE), rs.getString(\n+                JdbcUtil.TABLE_NAME)));\n+          }\n+\n+          return results;\n+        }\n+      });\n+\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to list tables in namespace: %s\", namespace);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted during JDBC operation\", e);\n+    }\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier to) {\n+    try {\n+      int updatedRecords = connections.run(conn -> {\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.RENAME_TABLE_SQL)) {\n+          // SET\n+          sql.setString(1, JdbcUtil.namespaceToString(to.namespace()));\n+          sql.setString(2, to.name());\n+          // WHERE\n+          sql.setString(3, catalogName);\n+          sql.setString(4, JdbcUtil.namespaceToString(from.namespace()));\n+          sql.setString(5, from.name());\n+          return sql.executeUpdate();\n+        }\n+      });\n+\n+      if (updatedRecords == 1) {\n+        LOG.debug(\"Successfully renamed table from {} to {}!\", from, to);\n+      } else if (updatedRecords == 0) {\n+        throw new NoSuchTableException(\"Failed to rename table! Table '%s' not found in the catalog!\", from);\n+      } else {\n+        throw new RuntimeException(\"Failed to rename table! Rename operation Failed\");\n+      }\n+\n+    } catch (SQLIntegrityConstraintViolationException e) {\n+      throw new AlreadyExistsException(\"Table with name '%s' already exists in the catalog!\", to);", "originalCommit": "fc9446405e27bbf8d4487dd4142079d5265c7336", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNzYxODIxNA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r637618214", "bodyText": "Nit: no need for a newline here.", "author": "rdblue", "createdAt": "2021-05-23T23:44:02Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,388 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    String uri = properties.get(CatalogProperties.URI);\n+    Preconditions.checkNotNull(uri, \"JDBC connection URI is required\");\n+\n+    String warehouse = properties.get(CatalogProperties.WAREHOUSE_LOCATION);\n+    Preconditions.checkNotNull(warehouse, \"JDBC warehouse location is required\");\n+    this.warehouseLocation = warehouse.replaceAll(\"/$\", \"\");\n+\n+    if (name != null) {\n+      this.catalogName = name;\n+    }\n+\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.io = fileIOImpl == null ? new HadoopFileIO(conf) : CatalogUtil.loadFileIO(fileIOImpl, properties, conf);\n+\n+    try {\n+      LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.URI));\n+      connections = new JdbcClientPool(uri, properties);\n+      initializeCatalogTables();\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog: Query timed out\");\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog: Connection failed\");\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog\");\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to initialize\", e);\n+    }\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    LOG.trace(\"Creating database tables (if missing) to store iceberg catalog\");\n+    connections.run(conn -> {\n+      DatabaseMetaData dbMeta = conn.getMetaData();\n+      ResultSet tableExists = dbMeta.getTables(null, null, JdbcUtil.CATALOG_TABLE_NAME, null);\n+\n+      if (tableExists.next()) {\n+        return true;\n+      }\n+\n+      LOG.debug(\"Creating table {} to store iceberg catalog!\", JdbcUtil.CATALOG_TABLE_NAME);\n+      return conn.prepareStatement(JdbcUtil.CREATE_CATALOG_TABLE).execute();\n+    });\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    return new JdbcTableOperations(connections, io, catalogName, tableIdentifier);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    return SLASH.join(defaultNamespaceLocation(table.namespace()), table.name());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+\n+    int deletedRecords;\n+    try {\n+      deletedRecords = connections.run(conn -> {\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.DROP_TABLE_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(identifier.namespace()));\n+          sql.setString(3, identifier.name());\n+          return sql.executeUpdate();\n+        }\n+      });\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to drop %s\", identifier);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to dropTable\", e);\n+    }\n+\n+    if (deletedRecords > 0) {\n+      LOG.info(\"Successfully dropped table {}.\", identifier);\n+    } else {\n+      LOG.info(\"Cannot drop table: {}! table not found in the catalog.\", identifier);\n+      return false;\n+    }\n+\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata = ops.current();\n+\n+    if (purge && lastMetadata != null) {\n+      CatalogUtil.dropTableData(ops.io(), lastMetadata);\n+      LOG.info(\"Table {} data purged!\", identifier);\n+    }\n+\n+    return true;\n+\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    if (!namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Namespace does not exist: %s\", namespace);\n+    }\n+\n+    try {\n+      return connections.run(conn -> {\n+        List<TableIdentifier> results = Lists.newArrayList();\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.LIST_TABLES_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(namespace));\n+\n+          ResultSet rs = sql.executeQuery();\n+          while (rs.next()) {\n+            results.add(JdbcUtil.stringToTableIdentifier(rs.getString(JdbcUtil.TABLE_NAMESPACE), rs.getString(\n+                JdbcUtil.TABLE_NAME)));\n+          }\n+\n+          return results;\n+        }\n+      });\n+\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to list tables in namespace: %s\", namespace);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted during JDBC operation\", e);\n+    }\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier to) {\n+    try {\n+      int updatedRecords = connections.run(conn -> {\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.RENAME_TABLE_SQL)) {\n+          // SET\n+          sql.setString(1, JdbcUtil.namespaceToString(to.namespace()));\n+          sql.setString(2, to.name());\n+          // WHERE\n+          sql.setString(3, catalogName);\n+          sql.setString(4, JdbcUtil.namespaceToString(from.namespace()));\n+          sql.setString(5, from.name());\n+          return sql.executeUpdate();\n+        }\n+      });\n+\n+      if (updatedRecords == 1) {\n+        LOG.debug(\"Successfully renamed table from {} to {}!\", from, to);\n+      } else if (updatedRecords == 0) {\n+        throw new NoSuchTableException(\"Failed to rename table! Table '%s' not found in the catalog!\", from);\n+      } else {\n+        throw new RuntimeException(\"Failed to rename table! Rename operation Failed\");\n+      }\n+\n+    } catch (SQLIntegrityConstraintViolationException e) {\n+      throw new AlreadyExistsException(\"Table with name '%s' already exists in the catalog!\", to);\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to rename table\");\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to rename\", e);\n+    }\n+  }\n+\n+  @Override\n+  public String name() {\n+    return catalogName;\n+  }\n+\n+  @Override\n+  public Configuration getConf() {\n+    return conf;\n+  }\n+\n+  @Override\n+  public void setConf(Configuration conf) {\n+    this.conf = conf;\n+  }\n+\n+  @Override\n+  public void createNamespace(Namespace namespace, Map<String, String> metadata) {\n+    throw new UnsupportedOperationException(\"Cannot create namespace \" + namespace +\n+        \": createNamespace is not supported\");\n+  }\n+\n+  @Override\n+  public List<Namespace> listNamespaces(Namespace namespace) throws NoSuchNamespaceException {\n+    if (!namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Namespace does not exist: %s\", namespace);\n+    }\n+\n+    try {\n+", "originalCommit": "fc9446405e27bbf8d4487dd4142079d5265c7336", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNzYxODQ4NA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r637618484", "bodyText": "I prefer not to add logs like this that take up so much space. Debug is okay, but in general I would avoid logs that simply state what happened (and in verbose detail) during normal execution unless it is a significant state change for the DB (like renamed, dropped, or created).", "author": "rdblue", "createdAt": "2021-05-23T23:46:36Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,388 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    String uri = properties.get(CatalogProperties.URI);\n+    Preconditions.checkNotNull(uri, \"JDBC connection URI is required\");\n+\n+    String warehouse = properties.get(CatalogProperties.WAREHOUSE_LOCATION);\n+    Preconditions.checkNotNull(warehouse, \"JDBC warehouse location is required\");\n+    this.warehouseLocation = warehouse.replaceAll(\"/$\", \"\");\n+\n+    if (name != null) {\n+      this.catalogName = name;\n+    }\n+\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.io = fileIOImpl == null ? new HadoopFileIO(conf) : CatalogUtil.loadFileIO(fileIOImpl, properties, conf);\n+\n+    try {\n+      LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.URI));\n+      connections = new JdbcClientPool(uri, properties);\n+      initializeCatalogTables();\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog: Query timed out\");\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog: Connection failed\");\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog\");\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to initialize\", e);\n+    }\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    LOG.trace(\"Creating database tables (if missing) to store iceberg catalog\");\n+    connections.run(conn -> {\n+      DatabaseMetaData dbMeta = conn.getMetaData();\n+      ResultSet tableExists = dbMeta.getTables(null, null, JdbcUtil.CATALOG_TABLE_NAME, null);\n+\n+      if (tableExists.next()) {\n+        return true;\n+      }\n+\n+      LOG.debug(\"Creating table {} to store iceberg catalog!\", JdbcUtil.CATALOG_TABLE_NAME);\n+      return conn.prepareStatement(JdbcUtil.CREATE_CATALOG_TABLE).execute();\n+    });\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    return new JdbcTableOperations(connections, io, catalogName, tableIdentifier);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    return SLASH.join(defaultNamespaceLocation(table.namespace()), table.name());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+\n+    int deletedRecords;\n+    try {\n+      deletedRecords = connections.run(conn -> {\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.DROP_TABLE_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(identifier.namespace()));\n+          sql.setString(3, identifier.name());\n+          return sql.executeUpdate();\n+        }\n+      });\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to drop %s\", identifier);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to dropTable\", e);\n+    }\n+\n+    if (deletedRecords > 0) {\n+      LOG.info(\"Successfully dropped table {}.\", identifier);\n+    } else {\n+      LOG.info(\"Cannot drop table: {}! table not found in the catalog.\", identifier);\n+      return false;\n+    }\n+\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata = ops.current();\n+\n+    if (purge && lastMetadata != null) {\n+      CatalogUtil.dropTableData(ops.io(), lastMetadata);\n+      LOG.info(\"Table {} data purged!\", identifier);\n+    }\n+\n+    return true;\n+\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    if (!namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Namespace does not exist: %s\", namespace);\n+    }\n+\n+    try {\n+      return connections.run(conn -> {\n+        List<TableIdentifier> results = Lists.newArrayList();\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.LIST_TABLES_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(namespace));\n+\n+          ResultSet rs = sql.executeQuery();\n+          while (rs.next()) {\n+            results.add(JdbcUtil.stringToTableIdentifier(rs.getString(JdbcUtil.TABLE_NAMESPACE), rs.getString(\n+                JdbcUtil.TABLE_NAME)));\n+          }\n+\n+          return results;\n+        }\n+      });\n+\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to list tables in namespace: %s\", namespace);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted during JDBC operation\", e);\n+    }\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier to) {\n+    try {\n+      int updatedRecords = connections.run(conn -> {\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.RENAME_TABLE_SQL)) {\n+          // SET\n+          sql.setString(1, JdbcUtil.namespaceToString(to.namespace()));\n+          sql.setString(2, to.name());\n+          // WHERE\n+          sql.setString(3, catalogName);\n+          sql.setString(4, JdbcUtil.namespaceToString(from.namespace()));\n+          sql.setString(5, from.name());\n+          return sql.executeUpdate();\n+        }\n+      });\n+\n+      if (updatedRecords == 1) {\n+        LOG.debug(\"Successfully renamed table from {} to {}!\", from, to);\n+      } else if (updatedRecords == 0) {\n+        throw new NoSuchTableException(\"Failed to rename table! Table '%s' not found in the catalog!\", from);\n+      } else {\n+        throw new RuntimeException(\"Failed to rename table! Rename operation Failed\");\n+      }\n+\n+    } catch (SQLIntegrityConstraintViolationException e) {\n+      throw new AlreadyExistsException(\"Table with name '%s' already exists in the catalog!\", to);\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to rename table\");\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to rename\", e);\n+    }\n+  }\n+\n+  @Override\n+  public String name() {\n+    return catalogName;\n+  }\n+\n+  @Override\n+  public Configuration getConf() {\n+    return conf;\n+  }\n+\n+  @Override\n+  public void setConf(Configuration conf) {\n+    this.conf = conf;\n+  }\n+\n+  @Override\n+  public void createNamespace(Namespace namespace, Map<String, String> metadata) {\n+    throw new UnsupportedOperationException(\"Cannot create namespace \" + namespace +\n+        \": createNamespace is not supported\");\n+  }\n+\n+  @Override\n+  public List<Namespace> listNamespaces(Namespace namespace) throws NoSuchNamespaceException {\n+    if (!namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Namespace does not exist: %s\", namespace);\n+    }\n+\n+    try {\n+\n+      List<Namespace> namespaces = connections.run(conn -> {\n+        List<Namespace> result = Lists.newArrayList();\n+\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.LIST_NAMESPACES_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(namespace) + \"%\");\n+          ResultSet rs = sql.executeQuery();\n+          while (rs.next()) {\n+            result.add(JdbcUtil.stringToNamespace(rs.getString(JdbcUtil.TABLE_NAMESPACE)));\n+          }\n+          rs.close();\n+        }\n+\n+        return result;\n+      });\n+\n+      int subNamespaceLevelLength = namespace.levels().length + 1;\n+      namespaces = namespaces.stream()\n+          // exclude itself\n+          .filter(n -> !n.equals(namespace))\n+          // only get sub namespaces/children\n+          .filter(n -> n.levels().length >= subNamespaceLevelLength)\n+          // only get sub namespaces/children\n+          .map(n -> Namespace.of(\n+              Arrays.stream(n.levels()).limit(subNamespaceLevelLength).toArray(String[]::new)\n+              )\n+          )\n+          // remove duplicates\n+          .distinct()\n+          .collect(Collectors.toList());\n+\n+      LOG.debug(\"From the namespace '{}' found: {}\", namespace, namespaces);", "originalCommit": "fc9446405e27bbf8d4487dd4142079d5265c7336", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNzYxODY2NA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r637618664", "bodyText": "defaultNamespaceLocation supports empty namespaces. Why did you choose to reject empty here?", "author": "rdblue", "createdAt": "2021-05-23T23:48:10Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,388 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    String uri = properties.get(CatalogProperties.URI);\n+    Preconditions.checkNotNull(uri, \"JDBC connection URI is required\");\n+\n+    String warehouse = properties.get(CatalogProperties.WAREHOUSE_LOCATION);\n+    Preconditions.checkNotNull(warehouse, \"JDBC warehouse location is required\");\n+    this.warehouseLocation = warehouse.replaceAll(\"/$\", \"\");\n+\n+    if (name != null) {\n+      this.catalogName = name;\n+    }\n+\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.io = fileIOImpl == null ? new HadoopFileIO(conf) : CatalogUtil.loadFileIO(fileIOImpl, properties, conf);\n+\n+    try {\n+      LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.URI));\n+      connections = new JdbcClientPool(uri, properties);\n+      initializeCatalogTables();\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog: Query timed out\");\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog: Connection failed\");\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog\");\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to initialize\", e);\n+    }\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    LOG.trace(\"Creating database tables (if missing) to store iceberg catalog\");\n+    connections.run(conn -> {\n+      DatabaseMetaData dbMeta = conn.getMetaData();\n+      ResultSet tableExists = dbMeta.getTables(null, null, JdbcUtil.CATALOG_TABLE_NAME, null);\n+\n+      if (tableExists.next()) {\n+        return true;\n+      }\n+\n+      LOG.debug(\"Creating table {} to store iceberg catalog!\", JdbcUtil.CATALOG_TABLE_NAME);\n+      return conn.prepareStatement(JdbcUtil.CREATE_CATALOG_TABLE).execute();\n+    });\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    return new JdbcTableOperations(connections, io, catalogName, tableIdentifier);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    return SLASH.join(defaultNamespaceLocation(table.namespace()), table.name());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+\n+    int deletedRecords;\n+    try {\n+      deletedRecords = connections.run(conn -> {\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.DROP_TABLE_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(identifier.namespace()));\n+          sql.setString(3, identifier.name());\n+          return sql.executeUpdate();\n+        }\n+      });\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to drop %s\", identifier);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to dropTable\", e);\n+    }\n+\n+    if (deletedRecords > 0) {\n+      LOG.info(\"Successfully dropped table {}.\", identifier);\n+    } else {\n+      LOG.info(\"Cannot drop table: {}! table not found in the catalog.\", identifier);\n+      return false;\n+    }\n+\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata = ops.current();\n+\n+    if (purge && lastMetadata != null) {\n+      CatalogUtil.dropTableData(ops.io(), lastMetadata);\n+      LOG.info(\"Table {} data purged!\", identifier);\n+    }\n+\n+    return true;\n+\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    if (!namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Namespace does not exist: %s\", namespace);\n+    }\n+\n+    try {\n+      return connections.run(conn -> {\n+        List<TableIdentifier> results = Lists.newArrayList();\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.LIST_TABLES_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(namespace));\n+\n+          ResultSet rs = sql.executeQuery();\n+          while (rs.next()) {\n+            results.add(JdbcUtil.stringToTableIdentifier(rs.getString(JdbcUtil.TABLE_NAMESPACE), rs.getString(\n+                JdbcUtil.TABLE_NAME)));\n+          }\n+\n+          return results;\n+        }\n+      });\n+\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to list tables in namespace: %s\", namespace);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted during JDBC operation\", e);\n+    }\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier to) {\n+    try {\n+      int updatedRecords = connections.run(conn -> {\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.RENAME_TABLE_SQL)) {\n+          // SET\n+          sql.setString(1, JdbcUtil.namespaceToString(to.namespace()));\n+          sql.setString(2, to.name());\n+          // WHERE\n+          sql.setString(3, catalogName);\n+          sql.setString(4, JdbcUtil.namespaceToString(from.namespace()));\n+          sql.setString(5, from.name());\n+          return sql.executeUpdate();\n+        }\n+      });\n+\n+      if (updatedRecords == 1) {\n+        LOG.debug(\"Successfully renamed table from {} to {}!\", from, to);\n+      } else if (updatedRecords == 0) {\n+        throw new NoSuchTableException(\"Failed to rename table! Table '%s' not found in the catalog!\", from);\n+      } else {\n+        throw new RuntimeException(\"Failed to rename table! Rename operation Failed\");\n+      }\n+\n+    } catch (SQLIntegrityConstraintViolationException e) {\n+      throw new AlreadyExistsException(\"Table with name '%s' already exists in the catalog!\", to);\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to rename table\");\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to rename\", e);\n+    }\n+  }\n+\n+  @Override\n+  public String name() {\n+    return catalogName;\n+  }\n+\n+  @Override\n+  public Configuration getConf() {\n+    return conf;\n+  }\n+\n+  @Override\n+  public void setConf(Configuration conf) {\n+    this.conf = conf;\n+  }\n+\n+  @Override\n+  public void createNamespace(Namespace namespace, Map<String, String> metadata) {\n+    throw new UnsupportedOperationException(\"Cannot create namespace \" + namespace +\n+        \": createNamespace is not supported\");\n+  }\n+\n+  @Override\n+  public List<Namespace> listNamespaces(Namespace namespace) throws NoSuchNamespaceException {\n+    if (!namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Namespace does not exist: %s\", namespace);\n+    }\n+\n+    try {\n+\n+      List<Namespace> namespaces = connections.run(conn -> {\n+        List<Namespace> result = Lists.newArrayList();\n+\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.LIST_NAMESPACES_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(namespace) + \"%\");\n+          ResultSet rs = sql.executeQuery();\n+          while (rs.next()) {\n+            result.add(JdbcUtil.stringToNamespace(rs.getString(JdbcUtil.TABLE_NAMESPACE)));\n+          }\n+          rs.close();\n+        }\n+\n+        return result;\n+      });\n+\n+      int subNamespaceLevelLength = namespace.levels().length + 1;\n+      namespaces = namespaces.stream()\n+          // exclude itself\n+          .filter(n -> !n.equals(namespace))\n+          // only get sub namespaces/children\n+          .filter(n -> n.levels().length >= subNamespaceLevelLength)\n+          // only get sub namespaces/children\n+          .map(n -> Namespace.of(\n+              Arrays.stream(n.levels()).limit(subNamespaceLevelLength).toArray(String[]::new)\n+              )\n+          )\n+          // remove duplicates\n+          .distinct()\n+          .collect(Collectors.toList());\n+\n+      LOG.debug(\"From the namespace '{}' found: {}\", namespace, namespaces);\n+      return namespaces;\n+\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to listNamespaces(namespace) Namespace: \" + namespace, e);\n+    } catch (SQLException e) {\n+      throw new RuntimeException(\"Failed to list all namespace: \" + namespace + \" in catalog!\", e);\n+    }\n+  }\n+\n+  @Override\n+  public Map<String, String> loadNamespaceMetadata(Namespace namespace) throws NoSuchNamespaceException {\n+    if (!namespaceExists(namespace) || namespace.isEmpty()) {", "originalCommit": "fc9446405e27bbf8d4487dd4142079d5265c7336", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0MTU0MjczNg==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r641542736", "bodyText": "updated, now empty namespaces are allowed", "author": "ismailsimsek", "createdAt": "2021-05-28T13:19:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNzYxODY2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNzYxODc2NQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r637618765", "bodyText": "No need to list tables, and because can be replaced with :", "author": "rdblue", "createdAt": "2021-05-23T23:48:51Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,388 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    String uri = properties.get(CatalogProperties.URI);\n+    Preconditions.checkNotNull(uri, \"JDBC connection URI is required\");\n+\n+    String warehouse = properties.get(CatalogProperties.WAREHOUSE_LOCATION);\n+    Preconditions.checkNotNull(warehouse, \"JDBC warehouse location is required\");\n+    this.warehouseLocation = warehouse.replaceAll(\"/$\", \"\");\n+\n+    if (name != null) {\n+      this.catalogName = name;\n+    }\n+\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.io = fileIOImpl == null ? new HadoopFileIO(conf) : CatalogUtil.loadFileIO(fileIOImpl, properties, conf);\n+\n+    try {\n+      LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.URI));\n+      connections = new JdbcClientPool(uri, properties);\n+      initializeCatalogTables();\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog: Query timed out\");\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog: Connection failed\");\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog\");\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to initialize\", e);\n+    }\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    LOG.trace(\"Creating database tables (if missing) to store iceberg catalog\");\n+    connections.run(conn -> {\n+      DatabaseMetaData dbMeta = conn.getMetaData();\n+      ResultSet tableExists = dbMeta.getTables(null, null, JdbcUtil.CATALOG_TABLE_NAME, null);\n+\n+      if (tableExists.next()) {\n+        return true;\n+      }\n+\n+      LOG.debug(\"Creating table {} to store iceberg catalog!\", JdbcUtil.CATALOG_TABLE_NAME);\n+      return conn.prepareStatement(JdbcUtil.CREATE_CATALOG_TABLE).execute();\n+    });\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    return new JdbcTableOperations(connections, io, catalogName, tableIdentifier);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    return SLASH.join(defaultNamespaceLocation(table.namespace()), table.name());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+\n+    int deletedRecords;\n+    try {\n+      deletedRecords = connections.run(conn -> {\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.DROP_TABLE_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(identifier.namespace()));\n+          sql.setString(3, identifier.name());\n+          return sql.executeUpdate();\n+        }\n+      });\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to drop %s\", identifier);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to dropTable\", e);\n+    }\n+\n+    if (deletedRecords > 0) {\n+      LOG.info(\"Successfully dropped table {}.\", identifier);\n+    } else {\n+      LOG.info(\"Cannot drop table: {}! table not found in the catalog.\", identifier);\n+      return false;\n+    }\n+\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata = ops.current();\n+\n+    if (purge && lastMetadata != null) {\n+      CatalogUtil.dropTableData(ops.io(), lastMetadata);\n+      LOG.info(\"Table {} data purged!\", identifier);\n+    }\n+\n+    return true;\n+\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    if (!namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Namespace does not exist: %s\", namespace);\n+    }\n+\n+    try {\n+      return connections.run(conn -> {\n+        List<TableIdentifier> results = Lists.newArrayList();\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.LIST_TABLES_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(namespace));\n+\n+          ResultSet rs = sql.executeQuery();\n+          while (rs.next()) {\n+            results.add(JdbcUtil.stringToTableIdentifier(rs.getString(JdbcUtil.TABLE_NAMESPACE), rs.getString(\n+                JdbcUtil.TABLE_NAME)));\n+          }\n+\n+          return results;\n+        }\n+      });\n+\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to list tables in namespace: %s\", namespace);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted during JDBC operation\", e);\n+    }\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier to) {\n+    try {\n+      int updatedRecords = connections.run(conn -> {\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.RENAME_TABLE_SQL)) {\n+          // SET\n+          sql.setString(1, JdbcUtil.namespaceToString(to.namespace()));\n+          sql.setString(2, to.name());\n+          // WHERE\n+          sql.setString(3, catalogName);\n+          sql.setString(4, JdbcUtil.namespaceToString(from.namespace()));\n+          sql.setString(5, from.name());\n+          return sql.executeUpdate();\n+        }\n+      });\n+\n+      if (updatedRecords == 1) {\n+        LOG.debug(\"Successfully renamed table from {} to {}!\", from, to);\n+      } else if (updatedRecords == 0) {\n+        throw new NoSuchTableException(\"Failed to rename table! Table '%s' not found in the catalog!\", from);\n+      } else {\n+        throw new RuntimeException(\"Failed to rename table! Rename operation Failed\");\n+      }\n+\n+    } catch (SQLIntegrityConstraintViolationException e) {\n+      throw new AlreadyExistsException(\"Table with name '%s' already exists in the catalog!\", to);\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to rename table\");\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to rename\", e);\n+    }\n+  }\n+\n+  @Override\n+  public String name() {\n+    return catalogName;\n+  }\n+\n+  @Override\n+  public Configuration getConf() {\n+    return conf;\n+  }\n+\n+  @Override\n+  public void setConf(Configuration conf) {\n+    this.conf = conf;\n+  }\n+\n+  @Override\n+  public void createNamespace(Namespace namespace, Map<String, String> metadata) {\n+    throw new UnsupportedOperationException(\"Cannot create namespace \" + namespace +\n+        \": createNamespace is not supported\");\n+  }\n+\n+  @Override\n+  public List<Namespace> listNamespaces(Namespace namespace) throws NoSuchNamespaceException {\n+    if (!namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Namespace does not exist: %s\", namespace);\n+    }\n+\n+    try {\n+\n+      List<Namespace> namespaces = connections.run(conn -> {\n+        List<Namespace> result = Lists.newArrayList();\n+\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.LIST_NAMESPACES_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(namespace) + \"%\");\n+          ResultSet rs = sql.executeQuery();\n+          while (rs.next()) {\n+            result.add(JdbcUtil.stringToNamespace(rs.getString(JdbcUtil.TABLE_NAMESPACE)));\n+          }\n+          rs.close();\n+        }\n+\n+        return result;\n+      });\n+\n+      int subNamespaceLevelLength = namespace.levels().length + 1;\n+      namespaces = namespaces.stream()\n+          // exclude itself\n+          .filter(n -> !n.equals(namespace))\n+          // only get sub namespaces/children\n+          .filter(n -> n.levels().length >= subNamespaceLevelLength)\n+          // only get sub namespaces/children\n+          .map(n -> Namespace.of(\n+              Arrays.stream(n.levels()).limit(subNamespaceLevelLength).toArray(String[]::new)\n+              )\n+          )\n+          // remove duplicates\n+          .distinct()\n+          .collect(Collectors.toList());\n+\n+      LOG.debug(\"From the namespace '{}' found: {}\", namespace, namespaces);\n+      return namespaces;\n+\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to listNamespaces(namespace) Namespace: \" + namespace, e);\n+    } catch (SQLException e) {\n+      throw new RuntimeException(\"Failed to list all namespace: \" + namespace + \" in catalog!\", e);\n+    }\n+  }\n+\n+  @Override\n+  public Map<String, String> loadNamespaceMetadata(Namespace namespace) throws NoSuchNamespaceException {\n+    if (!namespaceExists(namespace) || namespace.isEmpty()) {\n+      throw new NoSuchNamespaceException(\"Namespace does not exist: %s\", namespace);\n+    }\n+\n+    return ImmutableMap.of(\"location\", defaultNamespaceLocation(namespace));\n+  }\n+\n+  private String defaultNamespaceLocation(Namespace namespace) {\n+    if (namespace.isEmpty()) {\n+      return warehouseLocation;\n+    } else {\n+      return SLASH.join(warehouseLocation, SLASH.join(namespace.levels()));\n+    }\n+  }\n+\n+  @Override\n+  public boolean dropNamespace(Namespace namespace) throws NamespaceNotEmptyException {\n+    if (!namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Cannot drop namespace %s because it is not found!\", namespace);\n+    }\n+\n+    List<TableIdentifier> tableIdentifiers = listTables(namespace);\n+    if (tableIdentifiers != null && !tableIdentifiers.isEmpty()) {\n+      throw new NamespaceNotEmptyException(\"Cannot drop namespace %s because it is not empty. \" +", "originalCommit": "fc9446405e27bbf8d4487dd4142079d5265c7336", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0MTUwMTc4Nw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r641501787", "bodyText": "aligned log message with hive", "author": "ismailsimsek", "createdAt": "2021-05-28T12:14:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNzYxODc2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNzYxOTAwNA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r637619004", "bodyText": "This conflicts with the stated behavior from the API. If no action is taken, the method should return false: https://github.com/apache/iceberg/blob/master/api/src/main/java/org/apache/iceberg/catalog/SupportsNamespaces.java#L102", "author": "rdblue", "createdAt": "2021-05-23T23:50:31Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,388 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    String uri = properties.get(CatalogProperties.URI);\n+    Preconditions.checkNotNull(uri, \"JDBC connection URI is required\");\n+\n+    String warehouse = properties.get(CatalogProperties.WAREHOUSE_LOCATION);\n+    Preconditions.checkNotNull(warehouse, \"JDBC warehouse location is required\");\n+    this.warehouseLocation = warehouse.replaceAll(\"/$\", \"\");\n+\n+    if (name != null) {\n+      this.catalogName = name;\n+    }\n+\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.io = fileIOImpl == null ? new HadoopFileIO(conf) : CatalogUtil.loadFileIO(fileIOImpl, properties, conf);\n+\n+    try {\n+      LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.URI));\n+      connections = new JdbcClientPool(uri, properties);\n+      initializeCatalogTables();\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog: Query timed out\");\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog: Connection failed\");\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog\");\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to initialize\", e);\n+    }\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    LOG.trace(\"Creating database tables (if missing) to store iceberg catalog\");\n+    connections.run(conn -> {\n+      DatabaseMetaData dbMeta = conn.getMetaData();\n+      ResultSet tableExists = dbMeta.getTables(null, null, JdbcUtil.CATALOG_TABLE_NAME, null);\n+\n+      if (tableExists.next()) {\n+        return true;\n+      }\n+\n+      LOG.debug(\"Creating table {} to store iceberg catalog!\", JdbcUtil.CATALOG_TABLE_NAME);\n+      return conn.prepareStatement(JdbcUtil.CREATE_CATALOG_TABLE).execute();\n+    });\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    return new JdbcTableOperations(connections, io, catalogName, tableIdentifier);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    return SLASH.join(defaultNamespaceLocation(table.namespace()), table.name());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+\n+    int deletedRecords;\n+    try {\n+      deletedRecords = connections.run(conn -> {\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.DROP_TABLE_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(identifier.namespace()));\n+          sql.setString(3, identifier.name());\n+          return sql.executeUpdate();\n+        }\n+      });\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to drop %s\", identifier);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to dropTable\", e);\n+    }\n+\n+    if (deletedRecords > 0) {\n+      LOG.info(\"Successfully dropped table {}.\", identifier);\n+    } else {\n+      LOG.info(\"Cannot drop table: {}! table not found in the catalog.\", identifier);\n+      return false;\n+    }\n+\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata = ops.current();\n+\n+    if (purge && lastMetadata != null) {\n+      CatalogUtil.dropTableData(ops.io(), lastMetadata);\n+      LOG.info(\"Table {} data purged!\", identifier);\n+    }\n+\n+    return true;\n+\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    if (!namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Namespace does not exist: %s\", namespace);\n+    }\n+\n+    try {\n+      return connections.run(conn -> {\n+        List<TableIdentifier> results = Lists.newArrayList();\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.LIST_TABLES_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(namespace));\n+\n+          ResultSet rs = sql.executeQuery();\n+          while (rs.next()) {\n+            results.add(JdbcUtil.stringToTableIdentifier(rs.getString(JdbcUtil.TABLE_NAMESPACE), rs.getString(\n+                JdbcUtil.TABLE_NAME)));\n+          }\n+\n+          return results;\n+        }\n+      });\n+\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to list tables in namespace: %s\", namespace);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted during JDBC operation\", e);\n+    }\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier to) {\n+    try {\n+      int updatedRecords = connections.run(conn -> {\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.RENAME_TABLE_SQL)) {\n+          // SET\n+          sql.setString(1, JdbcUtil.namespaceToString(to.namespace()));\n+          sql.setString(2, to.name());\n+          // WHERE\n+          sql.setString(3, catalogName);\n+          sql.setString(4, JdbcUtil.namespaceToString(from.namespace()));\n+          sql.setString(5, from.name());\n+          return sql.executeUpdate();\n+        }\n+      });\n+\n+      if (updatedRecords == 1) {\n+        LOG.debug(\"Successfully renamed table from {} to {}!\", from, to);\n+      } else if (updatedRecords == 0) {\n+        throw new NoSuchTableException(\"Failed to rename table! Table '%s' not found in the catalog!\", from);\n+      } else {\n+        throw new RuntimeException(\"Failed to rename table! Rename operation Failed\");\n+      }\n+\n+    } catch (SQLIntegrityConstraintViolationException e) {\n+      throw new AlreadyExistsException(\"Table with name '%s' already exists in the catalog!\", to);\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to rename table\");\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to rename\", e);\n+    }\n+  }\n+\n+  @Override\n+  public String name() {\n+    return catalogName;\n+  }\n+\n+  @Override\n+  public Configuration getConf() {\n+    return conf;\n+  }\n+\n+  @Override\n+  public void setConf(Configuration conf) {\n+    this.conf = conf;\n+  }\n+\n+  @Override\n+  public void createNamespace(Namespace namespace, Map<String, String> metadata) {\n+    throw new UnsupportedOperationException(\"Cannot create namespace \" + namespace +\n+        \": createNamespace is not supported\");\n+  }\n+\n+  @Override\n+  public List<Namespace> listNamespaces(Namespace namespace) throws NoSuchNamespaceException {\n+    if (!namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Namespace does not exist: %s\", namespace);\n+    }\n+\n+    try {\n+\n+      List<Namespace> namespaces = connections.run(conn -> {\n+        List<Namespace> result = Lists.newArrayList();\n+\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.LIST_NAMESPACES_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(namespace) + \"%\");\n+          ResultSet rs = sql.executeQuery();\n+          while (rs.next()) {\n+            result.add(JdbcUtil.stringToNamespace(rs.getString(JdbcUtil.TABLE_NAMESPACE)));\n+          }\n+          rs.close();\n+        }\n+\n+        return result;\n+      });\n+\n+      int subNamespaceLevelLength = namespace.levels().length + 1;\n+      namespaces = namespaces.stream()\n+          // exclude itself\n+          .filter(n -> !n.equals(namespace))\n+          // only get sub namespaces/children\n+          .filter(n -> n.levels().length >= subNamespaceLevelLength)\n+          // only get sub namespaces/children\n+          .map(n -> Namespace.of(\n+              Arrays.stream(n.levels()).limit(subNamespaceLevelLength).toArray(String[]::new)\n+              )\n+          )\n+          // remove duplicates\n+          .distinct()\n+          .collect(Collectors.toList());\n+\n+      LOG.debug(\"From the namespace '{}' found: {}\", namespace, namespaces);\n+      return namespaces;\n+\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to listNamespaces(namespace) Namespace: \" + namespace, e);\n+    } catch (SQLException e) {\n+      throw new RuntimeException(\"Failed to list all namespace: \" + namespace + \" in catalog!\", e);\n+    }\n+  }\n+\n+  @Override\n+  public Map<String, String> loadNamespaceMetadata(Namespace namespace) throws NoSuchNamespaceException {\n+    if (!namespaceExists(namespace) || namespace.isEmpty()) {\n+      throw new NoSuchNamespaceException(\"Namespace does not exist: %s\", namespace);\n+    }\n+\n+    return ImmutableMap.of(\"location\", defaultNamespaceLocation(namespace));\n+  }\n+\n+  private String defaultNamespaceLocation(Namespace namespace) {\n+    if (namespace.isEmpty()) {\n+      return warehouseLocation;\n+    } else {\n+      return SLASH.join(warehouseLocation, SLASH.join(namespace.levels()));\n+    }\n+  }\n+\n+  @Override\n+  public boolean dropNamespace(Namespace namespace) throws NamespaceNotEmptyException {\n+    if (!namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Cannot drop namespace %s because it is not found!\", namespace);\n+    }\n+\n+    List<TableIdentifier> tableIdentifiers = listTables(namespace);\n+    if (tableIdentifiers != null && !tableIdentifiers.isEmpty()) {\n+      throw new NamespaceNotEmptyException(\"Cannot drop namespace %s because it is not empty. \" +\n+          \"Namespace contains %s tables\", namespace, tableIdentifiers.size());\n+    }\n+\n+    // namespaces are created/deleted by tables by default return true\n+    // when there is no tables with namespace then its considered dropped\n+    return true;", "originalCommit": "fc9446405e27bbf8d4487dd4142079d5265c7336", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNzYxOTQyMg==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r637619422", "bodyText": "I think this needs to throw UncheckedSQLException. It can't assume that any exception indicates that the table doesn't exist.", "author": "rdblue", "createdAt": "2021-05-23T23:53:35Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,388 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    String uri = properties.get(CatalogProperties.URI);\n+    Preconditions.checkNotNull(uri, \"JDBC connection URI is required\");\n+\n+    String warehouse = properties.get(CatalogProperties.WAREHOUSE_LOCATION);\n+    Preconditions.checkNotNull(warehouse, \"JDBC warehouse location is required\");\n+    this.warehouseLocation = warehouse.replaceAll(\"/$\", \"\");\n+\n+    if (name != null) {\n+      this.catalogName = name;\n+    }\n+\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.io = fileIOImpl == null ? new HadoopFileIO(conf) : CatalogUtil.loadFileIO(fileIOImpl, properties, conf);\n+\n+    try {\n+      LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.URI));\n+      connections = new JdbcClientPool(uri, properties);\n+      initializeCatalogTables();\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog: Query timed out\");\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog: Connection failed\");\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog\");\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to initialize\", e);\n+    }\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    LOG.trace(\"Creating database tables (if missing) to store iceberg catalog\");\n+    connections.run(conn -> {\n+      DatabaseMetaData dbMeta = conn.getMetaData();\n+      ResultSet tableExists = dbMeta.getTables(null, null, JdbcUtil.CATALOG_TABLE_NAME, null);\n+\n+      if (tableExists.next()) {\n+        return true;\n+      }\n+\n+      LOG.debug(\"Creating table {} to store iceberg catalog!\", JdbcUtil.CATALOG_TABLE_NAME);\n+      return conn.prepareStatement(JdbcUtil.CREATE_CATALOG_TABLE).execute();\n+    });\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    return new JdbcTableOperations(connections, io, catalogName, tableIdentifier);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    return SLASH.join(defaultNamespaceLocation(table.namespace()), table.name());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+\n+    int deletedRecords;\n+    try {\n+      deletedRecords = connections.run(conn -> {\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.DROP_TABLE_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(identifier.namespace()));\n+          sql.setString(3, identifier.name());\n+          return sql.executeUpdate();\n+        }\n+      });\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to drop %s\", identifier);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to dropTable\", e);\n+    }\n+\n+    if (deletedRecords > 0) {\n+      LOG.info(\"Successfully dropped table {}.\", identifier);\n+    } else {\n+      LOG.info(\"Cannot drop table: {}! table not found in the catalog.\", identifier);\n+      return false;\n+    }\n+\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata = ops.current();\n+\n+    if (purge && lastMetadata != null) {\n+      CatalogUtil.dropTableData(ops.io(), lastMetadata);\n+      LOG.info(\"Table {} data purged!\", identifier);\n+    }\n+\n+    return true;\n+\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    if (!namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Namespace does not exist: %s\", namespace);\n+    }\n+\n+    try {\n+      return connections.run(conn -> {\n+        List<TableIdentifier> results = Lists.newArrayList();\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.LIST_TABLES_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(namespace));\n+\n+          ResultSet rs = sql.executeQuery();\n+          while (rs.next()) {\n+            results.add(JdbcUtil.stringToTableIdentifier(rs.getString(JdbcUtil.TABLE_NAMESPACE), rs.getString(\n+                JdbcUtil.TABLE_NAME)));\n+          }\n+\n+          return results;\n+        }\n+      });\n+\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to list tables in namespace: %s\", namespace);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted during JDBC operation\", e);\n+    }\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier to) {\n+    try {\n+      int updatedRecords = connections.run(conn -> {\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.RENAME_TABLE_SQL)) {\n+          // SET\n+          sql.setString(1, JdbcUtil.namespaceToString(to.namespace()));\n+          sql.setString(2, to.name());\n+          // WHERE\n+          sql.setString(3, catalogName);\n+          sql.setString(4, JdbcUtil.namespaceToString(from.namespace()));\n+          sql.setString(5, from.name());\n+          return sql.executeUpdate();\n+        }\n+      });\n+\n+      if (updatedRecords == 1) {\n+        LOG.debug(\"Successfully renamed table from {} to {}!\", from, to);\n+      } else if (updatedRecords == 0) {\n+        throw new NoSuchTableException(\"Failed to rename table! Table '%s' not found in the catalog!\", from);\n+      } else {\n+        throw new RuntimeException(\"Failed to rename table! Rename operation Failed\");\n+      }\n+\n+    } catch (SQLIntegrityConstraintViolationException e) {\n+      throw new AlreadyExistsException(\"Table with name '%s' already exists in the catalog!\", to);\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to rename table\");\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to rename\", e);\n+    }\n+  }\n+\n+  @Override\n+  public String name() {\n+    return catalogName;\n+  }\n+\n+  @Override\n+  public Configuration getConf() {\n+    return conf;\n+  }\n+\n+  @Override\n+  public void setConf(Configuration conf) {\n+    this.conf = conf;\n+  }\n+\n+  @Override\n+  public void createNamespace(Namespace namespace, Map<String, String> metadata) {\n+    throw new UnsupportedOperationException(\"Cannot create namespace \" + namespace +\n+        \": createNamespace is not supported\");\n+  }\n+\n+  @Override\n+  public List<Namespace> listNamespaces(Namespace namespace) throws NoSuchNamespaceException {\n+    if (!namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Namespace does not exist: %s\", namespace);\n+    }\n+\n+    try {\n+\n+      List<Namespace> namespaces = connections.run(conn -> {\n+        List<Namespace> result = Lists.newArrayList();\n+\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.LIST_NAMESPACES_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(namespace) + \"%\");\n+          ResultSet rs = sql.executeQuery();\n+          while (rs.next()) {\n+            result.add(JdbcUtil.stringToNamespace(rs.getString(JdbcUtil.TABLE_NAMESPACE)));\n+          }\n+          rs.close();\n+        }\n+\n+        return result;\n+      });\n+\n+      int subNamespaceLevelLength = namespace.levels().length + 1;\n+      namespaces = namespaces.stream()\n+          // exclude itself\n+          .filter(n -> !n.equals(namespace))\n+          // only get sub namespaces/children\n+          .filter(n -> n.levels().length >= subNamespaceLevelLength)\n+          // only get sub namespaces/children\n+          .map(n -> Namespace.of(\n+              Arrays.stream(n.levels()).limit(subNamespaceLevelLength).toArray(String[]::new)\n+              )\n+          )\n+          // remove duplicates\n+          .distinct()\n+          .collect(Collectors.toList());\n+\n+      LOG.debug(\"From the namespace '{}' found: {}\", namespace, namespaces);\n+      return namespaces;\n+\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to listNamespaces(namespace) Namespace: \" + namespace, e);\n+    } catch (SQLException e) {\n+      throw new RuntimeException(\"Failed to list all namespace: \" + namespace + \" in catalog!\", e);\n+    }\n+  }\n+\n+  @Override\n+  public Map<String, String> loadNamespaceMetadata(Namespace namespace) throws NoSuchNamespaceException {\n+    if (!namespaceExists(namespace) || namespace.isEmpty()) {\n+      throw new NoSuchNamespaceException(\"Namespace does not exist: %s\", namespace);\n+    }\n+\n+    return ImmutableMap.of(\"location\", defaultNamespaceLocation(namespace));\n+  }\n+\n+  private String defaultNamespaceLocation(Namespace namespace) {\n+    if (namespace.isEmpty()) {\n+      return warehouseLocation;\n+    } else {\n+      return SLASH.join(warehouseLocation, SLASH.join(namespace.levels()));\n+    }\n+  }\n+\n+  @Override\n+  public boolean dropNamespace(Namespace namespace) throws NamespaceNotEmptyException {\n+    if (!namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Cannot drop namespace %s because it is not found!\", namespace);\n+    }\n+\n+    List<TableIdentifier> tableIdentifiers = listTables(namespace);\n+    if (tableIdentifiers != null && !tableIdentifiers.isEmpty()) {\n+      throw new NamespaceNotEmptyException(\"Cannot drop namespace %s because it is not empty. \" +\n+          \"Namespace contains %s tables\", namespace, tableIdentifiers.size());\n+    }\n+\n+    // namespaces are created/deleted by tables by default return true\n+    // when there is no tables with namespace then its considered dropped\n+    return true;\n+  }\n+\n+  @Override\n+  public boolean setProperties(Namespace namespace, Map<String, String> properties) throws\n+      NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+        \"Cannot set properties \" + namespace + \" : setProperties is not supported\");\n+  }\n+\n+  @Override\n+  public boolean removeProperties(Namespace namespace, Set<String> properties) throws NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+        \"Cannot remove properties \" + namespace + \" : removeProperties is not supported\");\n+  }\n+\n+  @Override\n+  public void close() {\n+    connections.close();\n+  }\n+\n+  @Override\n+  public boolean namespaceExists(Namespace namespace) {\n+    try {\n+      return connections.run(conn -> {\n+        boolean exists = false;\n+\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.GET_NAMESPACE_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(namespace) + \"%\");\n+          ResultSet rs = sql.executeQuery();\n+          if (rs.next()) {\n+            exists = true;\n+          }\n+\n+          rs.close();\n+        }\n+\n+        return exists;\n+      });\n+\n+    } catch (SQLException e) {\n+      LOG.warn(\"SQLException! \", e);\n+      return false;", "originalCommit": "fc9446405e27bbf8d4487dd4142079d5265c7336", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0MTU0MzcxMw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r641543713", "bodyText": "replaced with  throw new UncheckedSQLException(e, \"Failed to get namespace %s\", namespace);", "author": "ismailsimsek", "createdAt": "2021-05-28T13:21:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNzYxOTQyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNzYxOTcxNg==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r637619716", "bodyText": "Minor: it is more readable to wrap lines at the top-level function call's arguments rather than in the middle of those arguments.", "author": "rdblue", "createdAt": "2021-05-23T23:55:49Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,388 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    String uri = properties.get(CatalogProperties.URI);\n+    Preconditions.checkNotNull(uri, \"JDBC connection URI is required\");\n+\n+    String warehouse = properties.get(CatalogProperties.WAREHOUSE_LOCATION);\n+    Preconditions.checkNotNull(warehouse, \"JDBC warehouse location is required\");\n+    this.warehouseLocation = warehouse.replaceAll(\"/$\", \"\");\n+\n+    if (name != null) {\n+      this.catalogName = name;\n+    }\n+\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.io = fileIOImpl == null ? new HadoopFileIO(conf) : CatalogUtil.loadFileIO(fileIOImpl, properties, conf);\n+\n+    try {\n+      LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.URI));\n+      connections = new JdbcClientPool(uri, properties);\n+      initializeCatalogTables();\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog: Query timed out\");\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog: Connection failed\");\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog\");\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to initialize\", e);\n+    }\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    LOG.trace(\"Creating database tables (if missing) to store iceberg catalog\");\n+    connections.run(conn -> {\n+      DatabaseMetaData dbMeta = conn.getMetaData();\n+      ResultSet tableExists = dbMeta.getTables(null, null, JdbcUtil.CATALOG_TABLE_NAME, null);\n+\n+      if (tableExists.next()) {\n+        return true;\n+      }\n+\n+      LOG.debug(\"Creating table {} to store iceberg catalog!\", JdbcUtil.CATALOG_TABLE_NAME);\n+      return conn.prepareStatement(JdbcUtil.CREATE_CATALOG_TABLE).execute();\n+    });\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    return new JdbcTableOperations(connections, io, catalogName, tableIdentifier);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    return SLASH.join(defaultNamespaceLocation(table.namespace()), table.name());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+\n+    int deletedRecords;\n+    try {\n+      deletedRecords = connections.run(conn -> {\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.DROP_TABLE_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(identifier.namespace()));\n+          sql.setString(3, identifier.name());\n+          return sql.executeUpdate();\n+        }\n+      });\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to drop %s\", identifier);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to dropTable\", e);\n+    }\n+\n+    if (deletedRecords > 0) {\n+      LOG.info(\"Successfully dropped table {}.\", identifier);\n+    } else {\n+      LOG.info(\"Cannot drop table: {}! table not found in the catalog.\", identifier);\n+      return false;\n+    }\n+\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata = ops.current();\n+\n+    if (purge && lastMetadata != null) {\n+      CatalogUtil.dropTableData(ops.io(), lastMetadata);\n+      LOG.info(\"Table {} data purged!\", identifier);\n+    }\n+\n+    return true;\n+\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    if (!namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Namespace does not exist: %s\", namespace);\n+    }\n+\n+    try {\n+      return connections.run(conn -> {\n+        List<TableIdentifier> results = Lists.newArrayList();\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.LIST_TABLES_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(namespace));\n+\n+          ResultSet rs = sql.executeQuery();\n+          while (rs.next()) {\n+            results.add(JdbcUtil.stringToTableIdentifier(rs.getString(JdbcUtil.TABLE_NAMESPACE), rs.getString(\n+                JdbcUtil.TABLE_NAME)));", "originalCommit": "fc9446405e27bbf8d4487dd4142079d5265c7336", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNzYxOTg4Mw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r637619883", "bodyText": "If you instantiate the table ops here, then the table will never be cleaned up because it was just removed from the DB above so its metadata is lost.\nLike the Hive implementation, you need to instantiate the table operations, then run the drop only if the metadata is non-null. Otherwise the logic looks correct to me.", "author": "rdblue", "createdAt": "2021-05-23T23:57:24Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,388 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    String uri = properties.get(CatalogProperties.URI);\n+    Preconditions.checkNotNull(uri, \"JDBC connection URI is required\");\n+\n+    String warehouse = properties.get(CatalogProperties.WAREHOUSE_LOCATION);\n+    Preconditions.checkNotNull(warehouse, \"JDBC warehouse location is required\");\n+    this.warehouseLocation = warehouse.replaceAll(\"/$\", \"\");\n+\n+    if (name != null) {\n+      this.catalogName = name;\n+    }\n+\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.io = fileIOImpl == null ? new HadoopFileIO(conf) : CatalogUtil.loadFileIO(fileIOImpl, properties, conf);\n+\n+    try {\n+      LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.URI));\n+      connections = new JdbcClientPool(uri, properties);\n+      initializeCatalogTables();\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog: Query timed out\");\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog: Connection failed\");\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Cannot initialize jdbc catalog\");\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to initialize\", e);\n+    }\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    LOG.trace(\"Creating database tables (if missing) to store iceberg catalog\");\n+    connections.run(conn -> {\n+      DatabaseMetaData dbMeta = conn.getMetaData();\n+      ResultSet tableExists = dbMeta.getTables(null, null, JdbcUtil.CATALOG_TABLE_NAME, null);\n+\n+      if (tableExists.next()) {\n+        return true;\n+      }\n+\n+      LOG.debug(\"Creating table {} to store iceberg catalog!\", JdbcUtil.CATALOG_TABLE_NAME);\n+      return conn.prepareStatement(JdbcUtil.CREATE_CATALOG_TABLE).execute();\n+    });\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    return new JdbcTableOperations(connections, io, catalogName, tableIdentifier);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    return SLASH.join(defaultNamespaceLocation(table.namespace()), table.name());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+\n+    int deletedRecords;\n+    try {\n+      deletedRecords = connections.run(conn -> {\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.DROP_TABLE_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(identifier.namespace()));\n+          sql.setString(3, identifier.name());\n+          return sql.executeUpdate();\n+        }\n+      });\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to drop %s\", identifier);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to dropTable\", e);\n+    }\n+\n+    if (deletedRecords > 0) {\n+      LOG.info(\"Successfully dropped table {}.\", identifier);\n+    } else {\n+      LOG.info(\"Cannot drop table: {}! table not found in the catalog.\", identifier);\n+      return false;\n+    }\n+\n+    TableOperations ops = newTableOps(identifier);", "originalCommit": "fc9446405e27bbf8d4487dd4142079d5265c7336", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0MTU0MTkwOA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r641541908", "bodyText": "moved it to beginning and aligned with hive", "author": "ismailsimsek", "createdAt": "2021-05-28T13:18:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNzYxOTg4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYzNzYyMDAzOQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r637620039", "bodyText": "This is a long parameter prefix. Could we make it shorter, like just jdbc.?", "author": "rdblue", "createdAt": "2021-05-23T23:58:35Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,388 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";", "originalCommit": "fc9446405e27bbf8d4487dd4142079d5265c7336", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "ac7eb42f9609b2425ab5a8c7011483abd66409f9", "url": "https://github.com/apache/iceberg/commit/ac7eb42f9609b2425ab5a8c7011483abd66409f9", "message": "address review comments, align log messages with hive", "committedDate": "2021-05-28T12:04:03Z", "type": "commit"}, {"oid": "287c1051e49322959b448040777a50be64812ceb", "url": "https://github.com/apache/iceberg/commit/287c1051e49322959b448040777a50be64812ceb", "message": "address review comments", "committedDate": "2021-05-28T12:04:03Z", "type": "commit"}, {"oid": "57b83f10a418670a2e76581377c52d5067b14e1c", "url": "https://github.com/apache/iceberg/commit/57b83f10a418670a2e76581377c52d5067b14e1c", "message": "address review comments, allow empty namespace and throw UncheckedSQLException when namespaceExists fails", "committedDate": "2021-05-28T12:53:47Z", "type": "commit"}, {"oid": "4d9028f1d3ef188c3c73fed6a98413289220f5ae", "url": "https://github.com/apache/iceberg/commit/4d9028f1d3ef188c3c73fed6a98413289220f5ae", "message": "checkstyleTest", "committedDate": "2021-05-28T13:03:17Z", "type": "commit"}, {"oid": "cb03b9ce900ab169486965dbb79d3fd5545f09d5", "url": "https://github.com/apache/iceberg/commit/cb03b9ce900ab169486965dbb79d3fd5545f09d5", "message": "address review comments, use UncheckedInterruptedException", "committedDate": "2021-05-28T13:49:33Z", "type": "commit"}, {"oid": "a21579f5fdbb7934f8f7ebee5c8d620830c43310", "url": "https://github.com/apache/iceberg/commit/a21579f5fdbb7934f8f7ebee5c8d620830c43310", "message": "Merge branch 'master' into iceberg_jdbccatalog", "committedDate": "2021-06-17T22:10:51Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NDA1NjMyMQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r654056321", "bodyText": "Nit: should be \"in catalog\" not just \"catalog\"", "author": "rdblue", "createdAt": "2021-06-17T23:57:31Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcTableOperations.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.sql.DataTruncation;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Map;\n+import java.util.Objects;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+class JdbcTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcTableOperations.class);\n+  private final String catalogName;\n+  private final TableIdentifier tableIdentifier;\n+  private final FileIO fileIO;\n+  private final JdbcClientPool connections;\n+\n+  protected JdbcTableOperations(JdbcClientPool dbConnPool, FileIO fileIO, String catalogName,\n+                                TableIdentifier tableIdentifier) {\n+    this.catalogName = catalogName;\n+    this.tableIdentifier = tableIdentifier;\n+    this.fileIO = fileIO;\n+    this.connections = dbConnPool;\n+  }\n+\n+  @Override\n+  public void doRefresh() {\n+    Map<String, String> table;\n+\n+    try {\n+      table = getTable();\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new UncheckedInterruptedException(e, \"Interrupted during refresh\");\n+    } catch (SQLException e) {\n+      // SQL exception happened when getting table from catalog\n+      throw new UncheckedSQLException(e, \"Failed to get table %s from catalog %s\", tableIdentifier, catalogName);\n+    }\n+\n+    // Table not exists AND currentMetadataLocation is not NULL!\n+    if (table.isEmpty() && currentMetadataLocation() != null) {\n+      throw new NoSuchTableException(\"Failed to get table %s from catalog %s\" +\n+          \" maybe another process deleted it\", tableIdentifier, catalogName);\n+    }\n+\n+    // Table not exists in the catalog! metadataLocation is null here!\n+    if (table.isEmpty()) {\n+      refreshFromMetadataLocation(null);\n+      return;\n+    }\n+\n+    // Table exists but metadataLocation is null\n+    if (table.getOrDefault(JdbcUtil.METADATA_LOCATION, null) == null) {\n+      throw new RuntimeException(String.format(\"Failed to get metadata location of the table %s from catalog %s\",\n+          tableIdentifier, catalogName));\n+    }\n+\n+    refreshFromMetadataLocation(table.get(JdbcUtil.METADATA_LOCATION));\n+  }\n+\n+  @Override\n+  public void doCommit(TableMetadata base, TableMetadata metadata) {\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+    try {\n+      Map<String, String> table = getTable();\n+\n+      if (!table.isEmpty()) {\n+        validateMetadataLocation(table, base);\n+        String oldMetadataLocation = base.metadataFileLocation();\n+        // Start atomic update\n+        LOG.debug(\"Committing existing table: {}\", tableName());\n+        updateTable(newMetadataLocation, oldMetadataLocation);\n+      } else {\n+        // table not exists create it\n+        LOG.debug(\"Committing new table: {}\", tableName());\n+        createTable(newMetadataLocation);\n+      }\n+\n+    } catch (SQLIntegrityConstraintViolationException e) {\n+      throw new AlreadyExistsException(e, \"Table already exists, maybe another process created it\");\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(e, \"Database Connection timeout\");\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(e, \"Database Connection failed\");\n+    } catch (DataTruncation e) {\n+      throw new UncheckedSQLException(e, \"Database data truncation error\");\n+    } catch (SQLWarning e) {\n+      throw new UncheckedSQLException(e, \"Database warning\");\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to connect to database\");\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new UncheckedInterruptedException(e, \"Interrupted during commit\");\n+    }\n+  }\n+\n+  private void updateTable(String newMetadataLocation, String oldMetadataLocation)\n+      throws SQLException, InterruptedException {\n+    int updatedRecords = connections.run(conn -> {\n+      try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.DO_COMMIT_SQL)) {\n+        // UPDATE\n+        sql.setString(1, newMetadataLocation);\n+        sql.setString(2, oldMetadataLocation);\n+        // WHERE\n+        sql.setString(3, catalogName);\n+        sql.setString(4, JdbcUtil.namespaceToString(tableIdentifier.namespace()));\n+        sql.setString(5, tableIdentifier.name());\n+        sql.setString(6, oldMetadataLocation);\n+        return sql.executeUpdate();\n+      }\n+    });\n+\n+    if (updatedRecords == 1) {\n+      LOG.debug(\"Successfully committed to existing table: {}\", tableIdentifier);\n+    } else {\n+      throw new CommitFailedException(\"Failed to update the table %s from catalog %s \" +\n+          \"Maybe another process changed it\", tableIdentifier, catalogName);\n+    }\n+\n+  }\n+\n+  private void createTable(String newMetadataLocation) throws SQLException, InterruptedException {\n+    int insertRecord = connections.run(conn -> {\n+      try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.DO_COMMIT_CREATE_TABLE_SQL)) {\n+        sql.setString(1, catalogName);\n+        sql.setString(2, JdbcUtil.namespaceToString(tableIdentifier.namespace()));\n+        sql.setString(3, tableIdentifier.name());\n+        sql.setString(4, newMetadataLocation);\n+        return sql.executeUpdate();\n+      }\n+    });\n+\n+    if (insertRecord == 1) {\n+      LOG.debug(\"Successfully committed to new table: {}\", tableIdentifier);\n+    } else {\n+      throw new CommitFailedException(\"Failed to create table %s catalog %s\", tableIdentifier, catalogName);", "originalCommit": "a21579f5fdbb7934f8f7ebee5c8d620830c43310", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NDA1Njg2Ng==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r654056866", "bodyText": "Nit: No need for \"maybe\" here. It is enough to say that the table has changed.", "author": "rdblue", "createdAt": "2021-06-17T23:59:20Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcTableOperations.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.sql.DataTruncation;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Map;\n+import java.util.Objects;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+class JdbcTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcTableOperations.class);\n+  private final String catalogName;\n+  private final TableIdentifier tableIdentifier;\n+  private final FileIO fileIO;\n+  private final JdbcClientPool connections;\n+\n+  protected JdbcTableOperations(JdbcClientPool dbConnPool, FileIO fileIO, String catalogName,\n+                                TableIdentifier tableIdentifier) {\n+    this.catalogName = catalogName;\n+    this.tableIdentifier = tableIdentifier;\n+    this.fileIO = fileIO;\n+    this.connections = dbConnPool;\n+  }\n+\n+  @Override\n+  public void doRefresh() {\n+    Map<String, String> table;\n+\n+    try {\n+      table = getTable();\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new UncheckedInterruptedException(e, \"Interrupted during refresh\");\n+    } catch (SQLException e) {\n+      // SQL exception happened when getting table from catalog\n+      throw new UncheckedSQLException(e, \"Failed to get table %s from catalog %s\", tableIdentifier, catalogName);\n+    }\n+\n+    // Table not exists AND currentMetadataLocation is not NULL!\n+    if (table.isEmpty() && currentMetadataLocation() != null) {\n+      throw new NoSuchTableException(\"Failed to get table %s from catalog %s\" +\n+          \" maybe another process deleted it\", tableIdentifier, catalogName);\n+    }\n+\n+    // Table not exists in the catalog! metadataLocation is null here!\n+    if (table.isEmpty()) {\n+      refreshFromMetadataLocation(null);\n+      return;\n+    }\n+\n+    // Table exists but metadataLocation is null\n+    if (table.getOrDefault(JdbcUtil.METADATA_LOCATION, null) == null) {\n+      throw new RuntimeException(String.format(\"Failed to get metadata location of the table %s from catalog %s\",\n+          tableIdentifier, catalogName));\n+    }\n+\n+    refreshFromMetadataLocation(table.get(JdbcUtil.METADATA_LOCATION));\n+  }\n+\n+  @Override\n+  public void doCommit(TableMetadata base, TableMetadata metadata) {\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+    try {\n+      Map<String, String> table = getTable();\n+\n+      if (!table.isEmpty()) {\n+        validateMetadataLocation(table, base);\n+        String oldMetadataLocation = base.metadataFileLocation();\n+        // Start atomic update\n+        LOG.debug(\"Committing existing table: {}\", tableName());\n+        updateTable(newMetadataLocation, oldMetadataLocation);\n+      } else {\n+        // table not exists create it\n+        LOG.debug(\"Committing new table: {}\", tableName());\n+        createTable(newMetadataLocation);\n+      }\n+\n+    } catch (SQLIntegrityConstraintViolationException e) {\n+      throw new AlreadyExistsException(e, \"Table already exists, maybe another process created it\");\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(e, \"Database Connection timeout\");\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(e, \"Database Connection failed\");\n+    } catch (DataTruncation e) {\n+      throw new UncheckedSQLException(e, \"Database data truncation error\");\n+    } catch (SQLWarning e) {\n+      throw new UncheckedSQLException(e, \"Database warning\");\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to connect to database\");\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new UncheckedInterruptedException(e, \"Interrupted during commit\");\n+    }\n+  }\n+\n+  private void updateTable(String newMetadataLocation, String oldMetadataLocation)\n+      throws SQLException, InterruptedException {\n+    int updatedRecords = connections.run(conn -> {\n+      try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.DO_COMMIT_SQL)) {\n+        // UPDATE\n+        sql.setString(1, newMetadataLocation);\n+        sql.setString(2, oldMetadataLocation);\n+        // WHERE\n+        sql.setString(3, catalogName);\n+        sql.setString(4, JdbcUtil.namespaceToString(tableIdentifier.namespace()));\n+        sql.setString(5, tableIdentifier.name());\n+        sql.setString(6, oldMetadataLocation);\n+        return sql.executeUpdate();\n+      }\n+    });\n+\n+    if (updatedRecords == 1) {\n+      LOG.debug(\"Successfully committed to existing table: {}\", tableIdentifier);\n+    } else {\n+      throw new CommitFailedException(\"Failed to update the table %s from catalog %s \" +\n+          \"Maybe another process changed it\", tableIdentifier, catalogName);", "originalCommit": "a21579f5fdbb7934f8f7ebee5c8d620830c43310", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NDA1NzM0Ng==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r654057346", "bodyText": "Similar to below, no need for the \"maybe\" statement. This failed to load a table that it expected to exist.", "author": "rdblue", "createdAt": "2021-06-18T00:01:01Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcTableOperations.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.sql.DataTruncation;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Map;\n+import java.util.Objects;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+class JdbcTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcTableOperations.class);\n+  private final String catalogName;\n+  private final TableIdentifier tableIdentifier;\n+  private final FileIO fileIO;\n+  private final JdbcClientPool connections;\n+\n+  protected JdbcTableOperations(JdbcClientPool dbConnPool, FileIO fileIO, String catalogName,\n+                                TableIdentifier tableIdentifier) {\n+    this.catalogName = catalogName;\n+    this.tableIdentifier = tableIdentifier;\n+    this.fileIO = fileIO;\n+    this.connections = dbConnPool;\n+  }\n+\n+  @Override\n+  public void doRefresh() {\n+    Map<String, String> table;\n+\n+    try {\n+      table = getTable();\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new UncheckedInterruptedException(e, \"Interrupted during refresh\");\n+    } catch (SQLException e) {\n+      // SQL exception happened when getting table from catalog\n+      throw new UncheckedSQLException(e, \"Failed to get table %s from catalog %s\", tableIdentifier, catalogName);\n+    }\n+\n+    // Table not exists AND currentMetadataLocation is not NULL!\n+    if (table.isEmpty() && currentMetadataLocation() != null) {\n+      throw new NoSuchTableException(\"Failed to get table %s from catalog %s\" +\n+          \" maybe another process deleted it\", tableIdentifier, catalogName);", "originalCommit": "a21579f5fdbb7934f8f7ebee5c8d620830c43310", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "d9ab91975a557761dc262c85e3d87863669ca81a", "url": "https://github.com/apache/iceberg/commit/d9ab91975a557761dc262c85e3d87863669ca81a", "message": "address review comments, updated logging messages", "committedDate": "2021-06-18T14:02:34Z", "type": "commit"}, {"oid": "6d99ec0d420cec9070d254427e6d599d69f14422", "url": "https://github.com/apache/iceberg/commit/6d99ec0d420cec9070d254427e6d599d69f14422", "message": "address review comments, updated logging messages", "committedDate": "2021-06-18T14:57:26Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NDU0ODg5Ng==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r654548896", "bodyText": "Because currentMetadataLocation() must be null because of the check above, this will do basically nothing. I see that this call is probably here because Hive always calls refreshFromMetadataLocation, but I don't think that it is necessary to call it here.\nI'd probably combine this with the previous check:\nif (table.isEmpty()) {\n  if (currentMetadataLocation() != null) {\n    throw new NoSuchTableException(\"Failed to load table %s from catalog %s: dropped by another process\", ...);\n  } else {\n    return;\n  }\n}", "author": "rdblue", "createdAt": "2021-06-18T16:16:15Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcTableOperations.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.sql.DataTruncation;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Map;\n+import java.util.Objects;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+class JdbcTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcTableOperations.class);\n+  private final String catalogName;\n+  private final TableIdentifier tableIdentifier;\n+  private final FileIO fileIO;\n+  private final JdbcClientPool connections;\n+\n+  protected JdbcTableOperations(JdbcClientPool dbConnPool, FileIO fileIO, String catalogName,\n+                                TableIdentifier tableIdentifier) {\n+    this.catalogName = catalogName;\n+    this.tableIdentifier = tableIdentifier;\n+    this.fileIO = fileIO;\n+    this.connections = dbConnPool;\n+  }\n+\n+  @Override\n+  public void doRefresh() {\n+    Map<String, String> table;\n+\n+    try {\n+      table = getTable();\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new UncheckedInterruptedException(e, \"Interrupted during refresh\");\n+    } catch (SQLException e) {\n+      // SQL exception happened when getting table from catalog\n+      throw new UncheckedSQLException(e, \"Failed to get table %s from catalog %s\", tableIdentifier, catalogName);\n+    }\n+\n+    // Table not exists AND currentMetadataLocation is not NULL!\n+    if (table.isEmpty() && currentMetadataLocation() != null) {\n+      throw new NoSuchTableException(\"Failed to get table %s from catalog %s\" +\n+          \" maybe another process deleted it\", tableIdentifier, catalogName);\n+    }\n+\n+    // Table not exists in the catalog! metadataLocation is null here!\n+    if (table.isEmpty()) {\n+      refreshFromMetadataLocation(null);", "originalCommit": "a21579f5fdbb7934f8f7ebee5c8d620830c43310", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NDgxMTgxNg==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r654811816", "bodyText": "it was stuck in infinite loop(calling .refresh) so i had to call disableRefresh(); before the return\nloop call was\n\tat org.apache.iceberg.BaseMetastoreTableOperations.current(BaseMetastoreTableOperations.java:77)\n\tat org.apache.iceberg.BaseMetastoreTableOperations.refresh(BaseMetastoreTableOperations.java:106)\n\n\n    if (table.isEmpty()) {\n      if (currentMetadataLocation() != null) {\n        throw new NoSuchTableException(\"Failed to load table %s from catalog %s: dropped by another process\",\n            tableIdentifier, catalogName);\n      } else {\n        this.disableRefresh(); # new method added to `BaseMetastoreTableOperations` sets shouldRefresh=false\n        return;\n      }\n    }", "author": "ismailsimsek", "createdAt": "2021-06-19T15:58:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NDU0ODg5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NTcyNDg1OQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r655724859", "bodyText": "Nice job catching and fixing that.", "author": "rdblue", "createdAt": "2021-06-21T21:44:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NDU0ODg5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NDU1MDExNw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r654550117", "bodyText": "This get is done twice. Can you refactor to use a variable? I think this should also be IllegalStateException rather than just a RuntimeException so you could do this:\nString newMetadataLocation = table.get(JdbcUtil.METADATA_LOCATION);\nPreconditions.checkState(newMetadataLocation != null, \"Invalid table %s: metadata location is null\", tableIdentifier);\n\nrefreshFromMetadataLocation(newMetadataLocation);", "author": "rdblue", "createdAt": "2021-06-18T16:18:39Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcTableOperations.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.sql.DataTruncation;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Map;\n+import java.util.Objects;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+class JdbcTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcTableOperations.class);\n+  private final String catalogName;\n+  private final TableIdentifier tableIdentifier;\n+  private final FileIO fileIO;\n+  private final JdbcClientPool connections;\n+\n+  protected JdbcTableOperations(JdbcClientPool dbConnPool, FileIO fileIO, String catalogName,\n+                                TableIdentifier tableIdentifier) {\n+    this.catalogName = catalogName;\n+    this.tableIdentifier = tableIdentifier;\n+    this.fileIO = fileIO;\n+    this.connections = dbConnPool;\n+  }\n+\n+  @Override\n+  public void doRefresh() {\n+    Map<String, String> table;\n+\n+    try {\n+      table = getTable();\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new UncheckedInterruptedException(e, \"Interrupted during refresh\");\n+    } catch (SQLException e) {\n+      // SQL exception happened when getting table from catalog\n+      throw new UncheckedSQLException(e, \"Failed to get table %s from catalog %s\", tableIdentifier, catalogName);\n+    }\n+\n+    // Table not exists AND currentMetadataLocation is not NULL!\n+    if (table.isEmpty() && currentMetadataLocation() != null) {\n+      throw new NoSuchTableException(\"Failed to get table %s from catalog %s\" +\n+          \" maybe another process deleted it\", tableIdentifier, catalogName);\n+    }\n+\n+    // Table not exists in the catalog! metadataLocation is null here!\n+    if (table.isEmpty()) {\n+      refreshFromMetadataLocation(null);\n+      return;\n+    }\n+\n+    // Table exists but metadataLocation is null\n+    if (table.getOrDefault(JdbcUtil.METADATA_LOCATION, null) == null) {", "originalCommit": "a21579f5fdbb7934f8f7ebee5c8d620830c43310", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NDU1MDM5Ng==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r654550396", "bodyText": "(Also, getOrDefault with a null default is equivalent to get.)", "author": "rdblue", "createdAt": "2021-06-18T16:19:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NDU1MDExNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NDgxMTA4Mg==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r654811082", "bodyText": "updated", "author": "ismailsimsek", "createdAt": "2021-06-19T15:50:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NDU1MDExNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NDU1MDk4NA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r654550984", "bodyText": "I think this can just be table.get(JdbcUtil.METADATA_LOCATION).", "author": "rdblue", "createdAt": "2021-06-18T16:20:21Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcTableOperations.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.sql.DataTruncation;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Map;\n+import java.util.Objects;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+class JdbcTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcTableOperations.class);\n+  private final String catalogName;\n+  private final TableIdentifier tableIdentifier;\n+  private final FileIO fileIO;\n+  private final JdbcClientPool connections;\n+\n+  protected JdbcTableOperations(JdbcClientPool dbConnPool, FileIO fileIO, String catalogName,\n+                                TableIdentifier tableIdentifier) {\n+    this.catalogName = catalogName;\n+    this.tableIdentifier = tableIdentifier;\n+    this.fileIO = fileIO;\n+    this.connections = dbConnPool;\n+  }\n+\n+  @Override\n+  public void doRefresh() {\n+    Map<String, String> table;\n+\n+    try {\n+      table = getTable();\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new UncheckedInterruptedException(e, \"Interrupted during refresh\");\n+    } catch (SQLException e) {\n+      // SQL exception happened when getting table from catalog\n+      throw new UncheckedSQLException(e, \"Failed to get table %s from catalog %s\", tableIdentifier, catalogName);\n+    }\n+\n+    // Table not exists AND currentMetadataLocation is not NULL!\n+    if (table.isEmpty() && currentMetadataLocation() != null) {\n+      throw new NoSuchTableException(\"Failed to get table %s from catalog %s\" +\n+          \" maybe another process deleted it\", tableIdentifier, catalogName);\n+    }\n+\n+    // Table not exists in the catalog! metadataLocation is null here!\n+    if (table.isEmpty()) {\n+      refreshFromMetadataLocation(null);\n+      return;\n+    }\n+\n+    // Table exists but metadataLocation is null\n+    if (table.getOrDefault(JdbcUtil.METADATA_LOCATION, null) == null) {\n+      throw new RuntimeException(String.format(\"Failed to get metadata location of the table %s from catalog %s\",\n+          tableIdentifier, catalogName));\n+    }\n+\n+    refreshFromMetadataLocation(table.get(JdbcUtil.METADATA_LOCATION));\n+  }\n+\n+  @Override\n+  public void doCommit(TableMetadata base, TableMetadata metadata) {\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+    try {\n+      Map<String, String> table = getTable();\n+\n+      if (!table.isEmpty()) {\n+        validateMetadataLocation(table, base);\n+        String oldMetadataLocation = base.metadataFileLocation();\n+        // Start atomic update\n+        LOG.debug(\"Committing existing table: {}\", tableName());\n+        updateTable(newMetadataLocation, oldMetadataLocation);\n+      } else {\n+        // table not exists create it\n+        LOG.debug(\"Committing new table: {}\", tableName());\n+        createTable(newMetadataLocation);\n+      }\n+\n+    } catch (SQLIntegrityConstraintViolationException e) {\n+      throw new AlreadyExistsException(e, \"Table already exists, maybe another process created it\");\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(e, \"Database Connection timeout\");\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(e, \"Database Connection failed\");\n+    } catch (DataTruncation e) {\n+      throw new UncheckedSQLException(e, \"Database data truncation error\");\n+    } catch (SQLWarning e) {\n+      throw new UncheckedSQLException(e, \"Database warning\");\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to connect to database\");\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new UncheckedInterruptedException(e, \"Interrupted during commit\");\n+    }\n+  }\n+\n+  private void updateTable(String newMetadataLocation, String oldMetadataLocation)\n+      throws SQLException, InterruptedException {\n+    int updatedRecords = connections.run(conn -> {\n+      try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.DO_COMMIT_SQL)) {\n+        // UPDATE\n+        sql.setString(1, newMetadataLocation);\n+        sql.setString(2, oldMetadataLocation);\n+        // WHERE\n+        sql.setString(3, catalogName);\n+        sql.setString(4, JdbcUtil.namespaceToString(tableIdentifier.namespace()));\n+        sql.setString(5, tableIdentifier.name());\n+        sql.setString(6, oldMetadataLocation);\n+        return sql.executeUpdate();\n+      }\n+    });\n+\n+    if (updatedRecords == 1) {\n+      LOG.debug(\"Successfully committed to existing table: {}\", tableIdentifier);\n+    } else {\n+      throw new CommitFailedException(\"Failed to update the table %s from catalog %s \" +\n+          \"Maybe another process changed it\", tableIdentifier, catalogName);\n+    }\n+\n+  }\n+\n+  private void createTable(String newMetadataLocation) throws SQLException, InterruptedException {\n+    int insertRecord = connections.run(conn -> {\n+      try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.DO_COMMIT_CREATE_TABLE_SQL)) {\n+        sql.setString(1, catalogName);\n+        sql.setString(2, JdbcUtil.namespaceToString(tableIdentifier.namespace()));\n+        sql.setString(3, tableIdentifier.name());\n+        sql.setString(4, newMetadataLocation);\n+        return sql.executeUpdate();\n+      }\n+    });\n+\n+    if (insertRecord == 1) {\n+      LOG.debug(\"Successfully committed to new table: {}\", tableIdentifier);\n+    } else {\n+      throw new CommitFailedException(\"Failed to create table %s catalog %s\", tableIdentifier, catalogName);\n+    }\n+  }\n+\n+  private void validateMetadataLocation(Map<String, String> table, TableMetadata base) {\n+    String catalogMetadataLocation = !table.isEmpty() ? table.get(JdbcUtil.METADATA_LOCATION) : null;", "originalCommit": "a21579f5fdbb7934f8f7ebee5c8d620830c43310", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NDgxMTI1NA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r654811254", "bodyText": "updated", "author": "ismailsimsek", "createdAt": "2021-06-19T15:52:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NDU1MDk4NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NDU1MTU4OQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r654551589", "bodyText": "Nit: error message could be more concise: \"Cannot commit %s: metadata location %s has changed from %s\"", "author": "rdblue", "createdAt": "2021-06-18T16:21:28Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcTableOperations.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.sql.DataTruncation;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Map;\n+import java.util.Objects;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+class JdbcTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcTableOperations.class);\n+  private final String catalogName;\n+  private final TableIdentifier tableIdentifier;\n+  private final FileIO fileIO;\n+  private final JdbcClientPool connections;\n+\n+  protected JdbcTableOperations(JdbcClientPool dbConnPool, FileIO fileIO, String catalogName,\n+                                TableIdentifier tableIdentifier) {\n+    this.catalogName = catalogName;\n+    this.tableIdentifier = tableIdentifier;\n+    this.fileIO = fileIO;\n+    this.connections = dbConnPool;\n+  }\n+\n+  @Override\n+  public void doRefresh() {\n+    Map<String, String> table;\n+\n+    try {\n+      table = getTable();\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new UncheckedInterruptedException(e, \"Interrupted during refresh\");\n+    } catch (SQLException e) {\n+      // SQL exception happened when getting table from catalog\n+      throw new UncheckedSQLException(e, \"Failed to get table %s from catalog %s\", tableIdentifier, catalogName);\n+    }\n+\n+    // Table not exists AND currentMetadataLocation is not NULL!\n+    if (table.isEmpty() && currentMetadataLocation() != null) {\n+      throw new NoSuchTableException(\"Failed to get table %s from catalog %s\" +\n+          \" maybe another process deleted it\", tableIdentifier, catalogName);\n+    }\n+\n+    // Table not exists in the catalog! metadataLocation is null here!\n+    if (table.isEmpty()) {\n+      refreshFromMetadataLocation(null);\n+      return;\n+    }\n+\n+    // Table exists but metadataLocation is null\n+    if (table.getOrDefault(JdbcUtil.METADATA_LOCATION, null) == null) {\n+      throw new RuntimeException(String.format(\"Failed to get metadata location of the table %s from catalog %s\",\n+          tableIdentifier, catalogName));\n+    }\n+\n+    refreshFromMetadataLocation(table.get(JdbcUtil.METADATA_LOCATION));\n+  }\n+\n+  @Override\n+  public void doCommit(TableMetadata base, TableMetadata metadata) {\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+    try {\n+      Map<String, String> table = getTable();\n+\n+      if (!table.isEmpty()) {\n+        validateMetadataLocation(table, base);\n+        String oldMetadataLocation = base.metadataFileLocation();\n+        // Start atomic update\n+        LOG.debug(\"Committing existing table: {}\", tableName());\n+        updateTable(newMetadataLocation, oldMetadataLocation);\n+      } else {\n+        // table not exists create it\n+        LOG.debug(\"Committing new table: {}\", tableName());\n+        createTable(newMetadataLocation);\n+      }\n+\n+    } catch (SQLIntegrityConstraintViolationException e) {\n+      throw new AlreadyExistsException(e, \"Table already exists, maybe another process created it\");\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(e, \"Database Connection timeout\");\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(e, \"Database Connection failed\");\n+    } catch (DataTruncation e) {\n+      throw new UncheckedSQLException(e, \"Database data truncation error\");\n+    } catch (SQLWarning e) {\n+      throw new UncheckedSQLException(e, \"Database warning\");\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to connect to database\");\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new UncheckedInterruptedException(e, \"Interrupted during commit\");\n+    }\n+  }\n+\n+  private void updateTable(String newMetadataLocation, String oldMetadataLocation)\n+      throws SQLException, InterruptedException {\n+    int updatedRecords = connections.run(conn -> {\n+      try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.DO_COMMIT_SQL)) {\n+        // UPDATE\n+        sql.setString(1, newMetadataLocation);\n+        sql.setString(2, oldMetadataLocation);\n+        // WHERE\n+        sql.setString(3, catalogName);\n+        sql.setString(4, JdbcUtil.namespaceToString(tableIdentifier.namespace()));\n+        sql.setString(5, tableIdentifier.name());\n+        sql.setString(6, oldMetadataLocation);\n+        return sql.executeUpdate();\n+      }\n+    });\n+\n+    if (updatedRecords == 1) {\n+      LOG.debug(\"Successfully committed to existing table: {}\", tableIdentifier);\n+    } else {\n+      throw new CommitFailedException(\"Failed to update the table %s from catalog %s \" +\n+          \"Maybe another process changed it\", tableIdentifier, catalogName);\n+    }\n+\n+  }\n+\n+  private void createTable(String newMetadataLocation) throws SQLException, InterruptedException {\n+    int insertRecord = connections.run(conn -> {\n+      try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.DO_COMMIT_CREATE_TABLE_SQL)) {\n+        sql.setString(1, catalogName);\n+        sql.setString(2, JdbcUtil.namespaceToString(tableIdentifier.namespace()));\n+        sql.setString(3, tableIdentifier.name());\n+        sql.setString(4, newMetadataLocation);\n+        return sql.executeUpdate();\n+      }\n+    });\n+\n+    if (insertRecord == 1) {\n+      LOG.debug(\"Successfully committed to new table: {}\", tableIdentifier);\n+    } else {\n+      throw new CommitFailedException(\"Failed to create table %s catalog %s\", tableIdentifier, catalogName);\n+    }\n+  }\n+\n+  private void validateMetadataLocation(Map<String, String> table, TableMetadata base) {\n+    String catalogMetadataLocation = !table.isEmpty() ? table.get(JdbcUtil.METADATA_LOCATION) : null;\n+    String baseMetadataLocation = base != null ? base.metadataFileLocation() : null;\n+\n+    if (!Objects.equals(baseMetadataLocation, catalogMetadataLocation)) {\n+      throw new CommitFailedException(\n+          \"Cannot commit %s because base metadata location '%s' is not same as the current Catalog location '%s'\",", "originalCommit": "a21579f5fdbb7934f8f7ebee5c8d620830c43310", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NDgxMTI3Mg==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r654811272", "bodyText": "updated", "author": "ismailsimsek", "createdAt": "2021-06-19T15:52:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NDU1MTU4OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NDU1MzQ5Nw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r654553497", "bodyText": "I think this should only be thrown if currentMetadataLocation() is null because that indicates this is a new table. Otherwise, I think this should throw UncheckedSQLException.", "author": "rdblue", "createdAt": "2021-06-18T16:24:53Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcTableOperations.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.sql.DataTruncation;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Map;\n+import java.util.Objects;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+class JdbcTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcTableOperations.class);\n+  private final String catalogName;\n+  private final TableIdentifier tableIdentifier;\n+  private final FileIO fileIO;\n+  private final JdbcClientPool connections;\n+\n+  protected JdbcTableOperations(JdbcClientPool dbConnPool, FileIO fileIO, String catalogName,\n+                                TableIdentifier tableIdentifier) {\n+    this.catalogName = catalogName;\n+    this.tableIdentifier = tableIdentifier;\n+    this.fileIO = fileIO;\n+    this.connections = dbConnPool;\n+  }\n+\n+  @Override\n+  public void doRefresh() {\n+    Map<String, String> table;\n+\n+    try {\n+      table = getTable();\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new UncheckedInterruptedException(e, \"Interrupted during refresh\");\n+    } catch (SQLException e) {\n+      // SQL exception happened when getting table from catalog\n+      throw new UncheckedSQLException(e, \"Failed to get table %s from catalog %s\", tableIdentifier, catalogName);\n+    }\n+\n+    // Table not exists AND currentMetadataLocation is not NULL!\n+    if (table.isEmpty() && currentMetadataLocation() != null) {\n+      throw new NoSuchTableException(\"Failed to get table %s from catalog %s\" +\n+          \" maybe another process deleted it\", tableIdentifier, catalogName);\n+    }\n+\n+    // Table not exists in the catalog! metadataLocation is null here!\n+    if (table.isEmpty()) {\n+      refreshFromMetadataLocation(null);\n+      return;\n+    }\n+\n+    // Table exists but metadataLocation is null\n+    if (table.getOrDefault(JdbcUtil.METADATA_LOCATION, null) == null) {\n+      throw new RuntimeException(String.format(\"Failed to get metadata location of the table %s from catalog %s\",\n+          tableIdentifier, catalogName));\n+    }\n+\n+    refreshFromMetadataLocation(table.get(JdbcUtil.METADATA_LOCATION));\n+  }\n+\n+  @Override\n+  public void doCommit(TableMetadata base, TableMetadata metadata) {\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+    try {\n+      Map<String, String> table = getTable();\n+\n+      if (!table.isEmpty()) {\n+        validateMetadataLocation(table, base);\n+        String oldMetadataLocation = base.metadataFileLocation();\n+        // Start atomic update\n+        LOG.debug(\"Committing existing table: {}\", tableName());\n+        updateTable(newMetadataLocation, oldMetadataLocation);\n+      } else {\n+        // table not exists create it\n+        LOG.debug(\"Committing new table: {}\", tableName());\n+        createTable(newMetadataLocation);\n+      }\n+\n+    } catch (SQLIntegrityConstraintViolationException e) {\n+      throw new AlreadyExistsException(e, \"Table already exists, maybe another process created it\");", "originalCommit": "a21579f5fdbb7934f8f7ebee5c8d620830c43310", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NDgxMTk4Nw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r654811987", "bodyText": "updated with following if condition\n      if (currentMetadataLocation() == null) {\n        throw new AlreadyExistsException(e, \"Table already exists: %s\", tableIdentifier);\n      } else {\n        throw new UncheckedSQLException(e, \"Table already exists: %s\", tableIdentifier);\n      }", "author": "ismailsimsek", "createdAt": "2021-06-19T16:00:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NDU1MzQ5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NDU1Mzk2Mw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r654553963", "bodyText": "I don't think that \"failed to connect\" is necessarily correct since the SQL exception is generic. How about \"Unknown failure\"?", "author": "rdblue", "createdAt": "2021-06-18T16:25:47Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcTableOperations.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.sql.DataTruncation;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Map;\n+import java.util.Objects;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+class JdbcTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcTableOperations.class);\n+  private final String catalogName;\n+  private final TableIdentifier tableIdentifier;\n+  private final FileIO fileIO;\n+  private final JdbcClientPool connections;\n+\n+  protected JdbcTableOperations(JdbcClientPool dbConnPool, FileIO fileIO, String catalogName,\n+                                TableIdentifier tableIdentifier) {\n+    this.catalogName = catalogName;\n+    this.tableIdentifier = tableIdentifier;\n+    this.fileIO = fileIO;\n+    this.connections = dbConnPool;\n+  }\n+\n+  @Override\n+  public void doRefresh() {\n+    Map<String, String> table;\n+\n+    try {\n+      table = getTable();\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new UncheckedInterruptedException(e, \"Interrupted during refresh\");\n+    } catch (SQLException e) {\n+      // SQL exception happened when getting table from catalog\n+      throw new UncheckedSQLException(e, \"Failed to get table %s from catalog %s\", tableIdentifier, catalogName);\n+    }\n+\n+    // Table not exists AND currentMetadataLocation is not NULL!\n+    if (table.isEmpty() && currentMetadataLocation() != null) {\n+      throw new NoSuchTableException(\"Failed to get table %s from catalog %s\" +\n+          \" maybe another process deleted it\", tableIdentifier, catalogName);\n+    }\n+\n+    // Table not exists in the catalog! metadataLocation is null here!\n+    if (table.isEmpty()) {\n+      refreshFromMetadataLocation(null);\n+      return;\n+    }\n+\n+    // Table exists but metadataLocation is null\n+    if (table.getOrDefault(JdbcUtil.METADATA_LOCATION, null) == null) {\n+      throw new RuntimeException(String.format(\"Failed to get metadata location of the table %s from catalog %s\",\n+          tableIdentifier, catalogName));\n+    }\n+\n+    refreshFromMetadataLocation(table.get(JdbcUtil.METADATA_LOCATION));\n+  }\n+\n+  @Override\n+  public void doCommit(TableMetadata base, TableMetadata metadata) {\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+    try {\n+      Map<String, String> table = getTable();\n+\n+      if (!table.isEmpty()) {\n+        validateMetadataLocation(table, base);\n+        String oldMetadataLocation = base.metadataFileLocation();\n+        // Start atomic update\n+        LOG.debug(\"Committing existing table: {}\", tableName());\n+        updateTable(newMetadataLocation, oldMetadataLocation);\n+      } else {\n+        // table not exists create it\n+        LOG.debug(\"Committing new table: {}\", tableName());\n+        createTable(newMetadataLocation);\n+      }\n+\n+    } catch (SQLIntegrityConstraintViolationException e) {\n+      throw new AlreadyExistsException(e, \"Table already exists, maybe another process created it\");\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(e, \"Database Connection timeout\");\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(e, \"Database Connection failed\");\n+    } catch (DataTruncation e) {\n+      throw new UncheckedSQLException(e, \"Database data truncation error\");\n+    } catch (SQLWarning e) {\n+      throw new UncheckedSQLException(e, \"Database warning\");\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(e, \"Failed to connect to database\");", "originalCommit": "a21579f5fdbb7934f8f7ebee5c8d620830c43310", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NDgxMTMyMQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r654811321", "bodyText": "changed to \"Unknown failure\"", "author": "ismailsimsek", "createdAt": "2021-06-19T15:53:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NDU1Mzk2Mw=="}], "type": "inlineReview"}, {"oid": "c7942523f9b816f8067876a84c664b5db3d9c9fc", "url": "https://github.com/apache/iceberg/commit/c7942523f9b816f8067876a84c664b5db3d9c9fc", "message": "address review comments", "committedDate": "2021-06-19T15:46:14Z", "type": "commit"}, {"oid": "5f1be4c978c75e39fbd98dbd77d3441fb5266e11", "url": "https://github.com/apache/iceberg/commit/5f1be4c978c75e39fbd98dbd77d3441fb5266e11", "message": "address review comments, disable refresh when currentMetadataLocation is null", "committedDate": "2021-06-19T15:49:29Z", "type": "commit"}, {"oid": "d323722abed0acad3dab17e7aa0dffc230d7e844", "url": "https://github.com/apache/iceberg/commit/d323722abed0acad3dab17e7aa0dffc230d7e844", "message": "fix checkstyle", "committedDate": "2021-06-19T16:09:01Z", "type": "commit"}, {"oid": "8b4b3e8ad8b1e885e64ebf9b398b8ed460cd87ae", "url": "https://github.com/apache/iceberg/commit/8b4b3e8ad8b1e885e64ebf9b398b8ed460cd87ae", "message": "fix checkstyle", "committedDate": "2021-06-19T16:19:11Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQyNTQwNA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r535425404", "bodyText": "nit: the variable should be deletedRecords", "author": "jackye1995", "createdAt": "2020-12-03T17:12:22Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,248 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.hadoop;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.SQLException;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.commons.dbutils.DbUtils;\n+import org.apache.commons.dbutils.QueryRunner;\n+import org.apache.commons.dbutils.handlers.BeanListHandler;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.RuntimeIOException;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, Closeable {\n+\n+  public static final String JDBC_CATALOG_DEFAULT_NAME = \"default_catalog\";\n+  public static final String JDBC_CATALOG_TABLE_NAME = \"iceberg_catalog\";\n+  public static final String JDB_CATALOG_TABLE_DDL = \"CREATE TABLE IF NOT EXISTS \" +\n+          JDBC_CATALOG_TABLE_NAME + \" ( \" +\n+          \"catalogName VARCHAR(1255) NOT NULL,\" +\n+          \"tableNamespace VARCHAR(1255),\" +\n+          \"tableName VARCHAR(1255) NOT NULL,\" +\n+          \"metadataLocation VARCHAR(66255),\" +\n+          \"previousMetadataLocation VARCHAR(66255),\" +\n+          \"PRIMARY KEY (catalogName,tableNamespace,tableName)  \" +\n+          \")\";\n+  public static final String JDBC_NAMESPACE_TABLE_LIST = \"SELECT catalogName, tableNamespace, tableName, \" +\n+          \"metadataLocation, previousMetadataLocation FROM \" + JDBC_CATALOG_TABLE_NAME + \" \" +\n+          \"WHERE catalogName = ? AND tableNamespace = ?\";\n+  public static final String JDBC_TABLE_RENAME = \"UPDATE \" + JDBC_CATALOG_TABLE_NAME + \" SET tableNamespace = ? , \" +\n+          \"tableName = ? WHERE catalogName = ? AND tableNamespace = ? AND tableName = ? \";\n+  public static final String JDBC_TABLE_DROP = \"DELETE FROM \" + JDBC_CATALOG_TABLE_NAME + \" WHERE catalogName = ? \" +\n+          \"AND tableNamespace = ? AND tableName = ? \";\n+  public static final String JDBC_TABLE_SELECT = \"SELECT catalogName, tableNamespace, tableName, metadataLocation, \" +\n+          \"previousMetadataLocation FROM \" + JDBC_CATALOG_TABLE_NAME + \" WHERE catalogName = ? \" +\n+          \"AND tableNamespace = ? AND tableName = ? \";\n+  public static final String JDBC_TABLE_INSERT = \"INSERT INTO \" + JDBC_CATALOG_TABLE_NAME + \" (catalogName, \" +\n+          \"tableNamespace, tableName, metadataLocation, previousMetadataLocation) VALUES (?,?,?,?,?)\";\n+  public static final String JDBC_TABLE_UPDATE_METADATA = \"UPDATE \" + JDBC_CATALOG_TABLE_NAME + \" \" +\n+          \"SET metadataLocation = ? , previousMetadataLocation = ? WHERE catalogName = ? AND tableNamespace = ? \" +\n+          \"AND tableName = ? \";\n+\n+  public static final String JDBC_CATALOG_JDBC_DRIVER = \"jdbccatalog.jdbcdriver\";\n+  public static final String JDBC_CATALOG_DBURL = \"jdbccatalog.dburl\";\n+  public static final String JDBC_CATALOG_USER = \"jdbccatalog.user\";\n+  public static final String JDBC_CATALOG_PASSWORD = \"jdbccatalog.password\";\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private final QueryRunner queryRunner = new QueryRunner();\n+  private FileIO fileIO;\n+  private String catalogName = JDBC_CATALOG_DEFAULT_NAME;\n+  private String warehouseLocation;\n+  private Configuration hadoopConf;\n+  private Connection jdbcConnection;\n+\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  private void createCatalogIfNotExists() throws SQLException {\n+    queryRunner.execute(jdbcConnection, JDB_CATALOG_TABLE_DDL);\n+    LOG.debug(\"Created Jdbc table '{}' to store iceberg catalog!\", JDBC_CATALOG_TABLE_NAME);\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(properties.get(CatalogProperties.WAREHOUSE_LOCATION) != null &&\n+                    !properties.get(CatalogProperties.WAREHOUSE_LOCATION).equals(\"\"),\n+            \"no location provided for warehouse\");\n+    Preconditions.checkArgument(!properties.getOrDefault(JDBC_CATALOG_JDBC_DRIVER, \"\").equals(\"\"),\n+            \"no jdbc driver classname provided!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(JDBC_CATALOG_DBURL, \"\").equals(\"\"),\n+            \"no jdbc connection url provided!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(JDBC_CATALOG_USER, \"\").equals(\"\"),\n+            \"no jdbc database user provided!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(JDBC_CATALOG_PASSWORD, \"\").equals(\"\"),\n+            \"no jdbc database user password provided!\");\n+    String catalogJdbcDriver = properties.get(JDBC_CATALOG_JDBC_DRIVER);\n+    String catalogDburl = properties.get(JDBC_CATALOG_DBURL);\n+    String catalogUser = properties.get(JDBC_CATALOG_USER);\n+    String catalogDbpassword = properties.get(JDBC_CATALOG_PASSWORD);\n+    this.catalogName = name;\n+    this.warehouseLocation = properties.get(CatalogProperties.WAREHOUSE_LOCATION).replaceAll(\"/*$\", \"\");\n+\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(hadoopConf) : CatalogUtil.loadFileIO(fileIOImpl, properties,\n+            hadoopConf);\n+\n+    DbUtils.loadDriver(catalogJdbcDriver);\n+    LOG.debug(\"Connecting to Jdbc database {}.\", catalogDburl);\n+    try {\n+      jdbcConnection = DriverManager.getConnection(catalogDburl, catalogUser, catalogDbpassword);\n+      createCatalogIfNotExists();\n+    } catch (SQLException throwables) {\n+      throw new RuntimeIOException(\"Failed to initialize Jdbc Catalog!\\n %s %s\", throwables.getErrorCode(),\n+              throwables.getMessage());\n+    }\n+\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    return new JdbcTableOperations(jdbcConnection, fileIO, catalogName, tableIdentifier);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier tableIdentifier) {\n+    String tableName = tableIdentifier.name();\n+    StringBuilder sb = new StringBuilder();\n+\n+    sb.append(warehouseLocation).append('/');\n+    for (String level : tableIdentifier.namespace().levels()) {\n+      sb.append(level).append('/');\n+    }\n+    sb.append(tableName);\n+\n+    return sb.toString();\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata = ops.current();\n+    try {\n+      int insertedRecords = 0;\n+      insertedRecords = queryRunner.update(jdbcConnection, JDBC_TABLE_DROP, catalogName,", "originalCommit": "a97dfce94e656b4af5cac669790d76257996bc6a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTczMTAwMA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r535731000", "bodyText": "updated", "author": "ismailsimsek", "createdAt": "2020-12-03T23:49:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQyNTQwNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQyNzEzNw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r535427137", "bodyText": "nit: Following the convention of hive and hadoop catalog, the default name should probably be \"jdbc\"", "author": "jackye1995", "createdAt": "2020-12-03T17:14:42Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,248 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.hadoop;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.SQLException;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.commons.dbutils.DbUtils;\n+import org.apache.commons.dbutils.QueryRunner;\n+import org.apache.commons.dbutils.handlers.BeanListHandler;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.RuntimeIOException;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, Closeable {\n+\n+  public static final String JDBC_CATALOG_DEFAULT_NAME = \"default_catalog\";", "originalCommit": "a97dfce94e656b4af5cac669790d76257996bc6a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTczMTE1Mg==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r535731152", "bodyText": "changed to \"jdbc\"", "author": "ismailsimsek", "createdAt": "2020-12-03T23:50:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQyNzEzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQyODI5Mg==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r535428292", "bodyText": "nit: why not just select *?", "author": "jackye1995", "createdAt": "2020-12-03T17:16:21Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,248 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.hadoop;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.SQLException;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.commons.dbutils.DbUtils;\n+import org.apache.commons.dbutils.QueryRunner;\n+import org.apache.commons.dbutils.handlers.BeanListHandler;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.RuntimeIOException;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, Closeable {\n+\n+  public static final String JDBC_CATALOG_DEFAULT_NAME = \"default_catalog\";\n+  public static final String JDBC_CATALOG_TABLE_NAME = \"iceberg_catalog\";\n+  public static final String JDB_CATALOG_TABLE_DDL = \"CREATE TABLE IF NOT EXISTS \" +\n+          JDBC_CATALOG_TABLE_NAME + \" ( \" +\n+          \"catalogName VARCHAR(1255) NOT NULL,\" +\n+          \"tableNamespace VARCHAR(1255),\" +\n+          \"tableName VARCHAR(1255) NOT NULL,\" +\n+          \"metadataLocation VARCHAR(66255),\" +\n+          \"previousMetadataLocation VARCHAR(66255),\" +\n+          \"PRIMARY KEY (catalogName,tableNamespace,tableName)  \" +\n+          \")\";\n+  public static final String JDBC_NAMESPACE_TABLE_LIST = \"SELECT catalogName, tableNamespace, tableName, \" +\n+          \"metadataLocation, previousMetadataLocation FROM \" + JDBC_CATALOG_TABLE_NAME + \" \" +\n+          \"WHERE catalogName = ? AND tableNamespace = ?\";\n+  public static final String JDBC_TABLE_RENAME = \"UPDATE \" + JDBC_CATALOG_TABLE_NAME + \" SET tableNamespace = ? , \" +\n+          \"tableName = ? WHERE catalogName = ? AND tableNamespace = ? AND tableName = ? \";\n+  public static final String JDBC_TABLE_DROP = \"DELETE FROM \" + JDBC_CATALOG_TABLE_NAME + \" WHERE catalogName = ? \" +\n+          \"AND tableNamespace = ? AND tableName = ? \";\n+  public static final String JDBC_TABLE_SELECT = \"SELECT catalogName, tableNamespace, tableName, metadataLocation, \" +", "originalCommit": "a97dfce94e656b4af5cac669790d76257996bc6a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTczMTM1NA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r535731354", "bodyText": "changed", "author": "ismailsimsek", "createdAt": "2020-12-03T23:50:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQyODI5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQyOTM0NQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r535429345", "bodyText": "we should be able to implement SupportsNamespaces, do you plan to do that in another PR?", "author": "jackye1995", "createdAt": "2020-12-03T17:17:51Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,248 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.hadoop;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.SQLException;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.commons.dbutils.DbUtils;\n+import org.apache.commons.dbutils.QueryRunner;\n+import org.apache.commons.dbutils.handlers.BeanListHandler;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.RuntimeIOException;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, Closeable {", "originalCommit": "a97dfce94e656b4af5cac669790d76257996bc6a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTczMTU2OQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r535731569", "bodyText": "working on it now", "author": "ismailsimsek", "createdAt": "2020-12-03T23:51:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQyOTM0NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzA0NjM2Ng==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r537046366", "bodyText": "added it", "author": "ismailsimsek", "createdAt": "2020-12-06T14:09:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQyOTM0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQzMjkzNA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r535432934", "bodyText": "How do we incorporate the database concept in all SQL databases? Looks like we are just creating this table in the default database. My though on this is we can have a database named iceberg (maybe configurable), and inside it there can be a namesapce table to store namespace info, and this table (maybe with a different name like tables) to store all table information. Thoughts?", "author": "jackye1995", "createdAt": "2020-12-03T17:23:12Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,248 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.hadoop;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.SQLException;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.commons.dbutils.DbUtils;\n+import org.apache.commons.dbutils.QueryRunner;\n+import org.apache.commons.dbutils.handlers.BeanListHandler;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.RuntimeIOException;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, Closeable {\n+\n+  public static final String JDBC_CATALOG_DEFAULT_NAME = \"default_catalog\";\n+  public static final String JDBC_CATALOG_TABLE_NAME = \"iceberg_catalog\";", "originalCommit": "a97dfce94e656b4af5cac669790d76257996bc6a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzM0NDc0NA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r537344744", "bodyText": "this seems complicated, usually connection url contains database name predefined and dbsession connects to it at the beginning. it seems complicated to create new database and switch to it. at the moment database shuld be created in advance and provided with dburl.\ncurrently catalog name kept in a column in both tables, iceberg_namespaces table to store namespace info and iceberg_tables to store table data.  it shuld be possible to have multiple catalogs.", "author": "ismailsimsek", "createdAt": "2020-12-07T09:15:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQzMjkzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjI3Nzc3Mg==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r536277772", "bodyText": "I think it is sufficient to do Preconditions.checkNotNull, is there any benefit for doing this complicated check?", "author": "jackye1995", "createdAt": "2020-12-04T17:59:03Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,314 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.hadoop;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import java.io.IOException;\n+import java.sql.SQLException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import org.apache.commons.dbcp2.BasicDataSource;\n+import org.apache.commons.dbutils.QueryRunner;\n+import org.apache.commons.dbutils.handlers.BeanListHandler;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.RuntimeIOException;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces {\n+\n+  public static final String JDBC_CATALOG_DEFAULT_NAME = \"jdbc\";\n+\n+  public static final String JDBC_CATALOG_JDBC_DRIVER = \"jdbccatalog.jdbcdriver\";\n+  public static final String JDBC_CATALOG_DBURL = \"jdbccatalog.dburl\";\n+  public static final String JDBC_CATALOG_USER = \"jdbccatalog.user\";\n+  public static final String JDBC_CATALOG_PASSWORD = \"jdbccatalog.password\";\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private QueryRunner queryRunner;\n+  private FileIO fileIO;\n+  private String catalogName = JDBC_CATALOG_DEFAULT_NAME;\n+  private String warehouseLocation;\n+  private Configuration hadoopConf;\n+\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  private void initializeCatalog() throws SQLException {\n+    queryRunner.execute(JdbcNamespaceDao.NAMESPACES_TABLE_DDL);\n+    queryRunner.execute(JdbcTableDao.JDBC_CATALOG_TABLE_DDL);\n+    LOG.debug(\"Created Jdbc tables to store iceberg catalog!\");\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(properties.get(CatalogProperties.WAREHOUSE_LOCATION) != null &&", "originalCommit": "874b13d1a1a23de7c196da2422d4a314e42f608e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzA0NjUwMg==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r537046502", "bodyText": "simplified it, its checking for null and empty string now", "author": "ismailsimsek", "createdAt": "2020-12-06T14:09:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjI3Nzc3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjI4MTk3NA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r536281974", "bodyText": "I think I prefer DriverManager, because getConnection(String url, Properties info) is much more flexible. Many JDBC connector needs more than username and password, for example AWS RDS needs verifyServerCertificate and useSSL.\nI think instead of individual config fields, JDBC catalog can expose a config prefix jdbccatalog.property., and all configs under this prefix would be added to properties and initialize a connection. For example, user name and password would become configs jdbccatalog.property.username, jdbccatalog.property.password.", "author": "jackye1995", "createdAt": "2020-12-04T18:06:01Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,314 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.hadoop;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import java.io.IOException;\n+import java.sql.SQLException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import org.apache.commons.dbcp2.BasicDataSource;\n+import org.apache.commons.dbutils.QueryRunner;\n+import org.apache.commons.dbutils.handlers.BeanListHandler;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.RuntimeIOException;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces {\n+\n+  public static final String JDBC_CATALOG_DEFAULT_NAME = \"jdbc\";\n+\n+  public static final String JDBC_CATALOG_JDBC_DRIVER = \"jdbccatalog.jdbcdriver\";\n+  public static final String JDBC_CATALOG_DBURL = \"jdbccatalog.dburl\";\n+  public static final String JDBC_CATALOG_USER = \"jdbccatalog.user\";\n+  public static final String JDBC_CATALOG_PASSWORD = \"jdbccatalog.password\";\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private QueryRunner queryRunner;\n+  private FileIO fileIO;\n+  private String catalogName = JDBC_CATALOG_DEFAULT_NAME;\n+  private String warehouseLocation;\n+  private Configuration hadoopConf;\n+\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  private void initializeCatalog() throws SQLException {\n+    queryRunner.execute(JdbcNamespaceDao.NAMESPACES_TABLE_DDL);\n+    queryRunner.execute(JdbcTableDao.JDBC_CATALOG_TABLE_DDL);\n+    LOG.debug(\"Created Jdbc tables to store iceberg catalog!\");\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(properties.get(CatalogProperties.WAREHOUSE_LOCATION) != null &&\n+                    !properties.get(CatalogProperties.WAREHOUSE_LOCATION).equals(\"\"),\n+            \"no location provided for warehouse\");\n+    Preconditions.checkArgument(!properties.getOrDefault(JDBC_CATALOG_JDBC_DRIVER, \"\").equals(\"\"),\n+            \"no jdbc driver classname provided!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(JDBC_CATALOG_DBURL, \"\").equals(\"\"),\n+            \"no jdbc connection url provided!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(JDBC_CATALOG_USER, \"\").equals(\"\"),\n+            \"no jdbc database user provided!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(JDBC_CATALOG_PASSWORD, \"\").equals(\"\"),\n+            \"no jdbc database user password provided!\");\n+    this.catalogName = name;\n+    this.warehouseLocation = properties.get(CatalogProperties.WAREHOUSE_LOCATION).replaceAll(\"/*$\", \"\");\n+\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(hadoopConf) : CatalogUtil.loadFileIO(fileIOImpl, properties,\n+            hadoopConf);\n+\n+    LOG.debug(\"Connecting to Jdbc database {}.\", properties.get(JDBC_CATALOG_DBURL));\n+    // jdbcConnection = DriverManager.getConnection(catalogDburl, catalogUser, catalogDbpassword);", "originalCommit": "874b13d1a1a23de7c196da2422d4a314e42f608e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQxNjMwNw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r536416307", "bodyText": "I agree on using DriverManager. Modern JDBC implementations will automatically register themselves and make themselves findable via the appropriate META-INF/services file. And yes, many different JDBC implementations / ways that people have stood up their relational databases require a lot more information.", "author": "kbendick", "createdAt": "2020-12-04T22:17:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjI4MTk3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjY1OTcyMg==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r536659722", "bodyText": "Thank you for the hint it makes sense, will change it.", "author": "ismailsimsek", "createdAt": "2020-12-05T10:28:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjI4MTk3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjg5NDUxOQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r536894519", "bodyText": "We typically pass a connection string via uri.\nIt may also be a good idea to have a way to avoid exposing credentials. We typically allow registering a Supplier<String> that is called, although here it may make sense to use Function<Map<String, String>, String> so that the catalog config can be used.", "author": "rdblue", "createdAt": "2020-12-05T21:19:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjI4MTk3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzA0NzQ5NQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r537047495", "bodyText": "changed to DriverManager and Properties. creating  Properties using prefix connection.parameter.", "author": "ismailsimsek", "createdAt": "2020-12-06T14:15:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjI4MTk3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjMyNTQ3Mg==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r536325472", "bodyText": "These changes don't look related. Could you add them in a separate PR?", "author": "rdblue", "createdAt": "2020-12-04T19:19:40Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopCatalog.java", "diffHunk": "@@ -56,16 +56,16 @@\n import org.apache.iceberg.relocated.com.google.common.collect.Sets;\n \n /**\n- * HadoopCatalog provides a way to use table names like db.table to work with path-based tables under a common\n- * location. It uses a specified directory under a specified filesystem as the warehouse directory, and organizes\n- * multiple levels directories that mapped to the database, namespace and the table respectively. The HadoopCatalog\n- * takes a location as the warehouse directory. When creating a table such as $db.$tbl, it creates $db/$tbl\n- * directory under the warehouse directory, and put the table metadata into that directory.\n- *\n- * The HadoopCatalog now supports {@link org.apache.iceberg.catalog.Catalog#createTable},\n- * {@link org.apache.iceberg.catalog.Catalog#dropTable}, the {@link org.apache.iceberg.catalog.Catalog#renameTable}\n- * is not supported yet.\n- *\n+ * HadoopCatalog provides a way to use table names like db.table to work with path-based tables under a common location.\n+ * It uses a specified directory under a specified filesystem as the warehouse directory, and organizes multiple levels\n+ * directories that mapped to the database, namespace and the table respectively. The HadoopCatalog takes a location as\n+ * the warehouse directory. When creating a table such as $db.$tbl, it creates $db/$tbl directory under the warehouse\n+ * directory, and put the table metadata into that directory.\n+ * <p>\n+ * The HadoopCatalog now supports {@link org.apache.iceberg.catalog.Catalog#NoSuchNamespaceExceptioncreateTable}, {@link\n+ * org.apache.iceberg.catalog.Catalog#dropTable}, the {@link org.apache.iceberg.catalog.Catalog#renameTable} is not\n+ * supported yet.\n+ * <p>", "originalCommit": "874b13d1a1a23de7c196da2422d4a314e42f608e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjMyNTc3NA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r536325774", "bodyText": "Why put this in the hadoop package? There isn't anything specific to Hadoop is there?", "author": "rdblue", "createdAt": "2020-12-04T19:20:18Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,314 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.hadoop;", "originalCommit": "874b13d1a1a23de7c196da2422d4a314e42f608e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQxMzkzNg==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r536413936", "bodyText": "The Configurable interface that this implements is part of org.apache.hadoop.conf. Though I somewhat still agree. In my implementation, I don't have it in this package.", "author": "kbendick", "createdAt": "2020-12-04T22:12:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjMyNTc3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQxOTQzMg==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r536419432", "bodyText": "The hadoop Configurable should have nothing to do with the location of this JdbcCatalog. It is only used by HadoopFileIO. Btw, I just noticed this is in the core module. Should it instead be in its own module?", "author": "jackye1995", "createdAt": "2020-12-04T22:24:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjMyNTc3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjY3MDgwMA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r536670800", "bodyText": "I based the implementation using Hadoop catalog as an example(and glue catalog) so started it here, Maybe new module named something like \"catalog\" more suitable?", "author": "ismailsimsek", "createdAt": "2020-12-05T10:45:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjMyNTc3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjg5MzMzNQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r536893335", "bodyText": "How about org.apache.iceberg.jdbc? I'm okay with catalogs as well.\nAs for the module, I'm okay putting this in core for now. Let's see how big it ends up being and we can move it when we know more. I think that if it has a small enough dependency footprint, we can keep it here like we talked about in the recent community sync. If it is small, then it is much easier for people to have it included in our runtime builds by default.", "author": "rdblue", "createdAt": "2020-12-05T21:10:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjMyNTc3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzA0Mzg3NA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r537043874", "bodyText": "moved to org.apache.iceberg.jdbc", "author": "ismailsimsek", "createdAt": "2020-12-06T13:55:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjMyNTc3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjMyNjAzNw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r536326037", "bodyText": "Nit: please don't use multiple whitespace lines. One is sufficient.", "author": "rdblue", "createdAt": "2020-12-04T19:20:54Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,314 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.hadoop;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import java.io.IOException;\n+import java.sql.SQLException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import org.apache.commons.dbcp2.BasicDataSource;\n+import org.apache.commons.dbutils.QueryRunner;\n+import org.apache.commons.dbutils.handlers.BeanListHandler;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.RuntimeIOException;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+", "originalCommit": "874b13d1a1a23de7c196da2422d4a314e42f608e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjMyNzk3MA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r536327970", "bodyText": "Exceptions should not be discarded. Instead, this should create a new exception with the caught exception as a cause.\nAlso, we're moving from RuntimeIOException to Java's UncheckedIOException. So please use that instead.", "author": "rdblue", "createdAt": "2020-12-04T19:24:29Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,314 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.hadoop;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import java.io.IOException;\n+import java.sql.SQLException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import org.apache.commons.dbcp2.BasicDataSource;\n+import org.apache.commons.dbutils.QueryRunner;\n+import org.apache.commons.dbutils.handlers.BeanListHandler;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.RuntimeIOException;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces {\n+\n+  public static final String JDBC_CATALOG_DEFAULT_NAME = \"jdbc\";\n+\n+  public static final String JDBC_CATALOG_JDBC_DRIVER = \"jdbccatalog.jdbcdriver\";\n+  public static final String JDBC_CATALOG_DBURL = \"jdbccatalog.dburl\";\n+  public static final String JDBC_CATALOG_USER = \"jdbccatalog.user\";\n+  public static final String JDBC_CATALOG_PASSWORD = \"jdbccatalog.password\";\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private QueryRunner queryRunner;\n+  private FileIO fileIO;\n+  private String catalogName = JDBC_CATALOG_DEFAULT_NAME;\n+  private String warehouseLocation;\n+  private Configuration hadoopConf;\n+\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  private void initializeCatalog() throws SQLException {\n+    queryRunner.execute(JdbcNamespaceDao.NAMESPACES_TABLE_DDL);\n+    queryRunner.execute(JdbcTableDao.JDBC_CATALOG_TABLE_DDL);\n+    LOG.debug(\"Created Jdbc tables to store iceberg catalog!\");\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(properties.get(CatalogProperties.WAREHOUSE_LOCATION) != null &&\n+                    !properties.get(CatalogProperties.WAREHOUSE_LOCATION).equals(\"\"),\n+            \"no location provided for warehouse\");\n+    Preconditions.checkArgument(!properties.getOrDefault(JDBC_CATALOG_JDBC_DRIVER, \"\").equals(\"\"),\n+            \"no jdbc driver classname provided!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(JDBC_CATALOG_DBURL, \"\").equals(\"\"),\n+            \"no jdbc connection url provided!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(JDBC_CATALOG_USER, \"\").equals(\"\"),\n+            \"no jdbc database user provided!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(JDBC_CATALOG_PASSWORD, \"\").equals(\"\"),\n+            \"no jdbc database user password provided!\");\n+    this.catalogName = name;\n+    this.warehouseLocation = properties.get(CatalogProperties.WAREHOUSE_LOCATION).replaceAll(\"/*$\", \"\");\n+\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(hadoopConf) : CatalogUtil.loadFileIO(fileIOImpl, properties,\n+            hadoopConf);\n+\n+    LOG.debug(\"Connecting to Jdbc database {}.\", properties.get(JDBC_CATALOG_DBURL));\n+    // jdbcConnection = DriverManager.getConnection(catalogDburl, catalogUser, catalogDbpassword);\n+    BasicDataSource dataSource = new BasicDataSource();\n+    dataSource.setDriverClassName(properties.get(JDBC_CATALOG_JDBC_DRIVER));\n+    dataSource.setUrl(properties.get(JDBC_CATALOG_DBURL));\n+    dataSource.setUsername(properties.get(JDBC_CATALOG_USER));\n+    dataSource.setPassword(properties.get(JDBC_CATALOG_PASSWORD));\n+    this.queryRunner = new QueryRunner(dataSource);\n+\n+    try {\n+      initializeCatalog();\n+    } catch (SQLException throwables) {\n+      throw new RuntimeIOException(\"Failed to initialize Jdbc Catalog!\\n %s %s\", throwables.getErrorCode(),\n+              throwables.getMessage());", "originalCommit": "874b13d1a1a23de7c196da2422d4a314e42f608e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQxNzA3Mw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r536417073", "bodyText": "Is this List allocation necessary? It seems like it's discarded when results is reassigned from tableDao.getAll(namespace) below.", "author": "kbendick", "createdAt": "2020-12-04T22:19:05Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,314 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.hadoop;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import java.io.IOException;\n+import java.sql.SQLException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import org.apache.commons.dbcp2.BasicDataSource;\n+import org.apache.commons.dbutils.QueryRunner;\n+import org.apache.commons.dbutils.handlers.BeanListHandler;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.RuntimeIOException;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces {\n+\n+  public static final String JDBC_CATALOG_DEFAULT_NAME = \"jdbc\";\n+\n+  public static final String JDBC_CATALOG_JDBC_DRIVER = \"jdbccatalog.jdbcdriver\";\n+  public static final String JDBC_CATALOG_DBURL = \"jdbccatalog.dburl\";\n+  public static final String JDBC_CATALOG_USER = \"jdbccatalog.user\";\n+  public static final String JDBC_CATALOG_PASSWORD = \"jdbccatalog.password\";\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private QueryRunner queryRunner;\n+  private FileIO fileIO;\n+  private String catalogName = JDBC_CATALOG_DEFAULT_NAME;\n+  private String warehouseLocation;\n+  private Configuration hadoopConf;\n+\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  private void initializeCatalog() throws SQLException {\n+    queryRunner.execute(JdbcNamespaceDao.NAMESPACES_TABLE_DDL);\n+    queryRunner.execute(JdbcTableDao.JDBC_CATALOG_TABLE_DDL);\n+    LOG.debug(\"Created Jdbc tables to store iceberg catalog!\");\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(properties.get(CatalogProperties.WAREHOUSE_LOCATION) != null &&\n+                    !properties.get(CatalogProperties.WAREHOUSE_LOCATION).equals(\"\"),\n+            \"no location provided for warehouse\");\n+    Preconditions.checkArgument(!properties.getOrDefault(JDBC_CATALOG_JDBC_DRIVER, \"\").equals(\"\"),\n+            \"no jdbc driver classname provided!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(JDBC_CATALOG_DBURL, \"\").equals(\"\"),\n+            \"no jdbc connection url provided!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(JDBC_CATALOG_USER, \"\").equals(\"\"),\n+            \"no jdbc database user provided!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(JDBC_CATALOG_PASSWORD, \"\").equals(\"\"),\n+            \"no jdbc database user password provided!\");\n+    this.catalogName = name;\n+    this.warehouseLocation = properties.get(CatalogProperties.WAREHOUSE_LOCATION).replaceAll(\"/*$\", \"\");\n+\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(hadoopConf) : CatalogUtil.loadFileIO(fileIOImpl, properties,\n+            hadoopConf);\n+\n+    LOG.debug(\"Connecting to Jdbc database {}.\", properties.get(JDBC_CATALOG_DBURL));\n+    // jdbcConnection = DriverManager.getConnection(catalogDburl, catalogUser, catalogDbpassword);\n+    BasicDataSource dataSource = new BasicDataSource();\n+    dataSource.setDriverClassName(properties.get(JDBC_CATALOG_JDBC_DRIVER));\n+    dataSource.setUrl(properties.get(JDBC_CATALOG_DBURL));\n+    dataSource.setUsername(properties.get(JDBC_CATALOG_USER));\n+    dataSource.setPassword(properties.get(JDBC_CATALOG_PASSWORD));\n+    this.queryRunner = new QueryRunner(dataSource);\n+\n+    try {\n+      initializeCatalog();\n+    } catch (SQLException throwables) {\n+      throw new RuntimeIOException(\"Failed to initialize Jdbc Catalog!\\n %s %s\", throwables.getErrorCode(),\n+              throwables.getMessage());\n+    }\n+\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    return new JdbcTableOperations(queryRunner, fileIO, catalogName, tableIdentifier);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier tableIdentifier) {\n+    String tableName = tableIdentifier.name();\n+    StringBuilder sb = new StringBuilder();\n+\n+    sb.append(warehouseLocation).append('/');\n+    for (String level : tableIdentifier.namespace().levels()) {\n+      sb.append(level).append('/');\n+    }\n+    sb.append(tableName);\n+\n+    return sb.toString();\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata = ops.current();\n+    try {\n+      new JdbcTableDao(queryRunner, catalogName).delete(identifier);\n+      if (purge && lastMetadata != null) {\n+        CatalogUtil.dropTableData(ops.io(), lastMetadata);\n+        FileSystem fs = Util.getFs(new Path(warehouseLocation), hadoopConf);\n+        fs.delete(new Path(lastMetadata.location()), true /* recursive */);\n+        LOG.info(\"Table {} data purged!\", identifier);\n+      }\n+      return true;\n+    } catch (SQLException | IOException e) {\n+      LOG.error(\"Cannot complete drop table operation for {} due to unexpected exception {}!\", identifier,\n+              e.getMessage(), e);\n+      throw new RuntimeIOException(\"Failed to drop table %s\", identifier.toString());\n+    }\n+  }\n+\n+  public void logTables() {\n+    try {\n+      List<JdbcTable> tables = queryRunner.query(\"SELECT * FROM \" + JdbcTableDao.TABLES_TABLE_NAME,\n+              new BeanListHandler<>(JdbcTable.class));\n+      if (tables.isEmpty()) {\n+        LOG.info(\"No Table found!\");\n+      }\n+      for (JdbcTable table : tables) {\n+        LOG.info(\"Table:{} ,NS: {}\", table.toTableIdentifier().toString(), table.getTableNamespace().toString());\n+        LOG.warn(\"IS NULL:{} \", table.getTableNamespace() == null);\n+      }\n+    } catch (SQLException throwables) {\n+      LOG.error(\"Failed to list tables!\", throwables);\n+    }\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+\n+    JdbcNamespaceDao nsDao = new JdbcNamespaceDao(queryRunner, catalogName);\n+    if (nsDao.isExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Namespace %s does not exist!\", namespace.toString());\n+    }\n+    JdbcTableDao tableDao = new JdbcTableDao(queryRunner, catalogName);\n+    List<TableIdentifier> results = Lists.newArrayList();", "originalCommit": "874b13d1a1a23de7c196da2422d4a314e42f608e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQxNzM0OA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r536417348", "bodyText": "Nit: More unnecessary white space.", "author": "kbendick", "createdAt": "2020-12-04T22:19:40Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,314 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.hadoop;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import java.io.IOException;\n+import java.sql.SQLException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import org.apache.commons.dbcp2.BasicDataSource;\n+import org.apache.commons.dbutils.QueryRunner;\n+import org.apache.commons.dbutils.handlers.BeanListHandler;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.RuntimeIOException;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces {\n+\n+  public static final String JDBC_CATALOG_DEFAULT_NAME = \"jdbc\";\n+\n+  public static final String JDBC_CATALOG_JDBC_DRIVER = \"jdbccatalog.jdbcdriver\";\n+  public static final String JDBC_CATALOG_DBURL = \"jdbccatalog.dburl\";\n+  public static final String JDBC_CATALOG_USER = \"jdbccatalog.user\";\n+  public static final String JDBC_CATALOG_PASSWORD = \"jdbccatalog.password\";\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private QueryRunner queryRunner;\n+  private FileIO fileIO;\n+  private String catalogName = JDBC_CATALOG_DEFAULT_NAME;\n+  private String warehouseLocation;\n+  private Configuration hadoopConf;\n+\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  private void initializeCatalog() throws SQLException {\n+    queryRunner.execute(JdbcNamespaceDao.NAMESPACES_TABLE_DDL);\n+    queryRunner.execute(JdbcTableDao.JDBC_CATALOG_TABLE_DDL);\n+    LOG.debug(\"Created Jdbc tables to store iceberg catalog!\");\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(properties.get(CatalogProperties.WAREHOUSE_LOCATION) != null &&\n+                    !properties.get(CatalogProperties.WAREHOUSE_LOCATION).equals(\"\"),\n+            \"no location provided for warehouse\");\n+    Preconditions.checkArgument(!properties.getOrDefault(JDBC_CATALOG_JDBC_DRIVER, \"\").equals(\"\"),\n+            \"no jdbc driver classname provided!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(JDBC_CATALOG_DBURL, \"\").equals(\"\"),\n+            \"no jdbc connection url provided!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(JDBC_CATALOG_USER, \"\").equals(\"\"),\n+            \"no jdbc database user provided!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(JDBC_CATALOG_PASSWORD, \"\").equals(\"\"),\n+            \"no jdbc database user password provided!\");\n+    this.catalogName = name;\n+    this.warehouseLocation = properties.get(CatalogProperties.WAREHOUSE_LOCATION).replaceAll(\"/*$\", \"\");\n+\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(hadoopConf) : CatalogUtil.loadFileIO(fileIOImpl, properties,\n+            hadoopConf);\n+\n+    LOG.debug(\"Connecting to Jdbc database {}.\", properties.get(JDBC_CATALOG_DBURL));\n+    // jdbcConnection = DriverManager.getConnection(catalogDburl, catalogUser, catalogDbpassword);\n+    BasicDataSource dataSource = new BasicDataSource();\n+    dataSource.setDriverClassName(properties.get(JDBC_CATALOG_JDBC_DRIVER));\n+    dataSource.setUrl(properties.get(JDBC_CATALOG_DBURL));\n+    dataSource.setUsername(properties.get(JDBC_CATALOG_USER));\n+    dataSource.setPassword(properties.get(JDBC_CATALOG_PASSWORD));\n+    this.queryRunner = new QueryRunner(dataSource);\n+\n+    try {\n+      initializeCatalog();\n+    } catch (SQLException throwables) {\n+      throw new RuntimeIOException(\"Failed to initialize Jdbc Catalog!\\n %s %s\", throwables.getErrorCode(),\n+              throwables.getMessage());\n+    }\n+\n+  }\n+", "originalCommit": "874b13d1a1a23de7c196da2422d4a314e42f608e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQxODgwNQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r536418805", "bodyText": "Would it make more sense to just store the Namespace directly?", "author": "kbendick", "createdAt": "2020-12-04T22:22:57Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/JdbcNamespace.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.hadoop;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.core.type.TypeReference;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.apache.iceberg.catalog.Namespace;\n+\n+public class JdbcNamespace {\n+  private String catalogName;\n+  private String namespace;\n+  private String namespaceMetadata;\n+\n+  public JdbcNamespace(Namespace namespace) {\n+    this.namespace = namespace.toString();", "originalCommit": "874b13d1a1a23de7c196da2422d4a314e42f608e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjg5NDM1OA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r536894358", "bodyText": "Minor: Rather than breaking in the middle of a method call, the ternary operator provides good places to break lines:\nthis.fileIO = fileIOImpl == null ?\n   new HadoopFileIO(hadoopConf) :\n   CatalogUtil.loadFileIO(fileIOImpl, properties, hadoopConf);", "author": "rdblue", "createdAt": "2020-12-05T21:17:53Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,314 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.hadoop;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import java.io.IOException;\n+import java.sql.SQLException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import org.apache.commons.dbcp2.BasicDataSource;\n+import org.apache.commons.dbutils.QueryRunner;\n+import org.apache.commons.dbutils.handlers.BeanListHandler;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.RuntimeIOException;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces {\n+\n+  public static final String JDBC_CATALOG_DEFAULT_NAME = \"jdbc\";\n+\n+  public static final String JDBC_CATALOG_JDBC_DRIVER = \"jdbccatalog.jdbcdriver\";\n+  public static final String JDBC_CATALOG_DBURL = \"jdbccatalog.dburl\";\n+  public static final String JDBC_CATALOG_USER = \"jdbccatalog.user\";\n+  public static final String JDBC_CATALOG_PASSWORD = \"jdbccatalog.password\";\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private QueryRunner queryRunner;\n+  private FileIO fileIO;\n+  private String catalogName = JDBC_CATALOG_DEFAULT_NAME;\n+  private String warehouseLocation;\n+  private Configuration hadoopConf;\n+\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  private void initializeCatalog() throws SQLException {\n+    queryRunner.execute(JdbcNamespaceDao.NAMESPACES_TABLE_DDL);\n+    queryRunner.execute(JdbcTableDao.JDBC_CATALOG_TABLE_DDL);\n+    LOG.debug(\"Created Jdbc tables to store iceberg catalog!\");\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(properties.get(CatalogProperties.WAREHOUSE_LOCATION) != null &&\n+                    !properties.get(CatalogProperties.WAREHOUSE_LOCATION).equals(\"\"),\n+            \"no location provided for warehouse\");\n+    Preconditions.checkArgument(!properties.getOrDefault(JDBC_CATALOG_JDBC_DRIVER, \"\").equals(\"\"),\n+            \"no jdbc driver classname provided!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(JDBC_CATALOG_DBURL, \"\").equals(\"\"),\n+            \"no jdbc connection url provided!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(JDBC_CATALOG_USER, \"\").equals(\"\"),\n+            \"no jdbc database user provided!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(JDBC_CATALOG_PASSWORD, \"\").equals(\"\"),\n+            \"no jdbc database user password provided!\");\n+    this.catalogName = name;\n+    this.warehouseLocation = properties.get(CatalogProperties.WAREHOUSE_LOCATION).replaceAll(\"/*$\", \"\");\n+\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(hadoopConf) : CatalogUtil.loadFileIO(fileIOImpl, properties,\n+            hadoopConf);", "originalCommit": "874b13d1a1a23de7c196da2422d4a314e42f608e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjg5NTQ3Mw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r536895473", "bodyText": "Looks like this doesn't yet implement an atomic swap of the old metadata location for the new one, so table updates would be unsafe because concurrent writers would clobber each other's commits. @kbendick, did your solution tackle that problem yet?", "author": "rdblue", "createdAt": "2020-12-05T21:26:18Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/JdbcTableDao.java", "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.hadoop;\n+\n+import java.sql.SQLException;\n+import java.util.List;\n+import org.apache.commons.dbutils.QueryRunner;\n+import org.apache.commons.dbutils.handlers.BeanHandler;\n+import org.apache.commons.dbutils.handlers.BeanListHandler;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+public class JdbcTableDao {\n+  public static final String TABLES_TABLE_NAME = \"iceberg_tables\";\n+  public static final String JDBC_CATALOG_TABLE_DDL =\n+          \"CREATE TABLE IF NOT EXISTS \" + JdbcTableDao.TABLES_TABLE_NAME +\n+                  \"(catalogName VARCHAR(1255) NOT NULL,\" +\n+                  \"tableNamespace VARCHAR(1255) NOT NULL,\" +\n+                  \"tableName VARCHAR(1255) NOT NULL,\" +\n+                  \"metadataLocation VARCHAR(32768),\" +\n+                  \"previousMetadataLocation VARCHAR(32768),\" +\n+                  \"PRIMARY KEY (catalogName,tableNamespace,tableName),\" +\n+                  \"FOREIGN KEY (catalogName, tableNamespace) REFERENCES \" + JdbcNamespaceDao.NAMESPACES_TABLE_NAME +\n+                  \"(catalogName, namespace)\" +\n+                  \");\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcTableDao.class);\n+  private final QueryRunner queryRunner;\n+  private final String catalogName;\n+\n+\n+  public JdbcTableDao(QueryRunner queryRunner, String catalogName) {\n+    this.queryRunner = queryRunner;\n+    this.catalogName = catalogName;\n+  }\n+\n+  public boolean isExists(TableIdentifier tableIdentifier) {\n+    try {\n+      return this.get(tableIdentifier) != null;\n+    } catch (SQLException throwables) {\n+      return false;\n+    }\n+  }\n+\n+  public JdbcTable get(TableIdentifier tableIdentifier) throws SQLException {\n+    return queryRunner.query(\"SELECT * FROM \" + TABLES_TABLE_NAME + \" \" +\n+                    \"WHERE catalogName = ? AND tableNamespace = ? AND tableName = ? \",\n+            new BeanHandler<>(JdbcTable.class),\n+            catalogName, tableIdentifier.namespace().toString(), tableIdentifier.name());\n+  }\n+\n+  public List<TableIdentifier> getAll(Namespace namespace) throws SQLException {\n+    List<JdbcTable> tables = queryRunner.query(\"SELECT * FROM \" + TABLES_TABLE_NAME + \" \" +\n+                    \"WHERE catalogName = ? AND tableNamespace = ?\",\n+            new BeanListHandler<>(JdbcTable.class), catalogName, namespace.toString());\n+    List<TableIdentifier> results = Lists.newArrayList();\n+    for (JdbcTable table : tables) {\n+      results.add(table.toTableIdentifier());\n+    }\n+    return results;\n+  }\n+\n+  public void update(TableIdentifier tableIdentifier, String oldMetadataLocation,\n+                     String newMetadataLocation) throws SQLException {\n+    queryRunner.update(\"UPDATE \" + TABLES_TABLE_NAME + \" SET metadataLocation = ? , previousMetadataLocation = ? \" +\n+                    \"WHERE catalogName = ? AND tableNamespace = ? \" +\n+                    \"AND tableName = ? \", newMetadataLocation,\n+            oldMetadataLocation, catalogName, tableIdentifier.namespace().toString(), tableIdentifier.name());", "originalCommit": "874b13d1a1a23de7c196da2422d4a314e42f608e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjg5NjYwNg==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r536896606", "bodyText": "I think all you would need to do is to change the SQL slightly:\nUPDATE iceberg_tables\nSET metadata_location = ?, previous_metadata_location = ?\nWHERE table_namespace = ? AND table_name = ? AND metadata_location = ?\nThat adds a predicate to ensure that the table namespace and name combination will only be changed if the metadata_location is the expected one. If that affects 0 rows, then the metadata location was changed concurrently. If it affects 1 row, the commit was successful, and if it affects more than one row, there's a problem. (Note that I've simplified this to omit catalog_name.)", "author": "rdblue", "createdAt": "2020-12-05T21:33:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjg5NTQ3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzEzMDU0Mw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r537130543", "bodyText": "changed the update statement if update statement effects >0 rows it will succeed otherwise will throw CommitFailedException exception.", "author": "ismailsimsek", "createdAt": "2020-12-06T21:45:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjg5NTQ3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDA3Nzc2NQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r540077765", "bodyText": "updated the logic, now it will\nfor committing table:\n\nsucceed only if it effects row =1\nelse rollback with CommitFailedException\n\nfor renaming table:\n\nsucceed only if it effects row = 1\nrollback with NoSuchTableException  if it effects row =0\nelse rollback fail with UncheckedIOException", "author": "ismailsimsek", "createdAt": "2020-12-10T11:04:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjg5NTQ3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDA5MjUzNA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r540092534", "bodyText": "to strengthen it further we can user row level locking 'SELECT FOR UPDATE'\nif its not implemented JDBC Driver Throws SQLFeatureNotSupportedException. using this exception we could fallback to regular update statement.", "author": "ismailsimsek", "createdAt": "2020-12-10T11:28:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjg5NTQ3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjg5NTg0NA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r536895844", "bodyText": "It doesn't look like the dbutils classes are very useful here compared to simple prepared statements. Unless I'm missing something, I'd rather not rely on this dependency if we can add slightly more code here to use the JDBC API directly.", "author": "rdblue", "createdAt": "2020-12-05T21:28:25Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/JdbcTableDao.java", "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.hadoop;\n+\n+import java.sql.SQLException;\n+import java.util.List;\n+import org.apache.commons.dbutils.QueryRunner;\n+import org.apache.commons.dbutils.handlers.BeanHandler;\n+import org.apache.commons.dbutils.handlers.BeanListHandler;", "originalCommit": "874b13d1a1a23de7c196da2422d4a314e42f608e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzA0NjEwNA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r537046104", "bodyText": "removed apache.commons db packages. refactored code its using only JDBC API now, code-size even got smaller", "author": "ismailsimsek", "createdAt": "2020-12-06T14:07:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjg5NTg0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjg5Njg3NA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r536896874", "bodyText": "For structure, I would prefer to have all of the SQL statements as constants up at the top of the file, like the CREATE TABLE command. That makes it easy to read them independent of use here.", "author": "rdblue", "createdAt": "2020-12-05T21:35:11Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/JdbcTableDao.java", "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.hadoop;\n+\n+import java.sql.SQLException;\n+import java.util.List;\n+import org.apache.commons.dbutils.QueryRunner;\n+import org.apache.commons.dbutils.handlers.BeanHandler;\n+import org.apache.commons.dbutils.handlers.BeanListHandler;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+public class JdbcTableDao {\n+  public static final String TABLES_TABLE_NAME = \"iceberg_tables\";\n+  public static final String JDBC_CATALOG_TABLE_DDL =\n+          \"CREATE TABLE IF NOT EXISTS \" + JdbcTableDao.TABLES_TABLE_NAME +\n+                  \"(catalogName VARCHAR(1255) NOT NULL,\" +\n+                  \"tableNamespace VARCHAR(1255) NOT NULL,\" +\n+                  \"tableName VARCHAR(1255) NOT NULL,\" +\n+                  \"metadataLocation VARCHAR(32768),\" +\n+                  \"previousMetadataLocation VARCHAR(32768),\" +\n+                  \"PRIMARY KEY (catalogName,tableNamespace,tableName),\" +\n+                  \"FOREIGN KEY (catalogName, tableNamespace) REFERENCES \" + JdbcNamespaceDao.NAMESPACES_TABLE_NAME +\n+                  \"(catalogName, namespace)\" +\n+                  \");\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcTableDao.class);\n+  private final QueryRunner queryRunner;\n+  private final String catalogName;\n+\n+\n+  public JdbcTableDao(QueryRunner queryRunner, String catalogName) {\n+    this.queryRunner = queryRunner;\n+    this.catalogName = catalogName;\n+  }\n+\n+  public boolean isExists(TableIdentifier tableIdentifier) {\n+    try {\n+      return this.get(tableIdentifier) != null;\n+    } catch (SQLException throwables) {\n+      return false;\n+    }\n+  }\n+\n+  public JdbcTable get(TableIdentifier tableIdentifier) throws SQLException {\n+    return queryRunner.query(\"SELECT * FROM \" + TABLES_TABLE_NAME + \" \" +\n+                    \"WHERE catalogName = ? AND tableNamespace = ? AND tableName = ? \",", "originalCommit": "874b13d1a1a23de7c196da2422d4a314e42f608e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzA0NjI1OQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r537046259", "bodyText": "moved statements to constants", "author": "ismailsimsek", "createdAt": "2020-12-06T14:08:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjg5Njg3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjg5NjkzOA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r536896938", "bodyText": "Any SQL exception? What possible exceptions does this include?", "author": "rdblue", "createdAt": "2020-12-05T21:35:41Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/JdbcTableDao.java", "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.hadoop;\n+\n+import java.sql.SQLException;\n+import java.util.List;\n+import org.apache.commons.dbutils.QueryRunner;\n+import org.apache.commons.dbutils.handlers.BeanHandler;\n+import org.apache.commons.dbutils.handlers.BeanListHandler;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+public class JdbcTableDao {\n+  public static final String TABLES_TABLE_NAME = \"iceberg_tables\";\n+  public static final String JDBC_CATALOG_TABLE_DDL =\n+          \"CREATE TABLE IF NOT EXISTS \" + JdbcTableDao.TABLES_TABLE_NAME +\n+                  \"(catalogName VARCHAR(1255) NOT NULL,\" +\n+                  \"tableNamespace VARCHAR(1255) NOT NULL,\" +\n+                  \"tableName VARCHAR(1255) NOT NULL,\" +\n+                  \"metadataLocation VARCHAR(32768),\" +\n+                  \"previousMetadataLocation VARCHAR(32768),\" +\n+                  \"PRIMARY KEY (catalogName,tableNamespace,tableName),\" +\n+                  \"FOREIGN KEY (catalogName, tableNamespace) REFERENCES \" + JdbcNamespaceDao.NAMESPACES_TABLE_NAME +\n+                  \"(catalogName, namespace)\" +\n+                  \");\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcTableDao.class);\n+  private final QueryRunner queryRunner;\n+  private final String catalogName;\n+\n+\n+  public JdbcTableDao(QueryRunner queryRunner, String catalogName) {\n+    this.queryRunner = queryRunner;\n+    this.catalogName = catalogName;\n+  }\n+\n+  public boolean isExists(TableIdentifier tableIdentifier) {\n+    try {\n+      return this.get(tableIdentifier) != null;\n+    } catch (SQLException throwables) {", "originalCommit": "874b13d1a1a23de7c196da2422d4a314e42f608e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzYwNTc5MA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r537605790", "bodyText": "i would expect potential exceptions like 'when the database is down', 'not reachable' or 'table is not there'. otherwise the result shuld return = null\nmaybe its better to re-throw the exception? otherwise catalog class will assume table is not exists and will continue.", "author": "ismailsimsek", "createdAt": "2020-12-07T15:40:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjg5NjkzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjg5NzU1NQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r536897555", "bodyText": "You may want to also have a prefix-based lookup using LIKE:\nString namespacePrefix = namespace.toString() + \".%\";\nSELECT * FROM iceberg_namespaces WHERE catalog_name = ? AND namespace LIKE ?", "author": "rdblue", "createdAt": "2020-12-05T21:39:40Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/JdbcNamespaceDao.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.hadoop;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import java.sql.SQLException;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.commons.dbutils.QueryRunner;\n+import org.apache.commons.dbutils.handlers.BeanHandler;\n+import org.apache.commons.dbutils.handlers.BeanListHandler;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcNamespaceDao {\n+  public static final String NAMESPACES_TABLE_NAME = \"iceberg_namespaces\";\n+  public static final String NAMESPACES_TABLE_DDL = \"CREATE TABLE IF NOT EXISTS \" +\n+          JdbcNamespaceDao.NAMESPACES_TABLE_NAME + \" ( \" +\n+          \"catalogName VARCHAR(1255) NOT NULL,\" +\n+          \"namespace VARCHAR(1255) NOT NULL,\" +\n+          \"namespaceMetadata VARCHAR(32768),\" +\n+          \"PRIMARY KEY (catalogName, namespace) \" +\n+          \");\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcNamespaceDao.class);\n+  private final String catalogName;\n+  private QueryRunner queryRunner;\n+\n+\n+  public JdbcNamespaceDao(QueryRunner queryRunner, String catalogName) {\n+    this.queryRunner = queryRunner;\n+    this.catalogName = catalogName;\n+  }\n+\n+  public JdbcNamespace get(Namespace namespace) throws SQLException {\n+    return queryRunner.query(\"SELECT * FROM \" + NAMESPACES_TABLE_NAME + \" WHERE catalogName = \" +\n+                    \"? AND namespace = ? ;\",\n+            new BeanHandler<>(JdbcNamespace.class), catalogName, namespace.toString());\n+  }\n+\n+  public boolean isExists(Namespace namespace) {\n+    try {\n+      return this.get(namespace) != null;\n+    } catch (SQLException throwables) {\n+      return false;\n+    }\n+  }\n+\n+  public List<JdbcNamespace> getAll() throws SQLException {", "originalCommit": "874b13d1a1a23de7c196da2422d4a314e42f608e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzA4MDk2OA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r537080968", "bodyText": "right seems like this one (getAll()) is not needed, but kept it and added   public List<Namespace> getChildren(Namespace namespace)", "author": "ismailsimsek", "createdAt": "2020-12-06T17:03:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjg5NzU1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkwNDE1Mg==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r536904152", "bodyText": "For the initial version, let's not support namespace metadata. We can add that later in a separate PR where we consider more options for storage.", "author": "rdblue", "createdAt": "2020-12-05T22:24:24Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/JdbcNamespace.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.hadoop;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.core.type.TypeReference;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.apache.iceberg.catalog.Namespace;\n+\n+public class JdbcNamespace {\n+  private String catalogName;\n+  private String namespace;\n+  private String namespaceMetadata;\n+\n+  public JdbcNamespace(Namespace namespace) {\n+    this.namespace = namespace.toString();\n+  }\n+\n+  public String getCatalogName() {\n+    return catalogName;\n+  }\n+\n+  public void setCatalogName(String catalogName) {\n+    this.catalogName = catalogName;\n+  }\n+\n+  public String getNamespace() {\n+    return namespace;\n+  }\n+\n+  public void setNamespace(String namespace) {\n+    this.namespace = namespace;\n+  }\n+\n+  public String getNamespaceMetadata() {\n+    return namespaceMetadata;\n+  }\n+\n+  public void setNamespaceMetadata(String namespaceMetadata) {\n+    this.namespaceMetadata = namespaceMetadata;\n+  }\n+\n+  public Namespace toNamespace() {\n+    return Namespace.of(namespaceMetadata);\n+  }\n+\n+  public Map<String, String> toNamespaceMetadata() throws JsonProcessingException {", "originalCommit": "874b13d1a1a23de7c196da2422d4a314e42f608e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzA0OTA0Nw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r537049047", "bodyText": "relaying on toString() implementation didn't felt safe so for both namespace metadata and Namespace I used Json mapper to convert to string(\"json sting\"), and from.\nJdbcUtil.java\nex:\n  public static String namespaceToString(Namespace namespace) throws JsonProcessingException {\n    return JsonUtil.mapper().writer().writeValueAsString(namespace.levels());\n  }", "author": "ismailsimsek", "createdAt": "2020-12-06T14:23:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkwNDE1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkwNTQxNg==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r536905416", "bodyText": "Is this PRIMARY KEY and FOREIGN KEY syntax portable? I'm wondering if we should omit them to have more generic SQL.\nOf course, that would require some way to ensure that table creation is atomic because the primary key constraint wouldn't be enforced for the table. That would probably require a transaction to check whether a table exists and insert it to be portable. Some databases support ON CONFLICT DO NOTHING or INSERT IGNORE but it doesn't look like the syntax is portable.\nIt may be more portable to use PRIMARY KEY, but we will need to validate concurrent behavior.", "author": "rdblue", "createdAt": "2020-12-05T22:32:33Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/JdbcTableDao.java", "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.hadoop;\n+\n+import java.sql.SQLException;\n+import java.util.List;\n+import org.apache.commons.dbutils.QueryRunner;\n+import org.apache.commons.dbutils.handlers.BeanHandler;\n+import org.apache.commons.dbutils.handlers.BeanListHandler;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+public class JdbcTableDao {\n+  public static final String TABLES_TABLE_NAME = \"iceberg_tables\";\n+  public static final String JDBC_CATALOG_TABLE_DDL =\n+          \"CREATE TABLE IF NOT EXISTS \" + JdbcTableDao.TABLES_TABLE_NAME +\n+                  \"(catalogName VARCHAR(1255) NOT NULL,\" +\n+                  \"tableNamespace VARCHAR(1255) NOT NULL,\" +\n+                  \"tableName VARCHAR(1255) NOT NULL,\" +\n+                  \"metadataLocation VARCHAR(32768),\" +\n+                  \"previousMetadataLocation VARCHAR(32768),\" +\n+                  \"PRIMARY KEY (catalogName,tableNamespace,tableName),\" +\n+                  \"FOREIGN KEY (catalogName, tableNamespace) REFERENCES \" + JdbcNamespaceDao.NAMESPACES_TABLE_NAME +", "originalCommit": "874b13d1a1a23de7c196da2422d4a314e42f608e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzYwMTk4MA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r537601980", "bodyText": "PRIMARY KEY (catalogName,tableNamespace,tableName) is implemented in most relational databases.\nbut second one might not be. its nice to have PK to avoid duplicate data. another option might be adding it with alter statement it shuld be supported by many dbs\nALTER TABLE my_table ADD PRIMARY KEY (columnx);\nremoved PRIMARY KEY and FOREIGN KEY lines for now.", "author": "ismailsimsek", "createdAt": "2020-12-07T15:35:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkwNTQxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTI0MDY1MA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r539240650", "bodyText": "we could ignore if  'ALTER TABLE my_table ADD PRIMARY KEY (columnx);' fails. so for many dbs we can get PK created", "author": "ismailsimsek", "createdAt": "2020-12-09T11:48:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkwNTQxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTUxMjQ3OQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r539512479", "bodyText": "I think the problem is that we need that primary key to ensure that there is only one entry for a given table identifier. We don't want two concurrent creates to collide and create two different tables.", "author": "rdblue", "createdAt": "2020-12-09T17:40:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkwNTQxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDA4ODMxNQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r540088315", "bodyText": "using sqlfiddle for testing all databases there are (mysql, MS sql, postgresql, oracle )\n\ncompatible having PRIMARY KEY in the table DDL.\nMS SQL Server not supporting create Table IF NOT EXISTS", "author": "ismailsimsek", "createdAt": "2020-12-10T11:21:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkwNTQxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkwNjI5Mw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r536906293", "bodyText": "This doesn't look quite right because the exception is too generic to simply ignore and move on.\nAlso, no need to add a format argument for the exception. SLF4J loggers will detect that the last argument is an exception and add it properly without a placeholder for it.", "author": "rdblue", "createdAt": "2020-12-05T22:38:32Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/JdbcTableOperations.java", "diffHunk": "@@ -0,0 +1,113 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.hadoop;\n+\n+import java.sql.SQLException;\n+import java.util.Objects;\n+import org.apache.commons.dbutils.QueryRunner;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.io.FileIO;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+class JdbcTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcTableOperations.class);\n+  private final String catalogName;\n+  private final TableIdentifier tableIdentifier;\n+  private final FileIO fileIO;\n+  private QueryRunner queryRunner;\n+\n+  protected JdbcTableOperations(QueryRunner queryRunner, FileIO fileIO, String catalogName,\n+                                TableIdentifier tableIdentifier) {\n+    this.queryRunner = queryRunner;\n+    this.catalogName = catalogName;\n+    this.tableIdentifier = tableIdentifier;\n+    this.fileIO = fileIO;\n+  }\n+\n+  // The doRefresh method should provide implementation on how to get the metadata location\n+  @Override\n+  public void doRefresh() {\n+    String metadataLocation = null;\n+    JdbcTableDao tableDao = new JdbcTableDao(queryRunner, catalogName);\n+    JdbcTable table = null;\n+    try {\n+      table = tableDao.get(tableIdentifier);\n+    } catch (SQLException throwables) {\n+      LOG.debug(\"Table not found: {} , {}!\", tableIdentifier, throwables);", "originalCommit": "874b13d1a1a23de7c196da2422d4a314e42f608e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzA3OTUzMw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r537079533", "bodyText": "cleaned the logic with comments. for this line exception is re-thrown as RuntimeException", "author": "ismailsimsek", "createdAt": "2020-12-06T16:56:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkwNjI5Mw=="}], "type": "inlineReview"}, {"oid": "d8fc72d1b9978af4bc09e25be27ff0b5b7584581", "url": "https://github.com/apache/iceberg/commit/d8fc72d1b9978af4bc09e25be27ff0b5b7584581", "message": "implement Closeable", "committedDate": "2020-12-06T13:57:34Z", "type": "forcePushed"}, {"oid": "b230cabb5520d8b30cc244b2b776b5caaeaccb4f", "url": "https://github.com/apache/iceberg/commit/b230cabb5520d8b30cc244b2b776b5caaeaccb4f", "message": "add comments", "committedDate": "2020-12-06T18:59:14Z", "type": "forcePushed"}, {"oid": "b751492bb6cdfd48515d4519a41f60cdd95acabf", "url": "https://github.com/apache/iceberg/commit/b751492bb6cdfd48515d4519a41f60cdd95acabf", "message": "remove sql contraints", "committedDate": "2020-12-07T14:39:15Z", "type": "forcePushed"}, {"oid": "dec8e5fe3e8d576f842a0f39bccf2c3816b02be3", "url": "https://github.com/apache/iceberg/commit/dec8e5fe3e8d576f842a0f39bccf2c3816b02be3", "message": "jdbc catalog", "committedDate": "2020-12-07T18:43:40Z", "type": "forcePushed"}, {"oid": "9e1dd074565414d9a7417688ad7a89b84069afcf", "url": "https://github.com/apache/iceberg/commit/9e1dd074565414d9a7417688ad7a89b84069afcf", "message": "ensure target namespace is exists before renaming table", "committedDate": "2020-12-08T18:40:09Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDY2NDAwMg==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r544664002", "bodyText": "you need to also define a no-arg constructor for initialize for dynamic loading purpose. And in that case, you still need to initialize warehouse location and fileIO. So it is probably better to move all constructor logic to initialize.", "author": "jackye1995", "createdAt": "2020-12-16T22:19:34Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,382 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.PathFilter;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.hadoop.Util;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+\n+  public static final String JDBC_PARAM_PREFIX = \"connection.parameter.\";\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  private static final String TABLE_METADATA_FILE_EXTENSION = \".metadata.json\";\n+  private static final PathFilter TABLE_FILTER = path -> path.getName().endsWith(TABLE_METADATA_FILE_EXTENSION);\n+\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private FileIO fileIO;\n+  private FileSystem fs;\n+  private String name = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration hadoopConf;\n+  private Connection dbConn;\n+\n+  public JdbcCatalog(String name, Configuration conf, String warehouseLocation, Map<String, String> properties) {", "originalCommit": "4551cd87bd31fa42204e3be97c977a9a093fd584", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjAzMTA2MA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r546031060", "bodyText": "moved the logic to initialize", "author": "ismailsimsek", "createdAt": "2020-12-18T19:00:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDY2NDAwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDY2ODM3Nw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r544668377", "bodyText": "I don't understand why is fs used here. It seems like you have a JdbcNamespace that stores all the information, but also creates a file path for a namespace. Why are you doing this? I don't think the JdbcCatalog should have any dependency on Hadoop file system.", "author": "jackye1995", "createdAt": "2020-12-16T22:27:40Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,382 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.PathFilter;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.hadoop.Util;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+\n+  public static final String JDBC_PARAM_PREFIX = \"connection.parameter.\";\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  private static final String TABLE_METADATA_FILE_EXTENSION = \".metadata.json\";\n+  private static final PathFilter TABLE_FILTER = path -> path.getName().endsWith(TABLE_METADATA_FILE_EXTENSION);\n+\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private FileIO fileIO;\n+  private FileSystem fs;", "originalCommit": "4551cd87bd31fa42204e3be97c977a9a093fd584", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjAyOTQ4NA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r546029484", "bodyText": "you are right, removed it", "author": "ismailsimsek", "createdAt": "2020-12-18T18:59:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDY2ODM3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU2MDY2Mw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r547560663", "bodyText": "This adds quite a bit of complexity to the JDBC implementation because it requires a separate table for namespace and stores both namespace name and metadata as JSON objects. I think that ensuring consistency between the two tables adds a lot of unnecessary complexity. What happens if a table is added to a namespace that as it is concurrently deleted?\nI think a much simpler implementation is to omit the namespace table and determine whether a namespace exists based on whether there are any tables in it. As long as we can guarantee atomic changes to the tables table, consistency problems go away.\nThat's also a simpler way to start a JDBC implementation. Then we can add namespace metadata later in a way that doesn't have those problems.\n@ismailsimsek what do you think about removing this and implementing namespaceExists based just on the tables table?", "author": "rdblue", "createdAt": "2020-12-22T23:46:11Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcNamespace.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import java.sql.Connection;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Stream;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcNamespace {", "originalCommit": "534babe9d218992035b7d3d8b991fce73ba314fd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzkxNjA4OQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r547916089", "bodyText": "makes sense to keep initial implementation small and simple", "author": "ismailsimsek", "createdAt": "2020-12-23T11:38:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU2MDY2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODI0NDE3Nw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r548244177", "bodyText": "removed namespace table and some of namespace methods", "author": "ismailsimsek", "createdAt": "2020-12-23T21:15:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU2MDY2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU2MTI5NQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r547561295", "bodyText": "We would normally omit the \"is\" from a method name if it is clear that the return value is a boolean. I think that exists meets that requirement because it is natural to say \"if table exists\" instead of \"if table is exists\".", "author": "rdblue", "createdAt": "2020-12-22T23:48:29Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcTable.java", "diffHunk": "@@ -0,0 +1,187 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import java.sql.Connection;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcTable {\n+  public static final String SQL_TABLE_NAME = \"iceberg_tables\";\n+  public static final String SQL_TABLE_DDL =\n+          \"CREATE TABLE \" + JdbcTable.SQL_TABLE_NAME +\n+                  \"(catalog_name VARCHAR(1255) NOT NULL,\" +\n+                  \"table_namespace VARCHAR(1255) NOT NULL,\" +\n+                  \"table_name VARCHAR(1255) NOT NULL,\" +\n+                  \"metadata_location VARCHAR(32768),\" +\n+                  \"previous_metadata_location VARCHAR(32768),\" +\n+                  \"PRIMARY KEY (catalog_name, table_namespace, table_name)\" +\n+                  \")\";\n+  public static final String SQL_SELECT = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_ALL = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ?\";\n+  public static final String SQL_UPDATE_METADATA_LOCATION = \"UPDATE \" + SQL_TABLE_NAME +\n+          \" SET metadata_location = ? , previous_metadata_location = ? \" +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? AND metadata_location = ?\";\n+  public static final String SQL_INSERT = \"INSERT INTO \" + SQL_TABLE_NAME +\n+          \" (catalog_name, table_namespace, table_name, metadata_location, previous_metadata_location) \" +\n+          \" VALUES (?,?,?,?,?)\";\n+  public static final String SQL_UPDATE_TABLE_NAME = \"UPDATE \" + SQL_TABLE_NAME +\n+          \" SET table_namespace = ? , table_name = ? \" +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_DELETE = \"DELETE FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcTable.class);\n+  private final String catalogName;\n+  private final Connection dbConn;\n+\n+  public JdbcTable(Connection dbConn, String catalogName) {\n+    this.dbConn = dbConn;\n+    this.catalogName = catalogName;\n+  }\n+\n+  public void setAutoCommitOff() throws SQLException {\n+    this.dbConn.setAutoCommit(false);\n+  }\n+\n+  public void setAutoCommitOn() throws SQLException {\n+    this.dbConn.setAutoCommit(true);\n+  }\n+\n+  public void commit() throws SQLException {\n+    this.dbConn.commit();\n+  }\n+\n+  public void rollback() throws SQLException {\n+    this.dbConn.rollback();\n+  }\n+\n+  public boolean isExists(TableIdentifier tableIdentifier) {", "originalCommit": "534babe9d218992035b7d3d8b991fce73ba314fd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU2NTQ3Ng==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r547565476", "bodyText": "Rather than using JSON to encode the namespace, I suggest converting it to a String using Joiner.on(\".\").\nThere's a trade-off to simplifying the problem by doing it that way: both a.`b.c`  and a.b.c end up as a.b.c. That has two effects:\n\nNamespaces that \"collide\" like that are considered the same namespace\nWhen listing namespace a the result is [b] and not [b.c, b]\n\nI think that those are fine. For the collisions, I think it is rare for users to want namespaces that can collide but are not the same. If someone creates the table a.`b.c`.table_name then I really doubt that everyone wants to escape b.c every time they type the identifier. Everyone is going to type a.b.c.table_name anyway, which would return incorrect results if both tables exist. So not allowing namespaces that conflict is actually a good thing.\nThis is exactly what Iceberg does to look up columns in a table, too. All column names are converted to a lookup key by joining the parts with .. Columns that have different structures but identical names aren't allowed, and I think it is better that way.", "author": "rdblue", "createdAt": "2020-12-23T00:05:22Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcTable.java", "diffHunk": "@@ -0,0 +1,187 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import java.sql.Connection;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcTable {\n+  public static final String SQL_TABLE_NAME = \"iceberg_tables\";\n+  public static final String SQL_TABLE_DDL =\n+          \"CREATE TABLE \" + JdbcTable.SQL_TABLE_NAME +\n+                  \"(catalog_name VARCHAR(1255) NOT NULL,\" +\n+                  \"table_namespace VARCHAR(1255) NOT NULL,\" +\n+                  \"table_name VARCHAR(1255) NOT NULL,\" +\n+                  \"metadata_location VARCHAR(32768),\" +\n+                  \"previous_metadata_location VARCHAR(32768),\" +\n+                  \"PRIMARY KEY (catalog_name, table_namespace, table_name)\" +\n+                  \")\";\n+  public static final String SQL_SELECT = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_ALL = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ?\";\n+  public static final String SQL_UPDATE_METADATA_LOCATION = \"UPDATE \" + SQL_TABLE_NAME +\n+          \" SET metadata_location = ? , previous_metadata_location = ? \" +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? AND metadata_location = ?\";\n+  public static final String SQL_INSERT = \"INSERT INTO \" + SQL_TABLE_NAME +\n+          \" (catalog_name, table_namespace, table_name, metadata_location, previous_metadata_location) \" +\n+          \" VALUES (?,?,?,?,?)\";\n+  public static final String SQL_UPDATE_TABLE_NAME = \"UPDATE \" + SQL_TABLE_NAME +\n+          \" SET table_namespace = ? , table_name = ? \" +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_DELETE = \"DELETE FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcTable.class);\n+  private final String catalogName;\n+  private final Connection dbConn;\n+\n+  public JdbcTable(Connection dbConn, String catalogName) {\n+    this.dbConn = dbConn;\n+    this.catalogName = catalogName;\n+  }\n+\n+  public void setAutoCommitOff() throws SQLException {\n+    this.dbConn.setAutoCommit(false);\n+  }\n+\n+  public void setAutoCommitOn() throws SQLException {\n+    this.dbConn.setAutoCommit(true);\n+  }\n+\n+  public void commit() throws SQLException {\n+    this.dbConn.commit();\n+  }\n+\n+  public void rollback() throws SQLException {\n+    this.dbConn.rollback();\n+  }\n+\n+  public boolean isExists(TableIdentifier tableIdentifier) {\n+    try {\n+      return !this.get(tableIdentifier).isEmpty();\n+    } catch (SQLException | JsonProcessingException throwables) {\n+      return false;\n+    }\n+  }\n+\n+  public Map<String, String> get(TableIdentifier tableIdentifier) throws SQLException, JsonProcessingException {\n+    Map<String, String> table = Maps.newHashMap();\n+    PreparedStatement sql = dbConn.prepareStatement(SQL_SELECT);\n+    sql.setString(1, catalogName);\n+    sql.setString(2, JdbcUtil.namespaceToString(tableIdentifier.namespace()));", "originalCommit": "534babe9d218992035b7d3d8b991fce73ba314fd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODI0MzM0NQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r548243345", "bodyText": "changed to Joiner", "author": "ismailsimsek", "createdAt": "2020-12-23T21:14:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU2NTQ3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU2NjAwOQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r547566009", "bodyText": "Nit: no need for a blank line at the start of a method.", "author": "rdblue", "createdAt": "2020-12-23T00:07:21Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcTable.java", "diffHunk": "@@ -0,0 +1,187 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import java.sql.Connection;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcTable {\n+  public static final String SQL_TABLE_NAME = \"iceberg_tables\";\n+  public static final String SQL_TABLE_DDL =\n+          \"CREATE TABLE \" + JdbcTable.SQL_TABLE_NAME +\n+                  \"(catalog_name VARCHAR(1255) NOT NULL,\" +\n+                  \"table_namespace VARCHAR(1255) NOT NULL,\" +\n+                  \"table_name VARCHAR(1255) NOT NULL,\" +\n+                  \"metadata_location VARCHAR(32768),\" +\n+                  \"previous_metadata_location VARCHAR(32768),\" +\n+                  \"PRIMARY KEY (catalog_name, table_namespace, table_name)\" +\n+                  \")\";\n+  public static final String SQL_SELECT = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_ALL = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ?\";\n+  public static final String SQL_UPDATE_METADATA_LOCATION = \"UPDATE \" + SQL_TABLE_NAME +\n+          \" SET metadata_location = ? , previous_metadata_location = ? \" +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? AND metadata_location = ?\";\n+  public static final String SQL_INSERT = \"INSERT INTO \" + SQL_TABLE_NAME +\n+          \" (catalog_name, table_namespace, table_name, metadata_location, previous_metadata_location) \" +\n+          \" VALUES (?,?,?,?,?)\";\n+  public static final String SQL_UPDATE_TABLE_NAME = \"UPDATE \" + SQL_TABLE_NAME +\n+          \" SET table_namespace = ? , table_name = ? \" +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_DELETE = \"DELETE FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcTable.class);\n+  private final String catalogName;\n+  private final Connection dbConn;\n+\n+  public JdbcTable(Connection dbConn, String catalogName) {\n+    this.dbConn = dbConn;\n+    this.catalogName = catalogName;\n+  }\n+\n+  public void setAutoCommitOff() throws SQLException {\n+    this.dbConn.setAutoCommit(false);\n+  }\n+\n+  public void setAutoCommitOn() throws SQLException {\n+    this.dbConn.setAutoCommit(true);\n+  }\n+\n+  public void commit() throws SQLException {\n+    this.dbConn.commit();\n+  }\n+\n+  public void rollback() throws SQLException {\n+    this.dbConn.rollback();\n+  }\n+\n+  public boolean isExists(TableIdentifier tableIdentifier) {\n+    try {\n+      return !this.get(tableIdentifier).isEmpty();\n+    } catch (SQLException | JsonProcessingException throwables) {\n+      return false;\n+    }\n+  }\n+\n+  public Map<String, String> get(TableIdentifier tableIdentifier) throws SQLException, JsonProcessingException {\n+    Map<String, String> table = Maps.newHashMap();\n+    PreparedStatement sql = dbConn.prepareStatement(SQL_SELECT);\n+    sql.setString(1, catalogName);\n+    sql.setString(2, JdbcUtil.namespaceToString(tableIdentifier.namespace()));\n+    sql.setString(3, tableIdentifier.name());\n+    ResultSet rs = sql.executeQuery();\n+    if (rs.next()) {\n+      table.put(\"catalog_name\", rs.getString(\"catalog_name\"));\n+      table.put(\"table_namespace\", rs.getString(\"table_namespace\"));\n+      table.put(\"table_name\", rs.getString(\"table_name\"));\n+      table.put(\"metadata_location\", rs.getString(\"metadata_location\"));\n+      table.put(\"previous_metadata_location\", rs.getString(\"previous_metadata_location\"));\n+    }\n+    rs.close();\n+    return table;\n+  }\n+\n+  public List<TableIdentifier> getAll(Namespace namespace) throws SQLException, JsonProcessingException {\n+    List<TableIdentifier> results = Lists.newArrayList();\n+\n+    PreparedStatement sql = dbConn.prepareStatement(SQL_SELECT_ALL);\n+    sql.setString(1, catalogName);\n+    sql.setString(2, JdbcUtil.namespaceToString(namespace));\n+    ResultSet rs = sql.executeQuery();\n+\n+    while (rs.next()) {\n+      final TableIdentifier table = JdbcUtil.stringToTableIdentifier(\n+              rs.getString(\"table_namespace\"), rs.getString(\"table_name\"));\n+      results.add(table);\n+    }\n+    rs.close();\n+    return results;\n+  }\n+\n+  public int updateMetadataLocation(TableIdentifier tableIdentifier, String oldMetadataLocation,\n+                                    String newMetadataLocation) throws SQLException, JsonProcessingException {\n+    PreparedStatement sql = dbConn.prepareStatement(SQL_UPDATE_METADATA_LOCATION);\n+    // UPDATE\n+    sql.setString(1, newMetadataLocation);\n+    sql.setString(2, oldMetadataLocation);\n+    // WHERE\n+    sql.setString(3, catalogName);\n+    sql.setString(4, JdbcUtil.namespaceToString(tableIdentifier.namespace()));\n+    sql.setString(5, tableIdentifier.name());\n+    sql.setString(6, oldMetadataLocation);\n+    return sql.executeUpdate();\n+  }\n+\n+  public int save(TableIdentifier tableIdentifier, String oldMetadataLocation,\n+                  String newMetadataLocation) throws SQLException, JsonProcessingException {\n+\n+    PreparedStatement sql = dbConn.prepareStatement(SQL_INSERT);\n+    sql.setString(1, catalogName);\n+    sql.setString(2, JdbcUtil.namespaceToString(tableIdentifier.namespace()));\n+    sql.setString(3, tableIdentifier.name());\n+    sql.setString(4, newMetadataLocation);\n+    sql.setString(5, oldMetadataLocation);\n+    return sql.executeUpdate();\n+\n+  }\n+\n+  public int updateTableName(TableIdentifier from, TableIdentifier to) throws SQLException, JsonProcessingException {\n+\n+    PreparedStatement sql = dbConn.prepareStatement(SQL_UPDATE_TABLE_NAME);\n+    sql.setString(1, JdbcUtil.namespaceToString(to.namespace()));\n+    sql.setString(2, to.name());\n+    sql.setString(3, catalogName);\n+    sql.setString(4, JdbcUtil.namespaceToString(from.namespace()));\n+    sql.setString(5, from.name());\n+    return sql.executeUpdate();\n+\n+  }\n+\n+  public int delete(TableIdentifier identifier) throws SQLException, JsonProcessingException {\n+", "originalCommit": "534babe9d218992035b7d3d8b991fce73ba314fd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU2NjE4Mw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r547566183", "bodyText": "Why are there two metadata locations passed here?", "author": "rdblue", "createdAt": "2020-12-23T00:08:11Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcTable.java", "diffHunk": "@@ -0,0 +1,187 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import java.sql.Connection;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcTable {\n+  public static final String SQL_TABLE_NAME = \"iceberg_tables\";\n+  public static final String SQL_TABLE_DDL =\n+          \"CREATE TABLE \" + JdbcTable.SQL_TABLE_NAME +\n+                  \"(catalog_name VARCHAR(1255) NOT NULL,\" +\n+                  \"table_namespace VARCHAR(1255) NOT NULL,\" +\n+                  \"table_name VARCHAR(1255) NOT NULL,\" +\n+                  \"metadata_location VARCHAR(32768),\" +\n+                  \"previous_metadata_location VARCHAR(32768),\" +\n+                  \"PRIMARY KEY (catalog_name, table_namespace, table_name)\" +\n+                  \")\";\n+  public static final String SQL_SELECT = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_ALL = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ?\";\n+  public static final String SQL_UPDATE_METADATA_LOCATION = \"UPDATE \" + SQL_TABLE_NAME +\n+          \" SET metadata_location = ? , previous_metadata_location = ? \" +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? AND metadata_location = ?\";\n+  public static final String SQL_INSERT = \"INSERT INTO \" + SQL_TABLE_NAME +\n+          \" (catalog_name, table_namespace, table_name, metadata_location, previous_metadata_location) \" +\n+          \" VALUES (?,?,?,?,?)\";\n+  public static final String SQL_UPDATE_TABLE_NAME = \"UPDATE \" + SQL_TABLE_NAME +\n+          \" SET table_namespace = ? , table_name = ? \" +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_DELETE = \"DELETE FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcTable.class);\n+  private final String catalogName;\n+  private final Connection dbConn;\n+\n+  public JdbcTable(Connection dbConn, String catalogName) {\n+    this.dbConn = dbConn;\n+    this.catalogName = catalogName;\n+  }\n+\n+  public void setAutoCommitOff() throws SQLException {\n+    this.dbConn.setAutoCommit(false);\n+  }\n+\n+  public void setAutoCommitOn() throws SQLException {\n+    this.dbConn.setAutoCommit(true);\n+  }\n+\n+  public void commit() throws SQLException {\n+    this.dbConn.commit();\n+  }\n+\n+  public void rollback() throws SQLException {\n+    this.dbConn.rollback();\n+  }\n+\n+  public boolean isExists(TableIdentifier tableIdentifier) {\n+    try {\n+      return !this.get(tableIdentifier).isEmpty();\n+    } catch (SQLException | JsonProcessingException throwables) {\n+      return false;\n+    }\n+  }\n+\n+  public Map<String, String> get(TableIdentifier tableIdentifier) throws SQLException, JsonProcessingException {\n+    Map<String, String> table = Maps.newHashMap();\n+    PreparedStatement sql = dbConn.prepareStatement(SQL_SELECT);\n+    sql.setString(1, catalogName);\n+    sql.setString(2, JdbcUtil.namespaceToString(tableIdentifier.namespace()));\n+    sql.setString(3, tableIdentifier.name());\n+    ResultSet rs = sql.executeQuery();\n+    if (rs.next()) {\n+      table.put(\"catalog_name\", rs.getString(\"catalog_name\"));\n+      table.put(\"table_namespace\", rs.getString(\"table_namespace\"));\n+      table.put(\"table_name\", rs.getString(\"table_name\"));\n+      table.put(\"metadata_location\", rs.getString(\"metadata_location\"));\n+      table.put(\"previous_metadata_location\", rs.getString(\"previous_metadata_location\"));\n+    }\n+    rs.close();\n+    return table;\n+  }\n+\n+  public List<TableIdentifier> getAll(Namespace namespace) throws SQLException, JsonProcessingException {\n+    List<TableIdentifier> results = Lists.newArrayList();\n+\n+    PreparedStatement sql = dbConn.prepareStatement(SQL_SELECT_ALL);\n+    sql.setString(1, catalogName);\n+    sql.setString(2, JdbcUtil.namespaceToString(namespace));\n+    ResultSet rs = sql.executeQuery();\n+\n+    while (rs.next()) {\n+      final TableIdentifier table = JdbcUtil.stringToTableIdentifier(\n+              rs.getString(\"table_namespace\"), rs.getString(\"table_name\"));\n+      results.add(table);\n+    }\n+    rs.close();\n+    return results;\n+  }\n+\n+  public int updateMetadataLocation(TableIdentifier tableIdentifier, String oldMetadataLocation,\n+                                    String newMetadataLocation) throws SQLException, JsonProcessingException {\n+    PreparedStatement sql = dbConn.prepareStatement(SQL_UPDATE_METADATA_LOCATION);\n+    // UPDATE\n+    sql.setString(1, newMetadataLocation);\n+    sql.setString(2, oldMetadataLocation);\n+    // WHERE\n+    sql.setString(3, catalogName);\n+    sql.setString(4, JdbcUtil.namespaceToString(tableIdentifier.namespace()));\n+    sql.setString(5, tableIdentifier.name());\n+    sql.setString(6, oldMetadataLocation);\n+    return sql.executeUpdate();\n+  }\n+\n+  public int save(TableIdentifier tableIdentifier, String oldMetadataLocation,\n+                  String newMetadataLocation) throws SQLException, JsonProcessingException {", "originalCommit": "534babe9d218992035b7d3d8b991fce73ba314fd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODI2NTQxMA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r548265410", "bodyText": "removed", "author": "ismailsimsek", "createdAt": "2020-12-23T21:44:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU2NjE4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU2ODExNQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r547568115", "bodyText": "This connection is passed into the TableOperations when creating a table, which means that it is potentially shared across threads. I don't think that connections are thread-safe, so that is a problem. For Hive, we implemented a connection pool that you should be able to reuse by extending org.apache.iceberg.hive.ClientPool. We may want to move that class into core so it can be used by both.", "author": "rdblue", "createdAt": "2020-12-23T00:16:02Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,325 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.SQLException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String JDBC_PARAM_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  private FileIO fileIO;\n+  private String name = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration hadoopConf;\n+  private Connection dbConn;", "originalCommit": "534babe9d218992035b7d3d8b991fce73ba314fd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODIzODIzMA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r548238230", "bodyText": "moved it to core and used for jdbc catalog", "author": "ismailsimsek", "createdAt": "2020-12-23T21:07:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU2ODExNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU2ODUwNA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r547568504", "bodyText": "Style: just one exception is caught, so the variable name should be singular, like throwable. Also, we tend to refer to the exception as simply e in most catch blocks.", "author": "rdblue", "createdAt": "2020-12-23T00:17:28Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,325 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.SQLException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String JDBC_PARAM_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  private FileIO fileIO;\n+  private String name = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration hadoopConf;\n+  private Connection dbConn;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @SuppressWarnings(\"checkstyle:HiddenField\")\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) throws UncheckedIOException {\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.HIVE_URI, \"\").isEmpty(),\n+            \"No connection url provided for jdbc catalog!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.WAREHOUSE_LOCATION, \"\").isEmpty(),\n+            \"Cannot initialize Jdbc Catalog because warehousePath must not be null!\");\n+\n+    this.warehouseLocation = properties.get(CatalogProperties.WAREHOUSE_LOCATION).replaceAll(\"/$\", \"\");\n+    this.name = name == null ? \"jdbc\" : name;\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ?\n+            new HadoopFileIO(hadoopConf) :\n+            CatalogUtil.loadFileIO(fileIOImpl, properties, hadoopConf);\n+    initializeConnection(properties);\n+  }\n+\n+  private void initializeConnection(Map<String, String> properties) throws UncheckedIOException {\n+    try {\n+\n+      LOG.debug(\"Connecting to Jdbc database {}.\", properties.get(CatalogProperties.HIVE_URI));\n+      Properties connectionProps = new Properties();\n+      for (Map.Entry<String, String> prop : properties.entrySet()) {\n+        if (prop.getKey().startsWith(JDBC_PARAM_PREFIX)) {\n+          connectionProps.put(prop.getKey().substring(JDBC_PARAM_PREFIX.length()), prop.getValue());\n+        }\n+      }\n+\n+      dbConn = DriverManager.getConnection(properties.get(CatalogProperties.HIVE_URI), connectionProps);\n+      initializeCatalogTables();\n+\n+    } catch (SQLException throwables) {", "originalCommit": "534babe9d218992035b7d3d8b991fce73ba314fd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU2ODgyOA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r547568828", "bodyText": "No need to wrap in an IOException. I think we should create an unchecked exception used to wrap SQLException.", "author": "rdblue", "createdAt": "2020-12-23T00:18:40Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,325 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.SQLException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String JDBC_PARAM_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  private FileIO fileIO;\n+  private String name = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration hadoopConf;\n+  private Connection dbConn;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @SuppressWarnings(\"checkstyle:HiddenField\")\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) throws UncheckedIOException {\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.HIVE_URI, \"\").isEmpty(),\n+            \"No connection url provided for jdbc catalog!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.WAREHOUSE_LOCATION, \"\").isEmpty(),\n+            \"Cannot initialize Jdbc Catalog because warehousePath must not be null!\");\n+\n+    this.warehouseLocation = properties.get(CatalogProperties.WAREHOUSE_LOCATION).replaceAll(\"/$\", \"\");\n+    this.name = name == null ? \"jdbc\" : name;\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ?\n+            new HadoopFileIO(hadoopConf) :\n+            CatalogUtil.loadFileIO(fileIOImpl, properties, hadoopConf);\n+    initializeConnection(properties);\n+  }\n+\n+  private void initializeConnection(Map<String, String> properties) throws UncheckedIOException {\n+    try {\n+\n+      LOG.debug(\"Connecting to Jdbc database {}.\", properties.get(CatalogProperties.HIVE_URI));\n+      Properties connectionProps = new Properties();\n+      for (Map.Entry<String, String> prop : properties.entrySet()) {\n+        if (prop.getKey().startsWith(JDBC_PARAM_PREFIX)) {\n+          connectionProps.put(prop.getKey().substring(JDBC_PARAM_PREFIX.length()), prop.getValue());\n+        }\n+      }\n+\n+      dbConn = DriverManager.getConnection(properties.get(CatalogProperties.HIVE_URI), connectionProps);\n+      initializeCatalogTables();\n+\n+    } catch (SQLException throwables) {\n+      throw new UncheckedIOException(\"Failed to initialize Jdbc Catalog!\", new IOException(throwables));", "originalCommit": "534babe9d218992035b7d3d8b991fce73ba314fd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU2OTAyOA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r547569028", "bodyText": "Also, if we can catch more specific subclasses, that would be ideal. Here's a list of them: https://docs.oracle.com/javase/7/docs/api/java/sql/SQLException.html", "author": "rdblue", "createdAt": "2020-12-23T00:19:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU2ODgyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTE3NjQwNg==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r549176406", "bodyText": "created UncheckedSQLException extending UncheckedIOException, and captured some specific sql exceptions. not sure if i got it right..", "author": "ismailsimsek", "createdAt": "2020-12-27T23:31:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU2ODgyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU3Mjk1Mg==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r547572952", "bodyText": "I'm not sure that I think this class is valuable. It is nice that it keeps track of the SQL statements and exposes some high-level methods, like update. The problem is that this provides many of the same operations as catalog, just under different names and with a slightly different API. For example, getAll(Namespace) is basically the same thing as Catalog.listTables.\nThis class is also used in inconsistent ways. In Catalog.delete and in TableOperations, it is used for a single table even though it can work with any table and has no state other than catalog and connection. It is also used in Catalog.listTables and Catalog.renameTable, even though there is no table to encapsulate.\nI think that the problem is that this is attempting to encapsulate a table, but it is really more about abstracting some of the SQL details. I think an improvement would be to instantiate one per catalog instead (and pass in a connection pool so it can be shared with TableOperations). You'd probably want to rename it to something like TableSQL?", "author": "rdblue", "createdAt": "2020-12-23T00:34:28Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcTable.java", "diffHunk": "@@ -0,0 +1,187 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import java.sql.Connection;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcTable {", "originalCommit": "534babe9d218992035b7d3d8b991fce73ba314fd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU3NDUyOQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r547574529", "bodyText": "One more thing: it would be helpful if all of the methods in this class that correspond to methods in Catalog were named the same way as the ones in Catalog. For example, getAll is really listTables and updateTableName is really renameTable. Using names consistently will make it easier for people to understand what this is doing.", "author": "rdblue", "createdAt": "2020-12-23T00:40:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU3Mjk1Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODIzNzQzMA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r548237430", "bodyText": "good idea implement it, and reorganized code a bit\n\nI think an improvement would be to instantiate one per catalog instead (and pass in a connection pool so it can be shared with TableOperations). You'd probably want to rename it to something like TableSQL?", "author": "ismailsimsek", "createdAt": "2020-12-23T21:06:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU3Mjk1Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTExMjczNA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r549112734", "bodyText": "I'm not sure that I think this class is valuable. ...\n\ni see the pint totally makes sense. i see two options to address it\n\nmerge it to Catalog and TableOperations class and only pass connection pool to TableOperations, similar to hive.\nsplit it to CatalogSQL, TableOperationsSQL classes. TableOperationsSQL is used by TableOperations, and it additionally gets table identifier with constructor\n\nmaybe its best to merge it to Catalog and address it with the future changes? to keep it simple for now.", "author": "ismailsimsek", "createdAt": "2020-12-27T13:21:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU3Mjk1Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTE0ODE4MQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r549148181", "bodyText": "went with first option and moved code to to Catalog and TableOperations classes.", "author": "ismailsimsek", "createdAt": "2020-12-27T18:17:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU3Mjk1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU3Mzc5Mw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r547573793", "bodyText": "Are these needed? I think that autocommit can be used since all of the operations should just require a single command.", "author": "rdblue", "createdAt": "2020-12-23T00:37:51Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcTable.java", "diffHunk": "@@ -0,0 +1,187 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import java.sql.Connection;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcTable {\n+  public static final String SQL_TABLE_NAME = \"iceberg_tables\";\n+  public static final String SQL_TABLE_DDL =\n+          \"CREATE TABLE \" + JdbcTable.SQL_TABLE_NAME +\n+                  \"(catalog_name VARCHAR(1255) NOT NULL,\" +\n+                  \"table_namespace VARCHAR(1255) NOT NULL,\" +\n+                  \"table_name VARCHAR(1255) NOT NULL,\" +\n+                  \"metadata_location VARCHAR(32768),\" +\n+                  \"previous_metadata_location VARCHAR(32768),\" +\n+                  \"PRIMARY KEY (catalog_name, table_namespace, table_name)\" +\n+                  \")\";\n+  public static final String SQL_SELECT = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_ALL = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ?\";\n+  public static final String SQL_UPDATE_METADATA_LOCATION = \"UPDATE \" + SQL_TABLE_NAME +\n+          \" SET metadata_location = ? , previous_metadata_location = ? \" +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? AND metadata_location = ?\";\n+  public static final String SQL_INSERT = \"INSERT INTO \" + SQL_TABLE_NAME +\n+          \" (catalog_name, table_namespace, table_name, metadata_location, previous_metadata_location) \" +\n+          \" VALUES (?,?,?,?,?)\";\n+  public static final String SQL_UPDATE_TABLE_NAME = \"UPDATE \" + SQL_TABLE_NAME +\n+          \" SET table_namespace = ? , table_name = ? \" +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_DELETE = \"DELETE FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcTable.class);\n+  private final String catalogName;\n+  private final Connection dbConn;\n+\n+  public JdbcTable(Connection dbConn, String catalogName) {\n+    this.dbConn = dbConn;\n+    this.catalogName = catalogName;\n+  }\n+\n+  public void setAutoCommitOff() throws SQLException {\n+    this.dbConn.setAutoCommit(false);\n+  }\n+\n+  public void setAutoCommitOn() throws SQLException {\n+    this.dbConn.setAutoCommit(true);\n+  }\n+\n+  public void commit() throws SQLException {\n+    this.dbConn.commit();\n+  }\n+\n+  public void rollback() throws SQLException {\n+    this.dbConn.rollback();", "originalCommit": "534babe9d218992035b7d3d8b991fce73ba314fd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODIxNTg4MQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r548215881", "bodyText": "it was useful to rollback namespace changes when renaming a table fails(moving a table between catalogs). now we can remove it.", "author": "ismailsimsek", "createdAt": "2020-12-23T20:36:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU3Mzc5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU3NTIzMQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r547575231", "bodyText": "This shouldn't be needed because only Hadoop tables use version hints.", "author": "rdblue", "createdAt": "2020-12-23T00:43:35Z", "path": "core/src/test/java/org/apache/iceberg/jdbc/TestJdbcCatalog.java", "diffHunk": "@@ -0,0 +1,566 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.AssertHelpers;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.DataFiles;\n+import org.apache.iceberg.PartitionSpec;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.SortOrder;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.Transaction;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.Util;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.relocated.com.google.common.collect.Sets;\n+import org.apache.iceberg.transforms.Transform;\n+import org.apache.iceberg.transforms.Transforms;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+\n+import static org.apache.iceberg.NullOrder.NULLS_FIRST;\n+import static org.apache.iceberg.SortDirection.ASC;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+public class TestJdbcCatalog {\n+  // Schema passed to create tables\n+  static final Schema SCHEMA = new Schema(\n+          required(1, \"id\", Types.IntegerType.get(), \"unique ID\"),\n+          required(2, \"data\", Types.StringType.get())\n+  );\n+\n+  // This is the actual schema for the table, with column IDs reassigned\n+  static final Schema TABLE_SCHEMA = new Schema(\n+          required(1, \"id\", Types.IntegerType.get(), \"unique ID\"),\n+          required(2, \"data\", Types.StringType.get())\n+  );\n+\n+  // Partition spec used to create tables\n+  static final PartitionSpec SPEC = PartitionSpec.builderFor(SCHEMA)\n+          .bucket(\"data\", 16)\n+          .build();\n+\n+  private static final ImmutableMap<String, String> meta = ImmutableMap.of();\n+  static Configuration conf;\n+  private static JdbcCatalog catalog;\n+  @Rule\n+  public TemporaryFolder temp = new TemporaryFolder();\n+  File tableDir = null;\n+  String tableLocation = null;\n+  File versionHintFile = null;\n+  String warehousePath;\n+\n+  protected List<String> metadataVersionFiles(String location) {\n+    return Stream.of(new File(location).listFiles())\n+            .filter(file -> !file.isDirectory())\n+            .map(File::getName)\n+            .filter(fileName -> fileName.endsWith(\"metadata.json\"))\n+            .collect(Collectors.toList())\n+            ;\n+  }\n+\n+  protected List<String> manifestFiles(String location) {\n+    return Stream.of(new File(location).listFiles())\n+            .filter(file -> !file.isDirectory())\n+            .map(File::getName)\n+            .filter(fileName -> fileName.endsWith(\".avro\"))\n+            .collect(Collectors.toList())\n+            ;\n+  }\n+\n+  @Before\n+  public void setupTable() throws Exception {\n+    this.tableDir = temp.newFolder();\n+    tableDir.delete(); // created by table create\n+\n+    this.tableLocation = tableDir.toURI().toString();\n+    this.versionHintFile = new File(new File(tableDir, \"metadata\"), \"version-hint.text\");", "originalCommit": "534babe9d218992035b7d3d8b991fce73ba314fd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU3NTc2Nw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r547575767", "bodyText": "I think that there need to be tests for the JDBC operations that are exposed by JdbcTable directly. Those should check cases that are required, like creating a table fails if it already exists, updating a table when metadata is out of date catches the error, etc. Then we can add functional tests to ensure that the catalog calls those correctly.", "author": "rdblue", "createdAt": "2020-12-23T00:45:51Z", "path": "core/src/test/java/org/apache/iceberg/jdbc/TestJdbcCatalog.java", "diffHunk": "@@ -0,0 +1,566 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.AssertHelpers;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.DataFiles;\n+import org.apache.iceberg.PartitionSpec;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.SortOrder;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.Transaction;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.Util;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.relocated.com.google.common.collect.Sets;\n+import org.apache.iceberg.transforms.Transform;\n+import org.apache.iceberg.transforms.Transforms;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+\n+import static org.apache.iceberg.NullOrder.NULLS_FIRST;\n+import static org.apache.iceberg.SortDirection.ASC;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+public class TestJdbcCatalog {", "originalCommit": "534babe9d218992035b7d3d8b991fce73ba314fd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "561f1bce03b8c4a6217539d0ed50d697c9bf227b", "url": "https://github.com/apache/iceberg/commit/561f1bce03b8c4a6217539d0ed50d697c9bf227b", "message": "WIP address review comments - connection pool", "committedDate": "2020-12-23T20:07:30Z", "type": "forcePushed"}, {"oid": "9febe36ee420a77be431ce38b0e9960e5f31d04c", "url": "https://github.com/apache/iceberg/commit/9febe36ee420a77be431ce38b0e9960e5f31d04c", "message": "jdbc catalog\n\naddress review comments\n\nmore cleanup\n\ntest rollback scenario with renameTable\n\nfix\n\ncleanup\n\ncleanup, removed fs, create empty constructor and updated initialization\n\nfix unittest\n\nadded jdbc catalog to SparkCatalog and added tests to TestRemoveOrphanFilesAction3\n\nadded new test\n\nfix naming\n\ndo updates inside transaction and rollback updates if it fails.\n\nensure target namespace is exists before renaming table\n\nfix scope, revert license changes\n\njdbc catalog", "committedDate": "2020-12-23T20:09:53Z", "type": "forcePushed"}, {"oid": "81b65f7383b4b0cf5823aac7aa56c796126fcd7d", "url": "https://github.com/apache/iceberg/commit/81b65f7383b4b0cf5823aac7aa56c796126fcd7d", "message": "address review comments\n\naddress review comments", "committedDate": "2020-12-27T20:09:38Z", "type": "forcePushed"}, {"oid": "e6f8c6e36d78a79c8a8561292c2fa07f7e7f480a", "url": "https://github.com/apache/iceberg/commit/e6f8c6e36d78a79c8a8561292c2fa07f7e7f480a", "message": "extent UncheckedSQLException from UncheckedIOException", "committedDate": "2020-12-27T23:32:44Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUyNDgwNA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r549524804", "bodyText": "Why extend UncheckedIOException? This class is supposed to be the equivalent for SQLException, which is not an IOException.", "author": "rdblue", "createdAt": "2020-12-29T00:14:02Z", "path": "api/src/main/java/org/apache/iceberg/exceptions/UncheckedSQLException.java", "diffHunk": "@@ -0,0 +1,43 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.exceptions;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.sql.SQLException;\n+\n+public class UncheckedSQLException extends UncheckedIOException {", "originalCommit": "e6f8c6e36d78a79c8a8561292c2fa07f7e7f480a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUyNDg2OQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r549524869", "bodyText": "There is no need to wrap an exception that isn't a SQLException is there?", "author": "rdblue", "createdAt": "2020-12-29T00:14:29Z", "path": "api/src/main/java/org/apache/iceberg/exceptions/UncheckedSQLException.java", "diffHunk": "@@ -0,0 +1,43 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.exceptions;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.sql.SQLException;\n+\n+public class UncheckedSQLException extends UncheckedIOException {\n+\n+  public UncheckedSQLException(String message, SQLException cause) {\n+    super(message, new IOException(cause));\n+  }\n+\n+  public UncheckedSQLException(String message, Exception cause) {", "originalCommit": "e6f8c6e36d78a79c8a8561292c2fa07f7e7f480a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUyNDg5MQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r549524891", "bodyText": "I don't think this is needed.", "author": "rdblue", "createdAt": "2020-12-29T00:14:40Z", "path": "api/src/main/java/org/apache/iceberg/exceptions/UncheckedSQLException.java", "diffHunk": "@@ -0,0 +1,43 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.exceptions;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.sql.SQLException;\n+\n+public class UncheckedSQLException extends UncheckedIOException {\n+\n+  public UncheckedSQLException(String message, SQLException cause) {\n+    super(message, new IOException(cause));\n+  }\n+\n+  public UncheckedSQLException(String message, Exception cause) {\n+    super(message, new IOException(cause));\n+  }\n+\n+  public UncheckedSQLException(String message, InterruptedException cause) {\n+    super(message, new IOException(cause));\n+  }\n+\n+  public UncheckedSQLException(String message) {", "originalCommit": "e6f8c6e36d78a79c8a8561292c2fa07f7e7f480a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUyNDg5OA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r549524898", "bodyText": "I don't think this is needed.", "author": "rdblue", "createdAt": "2020-12-29T00:14:43Z", "path": "api/src/main/java/org/apache/iceberg/exceptions/UncheckedSQLException.java", "diffHunk": "@@ -0,0 +1,43 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.exceptions;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.sql.SQLException;\n+\n+public class UncheckedSQLException extends UncheckedIOException {\n+\n+  public UncheckedSQLException(String message, SQLException cause) {\n+    super(message, new IOException(cause));\n+  }\n+\n+  public UncheckedSQLException(String message, Exception cause) {\n+    super(message, new IOException(cause));\n+  }\n+\n+  public UncheckedSQLException(String message, InterruptedException cause) {", "originalCommit": "e6f8c6e36d78a79c8a8561292c2fa07f7e7f480a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUyNjEwNw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r549526107", "bodyText": "DriverManager.getConnection will throw SQLTimeoutException or a generic SQLException. Those are the only two exception classes that need to be handled. Considering there isn't much that can be done for either one, I think this should simply wrap any SQLException in UncheckedSQLException with a little context, like the connect URI.", "author": "rdblue", "createdAt": "2020-12-29T00:22:27Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcClientPool.java", "diffHunk": "@@ -0,0 +1,77 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.SQLException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Properties;\n+import org.apache.iceberg.ClientPool;\n+import org.apache.iceberg.exceptions.UncheckedSQLException;\n+\n+public class JdbcClientPool extends ClientPool<Connection, SQLException> {\n+\n+  private final String dbUrl;\n+  private final Properties dbProperties;\n+\n+  JdbcClientPool(String dbUrl, Properties props) {\n+    this((Integer) props.getOrDefault(\"iceberg.jdbc.client-pool-size\", 5), dbUrl, props);\n+  }\n+\n+  public JdbcClientPool(int poolSize, String dbUrl, Properties props) {\n+    super(poolSize, SQLException.class);\n+    dbProperties = props;\n+    this.dbUrl = dbUrl;\n+  }\n+\n+  @Override\n+  protected Connection newClient() {\n+    try {\n+      return DriverManager.getConnection(dbUrl, dbProperties);\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(\"Connection timeout!\", e);\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(\"Connection failed!\", e);\n+    } catch (SQLWarning e) {\n+      throw new UncheckedSQLException(\"Database connection warning!\", e);\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(\"Failed to connect to database!\", e);", "originalCommit": "e6f8c6e36d78a79c8a8561292c2fa07f7e7f480a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUyNzI3Ng==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r549527276", "bodyText": "The second argument for the ClientPool constructor is an exception that indicates a connection has gone bad and should be recreated using reconnect. I don't think that any SQLException should trigger reconnecting because there are a lot of different subclasses that have nothing to do with connection issues.\nIn Hive, we use TTransportException, which indicates a connection failure rather than an error from the remote service. It looks like the equivalent for JDBC might be SQLNonTransientConnectionException.", "author": "rdblue", "createdAt": "2020-12-29T00:29:06Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcClientPool.java", "diffHunk": "@@ -0,0 +1,77 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.SQLException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Properties;\n+import org.apache.iceberg.ClientPool;\n+import org.apache.iceberg.exceptions.UncheckedSQLException;\n+\n+public class JdbcClientPool extends ClientPool<Connection, SQLException> {\n+\n+  private final String dbUrl;\n+  private final Properties dbProperties;\n+\n+  JdbcClientPool(String dbUrl, Properties props) {\n+    this((Integer) props.getOrDefault(\"iceberg.jdbc.client-pool-size\", 5), dbUrl, props);\n+  }\n+\n+  public JdbcClientPool(int poolSize, String dbUrl, Properties props) {\n+    super(poolSize, SQLException.class);", "originalCommit": "e6f8c6e36d78a79c8a8561292c2fa07f7e7f480a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUyNzc4MQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r549527781", "bodyText": "I don't think that Iceberg uses Properties anywhere, so this should probably accept Map<String, String> and pass that to JDBC as properties if necessary.\nAlso, config properties don't need config context like iceberg.jdbc because that context is already dependent on how the catalog is configured. For example, Spark catalogs will use spark.sql.catalog.catalog_name.uri for the connection URI already. So the property keys here should just be the standard ones defined in CatalogProperties.", "author": "rdblue", "createdAt": "2020-12-29T00:32:31Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcClientPool.java", "diffHunk": "@@ -0,0 +1,77 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.SQLException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Properties;\n+import org.apache.iceberg.ClientPool;\n+import org.apache.iceberg.exceptions.UncheckedSQLException;\n+\n+public class JdbcClientPool extends ClientPool<Connection, SQLException> {\n+\n+  private final String dbUrl;\n+  private final Properties dbProperties;\n+\n+  JdbcClientPool(String dbUrl, Properties props) {", "originalCommit": "e6f8c6e36d78a79c8a8561292c2fa07f7e7f480a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQ3MDgwNw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r550470807", "bodyText": "i see updated it,\n@rdblue what do you think about passing additional jdbc parameters with following prefix? is it okay or there shuld be no prefix?\npublic static final String JDBC_PARAM_PREFIX = \"connection.parameter.\";\ncurrent setup will be like\nspark.sql.catalog.catalog_name.uri=jdbc:postgresql://localhost:5432/mydatabase\nspark.sql.catalog.catalog_name.connection.parameter.user=myuser\nspark.sql.catalog.catalog_name.connection.parameter.password=mypass\nspark.sql.catalog.catalog_name.connection.parameter.ssl=true\nspark.sql.catalog.catalog_name.connection.parameter.param1=val1\nspark.sql.catalog.catalog_name.connection.parameter.param2=val2", "author": "ismailsimsek", "createdAt": "2020-12-31T12:13:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUyNzc4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUyODAxNA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r549528014", "bodyText": "No need to prefix with this when calling a method or reading a field. We only add it to distinguish between setting instance fields (this.x = ...) and local variables (x = ...).", "author": "rdblue", "createdAt": "2020-12-29T00:34:06Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcClientPool.java", "diffHunk": "@@ -0,0 +1,77 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.SQLException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Properties;\n+import org.apache.iceberg.ClientPool;\n+import org.apache.iceberg.exceptions.UncheckedSQLException;\n+\n+public class JdbcClientPool extends ClientPool<Connection, SQLException> {\n+\n+  private final String dbUrl;\n+  private final Properties dbProperties;\n+\n+  JdbcClientPool(String dbUrl, Properties props) {\n+    this((Integer) props.getOrDefault(\"iceberg.jdbc.client-pool-size\", 5), dbUrl, props);\n+  }\n+\n+  public JdbcClientPool(int poolSize, String dbUrl, Properties props) {\n+    super(poolSize, SQLException.class);\n+    dbProperties = props;\n+    this.dbUrl = dbUrl;\n+  }\n+\n+  @Override\n+  protected Connection newClient() {\n+    try {\n+      return DriverManager.getConnection(dbUrl, dbProperties);\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(\"Connection timeout!\", e);\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(\"Connection failed!\", e);\n+    } catch (SQLWarning e) {\n+      throw new UncheckedSQLException(\"Database connection warning!\", e);\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(\"Failed to connect to database!\", e);\n+    }\n+  }\n+\n+  @Override\n+  protected Connection reconnect(Connection client) {\n+    this.close(client);", "originalCommit": "e6f8c6e36d78a79c8a8561292c2fa07f7e7f480a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUyODIyMw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r549528223", "bodyText": "Nit: continuation indents should be 2 indents, which is 4 spaces, not 8.", "author": "rdblue", "createdAt": "2020-12-29T00:35:31Z", "path": "core/src/test/java/org/apache/iceberg/jdbc/TestJdbcTableConcurrency.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.DataFiles;\n+import org.apache.iceberg.FileFormat;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.Iterables;\n+import org.apache.iceberg.relocated.com.google.common.util.concurrent.MoreExecutors;\n+import org.apache.iceberg.types.Types;\n+import org.apache.iceberg.util.Tasks;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+\n+import static org.apache.iceberg.TableProperties.COMMIT_MAX_RETRY_WAIT_MS;\n+import static org.apache.iceberg.TableProperties.COMMIT_MIN_RETRY_WAIT_MS;\n+import static org.apache.iceberg.TableProperties.COMMIT_NUM_RETRIES;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+public class TestJdbcTableConcurrency {\n+\n+  static final TableIdentifier TABLE_IDENTIFIER = TableIdentifier.of(\"db\", \"test_table\");\n+  static final Schema SCHEMA = new Schema(\n+          required(1, \"id\", Types.IntegerType.get(), \"unique ID\"),\n+          required(2, \"data\", Types.StringType.get())\n+  );\n+  @Rule\n+  public TemporaryFolder temp = new TemporaryFolder();\n+  File tableDir;\n+\n+  @Test\n+  public synchronized void testConcurrentFastAppends() throws IOException {\n+    Map<String, String> properties = new HashMap<>();\n+    this.tableDir = temp.newFolder();\n+    properties.put(CatalogProperties.WAREHOUSE_LOCATION, tableDir.getAbsolutePath());\n+    properties.put(CatalogProperties.HIVE_URI, \"jdbc:h2:mem:concurentFastAppend;create=true\");\n+    JdbcCatalog catalog = new JdbcCatalog();\n+    catalog.setConf(new Configuration());\n+    catalog.initialize(\"jdbc\", properties);\n+    catalog.createTable(TABLE_IDENTIFIER, SCHEMA);\n+\n+    Table icebergTable = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    String fileName = UUID.randomUUID().toString();\n+    DataFile file = DataFiles.builder(icebergTable.spec())\n+            .withPath(FileFormat.PARQUET.addExtension(fileName))", "originalCommit": "e6f8c6e36d78a79c8a8561292c2fa07f7e7f480a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQ4MTk4Ng==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r550481986", "bodyText": "updated my editor setting and reformatted files.", "author": "ismailsimsek", "createdAt": "2020-12-31T13:20:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUyODIyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUyODM2OQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r549528369", "bodyText": "This test should also be moved if the original class was moved.", "author": "rdblue", "createdAt": "2020-12-29T00:36:17Z", "path": "hive-metastore/src/test/java/org/apache/iceberg/hive/TestClientPool.java", "diffHunk": "@@ -19,6 +19,7 @@\n \n package org.apache.iceberg.hive;\n \n+import org.apache.iceberg.ClientPool;", "originalCommit": "e6f8c6e36d78a79c8a8561292c2fa07f7e7f480a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQ4MTkxNg==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r550481916", "bodyText": "my bad, thank you for pointing it.", "author": "ismailsimsek", "createdAt": "2020-12-31T13:20:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUyODM2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUyODQxNg==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r549528416", "bodyText": "Nit: unnecessary whitespace change.", "author": "rdblue", "createdAt": "2020-12-29T00:36:34Z", "path": "spark3/src/main/java/org/apache/iceberg/spark/SparkCatalog.java", "diffHunk": "@@ -111,14 +113,20 @@ protected Catalog buildIcebergCatalog(String name, CaseInsensitiveStringMap opti\n     switch (catalogType.toLowerCase(Locale.ENGLISH)) {\n       case ICEBERG_CATALOG_TYPE_HIVE:\n         int clientPoolSize = options.getInt(CatalogProperties.HIVE_CLIENT_POOL_SIZE,\n-            CatalogProperties.HIVE_CLIENT_POOL_SIZE_DEFAULT);\n+                CatalogProperties.HIVE_CLIENT_POOL_SIZE_DEFAULT);", "originalCommit": "e6f8c6e36d78a79c8a8561292c2fa07f7e7f480a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUyOTA4Ng==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r549529086", "bodyText": "Style: in other places, we use different naming conventions:\n\nFileIO instances are typically called io\nConfiguration instances are typically called conf\nA pool would typically be a plural named for the pooled objects, like connections", "author": "rdblue", "createdAt": "2020-12-29T00:40:48Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,391 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.Connection;\n+import java.sql.DataTruncation;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.UncheckedSQLException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String SQL_TABLE_NAME = \"iceberg_tables\";\n+  public static final String SQL_TABLE_DDL =\n+          \"CREATE TABLE \" + SQL_TABLE_NAME +\n+                  \"(catalog_name VARCHAR(1255) NOT NULL,\" +\n+                  \"table_namespace VARCHAR(1255) NOT NULL,\" +\n+                  \"table_name VARCHAR(1255) NOT NULL,\" +\n+                  \"metadata_location VARCHAR(32768),\" +\n+                  \"previous_metadata_location VARCHAR(32768),\" +\n+                  \"PRIMARY KEY (catalog_name, table_namespace, table_name)\" +\n+                  \")\";\n+  public static final String SQL_SELECT_TABLE = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_ALL = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ?\";\n+  public static final String SQL_UPDATE_TABLE_NAME = \"UPDATE \" + SQL_TABLE_NAME +\n+          \" SET table_namespace = ? , table_name = ? \" +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_DELETE_TABLE = \"DELETE FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_NAMESPACE = \"SELECT table_namespace FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace LIKE ? LIMIT 1\";\n+  public static final String SQL_SELECT_NAMESPACES = \"SELECT DISTINCT table_namespace FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace LIKE ?\";\n+  public static final String JDBC_PARAM_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO fileIO;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration hadoopConf;\n+  private JdbcClientPool dbConnPool;", "originalCommit": "e6f8c6e36d78a79c8a8561292c2fa07f7e7f480a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUyOTE2NA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r549529164", "bodyText": "I don't think we should suppress this. Instead, can you update the code to avoid it?", "author": "rdblue", "createdAt": "2020-12-29T00:41:32Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,391 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.Connection;\n+import java.sql.DataTruncation;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.UncheckedSQLException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String SQL_TABLE_NAME = \"iceberg_tables\";\n+  public static final String SQL_TABLE_DDL =\n+          \"CREATE TABLE \" + SQL_TABLE_NAME +\n+                  \"(catalog_name VARCHAR(1255) NOT NULL,\" +\n+                  \"table_namespace VARCHAR(1255) NOT NULL,\" +\n+                  \"table_name VARCHAR(1255) NOT NULL,\" +\n+                  \"metadata_location VARCHAR(32768),\" +\n+                  \"previous_metadata_location VARCHAR(32768),\" +\n+                  \"PRIMARY KEY (catalog_name, table_namespace, table_name)\" +\n+                  \")\";\n+  public static final String SQL_SELECT_TABLE = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_ALL = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ?\";\n+  public static final String SQL_UPDATE_TABLE_NAME = \"UPDATE \" + SQL_TABLE_NAME +\n+          \" SET table_namespace = ? , table_name = ? \" +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_DELETE_TABLE = \"DELETE FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_NAMESPACE = \"SELECT table_namespace FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace LIKE ? LIMIT 1\";\n+  public static final String SQL_SELECT_NAMESPACES = \"SELECT DISTINCT table_namespace FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace LIKE ?\";\n+  public static final String JDBC_PARAM_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO fileIO;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration hadoopConf;\n+  private JdbcClientPool dbConnPool;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @SuppressWarnings(\"checkstyle:HiddenField\")", "originalCommit": "e6f8c6e36d78a79c8a8561292c2fa07f7e7f480a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUyOTU2Nw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r549529567", "bodyText": "Is this required by the database or is it just a convention? I don't think we should check for multiple table names.", "author": "rdblue", "createdAt": "2020-12-29T00:44:03Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,391 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.Connection;\n+import java.sql.DataTruncation;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.UncheckedSQLException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String SQL_TABLE_NAME = \"iceberg_tables\";\n+  public static final String SQL_TABLE_DDL =\n+          \"CREATE TABLE \" + SQL_TABLE_NAME +\n+                  \"(catalog_name VARCHAR(1255) NOT NULL,\" +\n+                  \"table_namespace VARCHAR(1255) NOT NULL,\" +\n+                  \"table_name VARCHAR(1255) NOT NULL,\" +\n+                  \"metadata_location VARCHAR(32768),\" +\n+                  \"previous_metadata_location VARCHAR(32768),\" +\n+                  \"PRIMARY KEY (catalog_name, table_namespace, table_name)\" +\n+                  \")\";\n+  public static final String SQL_SELECT_TABLE = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_ALL = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ?\";\n+  public static final String SQL_UPDATE_TABLE_NAME = \"UPDATE \" + SQL_TABLE_NAME +\n+          \" SET table_namespace = ? , table_name = ? \" +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_DELETE_TABLE = \"DELETE FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_NAMESPACE = \"SELECT table_namespace FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace LIKE ? LIMIT 1\";\n+  public static final String SQL_SELECT_NAMESPACES = \"SELECT DISTINCT table_namespace FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace LIKE ?\";\n+  public static final String JDBC_PARAM_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO fileIO;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration hadoopConf;\n+  private JdbcClientPool dbConnPool;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @SuppressWarnings(\"checkstyle:HiddenField\")\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.HIVE_URI, \"\").isEmpty(),\n+            \"No connection url provided for jdbc catalog!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.WAREHOUSE_LOCATION, \"\").isEmpty(),\n+            \"Cannot initialize Jdbc Catalog because warehousePath must not be null!\");\n+\n+    this.warehouseLocation = properties.get(CatalogProperties.WAREHOUSE_LOCATION).replaceAll(\"/$\", \"\");\n+    this.catalogName = name == null ? \"jdbc\" : name;\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ?\n+            new HadoopFileIO(hadoopConf) :\n+            CatalogUtil.loadFileIO(fileIOImpl, properties, hadoopConf);\n+    initializeConnection(properties);\n+  }\n+\n+  private void initializeConnection(Map<String, String> properties) {\n+    try {\n+      LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.HIVE_URI));\n+      Properties dbProps = new Properties();\n+      for (Map.Entry<String, String> prop : properties.entrySet()) {\n+        if (prop.getKey().startsWith(JDBC_PARAM_PREFIX)) {\n+          dbProps.put(prop.getKey().substring(JDBC_PARAM_PREFIX.length()), prop.getValue());\n+        }\n+      }\n+      dbConnPool = new JdbcClientPool(properties.get(CatalogProperties.HIVE_URI), dbProps);\n+      initializeCatalogTables();\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(\"Database Connection timeout!\", e);\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(\"Database Connection failed!\", e);\n+    } catch (SQLWarning e) {\n+      throw new UncheckedSQLException(\"Database connection warning!\", e);\n+    } catch (SQLException | InterruptedException e) {\n+      throw new UncheckedSQLException(\"Failed to initialize Jdbc Catalog!\", e);\n+    }\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    // need to check multiple times because some databases are using different naming standard. ex: H2db keeping\n+    // table names as uppercase", "originalCommit": "e6f8c6e36d78a79c8a8561292c2fa07f7e7f480a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Mjc4ODAxMQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r552788011", "bodyText": "SQL standard requires names stored in uppercase. I think we can just use upper case names for all tables we define.\nnit: put ex on a second line as a complete sentence", "author": "jackye1995", "createdAt": "2021-01-06T16:37:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUyOTU2Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzQ1OTc3OQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r553459779", "bodyText": "this one is database dependent. following section is looking for a table case sensitive(database dependent)\nif we use CREATE TABLE IF NOT EXISTS we can remove this method, more details here \nDatabaseMetaData dbMeta = conn.getMetaData();\nResultSet tables = dbMeta.getTables(null, null, SQL_TABLE_NAME, null);", "author": "ismailsimsek", "createdAt": "2021-01-07T17:05:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUyOTU2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUyOTgwMA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r549529800", "bodyText": "I think these exceptions should be handled in initializeCatalogTables, not in this method.", "author": "rdblue", "createdAt": "2020-12-29T00:45:29Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,391 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.Connection;\n+import java.sql.DataTruncation;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.UncheckedSQLException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String SQL_TABLE_NAME = \"iceberg_tables\";\n+  public static final String SQL_TABLE_DDL =\n+          \"CREATE TABLE \" + SQL_TABLE_NAME +\n+                  \"(catalog_name VARCHAR(1255) NOT NULL,\" +\n+                  \"table_namespace VARCHAR(1255) NOT NULL,\" +\n+                  \"table_name VARCHAR(1255) NOT NULL,\" +\n+                  \"metadata_location VARCHAR(32768),\" +\n+                  \"previous_metadata_location VARCHAR(32768),\" +\n+                  \"PRIMARY KEY (catalog_name, table_namespace, table_name)\" +\n+                  \")\";\n+  public static final String SQL_SELECT_TABLE = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_ALL = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ?\";\n+  public static final String SQL_UPDATE_TABLE_NAME = \"UPDATE \" + SQL_TABLE_NAME +\n+          \" SET table_namespace = ? , table_name = ? \" +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_DELETE_TABLE = \"DELETE FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_NAMESPACE = \"SELECT table_namespace FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace LIKE ? LIMIT 1\";\n+  public static final String SQL_SELECT_NAMESPACES = \"SELECT DISTINCT table_namespace FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace LIKE ?\";\n+  public static final String JDBC_PARAM_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO fileIO;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration hadoopConf;\n+  private JdbcClientPool dbConnPool;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @SuppressWarnings(\"checkstyle:HiddenField\")\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.HIVE_URI, \"\").isEmpty(),\n+            \"No connection url provided for jdbc catalog!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.WAREHOUSE_LOCATION, \"\").isEmpty(),\n+            \"Cannot initialize Jdbc Catalog because warehousePath must not be null!\");\n+\n+    this.warehouseLocation = properties.get(CatalogProperties.WAREHOUSE_LOCATION).replaceAll(\"/$\", \"\");\n+    this.catalogName = name == null ? \"jdbc\" : name;\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ?\n+            new HadoopFileIO(hadoopConf) :\n+            CatalogUtil.loadFileIO(fileIOImpl, properties, hadoopConf);\n+    initializeConnection(properties);\n+  }\n+\n+  private void initializeConnection(Map<String, String> properties) {\n+    try {\n+      LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.HIVE_URI));\n+      Properties dbProps = new Properties();\n+      for (Map.Entry<String, String> prop : properties.entrySet()) {\n+        if (prop.getKey().startsWith(JDBC_PARAM_PREFIX)) {\n+          dbProps.put(prop.getKey().substring(JDBC_PARAM_PREFIX.length()), prop.getValue());\n+        }\n+      }\n+      dbConnPool = new JdbcClientPool(properties.get(CatalogProperties.HIVE_URI), dbProps);\n+      initializeCatalogTables();\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(\"Database Connection timeout!\", e);\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(\"Database Connection failed!\", e);\n+    } catch (SQLWarning e) {\n+      throw new UncheckedSQLException(\"Database connection warning!\", e);\n+    } catch (SQLException | InterruptedException e) {\n+      throw new UncheckedSQLException(\"Failed to initialize Jdbc Catalog!\", e);", "originalCommit": "e6f8c6e36d78a79c8a8561292c2fa07f7e7f480a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUyOTk1NQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r549529955", "bodyText": "Why doesn't this store the table name that was found? Does it rely on case insensitive SQL behavior later?", "author": "rdblue", "createdAt": "2020-12-29T00:46:20Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,391 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.Connection;\n+import java.sql.DataTruncation;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.UncheckedSQLException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String SQL_TABLE_NAME = \"iceberg_tables\";\n+  public static final String SQL_TABLE_DDL =\n+          \"CREATE TABLE \" + SQL_TABLE_NAME +\n+                  \"(catalog_name VARCHAR(1255) NOT NULL,\" +\n+                  \"table_namespace VARCHAR(1255) NOT NULL,\" +\n+                  \"table_name VARCHAR(1255) NOT NULL,\" +\n+                  \"metadata_location VARCHAR(32768),\" +\n+                  \"previous_metadata_location VARCHAR(32768),\" +\n+                  \"PRIMARY KEY (catalog_name, table_namespace, table_name)\" +\n+                  \")\";\n+  public static final String SQL_SELECT_TABLE = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_ALL = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ?\";\n+  public static final String SQL_UPDATE_TABLE_NAME = \"UPDATE \" + SQL_TABLE_NAME +\n+          \" SET table_namespace = ? , table_name = ? \" +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_DELETE_TABLE = \"DELETE FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_NAMESPACE = \"SELECT table_namespace FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace LIKE ? LIMIT 1\";\n+  public static final String SQL_SELECT_NAMESPACES = \"SELECT DISTINCT table_namespace FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace LIKE ?\";\n+  public static final String JDBC_PARAM_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO fileIO;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration hadoopConf;\n+  private JdbcClientPool dbConnPool;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @SuppressWarnings(\"checkstyle:HiddenField\")\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.HIVE_URI, \"\").isEmpty(),\n+            \"No connection url provided for jdbc catalog!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.WAREHOUSE_LOCATION, \"\").isEmpty(),\n+            \"Cannot initialize Jdbc Catalog because warehousePath must not be null!\");\n+\n+    this.warehouseLocation = properties.get(CatalogProperties.WAREHOUSE_LOCATION).replaceAll(\"/$\", \"\");\n+    this.catalogName = name == null ? \"jdbc\" : name;\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ?\n+            new HadoopFileIO(hadoopConf) :\n+            CatalogUtil.loadFileIO(fileIOImpl, properties, hadoopConf);\n+    initializeConnection(properties);\n+  }\n+\n+  private void initializeConnection(Map<String, String> properties) {\n+    try {\n+      LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.HIVE_URI));\n+      Properties dbProps = new Properties();\n+      for (Map.Entry<String, String> prop : properties.entrySet()) {\n+        if (prop.getKey().startsWith(JDBC_PARAM_PREFIX)) {\n+          dbProps.put(prop.getKey().substring(JDBC_PARAM_PREFIX.length()), prop.getValue());\n+        }\n+      }\n+      dbConnPool = new JdbcClientPool(properties.get(CatalogProperties.HIVE_URI), dbProps);\n+      initializeCatalogTables();\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(\"Database Connection timeout!\", e);\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(\"Database Connection failed!\", e);\n+    } catch (SQLWarning e) {\n+      throw new UncheckedSQLException(\"Database connection warning!\", e);\n+    } catch (SQLException | InterruptedException e) {\n+      throw new UncheckedSQLException(\"Failed to initialize Jdbc Catalog!\", e);\n+    }\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    // need to check multiple times because some databases are using different naming standard. ex: H2db keeping\n+    // table names as uppercase\n+    boolean exists = false;\n+    DatabaseMetaData dbMeta = dbConnPool.run(Connection::getMetaData);\n+    ResultSet tables = dbMeta.getTables(null, null, SQL_TABLE_NAME, null);\n+    if (tables.next()) {\n+      exists = true;\n+    }\n+    tables.close();\n+    ResultSet tablesUpper = dbMeta.getTables(null, null, SQL_TABLE_NAME.toUpperCase(), null);\n+    if (tablesUpper.next()) {\n+      exists = true;", "originalCommit": "e6f8c6e36d78a79c8a8561292c2fa07f7e7f480a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQ2ODg5NQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r550468895", "bodyText": "this one checking if the table exists and creates it if it is not. equivalent of CREATE TABLE IF NOT EXISTS since MS sql server not supporting IF NOT EXISTS created this method to do the check(if the catalog table already created or not).\n.getTables is doing case sensitive table check. and some databases are keeping table names uppercase that's why its doing multiple checks(lowercase, uppercase, as is). same question is here \nits not elegant but seems like working, few options i think of are\n\nuse CREATE TABLE IF NOT EXISTS\nfetch all tables once with dbMeta.getTables and then look for the table with case insensitive match", "author": "ismailsimsek", "createdAt": "2020-12-31T12:02:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUyOTk1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUzMDMwMg==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r549530302", "bodyText": "This will result in toString called on the result of levels(), which is a String[]. That isn't correct. I think you want to pass SLASH.join(table.namespace().levels()) into this join instead.", "author": "rdblue", "createdAt": "2020-12-29T00:48:35Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,391 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.Connection;\n+import java.sql.DataTruncation;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.UncheckedSQLException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String SQL_TABLE_NAME = \"iceberg_tables\";\n+  public static final String SQL_TABLE_DDL =\n+          \"CREATE TABLE \" + SQL_TABLE_NAME +\n+                  \"(catalog_name VARCHAR(1255) NOT NULL,\" +\n+                  \"table_namespace VARCHAR(1255) NOT NULL,\" +\n+                  \"table_name VARCHAR(1255) NOT NULL,\" +\n+                  \"metadata_location VARCHAR(32768),\" +\n+                  \"previous_metadata_location VARCHAR(32768),\" +\n+                  \"PRIMARY KEY (catalog_name, table_namespace, table_name)\" +\n+                  \")\";\n+  public static final String SQL_SELECT_TABLE = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_ALL = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ?\";\n+  public static final String SQL_UPDATE_TABLE_NAME = \"UPDATE \" + SQL_TABLE_NAME +\n+          \" SET table_namespace = ? , table_name = ? \" +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_DELETE_TABLE = \"DELETE FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_NAMESPACE = \"SELECT table_namespace FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace LIKE ? LIMIT 1\";\n+  public static final String SQL_SELECT_NAMESPACES = \"SELECT DISTINCT table_namespace FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace LIKE ?\";\n+  public static final String JDBC_PARAM_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO fileIO;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration hadoopConf;\n+  private JdbcClientPool dbConnPool;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @SuppressWarnings(\"checkstyle:HiddenField\")\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.HIVE_URI, \"\").isEmpty(),\n+            \"No connection url provided for jdbc catalog!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.WAREHOUSE_LOCATION, \"\").isEmpty(),\n+            \"Cannot initialize Jdbc Catalog because warehousePath must not be null!\");\n+\n+    this.warehouseLocation = properties.get(CatalogProperties.WAREHOUSE_LOCATION).replaceAll(\"/$\", \"\");\n+    this.catalogName = name == null ? \"jdbc\" : name;\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ?\n+            new HadoopFileIO(hadoopConf) :\n+            CatalogUtil.loadFileIO(fileIOImpl, properties, hadoopConf);\n+    initializeConnection(properties);\n+  }\n+\n+  private void initializeConnection(Map<String, String> properties) {\n+    try {\n+      LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.HIVE_URI));\n+      Properties dbProps = new Properties();\n+      for (Map.Entry<String, String> prop : properties.entrySet()) {\n+        if (prop.getKey().startsWith(JDBC_PARAM_PREFIX)) {\n+          dbProps.put(prop.getKey().substring(JDBC_PARAM_PREFIX.length()), prop.getValue());\n+        }\n+      }\n+      dbConnPool = new JdbcClientPool(properties.get(CatalogProperties.HIVE_URI), dbProps);\n+      initializeCatalogTables();\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(\"Database Connection timeout!\", e);\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(\"Database Connection failed!\", e);\n+    } catch (SQLWarning e) {\n+      throw new UncheckedSQLException(\"Database connection warning!\", e);\n+    } catch (SQLException | InterruptedException e) {\n+      throw new UncheckedSQLException(\"Failed to initialize Jdbc Catalog!\", e);\n+    }\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    // need to check multiple times because some databases are using different naming standard. ex: H2db keeping\n+    // table names as uppercase\n+    boolean exists = false;\n+    DatabaseMetaData dbMeta = dbConnPool.run(Connection::getMetaData);\n+    ResultSet tables = dbMeta.getTables(null, null, SQL_TABLE_NAME, null);\n+    if (tables.next()) {\n+      exists = true;\n+    }\n+    tables.close();\n+    ResultSet tablesUpper = dbMeta.getTables(null, null, SQL_TABLE_NAME.toUpperCase(), null);\n+    if (tablesUpper.next()) {\n+      exists = true;\n+    }\n+    tablesUpper.close();\n+    ResultSet tablesLower = dbMeta.getTables(null, null, SQL_TABLE_NAME.toLowerCase(), null);\n+    if (tablesLower.next()) {\n+      exists = true;\n+    }\n+    tablesLower.close();\n+\n+    // create table if not exits\n+    if (!exists) {\n+      dbConnPool.run(conn -> conn.prepareStatement(SQL_TABLE_DDL).execute());\n+      LOG.debug(\"Created table {} to store iceberg tables!\", SQL_TABLE_NAME);\n+    }\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    return new JdbcTableOperations(dbConnPool, fileIO, catalogName, tableIdentifier);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().levels(), table.name());", "originalCommit": "e6f8c6e36d78a79c8a8561292c2fa07f7e7f480a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUzMDU4Ng==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r549530586", "bodyText": "Style: please add newlines after control flow blocks like if, for, etc.", "author": "rdblue", "createdAt": "2020-12-29T00:50:23Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,391 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.Connection;\n+import java.sql.DataTruncation;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.UncheckedSQLException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String SQL_TABLE_NAME = \"iceberg_tables\";\n+  public static final String SQL_TABLE_DDL =\n+          \"CREATE TABLE \" + SQL_TABLE_NAME +\n+                  \"(catalog_name VARCHAR(1255) NOT NULL,\" +\n+                  \"table_namespace VARCHAR(1255) NOT NULL,\" +\n+                  \"table_name VARCHAR(1255) NOT NULL,\" +\n+                  \"metadata_location VARCHAR(32768),\" +\n+                  \"previous_metadata_location VARCHAR(32768),\" +\n+                  \"PRIMARY KEY (catalog_name, table_namespace, table_name)\" +\n+                  \")\";\n+  public static final String SQL_SELECT_TABLE = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_ALL = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ?\";\n+  public static final String SQL_UPDATE_TABLE_NAME = \"UPDATE \" + SQL_TABLE_NAME +\n+          \" SET table_namespace = ? , table_name = ? \" +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_DELETE_TABLE = \"DELETE FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_NAMESPACE = \"SELECT table_namespace FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace LIKE ? LIMIT 1\";\n+  public static final String SQL_SELECT_NAMESPACES = \"SELECT DISTINCT table_namespace FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace LIKE ?\";\n+  public static final String JDBC_PARAM_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO fileIO;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration hadoopConf;\n+  private JdbcClientPool dbConnPool;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @SuppressWarnings(\"checkstyle:HiddenField\")\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.HIVE_URI, \"\").isEmpty(),\n+            \"No connection url provided for jdbc catalog!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.WAREHOUSE_LOCATION, \"\").isEmpty(),\n+            \"Cannot initialize Jdbc Catalog because warehousePath must not be null!\");\n+\n+    this.warehouseLocation = properties.get(CatalogProperties.WAREHOUSE_LOCATION).replaceAll(\"/$\", \"\");\n+    this.catalogName = name == null ? \"jdbc\" : name;\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ?\n+            new HadoopFileIO(hadoopConf) :\n+            CatalogUtil.loadFileIO(fileIOImpl, properties, hadoopConf);\n+    initializeConnection(properties);\n+  }\n+\n+  private void initializeConnection(Map<String, String> properties) {\n+    try {\n+      LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.HIVE_URI));\n+      Properties dbProps = new Properties();\n+      for (Map.Entry<String, String> prop : properties.entrySet()) {\n+        if (prop.getKey().startsWith(JDBC_PARAM_PREFIX)) {\n+          dbProps.put(prop.getKey().substring(JDBC_PARAM_PREFIX.length()), prop.getValue());\n+        }\n+      }\n+      dbConnPool = new JdbcClientPool(properties.get(CatalogProperties.HIVE_URI), dbProps);\n+      initializeCatalogTables();\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(\"Database Connection timeout!\", e);\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(\"Database Connection failed!\", e);\n+    } catch (SQLWarning e) {\n+      throw new UncheckedSQLException(\"Database connection warning!\", e);\n+    } catch (SQLException | InterruptedException e) {\n+      throw new UncheckedSQLException(\"Failed to initialize Jdbc Catalog!\", e);\n+    }\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    // need to check multiple times because some databases are using different naming standard. ex: H2db keeping\n+    // table names as uppercase\n+    boolean exists = false;\n+    DatabaseMetaData dbMeta = dbConnPool.run(Connection::getMetaData);\n+    ResultSet tables = dbMeta.getTables(null, null, SQL_TABLE_NAME, null);\n+    if (tables.next()) {\n+      exists = true;\n+    }\n+    tables.close();\n+    ResultSet tablesUpper = dbMeta.getTables(null, null, SQL_TABLE_NAME.toUpperCase(), null);\n+    if (tablesUpper.next()) {\n+      exists = true;\n+    }\n+    tablesUpper.close();\n+    ResultSet tablesLower = dbMeta.getTables(null, null, SQL_TABLE_NAME.toLowerCase(), null);\n+    if (tablesLower.next()) {\n+      exists = true;\n+    }\n+    tablesLower.close();\n+\n+    // create table if not exits\n+    if (!exists) {\n+      dbConnPool.run(conn -> conn.prepareStatement(SQL_TABLE_DDL).execute());\n+      LOG.debug(\"Created table {} to store iceberg tables!\", SQL_TABLE_NAME);\n+    }\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    return new JdbcTableOperations(dbConnPool, fileIO, catalogName, tableIdentifier);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().levels(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata = ops.current();\n+    try {\n+      PreparedStatement sql = dbConnPool.run(c -> c.prepareStatement(SQL_DELETE_TABLE));\n+      sql.setString(1, catalogName);\n+      sql.setString(2, JdbcUtil.namespaceToString(identifier.namespace()));\n+      sql.setString(3, identifier.name());\n+      int deletedRecords = sql.executeUpdate();\n+\n+      if (deletedRecords > 0) {\n+        LOG.debug(\"Successfully dropped table {}.\", identifier);\n+      } else {\n+        throw new NoSuchTableException(\"Cannot drop table %s! table not found in the catalog.\", identifier);\n+      }\n+\n+      if (purge && lastMetadata != null) {\n+        CatalogUtil.dropTableData(ops.io(), lastMetadata);\n+        LOG.info(\"Table {} data purged!\", identifier);\n+      }\n+      return true;\n+    } catch (SQLException | InterruptedException e) {\n+      throw new UncheckedSQLException(\"Failed to drop table!\", e);\n+    }\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    if (!this.namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Namespace %s does not exist!\", namespace);\n+    }\n+    try {", "originalCommit": "e6f8c6e36d78a79c8a8561292c2fa07f7e7f480a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUzMDY0NA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r549530644", "bodyText": "Could this use try-with-resources instead of calling close later?", "author": "rdblue", "createdAt": "2020-12-29T00:50:59Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,391 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.Connection;\n+import java.sql.DataTruncation;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.UncheckedSQLException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String SQL_TABLE_NAME = \"iceberg_tables\";\n+  public static final String SQL_TABLE_DDL =\n+          \"CREATE TABLE \" + SQL_TABLE_NAME +\n+                  \"(catalog_name VARCHAR(1255) NOT NULL,\" +\n+                  \"table_namespace VARCHAR(1255) NOT NULL,\" +\n+                  \"table_name VARCHAR(1255) NOT NULL,\" +\n+                  \"metadata_location VARCHAR(32768),\" +\n+                  \"previous_metadata_location VARCHAR(32768),\" +\n+                  \"PRIMARY KEY (catalog_name, table_namespace, table_name)\" +\n+                  \")\";\n+  public static final String SQL_SELECT_TABLE = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_ALL = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ?\";\n+  public static final String SQL_UPDATE_TABLE_NAME = \"UPDATE \" + SQL_TABLE_NAME +\n+          \" SET table_namespace = ? , table_name = ? \" +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_DELETE_TABLE = \"DELETE FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_NAMESPACE = \"SELECT table_namespace FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace LIKE ? LIMIT 1\";\n+  public static final String SQL_SELECT_NAMESPACES = \"SELECT DISTINCT table_namespace FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace LIKE ?\";\n+  public static final String JDBC_PARAM_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO fileIO;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration hadoopConf;\n+  private JdbcClientPool dbConnPool;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @SuppressWarnings(\"checkstyle:HiddenField\")\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.HIVE_URI, \"\").isEmpty(),\n+            \"No connection url provided for jdbc catalog!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.WAREHOUSE_LOCATION, \"\").isEmpty(),\n+            \"Cannot initialize Jdbc Catalog because warehousePath must not be null!\");\n+\n+    this.warehouseLocation = properties.get(CatalogProperties.WAREHOUSE_LOCATION).replaceAll(\"/$\", \"\");\n+    this.catalogName = name == null ? \"jdbc\" : name;\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ?\n+            new HadoopFileIO(hadoopConf) :\n+            CatalogUtil.loadFileIO(fileIOImpl, properties, hadoopConf);\n+    initializeConnection(properties);\n+  }\n+\n+  private void initializeConnection(Map<String, String> properties) {\n+    try {\n+      LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.HIVE_URI));\n+      Properties dbProps = new Properties();\n+      for (Map.Entry<String, String> prop : properties.entrySet()) {\n+        if (prop.getKey().startsWith(JDBC_PARAM_PREFIX)) {\n+          dbProps.put(prop.getKey().substring(JDBC_PARAM_PREFIX.length()), prop.getValue());\n+        }\n+      }\n+      dbConnPool = new JdbcClientPool(properties.get(CatalogProperties.HIVE_URI), dbProps);\n+      initializeCatalogTables();\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(\"Database Connection timeout!\", e);\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(\"Database Connection failed!\", e);\n+    } catch (SQLWarning e) {\n+      throw new UncheckedSQLException(\"Database connection warning!\", e);\n+    } catch (SQLException | InterruptedException e) {\n+      throw new UncheckedSQLException(\"Failed to initialize Jdbc Catalog!\", e);\n+    }\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    // need to check multiple times because some databases are using different naming standard. ex: H2db keeping\n+    // table names as uppercase\n+    boolean exists = false;\n+    DatabaseMetaData dbMeta = dbConnPool.run(Connection::getMetaData);\n+    ResultSet tables = dbMeta.getTables(null, null, SQL_TABLE_NAME, null);\n+    if (tables.next()) {\n+      exists = true;\n+    }\n+    tables.close();\n+    ResultSet tablesUpper = dbMeta.getTables(null, null, SQL_TABLE_NAME.toUpperCase(), null);\n+    if (tablesUpper.next()) {\n+      exists = true;\n+    }\n+    tablesUpper.close();\n+    ResultSet tablesLower = dbMeta.getTables(null, null, SQL_TABLE_NAME.toLowerCase(), null);\n+    if (tablesLower.next()) {\n+      exists = true;\n+    }\n+    tablesLower.close();\n+\n+    // create table if not exits\n+    if (!exists) {\n+      dbConnPool.run(conn -> conn.prepareStatement(SQL_TABLE_DDL).execute());\n+      LOG.debug(\"Created table {} to store iceberg tables!\", SQL_TABLE_NAME);\n+    }\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    return new JdbcTableOperations(dbConnPool, fileIO, catalogName, tableIdentifier);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().levels(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata = ops.current();\n+    try {\n+      PreparedStatement sql = dbConnPool.run(c -> c.prepareStatement(SQL_DELETE_TABLE));\n+      sql.setString(1, catalogName);\n+      sql.setString(2, JdbcUtil.namespaceToString(identifier.namespace()));\n+      sql.setString(3, identifier.name());\n+      int deletedRecords = sql.executeUpdate();\n+\n+      if (deletedRecords > 0) {\n+        LOG.debug(\"Successfully dropped table {}.\", identifier);\n+      } else {\n+        throw new NoSuchTableException(\"Cannot drop table %s! table not found in the catalog.\", identifier);\n+      }\n+\n+      if (purge && lastMetadata != null) {\n+        CatalogUtil.dropTableData(ops.io(), lastMetadata);\n+        LOG.info(\"Table {} data purged!\", identifier);\n+      }\n+      return true;\n+    } catch (SQLException | InterruptedException e) {\n+      throw new UncheckedSQLException(\"Failed to drop table!\", e);\n+    }\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    if (!this.namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Namespace %s does not exist!\", namespace);\n+    }\n+    try {\n+      List<TableIdentifier> results = Lists.newArrayList();\n+      PreparedStatement sql = dbConnPool.run(c -> c.prepareStatement(SQL_SELECT_ALL));\n+      sql.setString(1, catalogName);\n+      sql.setString(2, JdbcUtil.namespaceToString(namespace));\n+      ResultSet rs = sql.executeQuery();", "originalCommit": "e6f8c6e36d78a79c8a8561292c2fa07f7e7f480a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUzNDU4NA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r549534584", "bodyText": "I fixed this in the version above. That uses a try-with-resources block for the prepared statement so that all of the resources are released before releasing the connection back to the pool.", "author": "rdblue", "createdAt": "2020-12-29T01:16:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUzMDY0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUzMTAxOA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r549531018", "bodyText": "This is not a correct return. If SQLException was thrown, then this should throw UncheckedSQLException with context about the operation, like Cannot list tables in namespace: %s.", "author": "rdblue", "createdAt": "2020-12-29T00:53:31Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,391 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.Connection;\n+import java.sql.DataTruncation;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.UncheckedSQLException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String SQL_TABLE_NAME = \"iceberg_tables\";\n+  public static final String SQL_TABLE_DDL =\n+          \"CREATE TABLE \" + SQL_TABLE_NAME +\n+                  \"(catalog_name VARCHAR(1255) NOT NULL,\" +\n+                  \"table_namespace VARCHAR(1255) NOT NULL,\" +\n+                  \"table_name VARCHAR(1255) NOT NULL,\" +\n+                  \"metadata_location VARCHAR(32768),\" +\n+                  \"previous_metadata_location VARCHAR(32768),\" +\n+                  \"PRIMARY KEY (catalog_name, table_namespace, table_name)\" +\n+                  \")\";\n+  public static final String SQL_SELECT_TABLE = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_ALL = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ?\";\n+  public static final String SQL_UPDATE_TABLE_NAME = \"UPDATE \" + SQL_TABLE_NAME +\n+          \" SET table_namespace = ? , table_name = ? \" +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_DELETE_TABLE = \"DELETE FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_NAMESPACE = \"SELECT table_namespace FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace LIKE ? LIMIT 1\";\n+  public static final String SQL_SELECT_NAMESPACES = \"SELECT DISTINCT table_namespace FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace LIKE ?\";\n+  public static final String JDBC_PARAM_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO fileIO;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration hadoopConf;\n+  private JdbcClientPool dbConnPool;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @SuppressWarnings(\"checkstyle:HiddenField\")\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.HIVE_URI, \"\").isEmpty(),\n+            \"No connection url provided for jdbc catalog!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.WAREHOUSE_LOCATION, \"\").isEmpty(),\n+            \"Cannot initialize Jdbc Catalog because warehousePath must not be null!\");\n+\n+    this.warehouseLocation = properties.get(CatalogProperties.WAREHOUSE_LOCATION).replaceAll(\"/$\", \"\");\n+    this.catalogName = name == null ? \"jdbc\" : name;\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ?\n+            new HadoopFileIO(hadoopConf) :\n+            CatalogUtil.loadFileIO(fileIOImpl, properties, hadoopConf);\n+    initializeConnection(properties);\n+  }\n+\n+  private void initializeConnection(Map<String, String> properties) {\n+    try {\n+      LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.HIVE_URI));\n+      Properties dbProps = new Properties();\n+      for (Map.Entry<String, String> prop : properties.entrySet()) {\n+        if (prop.getKey().startsWith(JDBC_PARAM_PREFIX)) {\n+          dbProps.put(prop.getKey().substring(JDBC_PARAM_PREFIX.length()), prop.getValue());\n+        }\n+      }\n+      dbConnPool = new JdbcClientPool(properties.get(CatalogProperties.HIVE_URI), dbProps);\n+      initializeCatalogTables();\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(\"Database Connection timeout!\", e);\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(\"Database Connection failed!\", e);\n+    } catch (SQLWarning e) {\n+      throw new UncheckedSQLException(\"Database connection warning!\", e);\n+    } catch (SQLException | InterruptedException e) {\n+      throw new UncheckedSQLException(\"Failed to initialize Jdbc Catalog!\", e);\n+    }\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    // need to check multiple times because some databases are using different naming standard. ex: H2db keeping\n+    // table names as uppercase\n+    boolean exists = false;\n+    DatabaseMetaData dbMeta = dbConnPool.run(Connection::getMetaData);\n+    ResultSet tables = dbMeta.getTables(null, null, SQL_TABLE_NAME, null);\n+    if (tables.next()) {\n+      exists = true;\n+    }\n+    tables.close();\n+    ResultSet tablesUpper = dbMeta.getTables(null, null, SQL_TABLE_NAME.toUpperCase(), null);\n+    if (tablesUpper.next()) {\n+      exists = true;\n+    }\n+    tablesUpper.close();\n+    ResultSet tablesLower = dbMeta.getTables(null, null, SQL_TABLE_NAME.toLowerCase(), null);\n+    if (tablesLower.next()) {\n+      exists = true;\n+    }\n+    tablesLower.close();\n+\n+    // create table if not exits\n+    if (!exists) {\n+      dbConnPool.run(conn -> conn.prepareStatement(SQL_TABLE_DDL).execute());\n+      LOG.debug(\"Created table {} to store iceberg tables!\", SQL_TABLE_NAME);\n+    }\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    return new JdbcTableOperations(dbConnPool, fileIO, catalogName, tableIdentifier);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().levels(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata = ops.current();\n+    try {\n+      PreparedStatement sql = dbConnPool.run(c -> c.prepareStatement(SQL_DELETE_TABLE));\n+      sql.setString(1, catalogName);\n+      sql.setString(2, JdbcUtil.namespaceToString(identifier.namespace()));\n+      sql.setString(3, identifier.name());\n+      int deletedRecords = sql.executeUpdate();\n+\n+      if (deletedRecords > 0) {\n+        LOG.debug(\"Successfully dropped table {}.\", identifier);\n+      } else {\n+        throw new NoSuchTableException(\"Cannot drop table %s! table not found in the catalog.\", identifier);\n+      }\n+\n+      if (purge && lastMetadata != null) {\n+        CatalogUtil.dropTableData(ops.io(), lastMetadata);\n+        LOG.info(\"Table {} data purged!\", identifier);\n+      }\n+      return true;\n+    } catch (SQLException | InterruptedException e) {\n+      throw new UncheckedSQLException(\"Failed to drop table!\", e);\n+    }\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    if (!this.namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Namespace %s does not exist!\", namespace);\n+    }\n+    try {\n+      List<TableIdentifier> results = Lists.newArrayList();\n+      PreparedStatement sql = dbConnPool.run(c -> c.prepareStatement(SQL_SELECT_ALL));\n+      sql.setString(1, catalogName);\n+      sql.setString(2, JdbcUtil.namespaceToString(namespace));\n+      ResultSet rs = sql.executeQuery();\n+\n+      while (rs.next()) {\n+        final TableIdentifier table = JdbcUtil.stringToTableIdentifier(\n+                rs.getString(\"table_namespace\"), rs.getString(\"table_name\"));\n+        results.add(table);\n+      }\n+      rs.close();\n+      return results;\n+\n+    } catch (SQLException | InterruptedException e) {\n+      LOG.error(\"Failed to list tables!\", e);\n+      return null;", "originalCommit": "e6f8c6e36d78a79c8a8561292c2fa07f7e7f480a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUzNDI4MA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r549534280", "bodyText": "I think that the result set and prepared statement are tied to the connection that was used to create the statement. That means that as long as this method is using either the statement or the result set, the connection should not be reused by another thread.\nTo hold the connection, the whole query will need to go in the run block. Here's my version of this method with that change:\n  @Override\n  public List<TableIdentifier> listTables(Namespace namespace) {\n    if (!this.namespaceExists(namespace)) {\n      throw new NoSuchNamespaceException(\"Namespace %s does not exist!\", namespace);\n    }\n\n    try {\n      return dbConnPool.run(conn -> {\n        List<TableIdentifier> results = Lists.newArrayList();\n        try (PreparedStatement sql = conn.prepareStatement(SQL_SELECT_ALL)) {\n          sql.setString(1, catalogName);\n          sql.setString(2, JdbcUtil.namespaceToString(namespace));\n\n          ResultSet rs = sql.executeQuery();\n          while (rs.next()) {\n            results.add(JdbcUtil.stringToTableIdentifier(rs.getString(\"table_namespace\"), rs.getString(\"table_name\")));\n          }\n\n          return results;\n        }\n      });\n\n    } catch (SQLException e) {\n      throw new UncheckedSQLException(String.format(\"Failed to list tables in namespace: %s\", namespace), e);\n    } catch (InterruptedException e) {\n      Thread.currentThread().interrupt();\n      throw new RuntimeException(\"Interrupted during JDBC operation\", e);\n    }\n  }\nI've also separated out the InterruptedException and handled it just like in HiveCatalog. I think that should be done in all cases here as well.", "author": "rdblue", "createdAt": "2020-12-29T01:14:20Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,391 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.Connection;\n+import java.sql.DataTruncation;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.UncheckedSQLException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String SQL_TABLE_NAME = \"iceberg_tables\";\n+  public static final String SQL_TABLE_DDL =\n+          \"CREATE TABLE \" + SQL_TABLE_NAME +\n+                  \"(catalog_name VARCHAR(1255) NOT NULL,\" +\n+                  \"table_namespace VARCHAR(1255) NOT NULL,\" +\n+                  \"table_name VARCHAR(1255) NOT NULL,\" +\n+                  \"metadata_location VARCHAR(32768),\" +\n+                  \"previous_metadata_location VARCHAR(32768),\" +\n+                  \"PRIMARY KEY (catalog_name, table_namespace, table_name)\" +\n+                  \")\";\n+  public static final String SQL_SELECT_TABLE = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_ALL = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ?\";\n+  public static final String SQL_UPDATE_TABLE_NAME = \"UPDATE \" + SQL_TABLE_NAME +\n+          \" SET table_namespace = ? , table_name = ? \" +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_DELETE_TABLE = \"DELETE FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_NAMESPACE = \"SELECT table_namespace FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace LIKE ? LIMIT 1\";\n+  public static final String SQL_SELECT_NAMESPACES = \"SELECT DISTINCT table_namespace FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace LIKE ?\";\n+  public static final String JDBC_PARAM_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO fileIO;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration hadoopConf;\n+  private JdbcClientPool dbConnPool;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @SuppressWarnings(\"checkstyle:HiddenField\")\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.HIVE_URI, \"\").isEmpty(),\n+            \"No connection url provided for jdbc catalog!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.WAREHOUSE_LOCATION, \"\").isEmpty(),\n+            \"Cannot initialize Jdbc Catalog because warehousePath must not be null!\");\n+\n+    this.warehouseLocation = properties.get(CatalogProperties.WAREHOUSE_LOCATION).replaceAll(\"/$\", \"\");\n+    this.catalogName = name == null ? \"jdbc\" : name;\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ?\n+            new HadoopFileIO(hadoopConf) :\n+            CatalogUtil.loadFileIO(fileIOImpl, properties, hadoopConf);\n+    initializeConnection(properties);\n+  }\n+\n+  private void initializeConnection(Map<String, String> properties) {\n+    try {\n+      LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.HIVE_URI));\n+      Properties dbProps = new Properties();\n+      for (Map.Entry<String, String> prop : properties.entrySet()) {\n+        if (prop.getKey().startsWith(JDBC_PARAM_PREFIX)) {\n+          dbProps.put(prop.getKey().substring(JDBC_PARAM_PREFIX.length()), prop.getValue());\n+        }\n+      }\n+      dbConnPool = new JdbcClientPool(properties.get(CatalogProperties.HIVE_URI), dbProps);\n+      initializeCatalogTables();\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(\"Database Connection timeout!\", e);\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(\"Database Connection failed!\", e);\n+    } catch (SQLWarning e) {\n+      throw new UncheckedSQLException(\"Database connection warning!\", e);\n+    } catch (SQLException | InterruptedException e) {\n+      throw new UncheckedSQLException(\"Failed to initialize Jdbc Catalog!\", e);\n+    }\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    // need to check multiple times because some databases are using different naming standard. ex: H2db keeping\n+    // table names as uppercase\n+    boolean exists = false;\n+    DatabaseMetaData dbMeta = dbConnPool.run(Connection::getMetaData);\n+    ResultSet tables = dbMeta.getTables(null, null, SQL_TABLE_NAME, null);\n+    if (tables.next()) {\n+      exists = true;\n+    }\n+    tables.close();\n+    ResultSet tablesUpper = dbMeta.getTables(null, null, SQL_TABLE_NAME.toUpperCase(), null);\n+    if (tablesUpper.next()) {\n+      exists = true;\n+    }\n+    tablesUpper.close();\n+    ResultSet tablesLower = dbMeta.getTables(null, null, SQL_TABLE_NAME.toLowerCase(), null);\n+    if (tablesLower.next()) {\n+      exists = true;\n+    }\n+    tablesLower.close();\n+\n+    // create table if not exits\n+    if (!exists) {\n+      dbConnPool.run(conn -> conn.prepareStatement(SQL_TABLE_DDL).execute());\n+      LOG.debug(\"Created table {} to store iceberg tables!\", SQL_TABLE_NAME);\n+    }\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    return new JdbcTableOperations(dbConnPool, fileIO, catalogName, tableIdentifier);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().levels(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata = ops.current();\n+    try {\n+      PreparedStatement sql = dbConnPool.run(c -> c.prepareStatement(SQL_DELETE_TABLE));\n+      sql.setString(1, catalogName);\n+      sql.setString(2, JdbcUtil.namespaceToString(identifier.namespace()));\n+      sql.setString(3, identifier.name());\n+      int deletedRecords = sql.executeUpdate();\n+\n+      if (deletedRecords > 0) {\n+        LOG.debug(\"Successfully dropped table {}.\", identifier);\n+      } else {\n+        throw new NoSuchTableException(\"Cannot drop table %s! table not found in the catalog.\", identifier);\n+      }\n+\n+      if (purge && lastMetadata != null) {\n+        CatalogUtil.dropTableData(ops.io(), lastMetadata);\n+        LOG.info(\"Table {} data purged!\", identifier);\n+      }\n+      return true;\n+    } catch (SQLException | InterruptedException e) {\n+      throw new UncheckedSQLException(\"Failed to drop table!\", e);\n+    }\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    if (!this.namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Namespace %s does not exist!\", namespace);\n+    }\n+    try {\n+      List<TableIdentifier> results = Lists.newArrayList();\n+      PreparedStatement sql = dbConnPool.run(c -> c.prepareStatement(SQL_SELECT_ALL));", "originalCommit": "e6f8c6e36d78a79c8a8561292c2fa07f7e7f480a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQ4MTQ3MQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r550481471", "bodyText": "thank you for the example and tip applied it to all cases", "author": "ismailsimsek", "createdAt": "2020-12-31T13:17:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUzNDI4MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUzNDc3Ng==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r549534776", "bodyText": "This case should return false, not throw an exception. That's the contract of the method specified in Javadoc.", "author": "rdblue", "createdAt": "2020-12-29T01:17:07Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,391 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.Connection;\n+import java.sql.DataTruncation;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.UncheckedSQLException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String SQL_TABLE_NAME = \"iceberg_tables\";\n+  public static final String SQL_TABLE_DDL =\n+          \"CREATE TABLE \" + SQL_TABLE_NAME +\n+                  \"(catalog_name VARCHAR(1255) NOT NULL,\" +\n+                  \"table_namespace VARCHAR(1255) NOT NULL,\" +\n+                  \"table_name VARCHAR(1255) NOT NULL,\" +\n+                  \"metadata_location VARCHAR(32768),\" +\n+                  \"previous_metadata_location VARCHAR(32768),\" +\n+                  \"PRIMARY KEY (catalog_name, table_namespace, table_name)\" +\n+                  \")\";\n+  public static final String SQL_SELECT_TABLE = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_ALL = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ?\";\n+  public static final String SQL_UPDATE_TABLE_NAME = \"UPDATE \" + SQL_TABLE_NAME +\n+          \" SET table_namespace = ? , table_name = ? \" +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_DELETE_TABLE = \"DELETE FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_NAMESPACE = \"SELECT table_namespace FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace LIKE ? LIMIT 1\";\n+  public static final String SQL_SELECT_NAMESPACES = \"SELECT DISTINCT table_namespace FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace LIKE ?\";\n+  public static final String JDBC_PARAM_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO fileIO;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration hadoopConf;\n+  private JdbcClientPool dbConnPool;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @SuppressWarnings(\"checkstyle:HiddenField\")\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.HIVE_URI, \"\").isEmpty(),\n+            \"No connection url provided for jdbc catalog!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.WAREHOUSE_LOCATION, \"\").isEmpty(),\n+            \"Cannot initialize Jdbc Catalog because warehousePath must not be null!\");\n+\n+    this.warehouseLocation = properties.get(CatalogProperties.WAREHOUSE_LOCATION).replaceAll(\"/$\", \"\");\n+    this.catalogName = name == null ? \"jdbc\" : name;\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ?\n+            new HadoopFileIO(hadoopConf) :\n+            CatalogUtil.loadFileIO(fileIOImpl, properties, hadoopConf);\n+    initializeConnection(properties);\n+  }\n+\n+  private void initializeConnection(Map<String, String> properties) {\n+    try {\n+      LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.HIVE_URI));\n+      Properties dbProps = new Properties();\n+      for (Map.Entry<String, String> prop : properties.entrySet()) {\n+        if (prop.getKey().startsWith(JDBC_PARAM_PREFIX)) {\n+          dbProps.put(prop.getKey().substring(JDBC_PARAM_PREFIX.length()), prop.getValue());\n+        }\n+      }\n+      dbConnPool = new JdbcClientPool(properties.get(CatalogProperties.HIVE_URI), dbProps);\n+      initializeCatalogTables();\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(\"Database Connection timeout!\", e);\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(\"Database Connection failed!\", e);\n+    } catch (SQLWarning e) {\n+      throw new UncheckedSQLException(\"Database connection warning!\", e);\n+    } catch (SQLException | InterruptedException e) {\n+      throw new UncheckedSQLException(\"Failed to initialize Jdbc Catalog!\", e);\n+    }\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    // need to check multiple times because some databases are using different naming standard. ex: H2db keeping\n+    // table names as uppercase\n+    boolean exists = false;\n+    DatabaseMetaData dbMeta = dbConnPool.run(Connection::getMetaData);\n+    ResultSet tables = dbMeta.getTables(null, null, SQL_TABLE_NAME, null);\n+    if (tables.next()) {\n+      exists = true;\n+    }\n+    tables.close();\n+    ResultSet tablesUpper = dbMeta.getTables(null, null, SQL_TABLE_NAME.toUpperCase(), null);\n+    if (tablesUpper.next()) {\n+      exists = true;\n+    }\n+    tablesUpper.close();\n+    ResultSet tablesLower = dbMeta.getTables(null, null, SQL_TABLE_NAME.toLowerCase(), null);\n+    if (tablesLower.next()) {\n+      exists = true;\n+    }\n+    tablesLower.close();\n+\n+    // create table if not exits\n+    if (!exists) {\n+      dbConnPool.run(conn -> conn.prepareStatement(SQL_TABLE_DDL).execute());\n+      LOG.debug(\"Created table {} to store iceberg tables!\", SQL_TABLE_NAME);\n+    }\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    return new JdbcTableOperations(dbConnPool, fileIO, catalogName, tableIdentifier);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().levels(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata = ops.current();\n+    try {\n+      PreparedStatement sql = dbConnPool.run(c -> c.prepareStatement(SQL_DELETE_TABLE));\n+      sql.setString(1, catalogName);\n+      sql.setString(2, JdbcUtil.namespaceToString(identifier.namespace()));\n+      sql.setString(3, identifier.name());\n+      int deletedRecords = sql.executeUpdate();\n+\n+      if (deletedRecords > 0) {\n+        LOG.debug(\"Successfully dropped table {}.\", identifier);\n+      } else {\n+        throw new NoSuchTableException(\"Cannot drop table %s! table not found in the catalog.\", identifier);", "originalCommit": "e6f8c6e36d78a79c8a8561292c2fa07f7e7f480a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUzNDg1NQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r549534855", "bodyText": "Other places use Namespace does not exist: %s", "author": "rdblue", "createdAt": "2020-12-29T01:17:47Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,391 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.Connection;\n+import java.sql.DataTruncation;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.UncheckedSQLException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String SQL_TABLE_NAME = \"iceberg_tables\";\n+  public static final String SQL_TABLE_DDL =\n+          \"CREATE TABLE \" + SQL_TABLE_NAME +\n+                  \"(catalog_name VARCHAR(1255) NOT NULL,\" +\n+                  \"table_namespace VARCHAR(1255) NOT NULL,\" +\n+                  \"table_name VARCHAR(1255) NOT NULL,\" +\n+                  \"metadata_location VARCHAR(32768),\" +\n+                  \"previous_metadata_location VARCHAR(32768),\" +\n+                  \"PRIMARY KEY (catalog_name, table_namespace, table_name)\" +\n+                  \")\";\n+  public static final String SQL_SELECT_TABLE = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_ALL = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ?\";\n+  public static final String SQL_UPDATE_TABLE_NAME = \"UPDATE \" + SQL_TABLE_NAME +\n+          \" SET table_namespace = ? , table_name = ? \" +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_DELETE_TABLE = \"DELETE FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_NAMESPACE = \"SELECT table_namespace FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace LIKE ? LIMIT 1\";\n+  public static final String SQL_SELECT_NAMESPACES = \"SELECT DISTINCT table_namespace FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace LIKE ?\";\n+  public static final String JDBC_PARAM_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO fileIO;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration hadoopConf;\n+  private JdbcClientPool dbConnPool;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @SuppressWarnings(\"checkstyle:HiddenField\")\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.HIVE_URI, \"\").isEmpty(),\n+            \"No connection url provided for jdbc catalog!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.WAREHOUSE_LOCATION, \"\").isEmpty(),\n+            \"Cannot initialize Jdbc Catalog because warehousePath must not be null!\");\n+\n+    this.warehouseLocation = properties.get(CatalogProperties.WAREHOUSE_LOCATION).replaceAll(\"/$\", \"\");\n+    this.catalogName = name == null ? \"jdbc\" : name;\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ?\n+            new HadoopFileIO(hadoopConf) :\n+            CatalogUtil.loadFileIO(fileIOImpl, properties, hadoopConf);\n+    initializeConnection(properties);\n+  }\n+\n+  private void initializeConnection(Map<String, String> properties) {\n+    try {\n+      LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.HIVE_URI));\n+      Properties dbProps = new Properties();\n+      for (Map.Entry<String, String> prop : properties.entrySet()) {\n+        if (prop.getKey().startsWith(JDBC_PARAM_PREFIX)) {\n+          dbProps.put(prop.getKey().substring(JDBC_PARAM_PREFIX.length()), prop.getValue());\n+        }\n+      }\n+      dbConnPool = new JdbcClientPool(properties.get(CatalogProperties.HIVE_URI), dbProps);\n+      initializeCatalogTables();\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(\"Database Connection timeout!\", e);\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(\"Database Connection failed!\", e);\n+    } catch (SQLWarning e) {\n+      throw new UncheckedSQLException(\"Database connection warning!\", e);\n+    } catch (SQLException | InterruptedException e) {\n+      throw new UncheckedSQLException(\"Failed to initialize Jdbc Catalog!\", e);\n+    }\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    // need to check multiple times because some databases are using different naming standard. ex: H2db keeping\n+    // table names as uppercase\n+    boolean exists = false;\n+    DatabaseMetaData dbMeta = dbConnPool.run(Connection::getMetaData);\n+    ResultSet tables = dbMeta.getTables(null, null, SQL_TABLE_NAME, null);\n+    if (tables.next()) {\n+      exists = true;\n+    }\n+    tables.close();\n+    ResultSet tablesUpper = dbMeta.getTables(null, null, SQL_TABLE_NAME.toUpperCase(), null);\n+    if (tablesUpper.next()) {\n+      exists = true;\n+    }\n+    tablesUpper.close();\n+    ResultSet tablesLower = dbMeta.getTables(null, null, SQL_TABLE_NAME.toLowerCase(), null);\n+    if (tablesLower.next()) {\n+      exists = true;\n+    }\n+    tablesLower.close();\n+\n+    // create table if not exits\n+    if (!exists) {\n+      dbConnPool.run(conn -> conn.prepareStatement(SQL_TABLE_DDL).execute());\n+      LOG.debug(\"Created table {} to store iceberg tables!\", SQL_TABLE_NAME);\n+    }\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    return new JdbcTableOperations(dbConnPool, fileIO, catalogName, tableIdentifier);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().levels(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata = ops.current();\n+    try {\n+      PreparedStatement sql = dbConnPool.run(c -> c.prepareStatement(SQL_DELETE_TABLE));\n+      sql.setString(1, catalogName);\n+      sql.setString(2, JdbcUtil.namespaceToString(identifier.namespace()));\n+      sql.setString(3, identifier.name());\n+      int deletedRecords = sql.executeUpdate();\n+\n+      if (deletedRecords > 0) {\n+        LOG.debug(\"Successfully dropped table {}.\", identifier);\n+      } else {\n+        throw new NoSuchTableException(\"Cannot drop table %s! table not found in the catalog.\", identifier);\n+      }\n+\n+      if (purge && lastMetadata != null) {\n+        CatalogUtil.dropTableData(ops.io(), lastMetadata);\n+        LOG.info(\"Table {} data purged!\", identifier);\n+      }\n+      return true;\n+    } catch (SQLException | InterruptedException e) {\n+      throw new UncheckedSQLException(\"Failed to drop table!\", e);\n+    }\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    if (!this.namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Namespace %s does not exist!\", namespace);", "originalCommit": "e6f8c6e36d78a79c8a8561292c2fa07f7e7f480a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUzNDk4Ng==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r549534986", "bodyText": "Can you name these SQL statements for the methods that they are used in? For example, LOAD_TABLE_SQL, RENAME_TABLE_SQL, etc.", "author": "rdblue", "createdAt": "2020-12-29T01:18:44Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,391 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.Connection;\n+import java.sql.DataTruncation;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.UncheckedSQLException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String SQL_TABLE_NAME = \"iceberg_tables\";\n+  public static final String SQL_TABLE_DDL =\n+          \"CREATE TABLE \" + SQL_TABLE_NAME +\n+                  \"(catalog_name VARCHAR(1255) NOT NULL,\" +\n+                  \"table_namespace VARCHAR(1255) NOT NULL,\" +\n+                  \"table_name VARCHAR(1255) NOT NULL,\" +\n+                  \"metadata_location VARCHAR(32768),\" +\n+                  \"previous_metadata_location VARCHAR(32768),\" +\n+                  \"PRIMARY KEY (catalog_name, table_namespace, table_name)\" +\n+                  \")\";\n+  public static final String SQL_SELECT_TABLE = \"SELECT * FROM \" + SQL_TABLE_NAME +", "originalCommit": "e6f8c6e36d78a79c8a8561292c2fa07f7e7f480a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUzNTM4OA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r549535388", "bodyText": "Shouldn't this use SLASH for the path instead?", "author": "rdblue", "createdAt": "2020-12-29T01:21:25Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,391 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.Connection;\n+import java.sql.DataTruncation;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.UncheckedSQLException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String SQL_TABLE_NAME = \"iceberg_tables\";\n+  public static final String SQL_TABLE_DDL =\n+          \"CREATE TABLE \" + SQL_TABLE_NAME +\n+                  \"(catalog_name VARCHAR(1255) NOT NULL,\" +\n+                  \"table_namespace VARCHAR(1255) NOT NULL,\" +\n+                  \"table_name VARCHAR(1255) NOT NULL,\" +\n+                  \"metadata_location VARCHAR(32768),\" +\n+                  \"previous_metadata_location VARCHAR(32768),\" +\n+                  \"PRIMARY KEY (catalog_name, table_namespace, table_name)\" +\n+                  \")\";\n+  public static final String SQL_SELECT_TABLE = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_ALL = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ?\";\n+  public static final String SQL_UPDATE_TABLE_NAME = \"UPDATE \" + SQL_TABLE_NAME +\n+          \" SET table_namespace = ? , table_name = ? \" +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_DELETE_TABLE = \"DELETE FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_NAMESPACE = \"SELECT table_namespace FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace LIKE ? LIMIT 1\";\n+  public static final String SQL_SELECT_NAMESPACES = \"SELECT DISTINCT table_namespace FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace LIKE ?\";\n+  public static final String JDBC_PARAM_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO fileIO;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration hadoopConf;\n+  private JdbcClientPool dbConnPool;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @SuppressWarnings(\"checkstyle:HiddenField\")\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.HIVE_URI, \"\").isEmpty(),\n+            \"No connection url provided for jdbc catalog!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.WAREHOUSE_LOCATION, \"\").isEmpty(),\n+            \"Cannot initialize Jdbc Catalog because warehousePath must not be null!\");\n+\n+    this.warehouseLocation = properties.get(CatalogProperties.WAREHOUSE_LOCATION).replaceAll(\"/$\", \"\");\n+    this.catalogName = name == null ? \"jdbc\" : name;\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ?\n+            new HadoopFileIO(hadoopConf) :\n+            CatalogUtil.loadFileIO(fileIOImpl, properties, hadoopConf);\n+    initializeConnection(properties);\n+  }\n+\n+  private void initializeConnection(Map<String, String> properties) {\n+    try {\n+      LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.HIVE_URI));\n+      Properties dbProps = new Properties();\n+      for (Map.Entry<String, String> prop : properties.entrySet()) {\n+        if (prop.getKey().startsWith(JDBC_PARAM_PREFIX)) {\n+          dbProps.put(prop.getKey().substring(JDBC_PARAM_PREFIX.length()), prop.getValue());\n+        }\n+      }\n+      dbConnPool = new JdbcClientPool(properties.get(CatalogProperties.HIVE_URI), dbProps);\n+      initializeCatalogTables();\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(\"Database Connection timeout!\", e);\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(\"Database Connection failed!\", e);\n+    } catch (SQLWarning e) {\n+      throw new UncheckedSQLException(\"Database connection warning!\", e);\n+    } catch (SQLException | InterruptedException e) {\n+      throw new UncheckedSQLException(\"Failed to initialize Jdbc Catalog!\", e);\n+    }\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    // need to check multiple times because some databases are using different naming standard. ex: H2db keeping\n+    // table names as uppercase\n+    boolean exists = false;\n+    DatabaseMetaData dbMeta = dbConnPool.run(Connection::getMetaData);\n+    ResultSet tables = dbMeta.getTables(null, null, SQL_TABLE_NAME, null);\n+    if (tables.next()) {\n+      exists = true;\n+    }\n+    tables.close();\n+    ResultSet tablesUpper = dbMeta.getTables(null, null, SQL_TABLE_NAME.toUpperCase(), null);\n+    if (tablesUpper.next()) {\n+      exists = true;\n+    }\n+    tablesUpper.close();\n+    ResultSet tablesLower = dbMeta.getTables(null, null, SQL_TABLE_NAME.toLowerCase(), null);\n+    if (tablesLower.next()) {\n+      exists = true;\n+    }\n+    tablesLower.close();\n+\n+    // create table if not exits\n+    if (!exists) {\n+      dbConnPool.run(conn -> conn.prepareStatement(SQL_TABLE_DDL).execute());\n+      LOG.debug(\"Created table {} to store iceberg tables!\", SQL_TABLE_NAME);\n+    }\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    return new JdbcTableOperations(dbConnPool, fileIO, catalogName, tableIdentifier);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().levels(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata = ops.current();\n+    try {\n+      PreparedStatement sql = dbConnPool.run(c -> c.prepareStatement(SQL_DELETE_TABLE));\n+      sql.setString(1, catalogName);\n+      sql.setString(2, JdbcUtil.namespaceToString(identifier.namespace()));\n+      sql.setString(3, identifier.name());\n+      int deletedRecords = sql.executeUpdate();\n+\n+      if (deletedRecords > 0) {\n+        LOG.debug(\"Successfully dropped table {}.\", identifier);\n+      } else {\n+        throw new NoSuchTableException(\"Cannot drop table %s! table not found in the catalog.\", identifier);\n+      }\n+\n+      if (purge && lastMetadata != null) {\n+        CatalogUtil.dropTableData(ops.io(), lastMetadata);\n+        LOG.info(\"Table {} data purged!\", identifier);\n+      }\n+      return true;\n+    } catch (SQLException | InterruptedException e) {\n+      throw new UncheckedSQLException(\"Failed to drop table!\", e);\n+    }\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    if (!this.namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Namespace %s does not exist!\", namespace);\n+    }\n+    try {\n+      List<TableIdentifier> results = Lists.newArrayList();\n+      PreparedStatement sql = dbConnPool.run(c -> c.prepareStatement(SQL_SELECT_ALL));\n+      sql.setString(1, catalogName);\n+      sql.setString(2, JdbcUtil.namespaceToString(namespace));\n+      ResultSet rs = sql.executeQuery();\n+\n+      while (rs.next()) {\n+        final TableIdentifier table = JdbcUtil.stringToTableIdentifier(\n+                rs.getString(\"table_namespace\"), rs.getString(\"table_name\"));\n+        results.add(table);\n+      }\n+      rs.close();\n+      return results;\n+\n+    } catch (SQLException | InterruptedException e) {\n+      LOG.error(\"Failed to list tables!\", e);\n+      return null;\n+    }\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier to) {\n+    try {\n+      PreparedStatement sql = dbConnPool.run(c -> c.prepareStatement(SQL_UPDATE_TABLE_NAME));\n+      // SET\n+      sql.setString(1, JdbcUtil.namespaceToString(to.namespace()));\n+      sql.setString(2, to.name());\n+      // WHERE\n+      sql.setString(3, catalogName);\n+      sql.setString(4, JdbcUtil.namespaceToString(from.namespace()));\n+      sql.setString(5, from.name());\n+      int updatedRecords = sql.executeUpdate();\n+\n+      if (updatedRecords == 1) {\n+        LOG.debug(\"Successfully renamed table from {} to {}!\", from, to);\n+      } else if (updatedRecords == 0) {\n+        throw new NoSuchTableException(\"Failed to rename table! Table '%s' not found in the catalog!\", from);\n+      } else {\n+        throw new UncheckedSQLException(\"Failed to rename table! Rename operation Failed\");\n+      }\n+    } catch (SQLIntegrityConstraintViolationException e) {\n+      throw new AlreadyExistsException(\"Table with name '%s' already exists in the catalog!\", to);\n+    } catch (DataTruncation e) {\n+      throw new UncheckedSQLException(\"Database data truncation error!\", e);\n+    } catch (SQLWarning e) {\n+      throw new UncheckedSQLException(\"Database warning!\", e);\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(\"Failed to rename table!\", e);\n+    } catch (InterruptedException e) {\n+      throw new UncheckedSQLException(\"Database Connection interrupted!\", e);\n+    }\n+  }\n+\n+  @Override\n+  public String name() {\n+    return catalogName;\n+  }\n+\n+  @Override\n+  public Configuration getConf() {\n+    return this.hadoopConf;\n+  }\n+\n+  @Override\n+  public void setConf(Configuration conf) {\n+    this.hadoopConf = conf;\n+  }\n+\n+  @Override\n+  public void createNamespace(Namespace namespace, Map<String, String> metadata) {\n+    throw new UnsupportedOperationException(\"Cannot create namespace \" + namespace +\n+            \": createNamespace is not supported\");\n+  }\n+\n+  @Override\n+  public List<Namespace> listNamespaces(Namespace namespace) throws NoSuchNamespaceException {\n+    if (!this.namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Namespace does not exist %s\", namespace);\n+    }\n+    try {\n+      List<Namespace> namespaces = Lists.newArrayList();\n+      PreparedStatement sql = dbConnPool.run(c -> c.prepareStatement(SQL_SELECT_NAMESPACES));\n+      sql.setString(1, catalogName);\n+      if (namespace.isEmpty()) {\n+        sql.setString(2, JdbcUtil.namespaceToString(namespace) + \"%\");\n+      } else {\n+        sql.setString(2, JdbcUtil.namespaceToString(namespace) + \".%\");\n+      }\n+      ResultSet rs = sql.executeQuery();\n+      while (rs.next()) {\n+        rs.getString(\"table_namespace\");\n+        namespaces.add(JdbcUtil.stringToNamespace(rs.getString(\"table_namespace\")));\n+      }\n+      rs.close();\n+      int subNamespaceLevelLength = namespace.levels().length + 1;\n+      namespaces = namespaces.stream()\n+              // exclude itself\n+              .filter(n -> !n.equals(namespace))\n+              // only get sub namespaces/children\n+              .map(n -> Namespace.of(\n+                      Arrays.stream(n.levels()).limit(subNamespaceLevelLength).toArray(String[]::new)\n+                      )\n+              )\n+              // remove duplicates\n+              .distinct()\n+              .collect(Collectors.toList());\n+\n+      LOG.debug(\"From the namespace '{}' found: {}\", namespace, namespaces);\n+      return namespaces;\n+    } catch (Exception e) {\n+      LOG.error(\"Failed to list namespace!\", e);\n+      return null;\n+    }\n+  }\n+\n+  @Override\n+  public Map<String, String> loadNamespaceMetadata(Namespace namespace) throws NoSuchNamespaceException {\n+    Path nsPath = new Path(warehouseLocation, JdbcUtil.JOINER_DOT.join(namespace.levels()));", "originalCommit": "e6f8c6e36d78a79c8a8561292c2fa07f7e7f480a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUzNTQ3Ng==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r549535476", "bodyText": "Missing @Override.", "author": "rdblue", "createdAt": "2020-12-29T01:21:59Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,391 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.Connection;\n+import java.sql.DataTruncation;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.UncheckedSQLException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String SQL_TABLE_NAME = \"iceberg_tables\";\n+  public static final String SQL_TABLE_DDL =\n+          \"CREATE TABLE \" + SQL_TABLE_NAME +\n+                  \"(catalog_name VARCHAR(1255) NOT NULL,\" +\n+                  \"table_namespace VARCHAR(1255) NOT NULL,\" +\n+                  \"table_name VARCHAR(1255) NOT NULL,\" +\n+                  \"metadata_location VARCHAR(32768),\" +\n+                  \"previous_metadata_location VARCHAR(32768),\" +\n+                  \"PRIMARY KEY (catalog_name, table_namespace, table_name)\" +\n+                  \")\";\n+  public static final String SQL_SELECT_TABLE = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_ALL = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ?\";\n+  public static final String SQL_UPDATE_TABLE_NAME = \"UPDATE \" + SQL_TABLE_NAME +\n+          \" SET table_namespace = ? , table_name = ? \" +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_DELETE_TABLE = \"DELETE FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String SQL_SELECT_NAMESPACE = \"SELECT table_namespace FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace LIKE ? LIMIT 1\";\n+  public static final String SQL_SELECT_NAMESPACES = \"SELECT DISTINCT table_namespace FROM \" + SQL_TABLE_NAME +\n+          \" WHERE catalog_name = ? AND table_namespace LIKE ?\";\n+  public static final String JDBC_PARAM_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO fileIO;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration hadoopConf;\n+  private JdbcClientPool dbConnPool;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @SuppressWarnings(\"checkstyle:HiddenField\")\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.HIVE_URI, \"\").isEmpty(),\n+            \"No connection url provided for jdbc catalog!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.WAREHOUSE_LOCATION, \"\").isEmpty(),\n+            \"Cannot initialize Jdbc Catalog because warehousePath must not be null!\");\n+\n+    this.warehouseLocation = properties.get(CatalogProperties.WAREHOUSE_LOCATION).replaceAll(\"/$\", \"\");\n+    this.catalogName = name == null ? \"jdbc\" : name;\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ?\n+            new HadoopFileIO(hadoopConf) :\n+            CatalogUtil.loadFileIO(fileIOImpl, properties, hadoopConf);\n+    initializeConnection(properties);\n+  }\n+\n+  private void initializeConnection(Map<String, String> properties) {\n+    try {\n+      LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.HIVE_URI));\n+      Properties dbProps = new Properties();\n+      for (Map.Entry<String, String> prop : properties.entrySet()) {\n+        if (prop.getKey().startsWith(JDBC_PARAM_PREFIX)) {\n+          dbProps.put(prop.getKey().substring(JDBC_PARAM_PREFIX.length()), prop.getValue());\n+        }\n+      }\n+      dbConnPool = new JdbcClientPool(properties.get(CatalogProperties.HIVE_URI), dbProps);\n+      initializeCatalogTables();\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(\"Database Connection timeout!\", e);\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(\"Database Connection failed!\", e);\n+    } catch (SQLWarning e) {\n+      throw new UncheckedSQLException(\"Database connection warning!\", e);\n+    } catch (SQLException | InterruptedException e) {\n+      throw new UncheckedSQLException(\"Failed to initialize Jdbc Catalog!\", e);\n+    }\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    // need to check multiple times because some databases are using different naming standard. ex: H2db keeping\n+    // table names as uppercase\n+    boolean exists = false;\n+    DatabaseMetaData dbMeta = dbConnPool.run(Connection::getMetaData);\n+    ResultSet tables = dbMeta.getTables(null, null, SQL_TABLE_NAME, null);\n+    if (tables.next()) {\n+      exists = true;\n+    }\n+    tables.close();\n+    ResultSet tablesUpper = dbMeta.getTables(null, null, SQL_TABLE_NAME.toUpperCase(), null);\n+    if (tablesUpper.next()) {\n+      exists = true;\n+    }\n+    tablesUpper.close();\n+    ResultSet tablesLower = dbMeta.getTables(null, null, SQL_TABLE_NAME.toLowerCase(), null);\n+    if (tablesLower.next()) {\n+      exists = true;\n+    }\n+    tablesLower.close();\n+\n+    // create table if not exits\n+    if (!exists) {\n+      dbConnPool.run(conn -> conn.prepareStatement(SQL_TABLE_DDL).execute());\n+      LOG.debug(\"Created table {} to store iceberg tables!\", SQL_TABLE_NAME);\n+    }\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    return new JdbcTableOperations(dbConnPool, fileIO, catalogName, tableIdentifier);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().levels(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata = ops.current();\n+    try {\n+      PreparedStatement sql = dbConnPool.run(c -> c.prepareStatement(SQL_DELETE_TABLE));\n+      sql.setString(1, catalogName);\n+      sql.setString(2, JdbcUtil.namespaceToString(identifier.namespace()));\n+      sql.setString(3, identifier.name());\n+      int deletedRecords = sql.executeUpdate();\n+\n+      if (deletedRecords > 0) {\n+        LOG.debug(\"Successfully dropped table {}.\", identifier);\n+      } else {\n+        throw new NoSuchTableException(\"Cannot drop table %s! table not found in the catalog.\", identifier);\n+      }\n+\n+      if (purge && lastMetadata != null) {\n+        CatalogUtil.dropTableData(ops.io(), lastMetadata);\n+        LOG.info(\"Table {} data purged!\", identifier);\n+      }\n+      return true;\n+    } catch (SQLException | InterruptedException e) {\n+      throw new UncheckedSQLException(\"Failed to drop table!\", e);\n+    }\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    if (!this.namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Namespace %s does not exist!\", namespace);\n+    }\n+    try {\n+      List<TableIdentifier> results = Lists.newArrayList();\n+      PreparedStatement sql = dbConnPool.run(c -> c.prepareStatement(SQL_SELECT_ALL));\n+      sql.setString(1, catalogName);\n+      sql.setString(2, JdbcUtil.namespaceToString(namespace));\n+      ResultSet rs = sql.executeQuery();\n+\n+      while (rs.next()) {\n+        final TableIdentifier table = JdbcUtil.stringToTableIdentifier(\n+                rs.getString(\"table_namespace\"), rs.getString(\"table_name\"));\n+        results.add(table);\n+      }\n+      rs.close();\n+      return results;\n+\n+    } catch (SQLException | InterruptedException e) {\n+      LOG.error(\"Failed to list tables!\", e);\n+      return null;\n+    }\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier to) {\n+    try {\n+      PreparedStatement sql = dbConnPool.run(c -> c.prepareStatement(SQL_UPDATE_TABLE_NAME));\n+      // SET\n+      sql.setString(1, JdbcUtil.namespaceToString(to.namespace()));\n+      sql.setString(2, to.name());\n+      // WHERE\n+      sql.setString(3, catalogName);\n+      sql.setString(4, JdbcUtil.namespaceToString(from.namespace()));\n+      sql.setString(5, from.name());\n+      int updatedRecords = sql.executeUpdate();\n+\n+      if (updatedRecords == 1) {\n+        LOG.debug(\"Successfully renamed table from {} to {}!\", from, to);\n+      } else if (updatedRecords == 0) {\n+        throw new NoSuchTableException(\"Failed to rename table! Table '%s' not found in the catalog!\", from);\n+      } else {\n+        throw new UncheckedSQLException(\"Failed to rename table! Rename operation Failed\");\n+      }\n+    } catch (SQLIntegrityConstraintViolationException e) {\n+      throw new AlreadyExistsException(\"Table with name '%s' already exists in the catalog!\", to);\n+    } catch (DataTruncation e) {\n+      throw new UncheckedSQLException(\"Database data truncation error!\", e);\n+    } catch (SQLWarning e) {\n+      throw new UncheckedSQLException(\"Database warning!\", e);\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(\"Failed to rename table!\", e);\n+    } catch (InterruptedException e) {\n+      throw new UncheckedSQLException(\"Database Connection interrupted!\", e);\n+    }\n+  }\n+\n+  @Override\n+  public String name() {\n+    return catalogName;\n+  }\n+\n+  @Override\n+  public Configuration getConf() {\n+    return this.hadoopConf;\n+  }\n+\n+  @Override\n+  public void setConf(Configuration conf) {\n+    this.hadoopConf = conf;\n+  }\n+\n+  @Override\n+  public void createNamespace(Namespace namespace, Map<String, String> metadata) {\n+    throw new UnsupportedOperationException(\"Cannot create namespace \" + namespace +\n+            \": createNamespace is not supported\");\n+  }\n+\n+  @Override\n+  public List<Namespace> listNamespaces(Namespace namespace) throws NoSuchNamespaceException {\n+    if (!this.namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Namespace does not exist %s\", namespace);\n+    }\n+    try {\n+      List<Namespace> namespaces = Lists.newArrayList();\n+      PreparedStatement sql = dbConnPool.run(c -> c.prepareStatement(SQL_SELECT_NAMESPACES));\n+      sql.setString(1, catalogName);\n+      if (namespace.isEmpty()) {\n+        sql.setString(2, JdbcUtil.namespaceToString(namespace) + \"%\");\n+      } else {\n+        sql.setString(2, JdbcUtil.namespaceToString(namespace) + \".%\");\n+      }\n+      ResultSet rs = sql.executeQuery();\n+      while (rs.next()) {\n+        rs.getString(\"table_namespace\");\n+        namespaces.add(JdbcUtil.stringToNamespace(rs.getString(\"table_namespace\")));\n+      }\n+      rs.close();\n+      int subNamespaceLevelLength = namespace.levels().length + 1;\n+      namespaces = namespaces.stream()\n+              // exclude itself\n+              .filter(n -> !n.equals(namespace))\n+              // only get sub namespaces/children\n+              .map(n -> Namespace.of(\n+                      Arrays.stream(n.levels()).limit(subNamespaceLevelLength).toArray(String[]::new)\n+                      )\n+              )\n+              // remove duplicates\n+              .distinct()\n+              .collect(Collectors.toList());\n+\n+      LOG.debug(\"From the namespace '{}' found: {}\", namespace, namespaces);\n+      return namespaces;\n+    } catch (Exception e) {\n+      LOG.error(\"Failed to list namespace!\", e);\n+      return null;\n+    }\n+  }\n+\n+  @Override\n+  public Map<String, String> loadNamespaceMetadata(Namespace namespace) throws NoSuchNamespaceException {\n+    Path nsPath = new Path(warehouseLocation, JdbcUtil.JOINER_DOT.join(namespace.levels()));\n+    if (!this.namespaceExists(namespace) || namespace.isEmpty()) {\n+      throw new NoSuchNamespaceException(\"Namespace does not exist: %s\", namespace);\n+    }\n+\n+    return ImmutableMap.of(\"location\", nsPath.toString());\n+  }\n+\n+  @Override\n+  public boolean dropNamespace(Namespace namespace) throws NamespaceNotEmptyException {\n+    if (!this.namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Cannot drop namespace %s because it is not found!\", namespace);\n+    }\n+\n+    List<TableIdentifier> tableIdentifiers = listTables(namespace);\n+    if (tableIdentifiers != null && !tableIdentifiers.isEmpty()) {\n+      throw new NamespaceNotEmptyException(\"Cannot drop namespace %s because it is not empty. \" +\n+              \"The following tables still exist under the namespace: %s\", namespace, tableIdentifiers);\n+    }\n+    // namespaces are created/deleted by tables by default return true\n+    return true;\n+  }\n+\n+  @Override\n+  public boolean setProperties(Namespace namespace, Map<String, String> properties) throws\n+          NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+            \"Cannot set properties \" + namespace + \" : setProperties is not supported\");\n+  }\n+\n+  @Override\n+  public boolean removeProperties(Namespace namespace, Set<String> properties) throws NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+            \"Cannot remove properties \" + namespace + \" : removeProperties is not supported\");\n+  }\n+\n+  @Override\n+  public void close() {\n+    this.dbConnPool.close();\n+  }\n+\n+  public boolean namespaceExists(Namespace namespace) {", "originalCommit": "e6f8c6e36d78a79c8a8561292c2fa07f7e7f480a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "bac375f6b7144abfe6839c0e64609afc7f812bac", "url": "https://github.com/apache/iceberg/commit/bac375f6b7144abfe6839c0e64609afc7f812bac", "message": "update spark3 catalog change", "committedDate": "2020-12-31T13:12:05Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTQyOTI1Nw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r551429257", "bodyText": "Shouldn't this refer to the JdbcCatalog class not HadoopCatalog?", "author": "massdosage", "createdAt": "2021-01-04T16:37:45Z", "path": "core/src/main/java/org/apache/iceberg/CatalogUtil.java", "diffHunk": "@@ -44,8 +44,10 @@\n   public static final String ICEBERG_CATALOG_TYPE = \"type\";\n   public static final String ICEBERG_CATALOG_TYPE_HADOOP = \"hadoop\";\n   public static final String ICEBERG_CATALOG_TYPE_HIVE = \"hive\";\n+  public static final String ICEBERG_CATALOG_TYPE_JDBC = \"jdbc\";\n   public static final String ICEBERG_CATALOG_HIVE = \"org.apache.iceberg.hive.HiveCatalog\";\n   public static final String ICEBERG_CATALOG_HADOOP = \"org.apache.iceberg.hadoop.HadoopCatalog\";\n+  public static final String ICEBERG_CATALOG_JDBC = \"org.apache.iceberg.hadoop.HadoopCatalog\";", "originalCommit": "bac375f6b7144abfe6839c0e64609afc7f812bac", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzQ2MDg0OA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r553460848", "bodyText": "corrected it", "author": "ismailsimsek", "createdAt": "2021-01-07T17:07:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTQyOTI1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Mjc5NDYxNg==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r552794616", "bodyText": "I am a bit confused, why we don't support creating namespace, but we have all the other namespace operations?\nLooks like the route we are going is to allow table creation with any namespace name, and simply collect namespace information by scanning the iceberg_tables table.\nI think we can do better, by having another iceberg_namesapce table. By doing that, we can also support storing and updating any namespace property. (I don't know if this is already discussed, I am still catching up with latest comments)", "author": "jackye1995", "createdAt": "2021-01-06T16:44:24Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,423 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.UncheckedSQLException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String SQL_TABLE_NAME = \"iceberg_tables\";\n+  public static final String SQL_CREATE_CATALOG_TABLE =\n+      \"CREATE TABLE \" + SQL_TABLE_NAME +\n+          \"(catalog_name VARCHAR(1255) NOT NULL,\" +\n+          \"table_namespace VARCHAR(1255) NOT NULL,\" +\n+          \"table_name VARCHAR(1255) NOT NULL,\" +\n+          \"metadata_location VARCHAR(32768),\" +\n+          \"previous_metadata_location VARCHAR(32768),\" +\n+          \"PRIMARY KEY (catalog_name, table_namespace, table_name)\" +\n+          \")\";\n+  public static final String LOAD_TABLE_SQL = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+      \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String LIST_TABLES_SQL = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+      \" WHERE catalog_name = ? AND table_namespace = ?\";\n+  public static final String RENAME_TABLE_SQL = \"UPDATE \" + SQL_TABLE_NAME +\n+      \" SET table_namespace = ? , table_name = ? \" +\n+      \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String DROP_TABLE_SQL = \"DELETE FROM \" + SQL_TABLE_NAME +\n+      \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String GET_NAMESPACE_SQL = \"SELECT table_namespace FROM \" + SQL_TABLE_NAME +\n+      \" WHERE catalog_name = ? AND table_namespace LIKE ? LIMIT 1\";\n+  public static final String LIST_NAMESPACES_SQL = \"SELECT DISTINCT table_namespace FROM \" + SQL_TABLE_NAME +\n+      \" WHERE catalog_name = ? AND table_namespace LIKE ?\";\n+  public static final String JDBC_PARAM_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.HIVE_URI, \"\").isEmpty(),\n+        \"No connection url provided for jdbc catalog!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.WAREHOUSE_LOCATION, \"\").isEmpty(),\n+        \"Cannot initialize Jdbc Catalog because warehousePath must not be null!\");\n+\n+    this.warehouseLocation = properties.get(CatalogProperties.WAREHOUSE_LOCATION).replaceAll(\"/$\", \"\");\n+    this.catalogName = name == null ? \"jdbc\" : name;\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.io = fileIOImpl == null ?\n+        new HadoopFileIO(conf) :\n+        CatalogUtil.loadFileIO(fileIOImpl, properties, conf);\n+\n+    try {\n+      initializeConnection(properties);\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(\"Database Connection timeout!\", e);\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(\"Database Connection failed!\", e);\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(\"Failed to initialize catalog!\", e);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to initialize!\", e);\n+    }\n+  }\n+\n+  private void initializeConnection(Map<String, String> properties) throws SQLException, InterruptedException {\n+    LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.HIVE_URI));\n+    connections = new JdbcClientPool(properties.get(CatalogProperties.HIVE_URI), properties);\n+    initializeCatalogTables();\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    // need to check multiple times because some databases are using different naming standard. ex: H2db keeping\n+    // table names as uppercase\n+\n+    boolean exists = connections.run(conn -> {\n+      boolean foundTable = false;\n+      DatabaseMetaData dbMeta = conn.getMetaData();\n+      ResultSet tables = dbMeta.getTables(null, null, SQL_TABLE_NAME, null);\n+      if (tables.next()) {\n+        foundTable = true;\n+      }\n+      tables.close();\n+      ResultSet tablesUpper = dbMeta.getTables(null, null, SQL_TABLE_NAME.toUpperCase(), null);\n+      if (tablesUpper.next()) {\n+        foundTable = true;\n+      }\n+      tablesUpper.close();\n+      ResultSet tablesLower = dbMeta.getTables(null, null, SQL_TABLE_NAME.toLowerCase(), null);\n+      if (tablesLower.next()) {\n+        foundTable = true;\n+      }\n+      tablesLower.close();\n+      return foundTable;\n+    });\n+\n+    // create table if not exits\n+    if (!exists) {\n+      connections.run(conn -> conn.prepareStatement(SQL_CREATE_CATALOG_TABLE).execute());\n+      LOG.debug(\"Created table {} to store iceberg tables!\", SQL_TABLE_NAME);\n+    }\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    return new JdbcTableOperations(connections, io, catalogName, tableIdentifier);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, SLASH.join(table.namespace().levels()), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+\n+    int deletedRecords;\n+    try {\n+      deletedRecords = connections.run(conn -> {\n+        try (PreparedStatement sql = conn.prepareStatement(DROP_TABLE_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(identifier.namespace()));\n+          sql.setString(3, identifier.name());\n+          return sql.executeUpdate();\n+        }\n+      });\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(\"Failed to drop \" + identifier, e);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to dropTable\", e);\n+    }\n+\n+    if (deletedRecords > 0) {\n+      LOG.debug(\"Successfully dropped table {}.\", identifier);\n+    } else {\n+      LOG.debug(\"Cannot drop table: {}! table not found in the catalog.\", identifier);\n+      return false;\n+    }\n+\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata = ops.current();\n+\n+    if (purge && lastMetadata != null) {\n+      CatalogUtil.dropTableData(ops.io(), lastMetadata);\n+      LOG.info(\"Table {} data purged!\", identifier);\n+    }\n+    return true;\n+\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    if (!namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Namespace does not exist: %s\", namespace);\n+    }\n+\n+    try {\n+      return connections.run(conn -> {\n+        List<TableIdentifier> results = Lists.newArrayList();\n+        try (PreparedStatement sql = conn.prepareStatement(LIST_TABLES_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(namespace));\n+\n+          ResultSet rs = sql.executeQuery();\n+          while (rs.next()) {\n+            results.add(JdbcUtil.stringToTableIdentifier(rs.getString(\"table_namespace\"), rs.getString(\"table_name\")));\n+          }\n+\n+          return results;\n+        }\n+      });\n+\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(String.format(\"Failed to list tables in namespace: %s\", namespace), e);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted during JDBC operation\", e);\n+    }\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier to) {\n+    try {\n+      int updatedRecords = connections.run(conn -> {\n+        try (PreparedStatement sql = conn.prepareStatement(RENAME_TABLE_SQL)) {\n+          // SET\n+          sql.setString(1, JdbcUtil.namespaceToString(to.namespace()));\n+          sql.setString(2, to.name());\n+          // WHERE\n+          sql.setString(3, catalogName);\n+          sql.setString(4, JdbcUtil.namespaceToString(from.namespace()));\n+          sql.setString(5, from.name());\n+          return sql.executeUpdate();\n+        }\n+      });\n+\n+      if (updatedRecords == 1) {\n+        LOG.debug(\"Successfully renamed table from {} to {}!\", from, to);\n+      } else if (updatedRecords == 0) {\n+        throw new NoSuchTableException(\"Failed to rename table! Table '%s' not found in the catalog!\", from);\n+      } else {\n+        throw new RuntimeException(\"Failed to rename table! Rename operation Failed\");\n+      }\n+    } catch (SQLIntegrityConstraintViolationException e) {\n+      throw new AlreadyExistsException(\"Table with name '%s' already exists in the catalog!\", to);\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(\"Failed to rename table!\", e);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to rename\", e);\n+    }\n+  }\n+\n+  @Override\n+  public String name() {\n+    return catalogName;\n+  }\n+\n+  @Override\n+  public Configuration getConf() {\n+    return conf;\n+  }\n+\n+  @Override\n+  public void setConf(Configuration conf) {\n+    this.conf = conf;\n+  }\n+\n+  @Override\n+  public void createNamespace(Namespace namespace, Map<String, String> metadata) {", "originalCommit": "849b0d2a12b44102c02ba6b89fe45374ad7398ec", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzQ1NTE2MQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r553455161", "bodyText": "with earlier discussion we agreed to keep initial implementation simple and based on single table.\nanother point about namespace metadata\nwith current implementatin if we want to implement createNamespace we need to create a table with it because its part of the primary key PRIMARY KEY (catalog_name, table_namespace, table_name)", "author": "ismailsimsek", "createdAt": "2021-01-07T16:57:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Mjc5NDYxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjExODE2OA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r562118168", "bodyText": "Yeah, in this implementation, namespaces exist (if a table in the namespace exists) and can be listed but we don't support namespace metadata. That keeps things simple so that we only need one table for the initial implementation. In the future, we can add a separate table with custom metadata. But that doesn't need to be done yet.", "author": "rdblue", "createdAt": "2021-01-21T18:49:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Mjc5NDYxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Mjc5NzY1Mw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r552797653", "bodyText": "Seems like we are cross referencing constants in JdbcCatalog and JdbcTableOperations, I suggest we move all the SQL table names and statements to a centralized place such as JdbcUtil, what do you think?", "author": "jackye1995", "createdAt": "2021-01-06T16:47:41Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcTableOperations.java", "diffHunk": "@@ -0,0 +1,217 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.sql.DataTruncation;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Map;\n+import java.util.Objects;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.UncheckedSQLException;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+class JdbcTableOperations extends BaseMetastoreTableOperations {\n+\n+  public static final String DO_COMMIT_SQL = \"UPDATE \" + JdbcCatalog.SQL_TABLE_NAME +", "originalCommit": "849b0d2a12b44102c02ba6b89fe45374ad7398ec", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzQ3Mzc3NA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r553473774", "bodyText": "moved sql constants to JdbcUtil", "author": "ismailsimsek", "createdAt": "2021-01-07T17:27:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Mjc5NzY1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjgwNDU2Ng==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r552804566", "bodyText": "why not put % in LIST_NAMESPACES_SQL? And also the same comment for other places using %.", "author": "jackye1995", "createdAt": "2021-01-06T16:54:57Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,423 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.UncheckedSQLException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String SQL_TABLE_NAME = \"iceberg_tables\";\n+  public static final String SQL_CREATE_CATALOG_TABLE =\n+      \"CREATE TABLE \" + SQL_TABLE_NAME +\n+          \"(catalog_name VARCHAR(1255) NOT NULL,\" +\n+          \"table_namespace VARCHAR(1255) NOT NULL,\" +\n+          \"table_name VARCHAR(1255) NOT NULL,\" +\n+          \"metadata_location VARCHAR(32768),\" +\n+          \"previous_metadata_location VARCHAR(32768),\" +\n+          \"PRIMARY KEY (catalog_name, table_namespace, table_name)\" +\n+          \")\";\n+  public static final String LOAD_TABLE_SQL = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+      \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String LIST_TABLES_SQL = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+      \" WHERE catalog_name = ? AND table_namespace = ?\";\n+  public static final String RENAME_TABLE_SQL = \"UPDATE \" + SQL_TABLE_NAME +\n+      \" SET table_namespace = ? , table_name = ? \" +\n+      \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String DROP_TABLE_SQL = \"DELETE FROM \" + SQL_TABLE_NAME +\n+      \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String GET_NAMESPACE_SQL = \"SELECT table_namespace FROM \" + SQL_TABLE_NAME +\n+      \" WHERE catalog_name = ? AND table_namespace LIKE ? LIMIT 1\";\n+  public static final String LIST_NAMESPACES_SQL = \"SELECT DISTINCT table_namespace FROM \" + SQL_TABLE_NAME +\n+      \" WHERE catalog_name = ? AND table_namespace LIKE ?\";\n+  public static final String JDBC_PARAM_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.HIVE_URI, \"\").isEmpty(),\n+        \"No connection url provided for jdbc catalog!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.WAREHOUSE_LOCATION, \"\").isEmpty(),\n+        \"Cannot initialize Jdbc Catalog because warehousePath must not be null!\");\n+\n+    this.warehouseLocation = properties.get(CatalogProperties.WAREHOUSE_LOCATION).replaceAll(\"/$\", \"\");\n+    this.catalogName = name == null ? \"jdbc\" : name;\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.io = fileIOImpl == null ?\n+        new HadoopFileIO(conf) :\n+        CatalogUtil.loadFileIO(fileIOImpl, properties, conf);\n+\n+    try {\n+      initializeConnection(properties);\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(\"Database Connection timeout!\", e);\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(\"Database Connection failed!\", e);\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(\"Failed to initialize catalog!\", e);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to initialize!\", e);\n+    }\n+  }\n+\n+  private void initializeConnection(Map<String, String> properties) throws SQLException, InterruptedException {\n+    LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.HIVE_URI));\n+    connections = new JdbcClientPool(properties.get(CatalogProperties.HIVE_URI), properties);\n+    initializeCatalogTables();\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    // need to check multiple times because some databases are using different naming standard. ex: H2db keeping\n+    // table names as uppercase\n+\n+    boolean exists = connections.run(conn -> {\n+      boolean foundTable = false;\n+      DatabaseMetaData dbMeta = conn.getMetaData();\n+      ResultSet tables = dbMeta.getTables(null, null, SQL_TABLE_NAME, null);\n+      if (tables.next()) {\n+        foundTable = true;\n+      }\n+      tables.close();\n+      ResultSet tablesUpper = dbMeta.getTables(null, null, SQL_TABLE_NAME.toUpperCase(), null);\n+      if (tablesUpper.next()) {\n+        foundTable = true;\n+      }\n+      tablesUpper.close();\n+      ResultSet tablesLower = dbMeta.getTables(null, null, SQL_TABLE_NAME.toLowerCase(), null);\n+      if (tablesLower.next()) {\n+        foundTable = true;\n+      }\n+      tablesLower.close();\n+      return foundTable;\n+    });\n+\n+    // create table if not exits\n+    if (!exists) {\n+      connections.run(conn -> conn.prepareStatement(SQL_CREATE_CATALOG_TABLE).execute());\n+      LOG.debug(\"Created table {} to store iceberg tables!\", SQL_TABLE_NAME);\n+    }\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    return new JdbcTableOperations(connections, io, catalogName, tableIdentifier);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, SLASH.join(table.namespace().levels()), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+\n+    int deletedRecords;\n+    try {\n+      deletedRecords = connections.run(conn -> {\n+        try (PreparedStatement sql = conn.prepareStatement(DROP_TABLE_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(identifier.namespace()));\n+          sql.setString(3, identifier.name());\n+          return sql.executeUpdate();\n+        }\n+      });\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(\"Failed to drop \" + identifier, e);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to dropTable\", e);\n+    }\n+\n+    if (deletedRecords > 0) {\n+      LOG.debug(\"Successfully dropped table {}.\", identifier);\n+    } else {\n+      LOG.debug(\"Cannot drop table: {}! table not found in the catalog.\", identifier);\n+      return false;\n+    }\n+\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata = ops.current();\n+\n+    if (purge && lastMetadata != null) {\n+      CatalogUtil.dropTableData(ops.io(), lastMetadata);\n+      LOG.info(\"Table {} data purged!\", identifier);\n+    }\n+    return true;\n+\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    if (!namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Namespace does not exist: %s\", namespace);\n+    }\n+\n+    try {\n+      return connections.run(conn -> {\n+        List<TableIdentifier> results = Lists.newArrayList();\n+        try (PreparedStatement sql = conn.prepareStatement(LIST_TABLES_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(namespace));\n+\n+          ResultSet rs = sql.executeQuery();\n+          while (rs.next()) {\n+            results.add(JdbcUtil.stringToTableIdentifier(rs.getString(\"table_namespace\"), rs.getString(\"table_name\")));\n+          }\n+\n+          return results;\n+        }\n+      });\n+\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(String.format(\"Failed to list tables in namespace: %s\", namespace), e);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted during JDBC operation\", e);\n+    }\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier to) {\n+    try {\n+      int updatedRecords = connections.run(conn -> {\n+        try (PreparedStatement sql = conn.prepareStatement(RENAME_TABLE_SQL)) {\n+          // SET\n+          sql.setString(1, JdbcUtil.namespaceToString(to.namespace()));\n+          sql.setString(2, to.name());\n+          // WHERE\n+          sql.setString(3, catalogName);\n+          sql.setString(4, JdbcUtil.namespaceToString(from.namespace()));\n+          sql.setString(5, from.name());\n+          return sql.executeUpdate();\n+        }\n+      });\n+\n+      if (updatedRecords == 1) {\n+        LOG.debug(\"Successfully renamed table from {} to {}!\", from, to);\n+      } else if (updatedRecords == 0) {\n+        throw new NoSuchTableException(\"Failed to rename table! Table '%s' not found in the catalog!\", from);\n+      } else {\n+        throw new RuntimeException(\"Failed to rename table! Rename operation Failed\");\n+      }\n+    } catch (SQLIntegrityConstraintViolationException e) {\n+      throw new AlreadyExistsException(\"Table with name '%s' already exists in the catalog!\", to);\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(\"Failed to rename table!\", e);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to rename\", e);\n+    }\n+  }\n+\n+  @Override\n+  public String name() {\n+    return catalogName;\n+  }\n+\n+  @Override\n+  public Configuration getConf() {\n+    return conf;\n+  }\n+\n+  @Override\n+  public void setConf(Configuration conf) {\n+    this.conf = conf;\n+  }\n+\n+  @Override\n+  public void createNamespace(Namespace namespace, Map<String, String> metadata) {\n+    throw new UnsupportedOperationException(\"Cannot create namespace \" + namespace +\n+        \": createNamespace is not supported\");\n+  }\n+\n+  @Override\n+  public List<Namespace> listNamespaces(Namespace namespace) throws NoSuchNamespaceException {\n+    if (!namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Namespace does not exist: %s\", namespace);\n+    }\n+    try {\n+\n+      List<Namespace> namespaces = connections.run(conn -> {\n+        List<Namespace> result = Lists.newArrayList();\n+\n+        try (PreparedStatement sql = conn.prepareStatement(LIST_NAMESPACES_SQL)) {\n+          sql.setString(1, catalogName);\n+          if (namespace.isEmpty()) {\n+            sql.setString(2, JdbcUtil.namespaceToString(namespace) + \"%\");", "originalCommit": "849b0d2a12b44102c02ba6b89fe45374ad7398ec", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzQzODkyNA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r553438924", "bodyText": "% needs to be set in the value itself, cannot add to the query. maybe i misunderstood ?\nbut removed if else logic for the second parameter by adding filter to lambda with a explanation.", "author": "ismailsimsek", "createdAt": "2021-01-07T16:30:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjgwNDU2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjgwNjE5MQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r552806191", "bodyText": "nit: seems like we are just using Path to join the two paths. Why not just use SLASH.join(warehouseLocation, SLASH.join(namespace.levels()))\nAlso, if this is the default namespace path, I think it is better to have its own method:\nprivate String defaultNamespaceLocation() {\n    return ....\n}", "author": "jackye1995", "createdAt": "2021-01-06T16:56:22Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,423 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.UncheckedSQLException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String SQL_TABLE_NAME = \"iceberg_tables\";\n+  public static final String SQL_CREATE_CATALOG_TABLE =\n+      \"CREATE TABLE \" + SQL_TABLE_NAME +\n+          \"(catalog_name VARCHAR(1255) NOT NULL,\" +\n+          \"table_namespace VARCHAR(1255) NOT NULL,\" +\n+          \"table_name VARCHAR(1255) NOT NULL,\" +\n+          \"metadata_location VARCHAR(32768),\" +\n+          \"previous_metadata_location VARCHAR(32768),\" +\n+          \"PRIMARY KEY (catalog_name, table_namespace, table_name)\" +\n+          \")\";\n+  public static final String LOAD_TABLE_SQL = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+      \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String LIST_TABLES_SQL = \"SELECT * FROM \" + SQL_TABLE_NAME +\n+      \" WHERE catalog_name = ? AND table_namespace = ?\";\n+  public static final String RENAME_TABLE_SQL = \"UPDATE \" + SQL_TABLE_NAME +\n+      \" SET table_namespace = ? , table_name = ? \" +\n+      \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String DROP_TABLE_SQL = \"DELETE FROM \" + SQL_TABLE_NAME +\n+      \" WHERE catalog_name = ? AND table_namespace = ? AND table_name = ? \";\n+  public static final String GET_NAMESPACE_SQL = \"SELECT table_namespace FROM \" + SQL_TABLE_NAME +\n+      \" WHERE catalog_name = ? AND table_namespace LIKE ? LIMIT 1\";\n+  public static final String LIST_NAMESPACES_SQL = \"SELECT DISTINCT table_namespace FROM \" + SQL_TABLE_NAME +\n+      \" WHERE catalog_name = ? AND table_namespace LIKE ?\";\n+  public static final String JDBC_PARAM_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.HIVE_URI, \"\").isEmpty(),\n+        \"No connection url provided for jdbc catalog!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.WAREHOUSE_LOCATION, \"\").isEmpty(),\n+        \"Cannot initialize Jdbc Catalog because warehousePath must not be null!\");\n+\n+    this.warehouseLocation = properties.get(CatalogProperties.WAREHOUSE_LOCATION).replaceAll(\"/$\", \"\");\n+    this.catalogName = name == null ? \"jdbc\" : name;\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.io = fileIOImpl == null ?\n+        new HadoopFileIO(conf) :\n+        CatalogUtil.loadFileIO(fileIOImpl, properties, conf);\n+\n+    try {\n+      initializeConnection(properties);\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(\"Database Connection timeout!\", e);\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(\"Database Connection failed!\", e);\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(\"Failed to initialize catalog!\", e);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to initialize!\", e);\n+    }\n+  }\n+\n+  private void initializeConnection(Map<String, String> properties) throws SQLException, InterruptedException {\n+    LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.HIVE_URI));\n+    connections = new JdbcClientPool(properties.get(CatalogProperties.HIVE_URI), properties);\n+    initializeCatalogTables();\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    // need to check multiple times because some databases are using different naming standard. ex: H2db keeping\n+    // table names as uppercase\n+\n+    boolean exists = connections.run(conn -> {\n+      boolean foundTable = false;\n+      DatabaseMetaData dbMeta = conn.getMetaData();\n+      ResultSet tables = dbMeta.getTables(null, null, SQL_TABLE_NAME, null);\n+      if (tables.next()) {\n+        foundTable = true;\n+      }\n+      tables.close();\n+      ResultSet tablesUpper = dbMeta.getTables(null, null, SQL_TABLE_NAME.toUpperCase(), null);\n+      if (tablesUpper.next()) {\n+        foundTable = true;\n+      }\n+      tablesUpper.close();\n+      ResultSet tablesLower = dbMeta.getTables(null, null, SQL_TABLE_NAME.toLowerCase(), null);\n+      if (tablesLower.next()) {\n+        foundTable = true;\n+      }\n+      tablesLower.close();\n+      return foundTable;\n+    });\n+\n+    // create table if not exits\n+    if (!exists) {\n+      connections.run(conn -> conn.prepareStatement(SQL_CREATE_CATALOG_TABLE).execute());\n+      LOG.debug(\"Created table {} to store iceberg tables!\", SQL_TABLE_NAME);\n+    }\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    return new JdbcTableOperations(connections, io, catalogName, tableIdentifier);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, SLASH.join(table.namespace().levels()), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+\n+    int deletedRecords;\n+    try {\n+      deletedRecords = connections.run(conn -> {\n+        try (PreparedStatement sql = conn.prepareStatement(DROP_TABLE_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(identifier.namespace()));\n+          sql.setString(3, identifier.name());\n+          return sql.executeUpdate();\n+        }\n+      });\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(\"Failed to drop \" + identifier, e);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to dropTable\", e);\n+    }\n+\n+    if (deletedRecords > 0) {\n+      LOG.debug(\"Successfully dropped table {}.\", identifier);\n+    } else {\n+      LOG.debug(\"Cannot drop table: {}! table not found in the catalog.\", identifier);\n+      return false;\n+    }\n+\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata = ops.current();\n+\n+    if (purge && lastMetadata != null) {\n+      CatalogUtil.dropTableData(ops.io(), lastMetadata);\n+      LOG.info(\"Table {} data purged!\", identifier);\n+    }\n+    return true;\n+\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    if (!namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Namespace does not exist: %s\", namespace);\n+    }\n+\n+    try {\n+      return connections.run(conn -> {\n+        List<TableIdentifier> results = Lists.newArrayList();\n+        try (PreparedStatement sql = conn.prepareStatement(LIST_TABLES_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(namespace));\n+\n+          ResultSet rs = sql.executeQuery();\n+          while (rs.next()) {\n+            results.add(JdbcUtil.stringToTableIdentifier(rs.getString(\"table_namespace\"), rs.getString(\"table_name\")));\n+          }\n+\n+          return results;\n+        }\n+      });\n+\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(String.format(\"Failed to list tables in namespace: %s\", namespace), e);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted during JDBC operation\", e);\n+    }\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier to) {\n+    try {\n+      int updatedRecords = connections.run(conn -> {\n+        try (PreparedStatement sql = conn.prepareStatement(RENAME_TABLE_SQL)) {\n+          // SET\n+          sql.setString(1, JdbcUtil.namespaceToString(to.namespace()));\n+          sql.setString(2, to.name());\n+          // WHERE\n+          sql.setString(3, catalogName);\n+          sql.setString(4, JdbcUtil.namespaceToString(from.namespace()));\n+          sql.setString(5, from.name());\n+          return sql.executeUpdate();\n+        }\n+      });\n+\n+      if (updatedRecords == 1) {\n+        LOG.debug(\"Successfully renamed table from {} to {}!\", from, to);\n+      } else if (updatedRecords == 0) {\n+        throw new NoSuchTableException(\"Failed to rename table! Table '%s' not found in the catalog!\", from);\n+      } else {\n+        throw new RuntimeException(\"Failed to rename table! Rename operation Failed\");\n+      }\n+    } catch (SQLIntegrityConstraintViolationException e) {\n+      throw new AlreadyExistsException(\"Table with name '%s' already exists in the catalog!\", to);\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(\"Failed to rename table!\", e);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to rename\", e);\n+    }\n+  }\n+\n+  @Override\n+  public String name() {\n+    return catalogName;\n+  }\n+\n+  @Override\n+  public Configuration getConf() {\n+    return conf;\n+  }\n+\n+  @Override\n+  public void setConf(Configuration conf) {\n+    this.conf = conf;\n+  }\n+\n+  @Override\n+  public void createNamespace(Namespace namespace, Map<String, String> metadata) {\n+    throw new UnsupportedOperationException(\"Cannot create namespace \" + namespace +\n+        \": createNamespace is not supported\");\n+  }\n+\n+  @Override\n+  public List<Namespace> listNamespaces(Namespace namespace) throws NoSuchNamespaceException {\n+    if (!namespaceExists(namespace)) {\n+      throw new NoSuchNamespaceException(\"Namespace does not exist: %s\", namespace);\n+    }\n+    try {\n+\n+      List<Namespace> namespaces = connections.run(conn -> {\n+        List<Namespace> result = Lists.newArrayList();\n+\n+        try (PreparedStatement sql = conn.prepareStatement(LIST_NAMESPACES_SQL)) {\n+          sql.setString(1, catalogName);\n+          if (namespace.isEmpty()) {\n+            sql.setString(2, JdbcUtil.namespaceToString(namespace) + \"%\");\n+          } else {\n+            sql.setString(2, JdbcUtil.namespaceToString(namespace) + \".%\");\n+          }\n+          ResultSet rs = sql.executeQuery();\n+          while (rs.next()) {\n+            result.add(JdbcUtil.stringToNamespace(rs.getString(\"table_namespace\")));\n+          }\n+          rs.close();\n+        }\n+\n+        return result;\n+      });\n+\n+      int subNamespaceLevelLength = namespace.levels().length + 1;\n+      namespaces = namespaces.stream()\n+          // exclude itself\n+          .filter(n -> !n.equals(namespace))\n+          // only get sub namespaces/children\n+          .map(n -> Namespace.of(\n+              Arrays.stream(n.levels()).limit(subNamespaceLevelLength).toArray(String[]::new)\n+              )\n+          )\n+          // remove duplicates\n+          .distinct()\n+          .collect(Collectors.toList());\n+\n+      LOG.debug(\"From the namespace '{}' found: {}\", namespace, namespaces);\n+      return namespaces;\n+\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to listNamespaces(namespace) Namespace: \" + namespace, e);\n+    } catch (SQLException e) {\n+      throw new RuntimeException(\"Failed to list all namespace: \" + namespace + \" in catalog!\", e);\n+    }\n+  }\n+\n+  @Override\n+  public Map<String, String> loadNamespaceMetadata(Namespace namespace) throws NoSuchNamespaceException {\n+    if (!namespaceExists(namespace) || namespace.isEmpty()) {\n+      throw new NoSuchNamespaceException(\"Namespace does not exist: %s\", namespace);\n+    }\n+\n+    Path nsPath = new Path(warehouseLocation, SLASH.join(namespace.levels()));", "originalCommit": "849b0d2a12b44102c02ba6b89fe45374ad7398ec", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzQzMzkzNA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r553433934", "bodyText": "changed to SLASH.join and created method defaultNamespaceLocation", "author": "ismailsimsek", "createdAt": "2021-01-07T16:22:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjgwNjE5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjMwNjk1OQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r556306959", "bodyText": "nit: unnecessary keyword protected", "author": "jackye1995", "createdAt": "2021-01-13T07:17:49Z", "path": "core/src/main/java/org/apache/iceberg/ClientPool.java", "diffHunk": "@@ -36,7 +36,7 @@\n   private volatile int currentSize;\n   private boolean closed;\n \n-  ClientPool(int poolSize, Class<? extends E> reconnectExc) {\n+  protected ClientPool(int poolSize, Class<? extends E> reconnectExc) {", "originalCommit": "75079f3360208f71730c9b0df8c1fe535686a613", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjExNjQyMA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r562116420", "bodyText": "I don't think this is unnecessary. This base class is public now and may be extended outside of this package.", "author": "rdblue", "createdAt": "2021-01-21T18:46:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjMwNjk1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjMwNzYxOA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r556307618", "bodyText": "I think this exception is specific to JDBC catalog and should be in the core jdbc package path.", "author": "jackye1995", "createdAt": "2021-01-13T07:19:27Z", "path": "api/src/main/java/org/apache/iceberg/exceptions/UncheckedSQLException.java", "diffHunk": "@@ -0,0 +1,29 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.exceptions;\n+\n+import java.sql.SQLException;\n+\n+public class UncheckedSQLException extends RuntimeException {", "originalCommit": "75079f3360208f71730c9b0df8c1fe535686a613", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjMwOTAyNw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r556309027", "bodyText": "This needs to be public, so that users can import this variable to set their custom properties.\nto be consistent with the name CatalogProperties, this should be named PROPERTY_PREFIX, so that users can use JdbcCatalog.PROPERTY_PREFIX.", "author": "jackye1995", "createdAt": "2021-01-13T07:23:03Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,404 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.UncheckedSQLException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  protected static final String JDBC_PARAM_PREFIX = \"connection.parameter.\";", "originalCommit": "75079f3360208f71730c9b0df8c1fe535686a613", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjMxMDE0Nw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r556310147", "bodyText": "This do not need to be public", "author": "jackye1995", "createdAt": "2021-01-13T07:25:30Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcClientPool.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.SQLException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.util.Map;\n+import java.util.Properties;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.ClientPool;\n+import org.apache.iceberg.exceptions.UncheckedSQLException;\n+\n+public class JdbcClientPool extends ClientPool<Connection, SQLException> {", "originalCommit": "75079f3360208f71730c9b0df8c1fe535686a613", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjMxMDc1MQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r556310751", "bodyText": "This do not need to be public", "author": "jackye1995", "createdAt": "2021-01-13T07:26:43Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcClientPool.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.SQLException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.util.Map;\n+import java.util.Properties;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.ClientPool;\n+import org.apache.iceberg.exceptions.UncheckedSQLException;\n+\n+public class JdbcClientPool extends ClientPool<Connection, SQLException> {\n+\n+  private final String dbUrl;\n+  private final Map<String, String> properties;\n+\n+  JdbcClientPool(String dbUrl, Map<String, String> props) {\n+    this(Integer.parseInt(props.getOrDefault(CatalogProperties.HIVE_CLIENT_POOL_SIZE,\n+        String.valueOf(CatalogProperties.HIVE_CLIENT_POOL_SIZE_DEFAULT))), dbUrl, props);\n+  }\n+\n+  public JdbcClientPool(int poolSize, String dbUrl, Map<String, String> props) {", "originalCommit": "75079f3360208f71730c9b0df8c1fe535686a613", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjMxMDkzMA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r556310930", "bodyText": "why not use your UncheckedSQLException?", "author": "jackye1995", "createdAt": "2021-01-13T07:27:05Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcClientPool.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.SQLException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.util.Map;\n+import java.util.Properties;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.ClientPool;\n+import org.apache.iceberg.exceptions.UncheckedSQLException;\n+\n+public class JdbcClientPool extends ClientPool<Connection, SQLException> {\n+\n+  private final String dbUrl;\n+  private final Map<String, String> properties;\n+\n+  JdbcClientPool(String dbUrl, Map<String, String> props) {\n+    this(Integer.parseInt(props.getOrDefault(CatalogProperties.HIVE_CLIENT_POOL_SIZE,\n+        String.valueOf(CatalogProperties.HIVE_CLIENT_POOL_SIZE_DEFAULT))), dbUrl, props);\n+  }\n+\n+  public JdbcClientPool(int poolSize, String dbUrl, Map<String, String> props) {\n+    super(poolSize, SQLNonTransientConnectionException.class);\n+    properties = props;\n+    this.dbUrl = dbUrl;\n+  }\n+\n+  @Override\n+  protected Connection newClient() {\n+    try {\n+      Properties dbProps = new Properties();\n+      properties.forEach((key, value) -> dbProps.put(key.replace(JdbcCatalog.JDBC_PARAM_PREFIX, \"\"), value));\n+      return DriverManager.getConnection(dbUrl, dbProps);\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(\"Failed to connect: \" + dbUrl, e);\n+    }\n+  }\n+\n+  @Override\n+  protected Connection reconnect(Connection client) {\n+    close(client);\n+    return newClient();\n+  }\n+\n+  @Override\n+  protected void close(Connection client) {\n+    try {\n+      client.close();\n+    } catch (SQLException e) {\n+      throw new RuntimeException(\"Failed to connect to database!\", e);", "originalCommit": "75079f3360208f71730c9b0df8c1fe535686a613", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjMxMjAwMg==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r556312002", "bodyText": "nit: Failed to get table %s from catalog %s, tableIdentifier, catalogName sounds better, also for other similar error messages below.", "author": "jackye1995", "createdAt": "2021-01-13T07:29:38Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcTableOperations.java", "diffHunk": "@@ -0,0 +1,211 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.sql.DataTruncation;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Map;\n+import java.util.Objects;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.UncheckedSQLException;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+class JdbcTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcTableOperations.class);\n+  private final String catalogName;\n+  private final TableIdentifier tableIdentifier;\n+  private final FileIO fileIO;\n+  private final JdbcClientPool connections;\n+\n+  protected JdbcTableOperations(JdbcClientPool dbConnPool, FileIO fileIO, String catalogName,\n+                                TableIdentifier tableIdentifier) {\n+    this.catalogName = catalogName;\n+    this.tableIdentifier = tableIdentifier;\n+    this.fileIO = fileIO;\n+    this.connections = dbConnPool;\n+  }\n+\n+  @Override\n+  public void doRefresh() {\n+    Map<String, String> table;\n+\n+    try {\n+      table = getTable();\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted during refresh\", e);\n+    } catch (SQLException e) {\n+      // unknown exception happened when getting table from catalog\n+      throw new UncheckedSQLException(String.format(\"Failed to get table from catalog %s.%s\", catalogName,", "originalCommit": "75079f3360208f71730c9b0df8c1fe535686a613", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjMxMjc5Nw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r556312797", "bodyText": "\"metadata_location\" should be a static variable", "author": "jackye1995", "createdAt": "2021-01-13T07:31:21Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcTableOperations.java", "diffHunk": "@@ -0,0 +1,211 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.sql.DataTruncation;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Map;\n+import java.util.Objects;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.UncheckedSQLException;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+class JdbcTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcTableOperations.class);\n+  private final String catalogName;\n+  private final TableIdentifier tableIdentifier;\n+  private final FileIO fileIO;\n+  private final JdbcClientPool connections;\n+\n+  protected JdbcTableOperations(JdbcClientPool dbConnPool, FileIO fileIO, String catalogName,\n+                                TableIdentifier tableIdentifier) {\n+    this.catalogName = catalogName;\n+    this.tableIdentifier = tableIdentifier;\n+    this.fileIO = fileIO;\n+    this.connections = dbConnPool;\n+  }\n+\n+  @Override\n+  public void doRefresh() {\n+    Map<String, String> table;\n+\n+    try {\n+      table = getTable();\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted during refresh\", e);\n+    } catch (SQLException e) {\n+      // unknown exception happened when getting table from catalog\n+      throw new UncheckedSQLException(String.format(\"Failed to get table from catalog %s.%s\", catalogName,\n+          tableIdentifier), e);\n+    }\n+\n+    // Table not exists AND currentMetadataLocation is not NULL!\n+    if (table.isEmpty() && currentMetadataLocation() != null) {\n+      throw new NoSuchTableException(\"Failed to get table from catalog %s.%s!\" +\n+          \" maybe another process deleted it!\", catalogName, tableIdentifier);\n+    }\n+\n+    // Table not exists in the catalog! metadataLocation is null here!\n+    if (table.isEmpty()) {\n+      refreshFromMetadataLocation(null);\n+      return;\n+    }\n+\n+    // Table exists but metadataLocation is null\n+    if (table.getOrDefault(\"metadata_location\", null) == null) {", "originalCommit": "75079f3360208f71730c9b0df8c1fe535686a613", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjMxMzYxMw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r556313613", "bodyText": "method too long, prefer to separate to smaller methods like updateTable and createTable based on exist condition.", "author": "jackye1995", "createdAt": "2021-01-13T07:33:05Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcTableOperations.java", "diffHunk": "@@ -0,0 +1,211 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.sql.DataTruncation;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Map;\n+import java.util.Objects;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.exceptions.UncheckedSQLException;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+class JdbcTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcTableOperations.class);\n+  private final String catalogName;\n+  private final TableIdentifier tableIdentifier;\n+  private final FileIO fileIO;\n+  private final JdbcClientPool connections;\n+\n+  protected JdbcTableOperations(JdbcClientPool dbConnPool, FileIO fileIO, String catalogName,\n+                                TableIdentifier tableIdentifier) {\n+    this.catalogName = catalogName;\n+    this.tableIdentifier = tableIdentifier;\n+    this.fileIO = fileIO;\n+    this.connections = dbConnPool;\n+  }\n+\n+  @Override\n+  public void doRefresh() {\n+    Map<String, String> table;\n+\n+    try {\n+      table = getTable();\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted during refresh\", e);\n+    } catch (SQLException e) {\n+      // unknown exception happened when getting table from catalog\n+      throw new UncheckedSQLException(String.format(\"Failed to get table from catalog %s.%s\", catalogName,\n+          tableIdentifier), e);\n+    }\n+\n+    // Table not exists AND currentMetadataLocation is not NULL!\n+    if (table.isEmpty() && currentMetadataLocation() != null) {\n+      throw new NoSuchTableException(\"Failed to get table from catalog %s.%s!\" +\n+          \" maybe another process deleted it!\", catalogName, tableIdentifier);\n+    }\n+\n+    // Table not exists in the catalog! metadataLocation is null here!\n+    if (table.isEmpty()) {\n+      refreshFromMetadataLocation(null);\n+      return;\n+    }\n+\n+    // Table exists but metadataLocation is null\n+    if (table.getOrDefault(\"metadata_location\", null) == null) {\n+      throw new RuntimeException(String.format(\"Failed to get metadata location if the table %s.%s\", catalogName,\n+          tableIdentifier));\n+    }\n+\n+    refreshFromMetadataLocation(table.get(\"metadata_location\"));\n+  }\n+\n+  @Override\n+  public void doCommit(TableMetadata base, TableMetadata metadata) {", "originalCommit": "75079f3360208f71730c9b0df8c1fe535686a613", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzAzOTEzNw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r557039137", "bodyText": "Since this is now used by more than Hive, it does not make sense to say HIVE_URI now. Let me update that in another PR so that you can rebase it.", "author": "jackye1995", "createdAt": "2021-01-14T04:37:55Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,403 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.HIVE_URI, \"\").isEmpty(),", "originalCommit": "e1cee5e8b26fdebae8b0e423ce9430b6bad5165c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzA0ODEyOQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r557048129", "bodyText": "#2088", "author": "jackye1995", "createdAt": "2021-01-14T05:13:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzAzOTEzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzAzOTg1NQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r557039855", "bodyText": "warehouse location is stored in the next line, so it make sense to first do this.warehouseLocation = properties.getOrDefault(CatalogProperties.WAREHOUSE_LOCATION, \"\").replaceAll(\"/$\", \"\"), and then do all the condition checks against this.warehouseLocation.", "author": "jackye1995", "createdAt": "2021-01-14T04:40:51Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,403 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.HIVE_URI, \"\").isEmpty(),\n+        \"No connection url provided for jdbc catalog!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.WAREHOUSE_LOCATION, \"\").isEmpty(),", "originalCommit": "e1cee5e8b26fdebae8b0e423ce9430b6bad5165c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzA0MDA4NQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r557040085", "bodyText": "catalogName is already jdbc if not set, so only need to do a if statement.", "author": "jackye1995", "createdAt": "2021-01-14T04:41:45Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,403 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.HIVE_URI, \"\").isEmpty(),\n+        \"No connection url provided for jdbc catalog!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.WAREHOUSE_LOCATION, \"\").isEmpty(),\n+        \"Cannot initialize Jdbc Catalog because warehousePath must not be null!\");\n+\n+    this.warehouseLocation = properties.get(CatalogProperties.WAREHOUSE_LOCATION).replaceAll(\"/$\", \"\");\n+    this.catalogName = name == null ? \"jdbc\" : name;", "originalCommit": "e1cee5e8b26fdebae8b0e423ce9430b6bad5165c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzA0MTMxOA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r557041318", "bodyText": "I think CATALOG_TABLE_NAME is a better name, in case we will introduce other tables in the future.\nAlso as discussed above, I think we can use upper case for the table name.", "author": "jackye1995", "createdAt": "2021-01-14T04:46:52Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcUtil.java", "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Splitter;\n+import org.apache.iceberg.relocated.com.google.common.collect.Iterables;\n+\n+public final class JdbcUtil {\n+  protected static final String SQL_TABLE_NAME = \"iceberg_tables\";", "originalCommit": "e1cee5e8b26fdebae8b0e423ce9430b6bad5165c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzA0NDY5NQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r557044695", "bodyText": "I just verified, postgres can accept all upper letter table name in queries. The table name is case insensitve anyway in SQL standard. So I think it is better to only check for upper case table name. Also change SQL_TABLE_NAME value to upper case.", "author": "jackye1995", "createdAt": "2021-01-14T04:59:34Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,403 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.HIVE_URI, \"\").isEmpty(),\n+        \"No connection url provided for jdbc catalog!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.WAREHOUSE_LOCATION, \"\").isEmpty(),\n+        \"Cannot initialize Jdbc Catalog because warehousePath must not be null!\");\n+\n+    this.warehouseLocation = properties.get(CatalogProperties.WAREHOUSE_LOCATION).replaceAll(\"/$\", \"\");\n+    this.catalogName = name == null ? \"jdbc\" : name;\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.io = fileIOImpl == null ?\n+        new HadoopFileIO(conf) :\n+        CatalogUtil.loadFileIO(fileIOImpl, properties, conf);\n+\n+    try {\n+      initializeConnection(properties);\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(\"Database Connection timeout!\", e);\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(\"Database Connection failed!\", e);\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(\"Failed to initialize catalog!\", e);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to initialize!\", e);\n+    }\n+  }\n+\n+  private void initializeConnection(Map<String, String> properties) throws SQLException, InterruptedException {\n+    LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.HIVE_URI));\n+    connections = new JdbcClientPool(properties.get(CatalogProperties.HIVE_URI), properties);\n+    initializeCatalogTables();\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    // need to check multiple times because some databases are using different naming standard.\n+    // ex: H2db keeping table names as uppercase, PostgreSQL is keeping lowercase", "originalCommit": "e1cee5e8b26fdebae8b0e423ce9430b6bad5165c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzA0NTA1MQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r557045051", "bodyText": "nit: space after if statement", "author": "jackye1995", "createdAt": "2021-01-14T05:01:01Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,403 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.HIVE_URI, \"\").isEmpty(),\n+        \"No connection url provided for jdbc catalog!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.WAREHOUSE_LOCATION, \"\").isEmpty(),\n+        \"Cannot initialize Jdbc Catalog because warehousePath must not be null!\");\n+\n+    this.warehouseLocation = properties.get(CatalogProperties.WAREHOUSE_LOCATION).replaceAll(\"/$\", \"\");\n+    this.catalogName = name == null ? \"jdbc\" : name;\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.io = fileIOImpl == null ?\n+        new HadoopFileIO(conf) :\n+        CatalogUtil.loadFileIO(fileIOImpl, properties, conf);\n+\n+    try {\n+      initializeConnection(properties);\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(\"Database Connection timeout!\", e);\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(\"Database Connection failed!\", e);\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(\"Failed to initialize catalog!\", e);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to initialize!\", e);\n+    }\n+  }\n+\n+  private void initializeConnection(Map<String, String> properties) throws SQLException, InterruptedException {\n+    LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.HIVE_URI));\n+    connections = new JdbcClientPool(properties.get(CatalogProperties.HIVE_URI), properties);\n+    initializeCatalogTables();\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    // need to check multiple times because some databases are using different naming standard.\n+    // ex: H2db keeping table names as uppercase, PostgreSQL is keeping lowercase\n+\n+    boolean exists = connections.run(conn -> {\n+      boolean foundTable = false;\n+      DatabaseMetaData dbMeta = conn.getMetaData();\n+      ResultSet tables = dbMeta.getTables(null, null, JdbcUtil.SQL_TABLE_NAME, null);\n+      if (tables.next()) {\n+        foundTable = true;\n+      }\n+      tables.close();\n+      ResultSet tablesUpper = dbMeta.getTables(null, null, JdbcUtil.SQL_TABLE_NAME.toUpperCase(), null);\n+      if (tablesUpper.next()) {\n+        foundTable = true;\n+      }\n+      tablesUpper.close();\n+      ResultSet tablesLower = dbMeta.getTables(null, null, JdbcUtil.SQL_TABLE_NAME.toLowerCase(), null);\n+      if (tablesLower.next()) {\n+        foundTable = true;\n+      }\n+      tablesLower.close();\n+      return foundTable;\n+    });\n+\n+    // create table if not exits\n+    if (!exists) {\n+      connections.run(conn -> conn.prepareStatement(JdbcUtil.SQL_CREATE_CATALOG_TABLE).execute());\n+      LOG.debug(\"Created table {} to store iceberg tables!\", JdbcUtil.SQL_TABLE_NAME);\n+    }\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    return new JdbcTableOperations(connections, io, catalogName, tableIdentifier);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(defaultNamespaceLocation(table.namespace()), table.name());\n+    }\n+    return SLASH.join(defaultNamespaceLocation(table.namespace()), table.name());", "originalCommit": "e1cee5e8b26fdebae8b0e423ce9430b6bad5165c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzA0NTA5MQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r557045091", "bodyText": "nit: space after if statement", "author": "jackye1995", "createdAt": "2021-01-14T05:01:09Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,403 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.HIVE_URI, \"\").isEmpty(),\n+        \"No connection url provided for jdbc catalog!\");\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.WAREHOUSE_LOCATION, \"\").isEmpty(),\n+        \"Cannot initialize Jdbc Catalog because warehousePath must not be null!\");\n+\n+    this.warehouseLocation = properties.get(CatalogProperties.WAREHOUSE_LOCATION).replaceAll(\"/$\", \"\");\n+    this.catalogName = name == null ? \"jdbc\" : name;\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.io = fileIOImpl == null ?\n+        new HadoopFileIO(conf) :\n+        CatalogUtil.loadFileIO(fileIOImpl, properties, conf);\n+\n+    try {\n+      initializeConnection(properties);\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(\"Database Connection timeout!\", e);\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(\"Database Connection failed!\", e);\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(\"Failed to initialize catalog!\", e);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to initialize!\", e);\n+    }\n+  }\n+\n+  private void initializeConnection(Map<String, String> properties) throws SQLException, InterruptedException {\n+    LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.HIVE_URI));\n+    connections = new JdbcClientPool(properties.get(CatalogProperties.HIVE_URI), properties);\n+    initializeCatalogTables();\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    // need to check multiple times because some databases are using different naming standard.\n+    // ex: H2db keeping table names as uppercase, PostgreSQL is keeping lowercase\n+\n+    boolean exists = connections.run(conn -> {\n+      boolean foundTable = false;\n+      DatabaseMetaData dbMeta = conn.getMetaData();\n+      ResultSet tables = dbMeta.getTables(null, null, JdbcUtil.SQL_TABLE_NAME, null);\n+      if (tables.next()) {\n+        foundTable = true;\n+      }\n+      tables.close();\n+      ResultSet tablesUpper = dbMeta.getTables(null, null, JdbcUtil.SQL_TABLE_NAME.toUpperCase(), null);\n+      if (tablesUpper.next()) {\n+        foundTable = true;\n+      }\n+      tablesUpper.close();\n+      ResultSet tablesLower = dbMeta.getTables(null, null, JdbcUtil.SQL_TABLE_NAME.toLowerCase(), null);\n+      if (tablesLower.next()) {\n+        foundTable = true;\n+      }\n+      tablesLower.close();\n+      return foundTable;\n+    });\n+\n+    // create table if not exits\n+    if (!exists) {\n+      connections.run(conn -> conn.prepareStatement(JdbcUtil.SQL_CREATE_CATALOG_TABLE).execute());\n+      LOG.debug(\"Created table {} to store iceberg tables!\", JdbcUtil.SQL_TABLE_NAME);\n+    }\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    return new JdbcTableOperations(connections, io, catalogName, tableIdentifier);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(defaultNamespaceLocation(table.namespace()), table.name());\n+    }\n+    return SLASH.join(defaultNamespaceLocation(table.namespace()), table.name());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+\n+    int deletedRecords;\n+    try {\n+      deletedRecords = connections.run(conn -> {\n+        try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.DROP_TABLE_SQL)) {\n+          sql.setString(1, catalogName);\n+          sql.setString(2, JdbcUtil.namespaceToString(identifier.namespace()));\n+          sql.setString(3, identifier.name());\n+          return sql.executeUpdate();\n+        }\n+      });\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(\"Failed to drop \" + identifier, e);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to dropTable\", e);\n+    }\n+\n+    if (deletedRecords > 0) {\n+      LOG.debug(\"Successfully dropped table {}.\", identifier);\n+    } else {\n+      LOG.debug(\"Cannot drop table: {}! table not found in the catalog.\", identifier);\n+      return false;\n+    }\n+\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata = ops.current();\n+\n+    if (purge && lastMetadata != null) {\n+      CatalogUtil.dropTableData(ops.io(), lastMetadata);\n+      LOG.info(\"Table {} data purged!\", identifier);\n+    }\n+    return true;", "originalCommit": "e1cee5e8b26fdebae8b0e423ce9430b6bad5165c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzA0NTcwMQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r557045701", "bodyText": "should indicate this is a create table operation, maybe message can be fail to create the table .... Same for the update table exception above.", "author": "jackye1995", "createdAt": "2021-01-14T05:03:51Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcTableOperations.java", "diffHunk": "@@ -0,0 +1,218 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.sql.DataTruncation;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Map;\n+import java.util.Objects;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+class JdbcTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcTableOperations.class);\n+  private final String catalogName;\n+  private final TableIdentifier tableIdentifier;\n+  private final FileIO fileIO;\n+  private final JdbcClientPool connections;\n+\n+  protected JdbcTableOperations(JdbcClientPool dbConnPool, FileIO fileIO, String catalogName,\n+                                TableIdentifier tableIdentifier) {\n+    this.catalogName = catalogName;\n+    this.tableIdentifier = tableIdentifier;\n+    this.fileIO = fileIO;\n+    this.connections = dbConnPool;\n+  }\n+\n+  @Override\n+  public void doRefresh() {\n+    Map<String, String> table;\n+\n+    try {\n+      table = getTable();\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted during refresh\", e);\n+    } catch (SQLException e) {\n+      // unknown exception happened when getting table from catalog\n+      throw new UncheckedSQLException(\n+          String.format(\"Failed to get table %s from catalog %s\", tableIdentifier, catalogName), e);\n+    }\n+\n+    // Table not exists AND currentMetadataLocation is not NULL!\n+    if (table.isEmpty() && currentMetadataLocation() != null) {\n+      throw new NoSuchTableException(\"Failed to get table %s from catalog %s!\" +\n+          \" maybe another process deleted it!\", tableIdentifier, catalogName);\n+    }\n+\n+    // Table not exists in the catalog! metadataLocation is null here!\n+    if (table.isEmpty()) {\n+      refreshFromMetadataLocation(null);\n+      return;\n+    }\n+\n+    // Table exists but metadataLocation is null\n+    if (table.getOrDefault(\"metadata_location\", null) == null) {\n+      throw new RuntimeException(String.format(\"Failed to get metadata location of the table %s from catalog %s\",\n+          tableIdentifier, catalogName));\n+    }\n+\n+    refreshFromMetadataLocation(table.get(\"metadata_location\"));\n+  }\n+\n+  @Override\n+  public void doCommit(TableMetadata base, TableMetadata metadata) {\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+    try {\n+      Map<String, String> table = getTable();\n+\n+      if (!table.isEmpty()) {\n+        validateMetadataLocation(table, base);\n+        String oldMetadataLocation = base.metadataFileLocation();\n+        // Start atomic update\n+        updateTable(newMetadataLocation, oldMetadataLocation);\n+      } else {\n+        // table not exists create it!\n+        createTable(newMetadataLocation);\n+      }\n+\n+    } catch (SQLIntegrityConstraintViolationException e) {\n+      throw new AlreadyExistsException(e, \"Table already exists! maybe another process created it!\");\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(\"Database Connection timeout!\", e);\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(\"Database Connection failed!\", e);\n+    } catch (DataTruncation e) {\n+      throw new UncheckedSQLException(\"Database data truncation error!\", e);\n+    } catch (SQLWarning e) {\n+      throw new UncheckedSQLException(\"Database warning!\", e);\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(\"Failed to connect to database!\", e);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted during commit\", e);\n+    }\n+  }\n+\n+  private void updateTable(String newMetadataLocation, String oldMetadataLocation)\n+      throws SQLException, InterruptedException {\n+    int updatedRecords = connections.run(conn -> {\n+      try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.DO_COMMIT_SQL)) {\n+        // UPDATE\n+        sql.setString(1, newMetadataLocation);\n+        sql.setString(2, oldMetadataLocation);\n+        // WHERE\n+        sql.setString(3, catalogName);\n+        sql.setString(4, JdbcUtil.namespaceToString(tableIdentifier.namespace()));\n+        sql.setString(5, tableIdentifier.name());\n+        sql.setString(6, oldMetadataLocation);\n+        return sql.executeUpdate();\n+      }\n+    });\n+\n+    if (updatedRecords == 1) {\n+      LOG.debug(\"Successfully committed to existing table: {}\", tableIdentifier);\n+    } else {\n+      throw new CommitFailedException(\"Failed to commit the table %s from catalog %s! \" +\n+          \"Maybe another process changed it!\", tableIdentifier, catalogName);\n+    }\n+\n+  }\n+\n+  private void createTable(String newMetadataLocation) throws SQLException, InterruptedException {\n+    int insertRecord = connections.run(conn -> {\n+      try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.DO_COMMIT_CREATE_SQL)) {\n+        sql.setString(1, catalogName);\n+        sql.setString(2, JdbcUtil.namespaceToString(tableIdentifier.namespace()));\n+        sql.setString(3, tableIdentifier.name());\n+        sql.setString(4, newMetadataLocation);\n+        return sql.executeUpdate();\n+      }\n+    });\n+\n+    if (insertRecord == 1) {\n+      LOG.debug(\"Successfully committed to new table: {}\", tableIdentifier);\n+    } else {\n+      throw new CommitFailedException(\"Failed to commit the table %s from catalog %s\", tableIdentifier, catalogName);", "originalCommit": "e1cee5e8b26fdebae8b0e423ce9430b6bad5165c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzA0NTg2Mw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r557045863", "bodyText": "these column names should all be static variables in JdbcUtil", "author": "jackye1995", "createdAt": "2021-01-14T05:04:37Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcTableOperations.java", "diffHunk": "@@ -0,0 +1,218 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.sql.DataTruncation;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Map;\n+import java.util.Objects;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+class JdbcTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcTableOperations.class);\n+  private final String catalogName;\n+  private final TableIdentifier tableIdentifier;\n+  private final FileIO fileIO;\n+  private final JdbcClientPool connections;\n+\n+  protected JdbcTableOperations(JdbcClientPool dbConnPool, FileIO fileIO, String catalogName,\n+                                TableIdentifier tableIdentifier) {\n+    this.catalogName = catalogName;\n+    this.tableIdentifier = tableIdentifier;\n+    this.fileIO = fileIO;\n+    this.connections = dbConnPool;\n+  }\n+\n+  @Override\n+  public void doRefresh() {\n+    Map<String, String> table;\n+\n+    try {\n+      table = getTable();\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted during refresh\", e);\n+    } catch (SQLException e) {\n+      // unknown exception happened when getting table from catalog\n+      throw new UncheckedSQLException(\n+          String.format(\"Failed to get table %s from catalog %s\", tableIdentifier, catalogName), e);\n+    }\n+\n+    // Table not exists AND currentMetadataLocation is not NULL!\n+    if (table.isEmpty() && currentMetadataLocation() != null) {\n+      throw new NoSuchTableException(\"Failed to get table %s from catalog %s!\" +\n+          \" maybe another process deleted it!\", tableIdentifier, catalogName);\n+    }\n+\n+    // Table not exists in the catalog! metadataLocation is null here!\n+    if (table.isEmpty()) {\n+      refreshFromMetadataLocation(null);\n+      return;\n+    }\n+\n+    // Table exists but metadataLocation is null\n+    if (table.getOrDefault(\"metadata_location\", null) == null) {\n+      throw new RuntimeException(String.format(\"Failed to get metadata location of the table %s from catalog %s\",\n+          tableIdentifier, catalogName));\n+    }\n+\n+    refreshFromMetadataLocation(table.get(\"metadata_location\"));\n+  }\n+\n+  @Override\n+  public void doCommit(TableMetadata base, TableMetadata metadata) {\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+    try {\n+      Map<String, String> table = getTable();\n+\n+      if (!table.isEmpty()) {\n+        validateMetadataLocation(table, base);\n+        String oldMetadataLocation = base.metadataFileLocation();\n+        // Start atomic update\n+        updateTable(newMetadataLocation, oldMetadataLocation);\n+      } else {\n+        // table not exists create it!\n+        createTable(newMetadataLocation);\n+      }\n+\n+    } catch (SQLIntegrityConstraintViolationException e) {\n+      throw new AlreadyExistsException(e, \"Table already exists! maybe another process created it!\");\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(\"Database Connection timeout!\", e);\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(\"Database Connection failed!\", e);\n+    } catch (DataTruncation e) {\n+      throw new UncheckedSQLException(\"Database data truncation error!\", e);\n+    } catch (SQLWarning e) {\n+      throw new UncheckedSQLException(\"Database warning!\", e);\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(\"Failed to connect to database!\", e);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted during commit\", e);\n+    }\n+  }\n+\n+  private void updateTable(String newMetadataLocation, String oldMetadataLocation)\n+      throws SQLException, InterruptedException {\n+    int updatedRecords = connections.run(conn -> {\n+      try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.DO_COMMIT_SQL)) {\n+        // UPDATE\n+        sql.setString(1, newMetadataLocation);\n+        sql.setString(2, oldMetadataLocation);\n+        // WHERE\n+        sql.setString(3, catalogName);\n+        sql.setString(4, JdbcUtil.namespaceToString(tableIdentifier.namespace()));\n+        sql.setString(5, tableIdentifier.name());\n+        sql.setString(6, oldMetadataLocation);\n+        return sql.executeUpdate();\n+      }\n+    });\n+\n+    if (updatedRecords == 1) {\n+      LOG.debug(\"Successfully committed to existing table: {}\", tableIdentifier);\n+    } else {\n+      throw new CommitFailedException(\"Failed to commit the table %s from catalog %s! \" +\n+          \"Maybe another process changed it!\", tableIdentifier, catalogName);\n+    }\n+\n+  }\n+\n+  private void createTable(String newMetadataLocation) throws SQLException, InterruptedException {\n+    int insertRecord = connections.run(conn -> {\n+      try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.DO_COMMIT_CREATE_SQL)) {\n+        sql.setString(1, catalogName);\n+        sql.setString(2, JdbcUtil.namespaceToString(tableIdentifier.namespace()));\n+        sql.setString(3, tableIdentifier.name());\n+        sql.setString(4, newMetadataLocation);\n+        return sql.executeUpdate();\n+      }\n+    });\n+\n+    if (insertRecord == 1) {\n+      LOG.debug(\"Successfully committed to new table: {}\", tableIdentifier);\n+    } else {\n+      throw new CommitFailedException(\"Failed to commit the table %s from catalog %s\", tableIdentifier, catalogName);\n+    }\n+  }\n+\n+  private void validateMetadataLocation(Map<String, String> table, TableMetadata base) {\n+    String catalogMetadataLocation = !table.isEmpty() ? table.get(\"metadata_location\") : null;\n+    String baseMetadataLocation = base != null ? base.metadataFileLocation() : null;\n+\n+    if (!Objects.equals(baseMetadataLocation, catalogMetadataLocation)) {\n+      throw new CommitFailedException(\n+          \"Cannot commit %s because base metadata location '%s' is not same as the current Catalog location '%s'\",\n+          tableIdentifier, baseMetadataLocation, catalogMetadataLocation);\n+    }\n+  }\n+\n+  @Override\n+  public FileIO io() {\n+    return fileIO;\n+  }\n+\n+  @Override\n+  protected String tableName() {\n+    return tableIdentifier.toString();\n+  }\n+\n+  private Map<String, String> getTable() throws UncheckedSQLException, SQLException, InterruptedException {\n+    return connections.run(conn -> {\n+      Map<String, String> table = Maps.newHashMap();\n+\n+      try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.LOAD_TABLE_SQL)) {\n+        sql.setString(1, catalogName);\n+        sql.setString(2, JdbcUtil.namespaceToString(tableIdentifier.namespace()));\n+        sql.setString(3, tableIdentifier.name());\n+        ResultSet rs = sql.executeQuery();\n+\n+        if (rs.next()) {\n+          table.put(\"catalog_name\", rs.getString(\"catalog_name\"));", "originalCommit": "e1cee5e8b26fdebae8b0e423ce9430b6bad5165c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU3OTk3MQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r557579971", "bodyText": "nit: fail to update the table", "author": "jackye1995", "createdAt": "2021-01-14T17:48:30Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcTableOperations.java", "diffHunk": "@@ -0,0 +1,219 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.sql.DataTruncation;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.sql.SQLWarning;\n+import java.util.Map;\n+import java.util.Objects;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+class JdbcTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcTableOperations.class);\n+  private final String catalogName;\n+  private final TableIdentifier tableIdentifier;\n+  private final FileIO fileIO;\n+  private final JdbcClientPool connections;\n+\n+  protected JdbcTableOperations(JdbcClientPool dbConnPool, FileIO fileIO, String catalogName,\n+                                TableIdentifier tableIdentifier) {\n+    this.catalogName = catalogName;\n+    this.tableIdentifier = tableIdentifier;\n+    this.fileIO = fileIO;\n+    this.connections = dbConnPool;\n+  }\n+\n+  @Override\n+  public void doRefresh() {\n+    Map<String, String> table;\n+\n+    try {\n+      table = getTable();\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted during refresh\", e);\n+    } catch (SQLException e) {\n+      // unknown exception happened when getting table from catalog\n+      throw new UncheckedSQLException(\n+          String.format(\"Failed to get table %s from catalog %s\", tableIdentifier, catalogName), e);\n+    }\n+\n+    // Table not exists AND currentMetadataLocation is not NULL!\n+    if (table.isEmpty() && currentMetadataLocation() != null) {\n+      throw new NoSuchTableException(\"Failed to get table %s from catalog %s!\" +\n+          \" maybe another process deleted it!\", tableIdentifier, catalogName);\n+    }\n+\n+    // Table not exists in the catalog! metadataLocation is null here!\n+    if (table.isEmpty()) {\n+      refreshFromMetadataLocation(null);\n+      return;\n+    }\n+\n+    // Table exists but metadataLocation is null\n+    if (table.getOrDefault(JdbcUtil.METADATA_LOCATION, null) == null) {\n+      throw new RuntimeException(String.format(\"Failed to get metadata location of the table %s from catalog %s\",\n+          tableIdentifier, catalogName));\n+    }\n+\n+    refreshFromMetadataLocation(table.get(JdbcUtil.METADATA_LOCATION));\n+  }\n+\n+  @Override\n+  public void doCommit(TableMetadata base, TableMetadata metadata) {\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+    try {\n+      Map<String, String> table = getTable();\n+\n+      if (!table.isEmpty()) {\n+        validateMetadataLocation(table, base);\n+        String oldMetadataLocation = base.metadataFileLocation();\n+        // Start atomic update\n+        updateTable(newMetadataLocation, oldMetadataLocation);\n+      } else {\n+        // table not exists create it!\n+        createTable(newMetadataLocation);\n+      }\n+\n+    } catch (SQLIntegrityConstraintViolationException e) {\n+      throw new AlreadyExistsException(e, \"Table already exists! maybe another process created it!\");\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(\"Database Connection timeout!\", e);\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(\"Database Connection failed!\", e);\n+    } catch (DataTruncation e) {\n+      throw new UncheckedSQLException(\"Database data truncation error!\", e);\n+    } catch (SQLWarning e) {\n+      throw new UncheckedSQLException(\"Database warning!\", e);\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(\"Failed to connect to database!\", e);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted during commit\", e);\n+    }\n+  }\n+\n+  private void updateTable(String newMetadataLocation, String oldMetadataLocation)\n+      throws SQLException, InterruptedException {\n+    int updatedRecords = connections.run(conn -> {\n+      try (PreparedStatement sql = conn.prepareStatement(JdbcUtil.DO_COMMIT_SQL)) {\n+        // UPDATE\n+        sql.setString(1, newMetadataLocation);\n+        sql.setString(2, oldMetadataLocation);\n+        // WHERE\n+        sql.setString(3, catalogName);\n+        sql.setString(4, JdbcUtil.namespaceToString(tableIdentifier.namespace()));\n+        sql.setString(5, tableIdentifier.name());\n+        sql.setString(6, oldMetadataLocation);\n+        return sql.executeUpdate();\n+      }\n+    });\n+\n+    if (updatedRecords == 1) {\n+      LOG.debug(\"Successfully committed to existing table: {}\", tableIdentifier);\n+    } else {\n+      throw new CommitFailedException(\"Failed to commit the table %s from catalog %s! \" +", "originalCommit": "5eeb6941ea2d5c31d54231c706107edfe7a59c48", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4MDQzMw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r557580433", "bodyText": "nit: space after if", "author": "jackye1995", "createdAt": "2021-01-14T17:49:13Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,403 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.HIVE_URI, \"\").isEmpty(),\n+        \"No connection url provided for jdbc catalog!\");\n+\n+    this.warehouseLocation = properties.getOrDefault(CatalogProperties.WAREHOUSE_LOCATION, \"\")\n+        .replaceAll(\"/$\", \"\");\n+    Preconditions.checkArgument(!warehouseLocation.isEmpty(),\n+        \"Cannot initialize Jdbc Catalog because warehousePath must not be null!\");\n+\n+    if (name != null) {\n+      this.catalogName = name;\n+    }", "originalCommit": "5eeb6941ea2d5c31d54231c706107edfe7a59c48", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzYwMzEwNw==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r557603107", "bodyText": "nit: since we removed lower case part, there is not need to have upper in the variable names, and no need to use JdbcUtil.CATALOG_TABLE_NAME.toUpperCase()", "author": "jackye1995", "createdAt": "2021-01-14T18:28:10Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,403 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.HIVE_URI, \"\").isEmpty(),\n+        \"No connection url provided for jdbc catalog!\");\n+\n+    this.warehouseLocation = properties.getOrDefault(CatalogProperties.WAREHOUSE_LOCATION, \"\")\n+        .replaceAll(\"/$\", \"\");\n+    Preconditions.checkArgument(!warehouseLocation.isEmpty(),\n+        \"Cannot initialize Jdbc Catalog because warehousePath must not be null!\");\n+\n+    if (name != null) {\n+      this.catalogName = name;\n+    }\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.io = fileIOImpl == null ?\n+        new HadoopFileIO(conf) :\n+        CatalogUtil.loadFileIO(fileIOImpl, properties, conf);\n+\n+    try {\n+      initializeConnection(properties);\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(\"Database Connection timeout!\", e);\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(\"Database Connection failed!\", e);\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(\"Failed to initialize catalog!\", e);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to initialize!\", e);\n+    }\n+  }\n+\n+  private void initializeConnection(Map<String, String> properties) throws SQLException, InterruptedException {\n+    LOG.debug(\"Connecting to Jdbc database {}\", properties.get(CatalogProperties.HIVE_URI));\n+    connections = new JdbcClientPool(properties.get(CatalogProperties.HIVE_URI), properties);\n+    initializeCatalogTables();\n+  }\n+\n+  private void initializeCatalogTables() throws InterruptedException, SQLException {\n+    connections.run(conn -> {\n+      boolean catalogTableExists = false;\n+      DatabaseMetaData dbMeta = conn.getMetaData();\n+      ResultSet tablesUpper = dbMeta.getTables(null, null, JdbcUtil.CATALOG_TABLE_NAME.toUpperCase(), null);", "originalCommit": "5eeb6941ea2d5c31d54231c706107edfe7a59c48", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzYwNTA3OQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r557605079", "bodyText": "no need to be public", "author": "jackye1995", "createdAt": "2021-01-14T18:31:38Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcUtil.java", "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Splitter;\n+import org.apache.iceberg.relocated.com.google.common.collect.Iterables;\n+\n+public final class JdbcUtil {", "originalCommit": "5eeb6941ea2d5c31d54231c706107edfe7a59c48", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "420633629ec20b6f68cf339529ac608668444437", "url": "https://github.com/apache/iceberg/commit/420633629ec20b6f68cf339529ac608668444437", "message": "update HIVE_URI to URI", "committedDate": "2021-01-21T08:32:16Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjI5OTU4NA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r562299584", "bodyText": "This mixes together two separate problems. First, the URI is required so it must be non-null in the map. Second, the URI must be valid. This uses isEmpty to check both, but that's not sufficient to know it is a valid URI, and hides when the URI is not set.\nI think this should check that the URI is non-null and leave the validity check to the JDBC driver. Then this error message can be more specific:\nString uri = properties.get(CatalogProperties.URI);\nPreconditions.checkNotNull(uri, \"JDBC connection URI is required\");", "author": "rdblue", "createdAt": "2021-01-22T00:57:45Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,404 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.URI, \"\").isEmpty(),\n+        \"No connection url provided for jdbc catalog!\");", "originalCommit": "f7bc654216a7c30752feb49825ed3a35f0ca6a51", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjMwMDAxMQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r562300011", "bodyText": "This should also not mix together cases where the warehouse location is missing vs invalid.\nCan you update it to this?\nString warehouse = properties.get(CatalogProperties.WAREHOUSE_LOCATION);\nPreconditions.checkNotNull(warehouse, \"JDBC warehouse location is required\");\nthis.warehouseLocation = warehouse.replaceAll(\"/$\", \"\");", "author": "rdblue", "createdAt": "2021-01-22T00:59:11Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,404 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.URI, \"\").isEmpty(),\n+        \"No connection url provided for jdbc catalog!\");\n+\n+    this.warehouseLocation = properties.getOrDefault(CatalogProperties.WAREHOUSE_LOCATION, \"\")\n+        .replaceAll(\"/$\", \"\");\n+    Preconditions.checkArgument(!warehouseLocation.isEmpty(),\n+        \"Cannot initialize Jdbc Catalog because warehousePath must not be null!\");", "originalCommit": "f7bc654216a7c30752feb49825ed3a35f0ca6a51", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjMwMDIwOA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r562300208", "bodyText": "Error messages should not end in !", "author": "rdblue", "createdAt": "2021-01-22T00:59:49Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,404 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.URI, \"\").isEmpty(),\n+        \"No connection url provided for jdbc catalog!\");\n+\n+    this.warehouseLocation = properties.getOrDefault(CatalogProperties.WAREHOUSE_LOCATION, \"\")\n+        .replaceAll(\"/$\", \"\");\n+    Preconditions.checkArgument(!warehouseLocation.isEmpty(),\n+        \"Cannot initialize Jdbc Catalog because warehousePath must not be null!\");\n+\n+    if (name != null) {\n+      this.catalogName = name;\n+    }\n+\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.io = fileIOImpl == null ?\n+        new HadoopFileIO(conf) :\n+        CatalogUtil.loadFileIO(fileIOImpl, properties, conf);\n+\n+    try {\n+      initializeConnection(properties);\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(\"Database Connection timeout!\", e);", "originalCommit": "f7bc654216a7c30752feb49825ed3a35f0ca6a51", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjMwMDQ3Ng==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r562300476", "bodyText": "I don't think it is necessary to pass all of the properties here. Just the URI, right?", "author": "rdblue", "createdAt": "2021-01-22T01:00:37Z", "path": "core/src/main/java/org/apache/iceberg/jdbc/JdbcCatalog.java", "diffHunk": "@@ -0,0 +1,404 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.jdbc;\n+\n+import java.io.Closeable;\n+import java.sql.DatabaseMetaData;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.SQLIntegrityConstraintViolationException;\n+import java.sql.SQLNonTransientConnectionException;\n+import java.sql.SQLTimeoutException;\n+import java.sql.SQLTransientConnectionException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class JdbcCatalog extends BaseMetastoreCatalog implements Configurable, SupportsNamespaces, Closeable {\n+\n+  public static final String PROPERTY_PREFIX = \"connection.parameter.\";\n+  private static final Logger LOG = LoggerFactory.getLogger(JdbcCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+\n+  private FileIO io;\n+  private String catalogName = \"jdbc\";\n+  private String warehouseLocation;\n+  private Configuration conf;\n+  private JdbcClientPool connections;\n+\n+  public JdbcCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String name, Map<String, String> properties) {\n+    Preconditions.checkArgument(!properties.getOrDefault(CatalogProperties.URI, \"\").isEmpty(),\n+        \"No connection url provided for jdbc catalog!\");\n+\n+    this.warehouseLocation = properties.getOrDefault(CatalogProperties.WAREHOUSE_LOCATION, \"\")\n+        .replaceAll(\"/$\", \"\");\n+    Preconditions.checkArgument(!warehouseLocation.isEmpty(),\n+        \"Cannot initialize Jdbc Catalog because warehousePath must not be null!\");\n+\n+    if (name != null) {\n+      this.catalogName = name;\n+    }\n+\n+    String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n+    this.io = fileIOImpl == null ?\n+        new HadoopFileIO(conf) :\n+        CatalogUtil.loadFileIO(fileIOImpl, properties, conf);\n+\n+    try {\n+      initializeConnection(properties);\n+    } catch (SQLTimeoutException e) {\n+      throw new UncheckedSQLException(\"Database Connection timeout!\", e);\n+    } catch (SQLTransientConnectionException | SQLNonTransientConnectionException e) {\n+      throw new UncheckedSQLException(\"Database Connection failed!\", e);\n+    } catch (SQLException e) {\n+      throw new UncheckedSQLException(\"Failed to initialize catalog!\", e);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new RuntimeException(\"Interrupted in call to initialize!\", e);\n+    }\n+  }\n+\n+  private void initializeConnection(Map<String, String> properties) throws SQLException, InterruptedException {", "originalCommit": "f7bc654216a7c30752feb49825ed3a35f0ca6a51", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjkxMzA5OA==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r562913098", "bodyText": "important parameters passed with properties are clients pool size and username password. except client pool size all other db parameters could be passed by uri .", "author": "ismailsimsek", "createdAt": "2021-01-22T21:11:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjMwMDQ3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjkxNzI5OQ==", "url": "https://github.com/apache/iceberg/pull/1870#discussion_r562917299", "bodyText": "moved this section to initialize seems to its too small to be separate", "author": "ismailsimsek", "createdAt": "2021-01-22T21:20:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjMwMDQ3Ng=="}], "type": "inlineReview"}, {"oid": "4fa1449c9305221988b763733d6fc1488052eab7", "url": "https://github.com/apache/iceberg/commit/4fa1449c9305221988b763733d6fc1488052eab7", "message": "moved initializeConnection to initialize", "committedDate": "2021-01-29T22:14:14Z", "type": "forcePushed"}, {"oid": "db4cb06f1a141a0bd0d9a0f96ea705e2b45a6988", "url": "https://github.com/apache/iceberg/commit/db4cb06f1a141a0bd0d9a0f96ea705e2b45a6988", "message": "move TestClientPool hive tests to TestHiveClientPool", "committedDate": "2021-02-13T11:46:38Z", "type": "forcePushed"}, {"oid": "7b4a736a90123595de5a02fe3e0a334d1a1eeeb3", "url": "https://github.com/apache/iceberg/commit/7b4a736a90123595de5a02fe3e0a334d1a1eeeb3", "message": "move ClientPoolImpl to core", "committedDate": "2021-04-05T18:26:04Z", "type": "forcePushed"}, {"oid": "2e4769578a9f0868e896aca4137dbc73657b8ad9", "url": "https://github.com/apache/iceberg/commit/2e4769578a9f0868e896aca4137dbc73657b8ad9", "message": "jdbc catalog\n\naddress review comments\n\nmore cleanup\n\ntest rollback scenario with renameTable\n\nfix\n\ncleanup\n\ncleanup, removed fs, create empty constructor and updated initialization\n\nfix unittest\n\nadded jdbc catalog to SparkCatalog and added tests to TestRemoveOrphanFilesAction3\n\nadded new test\n\nfix naming\n\ndo updates inside transaction and rollback updates if it fails.\n\nensure target namespace is exists before renaming table\n\nfix scope, revert license changes\n\njdbc catalog", "committedDate": "2021-04-18T06:56:41Z", "type": "commit"}, {"oid": "49382464569aff7f9e3097f90dc500473db20206", "url": "https://github.com/apache/iceberg/commit/49382464569aff7f9e3097f90dc500473db20206", "message": "address review comments", "committedDate": "2021-04-18T06:56:41Z", "type": "commit"}, {"oid": "0c507843783b04e67ac182540e5891b73a087d3f", "url": "https://github.com/apache/iceberg/commit/0c507843783b04e67ac182540e5891b73a087d3f", "message": "address review comments", "committedDate": "2021-04-18T06:56:41Z", "type": "commit"}, {"oid": "3fb7f6a8d89f8e2928b65f452e4f852d369f874d", "url": "https://github.com/apache/iceberg/commit/3fb7f6a8d89f8e2928b65f452e4f852d369f874d", "message": "address review comments", "committedDate": "2021-04-18T06:56:41Z", "type": "commit"}, {"oid": "61b921331bf8755685d544d91d4a1096d3ec8adf", "url": "https://github.com/apache/iceberg/commit/61b921331bf8755685d544d91d4a1096d3ec8adf", "message": "address review comments\n\naddress review comments", "committedDate": "2021-04-18T06:56:41Z", "type": "commit"}, {"oid": "33524d6846bc83e0f1fd254613f4dc270d4953c9", "url": "https://github.com/apache/iceberg/commit/33524d6846bc83e0f1fd254613f4dc270d4953c9", "message": "address review comments\n\naddress review comments", "committedDate": "2021-04-18T06:56:41Z", "type": "commit"}, {"oid": "fce1a8fcd89b4c417d3af1095f269f28cfe1ca17", "url": "https://github.com/apache/iceberg/commit/fce1a8fcd89b4c417d3af1095f269f28cfe1ca17", "message": "jdbc catalog duplicate concurrent test from hive", "committedDate": "2021-04-18T06:56:41Z", "type": "commit"}, {"oid": "40163066f42a9f64d2df77fd84e638f369ea5066", "url": "https://github.com/apache/iceberg/commit/40163066f42a9f64d2df77fd84e638f369ea5066", "message": "capture specific sql exceptions", "committedDate": "2021-04-18T06:56:41Z", "type": "commit"}, {"oid": "9bd2e474a25de4c8cf07d98eaa4ce5fe10e7f715", "url": "https://github.com/apache/iceberg/commit/9bd2e474a25de4c8cf07d98eaa4ce5fe10e7f715", "message": "extent UncheckedSQLException from UncheckedIOException", "committedDate": "2021-04-18T06:56:41Z", "type": "commit"}, {"oid": "60fafc3ab4fead0af10a3152ac08f773312412c1", "url": "https://github.com/apache/iceberg/commit/60fafc3ab4fead0af10a3152ac08f773312412c1", "message": "review fixes\n\nreview fixes\n\nreview fixes", "committedDate": "2021-04-18T06:56:42Z", "type": "commit"}, {"oid": "af3937ea443ee3a3f6db701f7aaba2203fa7bdff", "url": "https://github.com/apache/iceberg/commit/af3937ea443ee3a3f6db701f7aaba2203fa7bdff", "message": "update spark3 catalog change", "committedDate": "2021-04-18T06:56:42Z", "type": "commit"}, {"oid": "ef240b2087b37c70a4e4ec6643d08b95ce24aa6f", "url": "https://github.com/apache/iceberg/commit/ef240b2087b37c70a4e4ec6643d08b95ce24aa6f", "message": "fix catalog class name", "committedDate": "2021-04-18T06:56:42Z", "type": "commit"}, {"oid": "5386846207d96c5067c8e139fc9423da50ec9b38", "url": "https://github.com/apache/iceberg/commit/5386846207d96c5067c8e139fc9423da50ec9b38", "message": "review updates", "committedDate": "2021-04-18T06:56:42Z", "type": "commit"}, {"oid": "a0d6f9497a6253dd07dc79f1600f84aadcf25e4d", "url": "https://github.com/apache/iceberg/commit/a0d6f9497a6253dd07dc79f1600f84aadcf25e4d", "message": "add method defaultNamespaceLocation(namespace)", "committedDate": "2021-04-18T06:56:42Z", "type": "commit"}, {"oid": "aaea91cdd45414d49613dafe4cb10869ffd36502", "url": "https://github.com/apache/iceberg/commit/aaea91cdd45414d49613dafe4cb10869ffd36502", "message": "move sql statements to JdbcUtil", "committedDate": "2021-04-18T06:56:42Z", "type": "commit"}, {"oid": "428e57a5f1e4c00e811d500a36665222b97866f5", "url": "https://github.com/apache/iceberg/commit/428e57a5f1e4c00e811d500a36665222b97866f5", "message": "use protected for sql constants", "committedDate": "2021-04-18T06:56:42Z", "type": "commit"}, {"oid": "7ac78fa0ed1a732e5dda152030ace826903fdfbf", "url": "https://github.com/apache/iceberg/commit/7ac78fa0ed1a732e5dda152030ace826903fdfbf", "message": "address review notes", "committedDate": "2021-04-18T06:56:42Z", "type": "commit"}, {"oid": "699047429aa823bf0390857b47ee7c5bd1d49b1e", "url": "https://github.com/apache/iceberg/commit/699047429aa823bf0390857b47ee7c5bd1d49b1e", "message": "moved UncheckedSQLException to org.apache.iceberg.jdbc", "committedDate": "2021-04-18T06:56:42Z", "type": "commit"}, {"oid": "9d68634cf2656cdf52757bde1a2e6793e4c476cc", "url": "https://github.com/apache/iceberg/commit/9d68634cf2656cdf52757bde1a2e6793e4c476cc", "message": "update messages", "committedDate": "2021-04-18T06:56:42Z", "type": "commit"}, {"oid": "1a17053ab7fa6217dd278ade9e10d0060ec8e82d", "url": "https://github.com/apache/iceberg/commit/1a17053ab7fa6217dd278ade9e10d0060ec8e82d", "message": "use sqlite-jdbc for tests", "committedDate": "2021-04-18T06:56:42Z", "type": "commit"}]}