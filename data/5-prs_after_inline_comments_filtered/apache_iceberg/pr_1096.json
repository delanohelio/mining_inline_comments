{"pr_number": 1096, "pr_title": "Add flink data type convertor to convert data types between iceberg data type and flink data type.", "pr_createdAt": "2020-06-05T04:04:51Z", "pr_url": "https://github.com/apache/iceberg/pull/1096", "timeline": [{"oid": "9a9fafe929928fc1104f21488188f0de2679c757", "url": "https://github.com/apache/iceberg/commit/9a9fafe929928fc1104f21488188f0de2679c757", "message": "Add flink data type convertor to convert data types between iceberg data type and flink data type.", "committedDate": "2020-06-05T04:03:53Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAyOTM4Mg==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436029382", "bodyText": "Style: we like to have an empty line after control flow statements like the one above. Looks like we missed this in the original copy of this code.", "author": "rdblue", "createdAt": "2020-06-05T16:24:23Z", "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkSchemaUtil.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.types.CheckCompatibility;\n+import org.apache.iceberg.types.Type;\n+\n+public class FlinkSchemaUtil {\n+\n+  private FlinkSchemaUtil() {\n+  }\n+\n+  public static Schema convert(TableSchema flinkSchema) {\n+    FieldsDataType root = (FieldsDataType) flinkSchema.toRowDataType();\n+    Type converted = FlinkTypeVisitor.visit(root, new FlinkTypeToType(root));\n+    return new Schema(converted.asNestedType().asStructType().fields());\n+  }\n+\n+  static void validate(Schema readSchema, Schema writeSchema, boolean checkNullability, boolean checkOrdering) {\n+    List<String> errors;\n+    if (checkNullability) {\n+      errors = CheckCompatibility.writeCompatibilityErrors(readSchema, writeSchema, checkOrdering);\n+    } else {\n+      errors = CheckCompatibility.typeCompatibilityErrors(readSchema, writeSchema, checkOrdering);\n+    }\n+    if (!errors.isEmpty()) {", "originalCommit": "9a9fafe929928fc1104f21488188f0de2679c757", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzMDU4MQ==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436030581", "bodyText": "This looks identical to the one in Spark. Can we move this into a helper class so we don't duplicate the code?", "author": "rdblue", "createdAt": "2020-06-05T16:26:39Z", "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkSchemaUtil.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.types.CheckCompatibility;\n+import org.apache.iceberg.types.Type;\n+\n+public class FlinkSchemaUtil {\n+\n+  private FlinkSchemaUtil() {\n+  }\n+\n+  public static Schema convert(TableSchema flinkSchema) {\n+    FieldsDataType root = (FieldsDataType) flinkSchema.toRowDataType();\n+    Type converted = FlinkTypeVisitor.visit(root, new FlinkTypeToType(root));\n+    return new Schema(converted.asNestedType().asStructType().fields());\n+  }\n+\n+  static void validate(Schema readSchema, Schema writeSchema, boolean checkNullability, boolean checkOrdering) {", "originalCommit": "9a9fafe929928fc1104f21488188f0de2679c757", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzMTMzMA==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436031330", "bodyText": "Is BinaryType a fixed-length binary? If so, it should be FixedType instead.", "author": "rdblue", "createdAt": "2020-06-05T16:28:09Z", "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeToType.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.BinaryType;\n+import org.apache.flink.table.types.logical.BooleanType;\n+import org.apache.flink.table.types.logical.CharType;\n+import org.apache.flink.table.types.logical.DateType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.DoubleType;\n+import org.apache.flink.table.types.logical.FloatType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.table.types.logical.VarBinaryType;\n+import org.apache.flink.table.types.logical.VarCharType;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+public class FlinkTypeToType extends FlinkTypeVisitor<Type> {\n+  private final FieldsDataType root;\n+  private int nextId = 0;\n+\n+  FlinkTypeToType(FieldsDataType root) {\n+    this.root = root;\n+    // the root struct's fields use the first ids\n+    this.nextId = root.getFieldDataTypes().size();\n+  }\n+\n+  private int getNextId() {\n+    int next = nextId;\n+    nextId += 1;\n+    return next;\n+  }\n+\n+  @Override\n+  public Type fields(FieldsDataType dataType, Map<String, Tuple2<String, Type>> types) {\n+    List<Types.NestedField> newFields = Lists.newArrayListWithExpectedSize(types.size());\n+    boolean isRoot = root == dataType;\n+\n+    Map<String, DataType> fieldsMap = dataType.getFieldDataTypes();\n+    int index = 0;\n+    for (String name : types.keySet()) {\n+      assert fieldsMap.containsKey(name);\n+      DataType field = fieldsMap.get(name);\n+      Tuple2<String, Type> tuple2 = types.get(name);\n+\n+      int id = isRoot ? index : getNextId();\n+      if (field.getLogicalType().isNullable()) {\n+        newFields.add(Types.NestedField.optional(id, name, tuple2.f1, tuple2.f0));\n+      } else {\n+        newFields.add(Types.NestedField.required(id, name, tuple2.f1, tuple2.f0));\n+      }\n+      index++;\n+    }\n+    return Types.StructType.of(newFields);\n+  }\n+\n+  @Override\n+  public Type collection(CollectionDataType collection, Type elementType) {\n+    if (collection.getElementDataType().getLogicalType().isNullable()) {\n+      return Types.ListType.ofOptional(getNextId(), elementType);\n+    } else {\n+      return Types.ListType.ofRequired(getNextId(), elementType);\n+    }\n+  }\n+\n+  @Override\n+  public Type map(KeyValueDataType map, Type keyType, Type valueType) {\n+    if (map.getValueDataType().getLogicalType().isNullable()) {\n+      return Types.MapType.ofOptional(getNextId(), getNextId(), keyType, valueType);\n+    } else {\n+      return Types.MapType.ofRequired(getNextId(), getNextId(), keyType, valueType);\n+    }\n+  }\n+\n+  @SuppressWarnings(\"checkstyle:CyclomaticComplexity\")\n+  @Override\n+  public Type atomic(AtomicDataType type) {\n+    LogicalType inner = type.getLogicalType();\n+    if (inner instanceof VarCharType ||\n+        inner instanceof CharType) {\n+      return Types.StringType.get();\n+    } else if (inner instanceof BooleanType) {\n+      return Types.BooleanType.get();\n+    } else if (inner instanceof IntType ||\n+        inner instanceof SmallIntType ||\n+        inner instanceof TinyIntType) {\n+      return Types.IntegerType.get();\n+    } else if (inner instanceof BigIntType) {\n+      return Types.LongType.get();\n+    } else if (inner instanceof VarBinaryType ||\n+        inner instanceof BinaryType) {", "originalCommit": "9a9fafe929928fc1104f21488188f0de2679c757", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQzNzU0NA==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436437544", "bodyText": "Thanks for the reminding, will fix this and provide a unit test to address it. Thanks.", "author": "openinx", "createdAt": "2020-06-08T03:05:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzMTMzMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzMTUwMQ==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436031501", "bodyText": "Flink doesn't support TIMESTAMP WITHOUT TIME ZONE?", "author": "rdblue", "createdAt": "2020-06-05T16:28:28Z", "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeToType.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.BinaryType;\n+import org.apache.flink.table.types.logical.BooleanType;\n+import org.apache.flink.table.types.logical.CharType;\n+import org.apache.flink.table.types.logical.DateType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.DoubleType;\n+import org.apache.flink.table.types.logical.FloatType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.table.types.logical.VarBinaryType;\n+import org.apache.flink.table.types.logical.VarCharType;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+public class FlinkTypeToType extends FlinkTypeVisitor<Type> {\n+  private final FieldsDataType root;\n+  private int nextId = 0;\n+\n+  FlinkTypeToType(FieldsDataType root) {\n+    this.root = root;\n+    // the root struct's fields use the first ids\n+    this.nextId = root.getFieldDataTypes().size();\n+  }\n+\n+  private int getNextId() {\n+    int next = nextId;\n+    nextId += 1;\n+    return next;\n+  }\n+\n+  @Override\n+  public Type fields(FieldsDataType dataType, Map<String, Tuple2<String, Type>> types) {\n+    List<Types.NestedField> newFields = Lists.newArrayListWithExpectedSize(types.size());\n+    boolean isRoot = root == dataType;\n+\n+    Map<String, DataType> fieldsMap = dataType.getFieldDataTypes();\n+    int index = 0;\n+    for (String name : types.keySet()) {\n+      assert fieldsMap.containsKey(name);\n+      DataType field = fieldsMap.get(name);\n+      Tuple2<String, Type> tuple2 = types.get(name);\n+\n+      int id = isRoot ? index : getNextId();\n+      if (field.getLogicalType().isNullable()) {\n+        newFields.add(Types.NestedField.optional(id, name, tuple2.f1, tuple2.f0));\n+      } else {\n+        newFields.add(Types.NestedField.required(id, name, tuple2.f1, tuple2.f0));\n+      }\n+      index++;\n+    }\n+    return Types.StructType.of(newFields);\n+  }\n+\n+  @Override\n+  public Type collection(CollectionDataType collection, Type elementType) {\n+    if (collection.getElementDataType().getLogicalType().isNullable()) {\n+      return Types.ListType.ofOptional(getNextId(), elementType);\n+    } else {\n+      return Types.ListType.ofRequired(getNextId(), elementType);\n+    }\n+  }\n+\n+  @Override\n+  public Type map(KeyValueDataType map, Type keyType, Type valueType) {\n+    if (map.getValueDataType().getLogicalType().isNullable()) {\n+      return Types.MapType.ofOptional(getNextId(), getNextId(), keyType, valueType);\n+    } else {\n+      return Types.MapType.ofRequired(getNextId(), getNextId(), keyType, valueType);\n+    }\n+  }\n+\n+  @SuppressWarnings(\"checkstyle:CyclomaticComplexity\")\n+  @Override\n+  public Type atomic(AtomicDataType type) {\n+    LogicalType inner = type.getLogicalType();\n+    if (inner instanceof VarCharType ||\n+        inner instanceof CharType) {\n+      return Types.StringType.get();\n+    } else if (inner instanceof BooleanType) {\n+      return Types.BooleanType.get();\n+    } else if (inner instanceof IntType ||\n+        inner instanceof SmallIntType ||\n+        inner instanceof TinyIntType) {\n+      return Types.IntegerType.get();\n+    } else if (inner instanceof BigIntType) {\n+      return Types.LongType.get();\n+    } else if (inner instanceof VarBinaryType ||\n+        inner instanceof BinaryType) {\n+      return Types.BinaryType.get();\n+    } else if (inner instanceof FloatType) {\n+      return Types.FloatType.get();\n+    } else if (inner instanceof DoubleType) {\n+      return Types.DoubleType.get();\n+    } else if (inner instanceof DateType) {\n+      return Types.DateType.get();\n+    } else if (inner instanceof TimeType) {\n+      return Types.TimeType.get();\n+    } else if (inner instanceof TimestampType) {", "originalCommit": "9a9fafe929928fc1104f21488188f0de2679c757", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQzODI4Mg==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436438282", "bodyText": "It's a bug here which I forget to fix before. we have an issue to address this: https://github.com/generic-datalake/iceberg-pro/issues/30.\nLet me address it in this pull request.", "author": "openinx", "createdAt": "2020-06-08T03:10:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzMTUwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjg1NjU4Nw==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436856587", "bodyText": "It looks like the Flink type that most closely matches is LocalZonedTimestampType because the Iceberg type does not store the original time zone.", "author": "rdblue", "createdAt": "2020-06-08T17:01:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzMTUwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzEyNTAxNQ==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r437125015", "bodyText": "Read the javadoc again,  Yes you're right.", "author": "openinx", "createdAt": "2020-06-09T04:02:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzMTUwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzMjQ3NQ==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436032475", "bodyText": "Minor: We generally prefer Maps.newLinkedHashMap() instead of using a specific implementation.", "author": "rdblue", "createdAt": "2020-06-05T16:30:25Z", "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeVisitor.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.RowType;\n+\n+public class FlinkTypeVisitor<T> {\n+\n+  static <T> T visit(DataType dataType, FlinkTypeVisitor<T> visitor) {\n+    if (dataType instanceof FieldsDataType) {\n+      FieldsDataType fieldsType = (FieldsDataType) dataType;\n+      Map<String, DataType> fields = fieldsType.getFieldDataTypes();\n+      Map<String, Tuple2<String, T>> fieldResults = new LinkedHashMap<>();", "originalCommit": "9a9fafe929928fc1104f21488188f0de2679c757", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzMzE4Mg==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436033182", "bodyText": "How do we know that the logical type is RowType? Is that the only one? We may want to add a Precondition to validate this.", "author": "rdblue", "createdAt": "2020-06-05T16:31:47Z", "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeVisitor.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.RowType;\n+\n+public class FlinkTypeVisitor<T> {\n+\n+  static <T> T visit(DataType dataType, FlinkTypeVisitor<T> visitor) {\n+    if (dataType instanceof FieldsDataType) {\n+      FieldsDataType fieldsType = (FieldsDataType) dataType;\n+      Map<String, DataType> fields = fieldsType.getFieldDataTypes();\n+      Map<String, Tuple2<String, T>> fieldResults = new LinkedHashMap<>();\n+      // Make sure that we're traversing the fields in the same order as constructing the schema's fields.\n+      RowType rowType = (RowType) dataType.getLogicalType();", "originalCommit": "9a9fafe929928fc1104f21488188f0de2679c757", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ0MzMxMw==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436443313", "bodyText": "Yes, it's the only one.  Providing a Precondition seems good.", "author": "openinx", "createdAt": "2020-06-08T03:41:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzMzE4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzNDM3NQ==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436034375", "bodyText": "What is returned by rowType.getFields()? Why is that used to get the comment, but fields.get(name) is used for the type? I would expect this to use one or the other.", "author": "rdblue", "createdAt": "2020-06-05T16:34:12Z", "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeVisitor.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.RowType;\n+\n+public class FlinkTypeVisitor<T> {\n+\n+  static <T> T visit(DataType dataType, FlinkTypeVisitor<T> visitor) {\n+    if (dataType instanceof FieldsDataType) {\n+      FieldsDataType fieldsType = (FieldsDataType) dataType;\n+      Map<String, DataType> fields = fieldsType.getFieldDataTypes();\n+      Map<String, Tuple2<String, T>> fieldResults = new LinkedHashMap<>();\n+      // Make sure that we're traversing the fields in the same order as constructing the schema's fields.\n+      RowType rowType = (RowType) dataType.getLogicalType();\n+      for (int i = 0; i < fields.size(); i++) {\n+        String name = rowType.getFieldNames().get(i);\n+        String comment = rowType.getFields().get(i).getDescription().orElse(null);\n+        fieldResults.put(name, Tuple2.of(comment, visit(fields.get(name), visitor)));", "originalCommit": "9a9fafe929928fc1104f21488188f0de2679c757", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ0NjQzMQ==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436446431", "bodyText": "There are two different datatype class in flink type:  DataType and LogicalType. The DataType have the following types:\n\nAtomicDataType;\nCollectionDataType;\nFieldsDataType;\nKeyValueDataType;\n\nand the logicalType the following kinds: ArrayType/CharType/LongType/MapType etc , it describe more details about the type.\nThe RowType is a LogicalType, while we defined the visit by accepting DataType, that's why I need two types here:  the logical type to get the name & comment, while the DataType to passing the argument.\nI think I can write this code more clear, please see the next patch.", "author": "openinx", "createdAt": "2020-06-08T03:59:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzNDM3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjg1OTM0Mw==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436859343", "bodyText": "Looks good now.", "author": "rdblue", "createdAt": "2020-06-08T17:05:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzNDM3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzNTc2NQ==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436035765", "bodyText": "If fields is always a row, it seems to me that row might be a better name because it is more clear that it is a record/struct/tuple type. It wasn't clear to me that fields was the record type, since most other formats make a distinction between a record and its field list.", "author": "rdblue", "createdAt": "2020-06-05T16:36:46Z", "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeVisitor.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.RowType;\n+\n+public class FlinkTypeVisitor<T> {\n+\n+  static <T> T visit(DataType dataType, FlinkTypeVisitor<T> visitor) {\n+    if (dataType instanceof FieldsDataType) {\n+      FieldsDataType fieldsType = (FieldsDataType) dataType;\n+      Map<String, DataType> fields = fieldsType.getFieldDataTypes();\n+      Map<String, Tuple2<String, T>> fieldResults = new LinkedHashMap<>();\n+      // Make sure that we're traversing the fields in the same order as constructing the schema's fields.\n+      RowType rowType = (RowType) dataType.getLogicalType();\n+      for (int i = 0; i < fields.size(); i++) {\n+        String name = rowType.getFieldNames().get(i);\n+        String comment = rowType.getFields().get(i).getDescription().orElse(null);\n+        fieldResults.put(name, Tuple2.of(comment, visit(fields.get(name), visitor)));\n+      }\n+      return visitor.fields(fieldsType, fieldResults);\n+    } else if (dataType instanceof CollectionDataType) {\n+      CollectionDataType collectionType = (CollectionDataType) dataType;\n+      return visitor.collection(collectionType,\n+          visit(collectionType.getElementDataType(), visitor));\n+    } else if (dataType instanceof KeyValueDataType) {\n+      KeyValueDataType mapType = (KeyValueDataType) dataType;\n+      return visitor.map(mapType,\n+          visit(mapType.getKeyDataType(), visitor),\n+          visit(mapType.getValueDataType(), visitor));\n+    } else if (dataType instanceof AtomicDataType) {\n+      AtomicDataType atomic = (AtomicDataType) dataType;\n+      return visitor.atomic(atomic);\n+    } else {\n+      throw new UnsupportedOperationException(\"Unsupported data type: \" + dataType);\n+    }\n+  }\n+\n+  public T fields(FieldsDataType dataType, Map<String, Tuple2<String, T>> fieldResults) {", "originalCommit": "9a9fafe929928fc1104f21488188f0de2679c757", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ0Njk2Nw==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436446967", "bodyText": "The name fields is matching the FieldsDataType ,  like the collection is matching the CollectionDataType, map is matching the KeyValueDataType.", "author": "openinx", "createdAt": "2020-06-08T04:02:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzNTc2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzNjYwNg==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436036606", "bodyText": "In other visitors, we avoid the need for a Tuple2 or equivalent by adding a visitor method for a field. That also gives us an opportunity to add before and after callbacks to do things like keep track of the original schema's names. We can always add this later, but you might consider adding it.", "author": "rdblue", "createdAt": "2020-06-05T16:38:29Z", "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeVisitor.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.RowType;\n+\n+public class FlinkTypeVisitor<T> {\n+\n+  static <T> T visit(DataType dataType, FlinkTypeVisitor<T> visitor) {\n+    if (dataType instanceof FieldsDataType) {\n+      FieldsDataType fieldsType = (FieldsDataType) dataType;\n+      Map<String, DataType> fields = fieldsType.getFieldDataTypes();\n+      Map<String, Tuple2<String, T>> fieldResults = new LinkedHashMap<>();\n+      // Make sure that we're traversing the fields in the same order as constructing the schema's fields.\n+      RowType rowType = (RowType) dataType.getLogicalType();\n+      for (int i = 0; i < fields.size(); i++) {\n+        String name = rowType.getFieldNames().get(i);\n+        String comment = rowType.getFields().get(i).getDescription().orElse(null);\n+        fieldResults.put(name, Tuple2.of(comment, visit(fields.get(name), visitor)));", "originalCommit": "9a9fafe929928fc1104f21488188f0de2679c757", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ0ODAzNg==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436448036", "bodyText": "The reason why I add  a Tuple2/Pair here because the flink Type did not expose the interface to access the comment, so I have to maintain it by myself. I got your points about before or after hooks. In the worst case, the hooks may also accept the Map<String, Pair<String, Type>> as an argument. we may could do better ..", "author": "openinx", "createdAt": "2020-06-08T04:08:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzNjYwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzNjg5Ng==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436036896", "bodyText": "We typically use a Pair in Iceberg code for consistency.", "author": "rdblue", "createdAt": "2020-06-05T16:39:07Z", "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeVisitor.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.apache.flink.api.java.tuple.Tuple2;", "originalCommit": "9a9fafe929928fc1104f21488188f0de2679c757", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzNzY0Nw==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436037647", "bodyText": "Using a name like commentAndType would help make it clear what's happening when the values are used.", "author": "rdblue", "createdAt": "2020-06-05T16:40:41Z", "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeToType.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.BinaryType;\n+import org.apache.flink.table.types.logical.BooleanType;\n+import org.apache.flink.table.types.logical.CharType;\n+import org.apache.flink.table.types.logical.DateType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.DoubleType;\n+import org.apache.flink.table.types.logical.FloatType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.table.types.logical.VarBinaryType;\n+import org.apache.flink.table.types.logical.VarCharType;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+public class FlinkTypeToType extends FlinkTypeVisitor<Type> {\n+  private final FieldsDataType root;\n+  private int nextId = 0;\n+\n+  FlinkTypeToType(FieldsDataType root) {\n+    this.root = root;\n+    // the root struct's fields use the first ids\n+    this.nextId = root.getFieldDataTypes().size();\n+  }\n+\n+  private int getNextId() {\n+    int next = nextId;\n+    nextId += 1;\n+    return next;\n+  }\n+\n+  @Override\n+  public Type fields(FieldsDataType dataType, Map<String, Tuple2<String, Type>> types) {\n+    List<Types.NestedField> newFields = Lists.newArrayListWithExpectedSize(types.size());\n+    boolean isRoot = root == dataType;\n+\n+    Map<String, DataType> fieldsMap = dataType.getFieldDataTypes();\n+    int index = 0;\n+    for (String name : types.keySet()) {\n+      assert fieldsMap.containsKey(name);\n+      DataType field = fieldsMap.get(name);\n+      Tuple2<String, Type> tuple2 = types.get(name);", "originalCommit": "9a9fafe929928fc1104f21488188f0de2679c757", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQzNzIxMw==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436437213", "bodyText": "Sounds good.", "author": "openinx", "createdAt": "2020-06-08T03:03:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzNzY0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzOTA1NA==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436039054", "bodyText": "It would be good to use a different precision and scale so that this validates that they are passed correctly, since both are ints.", "author": "rdblue", "createdAt": "2020-06-05T16:43:25Z", "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkSchemaUtil.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestFlinkSchemaUtil {\n+\n+  @Test\n+  public void testConvertFlinkSchemaToIcebergSchema() {\n+    TableSchema flinkSchema = TableSchema.builder()\n+        .field(\"id\", DataTypes.INT().notNull())\n+        .field(\"name\", DataTypes.STRING()) /* optional by default */\n+        .field(\"salary\", DataTypes.DOUBLE().notNull())\n+        .field(\"locations\", DataTypes.MAP(DataTypes.STRING(),\n+            DataTypes.ROW(DataTypes.FIELD(\"posX\", DataTypes.DOUBLE().notNull(), \"X field\"),\n+                DataTypes.FIELD(\"posY\", DataTypes.DOUBLE().notNull(), \"Y field\"))))\n+        .field(\"strArray\", DataTypes.ARRAY(DataTypes.STRING()).nullable())\n+        .field(\"intArray\", DataTypes.ARRAY(DataTypes.INT()).nullable())\n+        .field(\"char\", DataTypes.CHAR(10).notNull())\n+        .field(\"varchar\", DataTypes.VARCHAR(10).notNull())\n+        .field(\"boolean\", DataTypes.BOOLEAN().nullable())\n+        .field(\"tinyint\", DataTypes.TINYINT())\n+        .field(\"smallint\", DataTypes.SMALLINT())\n+        .field(\"bigint\", DataTypes.BIGINT())\n+        .field(\"varbinary\", DataTypes.VARBINARY(10))\n+        .field(\"binary\", DataTypes.BINARY(10))\n+        .field(\"time\", DataTypes.TIME())\n+        .field(\"timestamp\", DataTypes.TIMESTAMP())\n+        .field(\"date\", DataTypes.DATE())\n+        .field(\"decimal\", DataTypes.DECIMAL(2, 2))", "originalCommit": "9a9fafe929928fc1104f21488188f0de2679c757", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjU3Njg5OA==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436576898", "bodyText": "Done", "author": "openinx", "createdAt": "2020-06-08T09:45:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzOTA1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAzOTU3MQ==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436039571", "bodyText": "Instead of using toString, use asStruct. Struct implements equals so you can use it in tests.", "author": "rdblue", "createdAt": "2020-06-05T16:44:22Z", "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkSchemaUtil.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestFlinkSchemaUtil {\n+\n+  @Test\n+  public void testConvertFlinkSchemaToIcebergSchema() {\n+    TableSchema flinkSchema = TableSchema.builder()\n+        .field(\"id\", DataTypes.INT().notNull())\n+        .field(\"name\", DataTypes.STRING()) /* optional by default */\n+        .field(\"salary\", DataTypes.DOUBLE().notNull())\n+        .field(\"locations\", DataTypes.MAP(DataTypes.STRING(),\n+            DataTypes.ROW(DataTypes.FIELD(\"posX\", DataTypes.DOUBLE().notNull(), \"X field\"),\n+                DataTypes.FIELD(\"posY\", DataTypes.DOUBLE().notNull(), \"Y field\"))))\n+        .field(\"strArray\", DataTypes.ARRAY(DataTypes.STRING()).nullable())\n+        .field(\"intArray\", DataTypes.ARRAY(DataTypes.INT()).nullable())\n+        .field(\"char\", DataTypes.CHAR(10).notNull())\n+        .field(\"varchar\", DataTypes.VARCHAR(10).notNull())\n+        .field(\"boolean\", DataTypes.BOOLEAN().nullable())\n+        .field(\"tinyint\", DataTypes.TINYINT())\n+        .field(\"smallint\", DataTypes.SMALLINT())\n+        .field(\"bigint\", DataTypes.BIGINT())\n+        .field(\"varbinary\", DataTypes.VARBINARY(10))\n+        .field(\"binary\", DataTypes.BINARY(10))\n+        .field(\"time\", DataTypes.TIME())\n+        .field(\"timestamp\", DataTypes.TIMESTAMP())\n+        .field(\"date\", DataTypes.DATE())\n+        .field(\"decimal\", DataTypes.DECIMAL(2, 2))\n+        .build();\n+\n+    Schema actualSchema = FlinkSchemaUtil.convert(flinkSchema);\n+    Schema expectedSchema = new Schema(\n+        Types.NestedField.required(0, \"id\", Types.IntegerType.get(), null),\n+        Types.NestedField.optional(1, \"name\", Types.StringType.get(), null),\n+        Types.NestedField.required(2, \"salary\", Types.DoubleType.get(), null),\n+        Types.NestedField.optional(3, \"locations\", Types.MapType.ofOptional(20, 21,\n+            Types.StringType.get(),\n+            Types.StructType.of(\n+                Types.NestedField.required(18, \"posX\", Types.DoubleType.get(), \"X field\"),\n+                Types.NestedField.required(19, \"posY\", Types.DoubleType.get(), \"Y field\")\n+            ))),\n+        Types.NestedField.optional(4, \"strArray\", Types.ListType.ofOptional(22, Types.StringType.get())),\n+        Types.NestedField.optional(5, \"intArray\", Types.ListType.ofOptional(23, Types.IntegerType.get())),\n+        Types.NestedField.required(6, \"char\", Types.StringType.get()),\n+        Types.NestedField.required(7, \"varchar\", Types.StringType.get()),\n+        Types.NestedField.optional(8, \"boolean\", Types.BooleanType.get()),\n+        Types.NestedField.optional(9, \"tinyint\", Types.IntegerType.get()),\n+        Types.NestedField.optional(10, \"smallint\", Types.IntegerType.get()),\n+        Types.NestedField.optional(11, \"bigint\", Types.LongType.get()),\n+        Types.NestedField.optional(12, \"varbinary\", Types.BinaryType.get()),\n+        Types.NestedField.optional(13, \"binary\", Types.BinaryType.get()),\n+        Types.NestedField.optional(14, \"time\", Types.TimeType.get()),\n+        Types.NestedField.optional(15, \"timestamp\", Types.TimestampType.withZone()),\n+        Types.NestedField.optional(16, \"date\", Types.DateType.get()),\n+        Types.NestedField.optional(17, \"decimal\", Types.DecimalType.of(2, 2))\n+    );\n+\n+    Assert.assertEquals(expectedSchema.toString(), actualSchema.toString());", "originalCommit": "9a9fafe929928fc1104f21488188f0de2679c757", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA0MDI0Nw==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436040247", "bodyText": "Looks like this doesn't test:\n\nField comments\nStruct types\nMaps or lists that contain structs\nMaps with non-string keys\n\nAre all of those supported? If so, can you add tests?", "author": "rdblue", "createdAt": "2020-06-05T16:45:41Z", "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkSchemaUtil.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestFlinkSchemaUtil {", "originalCommit": "9a9fafe929928fc1104f21488188f0de2679c757", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjU3Njc2OQ==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436576769", "bodyText": "Done", "author": "openinx", "createdAt": "2020-06-08T09:45:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA0MDI0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjg2OTgzNw==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436869837", "bodyText": "I don't see test cases for lists with required elements or lists of structs. Can you add those?", "author": "rdblue", "createdAt": "2020-06-08T17:21:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA0MDI0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzEyMjQ4OA==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r437122488", "bodyText": "Thanks for the reminding. when I provide the unit test for lists, I found a bug in the current patch.\n@Override\n  public Type collection(CollectionDataType collection, Type elementType) {\n    if (collection.getElementDataType().getLogicalType().isNullable()) {\n      return Types.ListType.ofOptional(getNextId(), elementType);\n    } else {\n      return Types.ListType.ofRequired(getNextId(), elementType);\n    }\n  }\nThe collection.getElementDataType().getLogicalType().isNullable() should be changed as collection.getLogicalType().isNullable().", "author": "openinx", "createdAt": "2020-06-09T03:50:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA0MDI0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI3OTYwMQ==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r438279601", "bodyText": "Why use the list's nullability for whether the elements in the list are nullable? It looks like that was correct before.\nThe javadoc for isNullable is \"Returns whether a value of this type can be null\". That sounds like it describes whether the list can be null or not. The element type has its own nullability that describes whether the elements can be null. I think it was correct before.", "author": "rdblue", "createdAt": "2020-06-10T17:06:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA0MDI0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODUwODA3MQ==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r438508071", "bodyText": "Why use the list's nullability for whether the elements in the list are nullable?\n\nI thought the ListType.ofOptional says that whether the list is allowed to be nullable. Checked the code, seems it means whether the element in list are allowed to be nullable.\n  public static class ListType extends NestedType {\n    public static ListType ofOptional(int elementId, Type elementType) {\n      Preconditions.checkNotNull(elementType, \"Element type cannot be null\");\n      return new ListType(NestedField.optional(elementId, \"element\", elementType));\n    }\n    //....\nSorry for this noise, let me check this code again.", "author": "openinx", "createdAt": "2020-06-11T02:27:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA0MDI0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA0MDQ1MQ==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436040451", "bodyText": "I think validation should be tested separately.", "author": "rdblue", "createdAt": "2020-06-05T16:46:04Z", "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkSchemaUtil.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestFlinkSchemaUtil {\n+\n+  @Test\n+  public void testConvertFlinkSchemaToIcebergSchema() {\n+    TableSchema flinkSchema = TableSchema.builder()\n+        .field(\"id\", DataTypes.INT().notNull())\n+        .field(\"name\", DataTypes.STRING()) /* optional by default */\n+        .field(\"salary\", DataTypes.DOUBLE().notNull())\n+        .field(\"locations\", DataTypes.MAP(DataTypes.STRING(),\n+            DataTypes.ROW(DataTypes.FIELD(\"posX\", DataTypes.DOUBLE().notNull(), \"X field\"),\n+                DataTypes.FIELD(\"posY\", DataTypes.DOUBLE().notNull(), \"Y field\"))))\n+        .field(\"strArray\", DataTypes.ARRAY(DataTypes.STRING()).nullable())\n+        .field(\"intArray\", DataTypes.ARRAY(DataTypes.INT()).nullable())\n+        .field(\"char\", DataTypes.CHAR(10).notNull())\n+        .field(\"varchar\", DataTypes.VARCHAR(10).notNull())\n+        .field(\"boolean\", DataTypes.BOOLEAN().nullable())\n+        .field(\"tinyint\", DataTypes.TINYINT())\n+        .field(\"smallint\", DataTypes.SMALLINT())\n+        .field(\"bigint\", DataTypes.BIGINT())\n+        .field(\"varbinary\", DataTypes.VARBINARY(10))\n+        .field(\"binary\", DataTypes.BINARY(10))\n+        .field(\"time\", DataTypes.TIME())\n+        .field(\"timestamp\", DataTypes.TIMESTAMP())\n+        .field(\"date\", DataTypes.DATE())\n+        .field(\"decimal\", DataTypes.DECIMAL(2, 2))\n+        .build();\n+\n+    Schema actualSchema = FlinkSchemaUtil.convert(flinkSchema);\n+    Schema expectedSchema = new Schema(\n+        Types.NestedField.required(0, \"id\", Types.IntegerType.get(), null),\n+        Types.NestedField.optional(1, \"name\", Types.StringType.get(), null),\n+        Types.NestedField.required(2, \"salary\", Types.DoubleType.get(), null),\n+        Types.NestedField.optional(3, \"locations\", Types.MapType.ofOptional(20, 21,\n+            Types.StringType.get(),\n+            Types.StructType.of(\n+                Types.NestedField.required(18, \"posX\", Types.DoubleType.get(), \"X field\"),\n+                Types.NestedField.required(19, \"posY\", Types.DoubleType.get(), \"Y field\")\n+            ))),\n+        Types.NestedField.optional(4, \"strArray\", Types.ListType.ofOptional(22, Types.StringType.get())),\n+        Types.NestedField.optional(5, \"intArray\", Types.ListType.ofOptional(23, Types.IntegerType.get())),\n+        Types.NestedField.required(6, \"char\", Types.StringType.get()),\n+        Types.NestedField.required(7, \"varchar\", Types.StringType.get()),\n+        Types.NestedField.optional(8, \"boolean\", Types.BooleanType.get()),\n+        Types.NestedField.optional(9, \"tinyint\", Types.IntegerType.get()),\n+        Types.NestedField.optional(10, \"smallint\", Types.IntegerType.get()),\n+        Types.NestedField.optional(11, \"bigint\", Types.LongType.get()),\n+        Types.NestedField.optional(12, \"varbinary\", Types.BinaryType.get()),\n+        Types.NestedField.optional(13, \"binary\", Types.BinaryType.get()),\n+        Types.NestedField.optional(14, \"time\", Types.TimeType.get()),\n+        Types.NestedField.optional(15, \"timestamp\", Types.TimestampType.withZone()),\n+        Types.NestedField.optional(16, \"date\", Types.DateType.get()),\n+        Types.NestedField.optional(17, \"decimal\", Types.DecimalType.of(2, 2))\n+    );\n+\n+    Assert.assertEquals(expectedSchema.toString(), actualSchema.toString());\n+    FlinkSchemaUtil.validate(expectedSchema, actualSchema, true, true);\n+    FlinkSchemaUtil.validate(expectedSchema, actualSchema, false, true);\n+    FlinkSchemaUtil.validate(expectedSchema, actualSchema, true, false);\n+    FlinkSchemaUtil.validate(expectedSchema, actualSchema, false, false);", "originalCommit": "9a9fafe929928fc1104f21488188f0de2679c757", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ0NzIyOA==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436447228", "bodyText": "As we discussed above, we will move this validate method into the common TypeUtil.  Let me add unit test in TestTypeUtil. Thanks.", "author": "openinx", "createdAt": "2020-06-08T04:04:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA0MDQ1MQ=="}], "type": "inlineReview"}, {"oid": "1a7c88003ff2206f83dcf8509b868b60cb2d7c4d", "url": "https://github.com/apache/iceberg/commit/1a7c88003ff2206f83dcf8509b868b60cb2d7c4d", "message": "Addressing the comments from Ryan blue", "committedDate": "2020-06-08T05:34:09Z", "type": "commit"}, {"oid": "98648e5fc0912b365a6b768435565f969fff4962", "url": "https://github.com/apache/iceberg/commit/98648e5fc0912b365a6b768435565f969fff4962", "message": "Minor updates and more unit tests", "committedDate": "2020-06-08T09:41:03Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjg2MjczMg==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436862732", "bodyText": "Schema doesn't implement equals because it isn't clear what schema equality means. Because we track fields by ID, two schemas are equal only if their fields have the same IDs, but most people don't think about schema equality that way and think of a SQL schema, like id bigint, data string. To avoid confusion, we don't provide an equals method that may have confusing results. Instead, we implement equals for structs so you can use schema.asStruct() in test assertions.", "author": "rdblue", "createdAt": "2020-06-08T17:11:05Z", "path": "api/src/main/java/org/apache/iceberg/Schema.java", "diffHunk": "@@ -314,4 +315,31 @@ public String toString() {\n             .map(f -> \"  \" + f)\n             .collect(Collectors.toList())));\n   }\n+\n+  @Override\n+  public boolean equals(Object o) {\n+    if (!(o instanceof Schema)) {\n+      return false;\n+    }\n+\n+    Schema that = (Schema) o;\n+    if (!Objects.equals(struct.fields(), that.struct.fields())) {\n+      return false;\n+    }\n+\n+    if (aliasToId == that.aliasToId) {\n+      return true;\n+    }\n+\n+    if (aliasToId == null || that.aliasToId == null) {\n+      return false;\n+    }\n+\n+    return aliasToId.equals(that.aliasToId);\n+  }\n+\n+  @Override\n+  public int hashCode() {\n+    return Objects.hash(struct.fields(), aliasToId == null ? 0 : aliasToId.hashCode());\n+  }", "originalCommit": "98648e5fc0912b365a6b768435565f969fff4962", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzEwMDE2NA==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r437100164", "bodyText": "Got it, thanks.", "author": "openinx", "createdAt": "2020-06-09T02:18:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjg2MjczMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjg2Mzc5NA==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436863794", "bodyText": "asNestedType is no longer necessary. Now asStructType is defined on Type, not just NestedType.", "author": "rdblue", "createdAt": "2020-06-08T17:12:40Z", "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkSchemaUtil.java", "diffHunk": "@@ -0,0 +1,44 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.types.Type;\n+\n+public class FlinkSchemaUtil {\n+\n+  private FlinkSchemaUtil() {\n+  }\n+\n+  /**\n+   * Convert the flink table schema to apache iceberg schema.\n+   */\n+  public static Schema convert(TableSchema schema) {\n+    Preconditions.checkArgument(schema.toRowDataType() instanceof FieldsDataType, \"Should be FieldsDataType\");\n+\n+    FieldsDataType root = (FieldsDataType) schema.toRowDataType();\n+    Type converted = FlinkTypeVisitor.visit(root, new FlinkTypeToType(root));\n+\n+    return new Schema(converted.asNestedType().asStructType().fields());", "originalCommit": "98648e5fc0912b365a6b768435565f969fff4962", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjg2NTE2MA==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r436865160", "bodyText": "Why have variable index  when its value is always equal to i?", "author": "rdblue", "createdAt": "2020-06-08T17:14:44Z", "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeToType.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.BinaryType;\n+import org.apache.flink.table.types.logical.BooleanType;\n+import org.apache.flink.table.types.logical.CharType;\n+import org.apache.flink.table.types.logical.DateType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.DoubleType;\n+import org.apache.flink.table.types.logical.FloatType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.table.types.logical.VarBinaryType;\n+import org.apache.flink.table.types.logical.VarCharType;\n+import org.apache.flink.table.types.logical.ZonedTimestampType;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+public class FlinkTypeToType extends FlinkTypeVisitor<Type> {\n+  private final FieldsDataType root;\n+  private int nextId = 0;\n+\n+  FlinkTypeToType(FieldsDataType root) {\n+    this.root = root;\n+    // the root struct's fields use the first ids\n+    this.nextId = root.getFieldDataTypes().size();\n+  }\n+\n+  private int getNextId() {\n+    int next = nextId;\n+    nextId += 1;\n+    return next;\n+  }\n+\n+  @Override\n+  public Type fields(FieldsDataType fields, List<Type> types) {\n+    List<Types.NestedField> newFields = Lists.newArrayListWithExpectedSize(types.size());\n+    boolean isRoot = root == fields;\n+\n+    List<RowType.RowField> rowFields = ((RowType) fields.getLogicalType()).getFields();\n+    Preconditions.checkArgument(rowFields.size() == types.size(), \"fields list and types list should have same size.\");\n+\n+    int index = 0;\n+    for (int i = 0; i < rowFields.size(); i++) {\n+      int id = isRoot ? index : getNextId();", "originalCommit": "98648e5fc0912b365a6b768435565f969fff4962", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzEwNDA3Ng==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r437104076", "bodyText": "OK, the index can be removed now (The first version I used a for (String name : types.keySet()) so defined a index variable) .", "author": "openinx", "createdAt": "2020-06-09T02:33:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjg2NTE2MA=="}], "type": "inlineReview"}, {"oid": "7ea48aa2439be6b77fc4bc7aad39e9bcb0a1843f", "url": "https://github.com/apache/iceberg/commit/7ea48aa2439be6b77fc4bc7aad39e9bcb0a1843f", "message": "Addressing the comments round#2", "committedDate": "2020-06-09T03:59:51Z", "type": "commit"}, {"oid": "6820f9e03108dcf272168b2d04113d5296a10a37", "url": "https://github.com/apache/iceberg/commit/6820f9e03108dcf272168b2d04113d5296a10a37", "message": "Add flink_2.12 module for scala 2.12", "committedDate": "2020-06-10T04:05:59Z", "type": "commit"}, {"oid": "2e3624f05d29b7d98b9e9602aa529c89e0acbf08", "url": "https://github.com/apache/iceberg/commit/2e3624f05d29b7d98b9e9602aa529c89e0acbf08", "message": "Revert the change that the nubllbility of ListType is depending on DataTypes.ARRAY (it should depend on the nullbility of elementType.)", "committedDate": "2020-06-11T02:46:50Z", "type": "commit"}, {"oid": "8891cd5438306f0b4b226706058beff7c3cd4080", "url": "https://github.com/apache/iceberg/commit/8891cd5438306f0b4b226706058beff7c3cd4080", "message": "Remove flink module with scala 2.11 binary", "committedDate": "2020-06-12T02:10:02Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTk1NTY2MA==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r441955660", "bodyText": "Flink has LogicalTypeVisitor and DataTypeVisitor, they are very useful for visiting types and you don't need have this static <T> T visit method, it is not so elegant.\nAnd for FieldsDataType, it not has a good design in 1.9 and 1.10, so in Flink 1.11, it has been refactored to be removed getFieldDataTypes.\nAnd I think maybe a LogicalTypeVisitor is enough, since we never touch the physical information in the DataTypes.", "author": "JingsongLi", "createdAt": "2020-06-18T04:02:22Z", "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeVisitor.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+\n+public class FlinkTypeVisitor<T> {", "originalCommit": "8891cd5438306f0b4b226706058beff7c3cd4080", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTk1NzQ4NA==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r441957484", "bodyText": "A better name is generateNextId or just nextId. Looks like it is not only \"get\".", "author": "JingsongLi", "createdAt": "2020-06-18T04:09:45Z", "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeToType.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.BinaryType;\n+import org.apache.flink.table.types.logical.BooleanType;\n+import org.apache.flink.table.types.logical.CharType;\n+import org.apache.flink.table.types.logical.DateType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.DoubleType;\n+import org.apache.flink.table.types.logical.FloatType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LocalZonedTimestampType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.table.types.logical.VarBinaryType;\n+import org.apache.flink.table.types.logical.VarCharType;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+public class FlinkTypeToType extends FlinkTypeVisitor<Type> {\n+  private final FieldsDataType root;\n+  private int nextId = 0;\n+\n+  FlinkTypeToType(FieldsDataType root) {\n+    this.root = root;\n+    // the root struct's fields use the first ids\n+    this.nextId = root.getFieldDataTypes().size();\n+  }\n+\n+  private int getNextId() {", "originalCommit": "8891cd5438306f0b4b226706058beff7c3cd4080", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTk1ODc2OQ==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r441958769", "bodyText": "A CollectionDataType may be MultisetType too. Maybe iceberg not support it now? Or we can map it to Map<T, Integer>.", "author": "JingsongLi", "createdAt": "2020-06-18T04:15:50Z", "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeToType.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.BinaryType;\n+import org.apache.flink.table.types.logical.BooleanType;\n+import org.apache.flink.table.types.logical.CharType;\n+import org.apache.flink.table.types.logical.DateType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.DoubleType;\n+import org.apache.flink.table.types.logical.FloatType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LocalZonedTimestampType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.table.types.logical.VarBinaryType;\n+import org.apache.flink.table.types.logical.VarCharType;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+public class FlinkTypeToType extends FlinkTypeVisitor<Type> {\n+  private final FieldsDataType root;\n+  private int nextId = 0;\n+\n+  FlinkTypeToType(FieldsDataType root) {\n+    this.root = root;\n+    // the root struct's fields use the first ids\n+    this.nextId = root.getFieldDataTypes().size();\n+  }\n+\n+  private int getNextId() {\n+    int next = nextId;\n+    nextId += 1;\n+    return next;\n+  }\n+\n+  @Override\n+  public Type fields(FieldsDataType fields, List<Type> types) {\n+    List<Types.NestedField> newFields = Lists.newArrayListWithExpectedSize(types.size());\n+    boolean isRoot = root == fields;\n+\n+    List<RowType.RowField> rowFields = ((RowType) fields.getLogicalType()).getFields();\n+    Preconditions.checkArgument(rowFields.size() == types.size(), \"fields list and types list should have same size.\");\n+\n+    for (int i = 0; i < rowFields.size(); i++) {\n+      int id = isRoot ? i : getNextId();\n+\n+      RowType.RowField field = rowFields.get(i);\n+      String name = field.getName();\n+      String comment = field.getDescription().orElse(null);\n+\n+      if (field.getType().isNullable()) {\n+        newFields.add(Types.NestedField.optional(id, name, types.get(i), comment));\n+      } else {\n+        newFields.add(Types.NestedField.required(id, name, types.get(i), comment));\n+      }\n+    }\n+\n+    return Types.StructType.of(newFields);\n+  }\n+\n+  @Override\n+  public Type collection(CollectionDataType collection, Type elementType) {", "originalCommit": "8891cd5438306f0b4b226706058beff7c3cd4080", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTk1OTMwMA==", "url": "https://github.com/apache/iceberg/pull/1096#discussion_r441959300", "bodyText": "But flink can be, so should we throw unsupported exception here?", "author": "JingsongLi", "createdAt": "2020-06-18T04:18:21Z", "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeToType.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import org.apache.flink.table.types.AtomicDataType;\n+import org.apache.flink.table.types.CollectionDataType;\n+import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.KeyValueDataType;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.BinaryType;\n+import org.apache.flink.table.types.logical.BooleanType;\n+import org.apache.flink.table.types.logical.CharType;\n+import org.apache.flink.table.types.logical.DateType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.DoubleType;\n+import org.apache.flink.table.types.logical.FloatType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LocalZonedTimestampType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.table.types.logical.VarBinaryType;\n+import org.apache.flink.table.types.logical.VarCharType;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+public class FlinkTypeToType extends FlinkTypeVisitor<Type> {\n+  private final FieldsDataType root;\n+  private int nextId = 0;\n+\n+  FlinkTypeToType(FieldsDataType root) {\n+    this.root = root;\n+    // the root struct's fields use the first ids\n+    this.nextId = root.getFieldDataTypes().size();\n+  }\n+\n+  private int getNextId() {\n+    int next = nextId;\n+    nextId += 1;\n+    return next;\n+  }\n+\n+  @Override\n+  public Type fields(FieldsDataType fields, List<Type> types) {\n+    List<Types.NestedField> newFields = Lists.newArrayListWithExpectedSize(types.size());\n+    boolean isRoot = root == fields;\n+\n+    List<RowType.RowField> rowFields = ((RowType) fields.getLogicalType()).getFields();\n+    Preconditions.checkArgument(rowFields.size() == types.size(), \"fields list and types list should have same size.\");\n+\n+    for (int i = 0; i < rowFields.size(); i++) {\n+      int id = isRoot ? i : getNextId();\n+\n+      RowType.RowField field = rowFields.get(i);\n+      String name = field.getName();\n+      String comment = field.getDescription().orElse(null);\n+\n+      if (field.getType().isNullable()) {\n+        newFields.add(Types.NestedField.optional(id, name, types.get(i), comment));\n+      } else {\n+        newFields.add(Types.NestedField.required(id, name, types.get(i), comment));\n+      }\n+    }\n+\n+    return Types.StructType.of(newFields);\n+  }\n+\n+  @Override\n+  public Type collection(CollectionDataType collection, Type elementType) {\n+    if (collection.getElementDataType().getLogicalType().isNullable()) {\n+      return Types.ListType.ofOptional(getNextId(), elementType);\n+    } else {\n+      return Types.ListType.ofRequired(getNextId(), elementType);\n+    }\n+  }\n+\n+  @Override\n+  public Type map(KeyValueDataType map, Type keyType, Type valueType) {\n+    // keys in map are not allowed to be null.", "originalCommit": "8891cd5438306f0b4b226706058beff7c3cd4080", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}