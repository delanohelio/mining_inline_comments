{"pr_number": 1480, "pr_title": "Parquet Vectorized Reads - Test case for exercising reallocation of Arrow buffers to accommodate larger values", "pr_createdAt": "2020-09-18T22:40:05Z", "pr_url": "https://github.com/apache/iceberg/pull/1480", "timeline": [{"oid": "65819657b3e27fd77ed489dfce5ebdce0c67bfdb", "url": "https://github.com/apache/iceberg/commit/65819657b3e27fd77ed489dfce5ebdce0c67bfdb", "message": "Parquet Vectorized Reads - Test case for exercising reallocation of Arrow buffers to accommodate larger values", "committedDate": "2020-09-18T22:40:13Z", "type": "commit"}, {"oid": "65819657b3e27fd77ed489dfce5ebdce0c67bfdb", "url": "https://github.com/apache/iceberg/commit/65819657b3e27fd77ed489dfce5ebdce0c67bfdb", "message": "Parquet Vectorized Reads - Test case for exercising reallocation of Arrow buffers to accommodate larger values", "committedDate": "2020-09-18T22:40:13Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjIyMDkxMQ==", "url": "https://github.com/apache/iceberg/pull/1480#discussion_r492220911", "bodyText": "It's strange that this adds the transform and then ignores it. Is there a better way to structure this so that it doesn't require doing this? Maybe just don't call this method in a subclass?", "author": "rdblue", "createdAt": "2020-09-21T17:15:59Z", "path": "spark/src/test/java/org/apache/iceberg/spark/data/parquet/vectorized/TestParquetDictionaryEncodedVectorizedReads.java", "diffHunk": "@@ -38,7 +39,8 @@\n public class TestParquetDictionaryEncodedVectorizedReads extends TestParquetVectorizedReads {\n \n   @Override\n-  Iterable<GenericData.Record> generateData(Schema schema, int numRecords, long seed, float nullPercentage) {\n+  Iterable<GenericData.Record> generateData(Schema schema, int numRecords, long seed, float nullPercentage,\n+                                            Function<GenericData.Record, GenericData.Record> transform) {", "originalCommit": "65819657b3e27fd77ed489dfce5ebdce0c67bfdb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjIyMTM3OA==", "url": "https://github.com/apache/iceberg/pull/1480#discussion_r492221378", "bodyText": "Why change this?", "author": "rdblue", "createdAt": "2020-09-21T17:16:46Z", "path": "spark/src/test/java/org/apache/iceberg/spark/data/TestHelpers.java", "diffHunk": "@@ -99,7 +99,7 @@ public static void assertEqualsBatch(Types.StructType struct, Iterator<Record> e\n         if (checkArrowValidityVector) {\n           ColumnVector columnVector = batch.column(i);\n           ValueVector arrowVector = ((IcebergArrowColumnVector) columnVector).vectorAccessor().getVector();\n-          Assert.assertEquals(\"Nullability doesn't match\", expectedValue == null, arrowVector.isNull(rowId));\n+          Assert.assertFalse(\"Nullability doesn't match\", expectedValue == null ^ arrowVector.isNull(rowId));", "originalCommit": "65819657b3e27fd77ed489dfce5ebdce0c67bfdb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjUwNDg2NA==", "url": "https://github.com/apache/iceberg/pull/1480#discussion_r492504864", "bodyText": "While stepping through the tests I realized that the case for expectedValue != null wasn't being tested. So I tweaked the check. slightly to cover both the cases.", "author": "samarthjain", "createdAt": "2020-09-22T06:43:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjIyMTM3OA=="}], "type": "inlineReview"}, {"oid": "b16e046f0347b7c6be956a5167b06fbefb15c6d0", "url": "https://github.com/apache/iceberg/commit/b16e046f0347b7c6be956a5167b06fbefb15c6d0", "message": "Address comments", "committedDate": "2020-09-22T18:04:44Z", "type": "commit"}, {"oid": "b16e046f0347b7c6be956a5167b06fbefb15c6d0", "url": "https://github.com/apache/iceberg/commit/b16e046f0347b7c6be956a5167b06fbefb15c6d0", "message": "Address comments", "committedDate": "2020-09-22T18:04:44Z", "type": "forcePushed"}]}