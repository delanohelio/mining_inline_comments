{"pr_number": 1778, "pr_title": "Parquet - Add a spark session configuration for controlling enabling vectorized reads", "pr_createdAt": "2020-11-17T19:17:18Z", "pr_url": "https://github.com/apache/iceberg/pull/1778", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYyMzUyNA==", "url": "https://github.com/apache/iceberg/pull/1778#discussion_r525623524", "bodyText": "Looks like these 4 lines didn't actually change. Can you revert the whitespace changes here?", "author": "rdblue", "createdAt": "2020-11-18T00:52:47Z", "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Reader.java", "diffHunk": "@@ -156,10 +156,13 @@\n     this.io = io;\n     this.encryptionManager = encryptionManager;\n     this.caseSensitive = caseSensitive;\n-\n-    this.batchReadsEnabled = options.get(\"vectorization-enabled\").map(Boolean::parseBoolean).orElseGet(() ->\n-        PropertyUtil.propertyAsBoolean(table.properties(),\n-            TableProperties.PARQUET_VECTORIZATION_ENABLED, TableProperties.PARQUET_VECTORIZATION_ENABLED_DEFAULT));\n+    boolean batchReadsSparkSessionConf = SparkSession.active().sparkContext().getConf()\n+            .getBoolean(\"read.parquet.vectorization.enabled\", true);\n+    boolean batchReadsEnabledTableProp = options.get(\"vectorization-enabled\").map(Boolean::parseBoolean).orElseGet(() ->\n+            PropertyUtil.propertyAsBoolean(table.properties(),\n+                    TableProperties.PARQUET_VECTORIZATION_ENABLED,\n+                    TableProperties.PARQUET_VECTORIZATION_ENABLED_DEFAULT));", "originalCommit": "f121d81611f678203d66b6a33e2402ec3021845e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYyNzI4NQ==", "url": "https://github.com/apache/iceberg/pull/1778#discussion_r525627285", "bodyText": "The variable name was changed which caused the previous line to exceed the 120 character limit.", "author": "samarthjain", "createdAt": "2020-11-18T01:04:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYyMzUyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYyMzc0Nw==", "url": "https://github.com/apache/iceberg/pull/1778#discussion_r525623747", "bodyText": "Don't Spark settings need to start with spark.? Otherwise they are discarded.\nHow about spark.iceberg.vectorization.enabled?", "author": "rdblue", "createdAt": "2020-11-18T00:53:35Z", "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Reader.java", "diffHunk": "@@ -156,10 +156,13 @@\n     this.io = io;\n     this.encryptionManager = encryptionManager;\n     this.caseSensitive = caseSensitive;\n-\n-    this.batchReadsEnabled = options.get(\"vectorization-enabled\").map(Boolean::parseBoolean).orElseGet(() ->\n-        PropertyUtil.propertyAsBoolean(table.properties(),\n-            TableProperties.PARQUET_VECTORIZATION_ENABLED, TableProperties.PARQUET_VECTORIZATION_ENABLED_DEFAULT));\n+    boolean batchReadsSparkSessionConf = SparkSession.active().sparkContext().getConf()\n+            .getBoolean(\"read.parquet.vectorization.enabled\", true);", "originalCommit": "f121d81611f678203d66b6a33e2402ec3021845e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYyODIzMw==", "url": "https://github.com/apache/iceberg/pull/1778#discussion_r525628233", "bodyText": "Looks like the logic here is too complicated. I think what you're trying to do is disable vectorized reads if the session conf disables them, and otherwise delegate to the table property. In other words, the session conf and the table property must be enabled to use vectorization. If that's the case, then this could be (batchReadsSparkSessionConf && batchReadsEnabledTableProp).\nI'm not sure that logic is a good idea, either. This may have surprising behavior because a user may expect that true enables vectorization for all tables when used as a session property.\nI think a better way to configure is to choose an order of priority and delegate to the next config if the option is not set. Here, I think session should override table. If session is set, return whatever it is. Otherwise, use the table property.", "author": "rdblue", "createdAt": "2020-11-18T01:06:51Z", "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Reader.java", "diffHunk": "@@ -156,10 +156,13 @@\n     this.io = io;\n     this.encryptionManager = encryptionManager;\n     this.caseSensitive = caseSensitive;\n-\n-    this.batchReadsEnabled = options.get(\"vectorization-enabled\").map(Boolean::parseBoolean).orElseGet(() ->\n-        PropertyUtil.propertyAsBoolean(table.properties(),\n-            TableProperties.PARQUET_VECTORIZATION_ENABLED, TableProperties.PARQUET_VECTORIZATION_ENABLED_DEFAULT));\n+    boolean batchReadsSparkSessionConf = SparkSession.active().sparkContext().getConf()\n+            .getBoolean(\"read.parquet.vectorization.enabled\", true);\n+    boolean batchReadsEnabledTableProp = options.get(\"vectorization-enabled\").map(Boolean::parseBoolean).orElseGet(() ->\n+            PropertyUtil.propertyAsBoolean(table.properties(),\n+                    TableProperties.PARQUET_VECTORIZATION_ENABLED,\n+                    TableProperties.PARQUET_VECTORIZATION_ENABLED_DEFAULT));\n+    this.batchReadsEnabled = !batchReadsSparkSessionConf ? false : batchReadsEnabledTableProp;", "originalCommit": "f121d81611f678203d66b6a33e2402ec3021845e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "f29de7aeca16d3c7ff5aefc1013e0f30a8395ae6", "url": "https://github.com/apache/iceberg/commit/f29de7aeca16d3c7ff5aefc1013e0f30a8395ae6", "message": "Prioritize session config if set", "committedDate": "2020-11-18T23:45:49Z", "type": "forcePushed"}, {"oid": "cb21c1c5c70e06df0a89f476790e69ab200be7ba", "url": "https://github.com/apache/iceberg/commit/cb21c1c5c70e06df0a89f476790e69ab200be7ba", "message": "Prioritize session config if set", "committedDate": "2020-11-19T00:23:02Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUyNjYyNA==", "url": "https://github.com/apache/iceberg/pull/1778#discussion_r526526624", "bodyText": "Continuation indents are 4 spaces or 2 indents from the previous. Could you update this?", "author": "rdblue", "createdAt": "2020-11-19T01:11:12Z", "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Reader.java", "diffHunk": "@@ -156,10 +157,15 @@\n     this.io = io;\n     this.encryptionManager = encryptionManager;\n     this.caseSensitive = caseSensitive;\n-\n-    this.batchReadsEnabled = options.get(\"vectorization-enabled\").map(Boolean::parseBoolean).orElseGet(() ->\n-        PropertyUtil.propertyAsBoolean(table.properties(),\n-            TableProperties.PARQUET_VECTORIZATION_ENABLED, TableProperties.PARQUET_VECTORIZATION_ENABLED_DEFAULT));\n+    Option<String> option = SparkSession.active().sparkContext().getConf()\n+            .getOption(\"spark.iceberg.vectorization.enabled\");\n+    if (option.isDefined()) {\n+      this.batchReadsEnabled = Boolean.valueOf(option.get());\n+    } else {\n+      this.batchReadsEnabled = options.get(\"vectorization-enabled\").map(Boolean::parseBoolean).orElseGet(() ->\n+              PropertyUtil.propertyAsBoolean(table.properties(), TableProperties.PARQUET_VECTORIZATION_ENABLED,\n+                      TableProperties.PARQUET_VECTORIZATION_ENABLED_DEFAULT));", "originalCommit": "cb21c1c5c70e06df0a89f476790e69ab200be7ba", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUyNzAwNg==", "url": "https://github.com/apache/iceberg/pull/1778#discussion_r526527006", "bodyText": "You should be able to use SparkSession.active().conf().get(\"key\", null) to get the value or null. No need to use the Spark context's conf.", "author": "rdblue", "createdAt": "2020-11-19T01:12:14Z", "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Reader.java", "diffHunk": "@@ -156,10 +157,15 @@\n     this.io = io;\n     this.encryptionManager = encryptionManager;\n     this.caseSensitive = caseSensitive;\n-\n-    this.batchReadsEnabled = options.get(\"vectorization-enabled\").map(Boolean::parseBoolean).orElseGet(() ->\n-        PropertyUtil.propertyAsBoolean(table.properties(),\n-            TableProperties.PARQUET_VECTORIZATION_ENABLED, TableProperties.PARQUET_VECTORIZATION_ENABLED_DEFAULT));\n+    Option<String> option = SparkSession.active().sparkContext().getConf()\n+            .getOption(\"spark.iceberg.vectorization.enabled\");", "originalCommit": "cb21c1c5c70e06df0a89f476790e69ab200be7ba", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "7c32a5212ace9f0ec2c74ac9d8628cf802ddeb84", "url": "https://github.com/apache/iceberg/commit/7c32a5212ace9f0ec2c74ac9d8628cf802ddeb84", "message": "Code review comments", "committedDate": "2020-11-19T09:59:43Z", "type": "forcePushed"}, {"oid": "ea760b96fae6be1c7df95a56712e8ae3e6c6b4a0", "url": "https://github.com/apache/iceberg/commit/ea760b96fae6be1c7df95a56712e8ae3e6c6b4a0", "message": "Parquet - Add a spark session configuration for controlling enabling vectorized reads", "committedDate": "2020-12-02T22:11:44Z", "type": "commit"}, {"oid": "a2f86a71ece3c2c63363b04182045fed3bc9fe70", "url": "https://github.com/apache/iceberg/commit/a2f86a71ece3c2c63363b04182045fed3bc9fe70", "message": "Prioritize session config if set", "committedDate": "2020-12-02T22:11:44Z", "type": "commit"}, {"oid": "d29c13a5548fe202f3da5fecaa2f8bb1e31a9e1c", "url": "https://github.com/apache/iceberg/commit/d29c13a5548fe202f3da5fecaa2f8bb1e31a9e1c", "message": "Code review comments", "committedDate": "2020-12-02T22:11:44Z", "type": "commit"}, {"oid": "0dddb89342fe73057bb182da9257959ebe1d91c1", "url": "https://github.com/apache/iceberg/commit/0dddb89342fe73057bb182da9257959ebe1d91c1", "message": "Add config control to Spark3 as well", "committedDate": "2020-12-02T22:13:10Z", "type": "commit"}, {"oid": "ea9d5f8277bceea845b2f4c70a8c7d0552c32502", "url": "https://github.com/apache/iceberg/commit/ea9d5f8277bceea845b2f4c70a8c7d0552c32502", "message": "Use spark.sql namespace for the config", "committedDate": "2020-12-02T22:13:10Z", "type": "commit"}, {"oid": "ea9d5f8277bceea845b2f4c70a8c7d0552c32502", "url": "https://github.com/apache/iceberg/commit/ea9d5f8277bceea845b2f4c70a8c7d0552c32502", "message": "Use spark.sql namespace for the config", "committedDate": "2020-12-02T22:13:10Z", "type": "forcePushed"}]}