{"pr_number": 1986, "pr_title": "Spark: Add a rule to align updates in MERGE operations", "pr_createdAt": "2020-12-26T13:13:04Z", "pr_url": "https://github.com/apache/iceberg/pull/1986", "timeline": [{"oid": "84a4d5e619edabf8baf373a73ee6b00b710681e7", "url": "https://github.com/apache/iceberg/commit/84a4d5e619edabf8baf373a73ee6b00b710681e7", "message": "Spark: Add a rule to align updates in MERGE operations", "committedDate": "2020-12-26T13:32:50Z", "type": "forcePushed"}, {"oid": "54e5f1530d8b1aa3dd83be96dc812ee435a37e5c", "url": "https://github.com/apache/iceberg/commit/54e5f1530d8b1aa3dd83be96dc812ee435a37e5c", "message": "Spark: Add a rule to align updates in MERGE operations", "committedDate": "2020-12-28T09:25:04Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY5Mzg1Mg==", "url": "https://github.com/apache/iceberg/pull/1986#discussion_r549693852", "bodyText": "This one is redundant, I'll remove it.", "author": "aokolnychyi", "createdAt": "2020-12-29T12:54:07Z", "path": "spark3-extensions/src/test/java/org/apache/iceberg/spark/extensions/TestMerge.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.extensions;\n+\n+import java.util.Map;\n+import org.apache.iceberg.AssertHelpers;\n+import org.apache.spark.sql.AnalysisException;\n+import org.junit.After;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+public abstract class TestMerge extends SparkRowLevelOperationsTestBase {\n+\n+  public TestMerge(String catalogName, String implementation, Map<String, String> config,\n+                   String fileFormat, boolean vectorized) {\n+    super(catalogName, implementation, config, fileFormat, vectorized);\n+  }\n+\n+  @BeforeClass\n+  public static void setupSparkConf() {\n+    spark.conf().set(\"spark.sql.shuffle.partitions\", \"4\");\n+  }\n+\n+  protected abstract Map<String, String> extraTableProperties();", "originalCommit": "2f0f1303fb0f96512736a553c1efe8c9e5b13552", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDIwOTU4Mw==", "url": "https://github.com/apache/iceberg/pull/1986#discussion_r550209583", "bodyText": "I am going to address the last two TODOs before this PR is merged.", "author": "aokolnychyi", "createdAt": "2020-12-30T14:17:41Z", "path": "spark3-extensions/src/test/java/org/apache/iceberg/spark/extensions/TestMerge.java", "diffHunk": "@@ -0,0 +1,197 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.extensions;\n+\n+import java.util.Map;\n+import org.apache.iceberg.AssertHelpers;\n+import org.apache.spark.sql.AnalysisException;\n+import org.junit.After;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+public abstract class TestMerge extends SparkRowLevelOperationsTestBase {\n+\n+  public TestMerge(String catalogName, String implementation, Map<String, String> config,\n+                   String fileFormat, boolean vectorized) {\n+    super(catalogName, implementation, config, fileFormat, vectorized);\n+  }\n+\n+  @BeforeClass\n+  public static void setupSparkConf() {\n+    spark.conf().set(\"spark.sql.shuffle.partitions\", \"4\");\n+  }\n+\n+  @After\n+  public void removeTables() {\n+    sql(\"DROP TABLE IF EXISTS %s\", tableName);\n+    sql(\"DROP TABLE IF EXISTS source\");\n+  }\n+\n+  // TODO: tests for reordering when operations succeed (both insert and update actions)\n+  // TODO: tests for action conditions\n+  // TODO: tests for writing nullable to not nullable, incompatible arrays, structs, atomic types", "originalCommit": "35180160909b685a2b3ac070aafda2ddaabc91b4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQ4MDIzMA==", "url": "https://github.com/apache/iceberg/pull/1986#discussion_r550480230", "bodyText": "These TODOs require an actual implementation.", "author": "aokolnychyi", "createdAt": "2020-12-31T13:10:05Z", "path": "spark3-extensions/src/test/java/org/apache/iceberg/spark/extensions/TestMerge.java", "diffHunk": "@@ -0,0 +1,336 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.extensions;\n+\n+import java.util.Arrays;\n+import java.util.Map;\n+import org.apache.iceberg.AssertHelpers;\n+import org.apache.spark.sql.AnalysisException;\n+import org.junit.After;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+public abstract class TestMerge extends SparkRowLevelOperationsTestBase {\n+\n+  public TestMerge(String catalogName, String implementation, Map<String, String> config,\n+                   String fileFormat, boolean vectorized) {\n+    super(catalogName, implementation, config, fileFormat, vectorized);\n+  }\n+\n+  @BeforeClass\n+  public static void setupSparkConf() {\n+    spark.conf().set(\"spark.sql.shuffle.partitions\", \"4\");\n+  }\n+\n+  @After\n+  public void removeTables() {\n+    sql(\"DROP TABLE IF EXISTS %s\", tableName);\n+    sql(\"DROP TABLE IF EXISTS source\");\n+  }\n+\n+  // TODO: tests for reordering when operations succeed (both insert and update actions)", "originalCommit": "7c14b157748a2146f66ee8101b30413433834328", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTY0MzczMQ==", "url": "https://github.com/apache/iceberg/pull/1986#discussion_r551643731", "bodyText": "What is the correct behavior here? Reject it?\nI think what would currently happen is it would fail if any existing field were accessed, but it would succeed if all fields were assigned. Is that correct?", "author": "rdblue", "createdAt": "2021-01-05T00:13:11Z", "path": "spark3-extensions/src/test/java/org/apache/iceberg/spark/extensions/TestMerge.java", "diffHunk": "@@ -0,0 +1,336 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.extensions;\n+\n+import java.util.Arrays;\n+import java.util.Map;\n+import org.apache.iceberg.AssertHelpers;\n+import org.apache.spark.sql.AnalysisException;\n+import org.junit.After;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+public abstract class TestMerge extends SparkRowLevelOperationsTestBase {\n+\n+  public TestMerge(String catalogName, String implementation, Map<String, String> config,\n+                   String fileFormat, boolean vectorized) {\n+    super(catalogName, implementation, config, fileFormat, vectorized);\n+  }\n+\n+  @BeforeClass\n+  public static void setupSparkConf() {\n+    spark.conf().set(\"spark.sql.shuffle.partitions\", \"4\");\n+  }\n+\n+  @After\n+  public void removeTables() {\n+    sql(\"DROP TABLE IF EXISTS %s\", tableName);\n+    sql(\"DROP TABLE IF EXISTS source\");\n+  }\n+\n+  // TODO: tests for reordering when operations succeed (both insert and update actions)\n+  // TODO: tests for modifying fields in a null struct", "originalCommit": "7c14b157748a2146f66ee8101b30413433834328", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTg1Mjc4Mw==", "url": "https://github.com/apache/iceberg/pull/1986#discussion_r551852783", "bodyText": "I think rejecting will be too restrictive. That would mean we won't be able to update any nullable structs.\nHere is what Postgres does:\npostgres=# INSERT INTO t_100 (id, c) VALUES (2, null);\nINSERT 0 1\n\npostgres=# SELECT * FROM t_100;\n id |   c   \n----+-------\n  1 | (1,2)\n  2 | \n(2 rows)\n\npostgres=# UPDATE t_100 SET c.n1 = -1;\nUPDATE 2\n\npostgres=# SELECT * FROM t_100;\n id |   c    \n----+--------\n  1 | (-1,2)\n  2 | (-1,)\n(2 rows)", "author": "aokolnychyi", "createdAt": "2021-01-05T10:43:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTY0MzczMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTg1MzExNw==", "url": "https://github.com/apache/iceberg/pull/1986#discussion_r551853117", "bodyText": "I think the existing logic matches Postgres.", "author": "aokolnychyi", "createdAt": "2021-01-05T10:44:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTY0MzczMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjEyMTY3MQ==", "url": "https://github.com/apache/iceberg/pull/1986#discussion_r552121671", "bodyText": "Okay, so the struct gets created and unspecified fields get set to null. Sounds good to me.", "author": "rdblue", "createdAt": "2021-01-05T18:42:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTY0MzczMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjQ0NzIwMg==", "url": "https://github.com/apache/iceberg/pull/1986#discussion_r552447202", "bodyText": "Yeah, correct.", "author": "aokolnychyi", "createdAt": "2021-01-06T09:00:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTY0MzczMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTY0NDc2MA==", "url": "https://github.com/apache/iceberg/pull/1986#discussion_r551644760", "bodyText": "I don't think that this should have a WHEN MATCHED case, to ensure that it is failing for the NOT MATCHED THEN INSERT.", "author": "rdblue", "createdAt": "2021-01-05T00:16:32Z", "path": "spark3-extensions/src/test/java/org/apache/iceberg/spark/extensions/TestMerge.java", "diffHunk": "@@ -0,0 +1,336 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.extensions;\n+\n+import java.util.Arrays;\n+import java.util.Map;\n+import org.apache.iceberg.AssertHelpers;\n+import org.apache.spark.sql.AnalysisException;\n+import org.junit.After;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+public abstract class TestMerge extends SparkRowLevelOperationsTestBase {\n+\n+  public TestMerge(String catalogName, String implementation, Map<String, String> config,\n+                   String fileFormat, boolean vectorized) {\n+    super(catalogName, implementation, config, fileFormat, vectorized);\n+  }\n+\n+  @BeforeClass\n+  public static void setupSparkConf() {\n+    spark.conf().set(\"spark.sql.shuffle.partitions\", \"4\");\n+  }\n+\n+  @After\n+  public void removeTables() {\n+    sql(\"DROP TABLE IF EXISTS %s\", tableName);\n+    sql(\"DROP TABLE IF EXISTS source\");\n+  }\n+\n+  // TODO: tests for reordering when operations succeed (both insert and update actions)\n+  // TODO: tests for modifying fields in a null struct\n+  // TODO: tests for subqueries in conditions\n+\n+  @Test\n+  public void testMergeWithNonExistingColumns() {\n+    createAndInitNestedColumnsTable();\n+    createOrReplaceView(\"source\", \"{ \\\"c1\\\": -100, \\\"c2\\\": -200 }\");\n+\n+    AssertHelpers.assertThrows(\"Should complain about the invalid top-level column\",\n+        AnalysisException.class, \"cannot resolve '`t.invalid_col`'\",\n+        () -> {\n+          sql(\"MERGE INTO %s t USING source s \" +\n+              \"ON t.id == s.c1 \" +\n+              \"WHEN MATCHED THEN \" +\n+              \"  UPDATE SET t.invalid_col = s.c2\", tableName);\n+        });\n+\n+    AssertHelpers.assertThrows(\"Should complain about the invalid nested column\",\n+        AnalysisException.class, \"No such struct field invalid_col\",\n+        () -> {\n+          sql(\"MERGE INTO %s t USING source s \" +\n+              \"ON t.id == s.c1 \" +\n+              \"WHEN MATCHED THEN \" +\n+              \"  UPDATE SET t.c.n2.invalid_col = s.c2\", tableName);\n+        });\n+\n+    AssertHelpers.assertThrows(\"Should complain about the invalid top-level column\",\n+        AnalysisException.class, \"cannot resolve '`invalid_col`'\",\n+        () -> {\n+          sql(\"MERGE INTO %s t USING source s \" +\n+              \"ON t.id == s.c1 \" +\n+              \"WHEN MATCHED THEN \" +\n+              \"  UPDATE SET t.c.n2.dn1 = s.c2 \" +\n+              \"WHEN NOT MATCHED THEN \" +\n+              \"  INSERT (id, invalid_col) VALUES (s.c1, null)\", tableName);\n+        });\n+  }\n+\n+  @Test\n+  public void testMergeWithInvalidColumnsInInsert() {\n+    createAndInitNestedColumnsTable();\n+    createOrReplaceView(\"source\", \"{ \\\"c1\\\": -100, \\\"c2\\\": -200 }\");\n+\n+    AssertHelpers.assertThrows(\"Should complain about the nested column\",\n+        AnalysisException.class, \"Nested fields are not supported inside INSERT clauses\",\n+        () -> {\n+          sql(\"MERGE INTO %s t USING source s \" +\n+              \"ON t.id == s.c1 \" +\n+              \"WHEN MATCHED THEN \" +\n+              \"  UPDATE SET t.c.n2.dn1 = s.c2 \" +\n+              \"WHEN NOT MATCHED THEN \" +\n+              \"  INSERT (id, c.n2) VALUES (s.c1, null)\", tableName);\n+        });\n+\n+    AssertHelpers.assertThrows(\"Should complain about duplicate columns\",\n+        AnalysisException.class, \"Duplicate column names inside INSERT clause\",\n+        () -> {\n+          sql(\"MERGE INTO %s t USING source s \" +\n+              \"ON t.id == s.c1 \" +\n+              \"WHEN MATCHED THEN \" +\n+              \"  UPDATE SET t.c.n2.dn1 = s.c2 \" +\n+              \"WHEN NOT MATCHED THEN \" +\n+              \"  INSERT (id, id) VALUES (s.c1, null)\", tableName);\n+        });\n+\n+    AssertHelpers.assertThrows(\"Should complain about missing columns\",\n+        AnalysisException.class, \"must provide values for all columns of the target table\",\n+        () -> {\n+          sql(\"MERGE INTO %s t USING source s \" +\n+              \"ON t.id == s.c1 \" +\n+              \"WHEN MATCHED THEN \" +\n+              \"  UPDATE SET t.c.n2.dn1 = s.c2 \" +", "originalCommit": "7c14b157748a2146f66ee8101b30413433834328", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTg2MTU5OQ==", "url": "https://github.com/apache/iceberg/pull/1986#discussion_r551861599", "bodyText": "+1", "author": "aokolnychyi", "createdAt": "2021-01-05T11:00:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTY0NDc2MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTg2MjgxNg==", "url": "https://github.com/apache/iceberg/pull/1986#discussion_r551862816", "bodyText": "Done.", "author": "aokolnychyi", "createdAt": "2021-01-05T11:03:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTY0NDc2MA=="}], "type": "inlineReview"}, {"oid": "12b567796ccb6ef878d2c063d2802df42168907f", "url": "https://github.com/apache/iceberg/commit/12b567796ccb6ef878d2c063d2802df42168907f", "message": "Spark: Add a rule to align updates in MERGE operations", "committedDate": "2021-01-05T10:59:17Z", "type": "forcePushed"}, {"oid": "8d48b6f6290b1f5a16cf1aea0d840ebb0ea36bcc", "url": "https://github.com/apache/iceberg/commit/8d48b6f6290b1f5a16cf1aea0d840ebb0ea36bcc", "message": "Spark: Add a rule to align updates in MERGE operations", "committedDate": "2021-01-05T11:01:44Z", "type": "forcePushed"}, {"oid": "58c7e78bb673e39fff0a71815073b8c07cef659a", "url": "https://github.com/apache/iceberg/commit/58c7e78bb673e39fff0a71815073b8c07cef659a", "message": "Spark: Add a rule to align updates in MERGE operations", "committedDate": "2021-01-05T11:02:43Z", "type": "commit"}, {"oid": "58c7e78bb673e39fff0a71815073b8c07cef659a", "url": "https://github.com/apache/iceberg/commit/58c7e78bb673e39fff0a71815073b8c07cef659a", "message": "Spark: Add a rule to align updates in MERGE operations", "committedDate": "2021-01-05T11:02:43Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjEyNjY0NQ==", "url": "https://github.com/apache/iceberg/pull/1986#discussion_r552126645", "bodyText": "I think it would be much easier to read these tests if instead of using these methods, you just embedded the CREATE TABLE here, like this:\n  sql(\"CREATE TABLE %s (..., complex struct<c1 int, c2 int) ...\", tableName);\n  initTable(tableName);\nThat way, it is easy to see what the available columns are without needing to refer back to the base class. I found it easy to see the structure and data for source, but kept going back to see what the target table's schema was. That was a bit harder considering the method is changed in this test.", "author": "rdblue", "createdAt": "2021-01-05T18:51:41Z", "path": "spark3-extensions/src/test/java/org/apache/iceberg/spark/extensions/TestMerge.java", "diffHunk": "@@ -0,0 +1,329 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.extensions;\n+\n+import java.util.Map;\n+import org.apache.iceberg.AssertHelpers;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.spark.sql.AnalysisException;\n+import org.junit.After;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+public abstract class TestMerge extends SparkRowLevelOperationsTestBase {\n+\n+  public TestMerge(String catalogName, String implementation, Map<String, String> config,\n+                   String fileFormat, boolean vectorized) {\n+    super(catalogName, implementation, config, fileFormat, vectorized);\n+  }\n+\n+  @BeforeClass\n+  public static void setupSparkConf() {\n+    spark.conf().set(\"spark.sql.shuffle.partitions\", \"4\");\n+  }\n+\n+  @After\n+  public void removeTables() {\n+    sql(\"DROP TABLE IF EXISTS %s\", tableName);\n+    sql(\"DROP TABLE IF EXISTS source\");\n+  }\n+\n+  // TODO: tests for reordering when operations succeed (both insert and update actions)\n+  // TODO: tests for modifying fields in a null struct\n+  // TODO: tests for subqueries in conditions\n+\n+  @Test\n+  public void testMergeWithNonExistingColumns() {\n+    createAndInitNestedColumnsTable();", "originalCommit": "58c7e78bb673e39fff0a71815073b8c07cef659a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjQ0MzM4Mg==", "url": "https://github.com/apache/iceberg/pull/1986#discussion_r552443382", "bodyText": "I tried to save some extra lines but I agree it is not readable.\nI'll change this to:\ncreateAndInitTable(\"id INT, c STRUCT<n1:INT,n2:STRUCT<dn1:INT,dn2:INT>>\");\n\nOnce we have tests for real cases, we can offer a method that will accept a JSON body.", "author": "aokolnychyi", "createdAt": "2021-01-06T08:51:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjEyNjY0NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjQ0ODcyMA==", "url": "https://github.com/apache/iceberg/pull/1986#discussion_r552448720", "bodyText": "Updated.", "author": "aokolnychyi", "createdAt": "2021-01-06T09:03:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjEyNjY0NQ=="}], "type": "inlineReview"}, {"oid": "7e58d21b421157de078d96bf92e10f6d352802f5", "url": "https://github.com/apache/iceberg/commit/7e58d21b421157de078d96bf92e10f6d352802f5", "message": "Some updates", "committedDate": "2021-01-06T09:03:04Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjkzMzAyMg==", "url": "https://github.com/apache/iceberg/pull/1986#discussion_r552933022", "bodyText": "Nit: this looks like Runnable with different names. If we are just introducing it to pass a lambda, we could probably use Runnable instead.", "author": "rdblue", "createdAt": "2021-01-06T19:57:07Z", "path": "spark/src/test/java/org/apache/iceberg/spark/SparkTestBase.java", "diffHunk": "@@ -132,4 +134,40 @@ protected void assertEquals(String context, List<Object[]> expectedRows, List<Ob\n   protected static String dbPath(String dbName) {\n     return metastore.getDatabasePath(dbName);\n   }\n+\n+  protected void withSQLConf(Map<String, String> conf, Action action) {\n+    SQLConf sqlConf = SQLConf.get();\n+\n+    Map<String, String> currentConfValues = Maps.newHashMap();\n+    conf.keySet().forEach(confKey -> {\n+      if (sqlConf.contains(confKey)) {\n+        String currentConfValue = sqlConf.getConfString(confKey);\n+        currentConfValues.put(confKey, currentConfValue);\n+      }\n+    });\n+\n+    conf.forEach((confKey, confValue) -> {\n+      if (SQLConf.staticConfKeys().contains(confKey)) {\n+        throw new RuntimeException(\"Cannot modify the value of a static config: \" + confKey);\n+      }\n+      sqlConf.setConfString(confKey, confValue);\n+    });\n+\n+    try {\n+      action.invoke();\n+    } finally {\n+      conf.forEach((confKey, confValue) -> {\n+        if (currentConfValues.containsKey(confKey)) {\n+          sqlConf.setConfString(confKey, currentConfValues.get(confKey));\n+        } else {\n+          sqlConf.unsetConf(confKey);\n+        }\n+      });\n+    }\n+  }\n+\n+  @FunctionalInterface\n+  protected interface Action {\n+    void invoke();\n+  }", "originalCommit": "7e58d21b421157de078d96bf92e10f6d352802f5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}