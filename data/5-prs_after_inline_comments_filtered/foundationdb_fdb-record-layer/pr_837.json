{"pr_number": 837, "pr_title": "Resolves #806: Rank index could have option for how to handle ties", "pr_createdAt": "2020-02-27T00:47:00Z", "pr_url": "https://github.com/FoundationDB/fdb-record-layer/pull/837", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg1NDQ1Ng==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r384854456", "bodyText": "There is a separate commit to relocate this method, which might make it easier to track how it has changed (other than that).", "author": "MMcM", "createdAt": "2020-02-27T00:48:20Z", "path": "fdb-extensions/src/main/java/com/apple/foundationdb/async/RankedSet.java", "diffHunk": "@@ -246,6 +382,80 @@ public RankedSet(Subspace subspace, Executor executor) {\n         });\n     }\n \n+    /**\n+     * Removes a key from the set.\n+     * @param tc the transaction to use to access the database\n+     * @param key the key to remove\n+     * @return a future that completes to {@code true} if the set was modified, that is, if the key was present before this operation\n+     */\n+    public CompletableFuture<Boolean> remove(TransactionContext tc, byte[] key) {", "originalCommit": "d1b1b6f12150d9e94b768b4c08c62200d1d4a478", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE1NTUyNw==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r389155527", "bodyText": "Thanks! That was actually fairly useful when reviewing.", "author": "alecgrieser", "createdAt": "2020-03-06T21:34:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg1NDQ1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg1NDgxOA==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r384854818", "bodyText": "If there were a separate RankedMultiset class, this would only be on it, though it seems well-defined everywhere.", "author": "MMcM", "createdAt": "2020-02-27T00:49:12Z", "path": "fdb-extensions/src/main/java/com/apple/foundationdb/async/RankedSet.java", "diffHunk": "@@ -267,17 +477,30 @@ public RankedSet(Subspace subspace, Executor executor) {\n      */\n     public CompletableFuture<Boolean> contains(ReadTransactionContext tc, byte[] key) {\n         checkKey(key);\n-        return containsCheckedKey(tc, key);\n+        return countCheckedKey(tc, key).thenApply(c -> c != null && c > 0);\n+    }\n+\n+    /**\n+     * Count the number of occurrences of a key in the set.\n+     * @param tc the transaction to use to access the database\n+     * @param key the key to check for\n+     * @return a future that completes to {@code 0} if the key is not present in the ranked set or\n+     * {@code 1} if the key is present in the ranked set and duplicates are not counted or\n+     * the number of occurrences if duplicated are counted separately\n+     */\n+    public CompletableFuture<Long> count(ReadTransactionContext tc, byte[] key) {", "originalCommit": "d1b1b6f12150d9e94b768b4c08c62200d1d4a478", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg1NTAxOA==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r384855018", "bodyText": "I don't think there was any reason to do this with a getRange before. I'm also not sure the snapshot is needed any more.", "author": "MMcM", "createdAt": "2020-02-27T00:49:55Z", "path": "fdb-extensions/src/main/java/com/apple/foundationdb/async/RankedSet.java", "diffHunk": "@@ -643,19 +819,21 @@ private static void checkKey(byte[] key) {\n                         .thenApply(longs -> longs.stream().reduce(0L, Long::sum)));\n     }\n \n-    private CompletableFuture<byte[]> getPreviousKey(TransactionContext tc, int level, byte[] key) {\n+    // Get the key before this one at the given level.\n+    // If orEqual is given, then an exactly matching key is also considered. This is only used when the key is known\n+    // to be a duplicate or an existing key and so should do whatever it did.\n+    private CompletableFuture<byte[]> getPreviousKey(TransactionContext tc, int level, byte[] key, boolean orEqual) {\n         byte[] k = subspace.pack(Tuple.from(level, key));\n         CompletableFuture<byte[]> kf = tc.run(tr ->\n-                tr.snapshot()\n-                        .getRange(KeySelector.lastLessThan(k), KeySelector.firstGreaterOrEqual(k), 1)\n-                        .asList()\n-                        .thenApply(kvs -> {\n-                            byte[] prevk = kvs.get(0).getKey();\n-                            // If another key were inserted after between this and the target key,\n-                            // it wouldn't be the one we should increment any more.\n-                            // But do not conflict when key itself is incremented.\n-                            byte[] exclusiveBegin = ByteArrayUtil.join(prevk, ZERO_ARRAY);\n-                            tr.addReadConflictRange(exclusiveBegin, k);\n+                tr.snapshot().getKey(orEqual ? KeySelector.lastLessOrEqual(k) : KeySelector.lastLessThan(k))", "originalCommit": "d1b1b6f12150d9e94b768b4c08c62200d1d4a478", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY1MDcxOQ==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r388650719", "bodyText": "I think we still want to do this at snapshot because I think a modification (like an increment) to exactly the read key will cause a conflict...though I could be wrong.\nAs to getRange or getKey, I think it's about six of one, half dozen of the other as it's actually translated to a get range call in the C API anyway. Usually, I think the advice is to not use getKey if you can't guarantee that the key range doesn't \"leak\" out of the subspace, but I think the empty arrays at the beginning of each level should handle that in this case, so I think it's fine.", "author": "alecgrieser", "createdAt": "2020-03-06T00:51:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg1NTAxOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTg2MDIyMA==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r389860220", "bodyText": "The previous code,\n.getRange(KeySelector.lastLessThan(k), KeySelector.firstGreaterOrEqual(k), 1)\n\ndidn't really have that protection, since it used two key selectors from the same input.\nWould it be better then (that is, protecting against some screwup with the ('',0) entry) to do a reverse getRange with the left the level limit and the right the target?", "author": "MMcM", "createdAt": "2020-03-09T17:52:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg1NTAxOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTg2MjIzNQ==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r389862235", "bodyText": "Yeah, I think a range read like that would make sense, and it would protect us from exactly that kind of screw up.", "author": "alecgrieser", "createdAt": "2020-03-09T17:55:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg1NTAxOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTg4MzY4NA==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r389883684", "bodyText": "I switched to not using KeySelectors and doing a limit 1 reverse range scan.", "author": "MMcM", "createdAt": "2020-03-09T18:34:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg1NTAxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTE2MDcwMQ==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r385160701", "bodyText": "Not much thought went into mixing set and multiset on the same subspace. Other than not violating the consistency invariants. In particular, remove always removes (up to) one occurrence. Would it be better if it removed all when not counting duplicates?", "author": "MMcM", "createdAt": "2020-02-27T14:28:19Z", "path": "fdb-extensions/src/main/java/com/apple/foundationdb/async/RankedSet.java", "diffHunk": "@@ -246,6 +382,80 @@ public RankedSet(Subspace subspace, Executor executor) {\n         });\n     }\n \n+    /**\n+     * Removes a key from the set.\n+     * @param tc the transaction to use to access the database\n+     * @param key the key to remove\n+     * @return a future that completes to {@code true} if the set was modified, that is, if the key was present before this operation\n+     */\n+    public CompletableFuture<Boolean> remove(TransactionContext tc, byte[] key) {\n+        checkKey(key);\n+        return tc.runAsync(tr ->\n+                countCheckedKey(tr, key)\n+                        .thenCompose(count -> {\n+                            if (count == null || count <= 0) {\n+                                return READY_FALSE;\n+                            }\n+                            // This works even if the current set does not track duplicates but duplicates were added\n+                            // earlier by one that did.\n+                            final boolean duplicate = count > 1;\n+                            final int nlevels = config.getNLevels();\n+                            final List<CompletableFuture<Void>> futures = new ArrayList<>(nlevels);\n+                            for (int li = 0; li < nlevels; ++li) {\n+                                final int level = li;\n+\n+                                final CompletableFuture<Void> future;\n+\n+                                if (duplicate) {\n+                                    // Always subtract one, never clearing a key. It is possible for this to leave\n+                                    // a key with a count of zero, if duplicates were inserted with different hash functions.\n+                                    Function<byte[], Void> decrement = k -> {\n+                                        tr.mutate(MutationType.ADD, subspace.pack(Tuple.from(level, k)), encodeLong(-1));\n+                                        return null;\n+                                    };\n+                                    if (level == 0) {\n+                                        decrement.apply(key);\n+                                        future = DONE;\n+                                    } else {\n+                                        future = getPreviousKey(tr, level, key, true).thenApply(decrement);\n+                                    }\n+                                } else {\n+                                    // This could be optimized to check the hash for which levels should have this key.\n+                                    // That would require that the hash function never changes, though.\n+                                    // This allows for it to change, with the distribution perhaps getting a little uneven\n+                                    // as a result. It even allows for the hash function to return a random number.\n+                                    final byte[] k = subspace.pack(Tuple.from(level, key));\n+                                    final CompletableFuture<byte[]> cf = tr.get(k);\n+\n+                                    if (level == 0) {\n+                                        future = cf.thenApply(c -> {\n+                                            if (c != null) {\n+                                                tr.clear(k);\n+                                            }\n+                                            return null;\n+                                        });\n+                                    } else {\n+                                        final CompletableFuture<byte[]> prevKeyF = getPreviousKey(tr, level, key, false);\n+                                        future = CompletableFuture.allOf(cf, prevKeyF)\n+                                                .thenApply(vignore -> {\n+                                                    final byte[] c = cf.join();\n+                                                    long countChange = -1;", "originalCommit": "d1b1b6f12150d9e94b768b4c08c62200d1d4a478", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE1NDAxMQ==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r389154011", "bodyText": "I think having it always remove 1 is fine, especially as it's generally unsafe to have a ranked set and a multiset in the same space. I guess this (kind of) actually removes all from level 0 and then 1 from the other levels, which is maybe a little weird. I guess also if someone calls remove on a value that isn't actually in the set, it will break the invariants of the range set (in that it will subtract 1 from only the higher levels).\nI suppose it would also be kind of nice if this and the \"duplicates\" case were more similar, though it would require I think changing either the semantics of the existing sets to allow for keys to be present in only the higher levels of the ranked set or to modify the logic in the \"removes duplicates\" case to remove keys that have been zero'd out (including possibly non-empty keys in the higher levels).", "author": "alecgrieser", "createdAt": "2020-03-06T21:31:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTE2MDcwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTg4NDc5Mw==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r389884793", "bodyText": "I fixed the comments. It should not, in fact, be possible to decrement to zero any more.\nWhich means that if we did decide that remove should mean remove all, it would be consistent in clearing any splits induced by the given key.", "author": "MMcM", "createdAt": "2020-03-09T18:36:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTE2MDcwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDAyMTA2Mg==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r390021062", "bodyText": "Maybe I'm missing the change, but it looks like one could still decrement a key to zero (in duplicate counting mode), in that it just decrements the value by 1.", "author": "alecgrieser", "createdAt": "2020-03-09T23:45:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTE2MDcwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDAzNjY3Ng==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r390036676", "bodyText": "Here is my reasoning:\nIn add, if a key is already present (based on checking level 0 != 0), then the hash is ignored and each key that was incremented last time is incremented again. In other words, a duplicate value is counted n times at every level reliably.\nIn remove, if a key is not the last occurrence (based on checking level 0 > 1), then it is safe to simply decrement every level because this key must have contributed at least 2 to each of them. If a key is the last occurrence, then if the key decremented at any level matches exactly (as opposed to being somewhere to the left), it is cleared. This is the only key that might otherwise have been decremented to zero, I believe.\nSimultaneous removes of the same key conflict on level 0.", "author": "MMcM", "createdAt": "2020-03-10T00:43:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTE2MDcwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDA0MjE1Ng==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r390042156", "bodyText": "Oh, I think I see what I was missing: I had though that the duplicate boolean was determined by the configuration rather than by the count that actually gets read. I'll have to rethink what this is doing with that in mind.", "author": "alecgrieser", "createdAt": "2020-03-10T01:06:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTE2MDcwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDA0NTUwNw==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r390045507", "bodyText": "Yeah, this now makes sense to me, and I believe you're right--that essentially because all updates contend on their level 0 key, some of the nasty edge cases that can lead to concurrent decrements resulting in there being a count set to zero. I suppose we may need to re-architect if we decide that that's \"too much contention\" or something.", "author": "alecgrieser", "createdAt": "2020-03-10T01:20:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTE2MDcwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDA0NjQzMQ==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r390046431", "bodyText": "As to the original question, I think that having remove always be \"remove 1\" is fine, and now here my reasoning is: (1) having it that way decreases the number of branches (on the config value) from the code and (2) changing the value of the config parameter is weird enough that we should generally avoid doing it (hence banning changing it at the meta-data level) and shouldn't add complexity to the code to support it.\nBut my feelings aren't particularly strong.", "author": "alecgrieser", "createdAt": "2020-03-10T01:24:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTE2MDcwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTE2MTE5NA==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r385161194", "bodyText": "Is it worth having a RANDOM_HASH_FUNCTION? Roughly, threadLocalRandom.getInt(). And a test to show that it works?", "author": "MMcM", "createdAt": "2020-02-27T14:29:03Z", "path": "fdb-extensions/src/main/java/com/apple/foundationdb/async/RankedSet.java", "diffHunk": "@@ -246,6 +382,80 @@ public RankedSet(Subspace subspace, Executor executor) {\n         });\n     }\n \n+    /**\n+     * Removes a key from the set.\n+     * @param tc the transaction to use to access the database\n+     * @param key the key to remove\n+     * @return a future that completes to {@code true} if the set was modified, that is, if the key was present before this operation\n+     */\n+    public CompletableFuture<Boolean> remove(TransactionContext tc, byte[] key) {\n+        checkKey(key);\n+        return tc.runAsync(tr ->\n+                countCheckedKey(tr, key)\n+                        .thenCompose(count -> {\n+                            if (count == null || count <= 0) {\n+                                return READY_FALSE;\n+                            }\n+                            // This works even if the current set does not track duplicates but duplicates were added\n+                            // earlier by one that did.\n+                            final boolean duplicate = count > 1;\n+                            final int nlevels = config.getNLevels();\n+                            final List<CompletableFuture<Void>> futures = new ArrayList<>(nlevels);\n+                            for (int li = 0; li < nlevels; ++li) {\n+                                final int level = li;\n+\n+                                final CompletableFuture<Void> future;\n+\n+                                if (duplicate) {\n+                                    // Always subtract one, never clearing a key. It is possible for this to leave\n+                                    // a key with a count of zero, if duplicates were inserted with different hash functions.\n+                                    Function<byte[], Void> decrement = k -> {\n+                                        tr.mutate(MutationType.ADD, subspace.pack(Tuple.from(level, k)), encodeLong(-1));\n+                                        return null;\n+                                    };\n+                                    if (level == 0) {\n+                                        decrement.apply(key);\n+                                        future = DONE;\n+                                    } else {\n+                                        future = getPreviousKey(tr, level, key, true).thenApply(decrement);\n+                                    }\n+                                } else {\n+                                    // This could be optimized to check the hash for which levels should have this key.\n+                                    // That would require that the hash function never changes, though.\n+                                    // This allows for it to change, with the distribution perhaps getting a little uneven\n+                                    // as a result. It even allows for the hash function to return a random number.", "originalCommit": "d1b1b6f12150d9e94b768b4c08c62200d1d4a478", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY5MzEzOA==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r388693138", "bodyText": "I think that would certainly be an interesting test hash function and test, if it's not too hard to add. Hard for me to say that it's necessarily \"worth\" it, though it would be kind of cool.", "author": "alecgrieser", "createdAt": "2020-03-06T03:11:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTE2MTE5NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTg4NDkwNQ==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r389884905", "bodyText": "I added the basic test for this.", "author": "MMcM", "createdAt": "2020-03-09T18:36:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTE2MTE5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTMyMDk4Mw==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r385320983", "bodyText": "I suppose these overloads could say that they are just synonyms for the overload that takes a full Config object with the defaults/parameters set as appropriate.", "author": "alecgrieser", "createdAt": "2020-02-27T19:23:15Z", "path": "fdb-extensions/src/main/java/com/apple/foundationdb/async/RankedSet.java", "diffHunk": "@@ -143,30 +144,153 @@ private static long decodeLong(byte[] v) {\n         int hash(byte[] key);\n     }\n \n+    /**\n+     * Configuration settings for a {@link RankedSet}.\n+     */\n+    public static class Config {\n+        private final HashFunction hashFunction;\n+        private final int nlevels;\n+        private final boolean countDuplicates;\n+\n+        protected Config() {\n+            this.hashFunction = DEFAULT_HASH_FUNCTION;\n+            this.nlevels = DEFAULT_LEVELS;\n+            this.countDuplicates = false;\n+        }\n+\n+        protected Config(HashFunction hashFunction, int nlevels, boolean countDuplicates) {\n+            this.hashFunction = hashFunction;\n+            this.nlevels = nlevels;\n+            this.countDuplicates = countDuplicates;\n+        }\n+\n+        /**\n+         * Get the hash function to use.\n+         * @return a {@link HashFunction} used to convert keys to a bit mask used to determine level splits in the skip list\n+         */\n+        public HashFunction getHashFunction() {\n+            return hashFunction;\n+        }\n+\n+        /**\n+         * Get the number of levels to use.\n+         * @return the number of levels in the skip list\n+         */\n+        public int getNLevels() {\n+            return nlevels;\n+        }\n+\n+        /**\n+         * Get whether duplicate entries increase ranks below them.\n+         * @return {@code true} if duplicates are counted separately\n+         */\n+        public boolean isCountDuplicates() {\n+            return countDuplicates;\n+        }\n+    }\n+\n+\n+    /**\n+     * Builder for {@link Config}.\n+     *\n+     * @see #newConfigBuilder\n+     */\n+    public static class ConfigBuilder {\n+        private HashFunction hashFunction = DEFAULT_HASH_FUNCTION;\n+        private int nlevels = DEFAULT_LEVELS;\n+        private boolean countDuplicates = false;\n+\n+        protected ConfigBuilder() {\n+        }\n+\n+        public HashFunction getHashFunction() {\n+            return hashFunction;\n+        }\n+\n+        /**\n+         * Set the hash function to use.\n+         *\n+         * It is possible to change the hash function of an existing ranked set, although this is not recommended since the distribution in the skip list may\n+         * become uneven as a result.\n+         * @param hashFunction the hash function to use\n+         * @return this builder\n+         */\n+        public ConfigBuilder setHashFunction(HashFunction hashFunction) {\n+            this.hashFunction = hashFunction;\n+            return this;\n+        }\n+\n+        public int getNLevels() {\n+            return nlevels;\n+        }\n+\n+        /**\n+         * Set the hash function to use.\n+         *\n+         * It is not currently possible to change the number of levels for an existing ranked set.\n+         * @param nlevels the number of levels to use\n+         * @return this builder\n+         */\n+        public ConfigBuilder setNLevels(int nlevels) {\n+            if (nlevels < 2 || nlevels > MAX_LEVELS) {\n+                throw new IllegalArgumentException(\"levels must be between 2 and \" + MAX_LEVELS);\n+            }\n+            this.nlevels = nlevels;\n+            return this;\n+        }\n+\n+        public boolean isCountDuplicates() {\n+            return countDuplicates;\n+        }\n+\n+        /**\n+         * Set whether to count duplicate keys separately.\n+         *\n+         * If duplicate keys are counted separately, ranks after them are increased by the number of duplicates.\n+         * @param countDuplicates whether to count duplicates\n+         * @return this builder\n+         */\n+        public ConfigBuilder setCountDuplicates(boolean countDuplicates) {\n+            this.countDuplicates = countDuplicates;\n+            return this;\n+        }\n+\n+        public Config build() {\n+            return new Config(hashFunction, nlevels, countDuplicates);\n+        }\n+    }\n+\n+    /**\n+     * Start building a {@link Config}.\n+     * @return a new {@code Config} that can be altered and then built for use with a {@link RankedSet}\n+     * @see ConfigBuilder#build\n+     */\n+    public static ConfigBuilder newConfigBuilder() {\n+        return new ConfigBuilder();\n+    }\n+\n     /**\n      * Initialize a new ranked set.\n      * @param subspace the subspace where the ranked set is stored\n      * @param executor an executor to use when running asynchronous tasks\n-     * @param hashFunction hash function to use to determine which levels a key splits on\n-     * @param nlevels number of skip list levels to maintain\n+     * @param config configuration to use\n      */\n-    public RankedSet(Subspace subspace, Executor executor, HashFunction hashFunction, int nlevels) {\n-        if (nlevels < 2 || nlevels > MAX_LEVELS) {\n-            throw new IllegalArgumentException(\"levels must be between 2 and \" + MAX_LEVELS);\n-        }\n-\n+    public RankedSet(Subspace subspace, Executor executor, Config config) {\n         this.subspace = subspace;\n         this.executor = executor;\n-        this.hashFunction = hashFunction;\n-        this.nlevels = nlevels;\n+        this.config = config;\n+    }\n+\n+    public RankedSet(Subspace subspace, Executor executor, HashFunction hashFunction, int nlevels) {", "originalCommit": "d1b1b6f12150d9e94b768b4c08c62200d1d4a478", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTg4NTA0MA==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r389885040", "bodyText": "Added such comments.", "author": "MMcM", "createdAt": "2020-03-09T18:36:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTMyMDk4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY0MTA1MQ==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r388641051", "bodyText": "If I understand this, the duplicate || here is to ensure that we don't split at the same point twice and then (in a world where, for example, the \"hash\" was just random each time instead of based on the data) don't decide to add a split only on the second time we see it (or something). Might be nice to have a comment here about that.", "author": "alecgrieser", "createdAt": "2020-03-06T00:22:25Z", "path": "fdb-extensions/src/main/java/com/apple/foundationdb/async/RankedSet.java", "diffHunk": "@@ -179,33 +303,39 @@ public RankedSet(Subspace subspace, Executor executor) {\n      * @return {@code true} if this ranked set needs to be initialized\n      */\n     public CompletableFuture<Boolean> initNeeded(ReadTransactionContext tc) {\n-        return containsCheckedKey(tc, EMPTY_ARRAY).thenApply(b -> !b);\n+        return countCheckedKey(tc, EMPTY_ARRAY).thenApply(Objects::isNull);\n     }\n \n     /**\n      * Add a key to the set.\n+     *\n+     * If {@link Config#isCountDuplicates} is {@code false} and {@code key} is already present, the return value is {@code false}.\n+     * If {@link Config#isCountDuplicates} is {@code true}, the return value is never {@code false} and a duplicate will\n+     * cause all {@link #rank}s below it to increase by one.\n      * @param tc the transaction to use to access the database\n      * @param key the key to add\n-     * @return a future that completes to {@code true} if the key was not already present\n+     * @return a future that completes to {@code true} if the ranked set was modified\n      */\n     public CompletableFuture<Boolean> add(TransactionContext tc, byte[] key) {\n         checkKey(key);\n         // Use the hash of the key, instead a p value and randomLevel. The key is likely Tuple-encoded.\n-        long keyHash = hashFunction.hash(key);\n+        final long keyHash = config.getHashFunction().hash(key);\n         return tc.runAsync(tr ->\n-            containsCheckedKey(tr, key)\n-                .thenCompose(exists -> {\n-                    if (exists) {\n+            countCheckedKey(tr, key)\n+                .thenCompose(count -> {\n+                    final boolean duplicate = count != null && count > 0;\n+                    if (duplicate && !config.isCountDuplicates()) {\n                         return READY_FALSE;\n                     }\n+                    final int nlevels = config.getNLevels();\n                     List<CompletableFuture<Void>> futures = new ArrayList<>(nlevels);\n                     for (int li = 0; li < nlevels; ++li) {\n-                        int level = li;\n+                        final int level = li;\n                         CompletableFuture<Void> future;\n                         if (level == 0) {\n-                            future = addLevelZeroKey(tr, key, level);\n-                        } else if ((keyHash & LEVEL_FAN_VALUES[level]) != 0) {\n-                            future = addIncrementLevelKey(tr, key, level);\n+                            future = addLevelZeroKey(tr, key, level, duplicate);\n+                        } else if (duplicate || (keyHash & LEVEL_FAN_VALUES[level]) != 0) {", "originalCommit": "d1b1b6f12150d9e94b768b4c08c62200d1d4a478", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTg4NTI0OQ==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r389885249", "bodyText": "I amplified these comments.", "author": "MMcM", "createdAt": "2020-03-09T18:37:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY0MTA1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY0NTQwNQ==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r388645405", "bodyText": "It's a little unfortunate our nullability annotations don't allow us to return an @Nullable Long. IIUC, we do actually check the nullity (rather than treat it as zero) to check if we need to initialize the ranked set, which is a little unfortunate. hmm", "author": "alecgrieser", "createdAt": "2020-03-06T00:34:15Z", "path": "fdb-extensions/src/main/java/com/apple/foundationdb/async/RankedSet.java", "diffHunk": "@@ -267,17 +477,30 @@ public RankedSet(Subspace subspace, Executor executor) {\n      */\n     public CompletableFuture<Boolean> contains(ReadTransactionContext tc, byte[] key) {\n         checkKey(key);\n-        return containsCheckedKey(tc, key);\n+        return countCheckedKey(tc, key).thenApply(c -> c != null && c > 0);\n+    }\n+\n+    /**\n+     * Count the number of occurrences of a key in the set.\n+     * @param tc the transaction to use to access the database\n+     * @param key the key to check for\n+     * @return a future that completes to {@code 0} if the key is not present in the ranked set or\n+     * {@code 1} if the key is present in the ranked set and duplicates are not counted or\n+     * the number of occurrences if duplicated are counted separately\n+     */\n+    public CompletableFuture<Long> count(ReadTransactionContext tc, byte[] key) {\n+        checkKey(key);\n+        return countCheckedKey(tc, key).thenApply(c -> c == null ? Long.valueOf(0) : c);\n     }\n \n-    private CompletableFuture<Boolean> containsCheckedKey(ReadTransactionContext tc, byte[] key) {\n-        return tc.readAsync(tr -> tr.get(subspace.pack(Tuple.from(0, key))).thenApply(Objects::nonNull));\n+    private CompletableFuture<Long> countCheckedKey(ReadTransactionContext tc, byte[] key) {\n+        return tc.readAsync(tr -> tr.get(subspace.pack(Tuple.from(0, key))).thenApply(b -> b == null ? null : decodeLong(b)));", "originalCommit": "d1b1b6f12150d9e94b768b4c08c62200d1d4a478", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY1MDc5MQ==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r388650791", "bodyText": "I don't think that this conflict is necessary in multi-set mode, as keys are never removed (at the moment), though I suppose that could change. It also could result in spurious conflicts when the values of those keys are incremented or decremented (but not to 0).\nedit: removed first claim based on re-read of remove code.", "author": "alecgrieser", "createdAt": "2020-03-06T00:51:22Z", "path": "fdb-extensions/src/main/java/com/apple/foundationdb/async/RankedSet.java", "diffHunk": "@@ -643,19 +819,21 @@ private static void checkKey(byte[] key) {\n                         .thenApply(longs -> longs.stream().reduce(0L, Long::sum)));\n     }\n \n-    private CompletableFuture<byte[]> getPreviousKey(TransactionContext tc, int level, byte[] key) {\n+    // Get the key before this one at the given level.\n+    // If orEqual is given, then an exactly matching key is also considered. This is only used when the key is known\n+    // to be a duplicate or an existing key and so should do whatever it did.\n+    private CompletableFuture<byte[]> getPreviousKey(TransactionContext tc, int level, byte[] key, boolean orEqual) {\n         byte[] k = subspace.pack(Tuple.from(level, key));\n         CompletableFuture<byte[]> kf = tc.run(tr ->\n-                tr.snapshot()\n-                        .getRange(KeySelector.lastLessThan(k), KeySelector.firstGreaterOrEqual(k), 1)\n-                        .asList()\n-                        .thenApply(kvs -> {\n-                            byte[] prevk = kvs.get(0).getKey();\n-                            // If another key were inserted after between this and the target key,\n-                            // it wouldn't be the one we should increment any more.\n-                            // But do not conflict when key itself is incremented.\n-                            byte[] exclusiveBegin = ByteArrayUtil.join(prevk, ZERO_ARRAY);\n-                            tr.addReadConflictRange(exclusiveBegin, k);\n+                tr.snapshot().getKey(orEqual ? KeySelector.lastLessOrEqual(k) : KeySelector.lastLessThan(k))\n+                        .thenApply(prevk -> {\n+                            if (!orEqual || !Arrays.equals(prevk, k)) {\n+                                // If another key were inserted after between this and the target key,\n+                                // it wouldn't be the one we should increment any more.\n+                                // But do not conflict when key itself is incremented.\n+                                byte[] exclusiveBegin = ByteArrayUtil.join(prevk, ZERO_ARRAY);\n+                                tr.addReadConflictRange(exclusiveBegin, k);\n+                            }\n                             // Do conflict if key is removed entirely.\n                             tr.addReadConflictKey(subspace.pack(Tuple.from(0, subspace.unpack(prevk).getBytes(1))));", "originalCommit": "d1b1b6f12150d9e94b768b4c08c62200d1d4a478", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTg2NDIzMg==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r389864232", "bodyText": "I believe that in the case where this is a duplicate and matches the key itself, this adds another read conflict for the one that was already added by countCheckedKey to determine that it was a duplicate. So I'm not sure what the case is where this is a totally superfluous read conflict.", "author": "MMcM", "createdAt": "2020-03-09T17:58:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY1MDc5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTg3MjA0Mw==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r389872043", "bodyText": "I was thinking something like: you have two entries, a and b in level 0 and only a in level 1. Then if you increment b, that will induce a conflict range on b in level 0 (from countCheckedKey) and the range (a, b] (I think) in level 1 and then on just a in level 0. But a concurrent increment of a would change the value of a in level 0, so the increment on b could be failed as a result, but if this conflict range is removed, I think the conflict induced by the increment of a that fails the increment of b wouldn't happen. I think.", "author": "alecgrieser", "createdAt": "2020-03-09T18:13:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY1MDc5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY1MjE3Ng==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r388652176", "bodyText": "Hm, it's a little unfortunate that this would leave around empty keys and signposts. I think we could almost get around this by adding tr.mutate(MutationType.COMPARE_AND_CLEAR, subspace.pack(Tuple.from(level, k)), encodeLong(0)) (probably not serializing the key twice), but there's a case I was thinking through that I think this breaks for.\nSuppose you had a 2-level skip list with something like:\nlevel 1: (0 -> 1)----(1 -> 1)---------------------(5 -> 1)\nlevel 0: (0 -> 1)-------------------(3 -> 1)------(5 -> 1)\n\n(That is 0, 3, and 5 in level 0 and 0, 1, and 5 in level 1. Presumably, there used to be a 1 in the skip list, but it was removed at some point.) Then suppose you had the following three operations: insert 2, remove 3, insert 4, and assume that neither of the two inserts cause a split. And assume the following ordering of GRVs and commits:\n\ninsert 4 GRV\nremove 3 GRV\nremove 3 commit\ninsert 2 GRV\ninsert 2 commit\ninsert 4 commit\n\nAfter the remove 3 has committed, then I think the skip list would look like:\nlevel 1: (0 -> 1)------------------------------(5 -> 1)\nlevel 0: (0 -> 1)------------------------------(5 -> 1)\n\nAs removing 3 also decrements the count of 1 to 0. So when 2 is inserted (and commits), it doesn't see anything at the higher levels before 0. So the skip list it writes looks like:\nlevel 1: (0 -> 2)-------------------------------(5 -> 1)\nlevel 0: (0 -> 1)--------------(2 -> 1)---------(5 -> 1)\n\nBut the insert of 4 happened when 1 still was in level 1, so it will increment that value, which I believes results in this invalid skip list if committed:\nlevel 1: (0 -> 2)---(1 -> 1)------------------------(5 -> 1)\nlevel 0: (0 -> 1)-------------(2 -> 1)---(4 -> 1)---(5 -> 1)\n\nAnd the read conflict set on committing the insert of 4 would be on level 0's key 1 (which was not modified) and on the level 1 range from key 1 (exclusive) to 4 (inclusive), none of which changed. So I think this commit is successful.\nI don't actually think this problem is possible with the code as it is, given that it keeps the zero's around, though I could be convinced that we haven't thought through all of the cases here. (The fatal flaw here is that we add a read conflict on the level 0 key for the sign-post key as a proxy for \"fail this transaction only if the key disappears\", but that isn't necessarily the case in the proposal as I've sketched it. As we never remove any key from the range set, the current code can't hit that pathology as written.)\nI wonder if there might be a way to expand the write conflict range of a delete (maybe) on a key delete or something, of at least the upper levels, and if that would be sufficient, though it may not work with mixed software versions. It's also possible that instead of this fancy \"compare and clear\" business that I suggested, instead, it needs to enforce that if a key is at level k, then that key is present in all levels less than k, which is a property of the current code and also skip lists more generally, but it would probably hurt the concurrency of the multi-set case (though maybe the code paths for set and multi-set are more similar?).", "author": "alecgrieser", "createdAt": "2020-03-06T00:54:21Z", "path": "fdb-extensions/src/main/java/com/apple/foundationdb/async/RankedSet.java", "diffHunk": "@@ -356,37 +396,59 @@ public RankedSet(Subspace subspace, Executor executor) {\n                             if (count == null || count <= 0) {\n                                 return READY_FALSE;\n                             }\n+                            // This works even if the current set does not track duplicates but duplicates were added\n+                            // earlier by one that did.\n+                            final boolean duplicate = count > 1;\n                             final int nlevels = config.getNLevels();\n                             final List<CompletableFuture<Void>> futures = new ArrayList<>(nlevels);\n                             for (int li = 0; li < nlevels; ++li) {\n                                 final int level = li;\n-                                // This could be optimized to check the hash for which levels should have this key.\n-                                final byte[] k = subspace.pack(Tuple.from(level, key));\n \n                                 final CompletableFuture<Void> future;\n-                                final CompletableFuture<byte[]> cf = tr.get(k);\n \n-                                if (level == 0) {\n-                                    future = cf.thenApply(c -> {\n-                                        if (c != null) {\n-                                            tr.clear(k);\n-                                        }\n+                                if (duplicate) {\n+                                    // Always subtract one, never clearing a key. It is possible for this to leave\n+                                    // a key with a count of zero, if duplicates were inserted with different hash functions.\n+                                    Function<byte[], Void> decrement = k -> {\n+                                        tr.mutate(MutationType.ADD, subspace.pack(Tuple.from(level, k)), encodeLong(-1));", "originalCommit": "eaca40e0c8b2079dc59730fa3dd94e7c4ddf4cad", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDA0MzAxOA==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r390043018", "bodyText": "I see now that as we read the count and, if the count is 1, just remove the key, that this is no longer something to be worried about, though I suppose one could wist hopefully for a data structure with fewer conflicts (e.g., no conflicts when adding or removing the same key). It....might be possible, but it probably requires additional fanciness like conflicts in same \"shadow realm\", and it can be done later if we decide we really want it.", "author": "alecgrieser", "createdAt": "2020-03-10T01:09:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY1MjE3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY2NDY3MQ==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r388664671", "bodyText": "This .allOf isn't new, but I suppose this could be thenCombine or .thenAcceptBoth, and I think it would be cleaner.", "author": "alecgrieser", "createdAt": "2020-03-06T01:16:45Z", "path": "fdb-extensions/src/main/java/com/apple/foundationdb/async/RankedSet.java", "diffHunk": "@@ -356,37 +396,59 @@ public RankedSet(Subspace subspace, Executor executor) {\n                             if (count == null || count <= 0) {\n                                 return READY_FALSE;\n                             }\n+                            // This works even if the current set does not track duplicates but duplicates were added\n+                            // earlier by one that did.\n+                            final boolean duplicate = count > 1;\n                             final int nlevels = config.getNLevels();\n                             final List<CompletableFuture<Void>> futures = new ArrayList<>(nlevels);\n                             for (int li = 0; li < nlevels; ++li) {\n                                 final int level = li;\n-                                // This could be optimized to check the hash for which levels should have this key.\n-                                final byte[] k = subspace.pack(Tuple.from(level, key));\n \n                                 final CompletableFuture<Void> future;\n-                                final CompletableFuture<byte[]> cf = tr.get(k);\n \n-                                if (level == 0) {\n-                                    future = cf.thenApply(c -> {\n-                                        if (c != null) {\n-                                            tr.clear(k);\n-                                        }\n+                                if (duplicate) {\n+                                    // Always subtract one, never clearing a key. It is possible for this to leave\n+                                    // a key with a count of zero, if duplicates were inserted with different hash functions.\n+                                    Function<byte[], Void> decrement = k -> {\n+                                        tr.mutate(MutationType.ADD, subspace.pack(Tuple.from(level, k)), encodeLong(-1));\n                                         return null;\n-                                    });\n+                                    };\n+                                    if (level == 0) {\n+                                        decrement.apply(key);\n+                                        future = DONE;\n+                                    } else {\n+                                        future = getPreviousKey(tr, level, key, true).thenApply(decrement);\n+                                    }\n                                 } else {\n-                                    final CompletableFuture<byte[]> prevKeyF = getPreviousKey(tr, level, key);\n-                                    future = CompletableFuture.allOf(cf, prevKeyF)\n-                                            .thenApply(vignore -> {\n-                                                final byte[] c = cf.join();\n-                                                long countChange = -1;\n-                                                if (c != null) {\n-                                                    // Give back additional count from the key we are erasing to the neighbor.\n-                                                    countChange += decodeLong(c);\n-                                                    tr.clear(k);\n-                                                }\n-                                                tr.mutate(MutationType.ADD, subspace.pack(Tuple.from(level, prevKeyF.join())), encodeLong(countChange));\n-                                                return null;\n-                                            });\n+                                    // This could be optimized to check the hash for which levels should have this key.\n+                                    // That would require that the hash function never changes, though.\n+                                    // This allows for it to change, with the distribution perhaps getting a little uneven\n+                                    // as a result. It even allows for the hash function to return a random number.\n+                                    final byte[] k = subspace.pack(Tuple.from(level, key));\n+                                    final CompletableFuture<byte[]> cf = tr.get(k);\n+\n+                                    if (level == 0) {\n+                                        future = cf.thenApply(c -> {\n+                                            if (c != null) {\n+                                                tr.clear(k);\n+                                            }\n+                                            return null;\n+                                        });\n+                                    } else {\n+                                        final CompletableFuture<byte[]> prevKeyF = getPreviousKey(tr, level, key, false);\n+                                        future = CompletableFuture.allOf(cf, prevKeyF)", "originalCommit": "eaca40e0c8b2079dc59730fa3dd94e7c4ddf4cad", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTg5MjQ2Nw==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r389892467", "bodyText": "Done", "author": "MMcM", "createdAt": "2020-03-09T18:50:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY2NDY3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE0OTk5MQ==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r389149991", "bodyText": "With the exception of HashFunction, I think it is the case that none of these are really a good idea to change midstream on an existing ranked set. It's probably good to document that here. Ideally, it would be good to also enforce that with some validation, but I don't think there's a way of doing that without extra latency, which we may want to avoid.", "author": "alecgrieser", "createdAt": "2020-03-06T21:21:04Z", "path": "fdb-extensions/src/main/java/com/apple/foundationdb/async/RankedSet.java", "diffHunk": "@@ -143,30 +144,153 @@ private static long decodeLong(byte[] v) {\n         int hash(byte[] key);\n     }\n \n+    /**\n+     * Configuration settings for a {@link RankedSet}.", "originalCommit": "d1b1b6f12150d9e94b768b4c08c62200d1d4a478", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTg4NjI5Mw==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r389886293", "bodyText": "It is enforced at the index level, which has old and new meta-data that can be compared.", "author": "MMcM", "createdAt": "2020-03-09T18:39:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE0OTk5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTk5MTQwNw==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r389991407", "bodyText": "Yeah, and that's probably as good as we're gonna get.", "author": "alecgrieser", "createdAt": "2020-03-09T22:14:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE0OTk5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE1NjkxNw==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r389156917", "bodyText": "Though I'm not sure how I feel about the randomSingleThread and randomFiveThreads tests in general (or as unit tests), it might be good to see if running them with duplicates counted and see if they find anything.\nAlso, as much time as they take, I could see there being possibly weird edge cases when building a ranked set with duplicates turned on (particularly with regard to parallelism).", "author": "alecgrieser", "createdAt": "2020-03-06T21:38:26Z", "path": "fdb-extensions/src/test/java/com/apple/foundationdb/async/RankedSetTest.java", "diffHunk": "@@ -118,6 +119,49 @@ private void basicOperations(RankedSet.HashFunction firstHashFunction, RankedSet\n                 boolean wasOld = rs.remove(tr, k).join();\n                 assertTrue(wasOld);\n             }\n+            assertFalse(rs.remove(tr, keys[20]).join());\n+            return null;\n+        });\n+    }\n+\n+    @Test\n+    public void duplicates() {", "originalCommit": "d1b1b6f12150d9e94b768b4c08c62200d1d4a478", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDA2NDcxNw==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r390064717", "bodyText": "I  don't much care for those tests, either. But I added one with duplicates.\nNote that the test already has knowledge of some invariants which are changed in the duplicates case, so some of the checks need to be conditional on the config.", "author": "MMcM", "createdAt": "2020-03-10T02:39:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE1NjkxNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE1ODc0Nw==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r389158747", "bodyText": "Should this allow going from not setting RANK_COUNT_DUPLICATES to setting it to false, or is that already allowed somehow?\nI also suppose that the TimeWindowLeaderboardMaintainerFactory could benefit from similar logic here (but I guess not for n-levels). I suppose it also isn't super necessary, though, as the default is to reject any option changes, which is conservative.", "author": "alecgrieser", "createdAt": "2020-03-06T21:42:53Z", "path": "fdb-record-layer-core/src/main/java/com/apple/foundationdb/record/provider/foundationdb/indexes/RankIndexMaintainerFactory.java", "diffHunk": "@@ -65,24 +65,24 @@ public void validate(@Nonnull MetaDataValidator metaDataValidator) {\n \n             @Override\n             public void validateChangedOptions(@Nonnull Index oldIndex, @Nonnull Set<String> changedOptions) {\n-                // Allow changing from unspecified to the default (or vice versa), but not otherwise.\n-                if (changedOptions.contains(IndexOptions.RANK_NLEVELS)) {\n-                    int oldLevels = RankedSetIndexHelper.getNLevels(oldIndex);\n-                    int newLevels = RankedSetIndexHelper.getNLevels(index);\n-                    if (oldLevels != newLevels) {\n-                        throw new MetaDataException(\"rank levels changed\",\n-                                LogMessageKeys.INDEX_NAME, index.getName());\n+                if (!changedOptions.isEmpty()) {", "originalCommit": "d1b1b6f12150d9e94b768b4c08c62200d1d4a478", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTg4NjcwMg==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r389886702", "bodyText": "I disallowed changing duplicates, in keeping with the conservative nature of the existing checks.", "author": "MMcM", "createdAt": "2020-03-09T18:39:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE1ODc0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTk5MjE1Nw==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r389992157", "bodyText": "That sounds right. I'd be tempted to say that even the most liberal of changes shouldn't allow that particular option to change ever (because the data won't be correct if you switch, even if it's understandable).", "author": "alecgrieser", "createdAt": "2020-03-09T22:16:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE1ODc0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDAwOTIxMA==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r390009210", "bodyText": "Hmm. There are, I think, two points of view:\n\nThe option defines a fundamental characteristic of the skip list, viz., whether the finest level has counts greater than one.\nThe option refines the behavior of the add method to either maintain counts or return false for things already present.\n\nWhich of those makes more sense also probably informs whether remove always removes one occurrence or is similarly influenced by the config option.", "author": "MMcM", "createdAt": "2020-03-09T23:06:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE1ODc0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDAxODQ5Nw==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r390018497", "bodyText": "Interesting. I had kind of been coming from the first point of view. It kind of seems like the second point of view makes sense from the point of view of the skip list itself, though it's harder to see how that is a sensible \"index\" over data. (In that with duplicate tracking off, it is just a data structure for optimizing \"rank without counting duplicates\" queries; with duplicate tracking on, it is a data structure for optimizing \"rank with duplicates counted\" queries; but with it changed half-way through, then I don't know if it answers any reasonable queries other than \"what is the state of skip list\".)", "author": "alecgrieser", "createdAt": "2020-03-09T23:36:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE1ODc0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDAyMDc3NA==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r390020774", "bodyText": "Yes, agreed. I don't have a great (not implementation based) idea of why a user of the index would want to change the answers to the rank / select operations it optimizes.", "author": "MMcM", "createdAt": "2020-03-09T23:44:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE1ODc0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE2MjM0NA==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r389162344", "bodyText": "I'm not sure if we care, but this isn't thread safe (in that two threads can modify and set the number of levels to different values). I think the alternative would be to either copy the builder before setting the levels or create a new one from the index and the leaderboard (for the levels) from scratch each time. (I think there are other things about using ranked sets that are also unsafe, but I think this one is also easy to fix, unlike the others, so might be worth doing.)", "author": "alecgrieser", "createdAt": "2020-03-06T21:52:58Z", "path": "fdb-record-layer-core/src/main/java/com/apple/foundationdb/record/provider/foundationdb/leaderboard/TimeWindowLeaderboardIndexMaintainer.java", "diffHunk": "@@ -197,8 +197,9 @@ protected void saveSubDirectory(@Nonnull TimeWindowLeaderboardSubDirectory subdi\n                 }\n                 final Subspace extraSubspace = getSecondarySubspace();\n                 final Subspace leaderboardSubspace = extraSubspace.subspace(leaderboard.getSubspaceKey());\n+                final RankedSet.Config config = configBuilder.setNLevels(leaderboard.getNLevels()).build();", "originalCommit": "d1b1b6f12150d9e94b768b4c08c62200d1d4a478", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTg4Njg1OQ==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r389886859", "bodyText": "I switched from a shared builder to toBuilder.", "author": "MMcM", "createdAt": "2020-03-09T18:40:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE2MjM0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE3MzA5OA==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r389173098", "bodyText": "I, um, am not sure this comment is true, or at least doesn't seem right given one of the comments I made in the remove function for RankedSet. On the other hand, we do test write only indexes as part of index builds, so I'm not entirely sure. (Understanding that this is a pre-existing comment that I probably wrote.)", "author": "alecgrieser", "createdAt": "2020-03-06T22:23:33Z", "path": "fdb-record-layer-core/src/main/java/com/apple/foundationdb/record/provider/foundationdb/indexes/RankedSetIndexHelper.java", "diffHunk": "@@ -233,38 +244,41 @@ private static Number extractRank(int groupPrefixSize, @Nullable Tuple maybeRank\n     @Nonnull\n     public static CompletableFuture<Void> updateRankedSet(@Nonnull IndexMaintainerState state,\n                                                           @Nonnull Subspace rankSubspace,\n-                                                          @Nonnull RankedSet.HashFunction hashFunction,\n-                                                          int nlevels,\n+                                                          @Nonnull RankedSet.Config config,\n                                                           @Nonnull Tuple valueKey,\n                                                           @Nonnull Tuple scoreKey,\n                                                           boolean remove) {\n-        final RankedSet rankedSet = new InstrumentedRankedSet(state, rankSubspace, hashFunction, nlevels);\n+        final RankedSet rankedSet = new InstrumentedRankedSet(state, rankSubspace, config);\n         final byte[] score = scoreKey.pack();\n         CompletableFuture<Void> result = init(state, rankedSet).thenCompose(v -> {\n             if (remove) {\n-                // If no one else has this score, remove from ranked set.\n-                return state.transaction.getRange(state.indexSubspace.range(valueKey)).iterator().onHasNext().thenCompose(hasNext -> {\n-                    if (hasNext) {\n-                        return AsyncUtil.DONE;\n-                    } else {\n-                        return rankedSet.remove(state.transaction, score).thenApply(exists -> {\n-                            // It is okay if the score isn't in the ranked set yet if the index is\n-                            // write only because this means that the score just hasn't yet\n-                            // been added by some record. We still want the conflict ranges, though.\n-                            if (!exists && !state.store.isIndexWriteOnly(state.index)) {\n-                                throw new RecordCoreException(\"Score was not present in ranked set.\");\n-                            }\n-                            return null;\n-                        });\n-                    }\n-                });\n+                if (config.isCountDuplicates()) {\n+                    // Decrement count and possibly remove.\n+                    return removeFromRankedSet(state, rankedSet, score);\n+                } else {\n+                    // If no one else has this score, remove from ranked set.\n+                    return state.transaction.getRange(state.indexSubspace.range(valueKey)).iterator().onHasNext()\n+                            .thenCompose(hasNext -> hasNext ? AsyncUtil.DONE : removeFromRankedSet(state, rankedSet, score));\n+                }\n             } else {\n                 return rankedSet.add(state.transaction, score).thenApply(added -> null);\n             }\n         });\n         return state.store.instrument(Events.RANKED_SET_UPDATE, result);\n     }\n \n+    private static CompletableFuture<Void> removeFromRankedSet(@Nonnull IndexMaintainerState state, @Nonnull RankedSet rankedSet, @Nonnull byte[] score) {\n+        return rankedSet.remove(state.transaction, score).thenApply(exists -> {\n+            // It is okay if the score isn't in the ranked set yet if the index is\n+            // write only because this means that the score just hasn't yet\n+            // been added by some record. We still want the conflict ranges, though.", "originalCommit": "d1b1b6f12150d9e94b768b4c08c62200d1d4a478", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDA0ODUyOA==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r390048528", "bodyText": "I somehow missed the part of the code in RankedSet that checks to make sure that the score isn't zero before decrementing. I am now more confident in this comment in at least the case of not duplicate tracking (so that's good).\nI'm trying to think, however, if there are pathologies in the count duplicates case. I think the answer is \"yes\" because adding to a ranked set index with duplicate counting isn't idempotent. In particular:\n\nImagine having two records with a rank index on field foo, both of which have the value foo = bar.\nAn index build indexes the first record. Now the count corresponding to bar in the foo rank index is 1.\nSomeone removes the second record. Now the count corresponding to bar in the foo rank index is 0 (i.e., it is removed from the ranked set).\nThe index build completes, never having indexed the second record.\n\nSo now bar has an incorrect rank. This is somewhat of a worst case in that bar is missing entirely from the ranked set, but I think one can also be in a position where the rank is wrong, but not removed entirely.\nI think this can be fixed by checking if the record is in the built range and only updating the ranked set if it is. It also seems to me like this would be safe for the regular ranked set, though perhaps would induce more conflicts.", "author": "alecgrieser", "createdAt": "2020-03-10T01:33:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE3MzA5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDA1NjA4Nw==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r390056087", "bodyText": "That would be accomplished by having isIdempotent check the option, correct? There is no need for a new instance of such built range checking code.", "author": "MMcM", "createdAt": "2020-03-10T02:03:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE3MzA5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTg4MDUyMw==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r391880523", "bodyText": "Yeah, I believe so--that no new mechanism is necessary because what I sketched out is already done by isIdempotent.", "author": "alecgrieser", "createdAt": "2020-03-12T20:37:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE3MzA5OA=="}], "type": "inlineReview"}, {"oid": "831639ef7eee7f50e160633c895c378b66e2dcdf", "url": "https://github.com/FoundationDB/fdb-record-layer/commit/831639ef7eee7f50e160633c895c378b66e2dcdf", "message": "Instead of getKey() or getRange() with two KeySelector derived from the target,\ndo a reverse range read limited by the level start.\nThis is no more expensive and adds another safety check.", "committedDate": "2020-03-09T18:30:38Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDA0NDAwNA==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r390044004", "bodyText": "It seems weird (though perhaps) harmless that this re-reads the key for level zero rather than, say, just clearing the key. For one, it almost gives the impression that the key could be null at this point...which seems wrong.", "author": "alecgrieser", "createdAt": "2020-03-10T01:14:03Z", "path": "fdb-extensions/src/main/java/com/apple/foundationdb/async/RankedSet.java", "diffHunk": "@@ -220,32 +391,110 @@ public RankedSet(Subspace subspace, Executor executor) {\n                 }));\n     }\n \n-    protected CompletableFuture<Void> addLevelZeroKey(Transaction tr, byte[] key, int level) {\n-        tr.set(subspace.pack(Tuple.from(level, key)), encodeLong(1));\n+    protected CompletableFuture<Void> addLevelZeroKey(Transaction tr, byte[] key, int level, boolean increment) {\n+        final byte[] k = subspace.pack(Tuple.from(level, key));\n+        final byte[] v = encodeLong(1);\n+        if (increment) {\n+            tr.mutate(MutationType.ADD, k, v);\n+        } else {\n+            tr.set(k, v);\n+        }\n         return DONE;\n     }\n \n-    protected CompletableFuture<Void> addIncrementLevelKey(Transaction tr, byte[] key, int level) {\n-        return getPreviousKey(tr, level, key).thenApply(prevKey -> {\n+    protected CompletableFuture<Void> addIncrementLevelKey(Transaction tr, byte[] key, int level, boolean orEqual) {\n+        return getPreviousKey(tr, level, key, orEqual).thenApply(prevKey -> {\n             tr.mutate(MutationType.ADD, subspace.pack(Tuple.from(level, prevKey)), encodeLong(1));\n             return null;\n         });\n     }\n \n     protected CompletableFuture<Void> addInsertLevelKey(Transaction tr, byte[] key, int level) {\n-        return getPreviousKey(tr, level, key).thenCompose(prevKey -> {\n+        return getPreviousKey(tr, level, key, false).thenCompose(prevKey -> {\n             CompletableFuture<Long> prevCount = tr.get(subspace.pack(Tuple.from(level, prevKey))).thenApply(RankedSet::decodeLong);\n             CompletableFuture<Long> newPrevCount = countRange(tr, level - 1, prevKey, key);\n-            return CompletableFuture.allOf(prevCount, newPrevCount)\n-                    .thenApply(vignore2 -> {\n-                        long count = prevCount.join() - newPrevCount.join() + 1;\n-                        tr.set(subspace.pack(Tuple.from(level, prevKey)), encodeLong(newPrevCount.join()));\n-                        tr.set(subspace.pack(Tuple.from(level, key)), encodeLong(count));\n-                        return null;\n-                    });\n+            return prevCount.thenAcceptBoth(newPrevCount, (prev, newPrev) -> {\n+                long count = prev - newPrev + 1;\n+                tr.set(subspace.pack(Tuple.from(level, prevKey)), encodeLong(newPrev));\n+                tr.set(subspace.pack(Tuple.from(level, key)), encodeLong(count));\n+            });\n         });\n     }\n \n+    /**\n+     * Removes a key from the set.\n+     * @param tc the transaction to use to access the database\n+     * @param key the key to remove\n+     * @return a future that completes to {@code true} if the set was modified, that is, if the key was present before this operation\n+     */\n+    public CompletableFuture<Boolean> remove(TransactionContext tc, byte[] key) {\n+        checkKey(key);\n+        return tc.runAsync(tr ->\n+                countCheckedKey(tr, key)\n+                        .thenCompose(count -> {\n+                            if (count == null || count <= 0) {\n+                                return READY_FALSE;\n+                            }\n+                            // This works even if the current set does not track duplicates but duplicates were added\n+                            // earlier by one that did.\n+                            final boolean duplicate = count > 1;\n+                            final int nlevels = config.getNLevels();\n+                            final List<CompletableFuture<Void>> futures = new ArrayList<>(nlevels);\n+                            for (int li = 0; li < nlevels; ++li) {\n+                                final int level = li;\n+\n+                                final CompletableFuture<Void> future;\n+\n+                                if (duplicate) {\n+                                    // Always subtract one, never clearing a level count key.\n+                                    // Concurrent requests both subtracting one when the count is two will conflict\n+                                    // on the level zero key, which was read to detect that this is a duplicate.\n+                                    // So it should not be possible for a count to go to zero.\n+                                    Function<byte[], Void> decrement = k -> {\n+                                        tr.mutate(MutationType.ADD, subspace.pack(Tuple.from(level, k)), encodeLong(-1));\n+                                        return null;\n+                                    };\n+                                    if (level == 0) {\n+                                        decrement.apply(key);\n+                                        future = DONE;\n+                                    } else {\n+                                        future = getPreviousKey(tr, level, key, true).thenApply(decrement);\n+                                    }\n+                                } else {\n+                                    // This could be optimized to check the hash for which levels should have this key.\n+                                    // That would require that the hash function never changes, though.\n+                                    // This allows for it to change, with the distribution perhaps getting a little uneven\n+                                    // as a result. It even allows for the hash function to return a random number.\n+                                    // It also further guarantees that counts never go to zero.\n+                                    final byte[] k = subspace.pack(Tuple.from(level, key));\n+                                    final CompletableFuture<byte[]> cf = tr.get(k);\n+\n+                                    if (level == 0) {\n+                                        future = cf.thenApply(c -> {\n+                                            if (c != null) {\n+                                                tr.clear(k);\n+                                            }\n+                                            return null;\n+                                        });", "originalCommit": "d15c7b81796741126f4bda96716ba744fa95f2ec", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDA1NjE2Mg==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r390056162", "bodyText": "Yes, it is simpler to just clear unconditionally.", "author": "MMcM", "createdAt": "2020-03-10T02:03:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDA0NDAwNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDA0NDM3Nw==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r390044377", "bodyText": "I suppose rather than decrementing, this could explicitly set the key to encodeLong(count - 1). I think the only thing this would do is underscore that we aren't actually making use of the ability of atomic operations to allow for concurrent updates to the level 0 keys.", "author": "alecgrieser", "createdAt": "2020-03-10T01:15:35Z", "path": "fdb-extensions/src/main/java/com/apple/foundationdb/async/RankedSet.java", "diffHunk": "@@ -220,32 +391,110 @@ public RankedSet(Subspace subspace, Executor executor) {\n                 }));\n     }\n \n-    protected CompletableFuture<Void> addLevelZeroKey(Transaction tr, byte[] key, int level) {\n-        tr.set(subspace.pack(Tuple.from(level, key)), encodeLong(1));\n+    protected CompletableFuture<Void> addLevelZeroKey(Transaction tr, byte[] key, int level, boolean increment) {\n+        final byte[] k = subspace.pack(Tuple.from(level, key));\n+        final byte[] v = encodeLong(1);\n+        if (increment) {\n+            tr.mutate(MutationType.ADD, k, v);\n+        } else {\n+            tr.set(k, v);\n+        }\n         return DONE;\n     }\n \n-    protected CompletableFuture<Void> addIncrementLevelKey(Transaction tr, byte[] key, int level) {\n-        return getPreviousKey(tr, level, key).thenApply(prevKey -> {\n+    protected CompletableFuture<Void> addIncrementLevelKey(Transaction tr, byte[] key, int level, boolean orEqual) {\n+        return getPreviousKey(tr, level, key, orEqual).thenApply(prevKey -> {\n             tr.mutate(MutationType.ADD, subspace.pack(Tuple.from(level, prevKey)), encodeLong(1));\n             return null;\n         });\n     }\n \n     protected CompletableFuture<Void> addInsertLevelKey(Transaction tr, byte[] key, int level) {\n-        return getPreviousKey(tr, level, key).thenCompose(prevKey -> {\n+        return getPreviousKey(tr, level, key, false).thenCompose(prevKey -> {\n             CompletableFuture<Long> prevCount = tr.get(subspace.pack(Tuple.from(level, prevKey))).thenApply(RankedSet::decodeLong);\n             CompletableFuture<Long> newPrevCount = countRange(tr, level - 1, prevKey, key);\n-            return CompletableFuture.allOf(prevCount, newPrevCount)\n-                    .thenApply(vignore2 -> {\n-                        long count = prevCount.join() - newPrevCount.join() + 1;\n-                        tr.set(subspace.pack(Tuple.from(level, prevKey)), encodeLong(newPrevCount.join()));\n-                        tr.set(subspace.pack(Tuple.from(level, key)), encodeLong(count));\n-                        return null;\n-                    });\n+            return prevCount.thenAcceptBoth(newPrevCount, (prev, newPrev) -> {\n+                long count = prev - newPrev + 1;\n+                tr.set(subspace.pack(Tuple.from(level, prevKey)), encodeLong(newPrev));\n+                tr.set(subspace.pack(Tuple.from(level, key)), encodeLong(count));\n+            });\n         });\n     }\n \n+    /**\n+     * Removes a key from the set.\n+     * @param tc the transaction to use to access the database\n+     * @param key the key to remove\n+     * @return a future that completes to {@code true} if the set was modified, that is, if the key was present before this operation\n+     */\n+    public CompletableFuture<Boolean> remove(TransactionContext tc, byte[] key) {\n+        checkKey(key);\n+        return tc.runAsync(tr ->\n+                countCheckedKey(tr, key)\n+                        .thenCompose(count -> {\n+                            if (count == null || count <= 0) {\n+                                return READY_FALSE;\n+                            }\n+                            // This works even if the current set does not track duplicates but duplicates were added\n+                            // earlier by one that did.\n+                            final boolean duplicate = count > 1;\n+                            final int nlevels = config.getNLevels();\n+                            final List<CompletableFuture<Void>> futures = new ArrayList<>(nlevels);\n+                            for (int li = 0; li < nlevels; ++li) {\n+                                final int level = li;\n+\n+                                final CompletableFuture<Void> future;\n+\n+                                if (duplicate) {\n+                                    // Always subtract one, never clearing a level count key.\n+                                    // Concurrent requests both subtracting one when the count is two will conflict\n+                                    // on the level zero key, which was read to detect that this is a duplicate.\n+                                    // So it should not be possible for a count to go to zero.\n+                                    Function<byte[], Void> decrement = k -> {\n+                                        tr.mutate(MutationType.ADD, subspace.pack(Tuple.from(level, k)), encodeLong(-1));\n+                                        return null;\n+                                    };\n+                                    if (level == 0) {\n+                                        decrement.apply(key);", "originalCommit": "d15c7b81796741126f4bda96716ba744fa95f2ec", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDA1NjI1Mg==", "url": "https://github.com/FoundationDB/fdb-record-layer/pull/837#discussion_r390056252", "bodyText": "Yes, that does seem more obvious and in line with the preceding comment.", "author": "MMcM", "createdAt": "2020-03-10T02:04:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDA0NDM3Nw=="}], "type": "inlineReview"}, {"oid": "d36de3ca1c6bc9128bbfc15091b120cceb3515fe", "url": "https://github.com/FoundationDB/fdb-record-layer/commit/d36de3ca1c6bc9128bbfc15091b120cceb3515fe", "message": "Move add and remove next to one another", "committedDate": "2020-03-12T22:19:49Z", "type": "commit"}, {"oid": "f8c313c178b594c6496e181f0a2d327d5ae39e03", "url": "https://github.com/FoundationDB/fdb-record-layer/commit/f8c313c178b594c6496e181f0a2d327d5ae39e03", "message": "Change an internal helper to return count", "committedDate": "2020-03-12T22:19:49Z", "type": "commit"}, {"oid": "9a3e7483bb97e3cc6a2c665e2d76f049d9e74840", "url": "https://github.com/FoundationDB/fdb-record-layer/commit/9a3e7483bb97e3cc6a2c665e2d76f049d9e74840", "message": "Move RankedSet settings out into own Config class", "committedDate": "2020-03-12T22:19:49Z", "type": "commit"}, {"oid": "2123ef39a69749fc3a8a3e4252b085ce90dfdb7c", "url": "https://github.com/FoundationDB/fdb-record-layer/commit/2123ef39a69749fc3a8a3e4252b085ce90dfdb7c", "message": "Add countDuplicates option to RankedSet.", "committedDate": "2020-03-12T22:19:49Z", "type": "commit"}, {"oid": "594e63daf5a561c6c895231a38e8da68ab23e57a", "url": "https://github.com/FoundationDB/fdb-record-layer/commit/594e63daf5a561c6c895231a38e8da68ab23e57a", "message": "Resolves #806: Rank index could have option for how to handle ties", "committedDate": "2020-03-12T22:19:49Z", "type": "commit"}, {"oid": "6b7d3bc285babc4f4b0271b28bb8fb916f444f13", "url": "https://github.com/FoundationDB/fdb-record-layer/commit/6b7d3bc285babc4f4b0271b28bb8fb916f444f13", "message": "Add a random hash function to test that this works.\nClarify some comments.", "committedDate": "2020-03-12T22:19:49Z", "type": "commit"}, {"oid": "a1106be02030c02571b487882e913c76a34128d1", "url": "https://github.com/FoundationDB/fdb-record-layer/commit/a1106be02030c02571b487882e913c76a34128d1", "message": "Stop sharing a ConfigBuilder, since it isn't thread safe", "committedDate": "2020-03-12T22:19:49Z", "type": "commit"}, {"oid": "b09aff2068a957279ffd567517f6d5e7bbb8a9e6", "url": "https://github.com/FoundationDB/fdb-record-layer/commit/b09aff2068a957279ffd567517f6d5e7bbb8a9e6", "message": "Instead of getKey() or getRange() with two KeySelector derived from the target,\ndo a reverse range read limited by the level start.\nThis is no more expensive and adds another safety check.", "committedDate": "2020-03-12T22:19:49Z", "type": "commit"}, {"oid": "8de90e4d486fe93575f2c7343b2c28084f1eacbf", "url": "https://github.com/FoundationDB/fdb-record-layer/commit/8de90e4d486fe93575f2c7343b2c28084f1eacbf", "message": "Switch from allOf to thenAcceptBoth", "committedDate": "2020-03-12T22:19:49Z", "type": "commit"}, {"oid": "dab2979c2d0e5b73136846a14351f40f62846a83", "url": "https://github.com/FoundationDB/fdb-record-layer/commit/dab2979c2d0e5b73136846a14351f40f62846a83", "message": "Simplify some futures", "committedDate": "2020-03-12T22:19:49Z", "type": "commit"}, {"oid": "122363674095f5fd98309165e4c7c6a800376ddb", "url": "https://github.com/FoundationDB/fdb-record-layer/commit/122363674095f5fd98309165e4c7c6a800376ddb", "message": "Add a random test with duplicates, too", "committedDate": "2020-03-12T22:19:49Z", "type": "commit"}, {"oid": "54fc11ff361d4c6cfe56bd29f742459021fc329e", "url": "https://github.com/FoundationDB/fdb-record-layer/commit/54fc11ff361d4c6cfe56bd29f742459021fc329e", "message": "Not idempotent if counting duplicates", "committedDate": "2020-03-12T22:19:58Z", "type": "commit"}, {"oid": "54fc11ff361d4c6cfe56bd29f742459021fc329e", "url": "https://github.com/FoundationDB/fdb-record-layer/commit/54fc11ff361d4c6cfe56bd29f742459021fc329e", "message": "Not idempotent if counting duplicates", "committedDate": "2020-03-12T22:19:58Z", "type": "forcePushed"}]}