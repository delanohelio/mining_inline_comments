{"pr_number": 5283, "pr_title": "Variable precision timestamp support for Hive write operations", "pr_createdAt": "2020-09-24T04:47:02Z", "pr_url": "https://github.com/trinodb/trino/pull/5283", "timeline": [{"oid": "83da8532cace3eee3bb5db13e6495e381240c0e5", "url": "https://github.com/trinodb/trino/commit/83da8532cace3eee3bb5db13e6495e381240c0e5", "message": "Variable precision timestamp support for Hive write operations", "committedDate": "2020-09-25T13:20:05Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAwODEzMg==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495008132", "bodyText": "compare with TIMESTAMP_MILLIS using ==\n(this is intentionally supported; reads better)", "author": "findepi", "createdAt": "2020-09-25T14:00:42Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HiveMetadata.java", "diffHunk": "@@ -2377,11 +2375,12 @@ public TableStatisticsMetadata getStatisticsCollectionMetadata(ConnectorSession\n \n     private TableStatisticsMetadata getStatisticsCollectionMetadata(List<ColumnMetadata> columns, List<String> partitionedBy, Optional<Set<String>> analyzeColumns, boolean includeRowCount)\n     {\n-        validateTimestampColumns(columns);\n         Set<ColumnStatisticMetadata> columnStatistics = columns.stream()\n                 .filter(column -> !partitionedBy.contains(column.getName()))\n                 .filter(column -> !column.isHidden())\n                 .filter(column -> analyzeColumns.isEmpty() || analyzeColumns.get().contains(column.getName()))\n+                // we only support stats collection at default precision for now\n+                .filter(column -> !(column.getType() instanceof TimestampType) || column.getType().equals(TIMESTAMP_MILLIS))", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAwOTA2NQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495009065", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            // we only support stats collection at default precision for now\n          \n          \n            \n                            // TODO we only support stats collection at default precision for now", "author": "findepi", "createdAt": "2020-09-25T14:02:07Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HiveMetadata.java", "diffHunk": "@@ -2377,11 +2375,12 @@ public TableStatisticsMetadata getStatisticsCollectionMetadata(ConnectorSession\n \n     private TableStatisticsMetadata getStatisticsCollectionMetadata(List<ColumnMetadata> columns, List<String> partitionedBy, Optional<Set<String>> analyzeColumns, boolean includeRowCount)\n     {\n-        validateTimestampColumns(columns);\n         Set<ColumnStatisticMetadata> columnStatistics = columns.stream()\n                 .filter(column -> !partitionedBy.contains(column.getName()))\n                 .filter(column -> !column.isHidden())\n                 .filter(column -> analyzeColumns.isEmpty() || analyzeColumns.get().contains(column.getName()))\n+                // we only support stats collection at default precision for now", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAxNjg4MA==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495016880", "bodyText": "IntSupplier -> int", "author": "findepi", "createdAt": "2020-09-25T14:13:20Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java", "diffHunk": "@@ -361,24 +375,60 @@ public void setField(Block block, int position)\n         }\n     }\n \n-    private static class TimestampFieldSetter\n+    private abstract static class TimestampFieldSetter\n             extends FieldSetter\n     {\n-        private final DateTimeZone timeZone;\n-        private final TimestampWritableV2 value = new TimestampWritableV2();\n+        protected final DateTimeZone timeZone;\n+        protected final TimestampWritableV2 value = new TimestampWritableV2();\n \n         public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n         {\n             super(rowInspector, row, field);\n             this.timeZone = requireNonNull(timeZone, \"timeZone is null\");\n         }\n \n+        protected Timestamp getTimestamp(long micros, IntSupplier picosSupplier)", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAxNzkwNw==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495017907", "bodyText": "This should be using actual type, not \"best type\"\npass the type from io.prestosql.plugin.hive.util.FieldSetterFactory#create here and use it", "author": "findepi", "createdAt": "2020-09-25T14:14:48Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java", "diffHunk": "@@ -361,24 +375,60 @@ public void setField(Block block, int position)\n         }\n     }\n \n-    private static class TimestampFieldSetter\n+    private abstract static class TimestampFieldSetter\n             extends FieldSetter\n     {\n-        private final DateTimeZone timeZone;\n-        private final TimestampWritableV2 value = new TimestampWritableV2();\n+        protected final DateTimeZone timeZone;\n+        protected final TimestampWritableV2 value = new TimestampWritableV2();\n \n         public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n         {\n             super(rowInspector, row, field);\n             this.timeZone = requireNonNull(timeZone, \"timeZone is null\");\n         }\n \n+        protected Timestamp getTimestamp(long micros, IntSupplier picosSupplier)\n+        {\n+            long epochMillis = floorDiv(micros, MICROSECONDS_PER_MILLISECOND);\n+            epochMillis = timeZone.convertLocalToUTC(epochMillis, false);\n+            int nanosFromMicros = floorMod(micros, MICROSECONDS_PER_SECOND) * NANOSECONDS_PER_MICROSECOND;\n+            int nanosFromPicos = (int) roundDiv(picosSupplier.getAsInt(), PICOSECONDS_PER_NANOSECOND);\n+            return Timestamp.ofEpochMilli(epochMillis, nanosFromMicros + nanosFromPicos);\n+        }\n+    }\n+\n+    private static class ShortTimestampFieldSetter\n+            extends TimestampFieldSetter\n+    {\n+        public ShortTimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n+        {\n+            super(rowInspector, row, field, timeZone);\n+        }\n+\n+        @Override\n+        public void setField(Block block, int position)\n+        {\n+            long micros = TIMESTAMP_MICROS.getLong(block, position);", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAxOTcxOQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495019719", "bodyText": "up to millis precision is covered by epochMillis parameter, so\nmod MICROSECONDS_PER_SECOND should probably be mod MICROSECONDS_PER_MILLISECOND", "author": "findepi", "createdAt": "2020-09-25T14:17:32Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java", "diffHunk": "@@ -361,24 +375,60 @@ public void setField(Block block, int position)\n         }\n     }\n \n-    private static class TimestampFieldSetter\n+    private abstract static class TimestampFieldSetter\n             extends FieldSetter\n     {\n-        private final DateTimeZone timeZone;\n-        private final TimestampWritableV2 value = new TimestampWritableV2();\n+        protected final DateTimeZone timeZone;\n+        protected final TimestampWritableV2 value = new TimestampWritableV2();\n \n         public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n         {\n             super(rowInspector, row, field);\n             this.timeZone = requireNonNull(timeZone, \"timeZone is null\");\n         }\n \n+        protected Timestamp getTimestamp(long micros, IntSupplier picosSupplier)\n+        {\n+            long epochMillis = floorDiv(micros, MICROSECONDS_PER_MILLISECOND);\n+            epochMillis = timeZone.convertLocalToUTC(epochMillis, false);\n+            int nanosFromMicros = floorMod(micros, MICROSECONDS_PER_SECOND) * NANOSECONDS_PER_MICROSECOND;", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTA0NjE1Mg==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495046152", "bodyText": "It's definitely no clear what's happening here, but the Timestamp we are returning is constructed from epoch millis and nanos of second (since it's using a java.time.LocalDateTime under the covers).  Pretty intuitive API, right?  I'll try to make this explicit.", "author": "aalbu", "createdAt": "2020-09-25T14:57:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAxOTcxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyMjg4Mw==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495022883", "bodyText": "This should be using actual type, not \"best type\"", "author": "findepi", "createdAt": "2020-09-25T14:22:17Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java", "diffHunk": "@@ -361,24 +375,60 @@ public void setField(Block block, int position)\n         }\n     }\n \n-    private static class TimestampFieldSetter\n+    private abstract static class TimestampFieldSetter\n             extends FieldSetter\n     {\n-        private final DateTimeZone timeZone;\n-        private final TimestampWritableV2 value = new TimestampWritableV2();\n+        protected final DateTimeZone timeZone;\n+        protected final TimestampWritableV2 value = new TimestampWritableV2();\n \n         public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n         {\n             super(rowInspector, row, field);\n             this.timeZone = requireNonNull(timeZone, \"timeZone is null\");\n         }\n \n+        protected Timestamp getTimestamp(long micros, IntSupplier picosSupplier)\n+        {\n+            long epochMillis = floorDiv(micros, MICROSECONDS_PER_MILLISECOND);\n+            epochMillis = timeZone.convertLocalToUTC(epochMillis, false);\n+            int nanosFromMicros = floorMod(micros, MICROSECONDS_PER_SECOND) * NANOSECONDS_PER_MICROSECOND;\n+            int nanosFromPicos = (int) roundDiv(picosSupplier.getAsInt(), PICOSECONDS_PER_NANOSECOND);\n+            return Timestamp.ofEpochMilli(epochMillis, nanosFromMicros + nanosFromPicos);\n+        }\n+    }\n+\n+    private static class ShortTimestampFieldSetter\n+            extends TimestampFieldSetter\n+    {\n+        public ShortTimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n+        {\n+            super(rowInspector, row, field, timeZone);\n+        }\n+\n+        @Override\n+        public void setField(Block block, int position)\n+        {\n+            long micros = TIMESTAMP_MICROS.getLong(block, position);\n+            Timestamp timestamp = getTimestamp(micros, () -> 0);\n+            value.set(timestamp);\n+            rowInspector.setStructFieldData(row, field, value);\n+        }\n+    }\n+\n+    private static class LongTimestampFieldSetter\n+            extends TimestampFieldSetter\n+    {\n+        public LongTimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n+        {\n+            super(rowInspector, row, field, timeZone);\n+        }\n+\n         @Override\n         public void setField(Block block, int position)\n         {\n-            long epochMilli = floorDiv(TIMESTAMP_MILLIS.getLong(block, position), MICROSECONDS_PER_MILLISECOND);\n-            epochMilli = timeZone.convertLocalToUTC(epochMilli, false);\n-            value.set(Timestamp.ofEpochMilli(epochMilli));\n+            LongTimestamp longTimestamp = (LongTimestamp) TIMESTAMP_NANOS.getObject(block, position);", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyMzUwNg==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495023506", "bodyText": "should we have this for other formats in this class?", "author": "findepi", "createdAt": "2020-09-25T14:23:14Z", "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveFileFormats.java", "diffHunk": "@@ -291,16 +294,15 @@ public void testRcBinaryOptimizedWriter(int rowCount)\n     public void testOrc(int rowCount, long fileSizePadding)\n             throws Exception\n     {\n-        // Hive binary writers are broken for timestamps\n-        List<TestColumn> testColumns = TEST_COLUMNS.stream()\n-                .filter(TestHiveFileFormats::withoutTimestamps)\n-                .collect(toImmutableList());\n-\n-        assertThatFileFormat(ORC)\n-                .withColumns(testColumns)\n-                .withRowsCount(rowCount)\n-                .withFileSizePadding(fileSizePadding)\n-                .isReadableByPageSource(new OrcPageSourceFactory(new OrcReaderOptions(), HDFS_ENVIRONMENT, STATS, UTC));\n+        for (HiveTimestampPrecision timestampPrecision : List.of(MILLISECONDS, MICROSECONDS, NANOSECONDS)) {", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAzNzQxMA==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495037410", "bodyText": "I'll add more.", "author": "aalbu", "createdAt": "2020-09-25T14:44:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyMzUwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyNDA0OA==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495024048", "bodyText": "Is this relevant? or did you disable stats collection for timestamp != 3 for now?", "author": "findepi", "createdAt": "2020-09-25T14:24:04Z", "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java", "diffHunk": "@@ -7238,6 +7261,8 @@ private Session withTimestampPrecision(Session session, String precision)\n     {\n         return Session.builder(session)\n                 .setCatalogSessionProperty(catalog, \"timestamp_precision\", precision)\n+                // TODO: remove when implementing https://github.com/prestosql/presto/issues/5170\n+                .setCatalogSessionProperty(catalog, \"collect_column_statistics_on_write\", \"false\")", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAzNTM4OQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495035389", "bodyText": "Shouldn't be needed.  I missed it when I was cleaning up my code.", "author": "aalbu", "createdAt": "2020-09-25T14:40:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyNDA0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyNDIyOA==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495024228", "bodyText": "debug?", "author": "findepi", "createdAt": "2020-09-25T14:24:19Z", "path": "presto-product-tests/src/main/java/io/prestosql/tests/hive/TestHiveStorageFormats.java", "diffHunk": "@@ -332,46 +332,269 @@ public void testSnappyCompressedParquetTableCreatedInHive()\n     }\n \n     @Test(dataProvider = \"storageFormatsWithNanosecondPrecision\", groups = STORAGE_FORMATS)\n-    public void testTimestamp(StorageFormat storageFormat)\n+    public void testTimestampCreatedFromHive(StorageFormat storageFormat)\n             throws Exception\n     {\n-        // only admin user is allowed to change session properties\n-        Connection connection = onPresto().getConnection();\n-        setAdminRole(connection);\n-        setSessionProperties(connection, storageFormat);\n-\n         String tableName = \"test_timestamp_\" + storageFormat.getName().toLowerCase(Locale.ENGLISH);\n-        onPresto().executeQuery(\"DROP TABLE IF EXISTS \" + tableName);\n-\n-        onPresto().executeQuery(format(\"CREATE TABLE %s (id BIGINT, ts TIMESTAMP) WITH (%s)\", tableName, storageFormat.getStoragePropertiesAsSql()));\n+        setupTimestampData(tableName, storageFormat);\n+        // write precision is not relevant here, as Hive always uses nanos\n         List<TimestampAndPrecision> data = ImmutableList.of(\n-                new TimestampAndPrecision(1, \"MILLISECONDS\", \"2020-01-02 12:34:56.123\", \"2020-01-02 12:34:56.123\"),\n-                new TimestampAndPrecision(2, \"MILLISECONDS\", \"2020-01-02 12:34:56.1234\", \"2020-01-02 12:34:56.123\"),\n-                new TimestampAndPrecision(3, \"MILLISECONDS\", \"2020-01-02 12:34:56.1236\", \"2020-01-02 12:34:56.124\"),\n-                new TimestampAndPrecision(4, \"MICROSECONDS\", \"2020-01-02 12:34:56.123456\", \"2020-01-02 12:34:56.123456\"),\n-                new TimestampAndPrecision(5, \"MICROSECONDS\", \"2020-01-02 12:34:56.1234564\", \"2020-01-02 12:34:56.123456\"),\n-                new TimestampAndPrecision(6, \"MICROSECONDS\", \"2020-01-02 12:34:56.1234567\", \"2020-01-02 12:34:56.123457\"),\n-                new TimestampAndPrecision(7, \"NANOSECONDS\", \"2020-01-02 12:34:56.123456789\", \"2020-01-02 12:34:56.123456789\"));\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.123\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.123\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.123\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.123\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.1234\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.1234\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.1234\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.1234\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.1234\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.1234\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.1236\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.124\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.1236\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.1236\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.1236\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.124\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.1236\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.1236\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.123456\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123456\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.123456\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.123456\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123456\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.123456\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.1234564\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123456\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.1234564\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.1234564\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123456\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.1234564\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.1234567\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123457\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.1234567\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.1234567\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123457\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.1234567\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.123456789\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123457\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.123456789\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.123456789\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123457\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.123456789\")));\n \n         // insert records one by one so that we have one file per record, which allows us to exercise predicate push-down in Parquet\n         // (which only works when the value range has a min = max)\n         for (TimestampAndPrecision entry : data) {\n-            onHive().executeQuery(format(\"INSERT INTO %s VALUES (%s, '%s')\", tableName, entry.getId(), entry.getValue()));\n+            onHive().executeQuery(format(\"INSERT INTO %s VALUES (%s, '%s')\", tableName, entry.getId(), entry.getWriteValue()));\n         }\n \n+        runTimestampQueries(tableName, data);\n+    }\n+\n+    @Test(dataProvider = \"storageFormatsWithNanosecondPrecision\", groups = STORAGE_FORMATS)\n+    public void testTimestampCreatedFromPresto(StorageFormat storageFormat)\n+            throws Exception\n+    {\n+        String tableName = \"test_timestamp_\" + storageFormat.getName().toLowerCase(Locale.ENGLISH);\n+        setupTimestampData(tableName, storageFormat);\n+\n+        // commenting out pre-epoch timestamps until https://github.com/prestosql/presto-hive-apache/pull/17 becomes available\n+        List<TimestampAndPrecision> data = ImmutableList.of(\n+//                new TimestampAndPrecision(\n+//                        \"MILLISECONDS\",\n+//                        \"1967-01-02 12:34:56.123\",\n+//                        ImmutableMap.of(", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyNTczMw==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495025733", "bodyText": "Avoid java.time's objectful representation.\nCan we use LongTimestamp or something like DecodedTimestamp (rename to HiveTimestamp?)", "author": "findepi", "createdAt": "2020-09-25T14:26:30Z", "path": "presto-rcfile/src/main/java/io/prestosql/rcfile/TimestampUtils.java", "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.rcfile;\n+\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.type.LongTimestamp;\n+import io.prestosql.spi.type.TimestampType;\n+\n+import java.time.LocalDateTime;", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAzNjk5OQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495036999", "bodyText": "I use this to format a timestamp with precision > milliseconds.  Since Joda only supports millisecond precision, I have to use java.time.", "author": "aalbu", "createdAt": "2020-09-25T14:43:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyNTczMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyNjEzNA==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495026134", "bodyText": "micros floorMod  MICROSECONDS_PER_SECOND ?", "author": "findepi", "createdAt": "2020-09-25T14:27:07Z", "path": "presto-rcfile/src/main/java/io/prestosql/rcfile/TimestampUtils.java", "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.rcfile;\n+\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.type.LongTimestamp;\n+import io.prestosql.spi.type.TimestampType;\n+\n+import java.time.LocalDateTime;\n+import java.time.ZoneOffset;\n+\n+import static io.prestosql.spi.type.Timestamps.MICROSECONDS_PER_SECOND;\n+import static io.prestosql.spi.type.Timestamps.NANOSECONDS_PER_MICROSECOND;\n+import static io.prestosql.spi.type.Timestamps.PICOSECONDS_PER_NANOSECOND;\n+import static io.prestosql.spi.type.Timestamps.roundDiv;\n+import static java.lang.Math.floorDiv;\n+import static java.lang.Math.floorMod;\n+\n+public final class TimestampUtils\n+{\n+    private TimestampUtils() {}\n+\n+    public static LocalDateTime getLocalDateTime(TimestampType type, Block block, int position)\n+    {\n+        if (type.isShort()) {\n+            long micros = type.getLong(block, position);\n+            long epochSeconds = floorDiv(micros, MICROSECONDS_PER_SECOND);\n+            // we know this fits in an int\n+            int nanosFraction = (int) ((micros - epochSeconds * MICROSECONDS_PER_SECOND) * NANOSECONDS_PER_MICROSECOND);", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTA3MTA0Nw==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495071047", "bodyText": "I was just trying to avoid re-executing floorDiv(micros, MICROSECONDS_PER_SECOND), but it's the second or third time I'm getting a similar review comment, so I'll stop trying to micro-optimize \ud83d\ude09", "author": "aalbu", "createdAt": "2020-09-25T15:37:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyNjEzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyODA4Nw==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495028087", "bodyText": "nit: we could add int roundDiv(int,long) overload for cases iike this one\nyou can take https://github.com/findepi/presto/commits/round-div is you want to", "author": "findepi", "createdAt": "2020-09-25T14:29:54Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java", "diffHunk": "@@ -361,24 +375,60 @@ public void setField(Block block, int position)\n         }\n     }\n \n-    private static class TimestampFieldSetter\n+    private abstract static class TimestampFieldSetter\n             extends FieldSetter\n     {\n-        private final DateTimeZone timeZone;\n-        private final TimestampWritableV2 value = new TimestampWritableV2();\n+        protected final DateTimeZone timeZone;\n+        protected final TimestampWritableV2 value = new TimestampWritableV2();\n \n         public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n         {\n             super(rowInspector, row, field);\n             this.timeZone = requireNonNull(timeZone, \"timeZone is null\");\n         }\n \n+        protected Timestamp getTimestamp(long micros, IntSupplier picosSupplier)\n+        {\n+            long epochMillis = floorDiv(micros, MICROSECONDS_PER_MILLISECOND);\n+            epochMillis = timeZone.convertLocalToUTC(epochMillis, false);\n+            int nanosFromMicros = floorMod(micros, MICROSECONDS_PER_SECOND) * NANOSECONDS_PER_MICROSECOND;\n+            int nanosFromPicos = (int) roundDiv(picosSupplier.getAsInt(), PICOSECONDS_PER_NANOSECOND);", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "1fc9aa8a1e5457407766a5c3bf37031e1857ec66", "url": "https://github.com/trinodb/trino/commit/1fc9aa8a1e5457407766a5c3bf37031e1857ec66", "message": "Minor ORC cleanup", "committedDate": "2020-09-30T00:37:02Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzQ4NDkxMQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497484911", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    return (int) roundDiv((long) value, factor);\n          \n          \n            \n                    //noinspection NumericCastThatLosesPrecision\n          \n          \n            \n                    return (int) roundDiv((long) value, factor);", "author": "findepi", "createdAt": "2020-09-30T12:53:22Z", "path": "presto-spi/src/main/java/io/prestosql/spi/type/Timestamps.java", "diffHunk": "@@ -102,6 +102,11 @@ private static long scaleFactor(int fromPrecision, int toPrecision)\n         return POWERS_OF_TEN[toPrecision - fromPrecision];\n     }\n \n+    public static int roundDiv(int value, long factor)\n+    {\n+        return (int) roundDiv((long) value, factor);", "originalCommit": "c5ac163b6c06959713acfbe6c88bcaa4596d14eb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzgxMzYyMw==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497813623", "bodyText": "I've added the inspection to my IDE \ud83d\ude00", "author": "aalbu", "createdAt": "2020-09-30T21:33:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzQ4NDkxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzQ4NjI0MQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497486241", "bodyText": "Add a\n// TODO validate timestamps in structural types\n\n+ issue", "author": "findepi", "createdAt": "2020-09-30T12:55:19Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HiveMetadata.java", "diffHunk": "@@ -2596,13 +2597,13 @@ private static void validateColumns(ConnectorTableMetadata tableMetadata)\n     }\n \n     // temporary, until variable precision timestamps are supported on write\n-    private static void validateTimestampColumns(List<ColumnMetadata> columns)\n+    private static void validateTimestampColumns(List<ColumnMetadata> columns, HiveTimestampPrecision timestampPrecision)", "originalCommit": "14ffa79a505a21b3f610a1ab8b067bcd695e0f77", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzQ4ODA3NA==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497488074", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        long epochMicros;\n          \n          \n            \n                        long epochSeconds;\n          \n      \n    \n    \n  \n\ndeclare epochSeconds and picosOfSecond outside and declare epochMicros separately inside of both branches\nthis will make the conversion easier to follow and verify correctness (micros, picosOfMicro, picosOfSecond), at the cost of writing epochSeconds = floorDiv(epochMicros, MICROSECONDS_PER_SECOND); twice", "author": "findepi", "createdAt": "2020-09-30T12:58:05Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java", "diffHunk": "@@ -365,22 +370,47 @@ public void setField(Block block, int position)\n             extends FieldSetter\n     {\n         private final DateTimeZone timeZone;\n+        private final TimestampType type;\n         private final TimestampWritableV2 value = new TimestampWritableV2();\n \n-        public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n+        public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, TimestampType type, DateTimeZone timeZone)\n         {\n             super(rowInspector, row, field);\n+            this.type = requireNonNull(type, \"type is null\");\n             this.timeZone = requireNonNull(timeZone, \"timeZone is null\");\n         }\n \n         @Override\n         public void setField(Block block, int position)\n         {\n-            long epochMilli = floorDiv(TIMESTAMP_MILLIS.getLong(block, position), MICROSECONDS_PER_MILLISECOND);\n-            epochMilli = timeZone.convertLocalToUTC(epochMilli, false);\n-            value.set(Timestamp.ofEpochMilli(epochMilli));\n+            long epochMicros;", "originalCommit": "14ffa79a505a21b3f610a1ab8b067bcd695e0f77", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU0ODk0OQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497548949", "bodyText": "since it's always used together with TIMESTAMP '%s', it would be more convenient to define\nprivate static String formatTimestamp(LocalDateTime) \n\nthe formatter can be inline in that method (or a const) -- perf doesnt matter", "author": "findepi", "createdAt": "2020-09-30T14:20:43Z", "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java", "diffHunk": "@@ -161,6 +160,7 @@\n public class TestHiveIntegrationSmokeTest\n         extends AbstractTestIntegrationSmokeTest\n {\n+    private static final DateTimeFormatter TIMESTAMP_FORMATTER = DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss.SSSSSSSSS\");", "originalCommit": "14ffa79a505a21b3f610a1ab8b067bcd695e0f77", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU1MDU1Ng==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497550556", "bodyText": "co we have correctness tests ensure\nWHERE col < actual_value + 1 nanosecond\n\ndoesn't filter out col = actual_value (for col being full millis .... h:m:s.001000000 or not: .... h:m:s.001000001)", "author": "findepi", "createdAt": "2020-09-30T14:22:47Z", "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java", "diffHunk": "@@ -4209,7 +4206,44 @@ public void testParquetTimestampPredicatePushdown(HiveTimestampPrecision timesta\n         assertEventually(new Duration(30, SECONDS), () -> {\n             ResultWithQueryId<MaterializedResult> result = queryRunner.executeWithQueryId(\n                     session,\n-                    format(\"SELECT * FROM test_parquet_timestamp_predicate_pushdown WHERE t = TIMESTAMP '%s'\", value));\n+                    format(\"SELECT * FROM test_parquet_timestamp_predicate_pushdown WHERE t = TIMESTAMP '%s'\", TIMESTAMP_FORMATTER.format(value)));\n+            sleeper.sleep();\n+            assertThat(getQueryInfo(queryRunner, result).getQueryStats().getProcessedInputDataSize().toBytes()).isGreaterThan(0);\n+        });\n+    }\n+\n+    @Test(dataProvider = \"timestampPrecisionAndValues\")\n+    public void testOrcTimestampPredicatePushdown(HiveTimestampPrecision timestampPrecision, LocalDateTime value)\n+    {\n+        Session session = withTimestampPrecision(getSession(), timestampPrecision);\n+        assertUpdate(\"DROP TABLE IF EXISTS test_orc_timestamp_predicate_pushdown\");\n+        assertUpdate(\"CREATE TABLE test_orc_timestamp_predicate_pushdown (t TIMESTAMP) WITH (format = 'ORC')\");\n+        assertUpdate(session, format(\"INSERT INTO test_orc_timestamp_predicate_pushdown VALUES (TIMESTAMP '%s')\", TIMESTAMP_FORMATTER.format(value)), 1);\n+        assertQuery(session, \"SELECT * FROM test_orc_timestamp_predicate_pushdown\", format(\"VALUES (TIMESTAMP '%s')\", TIMESTAMP_FORMATTER.format(value)));\n+\n+        // to account for the fact that ORC stats are stored at millisecond precision and Presto rounds timestamps,\n+        // we filter by timestamps that differ from the actual value by at least 1ms, to observe pruning", "originalCommit": "14ffa79a505a21b3f610a1ab8b067bcd695e0f77", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU1MDgyOQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497550829", "bodyText": "link to gh issue about that (#5172 right?)", "author": "findepi", "createdAt": "2020-09-30T14:23:08Z", "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java", "diffHunk": "@@ -4209,7 +4206,44 @@ public void testParquetTimestampPredicatePushdown(HiveTimestampPrecision timesta\n         assertEventually(new Duration(30, SECONDS), () -> {\n             ResultWithQueryId<MaterializedResult> result = queryRunner.executeWithQueryId(\n                     session,\n-                    format(\"SELECT * FROM test_parquet_timestamp_predicate_pushdown WHERE t = TIMESTAMP '%s'\", value));\n+                    format(\"SELECT * FROM test_parquet_timestamp_predicate_pushdown WHERE t = TIMESTAMP '%s'\", TIMESTAMP_FORMATTER.format(value)));\n+            sleeper.sleep();\n+            assertThat(getQueryInfo(queryRunner, result).getQueryStats().getProcessedInputDataSize().toBytes()).isGreaterThan(0);\n+        });\n+    }\n+\n+    @Test(dataProvider = \"timestampPrecisionAndValues\")\n+    public void testOrcTimestampPredicatePushdown(HiveTimestampPrecision timestampPrecision, LocalDateTime value)\n+    {\n+        Session session = withTimestampPrecision(getSession(), timestampPrecision);\n+        assertUpdate(\"DROP TABLE IF EXISTS test_orc_timestamp_predicate_pushdown\");\n+        assertUpdate(\"CREATE TABLE test_orc_timestamp_predicate_pushdown (t TIMESTAMP) WITH (format = 'ORC')\");\n+        assertUpdate(session, format(\"INSERT INTO test_orc_timestamp_predicate_pushdown VALUES (TIMESTAMP '%s')\", TIMESTAMP_FORMATTER.format(value)), 1);\n+        assertQuery(session, \"SELECT * FROM test_orc_timestamp_predicate_pushdown\", format(\"VALUES (TIMESTAMP '%s')\", TIMESTAMP_FORMATTER.format(value)));\n+\n+        // to account for the fact that ORC stats are stored at millisecond precision and Presto rounds timestamps,\n+        // we filter by timestamps that differ from the actual value by at least 1ms, to observe pruning\n+        DistributedQueryRunner queryRunner = (DistributedQueryRunner) getQueryRunner();\n+        ResultWithQueryId<MaterializedResult> queryResult = queryRunner.executeWithQueryId(\n+                session,\n+                format(\"SELECT * FROM test_orc_timestamp_predicate_pushdown WHERE t < TIMESTAMP '%s'\", TIMESTAMP_FORMATTER.format(value.minusNanos(MILLISECONDS.toNanos(1)))));\n+        assertEquals(getQueryInfo(queryRunner, queryResult).getQueryStats().getProcessedInputDataSize().toBytes(), 0);\n+\n+        queryResult = queryRunner.executeWithQueryId(\n+                session,\n+                format(\"SELECT * FROM test_orc_timestamp_predicate_pushdown WHERE t > TIMESTAMP '%s'\", TIMESTAMP_FORMATTER.format(value.plusNanos(MILLISECONDS.toNanos(1)))));\n+        assertEquals(getQueryInfo(queryRunner, queryResult).getQueryStats().getProcessedInputDataSize().toBytes(), 0);\n+\n+        // TODO: replace this with a simple query stats check once we find a way to wait until all pending updates to query stats have been applied", "originalCommit": "14ffa79a505a21b3f610a1ab8b067bcd695e0f77", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU1MTYzMQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497551631", "bodyText": "nit \"\\\\E\" is probably redundant", "author": "findepi", "createdAt": "2020-09-30T14:24:07Z", "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java", "diffHunk": "@@ -7078,6 +7092,148 @@ public void testUnsupportedCsvTable()\n                 \"\\\\QHive CSV storage format only supports VARCHAR (unbounded). Unsupported columns: i integer, bound varchar(10)\\\\E\");\n     }\n \n+    @Test\n+    public void testWriteInvalidPrecisionTimestamp()\n+    {\n+        Session session = withTimestampPrecision(getSession(), HiveTimestampPrecision.MICROSECONDS);\n+        assertQueryFails(\n+                session,\n+                \"CREATE TABLE test_invalid_precision_timestamp(ts) AS SELECT TIMESTAMP '2001-02-03 11:22:33.123456789'\",\n+                \"\\\\QIncorrect timestamp precision for timestamp(9); the configured precision is: \" + HiveTimestampPrecision.MICROSECONDS + \"\\\\E\");", "originalCommit": "14ffa79a505a21b3f610a1ab8b067bcd695e0f77", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU1MzA4Ng==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497553086", "bodyText": "i like the change but it belongs to the prep commit, not Variable precision timestamp support for Hive write operations", "author": "findepi", "createdAt": "2020-09-30T14:25:56Z", "path": "presto-main/src/main/java/io/prestosql/testing/MaterializedResult.java", "diffHunk": "@@ -345,13 +343,6 @@ else if (type instanceof RowType) {\n         }\n     }\n \n-    private static DecodedTimestamp toDecodedTimestamp(SqlTimestamp sqlTimestamp)", "originalCommit": "14ffa79a505a21b3f610a1ab8b067bcd695e0f77", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU1Mzg1Mw==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497553853", "bodyText": "why did we gain toIntExact here?", "author": "findepi", "createdAt": "2020-09-30T14:26:53Z", "path": "presto-orc/src/test/java/io/prestosql/orc/OrcTester.java", "diffHunk": "@@ -1041,7 +1041,7 @@ private static Object preprocessWriteValueHive(Type type, Object value)\n         }\n         if (type.equals(TIMESTAMP_TZ_MILLIS) || type.equals(TIMESTAMP_TZ_MICROS) || type.equals(TIMESTAMP_TZ_NANOS)) {\n             SqlTimestampWithTimeZone timestamp = (SqlTimestampWithTimeZone) value;\n-            int nanosOfMilli = roundDiv(timestamp.getPicosOfMilli(), PICOSECONDS_PER_NANOSECOND);\n+            int nanosOfMilli = toIntExact(roundDiv(timestamp.getPicosOfMilli(), PICOSECONDS_PER_NANOSECOND));", "originalCommit": "14ffa79a505a21b3f610a1ab8b067bcd695e0f77", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU3OTg4Mg==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497579882", "bodyText": "I messed up during a merge while trying to move this change to its own commit (per David's suggestion).  I'll clean up.", "author": "aalbu", "createdAt": "2020-09-30T14:59:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU1Mzg1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU1NjI0Nw==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497556247", "bodyText": "storage_formats tests are run multiple times, on many different environments, since file format behavior may interact with things like kerberos, impersonation\nthese tests do not need to run multiple times, and i guess they take quite some time (correct?)\nwe can move them to separate group\nor, we can have them without a group (then will be run in suite-1, on multine)\n-- in any case it'd be good to document the reason for this in a code comment\nor move the tests to a spearate class", "author": "findepi", "createdAt": "2020-09-30T14:29:29Z", "path": "presto-product-tests/src/main/java/io/prestosql/tests/hive/TestHiveStorageFormats.java", "diffHunk": "@@ -332,46 +332,219 @@ public void testSnappyCompressedParquetTableCreatedInHive()\n     }\n \n     @Test(dataProvider = \"storageFormatsWithNanosecondPrecision\", groups = STORAGE_FORMATS)\n-    public void testTimestamp(StorageFormat storageFormat)\n+    public void testTimestampCreatedFromHive(StorageFormat storageFormat)\n             throws Exception\n     {\n-        // only admin user is allowed to change session properties\n-        Connection connection = onPresto().getConnection();\n-        setAdminRole(connection);\n-        setSessionProperties(connection, storageFormat);\n-\n         String tableName = \"test_timestamp_\" + storageFormat.getName().toLowerCase(Locale.ENGLISH);\n-        onPresto().executeQuery(\"DROP TABLE IF EXISTS \" + tableName);\n-\n-        onPresto().executeQuery(format(\"CREATE TABLE %s (id BIGINT, ts TIMESTAMP) WITH (%s)\", tableName, storageFormat.getStoragePropertiesAsSql()));\n+        setupTimestampData(tableName, storageFormat);\n+        // write precision is not relevant here, as Hive always uses nanos\n         List<TimestampAndPrecision> data = ImmutableList.of(\n-                new TimestampAndPrecision(1, \"MILLISECONDS\", \"2020-01-02 12:34:56.123\", \"2020-01-02 12:34:56.123\"),\n-                new TimestampAndPrecision(2, \"MILLISECONDS\", \"2020-01-02 12:34:56.1234\", \"2020-01-02 12:34:56.123\"),\n-                new TimestampAndPrecision(3, \"MILLISECONDS\", \"2020-01-02 12:34:56.1236\", \"2020-01-02 12:34:56.124\"),\n-                new TimestampAndPrecision(4, \"MICROSECONDS\", \"2020-01-02 12:34:56.123456\", \"2020-01-02 12:34:56.123456\"),\n-                new TimestampAndPrecision(5, \"MICROSECONDS\", \"2020-01-02 12:34:56.1234564\", \"2020-01-02 12:34:56.123456\"),\n-                new TimestampAndPrecision(6, \"MICROSECONDS\", \"2020-01-02 12:34:56.1234567\", \"2020-01-02 12:34:56.123457\"),\n-                new TimestampAndPrecision(7, \"NANOSECONDS\", \"2020-01-02 12:34:56.123456789\", \"2020-01-02 12:34:56.123456789\"));\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.123\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.123\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.123\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.123\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.1234\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.1234\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.1234\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.1234\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.1234\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.1234\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.1236\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.124\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.1236\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.1236\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.1236\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.124\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.1236\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.1236\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.123456\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123456\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.123456\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.123456\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123456\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.123456\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.1234564\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123456\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.1234564\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.1234564\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123456\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.1234564\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.1234567\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123457\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.1234567\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.1234567\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123457\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.1234567\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.123456789\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123457\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.123456789\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.123456789\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123457\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.123456789\")));\n \n         // insert records one by one so that we have one file per record, which allows us to exercise predicate push-down in Parquet\n         // (which only works when the value range has a min = max)\n         for (TimestampAndPrecision entry : data) {\n-            onHive().executeQuery(format(\"INSERT INTO %s VALUES (%s, '%s')\", tableName, entry.getId(), entry.getValue()));\n+            onHive().executeQuery(format(\"INSERT INTO %s VALUES (%s, '%s')\", tableName, entry.getId(), entry.getWriteValue()));\n         }\n \n+        runTimestampQueries(tableName, data);\n+    }\n+\n+    @Test(dataProvider = \"storageFormatsWithNanosecondPrecision\", groups = STORAGE_FORMATS)", "originalCommit": "14ffa79a505a21b3f610a1ab8b067bcd695e0f77", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU1NzE1OA==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497557158", "bodyText": "here as elswhere: confine epochMicros to each of if/else blocks and have epochSeconds and picosOfSecond as the only things common", "author": "findepi", "createdAt": "2020-09-30T14:30:38Z", "path": "presto-rcfile/src/main/java/io/prestosql/rcfile/TimestampUtils.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.rcfile;\n+\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.type.LongTimestamp;\n+import io.prestosql.spi.type.TimestampType;\n+\n+import java.time.LocalDateTime;\n+import java.time.ZoneOffset;\n+\n+import static io.prestosql.spi.type.Timestamps.MICROSECONDS_PER_SECOND;\n+import static io.prestosql.spi.type.Timestamps.PICOSECONDS_PER_MICROSECOND;\n+import static io.prestosql.spi.type.Timestamps.PICOSECONDS_PER_NANOSECOND;\n+import static java.lang.Math.floorDiv;\n+import static java.lang.Math.floorMod;\n+import static java.lang.Math.toIntExact;\n+\n+public final class TimestampUtils\n+{\n+    private TimestampUtils() {}\n+\n+    public static LocalDateTime getLocalDateTime(TimestampType type, Block block, int position)\n+    {\n+        if (block.isNull(position)) {\n+            return null;\n+        }\n+        long epochMicros;\n+        long picosOfSecond;\n+        if (type.isShort()) {\n+            epochMicros = type.getLong(block, position);\n+            picosOfSecond = (long) floorMod(epochMicros, MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND;\n+        }\n+        else {\n+            LongTimestamp longTimestamp = (LongTimestamp) type.getObject(block, position);\n+            epochMicros = longTimestamp.getEpochMicros();\n+            picosOfSecond = (long) floorMod(epochMicros, MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND + longTimestamp.getPicosOfMicro();\n+        }\n+        long epochSeconds = floorDiv(epochMicros, MICROSECONDS_PER_SECOND);", "originalCommit": "14ffa79a505a21b3f610a1ab8b067bcd695e0f77", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "58817be6cb8344ce7c1e83ca005711584e34e7a3", "url": "https://github.com/trinodb/trino/commit/58817be6cb8344ce7c1e83ca005711584e34e7a3", "message": "Add roundDiv overload in Timestamps", "committedDate": "2020-11-02T23:31:23Z", "type": "commit"}, {"oid": "4cb7d74347385117166b0579ee36f0476ed753af", "url": "https://github.com/trinodb/trino/commit/4cb7d74347385117166b0579ee36f0476ed753af", "message": "Construct session correctly when finishing stats collection", "committedDate": "2020-11-02T23:31:23Z", "type": "commit"}, {"oid": "8904475bbb3b6de2fcf77cc30f597c9c2bc2ad80", "url": "https://github.com/trinodb/trino/commit/8904475bbb3b6de2fcf77cc30f597c9c2bc2ad80", "message": "Handle variable precision timestamps in MaterializedResult", "committedDate": "2020-11-02T23:31:24Z", "type": "commit"}, {"oid": "04b45b1c27c622b087e2040648bd074d77142055", "url": "https://github.com/trinodb/trino/commit/04b45b1c27c622b087e2040648bd074d77142055", "message": "Variable precision timestamp support for Hive write operations", "committedDate": "2020-11-03T03:15:14Z", "type": "commit"}, {"oid": "d3fde11bc72f06a3bfb7a9159d424f7ef588d3e4", "url": "https://github.com/trinodb/trino/commit/d3fde11bc72f06a3bfb7a9159d424f7ef588d3e4", "message": "Remove unused method", "committedDate": "2020-11-03T03:15:15Z", "type": "commit"}, {"oid": "26beb0e02d069b0ab269bb9e5436f8d65578a48a", "url": "https://github.com/trinodb/trino/commit/26beb0e02d069b0ab269bb9e5436f8d65578a48a", "message": "Change signature for HiveType#getType overload", "committedDate": "2020-11-03T03:15:15Z", "type": "commit"}, {"oid": "26beb0e02d069b0ab269bb9e5436f8d65578a48a", "url": "https://github.com/trinodb/trino/commit/26beb0e02d069b0ab269bb9e5436f8d65578a48a", "message": "Change signature for HiveType#getType overload", "committedDate": "2020-11-03T03:15:15Z", "type": "forcePushed"}]}