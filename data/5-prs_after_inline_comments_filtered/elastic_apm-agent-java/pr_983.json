{"pr_number": 983, "pr_title": "Inferring spans with async-profiler", "pr_createdAt": "2020-01-07T12:25:16Z", "pr_url": "https://github.com/elastic/apm-agent-java/pull/983", "timeline": [{"oid": "ee76d39f1fb469c5cd400256456e08d1b1b2cea1", "url": "https://github.com/elastic/apm-agent-java/commit/ee76d39f1fb469c5cd400256456e08d1b1b2cea1", "message": "Fix typo in method", "committedDate": "2020-02-19T15:57:16Z", "type": "commit"}, {"oid": "3c883d4e9341ad8f5e6ee449f47b28a2b22909c5", "url": "https://github.com/elastic/apm-agent-java/commit/3c883d4e9341ad8f5e6ee449f47b28a2b22909c5", "message": "Add async-profiler NOTICE", "committedDate": "2020-02-19T17:23:03Z", "type": "commit"}, {"oid": "54ac9cd4b978987bd92081ee69b4e012ed15ed2b", "url": "https://github.com/elastic/apm-agent-java/commit/54ac9cd4b978987bd92081ee69b4e012ed15ed2b", "message": "Don't validate schema of inferred spans in integration tests", "committedDate": "2020-02-19T17:29:42Z", "type": "commit"}, {"oid": "9572bfea9119404bab2316c40ba303236923331b", "url": "https://github.com/elastic/apm-agent-java/commit/9572bfea9119404bab2316c40ba303236923331b", "message": "Sampling profiler POC", "committedDate": "2019-12-05T15:10:02Z", "type": "commit"}, {"oid": "bdc28ef99bb2eef2d4eae66650c76293e5976ec6", "url": "https://github.com/elastic/apm-agent-java/commit/bdc28ef99bb2eef2d4eae66650c76293e5976ec6", "message": "Introduce profiling sessions\n\nAlso process events based on timestamp with a MessagePassingQueue", "committedDate": "2019-12-06T12:27:03Z", "type": "commit"}, {"oid": "ba20341c3b426062819871de8dc32d4f744d6192", "url": "https://github.com/elastic/apm-agent-java/commit/ba20341c3b426062819871de8dc32d4f744d6192", "message": "Support non-stop profiling via profiling_delay=0", "committedDate": "2019-12-06T13:21:30Z", "type": "commit"}, {"oid": "829bd416bb9c7350b0ceae8cb4f8efd7e8f6840c", "url": "https://github.com/elastic/apm-agent-java/commit/829bd416bb9c7350b0ceae8cb4f8efd7e8f6840c", "message": "Add profiling_included_classes option", "committedDate": "2019-12-06T15:17:20Z", "type": "commit"}, {"oid": "eadc244d7bc2d899189e4fa36cdd97d01d3cb6a4", "url": "https://github.com/elastic/apm-agent-java/commit/eadc244d7bc2d899189e4fa36cdd97d01d3cb6a4", "message": "Decouple CallTree From StackTraceElement", "committedDate": "2019-12-06T15:46:46Z", "type": "commit"}, {"oid": "6d210a966c1ccbdf4098dde42f9b15e3dc509a80", "url": "https://github.com/elastic/apm-agent-java/commit/6d210a966c1ccbdf4098dde42f9b15e3dc509a80", "message": "Early POC to use async-profiler to correlate apm traces with profiling data\n\nSome obstacles:\n- Can't use plain text trace format because it does not include the timestamp of the events.\n  There's an issue and prototype for the plain-text format:\n  https://github.com/jvm-profiling-tools/async-profiler/issues/191\n  - JFR output could potentially work\n    - ids for distinct stack trace\n    - records event metadata: thread id timestamp, stack trace id\n    - The thread state in JFR file is always RUNNABLE, even when {@code -e wall} is active\n      https://github.com/jvm-profiling-tools/async-profiler/issues/279\n- Uses native thread ids, not java thread ids\n  While async-profiler is capable of creating stack traces per thread,\n  it reports the native thread ID (which is not equal to `java.lang.Thread#getId()`.\n  Probably best to correlate by thread name which is reported (however not in JFR format)\n  https://github.com/jvm-profiling-tools/async-profiler/issues/277\n  https://github.com/jvm-profiling-tools/async-profiler/issues/252\n- For some reason exporting jfr files not working with the Java API\n  https://github.com/jvm-profiling-tools/async-profiler/issues/278\nThere are some more caveats which is the reason why we would still need a fallback to `java.lang.management.ThreadMXBean#dumpAllThreads`:\n- Doesn't work on windows\n- Limitations on profiling in containers: https://github.com/jvm-profiling-tools/async-profiler#profiling-java-in-a-container\n  By default, Docker container restricts the access to\u00a0perf_event_open\u00a0syscall.\n  - Workaround: `-e itimer` profiling mode is similar to cpu mode, but does not require perf_events support.\n    As a drawback, there will be no kernel stack traces.\n  - Is there something similar for `-e wall`? Is setting `--all-user` enough?", "committedDate": "2019-12-09T13:39:15Z", "type": "commit"}, {"oid": "d43d065c54501975e099c75c401eb1480e6a2fc8", "url": "https://github.com/elastic/apm-agent-java/commit/d43d065c54501975e099c75c401eb1480e6a2fc8", "message": "Don't call threadMXBean.getThreadInfo thread id array is empty\n\nTo avoid IllegalArgumentException", "committedDate": "2019-12-09T14:55:14Z", "type": "commit"}, {"oid": "0bb8403d56b8a5950d2f624a89b03eb29ccce31c", "url": "https://github.com/elastic/apm-agent-java/commit/0bb8403d56b8a5950d2f624a89b03eb29ccce31c", "message": "Populate span.stacktrace, duration and timestamp based on nano timestamps as opposed to ticks", "committedDate": "2019-12-11T15:52:30Z", "type": "commit"}, {"oid": "c84020d243463f725fd4b21dee563bc254590740", "url": "https://github.com/elastic/apm-agent-java/commit/c84020d243463f725fd4b21dee563bc254590740", "message": "Strongly instead of stringly type StackFrames", "committedDate": "2019-12-12T08:56:39Z", "type": "commit"}, {"oid": "5a9e35ba28c3636226ca5494e194ff7b4f3847cb", "url": "https://github.com/elastic/apm-agent-java/commit/5a9e35ba28c3636226ca5494e194ff7b4f3847cb", "message": "Avoid cloning the stack trace", "committedDate": "2019-12-13T08:46:27Z", "type": "commit"}, {"oid": "0ab21bd4c5499a73ae3157d212e36988cc18c2eb", "url": "https://github.com/elastic/apm-agent-java/commit/0ab21bd4c5499a73ae3157d212e36988cc18c2eb", "message": "Parent/child fixes, testing", "committedDate": "2019-12-13T14:20:16Z", "type": "commit"}, {"oid": "c945cb35223d4aed7cba8c4d515110c87b628545", "url": "https://github.com/elastic/apm-agent-java/commit/c945cb35223d4aed7cba8c4d515110c87b628545", "message": "Use same timestamp for processing events and stack traces", "committedDate": "2019-12-16T09:08:35Z", "type": "commit"}, {"oid": "cbb268f17b98772c3aca9eba9fd3c1789c95c997", "url": "https://github.com/elastic/apm-agent-java/commit/cbb268f17b98772c3aca9eba9fd3c1789c95c997", "message": "Docs for config options", "committedDate": "2019-12-16T16:03:26Z", "type": "commit"}, {"oid": "a7353619a4e45e04ab13ba4127b24c74b63b478b", "url": "https://github.com/elastic/apm-agent-java/commit/a7353619a4e45e04ab13ba4127b24c74b63b478b", "message": "Merge remote-tracking branch 'origin/master' into inferred-spans", "committedDate": "2019-12-16T16:12:39Z", "type": "commit"}, {"oid": "5bcd638b1373926a79c2ff0c7466ddaca480b657", "url": "https://github.com/elastic/apm-agent-java/commit/5bcd638b1373926a79c2ff0c7466ddaca480b657", "message": "Use RingBuffer instead of Queue for activation events\n\nThe RingBuffer also acts as an object pool.\nThe idea is that the number of activation events should not impact\nthe allocation rate, only the profiler_sampling_interval should.\nThat's currently not completely true\nas processing activation events requires copying the TraceContext.", "committedDate": "2019-12-18T09:27:41Z", "type": "commit"}, {"oid": "886f2d9659e8e20893396ca733bf4cecdb0daa51", "url": "https://github.com/elastic/apm-agent-java/commit/886f2d9659e8e20893396ca733bf4cecdb0daa51", "message": "Fix compile error", "committedDate": "2019-12-18T12:51:25Z", "type": "commit"}, {"oid": "d62d60b6d9fcd21984a00a8568a30c54c4890179", "url": "https://github.com/elastic/apm-agent-java/commit/d62d60b6d9fcd21984a00a8568a30c54c4890179", "message": "Make configuration options dynamic", "committedDate": "2019-12-18T16:03:46Z", "type": "commit"}, {"oid": "201f8db8d5a3af695e41773c4d7c2d888af3e147", "url": "https://github.com/elastic/apm-agent-java/commit/201f8db8d5a3af695e41773c4d7c2d888af3e147", "message": "Decrease size of ActivationEvent from 792B to 176B and increase RingBuffer size", "committedDate": "2019-12-19T15:09:54Z", "type": "commit"}, {"oid": "7f5173f3f1dd54525c66f27612cf76dc91c5073f", "url": "https://github.com/elastic/apm-agent-java/commit/7f5173f3f1dd54525c66f27612cf76dc91c5073f", "message": "Make processing ActivationEvents (almost) garbage free\n\n- Recycle CallTree.Roots\n- Only if an activation is actually relevant for the CallTree,\n  there will be an allocation", "committedDate": "2019-12-19T17:20:46Z", "type": "commit"}, {"oid": "4aabb324f9ae61ea9c60d4819494d1db09ec409d", "url": "https://github.com/elastic/apm-agent-java/commit/4aabb324f9ae61ea9c60d4819494d1db09ec409d", "message": "Fixing one parent/child relationship issue", "committedDate": "2019-12-20T16:50:24Z", "type": "commit"}, {"oid": "9403c9a92a858981b9db5bf27bef5ec20b364cd9", "url": "https://github.com/elastic/apm-agent-java/commit/9403c9a92a858981b9db5bf27bef5ec20b364cd9", "message": "Fixups", "committedDate": "2019-12-22T13:10:33Z", "type": "commit"}, {"oid": "29b941870d84179acd16b64a7eddea7c0fdd6715", "url": "https://github.com/elastic/apm-agent-java/commit/29b941870d84179acd16b64a7eddea7c0fdd6715", "message": "Fist inferred span should have no stack trace", "committedDate": "2019-12-22T22:22:48Z", "type": "commit"}, {"oid": "0fd7c69ad81b3525b977e0125ea013594e3a5cce", "url": "https://github.com/elastic/apm-agent-java/commit/0fd7c69ad81b3525b977e0125ea013594e3a5cce", "message": "Fix memory leak, allocation optimizations", "committedDate": "2019-12-24T08:39:05Z", "type": "commit"}, {"oid": "93135d5774b7dd7750804a531e2643116e81543a", "url": "https://github.com/elastic/apm-agent-java/commit/93135d5774b7dd7750804a531e2643116e81543a", "message": "Merge branch 'inferred-spans' into async-profiler", "committedDate": "2019-12-25T12:42:24Z", "type": "commit"}, {"oid": "16647d57c483df58d0cf06acf9accb29c3b67c6b", "url": "https://github.com/elastic/apm-agent-java/commit/16647d57c483df58d0cf06acf9accb29c3b67c6b", "message": "Add JFR file parser", "committedDate": "2019-12-29T10:07:58Z", "type": "commit"}, {"oid": "9f6176d58ab52a14605b4d33007adab80790b416", "url": "https://github.com/elastic/apm-agent-java/commit/9f6176d58ab52a14605b4d33007adab80790b416", "message": "Remove thread-dumping profiler in favor of async-profiler", "committedDate": "2019-12-31T13:37:18Z", "type": "commit"}, {"oid": "e64e1bc97a3407989e3eb1ada18e66490962f7f7", "url": "https://github.com/elastic/apm-agent-java/commit/e64e1bc97a3407989e3eb1ada18e66490962f7f7", "message": "Don't resolve symbols of excluded classes and methods\n\nreduces allocations", "committedDate": "2019-12-31T14:32:50Z", "type": "commit"}, {"oid": "ae1ffb8e0607b094a0d6c86d45cdb7b026a0300f", "url": "https://github.com/elastic/apm-agent-java/commit/ae1ffb8e0607b094a0d6c86d45cdb7b026a0300f", "message": "Write ActivationEvents into memory-mapped file\n\nThis file can hold up to 100k events and is around 10mb in size", "committedDate": "2020-01-04T16:23:27Z", "type": "commit"}, {"oid": "a2d64a3e8715d609629c082274453f3fadeef32f", "url": "https://github.com/elastic/apm-agent-java/commit/a2d64a3e8715d609629c082274453f3fadeef32f", "message": "Reduce allocations", "committedDate": "2020-01-05T08:32:42Z", "type": "commit"}, {"oid": "e72cd8848030e7ffdd1b1fae9443a9054aa98aa0", "url": "https://github.com/elastic/apm-agent-java/commit/e72cd8848030e7ffdd1b1fae9443a9054aa98aa0", "message": "Use primitive collections from Agrona and recycle JfrParser to minimize allocations", "committedDate": "2020-01-05T15:33:25Z", "type": "commit"}, {"oid": "7bec1182e2dda0c87532ce458fa1756b3e317464", "url": "https://github.com/elastic/apm-agent-java/commit/7bec1182e2dda0c87532ce458fa1756b3e317464", "message": "Fix async-profiler init race condition", "committedDate": "2020-01-07T14:08:53Z", "type": "commit"}, {"oid": "8e1430a9d916ca087422ccaf8c3daf7516d136fc", "url": "https://github.com/elastic/apm-agent-java/commit/8e1430a9d916ca087422ccaf8c3daf7516d136fc", "message": "Remove leftover file", "committedDate": "2020-01-07T14:17:45Z", "type": "commit"}, {"oid": "67cdd51826dcb6e33bd378d8ce8b5932ab757f46", "url": "https://github.com/elastic/apm-agent-java/commit/67cdd51826dcb6e33bd378d8ce8b5932ab757f46", "message": "Merge remote-tracking branch 'origin/master' into async-profiler", "committedDate": "2020-01-07T14:24:56Z", "type": "commit"}, {"oid": "2034cc5cf8e0ea52fe900728dd9d7f74389d5f6f", "url": "https://github.com/elastic/apm-agent-java/commit/2034cc5cf8e0ea52fe900728dd9d7f74389d5f6f", "message": "Update async-profiler\n\ngetNativeThreadId() returns the id of the current thread now", "committedDate": "2020-01-09T09:57:08Z", "type": "commit"}, {"oid": "e9c9b6c4edc7803d4ac83439c4d0ff2eecf212a8", "url": "https://github.com/elastic/apm-agent-java/commit/e9c9b6c4edc7803d4ac83439c4d0ff2eecf212a8", "message": "Load async-profiler library based on os and arch", "committedDate": "2020-01-09T13:39:23Z", "type": "commit"}, {"oid": "6136418998ea7fec2310ef1ff81fa527ba26ee60", "url": "https://github.com/elastic/apm-agent-java/commit/6136418998ea7fec2310ef1ff81fa527ba26ee60", "message": "Fix for the edge case when there's a non-shaded profiler in the bootstrap CL\n\nAlso loads the native library in an isolated CL as opposed to the bootstrap CL", "committedDate": "2020-01-09T14:33:43Z", "type": "commit"}, {"oid": "56e84d566039528e10793207b04a2cbf6835eec8", "url": "https://github.com/elastic/apm-agent-java/commit/56e84d566039528e10793207b04a2cbf6835eec8", "message": "Add comments to JfrParser", "committedDate": "2020-01-09T16:36:24Z", "type": "commit"}, {"oid": "444cbdcc41ae63b7cad1fb931a92319c9620e69d", "url": "https://github.com/elastic/apm-agent-java/commit/444cbdcc41ae63b7cad1fb931a92319c9620e69d", "message": "Add Javadocs to SamplingProfiler", "committedDate": "2020-01-10T09:24:03Z", "type": "commit"}, {"oid": "ca1a974b2c09396a9f562b0b28cb432862911da0", "url": "https://github.com/elastic/apm-agent-java/commit/ca1a974b2c09396a9f562b0b28cb432862911da0", "message": "Remove leftover files", "committedDate": "2020-01-10T09:25:13Z", "type": "commit"}, {"oid": "6fb0ef6c2498100707b79eca983b8fa29e09933b", "url": "https://github.com/elastic/apm-agent-java/commit/6fb0ef6c2498100707b79eca983b8fa29e09933b", "message": "Remove unused agrona collection classes", "committedDate": "2020-01-10T09:28:31Z", "type": "commit"}, {"oid": "8557ac65f481da9c3db6c5b8fced87d8f72ebb1f", "url": "https://github.com/elastic/apm-agent-java/commit/8557ac65f481da9c3db6c5b8fced87d8f72ebb1f", "message": "Give credit where credit is due", "committedDate": "2020-01-10T10:22:48Z", "type": "commit"}, {"oid": "1b71361374b3eb531fdd1a4920c5692c78595f66", "url": "https://github.com/elastic/apm-agent-java/commit/1b71361374b3eb531fdd1a4920c5692c78595f66", "message": "Add Javadoc to CallTree", "committedDate": "2020-01-10T11:07:22Z", "type": "commit"}, {"oid": "17f00e5fb94335664a7cca46d4fb5360463db4b0", "url": "https://github.com/elastic/apm-agent-java/commit/17f00e5fb94335664a7cca46d4fb5360463db4b0", "message": "Add documentation and changelog\n\nalso changes some config option names", "committedDate": "2020-01-10T15:26:28Z", "type": "commit"}, {"oid": "b3d135c5f3c14768613839a57f892019dfef5621", "url": "https://github.com/elastic/apm-agent-java/commit/b3d135c5f3c14768613839a57f892019dfef5621", "message": "Add Linux libasyncProfiler.so", "committedDate": "2020-01-11T11:50:17Z", "type": "commit"}, {"oid": "78b6ff77439185e4fe2b4fab7e1b9b738009f996", "url": "https://github.com/elastic/apm-agent-java/commit/78b6ff77439185e4fe2b4fab7e1b9b738009f996", "message": "Merge remote-tracking branch 'origin/master' into async-profiler", "committedDate": "2020-01-11T11:53:08Z", "type": "commit"}, {"oid": "2f6ead97d589d232651ecae6a1d8172a1fe287ca", "url": "https://github.com/elastic/apm-agent-java/commit/2f6ead97d589d232651ecae6a1d8172a1fe287ca", "message": "Avoid libasyncProfiler.so being loaded twice", "committedDate": "2020-01-11T14:24:35Z", "type": "commit"}, {"oid": "886c4ce259e9765a2e399d30a99e3f03d9981b3d", "url": "https://github.com/elastic/apm-agent-java/commit/886c4ce259e9765a2e399d30a99e3f03d9981b3d", "message": "Improve SamplingProfiler Javadoc", "committedDate": "2020-01-13T14:21:39Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE0NDA0NQ==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366144045", "bodyText": "Leftovers?", "author": "eyalkoren", "createdAt": "2020-01-14T04:03:40Z", "path": "apm-agent-benchmarks/src/main/java/co/elastic/apm/agent/benchmark/AbstractMockApmServerBenchmark.java", "diffHunk": "@@ -85,6 +85,8 @@ public void setUp(Blackhole blackhole) throws IOException {\n                     .add(CoreConfiguration.ACTIVE, Boolean.toString(apmEnabled))\n                     .add(\"api_request_size\", \"10mb\")\n                     .add(\"capture_headers\", \"false\")\n+//                     .add(\"profiling_inferred_spans\", \"true\")\n+//                     .add(\"profiling_interval\", \"10s\")", "originalCommit": "886c4ce259e9765a2e399d30a99e3f03d9981b3d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzMxMzMwNQ==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367313305", "bodyText": "Maybe leave it in so it's easy to do ad-hoc benchmarks with the profiler on. But as it's off by default I wouldn't include it in the actual benchmarking suite.", "author": "felixbarny", "createdAt": "2020-01-16T09:31:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE0NDA0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE0Njc0OQ==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366146749", "bodyText": "Extract, together with getLong, into a util class in the utils package.", "author": "eyalkoren", "createdAt": "2020-01-14T04:21:26Z", "path": "apm-agent-core/src/main/java/co/elastic/apm/agent/impl/transaction/TraceContext.java", "diffHunk": "@@ -439,10 +467,81 @@ public ClassLoader getApplicationClassLoader() {\n         }\n     }\n \n+    public byte[] serialize() {\n+        byte[] result = new byte[SERIALIZED_LENGTH];\n+        serialize(result);\n+        return result;\n+    }\n+\n+    public void serialize(byte[] buffer) {\n+        int offset = 0;\n+        offset = traceId.toBytes(buffer, offset);\n+        offset = id.toBytes(buffer, offset);\n+        offset = transactionId.toBytes(buffer, offset);\n+        buffer[offset++] = flags;\n+        buffer[offset++] = (byte) (discard ? 1 : 0);\n+        putLong(buffer, offset, clock.getOffset());\n+    }\n+\n+    private void asChildOf(byte[] buffer, @Nullable String serviceName) {\n+        int offset = 0;\n+        offset = traceId.fromBytes(buffer, offset);\n+        offset = parentId.fromBytes(buffer, offset);\n+        offset = transactionId.fromBytes(buffer, offset);\n+        id.setToRandomValue();\n+        flags = buffer[offset++];\n+        discard = buffer[offset++] == (byte) 1;\n+        clock.init(getLong(buffer, offset));\n+        this.serviceName = serviceName;\n+        onMutation();\n+    }\n+\n+    public void deserialize(byte[] buffer, @Nullable String serviceName) {\n+        int offset = 0;\n+        offset = traceId.fromBytes(buffer, offset);\n+        offset = id.fromBytes(buffer, offset);\n+        offset = transactionId.fromBytes(buffer, offset);\n+        flags = buffer[offset++];\n+        discard = buffer[offset++] == (byte) 1;\n+        clock.init(getLong(buffer, offset));\n+        this.serviceName = serviceName;\n+        onMutation();\n+    }\n+\n+    public boolean traceIdAndIdEquals(byte[] serialized) {\n+        return id.dataEquals(serialized, traceId.getLength()) && traceId.dataEquals(serialized, 0);\n+    }\n+\n+    private static void putLong(byte[] buffer, int offset, long l) {", "originalCommit": "886c4ce259e9765a2e399d30a99e3f03d9981b3d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE0NzAyOA==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366147028", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                private long getLong(byte[] buffer, int offset) {\n          \n          \n            \n                private static long getLong(byte[] buffer, int offset) {", "author": "eyalkoren", "createdAt": "2020-01-14T04:23:06Z", "path": "apm-agent-core/src/main/java/co/elastic/apm/agent/impl/transaction/TraceContext.java", "diffHunk": "@@ -439,10 +467,81 @@ public ClassLoader getApplicationClassLoader() {\n         }\n     }\n \n+    public byte[] serialize() {\n+        byte[] result = new byte[SERIALIZED_LENGTH];\n+        serialize(result);\n+        return result;\n+    }\n+\n+    public void serialize(byte[] buffer) {\n+        int offset = 0;\n+        offset = traceId.toBytes(buffer, offset);\n+        offset = id.toBytes(buffer, offset);\n+        offset = transactionId.toBytes(buffer, offset);\n+        buffer[offset++] = flags;\n+        buffer[offset++] = (byte) (discard ? 1 : 0);\n+        putLong(buffer, offset, clock.getOffset());\n+    }\n+\n+    private void asChildOf(byte[] buffer, @Nullable String serviceName) {\n+        int offset = 0;\n+        offset = traceId.fromBytes(buffer, offset);\n+        offset = parentId.fromBytes(buffer, offset);\n+        offset = transactionId.fromBytes(buffer, offset);\n+        id.setToRandomValue();\n+        flags = buffer[offset++];\n+        discard = buffer[offset++] == (byte) 1;\n+        clock.init(getLong(buffer, offset));\n+        this.serviceName = serviceName;\n+        onMutation();\n+    }\n+\n+    public void deserialize(byte[] buffer, @Nullable String serviceName) {\n+        int offset = 0;\n+        offset = traceId.fromBytes(buffer, offset);\n+        offset = id.fromBytes(buffer, offset);\n+        offset = transactionId.fromBytes(buffer, offset);\n+        flags = buffer[offset++];\n+        discard = buffer[offset++] == (byte) 1;\n+        clock.init(getLong(buffer, offset));\n+        this.serviceName = serviceName;\n+        onMutation();\n+    }\n+\n+    public boolean traceIdAndIdEquals(byte[] serialized) {\n+        return id.dataEquals(serialized, traceId.getLength()) && traceId.dataEquals(serialized, 0);\n+    }\n+\n+    private static void putLong(byte[] buffer, int offset, long l) {\n+        buffer[offset++] = (byte) l;\n+        buffer[offset++] = (byte) (l >> 8);\n+        buffer[offset++] = (byte) (l >> 16);\n+        buffer[offset++] = (byte) (l >> 24);\n+        buffer[offset++] = (byte) (l >> 32);\n+        buffer[offset++] = (byte) (l >> 40);\n+        buffer[offset++] = (byte) (l >> 48);\n+        buffer[offset] = (byte) (l >> 56);\n+    }\n+\n+    private long getLong(byte[] buffer, int offset) {", "originalCommit": "886c4ce259e9765a2e399d30a99e3f03d9981b3d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE0ODU3NQ==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366148575", "bodyText": "Is it actually used?", "author": "eyalkoren", "createdAt": "2020-01-14T04:32:53Z", "path": "apm-agent-core/src/main/java/co/elastic/apm/agent/impl/transaction/TraceContext.java", "diffHunk": "@@ -439,10 +467,81 @@ public ClassLoader getApplicationClassLoader() {\n         }\n     }\n \n+    public byte[] serialize() {\n+        byte[] result = new byte[SERIALIZED_LENGTH];\n+        serialize(result);\n+        return result;\n+    }\n+\n+    public void serialize(byte[] buffer) {\n+        int offset = 0;\n+        offset = traceId.toBytes(buffer, offset);\n+        offset = id.toBytes(buffer, offset);\n+        offset = transactionId.toBytes(buffer, offset);\n+        buffer[offset++] = flags;\n+        buffer[offset++] = (byte) (discard ? 1 : 0);\n+        putLong(buffer, offset, clock.getOffset());\n+    }\n+\n+    private void asChildOf(byte[] buffer, @Nullable String serviceName) {\n+        int offset = 0;\n+        offset = traceId.fromBytes(buffer, offset);\n+        offset = parentId.fromBytes(buffer, offset);\n+        offset = transactionId.fromBytes(buffer, offset);\n+        id.setToRandomValue();\n+        flags = buffer[offset++];\n+        discard = buffer[offset++] == (byte) 1;\n+        clock.init(getLong(buffer, offset));\n+        this.serviceName = serviceName;\n+        onMutation();\n+    }\n+\n+    public void deserialize(byte[] buffer, @Nullable String serviceName) {\n+        int offset = 0;\n+        offset = traceId.fromBytes(buffer, offset);\n+        offset = id.fromBytes(buffer, offset);\n+        offset = transactionId.fromBytes(buffer, offset);\n+        flags = buffer[offset++];\n+        discard = buffer[offset++] == (byte) 1;\n+        clock.init(getLong(buffer, offset));\n+        this.serviceName = serviceName;\n+        onMutation();\n+    }\n+\n+    public boolean traceIdAndIdEquals(byte[] serialized) {\n+        return id.dataEquals(serialized, traceId.getLength()) && traceId.dataEquals(serialized, 0);\n+    }\n+\n+    private static void putLong(byte[] buffer, int offset, long l) {\n+        buffer[offset++] = (byte) l;\n+        buffer[offset++] = (byte) (l >> 8);\n+        buffer[offset++] = (byte) (l >> 16);\n+        buffer[offset++] = (byte) (l >> 24);\n+        buffer[offset++] = (byte) (l >> 32);\n+        buffer[offset++] = (byte) (l >> 40);\n+        buffer[offset++] = (byte) (l >> 48);\n+        buffer[offset] = (byte) (l >> 56);\n+    }\n+\n+    private long getLong(byte[] buffer, int offset) {\n+        return ((long) buffer[offset + 7] << 56)\n+            | ((long) buffer[offset + 6] & 0xff) << 48\n+            | ((long) buffer[offset + 5] & 0xff) << 40\n+            | ((long) buffer[offset + 4] & 0xff) << 32\n+            | ((long) buffer[offset + 3] & 0xff) << 24\n+            | ((long) buffer[offset + 2] & 0xff) << 16\n+            | ((long) buffer[offset + 1] & 0xff) << 8\n+            | ((long) buffer[offset] & 0xff);\n+    }\n+\n     public interface ChildContextCreator<T> {\n         boolean asChildOf(TraceContext child, T parent);\n     }\n \n+    public interface ChildContextCreatorTwoArg<A, B> {", "originalCommit": "886c4ce259e9765a2e399d30a99e3f03d9981b3d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzMyMDA3Mw==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367320073", "bodyText": "You're right, it's totally unused! It's a leftover from experimentation, I went a different route in the end: co.elastic.apm.agent.impl.transaction.TraceContext#deserialize(byte[] buffer, String serviceName).\nThis means I can remove quite some dependant code.", "author": "felixbarny", "createdAt": "2020-01-16T09:45:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE0ODU3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE0OTk0Mg==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366149942", "bodyText": "I think it would make more sense to return the length of read bytes, rather than the end position of the reading action (which represent a state of the reader), but not something I would insist. In any case- javadoc would be nice here.", "author": "eyalkoren", "createdAt": "2020-01-14T04:39:39Z", "path": "apm-agent-core/src/main/java/co/elastic/apm/agent/impl/transaction/Id.java", "diffHunk": "@@ -70,13 +70,15 @@ public void fromHexString(String hexEncodedString, int offset) {\n         onMutation();\n     }\n \n-    public void fromBytes(byte[] bytes, int offset) {\n+    public int fromBytes(byte[] bytes, int offset) {", "originalCommit": "886c4ce259e9765a2e399d30a99e3f03d9981b3d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE1NjY4Ng==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366156686", "bodyText": "Would ClassFileLocator.ForClassLoader.ofSystemLoader() locate bootstrap classes? Wouldn't .redefine(DirectNativeBinding.class) (which is equivalent to using the locator ClassFileLocator.ForClassLoader.of(DirectNativeBinding.class.getClassLoader())) be safer?\nAlso, the redefine method javadoc says:\n\nByte Buddy might be forced to add a method if a redefined class already defines a class initializer.\n\nwhich the redefine class does. I can't see why this would be a problem, just worth mentioning in case you can.", "author": "eyalkoren", "createdAt": "2020-01-14T05:20:43Z", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/AsyncProfiler.java", "diffHunk": "@@ -0,0 +1,271 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+/*\n+ * Copyright 2018 Andrei Pangin\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.util.IOUtils;\n+import net.bytebuddy.ByteBuddy;\n+import net.bytebuddy.dynamic.ClassFileLocator;\n+import net.bytebuddy.dynamic.loading.ClassLoadingStrategy;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+\n+/**\n+ * Java API for in-process profiling. Serves as a wrapper around\n+ * async-profiler native library. This class is a singleton.\n+ * The first call to {@link #getInstance()} initiates loading of\n+ * libasyncProfiler.so.\n+ * <p>\n+ * This is based on https://github.com/jvm-profiling-tools/async-profiler/blob/master/src/java/one/profiler/AsyncProfiler.java,\n+ * under Apache License 2.0.\n+ * It is modified to allow it to be shaded into the {@code co.elastic.apm} namespace\n+ * </p>\n+ */\n+public abstract class AsyncProfiler {\n+\n+    @Nullable\n+    private static AsyncProfiler instance;\n+\n+    private final String version;\n+\n+    public AsyncProfiler() {\n+        this.version = version0();\n+    }\n+\n+    public static synchronized AsyncProfiler getInstance() {\n+        if (instance != null) {\n+            return instance;\n+        }\n+        instance = newInstance();\n+        return instance;\n+    }\n+\n+    /*\n+     * Allows AsyncProfiler to be shaded. JNI mapping works for a specific package so shading normally doesn't work.\n+     */\n+    private static AsyncProfiler newInstance() {\n+        try {\n+            return new ByteBuddy()\n+                .redefine(DirectNativeBinding.class, ClassFileLocator.ForClassLoader.ofSystemLoader())", "originalCommit": "886c4ce259e9765a2e399d30a99e3f03d9981b3d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQyNzQyNw==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367427427", "bodyText": "Would ClassFileLocator.ForClassLoader.ofSystemLoader() locate bootstrap classes?\n\nWe don't need to as attaching an Java agent always adds the classes to the system class loader.\nClassFileLocator.ForClassLoader.ofBootLoader() can't resolve resources added via Instrumentation.appendToBootstrapClassLoaderSearch. See https://stackoverflow.com/questions/51347432/why-cant-i-load-resources-which-are-appended-to-the-bootstrap-class-loader-sear", "author": "felixbarny", "createdAt": "2020-01-16T13:52:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE1NjY4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE1NjgxMg==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366156812", "bodyText": "\ud83d\ude2e", "author": "eyalkoren", "createdAt": "2020-01-14T05:21:27Z", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/AsyncProfiler.java", "diffHunk": "@@ -0,0 +1,271 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+/*\n+ * Copyright 2018 Andrei Pangin\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.util.IOUtils;\n+import net.bytebuddy.ByteBuddy;\n+import net.bytebuddy.dynamic.ClassFileLocator;\n+import net.bytebuddy.dynamic.loading.ClassLoadingStrategy;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+\n+/**\n+ * Java API for in-process profiling. Serves as a wrapper around\n+ * async-profiler native library. This class is a singleton.\n+ * The first call to {@link #getInstance()} initiates loading of\n+ * libasyncProfiler.so.\n+ * <p>\n+ * This is based on https://github.com/jvm-profiling-tools/async-profiler/blob/master/src/java/one/profiler/AsyncProfiler.java,\n+ * under Apache License 2.0.\n+ * It is modified to allow it to be shaded into the {@code co.elastic.apm} namespace\n+ * </p>\n+ */", "originalCommit": "886c4ce259e9765a2e399d30a99e3f03d9981b3d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjIyOTU3Mg==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366229572", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    if (major != 0 && minor != 9) {\n          \n          \n            \n                    if (major != 0 || minor != 9) {", "author": "eyalkoren", "createdAt": "2020-01-14T09:27:58Z", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/JfrParser.java", "diffHunk": "@@ -0,0 +1,518 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+import co.elastic.apm.agent.profiler.collections.Int2IntHashMap;\n+import co.elastic.apm.agent.profiler.collections.Int2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+/**\n+ * Parses the binary JFR file created by async-profiler.\n+ * May not work with JFR files created by an actual flight recorder.\n+ * <p>\n+ * The implementation is tuned with to minimize allocations when parsing a JFR file.\n+ * Most data structures can be reused by first {@linkplain #resetState() resetting the state} and then {@linkplain #parse(File, List, List) parsing}\n+ * another file.\n+ * </p>\n+ * <p>\n+ * The JFR file itself is mapped into memory via a {@link MappedByteBuffer}.\n+ * This does not consume heap memory, the operating system loads pages the file into memory as they are requested.\n+ * Unfortunately, unmapping a {@link MappedByteBuffer} can only be done by letting it be garbage collected.\n+ * </p>\n+ */\n+public class JfrParser implements Recyclable {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(JfrParser.class);\n+\n+    private static final byte[] MAGIC_BYTES = new byte[]{'F', 'L', 'R', '\\0'};\n+    private static final Set<String> JAVA_FRAME_TYPES = new HashSet<>(Arrays.asList(\"Interpreted\", \"JIT compiled\", \"Inlined\"));\n+\n+    @Nullable\n+    private MappedByteBuffer buffer;\n+    private int eventsOffset;\n+    private int metadataOffset;\n+    @Nullable\n+    private boolean[] isJavaFrameType;\n+    private final Int2IntHashMap classIdToClassNameSymbolId = new Int2IntHashMap(-1);\n+    private final Int2ObjectHashMap<Symbol> symbols = new Int2ObjectHashMap<>();\n+    private final Int2IntHashMap stackTraceIdToFilePositions = new Int2IntHashMap(-1);\n+    private final Long2ObjectHashMap<LazyStackFrame> framesByFrameId = new Long2ObjectHashMap<>();\n+    // used to resolve a symbol with minimal allocations\n+    private final StringBuilder symbolBuilder = new StringBuilder();\n+    @Nullable\n+    private List<WildcardMatcher> excludedClasses;\n+    @Nullable\n+    private List<WildcardMatcher> includedClasses;\n+\n+    /**\n+     * Initializes the parser to make it ready for {@link #getStackTrace(long, boolean, List)} to be called.\n+     *\n+     * @param file            the JFR file to parse\n+     * @param excludedClasses Class names to exclude in stack traces (has an effect on {@link #getStackTrace(long, boolean, List)})\n+     * @param includedClasses Class names to include in stack traces (has an effect on {@link #getStackTrace(long, boolean, List)})\n+     * @throws IOException if some I/O error occurs\n+     */\n+    public void parse(File file, List<WildcardMatcher> excludedClasses, List<WildcardMatcher> includedClasses) throws IOException {\n+        this.excludedClasses = excludedClasses;\n+        this.includedClasses = includedClasses;\n+        try (RandomAccessFile raf = new RandomAccessFile(file, \"r\")) {\n+            FileChannel channel = raf.getChannel();\n+            logger.info(\"Parsing {} ({} bytes)\", file, channel.size());\n+            if (channel.size() > Integer.MAX_VALUE) {\n+                // mapping a file into memory is only possible for chunks of the file which fall into the Integer range (2GB)\n+                // that is because MappedByteBuffers are ByteBuffers which only accept ints in position(int pos)\n+                throw new IllegalArgumentException(\"Input file too large\");\n+            }\n+            this.buffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, channel.size());\n+        }\n+        for (byte magicByte : MAGIC_BYTES) {\n+            if (buffer.get() != magicByte) {\n+                throw new IllegalArgumentException(\"Not a JFR file\");\n+            }\n+        }\n+        short major = buffer.getShort();\n+        short minor = buffer.getShort();\n+        if (major != 0 && minor != 9) {", "originalCommit": "886c4ce259e9765a2e399d30a99e3f03d9981b3d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjI1MjI3Ng==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366252276", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        logger.info(startMessage);\n          \n          \n            \n                        logger.debug(startMessage);", "author": "eyalkoren", "createdAt": "2020-01-14T10:13:27Z", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.configuration.converter.TimeDuration;\n+import co.elastic.apm.agent.context.LifecycleListener;\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.impl.transaction.TraceContextHolder;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Allocator;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.impl.ListBasedObjectPool;\n+import co.elastic.apm.agent.profiler.asyncprofiler.AsyncProfiler;\n+import co.elastic.apm.agent.profiler.asyncprofiler.JfrParser;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.LongHashSet;\n+import co.elastic.apm.agent.util.ExecutorUtils;\n+import com.lmax.disruptor.EventFactory;\n+import com.lmax.disruptor.EventPoller;\n+import com.lmax.disruptor.EventTranslatorTwoArg;\n+import com.lmax.disruptor.RingBuffer;\n+import com.lmax.disruptor.Sequence;\n+import com.lmax.disruptor.SequenceBarrier;\n+import com.lmax.disruptor.WaitStrategy;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.LockSupport;\n+\n+/**\n+ * Correlates {@link ActivationEvent}s with {@link StackFrame}s which are recorded by {@link AsyncProfiler},\n+ * a native <a href=\"http://psy-lob-saw.blogspot.com/2016/06/the-pros-and-cons-of-agct.html\">{@code AsyncGetCallTree}</a>-based\n+ * (and therefore <a href=\"http://psy-lob-saw.blogspot.com/2016/02/why-most-sampling-java-profilers-are.html\"> non safepoint-biased</a>)\n+ * JVMTI agent.\n+ * <p>\n+ * Recording of {@link ActivationEvent}s:\n+ * </p>\n+ * <p>\n+ * The {@link #onActivation} and {@link #onDeactivation} methods are called by {@link ProfilingActivationListener}\n+ * which register an {@link ActivationEvent} in to a {@linkplain #eventBuffer ring buffer} whenever a {@link Span}\n+ * gets {@link Span#activate()}d or {@link Span#deactivate()}d while a {@linkplain #profilingSessionOngoing profiling session is ongoing}.\n+ * A background thread consumes the {@link ActivationEvent}s and writes them to a {@linkplain #activationEventBuffer memory-mapped file}.\n+ * That is necessary because within a profiling session (which lasts 10s by default) there may be many more {@link ActivationEvent}s\n+ * than the ring buffer can hold {@link #RING_BUFFER_SIZE}.\n+ * The file can hold {@link #ACTIVATION_EVENTS_IN_FILE} events and each is {@link ActivationEvent#SERIALIZED_SIZE} in size.\n+ * This process is completely garbage free thanks to the {@link RingBuffer} acting as an object pool for {@link ActivationEvent}s.\n+ * </p>\n+ * <p>\n+ * Recording stack traces:\n+ * </p>\n+ * <p>\n+ * The same background thread that processes the {@link ActivationEvent}s starts the wall clock profiler of async-profiler via\n+ * {@link AsyncProfiler#execute(String)}.\n+ * After the {@link ProfilingConfiguration#getProfilingDuration()} is over it stops the profiling and starts processing the JFR file created\n+ * by async-profiler with {@link JfrParser}.\n+ * </p>\n+ * <p>\n+ * Correlating {@link ActivationEvent}s with the traces recorded by {@link AsyncProfiler}:\n+ * </p>\n+ * <p>\n+ * After both the JFR file and the memory-mapped file containing the {@link ActivationEvent}s have been written,\n+ * it's now time to process them in tandem by correlating based on thread ids and timestamps.\n+ * The result of this correlation, performed by {@link #processTraces(File)},\n+ * are {@link CallTree}s which are created for each thread which has seen an {@linkplain Span#activate() activation}\n+ * and at least one stack trace.\n+ * Once {@linkplain ActivationEvent#handleDeactivationEvent(SamplingProfiler) handling the deactivation event} of the root span in a thread\n+ * (after which {@link ElasticApmTracer#getActive()} would return {@code null}),\n+ * the {@link CallTree} is {@linkplain CallTree#spanify(CallTree.Root, TraceContext) converted into regular spans}.\n+ * </p>\n+ * <p>\n+ * Overall, the allocation rate does not depend on the number of {@link ActivationEvent}s but only on\n+ * {@link ProfilingConfiguration#getProfilingInterval()} and {@link ProfilingConfiguration#getSamplingInterval()}.\n+ * Having said that, there are some optimizations so that the JFR file is not processed at all if there have not been any\n+ * {@link ActivationEvent} in a given profiling session.\n+ * Also, only if there's a {@link CallTree.Root} for a {@link StackTraceEvent},\n+ * we will {@link JfrParser#getStackTrace(long, boolean, List) resolve the full stack trace}.\n+ * </p>\n+ */\n+public class SamplingProfiler implements Runnable, LifecycleListener {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(SamplingProfiler.class);\n+    private static final int ACTIVATION_EVENTS_IN_FILE = 100_000;\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> ACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder<?> active, TraceContextHolder<?> previouslyActive) {\n+                event.activation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> DEACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder active, TraceContextHolder previouslyActive) {\n+                event.deactivation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    // sizeof(ActivationEvent) is 176B so the ring buffer should be around 880KiB\n+    static final int RING_BUFFER_SIZE = 4 * 1024;\n+\n+    private final ProfilingConfiguration config;\n+    private final ScheduledExecutorService scheduler;\n+    private final Long2ObjectHashMap<CallTree.Root> profiledThreads = new Long2ObjectHashMap<>();\n+    private final RingBuffer<ActivationEvent> eventBuffer;\n+    private volatile boolean profilingSessionOngoing = false;\n+    private final Sequence sequence;\n+    private final ElasticApmTracer tracer;\n+    private final NanoClock nanoClock;\n+    private final ObjectPool<CallTree.Root> rootPool;\n+    private final AsyncProfiler asyncProfiler = AsyncProfiler.getInstance();\n+    private final NativeThreadIdToJavaThreadMapper threadMapper = new NativeThreadIdToJavaThreadMapper();\n+    private final MappedByteBuffer activationEventBuffer;\n+    private final EventPoller<ActivationEvent> poller;\n+    private final File activationEventsFile;\n+    private final File jfrFile;\n+    private final WriteActivationEventToFileHandler writeActivationEventToFileHandler = new WriteActivationEventToFileHandler();\n+    private final JfrParser jfrParser = new JfrParser();\n+    private volatile int profilingSessions;\n+\n+    public SamplingProfiler(ElasticApmTracer tracer, NanoClock nanoClock) throws IOException {\n+        this(tracer,\n+            tracer.getConfig(ProfilingConfiguration.class),\n+            ExecutorUtils.createSingleThreadSchedulingDeamonPool(\"apm-sampling-profiler\"),\n+            nanoClock);\n+    }\n+\n+    SamplingProfiler(final ElasticApmTracer tracer, ProfilingConfiguration config, ScheduledExecutorService scheduler, NanoClock nanoClock) throws IOException {\n+        this.tracer = tracer;\n+        this.config = config;\n+        this.scheduler = scheduler;\n+        this.nanoClock = nanoClock;\n+        this.eventBuffer = createRingBuffer();\n+        this.sequence = new Sequence();\n+        // tells the ring buffer to not override slots which have not been read yet\n+        this.eventBuffer.addGatingSequences(sequence);\n+        this.poller = eventBuffer.newPoller();\n+        // call tree roots are pooled so that fast activations/deactivations with no associated stack traces don't cause allocations\n+        this.rootPool = ListBasedObjectPool.<CallTree.Root>ofRecyclable(new ArrayList<CallTree.Root>(), 512, new Allocator<CallTree.Root>() {\n+            @Override\n+            public CallTree.Root createInstance() {\n+                return new CallTree.Root(tracer);\n+            }\n+        });\n+        jfrFile = File.createTempFile(\"apm-traces-\", \".jfr\");\n+        activationEventsFile = File.createTempFile(\"apm-activation-events-\", \".bin\");\n+        try (RandomAccessFile randomAccessFile = new RandomAccessFile(activationEventsFile, \"rw\")) {\n+            activationEventBuffer = randomAccessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, ACTIVATION_EVENTS_IN_FILE * ActivationEvent.SERIALIZED_SIZE);\n+        }\n+    }\n+\n+    private RingBuffer<ActivationEvent> createRingBuffer() {\n+        return RingBuffer.<ActivationEvent>createMultiProducer(\n+            new EventFactory<ActivationEvent>() {\n+                @Override\n+                public ActivationEvent newInstance() {\n+                    return new ActivationEvent();\n+                }\n+            },\n+            RING_BUFFER_SIZE,\n+            new NoWaitStrategy());\n+    }\n+\n+    /**\n+     * Called whenever a span is activated.\n+     * <p>\n+     * This and {@link #onDeactivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onActivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(ACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    /**\n+     * Called whenever a span is deactivated.\n+     * <p>\n+     * This and {@link #onActivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onDeactivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(DEACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    @Override\n+    public void run() {\n+        profilingSessions++;\n+        if (config.isProfilingDisabled()) {\n+            scheduler.schedule(this, config.getProfilingInterval().getMillis(), TimeUnit.MILLISECONDS);\n+            return;\n+        }\n+\n+        TimeDuration sampleRate = config.getSamplingInterval();\n+        TimeDuration profilingDuration = config.getProfilingDuration();\n+\n+        setProfilingSessionOngoing(true);\n+\n+        logger.debug(\"Start profiling session\");\n+        try {\n+            profile(sampleRate, profilingDuration);\n+        } catch (Exception e) {\n+            logger.error(\"Stopping profiler\", e);\n+            return;\n+        }\n+        logger.debug(\"End profiling session\");\n+\n+        boolean interrupted = Thread.currentThread().isInterrupted();\n+        boolean continueProfilingSession = config.isNonStopProfiling() && !interrupted && config.isProfilingEnabled();\n+        setProfilingSessionOngoing(continueProfilingSession);\n+\n+        if (!interrupted) {\n+            long delay = config.getProfilingInterval().getMillis() - profilingDuration.getMillis();\n+            scheduler.schedule(this, delay, TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private void profile(TimeDuration sampleRate, TimeDuration profilingDuration) throws Exception {\n+        try {\n+            String startMessage = asyncProfiler.execute(\"start,jfr,event=wall,interval=\" + sampleRate.getMillis() + \"ms,alluser,file=\" + jfrFile);\n+            logger.info(startMessage);", "originalCommit": "886c4ce259e9765a2e399d30a99e3f03d9981b3d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjI1MjM3NQ==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366252375", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        logger.info(stopMessage);\n          \n          \n            \n                        logger.debug(stopMessage);", "author": "eyalkoren", "createdAt": "2020-01-14T10:13:38Z", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.configuration.converter.TimeDuration;\n+import co.elastic.apm.agent.context.LifecycleListener;\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.impl.transaction.TraceContextHolder;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Allocator;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.impl.ListBasedObjectPool;\n+import co.elastic.apm.agent.profiler.asyncprofiler.AsyncProfiler;\n+import co.elastic.apm.agent.profiler.asyncprofiler.JfrParser;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.LongHashSet;\n+import co.elastic.apm.agent.util.ExecutorUtils;\n+import com.lmax.disruptor.EventFactory;\n+import com.lmax.disruptor.EventPoller;\n+import com.lmax.disruptor.EventTranslatorTwoArg;\n+import com.lmax.disruptor.RingBuffer;\n+import com.lmax.disruptor.Sequence;\n+import com.lmax.disruptor.SequenceBarrier;\n+import com.lmax.disruptor.WaitStrategy;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.LockSupport;\n+\n+/**\n+ * Correlates {@link ActivationEvent}s with {@link StackFrame}s which are recorded by {@link AsyncProfiler},\n+ * a native <a href=\"http://psy-lob-saw.blogspot.com/2016/06/the-pros-and-cons-of-agct.html\">{@code AsyncGetCallTree}</a>-based\n+ * (and therefore <a href=\"http://psy-lob-saw.blogspot.com/2016/02/why-most-sampling-java-profilers-are.html\"> non safepoint-biased</a>)\n+ * JVMTI agent.\n+ * <p>\n+ * Recording of {@link ActivationEvent}s:\n+ * </p>\n+ * <p>\n+ * The {@link #onActivation} and {@link #onDeactivation} methods are called by {@link ProfilingActivationListener}\n+ * which register an {@link ActivationEvent} in to a {@linkplain #eventBuffer ring buffer} whenever a {@link Span}\n+ * gets {@link Span#activate()}d or {@link Span#deactivate()}d while a {@linkplain #profilingSessionOngoing profiling session is ongoing}.\n+ * A background thread consumes the {@link ActivationEvent}s and writes them to a {@linkplain #activationEventBuffer memory-mapped file}.\n+ * That is necessary because within a profiling session (which lasts 10s by default) there may be many more {@link ActivationEvent}s\n+ * than the ring buffer can hold {@link #RING_BUFFER_SIZE}.\n+ * The file can hold {@link #ACTIVATION_EVENTS_IN_FILE} events and each is {@link ActivationEvent#SERIALIZED_SIZE} in size.\n+ * This process is completely garbage free thanks to the {@link RingBuffer} acting as an object pool for {@link ActivationEvent}s.\n+ * </p>\n+ * <p>\n+ * Recording stack traces:\n+ * </p>\n+ * <p>\n+ * The same background thread that processes the {@link ActivationEvent}s starts the wall clock profiler of async-profiler via\n+ * {@link AsyncProfiler#execute(String)}.\n+ * After the {@link ProfilingConfiguration#getProfilingDuration()} is over it stops the profiling and starts processing the JFR file created\n+ * by async-profiler with {@link JfrParser}.\n+ * </p>\n+ * <p>\n+ * Correlating {@link ActivationEvent}s with the traces recorded by {@link AsyncProfiler}:\n+ * </p>\n+ * <p>\n+ * After both the JFR file and the memory-mapped file containing the {@link ActivationEvent}s have been written,\n+ * it's now time to process them in tandem by correlating based on thread ids and timestamps.\n+ * The result of this correlation, performed by {@link #processTraces(File)},\n+ * are {@link CallTree}s which are created for each thread which has seen an {@linkplain Span#activate() activation}\n+ * and at least one stack trace.\n+ * Once {@linkplain ActivationEvent#handleDeactivationEvent(SamplingProfiler) handling the deactivation event} of the root span in a thread\n+ * (after which {@link ElasticApmTracer#getActive()} would return {@code null}),\n+ * the {@link CallTree} is {@linkplain CallTree#spanify(CallTree.Root, TraceContext) converted into regular spans}.\n+ * </p>\n+ * <p>\n+ * Overall, the allocation rate does not depend on the number of {@link ActivationEvent}s but only on\n+ * {@link ProfilingConfiguration#getProfilingInterval()} and {@link ProfilingConfiguration#getSamplingInterval()}.\n+ * Having said that, there are some optimizations so that the JFR file is not processed at all if there have not been any\n+ * {@link ActivationEvent} in a given profiling session.\n+ * Also, only if there's a {@link CallTree.Root} for a {@link StackTraceEvent},\n+ * we will {@link JfrParser#getStackTrace(long, boolean, List) resolve the full stack trace}.\n+ * </p>\n+ */\n+public class SamplingProfiler implements Runnable, LifecycleListener {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(SamplingProfiler.class);\n+    private static final int ACTIVATION_EVENTS_IN_FILE = 100_000;\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> ACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder<?> active, TraceContextHolder<?> previouslyActive) {\n+                event.activation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> DEACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder active, TraceContextHolder previouslyActive) {\n+                event.deactivation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    // sizeof(ActivationEvent) is 176B so the ring buffer should be around 880KiB\n+    static final int RING_BUFFER_SIZE = 4 * 1024;\n+\n+    private final ProfilingConfiguration config;\n+    private final ScheduledExecutorService scheduler;\n+    private final Long2ObjectHashMap<CallTree.Root> profiledThreads = new Long2ObjectHashMap<>();\n+    private final RingBuffer<ActivationEvent> eventBuffer;\n+    private volatile boolean profilingSessionOngoing = false;\n+    private final Sequence sequence;\n+    private final ElasticApmTracer tracer;\n+    private final NanoClock nanoClock;\n+    private final ObjectPool<CallTree.Root> rootPool;\n+    private final AsyncProfiler asyncProfiler = AsyncProfiler.getInstance();\n+    private final NativeThreadIdToJavaThreadMapper threadMapper = new NativeThreadIdToJavaThreadMapper();\n+    private final MappedByteBuffer activationEventBuffer;\n+    private final EventPoller<ActivationEvent> poller;\n+    private final File activationEventsFile;\n+    private final File jfrFile;\n+    private final WriteActivationEventToFileHandler writeActivationEventToFileHandler = new WriteActivationEventToFileHandler();\n+    private final JfrParser jfrParser = new JfrParser();\n+    private volatile int profilingSessions;\n+\n+    public SamplingProfiler(ElasticApmTracer tracer, NanoClock nanoClock) throws IOException {\n+        this(tracer,\n+            tracer.getConfig(ProfilingConfiguration.class),\n+            ExecutorUtils.createSingleThreadSchedulingDeamonPool(\"apm-sampling-profiler\"),\n+            nanoClock);\n+    }\n+\n+    SamplingProfiler(final ElasticApmTracer tracer, ProfilingConfiguration config, ScheduledExecutorService scheduler, NanoClock nanoClock) throws IOException {\n+        this.tracer = tracer;\n+        this.config = config;\n+        this.scheduler = scheduler;\n+        this.nanoClock = nanoClock;\n+        this.eventBuffer = createRingBuffer();\n+        this.sequence = new Sequence();\n+        // tells the ring buffer to not override slots which have not been read yet\n+        this.eventBuffer.addGatingSequences(sequence);\n+        this.poller = eventBuffer.newPoller();\n+        // call tree roots are pooled so that fast activations/deactivations with no associated stack traces don't cause allocations\n+        this.rootPool = ListBasedObjectPool.<CallTree.Root>ofRecyclable(new ArrayList<CallTree.Root>(), 512, new Allocator<CallTree.Root>() {\n+            @Override\n+            public CallTree.Root createInstance() {\n+                return new CallTree.Root(tracer);\n+            }\n+        });\n+        jfrFile = File.createTempFile(\"apm-traces-\", \".jfr\");\n+        activationEventsFile = File.createTempFile(\"apm-activation-events-\", \".bin\");\n+        try (RandomAccessFile randomAccessFile = new RandomAccessFile(activationEventsFile, \"rw\")) {\n+            activationEventBuffer = randomAccessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, ACTIVATION_EVENTS_IN_FILE * ActivationEvent.SERIALIZED_SIZE);\n+        }\n+    }\n+\n+    private RingBuffer<ActivationEvent> createRingBuffer() {\n+        return RingBuffer.<ActivationEvent>createMultiProducer(\n+            new EventFactory<ActivationEvent>() {\n+                @Override\n+                public ActivationEvent newInstance() {\n+                    return new ActivationEvent();\n+                }\n+            },\n+            RING_BUFFER_SIZE,\n+            new NoWaitStrategy());\n+    }\n+\n+    /**\n+     * Called whenever a span is activated.\n+     * <p>\n+     * This and {@link #onDeactivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onActivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(ACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    /**\n+     * Called whenever a span is deactivated.\n+     * <p>\n+     * This and {@link #onActivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onDeactivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(DEACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    @Override\n+    public void run() {\n+        profilingSessions++;\n+        if (config.isProfilingDisabled()) {\n+            scheduler.schedule(this, config.getProfilingInterval().getMillis(), TimeUnit.MILLISECONDS);\n+            return;\n+        }\n+\n+        TimeDuration sampleRate = config.getSamplingInterval();\n+        TimeDuration profilingDuration = config.getProfilingDuration();\n+\n+        setProfilingSessionOngoing(true);\n+\n+        logger.debug(\"Start profiling session\");\n+        try {\n+            profile(sampleRate, profilingDuration);\n+        } catch (Exception e) {\n+            logger.error(\"Stopping profiler\", e);\n+            return;\n+        }\n+        logger.debug(\"End profiling session\");\n+\n+        boolean interrupted = Thread.currentThread().isInterrupted();\n+        boolean continueProfilingSession = config.isNonStopProfiling() && !interrupted && config.isProfilingEnabled();\n+        setProfilingSessionOngoing(continueProfilingSession);\n+\n+        if (!interrupted) {\n+            long delay = config.getProfilingInterval().getMillis() - profilingDuration.getMillis();\n+            scheduler.schedule(this, delay, TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private void profile(TimeDuration sampleRate, TimeDuration profilingDuration) throws Exception {\n+        try {\n+            String startMessage = asyncProfiler.execute(\"start,jfr,event=wall,interval=\" + sampleRate.getMillis() + \"ms,alluser,file=\" + jfrFile);\n+            logger.info(startMessage);\n+\n+            consumeActivationEventsFromRingBufferAndWriteToFile(profilingDuration);\n+\n+            String stopMessage = asyncProfiler.execute(\"stop\");\n+            logger.info(stopMessage);", "originalCommit": "886c4ce259e9765a2e399d30a99e3f03d9981b3d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjI1ODA3MQ==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366258071", "bodyText": "Consider adding a single-thread object pool for those", "author": "eyalkoren", "createdAt": "2020-01-14T10:24:46Z", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.configuration.converter.TimeDuration;\n+import co.elastic.apm.agent.context.LifecycleListener;\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.impl.transaction.TraceContextHolder;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Allocator;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.impl.ListBasedObjectPool;\n+import co.elastic.apm.agent.profiler.asyncprofiler.AsyncProfiler;\n+import co.elastic.apm.agent.profiler.asyncprofiler.JfrParser;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.LongHashSet;\n+import co.elastic.apm.agent.util.ExecutorUtils;\n+import com.lmax.disruptor.EventFactory;\n+import com.lmax.disruptor.EventPoller;\n+import com.lmax.disruptor.EventTranslatorTwoArg;\n+import com.lmax.disruptor.RingBuffer;\n+import com.lmax.disruptor.Sequence;\n+import com.lmax.disruptor.SequenceBarrier;\n+import com.lmax.disruptor.WaitStrategy;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.LockSupport;\n+\n+/**\n+ * Correlates {@link ActivationEvent}s with {@link StackFrame}s which are recorded by {@link AsyncProfiler},\n+ * a native <a href=\"http://psy-lob-saw.blogspot.com/2016/06/the-pros-and-cons-of-agct.html\">{@code AsyncGetCallTree}</a>-based\n+ * (and therefore <a href=\"http://psy-lob-saw.blogspot.com/2016/02/why-most-sampling-java-profilers-are.html\"> non safepoint-biased</a>)\n+ * JVMTI agent.\n+ * <p>\n+ * Recording of {@link ActivationEvent}s:\n+ * </p>\n+ * <p>\n+ * The {@link #onActivation} and {@link #onDeactivation} methods are called by {@link ProfilingActivationListener}\n+ * which register an {@link ActivationEvent} in to a {@linkplain #eventBuffer ring buffer} whenever a {@link Span}\n+ * gets {@link Span#activate()}d or {@link Span#deactivate()}d while a {@linkplain #profilingSessionOngoing profiling session is ongoing}.\n+ * A background thread consumes the {@link ActivationEvent}s and writes them to a {@linkplain #activationEventBuffer memory-mapped file}.\n+ * That is necessary because within a profiling session (which lasts 10s by default) there may be many more {@link ActivationEvent}s\n+ * than the ring buffer can hold {@link #RING_BUFFER_SIZE}.\n+ * The file can hold {@link #ACTIVATION_EVENTS_IN_FILE} events and each is {@link ActivationEvent#SERIALIZED_SIZE} in size.\n+ * This process is completely garbage free thanks to the {@link RingBuffer} acting as an object pool for {@link ActivationEvent}s.\n+ * </p>\n+ * <p>\n+ * Recording stack traces:\n+ * </p>\n+ * <p>\n+ * The same background thread that processes the {@link ActivationEvent}s starts the wall clock profiler of async-profiler via\n+ * {@link AsyncProfiler#execute(String)}.\n+ * After the {@link ProfilingConfiguration#getProfilingDuration()} is over it stops the profiling and starts processing the JFR file created\n+ * by async-profiler with {@link JfrParser}.\n+ * </p>\n+ * <p>\n+ * Correlating {@link ActivationEvent}s with the traces recorded by {@link AsyncProfiler}:\n+ * </p>\n+ * <p>\n+ * After both the JFR file and the memory-mapped file containing the {@link ActivationEvent}s have been written,\n+ * it's now time to process them in tandem by correlating based on thread ids and timestamps.\n+ * The result of this correlation, performed by {@link #processTraces(File)},\n+ * are {@link CallTree}s which are created for each thread which has seen an {@linkplain Span#activate() activation}\n+ * and at least one stack trace.\n+ * Once {@linkplain ActivationEvent#handleDeactivationEvent(SamplingProfiler) handling the deactivation event} of the root span in a thread\n+ * (after which {@link ElasticApmTracer#getActive()} would return {@code null}),\n+ * the {@link CallTree} is {@linkplain CallTree#spanify(CallTree.Root, TraceContext) converted into regular spans}.\n+ * </p>\n+ * <p>\n+ * Overall, the allocation rate does not depend on the number of {@link ActivationEvent}s but only on\n+ * {@link ProfilingConfiguration#getProfilingInterval()} and {@link ProfilingConfiguration#getSamplingInterval()}.\n+ * Having said that, there are some optimizations so that the JFR file is not processed at all if there have not been any\n+ * {@link ActivationEvent} in a given profiling session.\n+ * Also, only if there's a {@link CallTree.Root} for a {@link StackTraceEvent},\n+ * we will {@link JfrParser#getStackTrace(long, boolean, List) resolve the full stack trace}.\n+ * </p>\n+ */\n+public class SamplingProfiler implements Runnable, LifecycleListener {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(SamplingProfiler.class);\n+    private static final int ACTIVATION_EVENTS_IN_FILE = 100_000;\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> ACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder<?> active, TraceContextHolder<?> previouslyActive) {\n+                event.activation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> DEACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder active, TraceContextHolder previouslyActive) {\n+                event.deactivation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    // sizeof(ActivationEvent) is 176B so the ring buffer should be around 880KiB\n+    static final int RING_BUFFER_SIZE = 4 * 1024;\n+\n+    private final ProfilingConfiguration config;\n+    private final ScheduledExecutorService scheduler;\n+    private final Long2ObjectHashMap<CallTree.Root> profiledThreads = new Long2ObjectHashMap<>();\n+    private final RingBuffer<ActivationEvent> eventBuffer;\n+    private volatile boolean profilingSessionOngoing = false;\n+    private final Sequence sequence;\n+    private final ElasticApmTracer tracer;\n+    private final NanoClock nanoClock;\n+    private final ObjectPool<CallTree.Root> rootPool;\n+    private final AsyncProfiler asyncProfiler = AsyncProfiler.getInstance();\n+    private final NativeThreadIdToJavaThreadMapper threadMapper = new NativeThreadIdToJavaThreadMapper();\n+    private final MappedByteBuffer activationEventBuffer;\n+    private final EventPoller<ActivationEvent> poller;\n+    private final File activationEventsFile;\n+    private final File jfrFile;\n+    private final WriteActivationEventToFileHandler writeActivationEventToFileHandler = new WriteActivationEventToFileHandler();\n+    private final JfrParser jfrParser = new JfrParser();\n+    private volatile int profilingSessions;\n+\n+    public SamplingProfiler(ElasticApmTracer tracer, NanoClock nanoClock) throws IOException {\n+        this(tracer,\n+            tracer.getConfig(ProfilingConfiguration.class),\n+            ExecutorUtils.createSingleThreadSchedulingDeamonPool(\"apm-sampling-profiler\"),\n+            nanoClock);\n+    }\n+\n+    SamplingProfiler(final ElasticApmTracer tracer, ProfilingConfiguration config, ScheduledExecutorService scheduler, NanoClock nanoClock) throws IOException {\n+        this.tracer = tracer;\n+        this.config = config;\n+        this.scheduler = scheduler;\n+        this.nanoClock = nanoClock;\n+        this.eventBuffer = createRingBuffer();\n+        this.sequence = new Sequence();\n+        // tells the ring buffer to not override slots which have not been read yet\n+        this.eventBuffer.addGatingSequences(sequence);\n+        this.poller = eventBuffer.newPoller();\n+        // call tree roots are pooled so that fast activations/deactivations with no associated stack traces don't cause allocations\n+        this.rootPool = ListBasedObjectPool.<CallTree.Root>ofRecyclable(new ArrayList<CallTree.Root>(), 512, new Allocator<CallTree.Root>() {\n+            @Override\n+            public CallTree.Root createInstance() {\n+                return new CallTree.Root(tracer);\n+            }\n+        });\n+        jfrFile = File.createTempFile(\"apm-traces-\", \".jfr\");\n+        activationEventsFile = File.createTempFile(\"apm-activation-events-\", \".bin\");\n+        try (RandomAccessFile randomAccessFile = new RandomAccessFile(activationEventsFile, \"rw\")) {\n+            activationEventBuffer = randomAccessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, ACTIVATION_EVENTS_IN_FILE * ActivationEvent.SERIALIZED_SIZE);\n+        }\n+    }\n+\n+    private RingBuffer<ActivationEvent> createRingBuffer() {\n+        return RingBuffer.<ActivationEvent>createMultiProducer(\n+            new EventFactory<ActivationEvent>() {\n+                @Override\n+                public ActivationEvent newInstance() {\n+                    return new ActivationEvent();\n+                }\n+            },\n+            RING_BUFFER_SIZE,\n+            new NoWaitStrategy());\n+    }\n+\n+    /**\n+     * Called whenever a span is activated.\n+     * <p>\n+     * This and {@link #onDeactivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onActivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(ACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    /**\n+     * Called whenever a span is deactivated.\n+     * <p>\n+     * This and {@link #onActivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onDeactivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(DEACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    @Override\n+    public void run() {\n+        profilingSessions++;\n+        if (config.isProfilingDisabled()) {\n+            scheduler.schedule(this, config.getProfilingInterval().getMillis(), TimeUnit.MILLISECONDS);\n+            return;\n+        }\n+\n+        TimeDuration sampleRate = config.getSamplingInterval();\n+        TimeDuration profilingDuration = config.getProfilingDuration();\n+\n+        setProfilingSessionOngoing(true);\n+\n+        logger.debug(\"Start profiling session\");\n+        try {\n+            profile(sampleRate, profilingDuration);\n+        } catch (Exception e) {\n+            logger.error(\"Stopping profiler\", e);\n+            return;\n+        }\n+        logger.debug(\"End profiling session\");\n+\n+        boolean interrupted = Thread.currentThread().isInterrupted();\n+        boolean continueProfilingSession = config.isNonStopProfiling() && !interrupted && config.isProfilingEnabled();\n+        setProfilingSessionOngoing(continueProfilingSession);\n+\n+        if (!interrupted) {\n+            long delay = config.getProfilingInterval().getMillis() - profilingDuration.getMillis();\n+            scheduler.schedule(this, delay, TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private void profile(TimeDuration sampleRate, TimeDuration profilingDuration) throws Exception {\n+        try {\n+            String startMessage = asyncProfiler.execute(\"start,jfr,event=wall,interval=\" + sampleRate.getMillis() + \"ms,alluser,file=\" + jfrFile);\n+            logger.info(startMessage);\n+\n+            consumeActivationEventsFromRingBufferAndWriteToFile(profilingDuration);\n+\n+            String stopMessage = asyncProfiler.execute(\"stop\");\n+            logger.info(stopMessage);\n+\n+            processTraces(jfrFile);\n+        } catch (InterruptedException e) {\n+            asyncProfiler.stop();\n+            Thread.currentThread().interrupt();\n+        }\n+    }\n+\n+    private void consumeActivationEventsFromRingBufferAndWriteToFile(TimeDuration profilingDuration) throws Exception {\n+        resetActivationEventBuffer();\n+        long threshold = System.currentTimeMillis() + profilingDuration.getMillis();\n+        long initialSleep = 100_000;\n+        long maxSleep = 10_000_000;\n+        long sleep = initialSleep;\n+        while (System.currentTimeMillis() < threshold) {\n+            if (activationEventBuffer.hasRemaining()) {\n+                EventPoller.PollState poll = consumeActivationEventsFromRingBufferAndWriteToFile();\n+                if (poll == EventPoller.PollState.PROCESSING) {\n+                    sleep = initialSleep;\n+                } else {\n+                    if (sleep < maxSleep) {\n+                        sleep *= 2;\n+                    }\n+                }\n+                LockSupport.parkNanos(sleep);\n+            } else {\n+                // the file is full, sleep the rest of the profilingDuration\n+                Thread.sleep(Math.max(0, threshold - System.currentTimeMillis()));\n+            }\n+        }\n+    }\n+\n+    private void resetActivationEventBuffer() {\n+        ((Buffer) activationEventBuffer).clear();\n+    }\n+\n+    EventPoller.PollState consumeActivationEventsFromRingBufferAndWriteToFile() throws Exception {\n+        return poller.poll(writeActivationEventToFileHandler);\n+    }\n+\n+    private void processTraces(File file) throws IOException {\n+        if (activationEventBuffer.position() == 0) {\n+            logger.debug(\"No activation events during this period. Skip processing stack traces.\");\n+            return;\n+        }\n+        List<WildcardMatcher> excludedClasses = config.getExcludedClasses();\n+        List<WildcardMatcher> includedClasses = config.getIncludedClasses();\n+        try {\n+            jfrParser.parse(file, excludedClasses, includedClasses);\n+            startProcessingActivationEventsFile();\n+            final SortedSet<StackTraceEvent> stackTraceEvents = getStackTraceEvents(jfrParser);\n+            if (logger.isDebugEnabled()) {\n+                logger.debug(\"Processing {} stack traces\", stackTraceEvents.size());\n+            }\n+            List<StackFrame> stackFrames = new ArrayList<>();\n+            ElasticApmTracer tracer = this.tracer;\n+            ActivationEvent event = new ActivationEvent();\n+            for (StackTraceEvent stackTrace : stackTraceEvents) {\n+                processActivationEventsUpTo(stackTrace.nanoTime, event);\n+                CallTree.Root root = profiledThreads.get(stackTrace.threadId);\n+                if (root != null) {\n+                    jfrParser.getStackTrace(stackTrace.stackTraceId, true, stackFrames);\n+                    root.addStackTrace(tracer, stackFrames, stackTrace.nanoTime);\n+                }\n+                stackFrames.clear();\n+            }\n+        } finally {\n+            jfrParser.resetState();\n+        }\n+    }\n+\n+    /**\n+     * Returns stack trace events of relevant threads sorted by timestamp.\n+     * The events in the JFR file are not in order.\n+     * Even for the same thread, a more recent event might come before an older event.\n+     * In order to be able to correlate stack trace events and activation events, both need to be in order.\n+     *\n+     * Returns only events for threads where at least one activation happened\n+     */\n+    private SortedSet<StackTraceEvent> getStackTraceEvents(JfrParser jfrParser) throws IOException {\n+        final LongHashSet nativeThreadIds = threadMapper.getNativeThreadIds();\n+        final SortedSet<StackTraceEvent> stackTraceEvents = new TreeSet<>();\n+        jfrParser.consumeStackTraces(new JfrParser.StackTraceConsumer() {\n+            @Override\n+            public void onCallTree(int threadId, long stackTraceId, long nanoTime) {\n+                if (nativeThreadIds.contains(threadId)) {\n+                    stackTraceEvents.add(new StackTraceEvent(nanoTime, stackTraceId, threadId));", "originalCommit": "886c4ce259e9765a2e399d30a99e3f03d9981b3d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjI1OTc5Ng==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366259796", "bodyText": "Consider adding time measurement of the processing and add a debug log", "author": "eyalkoren", "createdAt": "2020-01-14T10:27:53Z", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.configuration.converter.TimeDuration;\n+import co.elastic.apm.agent.context.LifecycleListener;\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.impl.transaction.TraceContextHolder;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Allocator;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.impl.ListBasedObjectPool;\n+import co.elastic.apm.agent.profiler.asyncprofiler.AsyncProfiler;\n+import co.elastic.apm.agent.profiler.asyncprofiler.JfrParser;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.LongHashSet;\n+import co.elastic.apm.agent.util.ExecutorUtils;\n+import com.lmax.disruptor.EventFactory;\n+import com.lmax.disruptor.EventPoller;\n+import com.lmax.disruptor.EventTranslatorTwoArg;\n+import com.lmax.disruptor.RingBuffer;\n+import com.lmax.disruptor.Sequence;\n+import com.lmax.disruptor.SequenceBarrier;\n+import com.lmax.disruptor.WaitStrategy;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.LockSupport;\n+\n+/**\n+ * Correlates {@link ActivationEvent}s with {@link StackFrame}s which are recorded by {@link AsyncProfiler},\n+ * a native <a href=\"http://psy-lob-saw.blogspot.com/2016/06/the-pros-and-cons-of-agct.html\">{@code AsyncGetCallTree}</a>-based\n+ * (and therefore <a href=\"http://psy-lob-saw.blogspot.com/2016/02/why-most-sampling-java-profilers-are.html\"> non safepoint-biased</a>)\n+ * JVMTI agent.\n+ * <p>\n+ * Recording of {@link ActivationEvent}s:\n+ * </p>\n+ * <p>\n+ * The {@link #onActivation} and {@link #onDeactivation} methods are called by {@link ProfilingActivationListener}\n+ * which register an {@link ActivationEvent} in to a {@linkplain #eventBuffer ring buffer} whenever a {@link Span}\n+ * gets {@link Span#activate()}d or {@link Span#deactivate()}d while a {@linkplain #profilingSessionOngoing profiling session is ongoing}.\n+ * A background thread consumes the {@link ActivationEvent}s and writes them to a {@linkplain #activationEventBuffer memory-mapped file}.\n+ * That is necessary because within a profiling session (which lasts 10s by default) there may be many more {@link ActivationEvent}s\n+ * than the ring buffer can hold {@link #RING_BUFFER_SIZE}.\n+ * The file can hold {@link #ACTIVATION_EVENTS_IN_FILE} events and each is {@link ActivationEvent#SERIALIZED_SIZE} in size.\n+ * This process is completely garbage free thanks to the {@link RingBuffer} acting as an object pool for {@link ActivationEvent}s.\n+ * </p>\n+ * <p>\n+ * Recording stack traces:\n+ * </p>\n+ * <p>\n+ * The same background thread that processes the {@link ActivationEvent}s starts the wall clock profiler of async-profiler via\n+ * {@link AsyncProfiler#execute(String)}.\n+ * After the {@link ProfilingConfiguration#getProfilingDuration()} is over it stops the profiling and starts processing the JFR file created\n+ * by async-profiler with {@link JfrParser}.\n+ * </p>\n+ * <p>\n+ * Correlating {@link ActivationEvent}s with the traces recorded by {@link AsyncProfiler}:\n+ * </p>\n+ * <p>\n+ * After both the JFR file and the memory-mapped file containing the {@link ActivationEvent}s have been written,\n+ * it's now time to process them in tandem by correlating based on thread ids and timestamps.\n+ * The result of this correlation, performed by {@link #processTraces(File)},\n+ * are {@link CallTree}s which are created for each thread which has seen an {@linkplain Span#activate() activation}\n+ * and at least one stack trace.\n+ * Once {@linkplain ActivationEvent#handleDeactivationEvent(SamplingProfiler) handling the deactivation event} of the root span in a thread\n+ * (after which {@link ElasticApmTracer#getActive()} would return {@code null}),\n+ * the {@link CallTree} is {@linkplain CallTree#spanify(CallTree.Root, TraceContext) converted into regular spans}.\n+ * </p>\n+ * <p>\n+ * Overall, the allocation rate does not depend on the number of {@link ActivationEvent}s but only on\n+ * {@link ProfilingConfiguration#getProfilingInterval()} and {@link ProfilingConfiguration#getSamplingInterval()}.\n+ * Having said that, there are some optimizations so that the JFR file is not processed at all if there have not been any\n+ * {@link ActivationEvent} in a given profiling session.\n+ * Also, only if there's a {@link CallTree.Root} for a {@link StackTraceEvent},\n+ * we will {@link JfrParser#getStackTrace(long, boolean, List) resolve the full stack trace}.\n+ * </p>\n+ */\n+public class SamplingProfiler implements Runnable, LifecycleListener {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(SamplingProfiler.class);\n+    private static final int ACTIVATION_EVENTS_IN_FILE = 100_000;\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> ACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder<?> active, TraceContextHolder<?> previouslyActive) {\n+                event.activation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> DEACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder active, TraceContextHolder previouslyActive) {\n+                event.deactivation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    // sizeof(ActivationEvent) is 176B so the ring buffer should be around 880KiB\n+    static final int RING_BUFFER_SIZE = 4 * 1024;\n+\n+    private final ProfilingConfiguration config;\n+    private final ScheduledExecutorService scheduler;\n+    private final Long2ObjectHashMap<CallTree.Root> profiledThreads = new Long2ObjectHashMap<>();\n+    private final RingBuffer<ActivationEvent> eventBuffer;\n+    private volatile boolean profilingSessionOngoing = false;\n+    private final Sequence sequence;\n+    private final ElasticApmTracer tracer;\n+    private final NanoClock nanoClock;\n+    private final ObjectPool<CallTree.Root> rootPool;\n+    private final AsyncProfiler asyncProfiler = AsyncProfiler.getInstance();\n+    private final NativeThreadIdToJavaThreadMapper threadMapper = new NativeThreadIdToJavaThreadMapper();\n+    private final MappedByteBuffer activationEventBuffer;\n+    private final EventPoller<ActivationEvent> poller;\n+    private final File activationEventsFile;\n+    private final File jfrFile;\n+    private final WriteActivationEventToFileHandler writeActivationEventToFileHandler = new WriteActivationEventToFileHandler();\n+    private final JfrParser jfrParser = new JfrParser();\n+    private volatile int profilingSessions;\n+\n+    public SamplingProfiler(ElasticApmTracer tracer, NanoClock nanoClock) throws IOException {\n+        this(tracer,\n+            tracer.getConfig(ProfilingConfiguration.class),\n+            ExecutorUtils.createSingleThreadSchedulingDeamonPool(\"apm-sampling-profiler\"),\n+            nanoClock);\n+    }\n+\n+    SamplingProfiler(final ElasticApmTracer tracer, ProfilingConfiguration config, ScheduledExecutorService scheduler, NanoClock nanoClock) throws IOException {\n+        this.tracer = tracer;\n+        this.config = config;\n+        this.scheduler = scheduler;\n+        this.nanoClock = nanoClock;\n+        this.eventBuffer = createRingBuffer();\n+        this.sequence = new Sequence();\n+        // tells the ring buffer to not override slots which have not been read yet\n+        this.eventBuffer.addGatingSequences(sequence);\n+        this.poller = eventBuffer.newPoller();\n+        // call tree roots are pooled so that fast activations/deactivations with no associated stack traces don't cause allocations\n+        this.rootPool = ListBasedObjectPool.<CallTree.Root>ofRecyclable(new ArrayList<CallTree.Root>(), 512, new Allocator<CallTree.Root>() {\n+            @Override\n+            public CallTree.Root createInstance() {\n+                return new CallTree.Root(tracer);\n+            }\n+        });\n+        jfrFile = File.createTempFile(\"apm-traces-\", \".jfr\");\n+        activationEventsFile = File.createTempFile(\"apm-activation-events-\", \".bin\");\n+        try (RandomAccessFile randomAccessFile = new RandomAccessFile(activationEventsFile, \"rw\")) {\n+            activationEventBuffer = randomAccessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, ACTIVATION_EVENTS_IN_FILE * ActivationEvent.SERIALIZED_SIZE);\n+        }\n+    }\n+\n+    private RingBuffer<ActivationEvent> createRingBuffer() {\n+        return RingBuffer.<ActivationEvent>createMultiProducer(\n+            new EventFactory<ActivationEvent>() {\n+                @Override\n+                public ActivationEvent newInstance() {\n+                    return new ActivationEvent();\n+                }\n+            },\n+            RING_BUFFER_SIZE,\n+            new NoWaitStrategy());\n+    }\n+\n+    /**\n+     * Called whenever a span is activated.\n+     * <p>\n+     * This and {@link #onDeactivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onActivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(ACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    /**\n+     * Called whenever a span is deactivated.\n+     * <p>\n+     * This and {@link #onActivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onDeactivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(DEACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    @Override\n+    public void run() {\n+        profilingSessions++;\n+        if (config.isProfilingDisabled()) {\n+            scheduler.schedule(this, config.getProfilingInterval().getMillis(), TimeUnit.MILLISECONDS);\n+            return;\n+        }\n+\n+        TimeDuration sampleRate = config.getSamplingInterval();\n+        TimeDuration profilingDuration = config.getProfilingDuration();\n+\n+        setProfilingSessionOngoing(true);\n+\n+        logger.debug(\"Start profiling session\");\n+        try {\n+            profile(sampleRate, profilingDuration);\n+        } catch (Exception e) {\n+            logger.error(\"Stopping profiler\", e);\n+            return;\n+        }\n+        logger.debug(\"End profiling session\");\n+\n+        boolean interrupted = Thread.currentThread().isInterrupted();\n+        boolean continueProfilingSession = config.isNonStopProfiling() && !interrupted && config.isProfilingEnabled();\n+        setProfilingSessionOngoing(continueProfilingSession);\n+\n+        if (!interrupted) {\n+            long delay = config.getProfilingInterval().getMillis() - profilingDuration.getMillis();\n+            scheduler.schedule(this, delay, TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private void profile(TimeDuration sampleRate, TimeDuration profilingDuration) throws Exception {\n+        try {\n+            String startMessage = asyncProfiler.execute(\"start,jfr,event=wall,interval=\" + sampleRate.getMillis() + \"ms,alluser,file=\" + jfrFile);\n+            logger.info(startMessage);\n+\n+            consumeActivationEventsFromRingBufferAndWriteToFile(profilingDuration);\n+\n+            String stopMessage = asyncProfiler.execute(\"stop\");\n+            logger.info(stopMessage);\n+\n+            processTraces(jfrFile);\n+        } catch (InterruptedException e) {\n+            asyncProfiler.stop();\n+            Thread.currentThread().interrupt();\n+        }\n+    }\n+\n+    private void consumeActivationEventsFromRingBufferAndWriteToFile(TimeDuration profilingDuration) throws Exception {\n+        resetActivationEventBuffer();\n+        long threshold = System.currentTimeMillis() + profilingDuration.getMillis();\n+        long initialSleep = 100_000;\n+        long maxSleep = 10_000_000;\n+        long sleep = initialSleep;\n+        while (System.currentTimeMillis() < threshold) {\n+            if (activationEventBuffer.hasRemaining()) {\n+                EventPoller.PollState poll = consumeActivationEventsFromRingBufferAndWriteToFile();\n+                if (poll == EventPoller.PollState.PROCESSING) {\n+                    sleep = initialSleep;\n+                } else {\n+                    if (sleep < maxSleep) {\n+                        sleep *= 2;\n+                    }\n+                }\n+                LockSupport.parkNanos(sleep);\n+            } else {\n+                // the file is full, sleep the rest of the profilingDuration\n+                Thread.sleep(Math.max(0, threshold - System.currentTimeMillis()));\n+            }\n+        }\n+    }\n+\n+    private void resetActivationEventBuffer() {\n+        ((Buffer) activationEventBuffer).clear();\n+    }\n+\n+    EventPoller.PollState consumeActivationEventsFromRingBufferAndWriteToFile() throws Exception {\n+        return poller.poll(writeActivationEventToFileHandler);\n+    }\n+\n+    private void processTraces(File file) throws IOException {", "originalCommit": "886c4ce259e9765a2e399d30a99e3f03d9981b3d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQyMzgwNw==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367423807", "bodyText": "What I was also thinking about is that we could create transactions and spans for this process - using the agent to monitor itself.", "author": "felixbarny", "createdAt": "2020-01-16T13:44:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjI1OTc5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQ0NjUwMA==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367446500", "bodyText": "And send to the same APM server?", "author": "eyalkoren", "createdAt": "2020-01-16T14:27:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjI1OTc5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQ2MTgyMA==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367461820", "bodyText": "Yes, with a special transaction.type. But that's not for this PR", "author": "felixbarny", "createdAt": "2020-01-16T14:53:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjI1OTc5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQ3MTA0OQ==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367471049", "bodyText": "Not sure about that...\nApart from additional overhead and possible tracing data loss (eg full buffer), it's storage user pays for.\nAnyway, may be an interesting debug info/stats to have.", "author": "eyalkoren", "createdAt": "2020-01-16T15:09:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjI1OTc5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjMxMjA4Nw==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366312087", "bodyText": "I think this calls for Symbol's polymorphism - either a MethodSymbol and a ClassSymbol implementing a Symbol or a Symbol class and a ClassSymbol subclass.", "author": "eyalkoren", "createdAt": "2020-01-14T12:32:39Z", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/JfrParser.java", "diffHunk": "@@ -0,0 +1,518 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+import co.elastic.apm.agent.profiler.collections.Int2IntHashMap;\n+import co.elastic.apm.agent.profiler.collections.Int2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+/**\n+ * Parses the binary JFR file created by async-profiler.\n+ * May not work with JFR files created by an actual flight recorder.\n+ * <p>\n+ * The implementation is tuned with to minimize allocations when parsing a JFR file.\n+ * Most data structures can be reused by first {@linkplain #resetState() resetting the state} and then {@linkplain #parse(File, List, List) parsing}\n+ * another file.\n+ * </p>\n+ * <p>\n+ * The JFR file itself is mapped into memory via a {@link MappedByteBuffer}.\n+ * This does not consume heap memory, the operating system loads pages the file into memory as they are requested.\n+ * Unfortunately, unmapping a {@link MappedByteBuffer} can only be done by letting it be garbage collected.\n+ * </p>\n+ */\n+public class JfrParser implements Recyclable {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(JfrParser.class);\n+\n+    private static final byte[] MAGIC_BYTES = new byte[]{'F', 'L', 'R', '\\0'};\n+    private static final Set<String> JAVA_FRAME_TYPES = new HashSet<>(Arrays.asList(\"Interpreted\", \"JIT compiled\", \"Inlined\"));\n+\n+    @Nullable\n+    private MappedByteBuffer buffer;\n+    private int eventsOffset;\n+    private int metadataOffset;\n+    @Nullable\n+    private boolean[] isJavaFrameType;\n+    private final Int2IntHashMap classIdToClassNameSymbolId = new Int2IntHashMap(-1);\n+    private final Int2ObjectHashMap<Symbol> symbols = new Int2ObjectHashMap<>();\n+    private final Int2IntHashMap stackTraceIdToFilePositions = new Int2IntHashMap(-1);\n+    private final Long2ObjectHashMap<LazyStackFrame> framesByFrameId = new Long2ObjectHashMap<>();\n+    // used to resolve a symbol with minimal allocations\n+    private final StringBuilder symbolBuilder = new StringBuilder();\n+    @Nullable\n+    private List<WildcardMatcher> excludedClasses;\n+    @Nullable\n+    private List<WildcardMatcher> includedClasses;\n+\n+    /**\n+     * Initializes the parser to make it ready for {@link #getStackTrace(long, boolean, List)} to be called.\n+     *\n+     * @param file            the JFR file to parse\n+     * @param excludedClasses Class names to exclude in stack traces (has an effect on {@link #getStackTrace(long, boolean, List)})\n+     * @param includedClasses Class names to include in stack traces (has an effect on {@link #getStackTrace(long, boolean, List)})\n+     * @throws IOException if some I/O error occurs\n+     */\n+    public void parse(File file, List<WildcardMatcher> excludedClasses, List<WildcardMatcher> includedClasses) throws IOException {\n+        this.excludedClasses = excludedClasses;\n+        this.includedClasses = includedClasses;\n+        try (RandomAccessFile raf = new RandomAccessFile(file, \"r\")) {\n+            FileChannel channel = raf.getChannel();\n+            logger.info(\"Parsing {} ({} bytes)\", file, channel.size());\n+            if (channel.size() > Integer.MAX_VALUE) {\n+                // mapping a file into memory is only possible for chunks of the file which fall into the Integer range (2GB)\n+                // that is because MappedByteBuffers are ByteBuffers which only accept ints in position(int pos)\n+                throw new IllegalArgumentException(\"Input file too large\");\n+            }\n+            this.buffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, channel.size());\n+        }\n+        for (byte magicByte : MAGIC_BYTES) {\n+            if (buffer.get() != magicByte) {\n+                throw new IllegalArgumentException(\"Not a JFR file\");\n+            }\n+        }\n+        short major = buffer.getShort();\n+        short minor = buffer.getShort();\n+        if (major != 0 && minor != 9) {\n+            throw new IllegalArgumentException(String.format(\"Can only parse version 0.9. Was %d.%d\", major, minor));\n+        }\n+        // safe as we only process files where size <= Integer.MAX_VALUE\n+        metadataOffset = (int) buffer.getLong();\n+        eventsOffset = buffer.position();\n+\n+        setPosition(buffer, metadataOffset);\n+        int checkpointOffset = parseMetadata(buffer);\n+        setPosition(buffer, checkpointOffset);\n+        parseCheckpoint(buffer);\n+    }\n+\n+    private int parseMetadata(MappedByteBuffer buffer) throws IOException {\n+        int size = buffer.getInt();\n+        expectEventType(buffer, EventTypeId.EVENT_METADATA);\n+        int checkpointOffsetPosition = size - 16;\n+        setPosition(buffer, buffer.position() + checkpointOffsetPosition);\n+        // safe as we only process files where size <= Integer.MAX_VALUE\n+        return (int) buffer.getLong();\n+    }\n+\n+    private void expectEventType(MappedByteBuffer buffer, int expectedEventType) throws IOException {\n+        int eventType = buffer.getInt();\n+        if (eventType != expectedEventType) {\n+            throw new IOException(\"Expected \" + expectedEventType + \" but got \" + eventType);\n+        }\n+    }\n+\n+    private void parseCheckpoint(MappedByteBuffer buffer) throws IOException {\n+        buffer.getInt(); // size\n+        expectEventType(buffer, EventTypeId.EVENT_CHECKPOINT);\n+        buffer.getLong(); // stop timestamp\n+        buffer.getLong(); // previous checkpoint - always 0 in async-profiler\n+        while (buffer.position() < metadataOffset) {\n+            parseContentType(buffer);\n+        }\n+    }\n+\n+    private void parseContentType(MappedByteBuffer buffer) throws IOException {\n+        int contentTypeId = buffer.getInt();\n+        logger.debug(\"Parsing content type {}\", contentTypeId);\n+        int count = buffer.getInt();\n+        switch (contentTypeId) {\n+            case ContentTypeId.CONTENT_THREAD:\n+                // currently no thread info\n+                break;\n+            case ContentTypeId.CONTENT_STACKTRACE:\n+                for (int i = 0; i < count; i++) {\n+                    int pos = buffer.position();\n+                    // always an integer\n+                    // see profiler.h\n+                    // MAX_CALLTRACES = 65536\n+                    int stackTraceKey = (int) buffer.getLong();\n+                    this.stackTraceIdToFilePositions.put(stackTraceKey, pos);\n+                    buffer.get(); // truncated\n+                    int numFrames = buffer.getInt();\n+                    int sizeOfFrame = 13;\n+                    setPosition(buffer, buffer.position() + numFrames * sizeOfFrame);\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_CLASS:\n+                for (int i = 0; i < count; i++) {\n+                    // classId is an incrementing integer, no way there are more than 2 billion distinct ones\n+                    int classId = (int) buffer.getLong();\n+                    buffer.getLong(); // loader class\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int classNameSymbolId = (int) buffer.getLong();\n+                    classIdToClassNameSymbolId.put(classId, classNameSymbolId); // class name\n+                    buffer.getShort(); // access flags\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_METHOD:\n+                for (int i = 1; i <= count; i++) {\n+                    long id = buffer.getLong();\n+                    // classId is an incrementing integer, no way there are more than 2 billion distinct ones\n+                    int classId = (int) buffer.getLong();\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int methodNameSymbolId = (int) buffer.getLong();\n+                    framesByFrameId.put(id, new LazyStackFrame(classId, methodNameSymbolId));\n+                    buffer.getLong(); // signature\n+                    buffer.getShort(); // modifiers\n+                    buffer.get(); // hidden\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_SYMBOL:\n+                for (int i = 0; i < count; i++) {\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int symbolId = (int) buffer.getLong();\n+                    int pos = buffer.position();\n+                    symbols.put(symbolId, new Symbol(pos));\n+                    skipString();\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_STATE:\n+                // we're not really interested in the thread states (async-profiler hard-codes state RUNNABLE) anyways\n+                // but we sill have to consume the bytes\n+                for (int i = 1; i <= count; i++) {\n+                    buffer.getShort();\n+                    skipString();\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_FRAME_TYPE:\n+                isJavaFrameType = new boolean[count + 1];\n+                for (int i = 1 ; i <= count; i++) {\n+                    int id = buffer.get();\n+                    if (i != id) {\n+                        throw new IllegalStateException(\"Expecting ids to be incrementing\");\n+                    }\n+                    isJavaFrameType[id] = JAVA_FRAME_TYPES.contains(readUtf8String().toString());\n+                }\n+                break;\n+            default:\n+                throw new IOException(\"Unknown content type \" + contentTypeId);\n+        }\n+    }\n+\n+    private void skipString() {\n+        short stringLength = buffer.getShort();\n+        setPosition(buffer, buffer.position() + stringLength);\n+    }\n+\n+    /**\n+     * Invokes the callback for each stack trace event in the JFR file.\n+     *\n+     * @param callback called for each stack trace event\n+     * @throws IOException if some I/O error occurs\n+     */\n+    public void consumeStackTraces(StackTraceConsumer callback) throws IOException {\n+        if (buffer == null) {\n+            throw new IllegalStateException(\"consumeStackTraces was called before parse\");\n+        }\n+        setPosition(buffer, eventsOffset);\n+        while (buffer.position() < metadataOffset) {\n+            int size = buffer.getInt();\n+            int eventType = buffer.getInt();\n+            if (eventType == EventTypeId.EVENT_RECORDING) {\n+                return;\n+            }\n+            if (eventType != EventTypeId.EVENT_EXECUTION_SAMPLE){\n+                throw new IOException(\"Expected \" + EventTypeId.EVENT_EXECUTION_SAMPLE + \" but got \" + eventType);\n+            }\n+            long nanoTime = buffer.getLong();\n+            int tid = buffer.getInt();\n+            long stackTraceId = buffer.getLong();\n+            short threadState = buffer.getShort();\n+            callback.onCallTree(tid, stackTraceId, nanoTime);\n+        }\n+    }\n+\n+    public interface StackTraceConsumer {\n+\n+        /**\n+         * @param threadId     The native thread id for with the event was recorded.\n+         *                     Note that this is not the same as {@link Thread#getId()}.\n+         * @param stackTraceId The id of the stack trace event.\n+         *                     Can be used to resolve the stack trace via {@link #getStackTrace(long, boolean, List)}\n+         * @param nanoTime     The timestamp of the event which can be correlated with {@link System#nanoTime()}\n+         */\n+        void onCallTree(int threadId, long stackTraceId, long nanoTime);\n+    }\n+\n+    /**\n+     * Resolves the stack trace with the given {@code stackTraceId}.\n+     * <p>\n+     * Note that his allocates strings for {@link Symbol#resolved} in case a stack frame has not already been resolved for the current JFR file yet.\n+     * These strings are currently not cached so this can create some GC pressure.\n+     * </p>\n+     *\n+     * @param stackTraceId   The id of the stack traced.\n+     *                       Used to look up the position of the file in which the given stack trace is stored via {@link #stackTraceIdToFilePositions}.\n+     * @param onlyJavaFrames If {@code true}, will only resolve {@code Interpreted}, {@code JIT compiled} and {@code Inlined} frames.\n+     *                       If {@code false}, will also resolve {@code Native}, {@code Kernel} and {@code C++} frames.\n+     * @param stackFrames    The mutable list where the stack frames are written to.\n+     *                       Don't forget to {@link List#clear()} the list before calling this method if the list is reused.\n+     */\n+    public void getStackTrace(long stackTraceId, boolean onlyJavaFrames, List<StackFrame> stackFrames) {\n+        if (buffer == null) {\n+            throw new IllegalStateException(\"getStackTrace was called before parse\");\n+        }\n+        MappedByteBuffer buffer = this.buffer;\n+        int position = buffer.position();\n+        setPosition(buffer, stackTraceIdToFilePositions.get((int) stackTraceId));\n+        long stackTraceIdFromFile = buffer.getLong();\n+        assert stackTraceId == stackTraceIdFromFile;\n+        buffer.get(); // truncated\n+        int numFrames = buffer.getInt();\n+        for (int i = 0; i < numFrames; i++) {\n+            long method = buffer.getLong();\n+            buffer.getInt(); // bci (always set to 0 by async-profiler)\n+            byte frameType = buffer.get();\n+            if (!onlyJavaFrames || isJavaFrameType(frameType)) {\n+                LazyStackFrame lazyStackFrame = framesByFrameId.get(method);\n+                if (lazyStackFrame.isIncluded(this)) {\n+                    StackFrame stackFrame = lazyStackFrame.resolve(this);\n+                    stackFrames.add(stackFrame);\n+                }\n+            }\n+        }\n+        setPosition(buffer, position);\n+    }\n+\n+    private boolean isJavaFrameType(byte frameType) {\n+        return isJavaFrameType[frameType];\n+    }\n+\n+    private StringBuilder resolveSymbol(int pos, boolean replaceSlashWithDot) {\n+        int currentPos = buffer.position();\n+        setPosition(buffer, pos);\n+        try {\n+            return readUtf8String(replaceSlashWithDot);\n+        } finally {\n+            setPosition(buffer, currentPos);\n+        }\n+    }\n+\n+    private boolean isClassIncluded(CharSequence className) {\n+        return WildcardMatcher.isAnyMatch(includedClasses, className) && WildcardMatcher.isNoneMatch(excludedClasses, className);\n+    }\n+\n+    private static void setPosition(MappedByteBuffer buffer, int pos) {\n+        // weird hack because of binary incompatibility introduced in Java 9\n+        // the return type was changed from Buffer to MappedByteBuffer\n+        // linking a method also incorporates the exact return type\n+        ((Buffer) buffer).position(pos);\n+    }\n+\n+    private StackFrame resolveStackFrame(int classId, int methodName) {\n+        Symbol classNameSymbol = symbols.get(classIdToClassNameSymbolId.get(classId));\n+        if (classNameSymbol.isClassNameIncluded(this)) {\n+            String className = classNameSymbol.resolveClassName(this);\n+            String method = symbols.get(methodName).resolve(this);\n+            return new StackFrame(className, Objects.requireNonNull(method));\n+        } else {\n+            return LazyStackFrame.EXCLUDED;\n+        }\n+    }\n+\n+    private StringBuilder readUtf8String() {\n+        return readUtf8String(false);\n+    }\n+\n+    private StringBuilder readUtf8String(boolean replaceSlashWithDot) {\n+        int size = buffer.getShort();\n+        StringBuilder symbolBuilder = this.symbolBuilder;\n+        symbolBuilder.setLength(0);\n+        for (int i = 0; i < size; i++) {\n+            char c = (char) buffer.get();\n+            if (replaceSlashWithDot && c == '/') {\n+                symbolBuilder.append('.');\n+            } else {\n+                symbolBuilder.append(c);\n+            }\n+        }\n+        return symbolBuilder;\n+    }\n+\n+    @Override\n+    public void resetState() {\n+        buffer = null;\n+        eventsOffset = 0;\n+        metadataOffset = 0;\n+        isJavaFrameType = null;\n+        classIdToClassNameSymbolId.clear();\n+        symbols.clear();\n+        stackTraceIdToFilePositions.clear();\n+        framesByFrameId.clear();\n+        symbolBuilder.setLength(0);\n+        excludedClasses = null;\n+        includedClasses = null;\n+    }\n+\n+    private interface EventTypeId {\n+        int EVENT_METADATA           = 0;\n+        int EVENT_CHECKPOINT         = 1;\n+        int EVENT_RECORDING          = 10;\n+        int EVENT_EXECUTION_SAMPLE   = 20;\n+    }\n+\n+    private interface ContentTypeId {\n+        int CONTENT_THREAD      = 7;\n+        int CONTENT_STACKTRACE  = 9;\n+        int CONTENT_CLASS       = 10;\n+        int CONTENT_METHOD      = 32;\n+        int CONTENT_SYMBOL      = 33;\n+        int CONTENT_STATE       = 34;\n+        int CONTENT_FRAME_TYPE  = 47;\n+    }\n+\n+    /**\n+     * Represents a single frame of a stack trace.\n+     * As stack frames are detached from stack traces, the same frame can occur in multiple stack traces.\n+     * That's why within a JFR file, a stack trace is basically represented as an array of pointers to stack frames.\n+     * <p>\n+     * The actual {@link StackFrame} is resolved lazily to avoid allocations when they are not needed.\n+     * That can be the case when not processing stack traces of particular threads, for example.\n+     * The resolved {@link #stackFrame} is then cached so that I/O is avoided when subsequently resolving the same frame.\n+     * </p>\n+     */\n+    private static class LazyStackFrame {\n+\n+        private final static StackFrame EXCLUDED = new StackFrame(\"excluded\", \"excluded\");\n+\n+        private final int classId;\n+        private final int methodName;\n+\n+        @Nullable\n+        private StackFrame stackFrame;\n+\n+        public LazyStackFrame(int classId, int methodName) {\n+            this.classId = classId;\n+            this.methodName = methodName;\n+        }\n+\n+        public StackFrame resolve(JfrParser parser) {\n+            if (stackFrame == null) {\n+                stackFrame = parser.resolveStackFrame(classId, methodName);\n+            }\n+            return stackFrame;\n+        }\n+\n+        /**\n+         * Returns {@code true} when the class name matches the matchers provided via {@link #parse(File, List, List)}\n+         *\n+         * @param parser\n+         * @return\n+         */\n+        public boolean isIncluded(JfrParser parser) {\n+            return resolve(parser) != EXCLUDED;\n+        }\n+    }\n+\n+    /**\n+     * A symbol is a UTF-8 string with an ID, representing a method name or class name, for example.\n+     * There's a specific section in the JFR file which contains all symbols.\n+     * <p>\n+     * Symbols are are {@link #resolve}d lazily to avoid allocations when they are not needed.\n+     * That can be the case when not processing stack traces of particular threads, for example.\n+     * The {@link #resolved} String is then cached so that I/O is avoided when subsequently resolving the same symbol.\n+     * </p>\n+     */\n+    private static class Symbol {\n+        private static final String EXCLUDED = \"3x cluded\";\n+        /**\n+         * The position in the JFR file which holds the symbol\n+         */\n+        private final int pos;\n+        @Nullable\n+        private String resolved;\n+\n+        private Symbol(int pos) {\n+            this.pos = pos;\n+        }\n+\n+        /**\n+         * Resolves a symbol representing a class name from the JFR file ({@link #buffer}).\n+         */\n+        @Nullable\n+        public String resolve(JfrParser parser) {\n+            return resolve(parser, false);\n+        }\n+\n+        /**\n+         * Resolves a symbol representing a class name from the JFR file ({@link #buffer}).\n+         * <p>\n+         * In the JFR file, class names are in their binary form (for example {@code foo/bar/Baz}.\n+         * This methods converts it to the form matching {@link Class#getName()} by replacing the slashes with dots.\n+         * </p>\n+         * <p>\n+         * Returns {@code null} if {@link #isClassNameIncluded(JfrParser)} returns {@code false}\n+         * </p>\n+         */\n+        @Nullable\n+        private String resolveClassName(JfrParser parser) {\n+            return resolve(parser, true);\n+        }\n+\n+        /**\n+         * Returns {@code true} when the class name matches the matchers provided via {@link #parse(File, List, List)}\n+         *\n+         * @param parser\n+         * @return\n+         */\n+        private boolean isClassNameIncluded(JfrParser parser) {\n+            return resolve(parser, true) != EXCLUDED;\n+        }\n+\n+        @Nullable\n+        private String resolve(JfrParser parser, boolean className) {", "originalCommit": "886c4ce259e9765a2e399d30a99e3f03d9981b3d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQzNTU2NA==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367435564", "bodyText": "But a symbol does not know whether it's a class name symbol or a regular one.", "author": "felixbarny", "createdAt": "2020-01-16T14:07:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjMxMjA4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQ0OTUyOA==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367449528", "bodyText": "Ahh, you mean that when you create them based on the file you can't tell?", "author": "eyalkoren", "createdAt": "2020-01-16T14:32:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjMxMjA4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQ2NDEzMw==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367464133", "bodyText": "yes", "author": "felixbarny", "createdAt": "2020-01-16T14:57:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjMxMjA4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjMxNDQ0Mg==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366314442", "bodyText": "Consider pooling StackFrames and use them with StringBuilders instead of Strings for class and method names, into which you can directly resolve from the file.", "author": "eyalkoren", "createdAt": "2020-01-14T12:38:00Z", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/JfrParser.java", "diffHunk": "@@ -0,0 +1,518 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+import co.elastic.apm.agent.profiler.collections.Int2IntHashMap;\n+import co.elastic.apm.agent.profiler.collections.Int2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+/**\n+ * Parses the binary JFR file created by async-profiler.\n+ * May not work with JFR files created by an actual flight recorder.\n+ * <p>\n+ * The implementation is tuned with to minimize allocations when parsing a JFR file.\n+ * Most data structures can be reused by first {@linkplain #resetState() resetting the state} and then {@linkplain #parse(File, List, List) parsing}\n+ * another file.\n+ * </p>\n+ * <p>\n+ * The JFR file itself is mapped into memory via a {@link MappedByteBuffer}.\n+ * This does not consume heap memory, the operating system loads pages the file into memory as they are requested.\n+ * Unfortunately, unmapping a {@link MappedByteBuffer} can only be done by letting it be garbage collected.\n+ * </p>\n+ */\n+public class JfrParser implements Recyclable {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(JfrParser.class);\n+\n+    private static final byte[] MAGIC_BYTES = new byte[]{'F', 'L', 'R', '\\0'};\n+    private static final Set<String> JAVA_FRAME_TYPES = new HashSet<>(Arrays.asList(\"Interpreted\", \"JIT compiled\", \"Inlined\"));\n+\n+    @Nullable\n+    private MappedByteBuffer buffer;\n+    private int eventsOffset;\n+    private int metadataOffset;\n+    @Nullable\n+    private boolean[] isJavaFrameType;\n+    private final Int2IntHashMap classIdToClassNameSymbolId = new Int2IntHashMap(-1);\n+    private final Int2ObjectHashMap<Symbol> symbols = new Int2ObjectHashMap<>();\n+    private final Int2IntHashMap stackTraceIdToFilePositions = new Int2IntHashMap(-1);\n+    private final Long2ObjectHashMap<LazyStackFrame> framesByFrameId = new Long2ObjectHashMap<>();\n+    // used to resolve a symbol with minimal allocations\n+    private final StringBuilder symbolBuilder = new StringBuilder();\n+    @Nullable\n+    private List<WildcardMatcher> excludedClasses;\n+    @Nullable\n+    private List<WildcardMatcher> includedClasses;\n+\n+    /**\n+     * Initializes the parser to make it ready for {@link #getStackTrace(long, boolean, List)} to be called.\n+     *\n+     * @param file            the JFR file to parse\n+     * @param excludedClasses Class names to exclude in stack traces (has an effect on {@link #getStackTrace(long, boolean, List)})\n+     * @param includedClasses Class names to include in stack traces (has an effect on {@link #getStackTrace(long, boolean, List)})\n+     * @throws IOException if some I/O error occurs\n+     */\n+    public void parse(File file, List<WildcardMatcher> excludedClasses, List<WildcardMatcher> includedClasses) throws IOException {\n+        this.excludedClasses = excludedClasses;\n+        this.includedClasses = includedClasses;\n+        try (RandomAccessFile raf = new RandomAccessFile(file, \"r\")) {\n+            FileChannel channel = raf.getChannel();\n+            logger.info(\"Parsing {} ({} bytes)\", file, channel.size());\n+            if (channel.size() > Integer.MAX_VALUE) {\n+                // mapping a file into memory is only possible for chunks of the file which fall into the Integer range (2GB)\n+                // that is because MappedByteBuffers are ByteBuffers which only accept ints in position(int pos)\n+                throw new IllegalArgumentException(\"Input file too large\");\n+            }\n+            this.buffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, channel.size());\n+        }\n+        for (byte magicByte : MAGIC_BYTES) {\n+            if (buffer.get() != magicByte) {\n+                throw new IllegalArgumentException(\"Not a JFR file\");\n+            }\n+        }\n+        short major = buffer.getShort();\n+        short minor = buffer.getShort();\n+        if (major != 0 && minor != 9) {\n+            throw new IllegalArgumentException(String.format(\"Can only parse version 0.9. Was %d.%d\", major, minor));\n+        }\n+        // safe as we only process files where size <= Integer.MAX_VALUE\n+        metadataOffset = (int) buffer.getLong();\n+        eventsOffset = buffer.position();\n+\n+        setPosition(buffer, metadataOffset);\n+        int checkpointOffset = parseMetadata(buffer);\n+        setPosition(buffer, checkpointOffset);\n+        parseCheckpoint(buffer);\n+    }\n+\n+    private int parseMetadata(MappedByteBuffer buffer) throws IOException {\n+        int size = buffer.getInt();\n+        expectEventType(buffer, EventTypeId.EVENT_METADATA);\n+        int checkpointOffsetPosition = size - 16;\n+        setPosition(buffer, buffer.position() + checkpointOffsetPosition);\n+        // safe as we only process files where size <= Integer.MAX_VALUE\n+        return (int) buffer.getLong();\n+    }\n+\n+    private void expectEventType(MappedByteBuffer buffer, int expectedEventType) throws IOException {\n+        int eventType = buffer.getInt();\n+        if (eventType != expectedEventType) {\n+            throw new IOException(\"Expected \" + expectedEventType + \" but got \" + eventType);\n+        }\n+    }\n+\n+    private void parseCheckpoint(MappedByteBuffer buffer) throws IOException {\n+        buffer.getInt(); // size\n+        expectEventType(buffer, EventTypeId.EVENT_CHECKPOINT);\n+        buffer.getLong(); // stop timestamp\n+        buffer.getLong(); // previous checkpoint - always 0 in async-profiler\n+        while (buffer.position() < metadataOffset) {\n+            parseContentType(buffer);\n+        }\n+    }\n+\n+    private void parseContentType(MappedByteBuffer buffer) throws IOException {\n+        int contentTypeId = buffer.getInt();\n+        logger.debug(\"Parsing content type {}\", contentTypeId);\n+        int count = buffer.getInt();\n+        switch (contentTypeId) {\n+            case ContentTypeId.CONTENT_THREAD:\n+                // currently no thread info\n+                break;\n+            case ContentTypeId.CONTENT_STACKTRACE:\n+                for (int i = 0; i < count; i++) {\n+                    int pos = buffer.position();\n+                    // always an integer\n+                    // see profiler.h\n+                    // MAX_CALLTRACES = 65536\n+                    int stackTraceKey = (int) buffer.getLong();\n+                    this.stackTraceIdToFilePositions.put(stackTraceKey, pos);\n+                    buffer.get(); // truncated\n+                    int numFrames = buffer.getInt();\n+                    int sizeOfFrame = 13;\n+                    setPosition(buffer, buffer.position() + numFrames * sizeOfFrame);\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_CLASS:\n+                for (int i = 0; i < count; i++) {\n+                    // classId is an incrementing integer, no way there are more than 2 billion distinct ones\n+                    int classId = (int) buffer.getLong();\n+                    buffer.getLong(); // loader class\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int classNameSymbolId = (int) buffer.getLong();\n+                    classIdToClassNameSymbolId.put(classId, classNameSymbolId); // class name\n+                    buffer.getShort(); // access flags\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_METHOD:\n+                for (int i = 1; i <= count; i++) {\n+                    long id = buffer.getLong();\n+                    // classId is an incrementing integer, no way there are more than 2 billion distinct ones\n+                    int classId = (int) buffer.getLong();\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int methodNameSymbolId = (int) buffer.getLong();\n+                    framesByFrameId.put(id, new LazyStackFrame(classId, methodNameSymbolId));\n+                    buffer.getLong(); // signature\n+                    buffer.getShort(); // modifiers\n+                    buffer.get(); // hidden\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_SYMBOL:\n+                for (int i = 0; i < count; i++) {\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int symbolId = (int) buffer.getLong();\n+                    int pos = buffer.position();\n+                    symbols.put(symbolId, new Symbol(pos));\n+                    skipString();\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_STATE:\n+                // we're not really interested in the thread states (async-profiler hard-codes state RUNNABLE) anyways\n+                // but we sill have to consume the bytes\n+                for (int i = 1; i <= count; i++) {\n+                    buffer.getShort();\n+                    skipString();\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_FRAME_TYPE:\n+                isJavaFrameType = new boolean[count + 1];\n+                for (int i = 1 ; i <= count; i++) {\n+                    int id = buffer.get();\n+                    if (i != id) {\n+                        throw new IllegalStateException(\"Expecting ids to be incrementing\");\n+                    }\n+                    isJavaFrameType[id] = JAVA_FRAME_TYPES.contains(readUtf8String().toString());\n+                }\n+                break;\n+            default:\n+                throw new IOException(\"Unknown content type \" + contentTypeId);\n+        }\n+    }\n+\n+    private void skipString() {\n+        short stringLength = buffer.getShort();\n+        setPosition(buffer, buffer.position() + stringLength);\n+    }\n+\n+    /**\n+     * Invokes the callback for each stack trace event in the JFR file.\n+     *\n+     * @param callback called for each stack trace event\n+     * @throws IOException if some I/O error occurs\n+     */\n+    public void consumeStackTraces(StackTraceConsumer callback) throws IOException {\n+        if (buffer == null) {\n+            throw new IllegalStateException(\"consumeStackTraces was called before parse\");\n+        }\n+        setPosition(buffer, eventsOffset);\n+        while (buffer.position() < metadataOffset) {\n+            int size = buffer.getInt();\n+            int eventType = buffer.getInt();\n+            if (eventType == EventTypeId.EVENT_RECORDING) {\n+                return;\n+            }\n+            if (eventType != EventTypeId.EVENT_EXECUTION_SAMPLE){\n+                throw new IOException(\"Expected \" + EventTypeId.EVENT_EXECUTION_SAMPLE + \" but got \" + eventType);\n+            }\n+            long nanoTime = buffer.getLong();\n+            int tid = buffer.getInt();\n+            long stackTraceId = buffer.getLong();\n+            short threadState = buffer.getShort();\n+            callback.onCallTree(tid, stackTraceId, nanoTime);\n+        }\n+    }\n+\n+    public interface StackTraceConsumer {\n+\n+        /**\n+         * @param threadId     The native thread id for with the event was recorded.\n+         *                     Note that this is not the same as {@link Thread#getId()}.\n+         * @param stackTraceId The id of the stack trace event.\n+         *                     Can be used to resolve the stack trace via {@link #getStackTrace(long, boolean, List)}\n+         * @param nanoTime     The timestamp of the event which can be correlated with {@link System#nanoTime()}\n+         */\n+        void onCallTree(int threadId, long stackTraceId, long nanoTime);\n+    }\n+\n+    /**\n+     * Resolves the stack trace with the given {@code stackTraceId}.\n+     * <p>\n+     * Note that his allocates strings for {@link Symbol#resolved} in case a stack frame has not already been resolved for the current JFR file yet.\n+     * These strings are currently not cached so this can create some GC pressure.\n+     * </p>\n+     *\n+     * @param stackTraceId   The id of the stack traced.\n+     *                       Used to look up the position of the file in which the given stack trace is stored via {@link #stackTraceIdToFilePositions}.\n+     * @param onlyJavaFrames If {@code true}, will only resolve {@code Interpreted}, {@code JIT compiled} and {@code Inlined} frames.\n+     *                       If {@code false}, will also resolve {@code Native}, {@code Kernel} and {@code C++} frames.\n+     * @param stackFrames    The mutable list where the stack frames are written to.\n+     *                       Don't forget to {@link List#clear()} the list before calling this method if the list is reused.\n+     */\n+    public void getStackTrace(long stackTraceId, boolean onlyJavaFrames, List<StackFrame> stackFrames) {\n+        if (buffer == null) {\n+            throw new IllegalStateException(\"getStackTrace was called before parse\");\n+        }\n+        MappedByteBuffer buffer = this.buffer;\n+        int position = buffer.position();\n+        setPosition(buffer, stackTraceIdToFilePositions.get((int) stackTraceId));\n+        long stackTraceIdFromFile = buffer.getLong();\n+        assert stackTraceId == stackTraceIdFromFile;\n+        buffer.get(); // truncated\n+        int numFrames = buffer.getInt();\n+        for (int i = 0; i < numFrames; i++) {\n+            long method = buffer.getLong();\n+            buffer.getInt(); // bci (always set to 0 by async-profiler)\n+            byte frameType = buffer.get();\n+            if (!onlyJavaFrames || isJavaFrameType(frameType)) {\n+                LazyStackFrame lazyStackFrame = framesByFrameId.get(method);\n+                if (lazyStackFrame.isIncluded(this)) {\n+                    StackFrame stackFrame = lazyStackFrame.resolve(this);\n+                    stackFrames.add(stackFrame);\n+                }\n+            }\n+        }\n+        setPosition(buffer, position);\n+    }\n+\n+    private boolean isJavaFrameType(byte frameType) {\n+        return isJavaFrameType[frameType];\n+    }\n+\n+    private StringBuilder resolveSymbol(int pos, boolean replaceSlashWithDot) {\n+        int currentPos = buffer.position();\n+        setPosition(buffer, pos);\n+        try {\n+            return readUtf8String(replaceSlashWithDot);\n+        } finally {\n+            setPosition(buffer, currentPos);\n+        }\n+    }\n+\n+    private boolean isClassIncluded(CharSequence className) {\n+        return WildcardMatcher.isAnyMatch(includedClasses, className) && WildcardMatcher.isNoneMatch(excludedClasses, className);\n+    }\n+\n+    private static void setPosition(MappedByteBuffer buffer, int pos) {\n+        // weird hack because of binary incompatibility introduced in Java 9\n+        // the return type was changed from Buffer to MappedByteBuffer\n+        // linking a method also incorporates the exact return type\n+        ((Buffer) buffer).position(pos);\n+    }\n+\n+    private StackFrame resolveStackFrame(int classId, int methodName) {\n+        Symbol classNameSymbol = symbols.get(classIdToClassNameSymbolId.get(classId));\n+        if (classNameSymbol.isClassNameIncluded(this)) {\n+            String className = classNameSymbol.resolveClassName(this);\n+            String method = symbols.get(methodName).resolve(this);\n+            return new StackFrame(className, Objects.requireNonNull(method));", "originalCommit": "886c4ce259e9765a2e399d30a99e3f03d9981b3d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQzNTA4Mw==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367435083", "bodyText": "and use them with StringBuilders instead of Strings for class and method names, into which you can directly resolve from the file.\n\nThat's probably going to use more memory as the majority of symbols is likely to be unresolved. But pooling the strings and the frames separately could be a nice improvement.", "author": "felixbarny", "createdAt": "2020-01-16T14:06:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjMxNDQ0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQ1MTEyNA==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367451124", "bodyText": "Or pool those StringBuilders, as suggested in #981 (comment) \ud83d\ude1c", "author": "eyalkoren", "createdAt": "2020-01-16T14:35:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjMxNDQ0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjMxNTU4Nw==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366315587", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public void getStackTrace(long stackTraceId, boolean onlyJavaFrames, List<StackFrame> stackFrames) {\n          \n          \n            \n                public void resolveStackTrace(long stackTraceId, boolean onlyJavaFrames, List<StackFrame> stackFrames) {", "author": "eyalkoren", "createdAt": "2020-01-14T12:40:47Z", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/JfrParser.java", "diffHunk": "@@ -0,0 +1,518 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+import co.elastic.apm.agent.profiler.collections.Int2IntHashMap;\n+import co.elastic.apm.agent.profiler.collections.Int2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+/**\n+ * Parses the binary JFR file created by async-profiler.\n+ * May not work with JFR files created by an actual flight recorder.\n+ * <p>\n+ * The implementation is tuned with to minimize allocations when parsing a JFR file.\n+ * Most data structures can be reused by first {@linkplain #resetState() resetting the state} and then {@linkplain #parse(File, List, List) parsing}\n+ * another file.\n+ * </p>\n+ * <p>\n+ * The JFR file itself is mapped into memory via a {@link MappedByteBuffer}.\n+ * This does not consume heap memory, the operating system loads pages the file into memory as they are requested.\n+ * Unfortunately, unmapping a {@link MappedByteBuffer} can only be done by letting it be garbage collected.\n+ * </p>\n+ */\n+public class JfrParser implements Recyclable {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(JfrParser.class);\n+\n+    private static final byte[] MAGIC_BYTES = new byte[]{'F', 'L', 'R', '\\0'};\n+    private static final Set<String> JAVA_FRAME_TYPES = new HashSet<>(Arrays.asList(\"Interpreted\", \"JIT compiled\", \"Inlined\"));\n+\n+    @Nullable\n+    private MappedByteBuffer buffer;\n+    private int eventsOffset;\n+    private int metadataOffset;\n+    @Nullable\n+    private boolean[] isJavaFrameType;\n+    private final Int2IntHashMap classIdToClassNameSymbolId = new Int2IntHashMap(-1);\n+    private final Int2ObjectHashMap<Symbol> symbols = new Int2ObjectHashMap<>();\n+    private final Int2IntHashMap stackTraceIdToFilePositions = new Int2IntHashMap(-1);\n+    private final Long2ObjectHashMap<LazyStackFrame> framesByFrameId = new Long2ObjectHashMap<>();\n+    // used to resolve a symbol with minimal allocations\n+    private final StringBuilder symbolBuilder = new StringBuilder();\n+    @Nullable\n+    private List<WildcardMatcher> excludedClasses;\n+    @Nullable\n+    private List<WildcardMatcher> includedClasses;\n+\n+    /**\n+     * Initializes the parser to make it ready for {@link #getStackTrace(long, boolean, List)} to be called.\n+     *\n+     * @param file            the JFR file to parse\n+     * @param excludedClasses Class names to exclude in stack traces (has an effect on {@link #getStackTrace(long, boolean, List)})\n+     * @param includedClasses Class names to include in stack traces (has an effect on {@link #getStackTrace(long, boolean, List)})\n+     * @throws IOException if some I/O error occurs\n+     */\n+    public void parse(File file, List<WildcardMatcher> excludedClasses, List<WildcardMatcher> includedClasses) throws IOException {\n+        this.excludedClasses = excludedClasses;\n+        this.includedClasses = includedClasses;\n+        try (RandomAccessFile raf = new RandomAccessFile(file, \"r\")) {\n+            FileChannel channel = raf.getChannel();\n+            logger.info(\"Parsing {} ({} bytes)\", file, channel.size());\n+            if (channel.size() > Integer.MAX_VALUE) {\n+                // mapping a file into memory is only possible for chunks of the file which fall into the Integer range (2GB)\n+                // that is because MappedByteBuffers are ByteBuffers which only accept ints in position(int pos)\n+                throw new IllegalArgumentException(\"Input file too large\");\n+            }\n+            this.buffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, channel.size());\n+        }\n+        for (byte magicByte : MAGIC_BYTES) {\n+            if (buffer.get() != magicByte) {\n+                throw new IllegalArgumentException(\"Not a JFR file\");\n+            }\n+        }\n+        short major = buffer.getShort();\n+        short minor = buffer.getShort();\n+        if (major != 0 && minor != 9) {\n+            throw new IllegalArgumentException(String.format(\"Can only parse version 0.9. Was %d.%d\", major, minor));\n+        }\n+        // safe as we only process files where size <= Integer.MAX_VALUE\n+        metadataOffset = (int) buffer.getLong();\n+        eventsOffset = buffer.position();\n+\n+        setPosition(buffer, metadataOffset);\n+        int checkpointOffset = parseMetadata(buffer);\n+        setPosition(buffer, checkpointOffset);\n+        parseCheckpoint(buffer);\n+    }\n+\n+    private int parseMetadata(MappedByteBuffer buffer) throws IOException {\n+        int size = buffer.getInt();\n+        expectEventType(buffer, EventTypeId.EVENT_METADATA);\n+        int checkpointOffsetPosition = size - 16;\n+        setPosition(buffer, buffer.position() + checkpointOffsetPosition);\n+        // safe as we only process files where size <= Integer.MAX_VALUE\n+        return (int) buffer.getLong();\n+    }\n+\n+    private void expectEventType(MappedByteBuffer buffer, int expectedEventType) throws IOException {\n+        int eventType = buffer.getInt();\n+        if (eventType != expectedEventType) {\n+            throw new IOException(\"Expected \" + expectedEventType + \" but got \" + eventType);\n+        }\n+    }\n+\n+    private void parseCheckpoint(MappedByteBuffer buffer) throws IOException {\n+        buffer.getInt(); // size\n+        expectEventType(buffer, EventTypeId.EVENT_CHECKPOINT);\n+        buffer.getLong(); // stop timestamp\n+        buffer.getLong(); // previous checkpoint - always 0 in async-profiler\n+        while (buffer.position() < metadataOffset) {\n+            parseContentType(buffer);\n+        }\n+    }\n+\n+    private void parseContentType(MappedByteBuffer buffer) throws IOException {\n+        int contentTypeId = buffer.getInt();\n+        logger.debug(\"Parsing content type {}\", contentTypeId);\n+        int count = buffer.getInt();\n+        switch (contentTypeId) {\n+            case ContentTypeId.CONTENT_THREAD:\n+                // currently no thread info\n+                break;\n+            case ContentTypeId.CONTENT_STACKTRACE:\n+                for (int i = 0; i < count; i++) {\n+                    int pos = buffer.position();\n+                    // always an integer\n+                    // see profiler.h\n+                    // MAX_CALLTRACES = 65536\n+                    int stackTraceKey = (int) buffer.getLong();\n+                    this.stackTraceIdToFilePositions.put(stackTraceKey, pos);\n+                    buffer.get(); // truncated\n+                    int numFrames = buffer.getInt();\n+                    int sizeOfFrame = 13;\n+                    setPosition(buffer, buffer.position() + numFrames * sizeOfFrame);\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_CLASS:\n+                for (int i = 0; i < count; i++) {\n+                    // classId is an incrementing integer, no way there are more than 2 billion distinct ones\n+                    int classId = (int) buffer.getLong();\n+                    buffer.getLong(); // loader class\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int classNameSymbolId = (int) buffer.getLong();\n+                    classIdToClassNameSymbolId.put(classId, classNameSymbolId); // class name\n+                    buffer.getShort(); // access flags\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_METHOD:\n+                for (int i = 1; i <= count; i++) {\n+                    long id = buffer.getLong();\n+                    // classId is an incrementing integer, no way there are more than 2 billion distinct ones\n+                    int classId = (int) buffer.getLong();\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int methodNameSymbolId = (int) buffer.getLong();\n+                    framesByFrameId.put(id, new LazyStackFrame(classId, methodNameSymbolId));\n+                    buffer.getLong(); // signature\n+                    buffer.getShort(); // modifiers\n+                    buffer.get(); // hidden\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_SYMBOL:\n+                for (int i = 0; i < count; i++) {\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int symbolId = (int) buffer.getLong();\n+                    int pos = buffer.position();\n+                    symbols.put(symbolId, new Symbol(pos));\n+                    skipString();\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_STATE:\n+                // we're not really interested in the thread states (async-profiler hard-codes state RUNNABLE) anyways\n+                // but we sill have to consume the bytes\n+                for (int i = 1; i <= count; i++) {\n+                    buffer.getShort();\n+                    skipString();\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_FRAME_TYPE:\n+                isJavaFrameType = new boolean[count + 1];\n+                for (int i = 1 ; i <= count; i++) {\n+                    int id = buffer.get();\n+                    if (i != id) {\n+                        throw new IllegalStateException(\"Expecting ids to be incrementing\");\n+                    }\n+                    isJavaFrameType[id] = JAVA_FRAME_TYPES.contains(readUtf8String().toString());\n+                }\n+                break;\n+            default:\n+                throw new IOException(\"Unknown content type \" + contentTypeId);\n+        }\n+    }\n+\n+    private void skipString() {\n+        short stringLength = buffer.getShort();\n+        setPosition(buffer, buffer.position() + stringLength);\n+    }\n+\n+    /**\n+     * Invokes the callback for each stack trace event in the JFR file.\n+     *\n+     * @param callback called for each stack trace event\n+     * @throws IOException if some I/O error occurs\n+     */\n+    public void consumeStackTraces(StackTraceConsumer callback) throws IOException {\n+        if (buffer == null) {\n+            throw new IllegalStateException(\"consumeStackTraces was called before parse\");\n+        }\n+        setPosition(buffer, eventsOffset);\n+        while (buffer.position() < metadataOffset) {\n+            int size = buffer.getInt();\n+            int eventType = buffer.getInt();\n+            if (eventType == EventTypeId.EVENT_RECORDING) {\n+                return;\n+            }\n+            if (eventType != EventTypeId.EVENT_EXECUTION_SAMPLE){\n+                throw new IOException(\"Expected \" + EventTypeId.EVENT_EXECUTION_SAMPLE + \" but got \" + eventType);\n+            }\n+            long nanoTime = buffer.getLong();\n+            int tid = buffer.getInt();\n+            long stackTraceId = buffer.getLong();\n+            short threadState = buffer.getShort();\n+            callback.onCallTree(tid, stackTraceId, nanoTime);\n+        }\n+    }\n+\n+    public interface StackTraceConsumer {\n+\n+        /**\n+         * @param threadId     The native thread id for with the event was recorded.\n+         *                     Note that this is not the same as {@link Thread#getId()}.\n+         * @param stackTraceId The id of the stack trace event.\n+         *                     Can be used to resolve the stack trace via {@link #getStackTrace(long, boolean, List)}\n+         * @param nanoTime     The timestamp of the event which can be correlated with {@link System#nanoTime()}\n+         */\n+        void onCallTree(int threadId, long stackTraceId, long nanoTime);\n+    }\n+\n+    /**\n+     * Resolves the stack trace with the given {@code stackTraceId}.\n+     * <p>\n+     * Note that his allocates strings for {@link Symbol#resolved} in case a stack frame has not already been resolved for the current JFR file yet.\n+     * These strings are currently not cached so this can create some GC pressure.\n+     * </p>\n+     *\n+     * @param stackTraceId   The id of the stack traced.\n+     *                       Used to look up the position of the file in which the given stack trace is stored via {@link #stackTraceIdToFilePositions}.\n+     * @param onlyJavaFrames If {@code true}, will only resolve {@code Interpreted}, {@code JIT compiled} and {@code Inlined} frames.\n+     *                       If {@code false}, will also resolve {@code Native}, {@code Kernel} and {@code C++} frames.\n+     * @param stackFrames    The mutable list where the stack frames are written to.\n+     *                       Don't forget to {@link List#clear()} the list before calling this method if the list is reused.\n+     */\n+    public void getStackTrace(long stackTraceId, boolean onlyJavaFrames, List<StackFrame> stackFrames) {", "originalCommit": "886c4ce259e9765a2e399d30a99e3f03d9981b3d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjMyOTE1Mw==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366329153", "bodyText": "This makes it dynamic only when starting with true. If you remove this check it will be completely dynamic, as you check at the beginning of each run invocation.", "author": "eyalkoren", "createdAt": "2020-01-14T13:12:31Z", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.configuration.converter.TimeDuration;\n+import co.elastic.apm.agent.context.LifecycleListener;\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.impl.transaction.TraceContextHolder;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Allocator;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.impl.ListBasedObjectPool;\n+import co.elastic.apm.agent.profiler.asyncprofiler.AsyncProfiler;\n+import co.elastic.apm.agent.profiler.asyncprofiler.JfrParser;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.LongHashSet;\n+import co.elastic.apm.agent.util.ExecutorUtils;\n+import com.lmax.disruptor.EventFactory;\n+import com.lmax.disruptor.EventPoller;\n+import com.lmax.disruptor.EventTranslatorTwoArg;\n+import com.lmax.disruptor.RingBuffer;\n+import com.lmax.disruptor.Sequence;\n+import com.lmax.disruptor.SequenceBarrier;\n+import com.lmax.disruptor.WaitStrategy;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.LockSupport;\n+\n+/**\n+ * Correlates {@link ActivationEvent}s with {@link StackFrame}s which are recorded by {@link AsyncProfiler},\n+ * a native <a href=\"http://psy-lob-saw.blogspot.com/2016/06/the-pros-and-cons-of-agct.html\">{@code AsyncGetCallTree}</a>-based\n+ * (and therefore <a href=\"http://psy-lob-saw.blogspot.com/2016/02/why-most-sampling-java-profilers-are.html\"> non safepoint-biased</a>)\n+ * JVMTI agent.\n+ * <p>\n+ * Recording of {@link ActivationEvent}s:\n+ * </p>\n+ * <p>\n+ * The {@link #onActivation} and {@link #onDeactivation} methods are called by {@link ProfilingActivationListener}\n+ * which register an {@link ActivationEvent} in to a {@linkplain #eventBuffer ring buffer} whenever a {@link Span}\n+ * gets {@link Span#activate()}d or {@link Span#deactivate()}d while a {@linkplain #profilingSessionOngoing profiling session is ongoing}.\n+ * A background thread consumes the {@link ActivationEvent}s and writes them to a {@linkplain #activationEventBuffer memory-mapped file}.\n+ * That is necessary because within a profiling session (which lasts 10s by default) there may be many more {@link ActivationEvent}s\n+ * than the ring buffer can hold {@link #RING_BUFFER_SIZE}.\n+ * The file can hold {@link #ACTIVATION_EVENTS_IN_FILE} events and each is {@link ActivationEvent#SERIALIZED_SIZE} in size.\n+ * This process is completely garbage free thanks to the {@link RingBuffer} acting as an object pool for {@link ActivationEvent}s.\n+ * </p>\n+ * <p>\n+ * Recording stack traces:\n+ * </p>\n+ * <p>\n+ * The same background thread that processes the {@link ActivationEvent}s starts the wall clock profiler of async-profiler via\n+ * {@link AsyncProfiler#execute(String)}.\n+ * After the {@link ProfilingConfiguration#getProfilingDuration()} is over it stops the profiling and starts processing the JFR file created\n+ * by async-profiler with {@link JfrParser}.\n+ * </p>\n+ * <p>\n+ * Correlating {@link ActivationEvent}s with the traces recorded by {@link AsyncProfiler}:\n+ * </p>\n+ * <p>\n+ * After both the JFR file and the memory-mapped file containing the {@link ActivationEvent}s have been written,\n+ * it's now time to process them in tandem by correlating based on thread ids and timestamps.\n+ * The result of this correlation, performed by {@link #processTraces(File)},\n+ * are {@link CallTree}s which are created for each thread which has seen an {@linkplain Span#activate() activation}\n+ * and at least one stack trace.\n+ * Once {@linkplain ActivationEvent#handleDeactivationEvent(SamplingProfiler) handling the deactivation event} of the root span in a thread\n+ * (after which {@link ElasticApmTracer#getActive()} would return {@code null}),\n+ * the {@link CallTree} is {@linkplain CallTree#spanify(CallTree.Root, TraceContext) converted into regular spans}.\n+ * </p>\n+ * <p>\n+ * Overall, the allocation rate does not depend on the number of {@link ActivationEvent}s but only on\n+ * {@link ProfilingConfiguration#getProfilingInterval()} and {@link ProfilingConfiguration#getSamplingInterval()}.\n+ * Having said that, there are some optimizations so that the JFR file is not processed at all if there have not been any\n+ * {@link ActivationEvent} in a given profiling session.\n+ * Also, only if there's a {@link CallTree.Root} for a {@link StackTraceEvent},\n+ * we will {@link JfrParser#getStackTrace(long, boolean, List) resolve the full stack trace}.\n+ * </p>\n+ */\n+public class SamplingProfiler implements Runnable, LifecycleListener {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(SamplingProfiler.class);\n+    private static final int ACTIVATION_EVENTS_IN_FILE = 100_000;\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> ACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder<?> active, TraceContextHolder<?> previouslyActive) {\n+                event.activation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> DEACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder active, TraceContextHolder previouslyActive) {\n+                event.deactivation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    // sizeof(ActivationEvent) is 176B so the ring buffer should be around 880KiB\n+    static final int RING_BUFFER_SIZE = 4 * 1024;\n+\n+    private final ProfilingConfiguration config;\n+    private final ScheduledExecutorService scheduler;\n+    private final Long2ObjectHashMap<CallTree.Root> profiledThreads = new Long2ObjectHashMap<>();\n+    private final RingBuffer<ActivationEvent> eventBuffer;\n+    private volatile boolean profilingSessionOngoing = false;\n+    private final Sequence sequence;\n+    private final ElasticApmTracer tracer;\n+    private final NanoClock nanoClock;\n+    private final ObjectPool<CallTree.Root> rootPool;\n+    private final AsyncProfiler asyncProfiler = AsyncProfiler.getInstance();\n+    private final NativeThreadIdToJavaThreadMapper threadMapper = new NativeThreadIdToJavaThreadMapper();\n+    private final MappedByteBuffer activationEventBuffer;\n+    private final EventPoller<ActivationEvent> poller;\n+    private final File activationEventsFile;\n+    private final File jfrFile;\n+    private final WriteActivationEventToFileHandler writeActivationEventToFileHandler = new WriteActivationEventToFileHandler();\n+    private final JfrParser jfrParser = new JfrParser();\n+    private volatile int profilingSessions;\n+\n+    public SamplingProfiler(ElasticApmTracer tracer, NanoClock nanoClock) throws IOException {\n+        this(tracer,\n+            tracer.getConfig(ProfilingConfiguration.class),\n+            ExecutorUtils.createSingleThreadSchedulingDeamonPool(\"apm-sampling-profiler\"),\n+            nanoClock);\n+    }\n+\n+    SamplingProfiler(final ElasticApmTracer tracer, ProfilingConfiguration config, ScheduledExecutorService scheduler, NanoClock nanoClock) throws IOException {\n+        this.tracer = tracer;\n+        this.config = config;\n+        this.scheduler = scheduler;\n+        this.nanoClock = nanoClock;\n+        this.eventBuffer = createRingBuffer();\n+        this.sequence = new Sequence();\n+        // tells the ring buffer to not override slots which have not been read yet\n+        this.eventBuffer.addGatingSequences(sequence);\n+        this.poller = eventBuffer.newPoller();\n+        // call tree roots are pooled so that fast activations/deactivations with no associated stack traces don't cause allocations\n+        this.rootPool = ListBasedObjectPool.<CallTree.Root>ofRecyclable(new ArrayList<CallTree.Root>(), 512, new Allocator<CallTree.Root>() {\n+            @Override\n+            public CallTree.Root createInstance() {\n+                return new CallTree.Root(tracer);\n+            }\n+        });\n+        jfrFile = File.createTempFile(\"apm-traces-\", \".jfr\");\n+        activationEventsFile = File.createTempFile(\"apm-activation-events-\", \".bin\");\n+        try (RandomAccessFile randomAccessFile = new RandomAccessFile(activationEventsFile, \"rw\")) {\n+            activationEventBuffer = randomAccessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, ACTIVATION_EVENTS_IN_FILE * ActivationEvent.SERIALIZED_SIZE);\n+        }\n+    }\n+\n+    private RingBuffer<ActivationEvent> createRingBuffer() {\n+        return RingBuffer.<ActivationEvent>createMultiProducer(\n+            new EventFactory<ActivationEvent>() {\n+                @Override\n+                public ActivationEvent newInstance() {\n+                    return new ActivationEvent();\n+                }\n+            },\n+            RING_BUFFER_SIZE,\n+            new NoWaitStrategy());\n+    }\n+\n+    /**\n+     * Called whenever a span is activated.\n+     * <p>\n+     * This and {@link #onDeactivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onActivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(ACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    /**\n+     * Called whenever a span is deactivated.\n+     * <p>\n+     * This and {@link #onActivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onDeactivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(DEACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    @Override\n+    public void run() {\n+        profilingSessions++;\n+        if (config.isProfilingDisabled()) {\n+            scheduler.schedule(this, config.getProfilingInterval().getMillis(), TimeUnit.MILLISECONDS);\n+            return;\n+        }\n+\n+        TimeDuration sampleRate = config.getSamplingInterval();\n+        TimeDuration profilingDuration = config.getProfilingDuration();\n+\n+        setProfilingSessionOngoing(true);\n+\n+        logger.debug(\"Start profiling session\");\n+        try {\n+            profile(sampleRate, profilingDuration);\n+        } catch (Exception e) {\n+            logger.error(\"Stopping profiler\", e);\n+            return;\n+        }\n+        logger.debug(\"End profiling session\");\n+\n+        boolean interrupted = Thread.currentThread().isInterrupted();\n+        boolean continueProfilingSession = config.isNonStopProfiling() && !interrupted && config.isProfilingEnabled();\n+        setProfilingSessionOngoing(continueProfilingSession);\n+\n+        if (!interrupted) {\n+            long delay = config.getProfilingInterval().getMillis() - profilingDuration.getMillis();\n+            scheduler.schedule(this, delay, TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private void profile(TimeDuration sampleRate, TimeDuration profilingDuration) throws Exception {\n+        try {\n+            String startMessage = asyncProfiler.execute(\"start,jfr,event=wall,interval=\" + sampleRate.getMillis() + \"ms,alluser,file=\" + jfrFile);\n+            logger.info(startMessage);\n+\n+            consumeActivationEventsFromRingBufferAndWriteToFile(profilingDuration);\n+\n+            String stopMessage = asyncProfiler.execute(\"stop\");\n+            logger.info(stopMessage);\n+\n+            processTraces(jfrFile);\n+        } catch (InterruptedException e) {\n+            asyncProfiler.stop();\n+            Thread.currentThread().interrupt();\n+        }\n+    }\n+\n+    private void consumeActivationEventsFromRingBufferAndWriteToFile(TimeDuration profilingDuration) throws Exception {\n+        resetActivationEventBuffer();\n+        long threshold = System.currentTimeMillis() + profilingDuration.getMillis();\n+        long initialSleep = 100_000;\n+        long maxSleep = 10_000_000;\n+        long sleep = initialSleep;\n+        while (System.currentTimeMillis() < threshold) {\n+            if (activationEventBuffer.hasRemaining()) {\n+                EventPoller.PollState poll = consumeActivationEventsFromRingBufferAndWriteToFile();\n+                if (poll == EventPoller.PollState.PROCESSING) {\n+                    sleep = initialSleep;\n+                } else {\n+                    if (sleep < maxSleep) {\n+                        sleep *= 2;\n+                    }\n+                }\n+                LockSupport.parkNanos(sleep);\n+            } else {\n+                // the file is full, sleep the rest of the profilingDuration\n+                Thread.sleep(Math.max(0, threshold - System.currentTimeMillis()));\n+            }\n+        }\n+    }\n+\n+    private void resetActivationEventBuffer() {\n+        ((Buffer) activationEventBuffer).clear();\n+    }\n+\n+    EventPoller.PollState consumeActivationEventsFromRingBufferAndWriteToFile() throws Exception {\n+        return poller.poll(writeActivationEventToFileHandler);\n+    }\n+\n+    private void processTraces(File file) throws IOException {\n+        if (activationEventBuffer.position() == 0) {\n+            logger.debug(\"No activation events during this period. Skip processing stack traces.\");\n+            return;\n+        }\n+        List<WildcardMatcher> excludedClasses = config.getExcludedClasses();\n+        List<WildcardMatcher> includedClasses = config.getIncludedClasses();\n+        try {\n+            jfrParser.parse(file, excludedClasses, includedClasses);\n+            startProcessingActivationEventsFile();\n+            final SortedSet<StackTraceEvent> stackTraceEvents = getStackTraceEvents(jfrParser);\n+            if (logger.isDebugEnabled()) {\n+                logger.debug(\"Processing {} stack traces\", stackTraceEvents.size());\n+            }\n+            List<StackFrame> stackFrames = new ArrayList<>();\n+            ElasticApmTracer tracer = this.tracer;\n+            ActivationEvent event = new ActivationEvent();\n+            for (StackTraceEvent stackTrace : stackTraceEvents) {\n+                processActivationEventsUpTo(stackTrace.nanoTime, event);\n+                CallTree.Root root = profiledThreads.get(stackTrace.threadId);\n+                if (root != null) {\n+                    jfrParser.getStackTrace(stackTrace.stackTraceId, true, stackFrames);\n+                    root.addStackTrace(tracer, stackFrames, stackTrace.nanoTime);\n+                }\n+                stackFrames.clear();\n+            }\n+        } finally {\n+            jfrParser.resetState();\n+        }\n+    }\n+\n+    /**\n+     * Returns stack trace events of relevant threads sorted by timestamp.\n+     * The events in the JFR file are not in order.\n+     * Even for the same thread, a more recent event might come before an older event.\n+     * In order to be able to correlate stack trace events and activation events, both need to be in order.\n+     *\n+     * Returns only events for threads where at least one activation happened\n+     */\n+    private SortedSet<StackTraceEvent> getStackTraceEvents(JfrParser jfrParser) throws IOException {\n+        final LongHashSet nativeThreadIds = threadMapper.getNativeThreadIds();\n+        final SortedSet<StackTraceEvent> stackTraceEvents = new TreeSet<>();\n+        jfrParser.consumeStackTraces(new JfrParser.StackTraceConsumer() {\n+            @Override\n+            public void onCallTree(int threadId, long stackTraceId, long nanoTime) {\n+                if (nativeThreadIds.contains(threadId)) {\n+                    stackTraceEvents.add(new StackTraceEvent(nanoTime, stackTraceId, threadId));\n+                }\n+            }\n+        });\n+        return stackTraceEvents;\n+    }\n+\n+    void processActivationEventsUpTo(long timestamp) {\n+        processActivationEventsUpTo(timestamp, new ActivationEvent());\n+    }\n+\n+    public void processActivationEventsUpTo(long timestamp, ActivationEvent event) {\n+        MappedByteBuffer buf = this.activationEventBuffer;\n+        while (buf.hasRemaining()) {\n+            long eventTimestamp = peekLong(buf);\n+            if (eventTimestamp <= timestamp) {\n+                event.deserialize(buf);\n+                event.handle(this);\n+            } else {\n+                return;\n+            }\n+        }\n+    }\n+\n+    private static long peekLong(ByteBuffer buf) {\n+        int pos = buf.position();\n+        try {\n+            return buf.getLong();\n+        } finally {\n+            ((Buffer) buf).position(pos);\n+        }\n+    }\n+\n+    @Override\n+    public void start(ElasticApmTracer tracer) {\n+        if (config.isProfilingEnabled()) {", "originalCommit": "886c4ce259e9765a2e399d30a99e3f03d9981b3d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjMzMjE3NA==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366332174", "bodyText": "Is this required? If you always parse activation events in the right order, then the state of the profiledThreads map should always indicate whether an activation event for a thread is a root or not- if there is one for the thread, it is not a root, otherwise it is. Am I missing something?", "author": "eyalkoren", "createdAt": "2020-01-14T13:19:07Z", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.configuration.converter.TimeDuration;\n+import co.elastic.apm.agent.context.LifecycleListener;\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.impl.transaction.TraceContextHolder;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Allocator;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.impl.ListBasedObjectPool;\n+import co.elastic.apm.agent.profiler.asyncprofiler.AsyncProfiler;\n+import co.elastic.apm.agent.profiler.asyncprofiler.JfrParser;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.LongHashSet;\n+import co.elastic.apm.agent.util.ExecutorUtils;\n+import com.lmax.disruptor.EventFactory;\n+import com.lmax.disruptor.EventPoller;\n+import com.lmax.disruptor.EventTranslatorTwoArg;\n+import com.lmax.disruptor.RingBuffer;\n+import com.lmax.disruptor.Sequence;\n+import com.lmax.disruptor.SequenceBarrier;\n+import com.lmax.disruptor.WaitStrategy;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.LockSupport;\n+\n+/**\n+ * Correlates {@link ActivationEvent}s with {@link StackFrame}s which are recorded by {@link AsyncProfiler},\n+ * a native <a href=\"http://psy-lob-saw.blogspot.com/2016/06/the-pros-and-cons-of-agct.html\">{@code AsyncGetCallTree}</a>-based\n+ * (and therefore <a href=\"http://psy-lob-saw.blogspot.com/2016/02/why-most-sampling-java-profilers-are.html\"> non safepoint-biased</a>)\n+ * JVMTI agent.\n+ * <p>\n+ * Recording of {@link ActivationEvent}s:\n+ * </p>\n+ * <p>\n+ * The {@link #onActivation} and {@link #onDeactivation} methods are called by {@link ProfilingActivationListener}\n+ * which register an {@link ActivationEvent} in to a {@linkplain #eventBuffer ring buffer} whenever a {@link Span}\n+ * gets {@link Span#activate()}d or {@link Span#deactivate()}d while a {@linkplain #profilingSessionOngoing profiling session is ongoing}.\n+ * A background thread consumes the {@link ActivationEvent}s and writes them to a {@linkplain #activationEventBuffer memory-mapped file}.\n+ * That is necessary because within a profiling session (which lasts 10s by default) there may be many more {@link ActivationEvent}s\n+ * than the ring buffer can hold {@link #RING_BUFFER_SIZE}.\n+ * The file can hold {@link #ACTIVATION_EVENTS_IN_FILE} events and each is {@link ActivationEvent#SERIALIZED_SIZE} in size.\n+ * This process is completely garbage free thanks to the {@link RingBuffer} acting as an object pool for {@link ActivationEvent}s.\n+ * </p>\n+ * <p>\n+ * Recording stack traces:\n+ * </p>\n+ * <p>\n+ * The same background thread that processes the {@link ActivationEvent}s starts the wall clock profiler of async-profiler via\n+ * {@link AsyncProfiler#execute(String)}.\n+ * After the {@link ProfilingConfiguration#getProfilingDuration()} is over it stops the profiling and starts processing the JFR file created\n+ * by async-profiler with {@link JfrParser}.\n+ * </p>\n+ * <p>\n+ * Correlating {@link ActivationEvent}s with the traces recorded by {@link AsyncProfiler}:\n+ * </p>\n+ * <p>\n+ * After both the JFR file and the memory-mapped file containing the {@link ActivationEvent}s have been written,\n+ * it's now time to process them in tandem by correlating based on thread ids and timestamps.\n+ * The result of this correlation, performed by {@link #processTraces(File)},\n+ * are {@link CallTree}s which are created for each thread which has seen an {@linkplain Span#activate() activation}\n+ * and at least one stack trace.\n+ * Once {@linkplain ActivationEvent#handleDeactivationEvent(SamplingProfiler) handling the deactivation event} of the root span in a thread\n+ * (after which {@link ElasticApmTracer#getActive()} would return {@code null}),\n+ * the {@link CallTree} is {@linkplain CallTree#spanify(CallTree.Root, TraceContext) converted into regular spans}.\n+ * </p>\n+ * <p>\n+ * Overall, the allocation rate does not depend on the number of {@link ActivationEvent}s but only on\n+ * {@link ProfilingConfiguration#getProfilingInterval()} and {@link ProfilingConfiguration#getSamplingInterval()}.\n+ * Having said that, there are some optimizations so that the JFR file is not processed at all if there have not been any\n+ * {@link ActivationEvent} in a given profiling session.\n+ * Also, only if there's a {@link CallTree.Root} for a {@link StackTraceEvent},\n+ * we will {@link JfrParser#getStackTrace(long, boolean, List) resolve the full stack trace}.\n+ * </p>\n+ */\n+public class SamplingProfiler implements Runnable, LifecycleListener {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(SamplingProfiler.class);\n+    private static final int ACTIVATION_EVENTS_IN_FILE = 100_000;\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> ACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder<?> active, TraceContextHolder<?> previouslyActive) {\n+                event.activation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> DEACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder active, TraceContextHolder previouslyActive) {\n+                event.deactivation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    // sizeof(ActivationEvent) is 176B so the ring buffer should be around 880KiB\n+    static final int RING_BUFFER_SIZE = 4 * 1024;\n+\n+    private final ProfilingConfiguration config;\n+    private final ScheduledExecutorService scheduler;\n+    private final Long2ObjectHashMap<CallTree.Root> profiledThreads = new Long2ObjectHashMap<>();\n+    private final RingBuffer<ActivationEvent> eventBuffer;\n+    private volatile boolean profilingSessionOngoing = false;\n+    private final Sequence sequence;\n+    private final ElasticApmTracer tracer;\n+    private final NanoClock nanoClock;\n+    private final ObjectPool<CallTree.Root> rootPool;\n+    private final AsyncProfiler asyncProfiler = AsyncProfiler.getInstance();\n+    private final NativeThreadIdToJavaThreadMapper threadMapper = new NativeThreadIdToJavaThreadMapper();\n+    private final MappedByteBuffer activationEventBuffer;\n+    private final EventPoller<ActivationEvent> poller;\n+    private final File activationEventsFile;\n+    private final File jfrFile;\n+    private final WriteActivationEventToFileHandler writeActivationEventToFileHandler = new WriteActivationEventToFileHandler();\n+    private final JfrParser jfrParser = new JfrParser();\n+    private volatile int profilingSessions;\n+\n+    public SamplingProfiler(ElasticApmTracer tracer, NanoClock nanoClock) throws IOException {\n+        this(tracer,\n+            tracer.getConfig(ProfilingConfiguration.class),\n+            ExecutorUtils.createSingleThreadSchedulingDeamonPool(\"apm-sampling-profiler\"),\n+            nanoClock);\n+    }\n+\n+    SamplingProfiler(final ElasticApmTracer tracer, ProfilingConfiguration config, ScheduledExecutorService scheduler, NanoClock nanoClock) throws IOException {\n+        this.tracer = tracer;\n+        this.config = config;\n+        this.scheduler = scheduler;\n+        this.nanoClock = nanoClock;\n+        this.eventBuffer = createRingBuffer();\n+        this.sequence = new Sequence();\n+        // tells the ring buffer to not override slots which have not been read yet\n+        this.eventBuffer.addGatingSequences(sequence);\n+        this.poller = eventBuffer.newPoller();\n+        // call tree roots are pooled so that fast activations/deactivations with no associated stack traces don't cause allocations\n+        this.rootPool = ListBasedObjectPool.<CallTree.Root>ofRecyclable(new ArrayList<CallTree.Root>(), 512, new Allocator<CallTree.Root>() {\n+            @Override\n+            public CallTree.Root createInstance() {\n+                return new CallTree.Root(tracer);\n+            }\n+        });\n+        jfrFile = File.createTempFile(\"apm-traces-\", \".jfr\");\n+        activationEventsFile = File.createTempFile(\"apm-activation-events-\", \".bin\");\n+        try (RandomAccessFile randomAccessFile = new RandomAccessFile(activationEventsFile, \"rw\")) {\n+            activationEventBuffer = randomAccessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, ACTIVATION_EVENTS_IN_FILE * ActivationEvent.SERIALIZED_SIZE);\n+        }\n+    }\n+\n+    private RingBuffer<ActivationEvent> createRingBuffer() {\n+        return RingBuffer.<ActivationEvent>createMultiProducer(\n+            new EventFactory<ActivationEvent>() {\n+                @Override\n+                public ActivationEvent newInstance() {\n+                    return new ActivationEvent();\n+                }\n+            },\n+            RING_BUFFER_SIZE,\n+            new NoWaitStrategy());\n+    }\n+\n+    /**\n+     * Called whenever a span is activated.\n+     * <p>\n+     * This and {@link #onDeactivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onActivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(ACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    /**\n+     * Called whenever a span is deactivated.\n+     * <p>\n+     * This and {@link #onActivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onDeactivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            return eventBuffer.tryPublishEvent(DEACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+        }\n+        return false;\n+    }\n+\n+    @Override\n+    public void run() {\n+        profilingSessions++;\n+        if (config.isProfilingDisabled()) {\n+            scheduler.schedule(this, config.getProfilingInterval().getMillis(), TimeUnit.MILLISECONDS);\n+            return;\n+        }\n+\n+        TimeDuration sampleRate = config.getSamplingInterval();\n+        TimeDuration profilingDuration = config.getProfilingDuration();\n+\n+        setProfilingSessionOngoing(true);\n+\n+        logger.debug(\"Start profiling session\");\n+        try {\n+            profile(sampleRate, profilingDuration);\n+        } catch (Exception e) {\n+            logger.error(\"Stopping profiler\", e);\n+            return;\n+        }\n+        logger.debug(\"End profiling session\");\n+\n+        boolean interrupted = Thread.currentThread().isInterrupted();\n+        boolean continueProfilingSession = config.isNonStopProfiling() && !interrupted && config.isProfilingEnabled();\n+        setProfilingSessionOngoing(continueProfilingSession);\n+\n+        if (!interrupted) {\n+            long delay = config.getProfilingInterval().getMillis() - profilingDuration.getMillis();\n+            scheduler.schedule(this, delay, TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private void profile(TimeDuration sampleRate, TimeDuration profilingDuration) throws Exception {\n+        try {\n+            String startMessage = asyncProfiler.execute(\"start,jfr,event=wall,interval=\" + sampleRate.getMillis() + \"ms,alluser,file=\" + jfrFile);\n+            logger.info(startMessage);\n+\n+            consumeActivationEventsFromRingBufferAndWriteToFile(profilingDuration);\n+\n+            String stopMessage = asyncProfiler.execute(\"stop\");\n+            logger.info(stopMessage);\n+\n+            processTraces(jfrFile);\n+        } catch (InterruptedException e) {\n+            asyncProfiler.stop();\n+            Thread.currentThread().interrupt();\n+        }\n+    }\n+\n+    private void consumeActivationEventsFromRingBufferAndWriteToFile(TimeDuration profilingDuration) throws Exception {\n+        resetActivationEventBuffer();\n+        long threshold = System.currentTimeMillis() + profilingDuration.getMillis();\n+        long initialSleep = 100_000;\n+        long maxSleep = 10_000_000;\n+        long sleep = initialSleep;\n+        while (System.currentTimeMillis() < threshold) {\n+            if (activationEventBuffer.hasRemaining()) {\n+                EventPoller.PollState poll = consumeActivationEventsFromRingBufferAndWriteToFile();\n+                if (poll == EventPoller.PollState.PROCESSING) {\n+                    sleep = initialSleep;\n+                } else {\n+                    if (sleep < maxSleep) {\n+                        sleep *= 2;\n+                    }\n+                }\n+                LockSupport.parkNanos(sleep);\n+            } else {\n+                // the file is full, sleep the rest of the profilingDuration\n+                Thread.sleep(Math.max(0, threshold - System.currentTimeMillis()));\n+            }\n+        }\n+    }\n+\n+    private void resetActivationEventBuffer() {\n+        ((Buffer) activationEventBuffer).clear();\n+    }\n+\n+    EventPoller.PollState consumeActivationEventsFromRingBufferAndWriteToFile() throws Exception {\n+        return poller.poll(writeActivationEventToFileHandler);\n+    }\n+\n+    private void processTraces(File file) throws IOException {\n+        if (activationEventBuffer.position() == 0) {\n+            logger.debug(\"No activation events during this period. Skip processing stack traces.\");\n+            return;\n+        }\n+        List<WildcardMatcher> excludedClasses = config.getExcludedClasses();\n+        List<WildcardMatcher> includedClasses = config.getIncludedClasses();\n+        try {\n+            jfrParser.parse(file, excludedClasses, includedClasses);\n+            startProcessingActivationEventsFile();\n+            final SortedSet<StackTraceEvent> stackTraceEvents = getStackTraceEvents(jfrParser);\n+            if (logger.isDebugEnabled()) {\n+                logger.debug(\"Processing {} stack traces\", stackTraceEvents.size());\n+            }\n+            List<StackFrame> stackFrames = new ArrayList<>();\n+            ElasticApmTracer tracer = this.tracer;\n+            ActivationEvent event = new ActivationEvent();\n+            for (StackTraceEvent stackTrace : stackTraceEvents) {\n+                processActivationEventsUpTo(stackTrace.nanoTime, event);\n+                CallTree.Root root = profiledThreads.get(stackTrace.threadId);\n+                if (root != null) {\n+                    jfrParser.getStackTrace(stackTrace.stackTraceId, true, stackFrames);\n+                    root.addStackTrace(tracer, stackFrames, stackTrace.nanoTime);\n+                }\n+                stackFrames.clear();\n+            }\n+        } finally {\n+            jfrParser.resetState();\n+        }\n+    }\n+\n+    /**\n+     * Returns stack trace events of relevant threads sorted by timestamp.\n+     * The events in the JFR file are not in order.\n+     * Even for the same thread, a more recent event might come before an older event.\n+     * In order to be able to correlate stack trace events and activation events, both need to be in order.\n+     *\n+     * Returns only events for threads where at least one activation happened\n+     */\n+    private SortedSet<StackTraceEvent> getStackTraceEvents(JfrParser jfrParser) throws IOException {\n+        final LongHashSet nativeThreadIds = threadMapper.getNativeThreadIds();\n+        final SortedSet<StackTraceEvent> stackTraceEvents = new TreeSet<>();\n+        jfrParser.consumeStackTraces(new JfrParser.StackTraceConsumer() {\n+            @Override\n+            public void onCallTree(int threadId, long stackTraceId, long nanoTime) {\n+                if (nativeThreadIds.contains(threadId)) {\n+                    stackTraceEvents.add(new StackTraceEvent(nanoTime, stackTraceId, threadId));\n+                }\n+            }\n+        });\n+        return stackTraceEvents;\n+    }\n+\n+    void processActivationEventsUpTo(long timestamp) {\n+        processActivationEventsUpTo(timestamp, new ActivationEvent());\n+    }\n+\n+    public void processActivationEventsUpTo(long timestamp, ActivationEvent event) {\n+        MappedByteBuffer buf = this.activationEventBuffer;\n+        while (buf.hasRemaining()) {\n+            long eventTimestamp = peekLong(buf);\n+            if (eventTimestamp <= timestamp) {\n+                event.deserialize(buf);\n+                event.handle(this);\n+            } else {\n+                return;\n+            }\n+        }\n+    }\n+\n+    private static long peekLong(ByteBuffer buf) {\n+        int pos = buf.position();\n+        try {\n+            return buf.getLong();\n+        } finally {\n+            ((Buffer) buf).position(pos);\n+        }\n+    }\n+\n+    @Override\n+    public void start(ElasticApmTracer tracer) {\n+        if (config.isProfilingEnabled()) {\n+            scheduler.submit(this);\n+        }\n+    }\n+\n+    @Override\n+    public void stop() throws Exception {\n+        // cancels/interrupts the profiling thread\n+        scheduler.shutdownNow();\n+        if (!jfrFile.delete()) {\n+            jfrFile.deleteOnExit();\n+        }\n+        if (!activationEventsFile.delete()) {\n+            activationEventsFile.deleteOnExit();\n+        }\n+    }\n+\n+    void setProfilingSessionOngoing(boolean profilingSessionOngoing) {\n+        this.profilingSessionOngoing = profilingSessionOngoing;\n+        if (!profilingSessionOngoing) {\n+            profiledThreads.clear();\n+        }\n+    }\n+\n+    void startProcessingActivationEventsFile() {\n+        ((Buffer) activationEventBuffer).flip();\n+    }\n+\n+    // for testing\n+    CallTree.Root getRoot() {\n+        return profiledThreads.get(threadMapper.getNativeThreadId());\n+    }\n+\n+    void clear() {\n+        profiledThreads.clear();\n+        // consume all remaining events from the ring buffer\n+        try {\n+            poller.poll(new EventPoller.Handler<ActivationEvent>() {\n+                @Override\n+                public boolean onEvent(ActivationEvent event, long sequence, boolean endOfBatch) {\n+                    SamplingProfiler.this.sequence.set(sequence);\n+                    return true;\n+                }\n+            });\n+        } catch (Exception e) {\n+            throw new RuntimeException(e);\n+        }\n+        resetActivationEventBuffer();\n+    }\n+\n+    int getProfilingSessions() {\n+        return profilingSessions;\n+    }\n+    // --\n+\n+    private static class StackTraceEvent implements Comparable<StackTraceEvent> {\n+        private final long nanoTime;\n+        private final long stackTraceId;\n+        private final int threadId;\n+\n+        private StackTraceEvent(long nanoTime, long stackTraceId, int threadId) {\n+            this.nanoTime = nanoTime;\n+            this.stackTraceId = stackTraceId;\n+            this.threadId = threadId;\n+        }\n+\n+        @Override\n+        public int compareTo(StackTraceEvent o) {\n+            return Long.compare(nanoTime, o.nanoTime);\n+        }\n+    }\n+\n+    private static class ActivationEvent {\n+        public static final int SERIALIZED_SIZE =\n+            Long.SIZE / Byte.SIZE + // timestamp\n+                Short.SIZE / Byte.SIZE + // serviceName index\n+                TraceContext.SERIALIZED_LENGTH + // traceContextBuffer\n+                TraceContext.SERIALIZED_LENGTH + // previousContextBuffer\n+                1 + // rootContext\n+                Long.SIZE / Byte.SIZE + // threadId\n+                1; // activation\n+\n+        private static final Map<String, Short> serviceNameMap = new HashMap<>();\n+        private static final Map<Short, String> serviceNameBackMap = new HashMap<>();\n+\n+        private long timestamp;\n+        @Nullable\n+        private String serviceName;\n+        private byte[] traceContextBuffer = new byte[TraceContext.SERIALIZED_LENGTH];\n+        private byte[] previousContextBuffer = new byte[TraceContext.SERIALIZED_LENGTH];\n+        private boolean rootContext;", "originalCommit": "886c4ce259e9765a2e399d30a99e3f03d9981b3d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQyNTgwMQ==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367425801", "bodyText": "There is a chance that we lose events in case the ring buffer is full.", "author": "felixbarny", "createdAt": "2020-01-16T13:48:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjMzMjE3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjMzOTk3NQ==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366339975", "bodyText": "Consider pooling CallTree objects.", "author": "eyalkoren", "createdAt": "2020-01-14T13:35:35Z", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/CallTree.java", "diffHunk": "@@ -0,0 +1,422 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.ListIterator;\n+import java.util.Objects;\n+\n+/**\n+ * Converts a sequence of stack traces into a tree structure of method calls.\n+ * <pre>\n+ *             count\n+ *  b b     a      4\n+ * aaaa ->  \u251c\u2500b    1\n+ *          \u2514\u2500b    1\n+ * </pre>\n+ * <p>\n+ * It also stores information about which span is the parent of a particular call tree node,\n+ * based on which span has been {@linkplain ElasticApmTracer#getActive() active} at that time.\n+ * </p>\n+ * <p>\n+ * This allows to {@linkplain Root#spanify() infer spans from the call tree} which have the correct parent/child relationships\n+ * with the regular spans.\n+ * </p>\n+ */\n+public class CallTree implements Recyclable {\n+\n+    @Nullable\n+    private CallTree parent;\n+    protected int count;\n+    private List<CallTree> children = new ArrayList<>();\n+    @Nullable\n+    private StackFrame frame;\n+    protected long start;\n+    private long lastSeen;\n+    private boolean ended;\n+    private long activationTimestamp = -1;\n+    @Nullable\n+    private TraceContext activeContext;\n+    private long deactivationTimestamp = -1;\n+    private boolean isSpan;\n+\n+    public CallTree() {\n+    }\n+\n+    public void set(@Nullable CallTree parent, StackFrame frame, long nanoTime) {\n+        this.parent = parent;\n+        this.frame = frame;\n+        this.start = nanoTime;\n+    }\n+\n+    public void activation(TraceContext traceContext, long activationTimestamp) {\n+        this.activeContext = traceContext;\n+        this.activationTimestamp = activationTimestamp;\n+    }\n+\n+    protected void handleDeactivation(TraceContext deactivatedSpan, long timestamp) {\n+        if (deactivatedSpan.equals(activeContext)) {\n+            deactivationTimestamp = timestamp;\n+        } else {\n+            CallTree lastChild = getLastChild();\n+            if (lastChild != null && !lastChild.isEnded()) {\n+                lastChild.handleDeactivation(deactivatedSpan, timestamp);\n+            }\n+        }\n+    }\n+\n+    public static CallTree.Root createRoot(ObjectPool<CallTree.Root> rootPool, byte[] traceContext, @Nullable String serviceName, long nanoTime) {\n+        CallTree.Root root = rootPool.createInstance();\n+        root.set(traceContext, serviceName, nanoTime);\n+        return root;\n+    }\n+\n+    protected void addFrame(ListIterator<StackFrame> iterator, @Nullable TraceContext traceContext, long activationTimestamp, long nanoTime) {\n+        count++;\n+        lastSeen = nanoTime;\n+        //     c ee   <- traceContext not set - they are not a child of the active span but the frame below them\n+        //   bbb dd   <- traceContext set\n+        //   ------   <- all new CallTree during this period should have the traceContext set\n+        // a aaaaaa a\n+        //  |      |\n+        // active  deactive\n+\n+        // this branch is already aware of the activation\n+        if (Objects.equals(this.activeContext, traceContext)) {\n+            traceContext = null;\n+        }\n+\n+        CallTree lastChild = getLastChild();\n+        // if the frame corresponding to the last child is not in the stack trace\n+        // it's assumed to have ended one tick ago\n+        boolean endChild = true;\n+        if (iterator.hasPrevious()) {\n+            final StackFrame frame = iterator.previous();\n+            if (lastChild != null) {\n+                if (!lastChild.isEnded() && frame.equals(lastChild.frame)) {\n+                    lastChild.addFrame(iterator, traceContext, activationTimestamp, nanoTime);\n+                    endChild = false;\n+                } else {\n+                    addChild(frame, iterator, traceContext, activationTimestamp, nanoTime);\n+                }\n+            } else {\n+                addChild(frame, iterator, traceContext, activationTimestamp, nanoTime);\n+            }\n+        }\n+        if (lastChild != null && !lastChild.isEnded() && endChild) {\n+            lastChild.end();\n+        }\n+    }\n+\n+    void addChild(StackFrame frame, ListIterator<StackFrame> iterator, @Nullable TraceContext traceContext, long activationTimestamp, long nanoTime) {\n+        CallTree callTree = new CallTree();", "originalCommit": "886c4ce259e9765a2e399d30a99e3f03d9981b3d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Njc1Nzk4NQ==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366757985", "bodyText": "Log if it IS null", "author": "eyalkoren", "createdAt": "2020-01-15T09:00:59Z", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/CallTree.java", "diffHunk": "@@ -0,0 +1,422 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.ListIterator;\n+import java.util.Objects;\n+\n+/**\n+ * Converts a sequence of stack traces into a tree structure of method calls.\n+ * <pre>\n+ *             count\n+ *  b b     a      4\n+ * aaaa ->  \u251c\u2500b    1\n+ *          \u2514\u2500b    1\n+ * </pre>\n+ * <p>\n+ * It also stores information about which span is the parent of a particular call tree node,\n+ * based on which span has been {@linkplain ElasticApmTracer#getActive() active} at that time.\n+ * </p>\n+ * <p>\n+ * This allows to {@linkplain Root#spanify() infer spans from the call tree} which have the correct parent/child relationships\n+ * with the regular spans.\n+ * </p>\n+ */\n+public class CallTree implements Recyclable {\n+\n+    @Nullable\n+    private CallTree parent;\n+    protected int count;\n+    private List<CallTree> children = new ArrayList<>();\n+    @Nullable\n+    private StackFrame frame;\n+    protected long start;\n+    private long lastSeen;\n+    private boolean ended;\n+    private long activationTimestamp = -1;\n+    @Nullable\n+    private TraceContext activeContext;\n+    private long deactivationTimestamp = -1;\n+    private boolean isSpan;\n+\n+    public CallTree() {\n+    }\n+\n+    public void set(@Nullable CallTree parent, StackFrame frame, long nanoTime) {\n+        this.parent = parent;\n+        this.frame = frame;\n+        this.start = nanoTime;\n+    }\n+\n+    public void activation(TraceContext traceContext, long activationTimestamp) {\n+        this.activeContext = traceContext;\n+        this.activationTimestamp = activationTimestamp;\n+    }\n+\n+    protected void handleDeactivation(TraceContext deactivatedSpan, long timestamp) {\n+        if (deactivatedSpan.equals(activeContext)) {\n+            deactivationTimestamp = timestamp;\n+        } else {\n+            CallTree lastChild = getLastChild();\n+            if (lastChild != null && !lastChild.isEnded()) {\n+                lastChild.handleDeactivation(deactivatedSpan, timestamp);\n+            }\n+        }\n+    }\n+\n+    public static CallTree.Root createRoot(ObjectPool<CallTree.Root> rootPool, byte[] traceContext, @Nullable String serviceName, long nanoTime) {\n+        CallTree.Root root = rootPool.createInstance();\n+        root.set(traceContext, serviceName, nanoTime);\n+        return root;\n+    }\n+\n+    protected void addFrame(ListIterator<StackFrame> iterator, @Nullable TraceContext traceContext, long activationTimestamp, long nanoTime) {\n+        count++;\n+        lastSeen = nanoTime;\n+        //     c ee   <- traceContext not set - they are not a child of the active span but the frame below them\n+        //   bbb dd   <- traceContext set\n+        //   ------   <- all new CallTree during this period should have the traceContext set\n+        // a aaaaaa a\n+        //  |      |\n+        // active  deactive\n+\n+        // this branch is already aware of the activation\n+        if (Objects.equals(this.activeContext, traceContext)) {\n+            traceContext = null;\n+        }\n+\n+        CallTree lastChild = getLastChild();\n+        // if the frame corresponding to the last child is not in the stack trace\n+        // it's assumed to have ended one tick ago\n+        boolean endChild = true;\n+        if (iterator.hasPrevious()) {\n+            final StackFrame frame = iterator.previous();\n+            if (lastChild != null) {\n+                if (!lastChild.isEnded() && frame.equals(lastChild.frame)) {\n+                    lastChild.addFrame(iterator, traceContext, activationTimestamp, nanoTime);\n+                    endChild = false;\n+                } else {\n+                    addChild(frame, iterator, traceContext, activationTimestamp, nanoTime);\n+                }\n+            } else {\n+                addChild(frame, iterator, traceContext, activationTimestamp, nanoTime);\n+            }\n+        }\n+        if (lastChild != null && !lastChild.isEnded() && endChild) {\n+            lastChild.end();\n+        }\n+    }\n+\n+    void addChild(StackFrame frame, ListIterator<StackFrame> iterator, @Nullable TraceContext traceContext, long activationTimestamp, long nanoTime) {\n+        CallTree callTree = new CallTree();\n+        callTree.set(this, frame, nanoTime);\n+        if (traceContext != null) {\n+            callTree.activation(traceContext, activationTimestamp);\n+        }\n+        children.add(callTree);\n+        callTree.addFrame(iterator, null, activationTimestamp, nanoTime);\n+    }\n+\n+    long getDurationUs() {\n+        return (lastSeen - start) / 1000;\n+    }\n+\n+    public int getCount() {\n+        return count;\n+    }\n+\n+    public StackFrame getFrame() {\n+        return frame;\n+    }\n+\n+    public List<CallTree> getChildren() {\n+        return children;\n+    }\n+\n+    void end() {\n+        ended = true;\n+        // if the parent span has already been deactivated before this call tree node has ended\n+        // it means that this node is actually the parent of the already deactivated span\n+        //                     make b parent of a and pre-date the start of b to the activation of a\n+        // [c        ]    \u2500\u2500\u2510  [a(inferred) ]\n+        // \u2514[a(inferred)]   \u2502  [b(inferred)]\n+        //  [b(infer.) ]    \u2514\u25ba [c        ]\n+        //  \u2514\u2500[d(i.)]          \u2514\u2500\u2500[d(i.)]\n+        // see also profiler.CallTreeTest::testDectivationBeforeEnd\n+        if (deactivationHappenedBeforeEnd()) {\n+            start = Math.min(activationTimestamp, start);\n+            List<CallTree> callTrees = getChildren();\n+            for (int i = 0, size = callTrees.size(); i < size; i++) {\n+                CallTree child = callTrees.get(i);\n+                child.activation(activeContext, activationTimestamp);\n+                child.deactivationTimestamp = deactivationTimestamp;\n+                // re-run this logic for all children, even if they have already ended\n+                child.end();\n+            }\n+            activeContext = null;\n+            activationTimestamp = -1;\n+            deactivationTimestamp = -1;\n+        }\n+        CallTree lastChild = getLastChild();\n+        if (lastChild != null && !lastChild.isEnded()) {\n+            lastChild.end();\n+        }\n+    }\n+\n+    private boolean deactivationHappenedBeforeEnd() {\n+        return activeContext != null && deactivationTimestamp > -1 && lastSeen > deactivationTimestamp;\n+    }\n+\n+    public boolean isLeaf() {\n+        return children.isEmpty();\n+    }\n+\n+    /**\n+     * Returns {@code true} if this node has just one child and no self time.\n+     *\n+     * <pre>\n+     *  c\n+     *  b  <- b is a pillar\n+     * aaa\n+     * </pre>\n+     */\n+    private boolean isPillar() {\n+        return children.size() == 1 && children.get(0).count == count;\n+    }\n+\n+    @Nullable\n+    public CallTree getLastChild() {\n+        return children.size() > 0 ? children.get(children.size() - 1) : null;\n+    }\n+\n+    public boolean isEnded() {\n+        return ended;\n+    }\n+\n+    @Override\n+    public String toString() {\n+        StringBuilder sb = new StringBuilder();\n+        try {\n+            toString(sb);\n+        } catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+        return sb.toString();\n+    }\n+\n+    public void toString(Appendable out) throws IOException {\n+        toString(out, 0);\n+    }\n+\n+    private void toString(Appendable out, int level) throws IOException {\n+        for (int i = 0; i < level; i++) {\n+            out.append(\"  \");\n+        }\n+        out.append(frame.getClassName())\n+            .append('.')\n+            .append(frame.getMethodName())\n+            .append(' ').append(Integer.toString(count))\n+            .append('\\n');\n+        for (CallTree node : children) {\n+            node.toString(out, level + 1);\n+        }\n+    }\n+\n+    void spanify(CallTree.Root root, TraceContext parentContext) {\n+        if (activeContext != null) {\n+            parentContext = activeContext;\n+        }\n+        Span span = null;\n+        if (!isPillar() || isLeaf()) {\n+            span = asSpan(root, parentContext);\n+            this.isSpan = true;\n+        }\n+        for (CallTree child : getChildren()) {\n+            child.spanify(root, span != null ? span.getTraceContext() : parentContext);\n+        }\n+        if (span != null) {\n+            span.end(span.getTimestamp() + getDurationUs());\n+        }\n+    }\n+\n+    protected Span asSpan(Root root, TraceContext parentContext) {\n+        Span span = parentContext.createSpan(root.getEpochMicros(this.start))\n+            .withType(\"app\")\n+            .withSubtype(\"inferred\");\n+\n+        frame.appendSimpleClassName(span.getNameForSerialization());\n+        span.appendToName(\"#\");\n+        span.appendToName(frame.getMethodName());\n+\n+        // we're not interested in the very bottom of the stack which contains things like accepting and handling connections\n+        if (!root.traceContext.equals(parentContext)) {\n+            // we're never spanifying the root\n+            assert this.parent != null;\n+            List<StackFrame> stackTrace = new ArrayList<>();\n+            this.parent.fillStackTrace(stackTrace);\n+            span.setStackTrace(stackTrace);\n+        } else {\n+            span.setStackTrace(Collections.<StackFrame>emptyList());\n+        }\n+        return span;\n+    }\n+\n+    /**\n+     * Fill in the stack trace up to the parent span\n+     */\n+    private void fillStackTrace(List<StackFrame> stackTrace) {\n+        if (parent != null && !this.isSpan) {\n+            stackTrace.add(frame);\n+            parent.fillStackTrace(stackTrace);\n+        }\n+    }\n+\n+    public void removeNodesFasterThan(float percent, int minCount) {\n+        int ticks = (int) (count * percent);\n+        removeNodesFasterThan(Math.max(ticks, minCount));\n+    }\n+\n+    public void removeNodesFasterThan(int minCount) {\n+        List<CallTree> callTrees = getChildren();\n+        for (int i = 0; i < callTrees.size(); i++) {\n+            CallTree child = callTrees.get(i);\n+            if (child.count < minCount) {\n+                callTrees.remove(i--);\n+            } else {\n+                child.removeNodesFasterThan(minCount);\n+            }\n+        }\n+    }\n+\n+    @Override\n+    public void resetState() {\n+        parent = null;\n+        count = 0;\n+        frame = null;\n+        start = 0;\n+        lastSeen = 0;\n+        ended = false;\n+        activationTimestamp = -1;\n+        activeContext = null;\n+        deactivationTimestamp = -1;\n+        isSpan = false;\n+        children.clear();\n+    }\n+\n+    /**\n+     * A special kind of a {@link CallTree} node which represents the root of the call tree.\n+     * This acts as the interface to the outside to add new nodes to the tree or to update existing ones by\n+     * {@linkplain #addStackTrace(ElasticApmTracer, List, long) adding stack traces}.\n+     */\n+    public static class Root extends CallTree implements Recyclable {\n+        private static final StackFrame ROOT_FRAME = new StackFrame(\"root\", \"root\");\n+        protected TraceContext traceContext;\n+        private long activationTimestamp;\n+        @Nullable\n+        private TraceContext activeSpan;\n+        private byte[] activeSpanSerialized = new byte[TraceContext.SERIALIZED_LENGTH];\n+\n+        public Root(ElasticApmTracer tracer) {\n+            this.traceContext = TraceContext.with64BitId(tracer);\n+        }\n+\n+        private void set(byte[] traceContext, @Nullable String serviceName, long nanoTime) {\n+            super.set(null, ROOT_FRAME, nanoTime);\n+            this.traceContext.deserialize(traceContext, serviceName);\n+            setActiveSpan(traceContext, nanoTime);\n+        }\n+\n+        public void setActiveSpan(byte[] activeSpanSerialized, long timestamp) {\n+            activationTimestamp = timestamp;\n+            System.arraycopy(activeSpanSerialized, 0, this.activeSpanSerialized, 0, activeSpanSerialized.length);\n+            this.activeSpan = null;\n+        }\n+\n+        public void onActivation(byte[] active, long timestamp) {\n+            setActiveSpan(active, timestamp);\n+        }\n+\n+        public void onDeactivation(byte[] active, long timestamp) {\n+            if (activeSpan != null) {", "originalCommit": "886c4ce259e9765a2e399d30a99e3f03d9981b3d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQyMzAzMQ==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367423031", "bodyText": "That could happen if the ring buffer gets overwhelmed and we miss the activation event. Not sure if logging that helps, but otoh, probably not a big harm either when logged on debug.", "author": "felixbarny", "createdAt": "2020-01-16T13:43:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Njc1Nzk4NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Njc3MDQxNQ==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366770415", "bodyText": "Add a few words on each, at least traceContext, activeSpan and activeSpanSerialized. It will make it easier to understand.\nCan you reuse CallTree#activeContext instead of using activeSpan, or is it used to reflect a special root state (where activeContext is never set)?\nWouldn't traceContext better be called rootContext?", "author": "eyalkoren", "createdAt": "2020-01-15T09:27:53Z", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/CallTree.java", "diffHunk": "@@ -0,0 +1,422 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.ListIterator;\n+import java.util.Objects;\n+\n+/**\n+ * Converts a sequence of stack traces into a tree structure of method calls.\n+ * <pre>\n+ *             count\n+ *  b b     a      4\n+ * aaaa ->  \u251c\u2500b    1\n+ *          \u2514\u2500b    1\n+ * </pre>\n+ * <p>\n+ * It also stores information about which span is the parent of a particular call tree node,\n+ * based on which span has been {@linkplain ElasticApmTracer#getActive() active} at that time.\n+ * </p>\n+ * <p>\n+ * This allows to {@linkplain Root#spanify() infer spans from the call tree} which have the correct parent/child relationships\n+ * with the regular spans.\n+ * </p>\n+ */\n+public class CallTree implements Recyclable {\n+\n+    @Nullable\n+    private CallTree parent;\n+    protected int count;\n+    private List<CallTree> children = new ArrayList<>();\n+    @Nullable\n+    private StackFrame frame;\n+    protected long start;\n+    private long lastSeen;\n+    private boolean ended;\n+    private long activationTimestamp = -1;\n+    @Nullable\n+    private TraceContext activeContext;\n+    private long deactivationTimestamp = -1;\n+    private boolean isSpan;\n+\n+    public CallTree() {\n+    }\n+\n+    public void set(@Nullable CallTree parent, StackFrame frame, long nanoTime) {\n+        this.parent = parent;\n+        this.frame = frame;\n+        this.start = nanoTime;\n+    }\n+\n+    public void activation(TraceContext traceContext, long activationTimestamp) {\n+        this.activeContext = traceContext;\n+        this.activationTimestamp = activationTimestamp;\n+    }\n+\n+    protected void handleDeactivation(TraceContext deactivatedSpan, long timestamp) {\n+        if (deactivatedSpan.equals(activeContext)) {\n+            deactivationTimestamp = timestamp;\n+        } else {\n+            CallTree lastChild = getLastChild();\n+            if (lastChild != null && !lastChild.isEnded()) {\n+                lastChild.handleDeactivation(deactivatedSpan, timestamp);\n+            }\n+        }\n+    }\n+\n+    public static CallTree.Root createRoot(ObjectPool<CallTree.Root> rootPool, byte[] traceContext, @Nullable String serviceName, long nanoTime) {\n+        CallTree.Root root = rootPool.createInstance();\n+        root.set(traceContext, serviceName, nanoTime);\n+        return root;\n+    }\n+\n+    protected void addFrame(ListIterator<StackFrame> iterator, @Nullable TraceContext traceContext, long activationTimestamp, long nanoTime) {\n+        count++;\n+        lastSeen = nanoTime;\n+        //     c ee   <- traceContext not set - they are not a child of the active span but the frame below them\n+        //   bbb dd   <- traceContext set\n+        //   ------   <- all new CallTree during this period should have the traceContext set\n+        // a aaaaaa a\n+        //  |      |\n+        // active  deactive\n+\n+        // this branch is already aware of the activation\n+        if (Objects.equals(this.activeContext, traceContext)) {\n+            traceContext = null;\n+        }\n+\n+        CallTree lastChild = getLastChild();\n+        // if the frame corresponding to the last child is not in the stack trace\n+        // it's assumed to have ended one tick ago\n+        boolean endChild = true;\n+        if (iterator.hasPrevious()) {\n+            final StackFrame frame = iterator.previous();\n+            if (lastChild != null) {\n+                if (!lastChild.isEnded() && frame.equals(lastChild.frame)) {\n+                    lastChild.addFrame(iterator, traceContext, activationTimestamp, nanoTime);\n+                    endChild = false;\n+                } else {\n+                    addChild(frame, iterator, traceContext, activationTimestamp, nanoTime);\n+                }\n+            } else {\n+                addChild(frame, iterator, traceContext, activationTimestamp, nanoTime);\n+            }\n+        }\n+        if (lastChild != null && !lastChild.isEnded() && endChild) {\n+            lastChild.end();\n+        }\n+    }\n+\n+    void addChild(StackFrame frame, ListIterator<StackFrame> iterator, @Nullable TraceContext traceContext, long activationTimestamp, long nanoTime) {\n+        CallTree callTree = new CallTree();\n+        callTree.set(this, frame, nanoTime);\n+        if (traceContext != null) {\n+            callTree.activation(traceContext, activationTimestamp);\n+        }\n+        children.add(callTree);\n+        callTree.addFrame(iterator, null, activationTimestamp, nanoTime);\n+    }\n+\n+    long getDurationUs() {\n+        return (lastSeen - start) / 1000;\n+    }\n+\n+    public int getCount() {\n+        return count;\n+    }\n+\n+    public StackFrame getFrame() {\n+        return frame;\n+    }\n+\n+    public List<CallTree> getChildren() {\n+        return children;\n+    }\n+\n+    void end() {\n+        ended = true;\n+        // if the parent span has already been deactivated before this call tree node has ended\n+        // it means that this node is actually the parent of the already deactivated span\n+        //                     make b parent of a and pre-date the start of b to the activation of a\n+        // [c        ]    \u2500\u2500\u2510  [a(inferred) ]\n+        // \u2514[a(inferred)]   \u2502  [b(inferred)]\n+        //  [b(infer.) ]    \u2514\u25ba [c        ]\n+        //  \u2514\u2500[d(i.)]          \u2514\u2500\u2500[d(i.)]\n+        // see also profiler.CallTreeTest::testDectivationBeforeEnd\n+        if (deactivationHappenedBeforeEnd()) {\n+            start = Math.min(activationTimestamp, start);\n+            List<CallTree> callTrees = getChildren();\n+            for (int i = 0, size = callTrees.size(); i < size; i++) {\n+                CallTree child = callTrees.get(i);\n+                child.activation(activeContext, activationTimestamp);\n+                child.deactivationTimestamp = deactivationTimestamp;\n+                // re-run this logic for all children, even if they have already ended\n+                child.end();\n+            }\n+            activeContext = null;\n+            activationTimestamp = -1;\n+            deactivationTimestamp = -1;\n+        }\n+        CallTree lastChild = getLastChild();\n+        if (lastChild != null && !lastChild.isEnded()) {\n+            lastChild.end();\n+        }\n+    }\n+\n+    private boolean deactivationHappenedBeforeEnd() {\n+        return activeContext != null && deactivationTimestamp > -1 && lastSeen > deactivationTimestamp;\n+    }\n+\n+    public boolean isLeaf() {\n+        return children.isEmpty();\n+    }\n+\n+    /**\n+     * Returns {@code true} if this node has just one child and no self time.\n+     *\n+     * <pre>\n+     *  c\n+     *  b  <- b is a pillar\n+     * aaa\n+     * </pre>\n+     */\n+    private boolean isPillar() {\n+        return children.size() == 1 && children.get(0).count == count;\n+    }\n+\n+    @Nullable\n+    public CallTree getLastChild() {\n+        return children.size() > 0 ? children.get(children.size() - 1) : null;\n+    }\n+\n+    public boolean isEnded() {\n+        return ended;\n+    }\n+\n+    @Override\n+    public String toString() {\n+        StringBuilder sb = new StringBuilder();\n+        try {\n+            toString(sb);\n+        } catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+        return sb.toString();\n+    }\n+\n+    public void toString(Appendable out) throws IOException {\n+        toString(out, 0);\n+    }\n+\n+    private void toString(Appendable out, int level) throws IOException {\n+        for (int i = 0; i < level; i++) {\n+            out.append(\"  \");\n+        }\n+        out.append(frame.getClassName())\n+            .append('.')\n+            .append(frame.getMethodName())\n+            .append(' ').append(Integer.toString(count))\n+            .append('\\n');\n+        for (CallTree node : children) {\n+            node.toString(out, level + 1);\n+        }\n+    }\n+\n+    void spanify(CallTree.Root root, TraceContext parentContext) {\n+        if (activeContext != null) {\n+            parentContext = activeContext;\n+        }\n+        Span span = null;\n+        if (!isPillar() || isLeaf()) {\n+            span = asSpan(root, parentContext);\n+            this.isSpan = true;\n+        }\n+        for (CallTree child : getChildren()) {\n+            child.spanify(root, span != null ? span.getTraceContext() : parentContext);\n+        }\n+        if (span != null) {\n+            span.end(span.getTimestamp() + getDurationUs());\n+        }\n+    }\n+\n+    protected Span asSpan(Root root, TraceContext parentContext) {\n+        Span span = parentContext.createSpan(root.getEpochMicros(this.start))\n+            .withType(\"app\")\n+            .withSubtype(\"inferred\");\n+\n+        frame.appendSimpleClassName(span.getNameForSerialization());\n+        span.appendToName(\"#\");\n+        span.appendToName(frame.getMethodName());\n+\n+        // we're not interested in the very bottom of the stack which contains things like accepting and handling connections\n+        if (!root.traceContext.equals(parentContext)) {\n+            // we're never spanifying the root\n+            assert this.parent != null;\n+            List<StackFrame> stackTrace = new ArrayList<>();\n+            this.parent.fillStackTrace(stackTrace);\n+            span.setStackTrace(stackTrace);\n+        } else {\n+            span.setStackTrace(Collections.<StackFrame>emptyList());\n+        }\n+        return span;\n+    }\n+\n+    /**\n+     * Fill in the stack trace up to the parent span\n+     */\n+    private void fillStackTrace(List<StackFrame> stackTrace) {\n+        if (parent != null && !this.isSpan) {\n+            stackTrace.add(frame);\n+            parent.fillStackTrace(stackTrace);\n+        }\n+    }\n+\n+    public void removeNodesFasterThan(float percent, int minCount) {\n+        int ticks = (int) (count * percent);\n+        removeNodesFasterThan(Math.max(ticks, minCount));\n+    }\n+\n+    public void removeNodesFasterThan(int minCount) {\n+        List<CallTree> callTrees = getChildren();\n+        for (int i = 0; i < callTrees.size(); i++) {\n+            CallTree child = callTrees.get(i);\n+            if (child.count < minCount) {\n+                callTrees.remove(i--);\n+            } else {\n+                child.removeNodesFasterThan(minCount);\n+            }\n+        }\n+    }\n+\n+    @Override\n+    public void resetState() {\n+        parent = null;\n+        count = 0;\n+        frame = null;\n+        start = 0;\n+        lastSeen = 0;\n+        ended = false;\n+        activationTimestamp = -1;\n+        activeContext = null;\n+        deactivationTimestamp = -1;\n+        isSpan = false;\n+        children.clear();\n+    }\n+\n+    /**\n+     * A special kind of a {@link CallTree} node which represents the root of the call tree.\n+     * This acts as the interface to the outside to add new nodes to the tree or to update existing ones by\n+     * {@linkplain #addStackTrace(ElasticApmTracer, List, long) adding stack traces}.\n+     */\n+    public static class Root extends CallTree implements Recyclable {\n+        private static final StackFrame ROOT_FRAME = new StackFrame(\"root\", \"root\");\n+        protected TraceContext traceContext;\n+        private long activationTimestamp;\n+        @Nullable\n+        private TraceContext activeSpan;\n+        private byte[] activeSpanSerialized = new byte[TraceContext.SERIALIZED_LENGTH];", "originalCommit": "886c4ce259e9765a2e399d30a99e3f03d9981b3d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Njc3NDAxMg==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366774012", "bodyText": "It would very useful if you add a detailed explanation about the algorithm as a javadoc of this method. Not all corner-cases handled, but the general concept.", "author": "eyalkoren", "createdAt": "2020-01-15T09:35:38Z", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/CallTree.java", "diffHunk": "@@ -0,0 +1,422 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.ListIterator;\n+import java.util.Objects;\n+\n+/**\n+ * Converts a sequence of stack traces into a tree structure of method calls.\n+ * <pre>\n+ *             count\n+ *  b b     a      4\n+ * aaaa ->  \u251c\u2500b    1\n+ *          \u2514\u2500b    1\n+ * </pre>\n+ * <p>\n+ * It also stores information about which span is the parent of a particular call tree node,\n+ * based on which span has been {@linkplain ElasticApmTracer#getActive() active} at that time.\n+ * </p>\n+ * <p>\n+ * This allows to {@linkplain Root#spanify() infer spans from the call tree} which have the correct parent/child relationships\n+ * with the regular spans.\n+ * </p>\n+ */\n+public class CallTree implements Recyclable {\n+\n+    @Nullable\n+    private CallTree parent;\n+    protected int count;\n+    private List<CallTree> children = new ArrayList<>();\n+    @Nullable\n+    private StackFrame frame;\n+    protected long start;\n+    private long lastSeen;\n+    private boolean ended;\n+    private long activationTimestamp = -1;\n+    @Nullable\n+    private TraceContext activeContext;\n+    private long deactivationTimestamp = -1;\n+    private boolean isSpan;\n+\n+    public CallTree() {\n+    }\n+\n+    public void set(@Nullable CallTree parent, StackFrame frame, long nanoTime) {\n+        this.parent = parent;\n+        this.frame = frame;\n+        this.start = nanoTime;\n+    }\n+\n+    public void activation(TraceContext traceContext, long activationTimestamp) {\n+        this.activeContext = traceContext;\n+        this.activationTimestamp = activationTimestamp;\n+    }\n+\n+    protected void handleDeactivation(TraceContext deactivatedSpan, long timestamp) {\n+        if (deactivatedSpan.equals(activeContext)) {\n+            deactivationTimestamp = timestamp;\n+        } else {\n+            CallTree lastChild = getLastChild();\n+            if (lastChild != null && !lastChild.isEnded()) {\n+                lastChild.handleDeactivation(deactivatedSpan, timestamp);\n+            }\n+        }\n+    }\n+\n+    public static CallTree.Root createRoot(ObjectPool<CallTree.Root> rootPool, byte[] traceContext, @Nullable String serviceName, long nanoTime) {\n+        CallTree.Root root = rootPool.createInstance();\n+        root.set(traceContext, serviceName, nanoTime);\n+        return root;\n+    }\n+\n+    protected void addFrame(ListIterator<StackFrame> iterator, @Nullable TraceContext traceContext, long activationTimestamp, long nanoTime) {", "originalCommit": "886c4ce259e9765a2e399d30a99e3f03d9981b3d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQ3NTkwMA==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367475900", "bodyText": "Added some comments but did not go into details. Do you like it now? Any suggestions what/how to explain specifically?", "author": "felixbarny", "createdAt": "2020-01-16T15:16:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Njc3NDAxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjkxMjI3OQ==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366912279", "bodyText": "I think we should also avoid creating spans when count < 2. If we take snapshots every 20 ms in a 2-second transaction, we may get 100 non-informative spans. More importantly, when someone will compare traces to one another they will seem as there are many arbitrary areas with random spans.", "author": "eyalkoren", "createdAt": "2020-01-15T14:42:24Z", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/CallTree.java", "diffHunk": "@@ -0,0 +1,422 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.ListIterator;\n+import java.util.Objects;\n+\n+/**\n+ * Converts a sequence of stack traces into a tree structure of method calls.\n+ * <pre>\n+ *             count\n+ *  b b     a      4\n+ * aaaa ->  \u251c\u2500b    1\n+ *          \u2514\u2500b    1\n+ * </pre>\n+ * <p>\n+ * It also stores information about which span is the parent of a particular call tree node,\n+ * based on which span has been {@linkplain ElasticApmTracer#getActive() active} at that time.\n+ * </p>\n+ * <p>\n+ * This allows to {@linkplain Root#spanify() infer spans from the call tree} which have the correct parent/child relationships\n+ * with the regular spans.\n+ * </p>\n+ */\n+public class CallTree implements Recyclable {\n+\n+    @Nullable\n+    private CallTree parent;\n+    protected int count;\n+    private List<CallTree> children = new ArrayList<>();\n+    @Nullable\n+    private StackFrame frame;\n+    protected long start;\n+    private long lastSeen;\n+    private boolean ended;\n+    private long activationTimestamp = -1;\n+    @Nullable\n+    private TraceContext activeContext;\n+    private long deactivationTimestamp = -1;\n+    private boolean isSpan;\n+\n+    public CallTree() {\n+    }\n+\n+    public void set(@Nullable CallTree parent, StackFrame frame, long nanoTime) {\n+        this.parent = parent;\n+        this.frame = frame;\n+        this.start = nanoTime;\n+    }\n+\n+    public void activation(TraceContext traceContext, long activationTimestamp) {\n+        this.activeContext = traceContext;\n+        this.activationTimestamp = activationTimestamp;\n+    }\n+\n+    protected void handleDeactivation(TraceContext deactivatedSpan, long timestamp) {\n+        if (deactivatedSpan.equals(activeContext)) {\n+            deactivationTimestamp = timestamp;\n+        } else {\n+            CallTree lastChild = getLastChild();\n+            if (lastChild != null && !lastChild.isEnded()) {\n+                lastChild.handleDeactivation(deactivatedSpan, timestamp);\n+            }\n+        }\n+    }\n+\n+    public static CallTree.Root createRoot(ObjectPool<CallTree.Root> rootPool, byte[] traceContext, @Nullable String serviceName, long nanoTime) {\n+        CallTree.Root root = rootPool.createInstance();\n+        root.set(traceContext, serviceName, nanoTime);\n+        return root;\n+    }\n+\n+    protected void addFrame(ListIterator<StackFrame> iterator, @Nullable TraceContext traceContext, long activationTimestamp, long nanoTime) {\n+        count++;\n+        lastSeen = nanoTime;\n+        //     c ee   <- traceContext not set - they are not a child of the active span but the frame below them\n+        //   bbb dd   <- traceContext set\n+        //   ------   <- all new CallTree during this period should have the traceContext set\n+        // a aaaaaa a\n+        //  |      |\n+        // active  deactive\n+\n+        // this branch is already aware of the activation\n+        if (Objects.equals(this.activeContext, traceContext)) {\n+            traceContext = null;\n+        }\n+\n+        CallTree lastChild = getLastChild();\n+        // if the frame corresponding to the last child is not in the stack trace\n+        // it's assumed to have ended one tick ago\n+        boolean endChild = true;\n+        if (iterator.hasPrevious()) {\n+            final StackFrame frame = iterator.previous();\n+            if (lastChild != null) {\n+                if (!lastChild.isEnded() && frame.equals(lastChild.frame)) {\n+                    lastChild.addFrame(iterator, traceContext, activationTimestamp, nanoTime);\n+                    endChild = false;\n+                } else {\n+                    addChild(frame, iterator, traceContext, activationTimestamp, nanoTime);\n+                }\n+            } else {\n+                addChild(frame, iterator, traceContext, activationTimestamp, nanoTime);\n+            }\n+        }\n+        if (lastChild != null && !lastChild.isEnded() && endChild) {\n+            lastChild.end();\n+        }\n+    }\n+\n+    void addChild(StackFrame frame, ListIterator<StackFrame> iterator, @Nullable TraceContext traceContext, long activationTimestamp, long nanoTime) {\n+        CallTree callTree = new CallTree();\n+        callTree.set(this, frame, nanoTime);\n+        if (traceContext != null) {\n+            callTree.activation(traceContext, activationTimestamp);\n+        }\n+        children.add(callTree);\n+        callTree.addFrame(iterator, null, activationTimestamp, nanoTime);\n+    }\n+\n+    long getDurationUs() {\n+        return (lastSeen - start) / 1000;\n+    }\n+\n+    public int getCount() {\n+        return count;\n+    }\n+\n+    public StackFrame getFrame() {\n+        return frame;\n+    }\n+\n+    public List<CallTree> getChildren() {\n+        return children;\n+    }\n+\n+    void end() {\n+        ended = true;\n+        // if the parent span has already been deactivated before this call tree node has ended\n+        // it means that this node is actually the parent of the already deactivated span\n+        //                     make b parent of a and pre-date the start of b to the activation of a\n+        // [c        ]    \u2500\u2500\u2510  [a(inferred) ]\n+        // \u2514[a(inferred)]   \u2502  [b(inferred)]\n+        //  [b(infer.) ]    \u2514\u25ba [c        ]\n+        //  \u2514\u2500[d(i.)]          \u2514\u2500\u2500[d(i.)]\n+        // see also profiler.CallTreeTest::testDectivationBeforeEnd\n+        if (deactivationHappenedBeforeEnd()) {\n+            start = Math.min(activationTimestamp, start);\n+            List<CallTree> callTrees = getChildren();\n+            for (int i = 0, size = callTrees.size(); i < size; i++) {\n+                CallTree child = callTrees.get(i);\n+                child.activation(activeContext, activationTimestamp);\n+                child.deactivationTimestamp = deactivationTimestamp;\n+                // re-run this logic for all children, even if they have already ended\n+                child.end();\n+            }\n+            activeContext = null;\n+            activationTimestamp = -1;\n+            deactivationTimestamp = -1;\n+        }\n+        CallTree lastChild = getLastChild();\n+        if (lastChild != null && !lastChild.isEnded()) {\n+            lastChild.end();\n+        }\n+    }\n+\n+    private boolean deactivationHappenedBeforeEnd() {\n+        return activeContext != null && deactivationTimestamp > -1 && lastSeen > deactivationTimestamp;\n+    }\n+\n+    public boolean isLeaf() {\n+        return children.isEmpty();\n+    }\n+\n+    /**\n+     * Returns {@code true} if this node has just one child and no self time.\n+     *\n+     * <pre>\n+     *  c\n+     *  b  <- b is a pillar\n+     * aaa\n+     * </pre>\n+     */\n+    private boolean isPillar() {\n+        return children.size() == 1 && children.get(0).count == count;\n+    }\n+\n+    @Nullable\n+    public CallTree getLastChild() {\n+        return children.size() > 0 ? children.get(children.size() - 1) : null;\n+    }\n+\n+    public boolean isEnded() {\n+        return ended;\n+    }\n+\n+    @Override\n+    public String toString() {\n+        StringBuilder sb = new StringBuilder();\n+        try {\n+            toString(sb);\n+        } catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+        return sb.toString();\n+    }\n+\n+    public void toString(Appendable out) throws IOException {\n+        toString(out, 0);\n+    }\n+\n+    private void toString(Appendable out, int level) throws IOException {\n+        for (int i = 0; i < level; i++) {\n+            out.append(\"  \");\n+        }\n+        out.append(frame.getClassName())\n+            .append('.')\n+            .append(frame.getMethodName())\n+            .append(' ').append(Integer.toString(count))\n+            .append('\\n');\n+        for (CallTree node : children) {\n+            node.toString(out, level + 1);\n+        }\n+    }\n+\n+    void spanify(CallTree.Root root, TraceContext parentContext) {\n+        if (activeContext != null) {\n+            parentContext = activeContext;\n+        }\n+        Span span = null;\n+        if (!isPillar() || isLeaf()) {", "originalCommit": "886c4ce259e9765a2e399d30a99e3f03d9981b3d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxNjAxNA==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367416014", "bodyText": "Those are filtered out in a separate step in co.elastic.apm.agent.profiler.CallTree#removeNodesFasterThan(float, int)", "author": "felixbarny", "createdAt": "2020-01-16T13:28:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjkxMjI3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQ1MzY3OA==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367453678", "bodyText": "In the spirit of runtime-call-tree-trimming, you can remove entire branches with count < 2 during the recursive end. If it doesn't complicate stuff too much, maybe worth considering.", "author": "eyalkoren", "createdAt": "2020-01-16T14:40:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjkxMjI3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Njk3ODMwMg==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366978302", "bodyText": "What's the benefit over the queue-based pool?", "author": "eyalkoren", "createdAt": "2020-01-15T16:33:00Z", "path": "apm-agent-core/src/main/java/co/elastic/apm/agent/objectpool/impl/ListBasedObjectPool.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * \n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ * \n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.objectpool.impl;\n+\n+import co.elastic.apm.agent.objectpool.Allocator;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.List;\n+\n+public class ListBasedObjectPool<T> extends AbstractObjectPool<T> {\n+\n+    private final List<T> pool;", "originalCommit": "886c4ce259e9765a2e399d30a99e3f03d9981b3d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzMyMTI3OQ==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367321279", "bodyText": "Mainly that it can be used with a plain ArrayList, useful in single-threaded scenarios. Adding Javadoc.", "author": "felixbarny", "createdAt": "2020-01-16T09:47:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Njk3ODMwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Njk4NTIxOQ==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r366985219", "bodyText": "If you find an easy and cheap way (i.e. without getting the full stack trace) to get Transaction's frame in the root, you can cut all the unnecessary call tree \"trunk\".", "author": "eyalkoren", "createdAt": "2020-01-15T16:45:17Z", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/CallTree.java", "diffHunk": "@@ -0,0 +1,422 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.ListIterator;\n+import java.util.Objects;\n+\n+/**\n+ * Converts a sequence of stack traces into a tree structure of method calls.\n+ * <pre>\n+ *             count\n+ *  b b     a      4\n+ * aaaa ->  \u251c\u2500b    1\n+ *          \u2514\u2500b    1\n+ * </pre>\n+ * <p>\n+ * It also stores information about which span is the parent of a particular call tree node,\n+ * based on which span has been {@linkplain ElasticApmTracer#getActive() active} at that time.\n+ * </p>\n+ * <p>\n+ * This allows to {@linkplain Root#spanify() infer spans from the call tree} which have the correct parent/child relationships\n+ * with the regular spans.\n+ * </p>\n+ */\n+public class CallTree implements Recyclable {\n+\n+    @Nullable\n+    private CallTree parent;\n+    protected int count;\n+    private List<CallTree> children = new ArrayList<>();\n+    @Nullable\n+    private StackFrame frame;\n+    protected long start;\n+    private long lastSeen;\n+    private boolean ended;\n+    private long activationTimestamp = -1;\n+    @Nullable\n+    private TraceContext activeContext;\n+    private long deactivationTimestamp = -1;\n+    private boolean isSpan;\n+\n+    public CallTree() {\n+    }\n+\n+    public void set(@Nullable CallTree parent, StackFrame frame, long nanoTime) {\n+        this.parent = parent;\n+        this.frame = frame;\n+        this.start = nanoTime;\n+    }\n+\n+    public void activation(TraceContext traceContext, long activationTimestamp) {\n+        this.activeContext = traceContext;\n+        this.activationTimestamp = activationTimestamp;\n+    }\n+\n+    protected void handleDeactivation(TraceContext deactivatedSpan, long timestamp) {\n+        if (deactivatedSpan.equals(activeContext)) {\n+            deactivationTimestamp = timestamp;\n+        } else {\n+            CallTree lastChild = getLastChild();\n+            if (lastChild != null && !lastChild.isEnded()) {\n+                lastChild.handleDeactivation(deactivatedSpan, timestamp);\n+            }\n+        }\n+    }\n+\n+    public static CallTree.Root createRoot(ObjectPool<CallTree.Root> rootPool, byte[] traceContext, @Nullable String serviceName, long nanoTime) {\n+        CallTree.Root root = rootPool.createInstance();\n+        root.set(traceContext, serviceName, nanoTime);\n+        return root;\n+    }\n+\n+    protected void addFrame(ListIterator<StackFrame> iterator, @Nullable TraceContext traceContext, long activationTimestamp, long nanoTime) {\n+        count++;\n+        lastSeen = nanoTime;\n+        //     c ee   <- traceContext not set - they are not a child of the active span but the frame below them\n+        //   bbb dd   <- traceContext set\n+        //   ------   <- all new CallTree during this period should have the traceContext set\n+        // a aaaaaa a\n+        //  |      |\n+        // active  deactive\n+\n+        // this branch is already aware of the activation\n+        if (Objects.equals(this.activeContext, traceContext)) {\n+            traceContext = null;\n+        }\n+\n+        CallTree lastChild = getLastChild();\n+        // if the frame corresponding to the last child is not in the stack trace\n+        // it's assumed to have ended one tick ago\n+        boolean endChild = true;\n+        if (iterator.hasPrevious()) {", "originalCommit": "886c4ce259e9765a2e399d30a99e3f03d9981b3d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzMzNTk0Mg==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367335942", "bodyText": "It would probably be relatively easy to provide the option to set the class and method name when creating a transaction. But we can't require that as it wouldn't work with bridges. I don't see a generic solution that does not create overhead and allocations.", "author": "felixbarny", "createdAt": "2020-01-16T10:17:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Njk4NTIxOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQ3MjYzOQ==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r367472639", "bodyText": "Right, this is not for now. Would make sense within this PR only if it is simple enough to do without overhead. We can consider as future enhancement if the need arises.", "author": "eyalkoren", "createdAt": "2020-01-16T15:11:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Njk4NTIxOQ=="}], "type": "inlineReview"}, {"oid": "69141d6eb4ad7acb17eba7f5b20847c32247cfc4", "url": "https://github.com/elastic/apm-agent-java/commit/69141d6eb4ad7acb17eba7f5b20847c32247cfc4", "message": "Apply suggestions from code review", "committedDate": "2020-01-16T14:15:17Z", "type": "commit"}, {"oid": "77bd38dc68e7c0d797ddab45b5889f6c394f9b5d", "url": "https://github.com/elastic/apm-agent-java/commit/77bd38dc68e7c0d797ddab45b5889f6c394f9b5d", "message": "Merge remote-tracking branch 'origin/master' into async-profiler", "committedDate": "2020-01-16T14:15:59Z", "type": "commit"}, {"oid": "5b107c8ed87b50a39f23c97895889cb716c170e6", "url": "https://github.com/elastic/apm-agent-java/commit/5b107c8ed87b50a39f23c97895889cb716c170e6", "message": "Merge remote-tracking branch 'origin/master' into async-profiler", "committedDate": "2020-01-16T15:23:51Z", "type": "commit"}, {"oid": "1b6b1d066698cec39a725571be381f866bd2389d", "url": "https://github.com/elastic/apm-agent-java/commit/1b6b1d066698cec39a725571be381f866bd2389d", "message": "Limit depth of call tree to 256\n\nThe limit is somewhat arbitrary and maybe even too conservative.\nCan't really decide between 512 and 256.\nThe idea behind is to limit the depth so the recursive algorithms on\nthe CallTree don't cause StackOverflowErrors and also to limit allocations.", "committedDate": "2020-01-17T16:00:02Z", "type": "commit"}, {"oid": "5076cc59f5f6e99d370031bd3f63ea96c54415b5", "url": "https://github.com/elastic/apm-agent-java/commit/5076cc59f5f6e99d370031bd3f63ea96c54415b5", "message": "Add benchmarks", "committedDate": "2020-01-20T14:53:17Z", "type": "commit"}, {"oid": "76a17200dc066ac4438104db580eb39e4d01bb2e", "url": "https://github.com/elastic/apm-agent-java/commit/76a17200dc066ac4438104db580eb39e4d01bb2e", "message": "Update async-profiler\n\nto include fix for https://github.com/jvm-profiling-tools/async-profiler/issues/290", "committedDate": "2020-01-23T06:47:45Z", "type": "commit"}, {"oid": "3dcb386c1ec735aa02fcf25d01b25e83f588674f", "url": "https://github.com/elastic/apm-agent-java/commit/3dcb386c1ec735aa02fcf25d01b25e83f588674f", "message": "Avoid ListIterator allocation", "committedDate": "2020-01-23T09:01:15Z", "type": "commit"}, {"oid": "ed80b5dde8412c58acfdd46581f632bc15867d6d", "url": "https://github.com/elastic/apm-agent-java/commit/ed80b5dde8412c58acfdd46581f632bc15867d6d", "message": "Merge remote-tracking branch 'origin/master' into async-profiler", "committedDate": "2020-01-23T09:32:19Z", "type": "commit"}, {"oid": "3e432f9e316f5a9af42f0e71a07c07c9cb6772a1", "url": "https://github.com/elastic/apm-agent-java/commit/3e432f9e316f5a9af42f0e71a07c07c9cb6772a1", "message": "Add license headers", "committedDate": "2020-01-23T09:43:16Z", "type": "commit"}, {"oid": "ac651803933edc1730dac1e5312a84830e6932e3", "url": "https://github.com/elastic/apm-agent-java/commit/ac651803933edc1730dac1e5312a84830e6932e3", "message": "Load libasyncProfiler.so lazily\n\navoids loading the lib if profiling is off\nwhile still allowing to dynamically turn on profiling", "committedDate": "2020-01-23T10:02:31Z", "type": "commit"}, {"oid": "97b6a411f80a499a0ba35105e7ff018ca228ddbb", "url": "https://github.com/elastic/apm-agent-java/commit/97b6a411f80a499a0ba35105e7ff018ca228ddbb", "message": "Increase max size and pre-allocate first 10mb of activation events file", "committedDate": "2020-01-23T11:31:51Z", "type": "commit"}, {"oid": "ac285fa7890c8264d05ca4e71889b4479f9a2641", "url": "https://github.com/elastic/apm-agent-java/commit/ac285fa7890c8264d05ca4e71889b4479f9a2641", "message": "Fix deactivation after end", "committedDate": "2020-01-24T08:58:52Z", "type": "commit"}, {"oid": "4839254ed0d064b6b934c9eafe1851e27f436d95", "url": "https://github.com/elastic/apm-agent-java/commit/4839254ed0d064b6b934c9eafe1851e27f436d95", "message": "Make sure there's a log if async-profiler can't load", "committedDate": "2020-01-24T09:53:50Z", "type": "commit"}, {"oid": "a3ef6308af05fbcc2df16d25276713fc8435ccb9", "url": "https://github.com/elastic/apm-agent-java/commit/a3ef6308af05fbcc2df16d25276713fc8435ccb9", "message": "Enhance tests", "committedDate": "2020-01-24T13:24:28Z", "type": "commit"}, {"oid": "b7f0f0da01a04527a9e1f225e806759c9f24f7d9", "url": "https://github.com/elastic/apm-agent-java/commit/b7f0f0da01a04527a9e1f225e806759c9f24f7d9", "message": "Add profiling_spans_min_duration option", "committedDate": "2020-01-24T14:12:33Z", "type": "commit"}, {"oid": "3fd39fc527563a20fa67bcdcc19cdaf7783e47dd", "url": "https://github.com/elastic/apm-agent-java/commit/3fd39fc527563a20fa67bcdcc19cdaf7783e47dd", "message": "Fix for older Java versions", "committedDate": "2020-01-24T15:36:39Z", "type": "commit"}, {"oid": "c1581e2ba354900a4a7fa73117166a38bf615906", "url": "https://github.com/elastic/apm-agent-java/commit/c1581e2ba354900a4a7fa73117166a38bf615906", "message": "Test inferred spans in integration tests", "committedDate": "2020-01-24T15:37:44Z", "type": "commit"}, {"oid": "9b3e9e7c1002a863d2499784166fba9d99bfaa09", "url": "https://github.com/elastic/apm-agent-java/commit/9b3e9e7c1002a863d2499784166fba9d99bfaa09", "message": "Disable async-profiler test on J9-based tests", "committedDate": "2020-01-24T16:41:45Z", "type": "commit"}, {"oid": "d9fcf76eaa89a5fc80b1812402299be5d9d7bb73", "url": "https://github.com/elastic/apm-agent-java/commit/d9fcf76eaa89a5fc80b1812402299be5d9d7bb73", "message": "Merge remote-tracking branch 'origin/master' into async-profiler", "committedDate": "2020-01-24T16:41:53Z", "type": "commit"}, {"oid": "9641d04b92038454dea0c0f099adb91259cbbe69", "url": "https://github.com/elastic/apm-agent-java/commit/9641d04b92038454dea0c0f099adb91259cbbe69", "message": "Update async-profiler to 1.7-ea", "committedDate": "2020-01-27T08:06:32Z", "type": "commit"}, {"oid": "96dc45e1a6b15c457e109609fc409633ea292eab", "url": "https://github.com/elastic/apm-agent-java/commit/96dc45e1a6b15c457e109609fc409633ea292eab", "message": "Remove flaky inferred span integration test\n\nStill start the integration tests with the profiler on\nto test for obvious errors like segfaults", "committedDate": "2020-01-27T08:35:29Z", "type": "commit"}, {"oid": "700bdfd7a178926aa759ad8d44dc4e5b2582647a", "url": "https://github.com/elastic/apm-agent-java/commit/700bdfd7a178926aa759ad8d44dc4e5b2582647a", "message": "Merge remote-tracking branch 'origin/master' into async-profiler", "committedDate": "2020-01-27T15:43:44Z", "type": "commit"}, {"oid": "d1f24f4fa0dc2589d2fcfdd5e243eb58c1446489", "url": "https://github.com/elastic/apm-agent-java/commit/d1f24f4fa0dc2589d2fcfdd5e243eb58c1446489", "message": "Merge remote-tracking branch 'origin/master' into async-profiler", "committedDate": "2020-01-29T13:54:42Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mjk0NTMyMw==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r372945323", "bodyText": "Isn't it the other way round? Smaller interval => higher accuracy", "author": "apangin", "createdAt": "2020-01-30T13:26:48Z", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/ProfilingConfiguration.java", "diffHunk": "@@ -0,0 +1,182 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.configuration.converter.ListValueConverter;\n+import co.elastic.apm.agent.configuration.converter.TimeDuration;\n+import co.elastic.apm.agent.configuration.converter.TimeDurationValueConverter;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.matcher.WildcardMatcherValueConverter;\n+import org.stagemonitor.configuration.ConfigurationOption;\n+import org.stagemonitor.configuration.ConfigurationOptionProvider;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import static co.elastic.apm.agent.configuration.validation.RangeValidator.isInRange;\n+import static co.elastic.apm.agent.configuration.validation.RangeValidator.min;\n+\n+public class ProfilingConfiguration extends ConfigurationOptionProvider {\n+\n+    private static final String PROFILING_CATEGORY = \"Profiling\";\n+\n+    private final ConfigurationOption<Boolean> profilingEnabled = ConfigurationOption.<Boolean>booleanOption()\n+        .key(\"profiling_spans_enabled\")\n+        .configurationCategory(PROFILING_CATEGORY)\n+        .description(\"Set to `true` to make the agent create spans for method executions based on\\n\" +\n+            \"https://github.com/jvm-profiling-tools/async-profiler[async-profiler], a sampling aka statistical profiler.\\n\" +\n+            \"\\n\" +\n+            \"If this is enabled, the agent will start a profiling session every\\n\" +\n+            \"<<config-profiling-interval, `profiling_interval`>> which lasts for <<config-profiling-duration, `profiling_duration`>>.\\n\" +\n+            \"If a transaction happens within a profiling session,\\n\" +\n+            \"the agent creates spans for slow methods.\\n\" +\n+            \"\\n\" +\n+            \"Due to the nature of how sampling profilers work,\\n\" +\n+            \"the duration of the inferred spans are not exact, but only estimations.\\n\" +\n+            \"The <<config-profiling-sampling-interval, `profiling_sampling_interval`>> lets you fine tune the trade-off between accuracy and overhead.\\n\" +\n+            \"\\n\" +\n+            \"The inferred spans are created after a profiling session has ended.\\n\" +\n+            \"This means there is a delay between the regular and the inferred spans being visible in the UI.\\n\" +\n+            \"\\n\" +\n+            \"NOTE: This feature is not available on Windows\")\n+        .tags(\"experimental\")\n+        .dynamic(true)\n+        .tags(\"added[1.13.0]\")\n+        .buildWithDefault(false);\n+\n+    private final ConfigurationOption<TimeDuration> samplingInterval = TimeDurationValueConverter.durationOption(\"ms\")\n+        .key(\"profiling_sampling_interval\")\n+        .configurationCategory(PROFILING_CATEGORY)\n+        .dynamic(true)\n+        .description(\"The frequency at which stack traces are gathered within a profiling session.\\n\" +\n+            \"The lower you set it, the more accurate the durations will be.\\n\" +\n+            \"This comes at the expense of higher overhead and more spans for potentially irrelevant operations.\\n\" +\n+            \"The minimal duration of a profiling-inferred span is the same as the value of this setting.\")\n+        .addValidator(isInRange(TimeDuration.of(\"1ms\"), TimeDuration.of(\"1s\")))\n+        .tags(\"added[1.13.0]\")\n+        .buildWithDefault(TimeDuration.of(\"20ms\"));\n+\n+    private final ConfigurationOption<TimeDuration> inferredSpansMinDuration = TimeDurationValueConverter.durationOption(\"ms\")\n+        .key(\"profiling_spans_min_duration\")\n+        .configurationCategory(PROFILING_CATEGORY)\n+        .dynamic(true)\n+        .description(\"The minimum duration of an inferred span.\\n\" +\n+            \"Note that the min duration is also implicitly set by the sampling interval.\\n\" +\n+            \"However, decreasing the sampling interval also decreases the accuracy of the duration of inferred spans.\")", "originalCommit": "d1f24f4fa0dc2589d2fcfdd5e243eb58c1446489", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIxNzg5OA==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r374217898", "bodyText": "Good catch \ud83d\udc4d", "author": "felixbarny", "createdAt": "2020-02-03T16:53:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mjk0NTMyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mjk3NDc3MA==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r372974770", "bodyText": "I'm going to re-implement the way how native methods are bound, so that no fancy layers will be needed. It's possible to make it work without instrumentation or dynamic class generation.\nFurthermore, the number of native methods will be likely reduced to the minimum required. E.g. all dumpXXX stuff can be implemented on top of execute0.", "author": "apangin", "createdAt": "2020-01-30T14:20:40Z", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/AsyncProfiler.java", "diffHunk": "@@ -0,0 +1,278 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+/*\n+ * Copyright 2018 Andrei Pangin\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.util.IOUtils;\n+import net.bytebuddy.ByteBuddy;\n+import net.bytebuddy.dynamic.ClassFileLocator;\n+import net.bytebuddy.dynamic.loading.ClassLoadingStrategy;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+\n+/**\n+ * Java API for in-process profiling. Serves as a wrapper around\n+ * async-profiler native library. This class is a singleton.\n+ * The first call to {@link #getInstance()} initiates loading of\n+ * libasyncProfiler.so.\n+ * <p>\n+ * This is based on https://github.com/jvm-profiling-tools/async-profiler/blob/master/src/java/one/profiler/AsyncProfiler.java,\n+ * under Apache License 2.0.\n+ * It is modified to allow it to be shaded into the {@code co.elastic.apm} namespace\n+ * </p>\n+ */\n+public abstract class AsyncProfiler {\n+\n+    @Nullable\n+    private static volatile AsyncProfiler instance;\n+\n+    private final String version;\n+\n+    public AsyncProfiler() {\n+        this.version = version0();\n+    }\n+\n+    public static AsyncProfiler getInstance() {\n+        AsyncProfiler result = AsyncProfiler.instance;\n+        if (result != null) {\n+            return result;\n+        }\n+        synchronized (AsyncProfiler.class) {\n+            if (instance == null) {\n+                instance = newInstance();\n+            }\n+            return instance;\n+        }\n+    }\n+\n+    /*\n+     * Allows AsyncProfiler to be shaded. JNI mapping works for a specific package so shading normally doesn't work.\n+     */\n+    private static AsyncProfiler newInstance() {\n+        try {\n+            return new ByteBuddy()\n+                // ClassFileLocator.ForClassLoader.ofBootLoader() can't resolve resources added via Instrumentation.appendToBootstrapClassLoaderSearch\n+                // see also https://stackoverflow.com/questions/51347432/why-cant-i-load-resources-which-are-appended-to-the-bootstrap-class-loader-sear\n+                .redefine(DirectNativeBinding.class, ClassFileLocator.ForClassLoader.ofSystemLoader())\n+                .name(\"one.profiler.AsyncProfiler\")\n+                .make()\n+                .load(AsyncProfiler.class.getClassLoader(), ClassLoadingStrategy.Default.CHILD_FIRST)\n+                .getLoaded()\n+                .getConstructor()\n+                .newInstance();\n+        } catch (Exception e) {\n+            throw new IllegalStateException(e);\n+        }\n+    }\n+\n+    /**\n+     * Start profiling\n+     *\n+     * @param event Profiling event, see {@link Events}\n+     * @param interval Sampling interval, e.g. nanoseconds for Events.CPU\n+     * @throws IllegalStateException If profiler is already running\n+     */\n+    public void start(String event, long interval) throws IllegalStateException {\n+        start0(event, interval, true);\n+    }\n+\n+    /**\n+     * Start or resume profiling without resetting collected data.\n+     * Note that event and interval may change since the previous profiling session.\n+     *\n+     * @param event Profiling event, see {@link Events}\n+     * @param interval Sampling interval, e.g. nanoseconds for Events.CPU\n+     * @throws IllegalStateException If profiler is already running\n+     */\n+    public void resume(String event, long interval) throws IllegalStateException {\n+        start0(event, interval, false);\n+    }\n+\n+    /**\n+     * Stop profiling (without dumping results)\n+     *\n+     * @throws IllegalStateException If profiler is not running\n+     */\n+    public void stop() throws IllegalStateException {\n+        stop0();\n+    }\n+\n+    /**\n+     * Get the number of samples collected during the profiling session\n+     *\n+     * @return Number of samples\n+     */\n+    public native long getSamples();\n+\n+    /**\n+     * Get profiler agent version, e.g. \"1.0\"\n+     *\n+     * @return Version string\n+     */\n+    public String getVersion() {\n+        return version;\n+    }\n+\n+    /**\n+     * Execute an agent-compatible profiling command -\n+     * the comma-separated list of arguments described in arguments.cpp\n+     *\n+     * @param command Profiling command\n+     * @return The command result\n+     * @throws IllegalArgumentException If failed to parse the command\n+     * @throws java.io.IOException If failed to create output file\n+     */\n+    public String execute(String command) throws IllegalArgumentException, java.io.IOException {\n+        return execute0(command);\n+    }\n+\n+    /**\n+     * Dump profile in 'collapsed stacktraces' format\n+     *\n+     * @param counter Which counter to display in the output\n+     * @return Textual representation of the profile\n+     */\n+    public String dumpCollapsed(Counter counter) {\n+        return dumpCollapsed0(counter.ordinal());\n+    }\n+\n+    /**\n+     * Dump collected stack traces\n+     *\n+     * @param maxTraces Maximum number of stack traces to dump. 0 means no limit\n+     * @return Textual representation of the profile\n+     */\n+    public String dumpTraces(int maxTraces) {\n+        return dumpTraces0(maxTraces);\n+    }\n+\n+    /**\n+     * Dump flat profile, i.e. the histogram of the hottest methods\n+     *\n+     * @param maxMethods Maximum number of methods to dump. 0 means no limit\n+     * @return Textual representation of the profile\n+     */\n+    public String dumpFlat(int maxMethods) {\n+        return dumpFlat0(maxMethods);\n+    }\n+\n+    /**\n+     * Get OS thread ID of the current Java thread. On Linux, this is the same number\n+     * as gettid() returns. The result ID matches 'tid' in the profiler output.\n+     *\n+     * @return 64-bit integer that matches native (OS level) thread ID\n+     */\n+    public long getNativeThreadId() {\n+        return getNativeThreadId0();\n+    }\n+\n+    public abstract void start0(String event, long interval, boolean reset) throws IllegalStateException;\n+    public abstract void stop0() throws IllegalStateException;\n+    public abstract String execute0(String command) throws IllegalArgumentException, java.io.IOException;\n+    public abstract String dumpCollapsed0(int counter);\n+    public abstract String dumpTraces0(int maxTraces);\n+    public abstract String dumpFlat0(int maxMethods);\n+    public abstract String version0();\n+    public abstract long getNativeThreadId0();", "originalCommit": "d1f24f4fa0dc2589d2fcfdd5e243eb58c1446489", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mjk4ODIwMQ==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r372988201", "bodyText": "There are definitely more platforms where async-profiler works, e.g. x64-musl and AArch64. Probably, more platforms in future - there is already a PR for PPC port, for example. Not sure if packing all binaries into a single .jar is a good idea.\nAlso, it's not enough to look only at these two properties to distinguish glibc from musl libc.", "author": "apangin", "createdAt": "2020-01-30T14:42:43Z", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/AsyncProfiler.java", "diffHunk": "@@ -0,0 +1,278 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+/*\n+ * Copyright 2018 Andrei Pangin\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.util.IOUtils;\n+import net.bytebuddy.ByteBuddy;\n+import net.bytebuddy.dynamic.ClassFileLocator;\n+import net.bytebuddy.dynamic.loading.ClassLoadingStrategy;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+\n+/**\n+ * Java API for in-process profiling. Serves as a wrapper around\n+ * async-profiler native library. This class is a singleton.\n+ * The first call to {@link #getInstance()} initiates loading of\n+ * libasyncProfiler.so.\n+ * <p>\n+ * This is based on https://github.com/jvm-profiling-tools/async-profiler/blob/master/src/java/one/profiler/AsyncProfiler.java,\n+ * under Apache License 2.0.\n+ * It is modified to allow it to be shaded into the {@code co.elastic.apm} namespace\n+ * </p>\n+ */\n+public abstract class AsyncProfiler {\n+\n+    @Nullable\n+    private static volatile AsyncProfiler instance;\n+\n+    private final String version;\n+\n+    public AsyncProfiler() {\n+        this.version = version0();\n+    }\n+\n+    public static AsyncProfiler getInstance() {\n+        AsyncProfiler result = AsyncProfiler.instance;\n+        if (result != null) {\n+            return result;\n+        }\n+        synchronized (AsyncProfiler.class) {\n+            if (instance == null) {\n+                instance = newInstance();\n+            }\n+            return instance;\n+        }\n+    }\n+\n+    /*\n+     * Allows AsyncProfiler to be shaded. JNI mapping works for a specific package so shading normally doesn't work.\n+     */\n+    private static AsyncProfiler newInstance() {\n+        try {\n+            return new ByteBuddy()\n+                // ClassFileLocator.ForClassLoader.ofBootLoader() can't resolve resources added via Instrumentation.appendToBootstrapClassLoaderSearch\n+                // see also https://stackoverflow.com/questions/51347432/why-cant-i-load-resources-which-are-appended-to-the-bootstrap-class-loader-sear\n+                .redefine(DirectNativeBinding.class, ClassFileLocator.ForClassLoader.ofSystemLoader())\n+                .name(\"one.profiler.AsyncProfiler\")\n+                .make()\n+                .load(AsyncProfiler.class.getClassLoader(), ClassLoadingStrategy.Default.CHILD_FIRST)\n+                .getLoaded()\n+                .getConstructor()\n+                .newInstance();\n+        } catch (Exception e) {\n+            throw new IllegalStateException(e);\n+        }\n+    }\n+\n+    /**\n+     * Start profiling\n+     *\n+     * @param event Profiling event, see {@link Events}\n+     * @param interval Sampling interval, e.g. nanoseconds for Events.CPU\n+     * @throws IllegalStateException If profiler is already running\n+     */\n+    public void start(String event, long interval) throws IllegalStateException {\n+        start0(event, interval, true);\n+    }\n+\n+    /**\n+     * Start or resume profiling without resetting collected data.\n+     * Note that event and interval may change since the previous profiling session.\n+     *\n+     * @param event Profiling event, see {@link Events}\n+     * @param interval Sampling interval, e.g. nanoseconds for Events.CPU\n+     * @throws IllegalStateException If profiler is already running\n+     */\n+    public void resume(String event, long interval) throws IllegalStateException {\n+        start0(event, interval, false);\n+    }\n+\n+    /**\n+     * Stop profiling (without dumping results)\n+     *\n+     * @throws IllegalStateException If profiler is not running\n+     */\n+    public void stop() throws IllegalStateException {\n+        stop0();\n+    }\n+\n+    /**\n+     * Get the number of samples collected during the profiling session\n+     *\n+     * @return Number of samples\n+     */\n+    public native long getSamples();\n+\n+    /**\n+     * Get profiler agent version, e.g. \"1.0\"\n+     *\n+     * @return Version string\n+     */\n+    public String getVersion() {\n+        return version;\n+    }\n+\n+    /**\n+     * Execute an agent-compatible profiling command -\n+     * the comma-separated list of arguments described in arguments.cpp\n+     *\n+     * @param command Profiling command\n+     * @return The command result\n+     * @throws IllegalArgumentException If failed to parse the command\n+     * @throws java.io.IOException If failed to create output file\n+     */\n+    public String execute(String command) throws IllegalArgumentException, java.io.IOException {\n+        return execute0(command);\n+    }\n+\n+    /**\n+     * Dump profile in 'collapsed stacktraces' format\n+     *\n+     * @param counter Which counter to display in the output\n+     * @return Textual representation of the profile\n+     */\n+    public String dumpCollapsed(Counter counter) {\n+        return dumpCollapsed0(counter.ordinal());\n+    }\n+\n+    /**\n+     * Dump collected stack traces\n+     *\n+     * @param maxTraces Maximum number of stack traces to dump. 0 means no limit\n+     * @return Textual representation of the profile\n+     */\n+    public String dumpTraces(int maxTraces) {\n+        return dumpTraces0(maxTraces);\n+    }\n+\n+    /**\n+     * Dump flat profile, i.e. the histogram of the hottest methods\n+     *\n+     * @param maxMethods Maximum number of methods to dump. 0 means no limit\n+     * @return Textual representation of the profile\n+     */\n+    public String dumpFlat(int maxMethods) {\n+        return dumpFlat0(maxMethods);\n+    }\n+\n+    /**\n+     * Get OS thread ID of the current Java thread. On Linux, this is the same number\n+     * as gettid() returns. The result ID matches 'tid' in the profiler output.\n+     *\n+     * @return 64-bit integer that matches native (OS level) thread ID\n+     */\n+    public long getNativeThreadId() {\n+        return getNativeThreadId0();\n+    }\n+\n+    public abstract void start0(String event, long interval, boolean reset) throws IllegalStateException;\n+    public abstract void stop0() throws IllegalStateException;\n+    public abstract String execute0(String command) throws IllegalArgumentException, java.io.IOException;\n+    public abstract String dumpCollapsed0(int counter);\n+    public abstract String dumpTraces0(int maxTraces);\n+    public abstract String dumpFlat0(int maxMethods);\n+    public abstract String version0();\n+    public abstract long getNativeThreadId0();\n+\n+    /**\n+     * Inspired by https://gist.github.com/raphw/be0994259e75652f057c9e1d3ee5f567\n+     */\n+    public static class DirectNativeBinding extends AsyncProfiler {\n+\n+        static {\n+            loadNativeLibrary();\n+        }\n+\n+        private static void loadNativeLibrary() {\n+            String libraryName = getLibraryFileName();\n+            File file = IOUtils.exportResourceToTemp(\"asyncprofiler/\" + libraryName + \".so\", libraryName, \".so\");\n+            System.load(file.getAbsolutePath());\n+        }\n+\n+        private static String getLibraryFileName() {\n+            String os = System.getProperty(\"os.name\").toLowerCase();\n+            String arch = System.getProperty(\"os.arch\").toLowerCase();\n+            if (os.contains(\"linux\")) {\n+                if (arch.contains(\"arm\") || arch.contains(\"aarch\")) {\n+                    return \"libasyncProfiler-linux-arm\";\n+                } else if (arch.contains(\"64\")) {\n+                    return \"libasyncProfiler-linux-x64\";\n+                } else if (arch.contains(\"86\")) {\n+                    return \"libasyncProfiler-linux-x86\";\n+                } else {\n+                    throw new IllegalStateException(\"Async-profiler does not work on Linux \" + arch);\n+                }", "originalCommit": "d1f24f4fa0dc2589d2fcfdd5e243eb58c1446489", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIyMTMzNA==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r374221334", "bodyText": "Let's start with just the 4 platforms.", "author": "felixbarny", "createdAt": "2020-02-03T16:59:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mjk4ODIwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzAwMTM0OA==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r373001348", "bodyText": "Although async-profiler currently writes everything within a single checkpoint, JFR format can possibly have many checkpoints. In order to support continuous profiling, both JFR reader and writer should consider multiple checkpoints.", "author": "apangin", "createdAt": "2020-01-30T15:03:10Z", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/JfrParser.java", "diffHunk": "@@ -0,0 +1,531 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+import co.elastic.apm.agent.profiler.collections.Int2IntHashMap;\n+import co.elastic.apm.agent.profiler.collections.Int2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+/**\n+ * Parses the binary JFR file created by async-profiler.\n+ * May not work with JFR files created by an actual flight recorder.\n+ * <p>\n+ * The implementation is tuned with to minimize allocations when parsing a JFR file.\n+ * Most data structures can be reused by first {@linkplain #resetState() resetting the state} and then {@linkplain #parse(File, List, List) parsing}\n+ * another file.\n+ * </p>\n+ * <p>\n+ * The JFR file itself is mapped into memory via a {@link MappedByteBuffer}.\n+ * This does not consume heap memory, the operating system loads pages the file into memory as they are requested.\n+ * Unfortunately, unmapping a {@link MappedByteBuffer} can only be done by letting it be garbage collected.\n+ * </p>\n+ */\n+public class JfrParser implements Recyclable {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(JfrParser.class);\n+\n+    private static final byte[] MAGIC_BYTES = new byte[]{'F', 'L', 'R', '\\0'};\n+    private static final Set<String> JAVA_FRAME_TYPES = new HashSet<>(Arrays.asList(\"Interpreted\", \"JIT compiled\", \"Inlined\"));\n+\n+    @Nullable\n+    private MappedByteBuffer buffer;\n+    private int eventsOffset;\n+    private int metadataOffset;\n+    @Nullable\n+    private boolean[] isJavaFrameType;\n+    private final Int2IntHashMap classIdToClassNameSymbolId = new Int2IntHashMap(-1);\n+    private final Int2ObjectHashMap<Symbol> symbols = new Int2ObjectHashMap<>();\n+    private final Int2IntHashMap stackTraceIdToFilePositions = new Int2IntHashMap(-1);\n+    private final Long2ObjectHashMap<LazyStackFrame> framesByFrameId = new Long2ObjectHashMap<>();\n+    // used to resolve a symbol with minimal allocations\n+    private final StringBuilder symbolBuilder = new StringBuilder();\n+    @Nullable\n+    private List<WildcardMatcher> excludedClasses;\n+    @Nullable\n+    private List<WildcardMatcher> includedClasses;\n+\n+    /**\n+     * Initializes the parser to make it ready for {@link #resolveStackTrace(long, boolean, List, int)} to be called.\n+     *\n+     * @param file            the JFR file to parse\n+     * @param excludedClasses Class names to exclude in stack traces (has an effect on {@link #resolveStackTrace(long, boolean, List, int)})\n+     * @param includedClasses Class names to include in stack traces (has an effect on {@link #resolveStackTrace(long, boolean, List, int)})\n+     * @throws IOException if some I/O error occurs\n+     */\n+    public void parse(File file, List<WildcardMatcher> excludedClasses, List<WildcardMatcher> includedClasses) throws IOException {\n+        this.excludedClasses = excludedClasses;\n+        this.includedClasses = includedClasses;\n+        try (RandomAccessFile raf = new RandomAccessFile(file, \"r\")) {\n+            FileChannel channel = raf.getChannel();\n+            logger.debug(\"Parsing {} ({} bytes)\", file, channel.size());\n+            if (channel.size() > Integer.MAX_VALUE) {\n+                // mapping a file into memory is only possible for chunks of the file which fall into the Integer range (2GB)\n+                // that is because MappedByteBuffers are ByteBuffers which only accept ints in position(int pos)\n+                throw new IllegalArgumentException(\"Input file too large\");\n+            }\n+            this.buffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, channel.size());\n+        }\n+        for (byte magicByte : MAGIC_BYTES) {\n+            if (buffer.get() != magicByte) {\n+                throw new IllegalArgumentException(\"Not a JFR file\");\n+            }\n+        }\n+        short major = buffer.getShort();\n+        short minor = buffer.getShort();\n+        if (major != 0 || minor != 9) {\n+            throw new IllegalArgumentException(String.format(\"Can only parse version 0.9. Was %d.%d\", major, minor));\n+        }\n+        // safe as we only process files where size <= Integer.MAX_VALUE\n+        metadataOffset = (int) buffer.getLong();\n+        eventsOffset = buffer.position();\n+\n+        setPosition(buffer, metadataOffset);\n+        int checkpointOffset = parseMetadata(buffer);\n+        setPosition(buffer, checkpointOffset);\n+        parseCheckpoint(buffer);", "originalCommit": "d1f24f4fa0dc2589d2fcfdd5e243eb58c1446489", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIyMjAyNA==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r374222024", "bodyText": "I'm aware that this class makes quite a few assumptions about how the JFR file is written. But as we always ship with a specific version of async-profiler I think this is fine and allows for some optimizations.", "author": "felixbarny", "createdAt": "2020-02-03T17:00:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzAwMTM0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzAwODc5Nw==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r373008797", "bodyText": "There are plans to support at least two states: RUNNABLE and SLEEPING, depending on whether the thread is currently on cpu or not.", "author": "apangin", "createdAt": "2020-01-30T15:15:08Z", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/JfrParser.java", "diffHunk": "@@ -0,0 +1,531 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+import co.elastic.apm.agent.profiler.collections.Int2IntHashMap;\n+import co.elastic.apm.agent.profiler.collections.Int2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+/**\n+ * Parses the binary JFR file created by async-profiler.\n+ * May not work with JFR files created by an actual flight recorder.\n+ * <p>\n+ * The implementation is tuned with to minimize allocations when parsing a JFR file.\n+ * Most data structures can be reused by first {@linkplain #resetState() resetting the state} and then {@linkplain #parse(File, List, List) parsing}\n+ * another file.\n+ * </p>\n+ * <p>\n+ * The JFR file itself is mapped into memory via a {@link MappedByteBuffer}.\n+ * This does not consume heap memory, the operating system loads pages the file into memory as they are requested.\n+ * Unfortunately, unmapping a {@link MappedByteBuffer} can only be done by letting it be garbage collected.\n+ * </p>\n+ */\n+public class JfrParser implements Recyclable {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(JfrParser.class);\n+\n+    private static final byte[] MAGIC_BYTES = new byte[]{'F', 'L', 'R', '\\0'};\n+    private static final Set<String> JAVA_FRAME_TYPES = new HashSet<>(Arrays.asList(\"Interpreted\", \"JIT compiled\", \"Inlined\"));\n+\n+    @Nullable\n+    private MappedByteBuffer buffer;\n+    private int eventsOffset;\n+    private int metadataOffset;\n+    @Nullable\n+    private boolean[] isJavaFrameType;\n+    private final Int2IntHashMap classIdToClassNameSymbolId = new Int2IntHashMap(-1);\n+    private final Int2ObjectHashMap<Symbol> symbols = new Int2ObjectHashMap<>();\n+    private final Int2IntHashMap stackTraceIdToFilePositions = new Int2IntHashMap(-1);\n+    private final Long2ObjectHashMap<LazyStackFrame> framesByFrameId = new Long2ObjectHashMap<>();\n+    // used to resolve a symbol with minimal allocations\n+    private final StringBuilder symbolBuilder = new StringBuilder();\n+    @Nullable\n+    private List<WildcardMatcher> excludedClasses;\n+    @Nullable\n+    private List<WildcardMatcher> includedClasses;\n+\n+    /**\n+     * Initializes the parser to make it ready for {@link #resolveStackTrace(long, boolean, List, int)} to be called.\n+     *\n+     * @param file            the JFR file to parse\n+     * @param excludedClasses Class names to exclude in stack traces (has an effect on {@link #resolveStackTrace(long, boolean, List, int)})\n+     * @param includedClasses Class names to include in stack traces (has an effect on {@link #resolveStackTrace(long, boolean, List, int)})\n+     * @throws IOException if some I/O error occurs\n+     */\n+    public void parse(File file, List<WildcardMatcher> excludedClasses, List<WildcardMatcher> includedClasses) throws IOException {\n+        this.excludedClasses = excludedClasses;\n+        this.includedClasses = includedClasses;\n+        try (RandomAccessFile raf = new RandomAccessFile(file, \"r\")) {\n+            FileChannel channel = raf.getChannel();\n+            logger.debug(\"Parsing {} ({} bytes)\", file, channel.size());\n+            if (channel.size() > Integer.MAX_VALUE) {\n+                // mapping a file into memory is only possible for chunks of the file which fall into the Integer range (2GB)\n+                // that is because MappedByteBuffers are ByteBuffers which only accept ints in position(int pos)\n+                throw new IllegalArgumentException(\"Input file too large\");\n+            }\n+            this.buffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, channel.size());\n+        }\n+        for (byte magicByte : MAGIC_BYTES) {\n+            if (buffer.get() != magicByte) {\n+                throw new IllegalArgumentException(\"Not a JFR file\");\n+            }\n+        }\n+        short major = buffer.getShort();\n+        short minor = buffer.getShort();\n+        if (major != 0 || minor != 9) {\n+            throw new IllegalArgumentException(String.format(\"Can only parse version 0.9. Was %d.%d\", major, minor));\n+        }\n+        // safe as we only process files where size <= Integer.MAX_VALUE\n+        metadataOffset = (int) buffer.getLong();\n+        eventsOffset = buffer.position();\n+\n+        setPosition(buffer, metadataOffset);\n+        int checkpointOffset = parseMetadata(buffer);\n+        setPosition(buffer, checkpointOffset);\n+        parseCheckpoint(buffer);\n+    }\n+\n+    private int parseMetadata(MappedByteBuffer buffer) throws IOException {\n+        int size = buffer.getInt();\n+        expectEventType(buffer, EventTypeId.EVENT_METADATA);\n+        int checkpointOffsetPosition = size - 16;\n+        setPosition(buffer, buffer.position() + checkpointOffsetPosition);\n+        // safe as we only process files where size <= Integer.MAX_VALUE\n+        return (int) buffer.getLong();\n+    }\n+\n+    private void expectEventType(MappedByteBuffer buffer, int expectedEventType) throws IOException {\n+        int eventType = buffer.getInt();\n+        if (eventType != expectedEventType) {\n+            throw new IOException(\"Expected \" + expectedEventType + \" but got \" + eventType);\n+        }\n+    }\n+\n+    private void parseCheckpoint(MappedByteBuffer buffer) throws IOException {\n+        buffer.getInt(); // size\n+        expectEventType(buffer, EventTypeId.EVENT_CHECKPOINT);\n+        buffer.getLong(); // stop timestamp\n+        buffer.getLong(); // previous checkpoint - always 0 in async-profiler\n+        while (buffer.position() < metadataOffset) {\n+            parseContentType(buffer);\n+        }\n+    }\n+\n+    private void parseContentType(MappedByteBuffer buffer) throws IOException {\n+        int contentTypeId = buffer.getInt();\n+        logger.debug(\"Parsing content type {}\", contentTypeId);\n+        int count = buffer.getInt();\n+        switch (contentTypeId) {\n+            case ContentTypeId.CONTENT_THREAD:\n+                // currently no thread info\n+                break;\n+            case ContentTypeId.CONTENT_STACKTRACE:\n+                for (int i = 0; i < count; i++) {\n+                    int pos = buffer.position();\n+                    // always an integer\n+                    // see profiler.h\n+                    // MAX_CALLTRACES = 65536\n+                    int stackTraceKey = (int) buffer.getLong();\n+                    this.stackTraceIdToFilePositions.put(stackTraceKey, pos);\n+                    buffer.get(); // truncated\n+                    int numFrames = buffer.getInt();\n+                    int sizeOfFrame = 13;\n+                    setPosition(buffer, buffer.position() + numFrames * sizeOfFrame);\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_CLASS:\n+                for (int i = 0; i < count; i++) {\n+                    // classId is an incrementing integer, no way there are more than 2 billion distinct ones\n+                    int classId = (int) buffer.getLong();\n+                    buffer.getLong(); // loader class\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int classNameSymbolId = (int) buffer.getLong();\n+                    classIdToClassNameSymbolId.put(classId, classNameSymbolId); // class name\n+                    buffer.getShort(); // access flags\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_METHOD:\n+                for (int i = 1; i <= count; i++) {\n+                    long id = buffer.getLong();\n+                    // classId is an incrementing integer, no way there are more than 2 billion distinct ones\n+                    int classId = (int) buffer.getLong();\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int methodNameSymbolId = (int) buffer.getLong();\n+                    framesByFrameId.put(id, new LazyStackFrame(classId, methodNameSymbolId));\n+                    buffer.getLong(); // signature\n+                    buffer.getShort(); // modifiers\n+                    buffer.get(); // hidden\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_SYMBOL:\n+                for (int i = 0; i < count; i++) {\n+                    // symbol ids are incrementing integers, no way there are more than 2 billion distinct ones\n+                    int symbolId = (int) buffer.getLong();\n+                    int pos = buffer.position();\n+                    symbols.put(symbolId, new Symbol(pos));\n+                    skipString();\n+                }\n+                break;\n+            case ContentTypeId.CONTENT_STATE:\n+                // we're not really interested in the thread states (async-profiler hard-codes state RUNNABLE) anyways\n+                // but we sill have to consume the bytes", "originalCommit": "d1f24f4fa0dc2589d2fcfdd5e243eb58c1446489", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIyMjM0Nw==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r374222347", "bodyText": "That's great news. I'll implement that once it's available in async-profiler.", "author": "felixbarny", "createdAt": "2020-02-03T17:01:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzAwODc5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzA2MjkzOA==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r373062938", "bodyText": "Writing to a (large) MappedByteBuffer is somewhat guileful. Any put() operation may potentially get stuck, and not only in writing thread, but also cause long global time-to-safepoint pause.\nIn this sense, writing to a temporary direct ByteBuffer and then flushing with a regular write() call is safer.", "author": "apangin", "createdAt": "2020-01-30T16:42:32Z", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "diffHunk": "@@ -0,0 +1,657 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.configuration.converter.TimeDuration;\n+import co.elastic.apm.agent.context.LifecycleListener;\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.impl.transaction.TraceContextHolder;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Allocator;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.impl.ListBasedObjectPool;\n+import co.elastic.apm.agent.profiler.asyncprofiler.AsyncProfiler;\n+import co.elastic.apm.agent.profiler.asyncprofiler.JfrParser;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.LongHashSet;\n+import co.elastic.apm.agent.util.ExecutorUtils;\n+import com.lmax.disruptor.EventFactory;\n+import com.lmax.disruptor.EventPoller;\n+import com.lmax.disruptor.EventTranslatorTwoArg;\n+import com.lmax.disruptor.RingBuffer;\n+import com.lmax.disruptor.Sequence;\n+import com.lmax.disruptor.SequenceBarrier;\n+import com.lmax.disruptor.WaitStrategy;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.LockSupport;\n+\n+/**\n+ * Correlates {@link ActivationEvent}s with {@link StackFrame}s which are recorded by {@link AsyncProfiler},\n+ * a native <a href=\"http://psy-lob-saw.blogspot.com/2016/06/the-pros-and-cons-of-agct.html\">{@code AsyncGetCallTree}</a>-based\n+ * (and therefore <a href=\"http://psy-lob-saw.blogspot.com/2016/02/why-most-sampling-java-profilers-are.html\"> non safepoint-biased</a>)\n+ * JVMTI agent.\n+ * <p>\n+ * Recording of {@link ActivationEvent}s:\n+ * </p>\n+ * <p>\n+ * The {@link #onActivation} and {@link #onDeactivation} methods are called by {@link ProfilingActivationListener}\n+ * which register an {@link ActivationEvent} in to a {@linkplain #eventBuffer ring buffer} whenever a {@link Span}\n+ * gets {@link Span#activate()}d or {@link Span#deactivate()}d while a {@linkplain #profilingSessionOngoing profiling session is ongoing}.\n+ * A background thread consumes the {@link ActivationEvent}s and writes them to a {@linkplain #activationEventBuffer memory-mapped file}.\n+ * That is necessary because within a profiling session (which lasts 10s by default) there may be many more {@link ActivationEvent}s\n+ * than the ring buffer can hold {@link #RING_BUFFER_SIZE}.\n+ * The file can hold {@link #ACTIVATION_EVENTS_IN_FILE} events and each is {@link ActivationEvent#SERIALIZED_SIZE} in size.\n+ * This process is completely garbage free thanks to the {@link RingBuffer} acting as an object pool for {@link ActivationEvent}s.\n+ * </p>\n+ * <p>\n+ * Recording stack traces:\n+ * </p>\n+ * <p>\n+ * The same background thread that processes the {@link ActivationEvent}s starts the wall clock profiler of async-profiler via\n+ * {@link AsyncProfiler#execute(String)}.\n+ * After the {@link ProfilingConfiguration#getProfilingDuration()} is over it stops the profiling and starts processing the JFR file created\n+ * by async-profiler with {@link JfrParser}.\n+ * </p>\n+ * <p>\n+ * Correlating {@link ActivationEvent}s with the traces recorded by {@link AsyncProfiler}:\n+ * </p>\n+ * <p>\n+ * After both the JFR file and the memory-mapped file containing the {@link ActivationEvent}s have been written,\n+ * it's now time to process them in tandem by correlating based on thread ids and timestamps.\n+ * The result of this correlation, performed by {@link #processTraces(File)},\n+ * are {@link CallTree}s which are created for each thread which has seen an {@linkplain Span#activate() activation}\n+ * and at least one stack trace.\n+ * Once {@linkplain ActivationEvent#handleDeactivationEvent(SamplingProfiler) handling the deactivation event} of the root span in a thread\n+ * (after which {@link ElasticApmTracer#getActive()} would return {@code null}),\n+ * the {@link CallTree} is {@linkplain CallTree#spanify(CallTree.Root, TraceContext) converted into regular spans}.\n+ * </p>\n+ * <p>\n+ * Overall, the allocation rate does not depend on the number of {@link ActivationEvent}s but only on\n+ * {@link ProfilingConfiguration#getProfilingInterval()} and {@link ProfilingConfiguration#getSamplingInterval()}.\n+ * Having said that, there are some optimizations so that the JFR file is not processed at all if there have not been any\n+ * {@link ActivationEvent} in a given profiling session.\n+ * Also, only if there's a {@link CallTree.Root} for a {@link StackTraceEvent},\n+ * we will {@link JfrParser#resolveStackTrace(long, boolean, List, int) resolve the full stack trace}.\n+ * </p>\n+ */\n+public class SamplingProfiler implements Runnable, LifecycleListener {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(SamplingProfiler.class);\n+    private static final int ACTIVATION_EVENTS_IN_FILE = 1_000_000;\n+    private static final int MAX_STACK_DEPTH = 256;\n+    private static final int PRE_ALLOCATE_ACTIVATION_EVENTS_FILE_MB = 10;\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> ACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder<?> active, TraceContextHolder<?> previouslyActive) {\n+                event.activation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> DEACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder active, TraceContextHolder previouslyActive) {\n+                event.deactivation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    // sizeof(ActivationEvent) is 176B so the ring buffer should be around 880KiB\n+    static final int RING_BUFFER_SIZE = 4 * 1024;\n+\n+    private final ProfilingConfiguration config;\n+    private final ScheduledExecutorService scheduler;\n+    private final Long2ObjectHashMap<CallTree.Root> profiledThreads = new Long2ObjectHashMap<>();\n+    private final RingBuffer<ActivationEvent> eventBuffer;\n+    private volatile boolean profilingSessionOngoing = false;\n+    private final Sequence sequence;\n+    private final ElasticApmTracer tracer;\n+    private final NanoClock nanoClock;\n+    private final ObjectPool<CallTree.Root> rootPool;\n+    private final NativeThreadIdToJavaThreadMapper threadMapper = new NativeThreadIdToJavaThreadMapper();\n+    private final MappedByteBuffer activationEventBuffer;\n+    private final EventPoller<ActivationEvent> poller;\n+    private final File activationEventsFile;\n+    private final File jfrFile;\n+    private final WriteActivationEventToFileHandler writeActivationEventToFileHandler = new WriteActivationEventToFileHandler();\n+    private final JfrParser jfrParser = new JfrParser();\n+    private volatile int profilingSessions;\n+\n+    public SamplingProfiler(ElasticApmTracer tracer, NanoClock nanoClock) throws IOException {\n+        this(tracer,\n+            tracer.getConfig(ProfilingConfiguration.class),\n+            ExecutorUtils.createSingleThreadSchedulingDeamonPool(\"sampling-profiler\"),\n+            nanoClock);\n+    }\n+\n+    SamplingProfiler(final ElasticApmTracer tracer, ProfilingConfiguration config, ScheduledExecutorService scheduler, NanoClock nanoClock) throws IOException {\n+        this.tracer = tracer;\n+        this.config = config;\n+        this.scheduler = scheduler;\n+        this.nanoClock = nanoClock;\n+        this.eventBuffer = createRingBuffer();\n+        this.sequence = new Sequence();\n+        // tells the ring buffer to not override slots which have not been read yet\n+        this.eventBuffer.addGatingSequences(sequence);\n+        this.poller = eventBuffer.newPoller();\n+        // call tree roots are pooled so that fast activations/deactivations with no associated stack traces don't cause allocations\n+        this.rootPool = ListBasedObjectPool.<CallTree.Root>ofRecyclable(new ArrayList<CallTree.Root>(), 512, new Allocator<CallTree.Root>() {\n+            @Override\n+            public CallTree.Root createInstance() {\n+                return new CallTree.Root(tracer);\n+            }\n+        });\n+        jfrFile = File.createTempFile(\"apm-traces-\", \".jfr\");\n+        activationEventsFile = File.createTempFile(\"apm-activation-events-\", \".bin\");\n+        try (RandomAccessFile randomAccessFile = new RandomAccessFile(activationEventsFile, \"rw\")) {\n+            activationEventBuffer = randomAccessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, ACTIVATION_EVENTS_IN_FILE * ActivationEvent.SERIALIZED_SIZE);\n+            preAllocate(activationEventBuffer, PRE_ALLOCATE_ACTIVATION_EVENTS_FILE_MB);", "originalCommit": "d1f24f4fa0dc2589d2fcfdd5e243eb58c1446489", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIxODM5NA==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r374218394", "bodyText": "Thx for the tip!\nDo similar problems occur when reading?", "author": "felixbarny", "createdAt": "2020-02-03T16:54:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzA2MjkzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQwNDI2OQ==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r374404269", "bodyText": "Yes, reading can be even worse. When writing to a MappedByteBuffer, dirty pages are flushed in background as long as it is possible; but when reading, page faults are synchronous.", "author": "apangin", "createdAt": "2020-02-03T23:42:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzA2MjkzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzA2MzY0OA==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r373063648", "bodyText": "Sleeping even if there is more data to process - is it intentional?", "author": "apangin", "createdAt": "2020-01-30T16:43:47Z", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "diffHunk": "@@ -0,0 +1,657 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.configuration.converter.TimeDuration;\n+import co.elastic.apm.agent.context.LifecycleListener;\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.impl.transaction.TraceContextHolder;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Allocator;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.impl.ListBasedObjectPool;\n+import co.elastic.apm.agent.profiler.asyncprofiler.AsyncProfiler;\n+import co.elastic.apm.agent.profiler.asyncprofiler.JfrParser;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.LongHashSet;\n+import co.elastic.apm.agent.util.ExecutorUtils;\n+import com.lmax.disruptor.EventFactory;\n+import com.lmax.disruptor.EventPoller;\n+import com.lmax.disruptor.EventTranslatorTwoArg;\n+import com.lmax.disruptor.RingBuffer;\n+import com.lmax.disruptor.Sequence;\n+import com.lmax.disruptor.SequenceBarrier;\n+import com.lmax.disruptor.WaitStrategy;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.LockSupport;\n+\n+/**\n+ * Correlates {@link ActivationEvent}s with {@link StackFrame}s which are recorded by {@link AsyncProfiler},\n+ * a native <a href=\"http://psy-lob-saw.blogspot.com/2016/06/the-pros-and-cons-of-agct.html\">{@code AsyncGetCallTree}</a>-based\n+ * (and therefore <a href=\"http://psy-lob-saw.blogspot.com/2016/02/why-most-sampling-java-profilers-are.html\"> non safepoint-biased</a>)\n+ * JVMTI agent.\n+ * <p>\n+ * Recording of {@link ActivationEvent}s:\n+ * </p>\n+ * <p>\n+ * The {@link #onActivation} and {@link #onDeactivation} methods are called by {@link ProfilingActivationListener}\n+ * which register an {@link ActivationEvent} in to a {@linkplain #eventBuffer ring buffer} whenever a {@link Span}\n+ * gets {@link Span#activate()}d or {@link Span#deactivate()}d while a {@linkplain #profilingSessionOngoing profiling session is ongoing}.\n+ * A background thread consumes the {@link ActivationEvent}s and writes them to a {@linkplain #activationEventBuffer memory-mapped file}.\n+ * That is necessary because within a profiling session (which lasts 10s by default) there may be many more {@link ActivationEvent}s\n+ * than the ring buffer can hold {@link #RING_BUFFER_SIZE}.\n+ * The file can hold {@link #ACTIVATION_EVENTS_IN_FILE} events and each is {@link ActivationEvent#SERIALIZED_SIZE} in size.\n+ * This process is completely garbage free thanks to the {@link RingBuffer} acting as an object pool for {@link ActivationEvent}s.\n+ * </p>\n+ * <p>\n+ * Recording stack traces:\n+ * </p>\n+ * <p>\n+ * The same background thread that processes the {@link ActivationEvent}s starts the wall clock profiler of async-profiler via\n+ * {@link AsyncProfiler#execute(String)}.\n+ * After the {@link ProfilingConfiguration#getProfilingDuration()} is over it stops the profiling and starts processing the JFR file created\n+ * by async-profiler with {@link JfrParser}.\n+ * </p>\n+ * <p>\n+ * Correlating {@link ActivationEvent}s with the traces recorded by {@link AsyncProfiler}:\n+ * </p>\n+ * <p>\n+ * After both the JFR file and the memory-mapped file containing the {@link ActivationEvent}s have been written,\n+ * it's now time to process them in tandem by correlating based on thread ids and timestamps.\n+ * The result of this correlation, performed by {@link #processTraces(File)},\n+ * are {@link CallTree}s which are created for each thread which has seen an {@linkplain Span#activate() activation}\n+ * and at least one stack trace.\n+ * Once {@linkplain ActivationEvent#handleDeactivationEvent(SamplingProfiler) handling the deactivation event} of the root span in a thread\n+ * (after which {@link ElasticApmTracer#getActive()} would return {@code null}),\n+ * the {@link CallTree} is {@linkplain CallTree#spanify(CallTree.Root, TraceContext) converted into regular spans}.\n+ * </p>\n+ * <p>\n+ * Overall, the allocation rate does not depend on the number of {@link ActivationEvent}s but only on\n+ * {@link ProfilingConfiguration#getProfilingInterval()} and {@link ProfilingConfiguration#getSamplingInterval()}.\n+ * Having said that, there are some optimizations so that the JFR file is not processed at all if there have not been any\n+ * {@link ActivationEvent} in a given profiling session.\n+ * Also, only if there's a {@link CallTree.Root} for a {@link StackTraceEvent},\n+ * we will {@link JfrParser#resolveStackTrace(long, boolean, List, int) resolve the full stack trace}.\n+ * </p>\n+ */\n+public class SamplingProfiler implements Runnable, LifecycleListener {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(SamplingProfiler.class);\n+    private static final int ACTIVATION_EVENTS_IN_FILE = 1_000_000;\n+    private static final int MAX_STACK_DEPTH = 256;\n+    private static final int PRE_ALLOCATE_ACTIVATION_EVENTS_FILE_MB = 10;\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> ACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder<?> active, TraceContextHolder<?> previouslyActive) {\n+                event.activation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> DEACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder active, TraceContextHolder previouslyActive) {\n+                event.deactivation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    // sizeof(ActivationEvent) is 176B so the ring buffer should be around 880KiB\n+    static final int RING_BUFFER_SIZE = 4 * 1024;\n+\n+    private final ProfilingConfiguration config;\n+    private final ScheduledExecutorService scheduler;\n+    private final Long2ObjectHashMap<CallTree.Root> profiledThreads = new Long2ObjectHashMap<>();\n+    private final RingBuffer<ActivationEvent> eventBuffer;\n+    private volatile boolean profilingSessionOngoing = false;\n+    private final Sequence sequence;\n+    private final ElasticApmTracer tracer;\n+    private final NanoClock nanoClock;\n+    private final ObjectPool<CallTree.Root> rootPool;\n+    private final NativeThreadIdToJavaThreadMapper threadMapper = new NativeThreadIdToJavaThreadMapper();\n+    private final MappedByteBuffer activationEventBuffer;\n+    private final EventPoller<ActivationEvent> poller;\n+    private final File activationEventsFile;\n+    private final File jfrFile;\n+    private final WriteActivationEventToFileHandler writeActivationEventToFileHandler = new WriteActivationEventToFileHandler();\n+    private final JfrParser jfrParser = new JfrParser();\n+    private volatile int profilingSessions;\n+\n+    public SamplingProfiler(ElasticApmTracer tracer, NanoClock nanoClock) throws IOException {\n+        this(tracer,\n+            tracer.getConfig(ProfilingConfiguration.class),\n+            ExecutorUtils.createSingleThreadSchedulingDeamonPool(\"sampling-profiler\"),\n+            nanoClock);\n+    }\n+\n+    SamplingProfiler(final ElasticApmTracer tracer, ProfilingConfiguration config, ScheduledExecutorService scheduler, NanoClock nanoClock) throws IOException {\n+        this.tracer = tracer;\n+        this.config = config;\n+        this.scheduler = scheduler;\n+        this.nanoClock = nanoClock;\n+        this.eventBuffer = createRingBuffer();\n+        this.sequence = new Sequence();\n+        // tells the ring buffer to not override slots which have not been read yet\n+        this.eventBuffer.addGatingSequences(sequence);\n+        this.poller = eventBuffer.newPoller();\n+        // call tree roots are pooled so that fast activations/deactivations with no associated stack traces don't cause allocations\n+        this.rootPool = ListBasedObjectPool.<CallTree.Root>ofRecyclable(new ArrayList<CallTree.Root>(), 512, new Allocator<CallTree.Root>() {\n+            @Override\n+            public CallTree.Root createInstance() {\n+                return new CallTree.Root(tracer);\n+            }\n+        });\n+        jfrFile = File.createTempFile(\"apm-traces-\", \".jfr\");\n+        activationEventsFile = File.createTempFile(\"apm-activation-events-\", \".bin\");\n+        try (RandomAccessFile randomAccessFile = new RandomAccessFile(activationEventsFile, \"rw\")) {\n+            activationEventBuffer = randomAccessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, ACTIVATION_EVENTS_IN_FILE * ActivationEvent.SERIALIZED_SIZE);\n+            preAllocate(activationEventBuffer, PRE_ALLOCATE_ACTIVATION_EVENTS_FILE_MB);\n+        }\n+    }\n+\n+    /**\n+     * Makes sure that the first blocks of the file are contiguous to provide fast sequential access\n+     */\n+    private static void preAllocate(MappedByteBuffer activationEventBuffer, int mb) {\n+        byte[] oneKb = new byte[1024];\n+        for (int i = 0; i < mb * 1024; i++) {\n+            activationEventBuffer.put(oneKb);\n+        }\n+        ((Buffer) activationEventBuffer).clear();\n+    }\n+\n+    private RingBuffer<ActivationEvent> createRingBuffer() {\n+        return RingBuffer.<ActivationEvent>createMultiProducer(\n+            new EventFactory<ActivationEvent>() {\n+                @Override\n+                public ActivationEvent newInstance() {\n+                    return new ActivationEvent();\n+                }\n+            },\n+            RING_BUFFER_SIZE,\n+            new NoWaitStrategy());\n+    }\n+\n+    /**\n+     * Called whenever a span is activated.\n+     * <p>\n+     * This and {@link #onDeactivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onActivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            boolean success = eventBuffer.tryPublishEvent(ACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+            if (!success && logger.isDebugEnabled()) {\n+                logger.debug(\"Could not add activation event to ring buffer as no slots are available\");\n+            }\n+            return success;\n+        }\n+        return false;\n+    }\n+\n+    /**\n+     * Called whenever a span is deactivated.\n+     * <p>\n+     * This and {@link #onActivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onDeactivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            boolean success = eventBuffer.tryPublishEvent(DEACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+            if (!success && logger.isDebugEnabled()) {\n+                logger.debug(\"Could not add deactivation event to ring buffer as no slots are available\");\n+            }\n+            return success;\n+        }\n+        return false;\n+    }\n+\n+    @Override\n+    public void run() {\n+        profilingSessions++;\n+        if (config.isProfilingDisabled()) {\n+            scheduler.schedule(this, config.getProfilingInterval().getMillis(), TimeUnit.MILLISECONDS);\n+            return;\n+        }\n+\n+        TimeDuration sampleRate = config.getSamplingInterval();\n+        TimeDuration profilingDuration = config.getProfilingDuration();\n+\n+        setProfilingSessionOngoing(true);\n+\n+        logger.debug(\"Start profiling session\");\n+        try {\n+            profile(sampleRate, profilingDuration);\n+        } catch (Throwable t) {\n+            setProfilingSessionOngoing(false);\n+            logger.error(\"Stopping profiler\", t);\n+            return;\n+        }\n+        logger.debug(\"End profiling session\");\n+\n+        boolean interrupted = Thread.currentThread().isInterrupted();\n+        boolean continueProfilingSession = config.isNonStopProfiling() && !interrupted && config.isProfilingEnabled();\n+        setProfilingSessionOngoing(continueProfilingSession);\n+\n+        if (!interrupted) {\n+            long delay = config.getProfilingInterval().getMillis() - profilingDuration.getMillis();\n+            scheduler.schedule(this, delay, TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private void profile(TimeDuration sampleRate, TimeDuration profilingDuration) throws Exception {\n+        AsyncProfiler asyncProfiler = AsyncProfiler.getInstance();\n+        try {\n+            String startMessage = asyncProfiler.execute(\"start,jfr,event=wall,interval=\" + sampleRate.getMillis() + \"ms,alluser,file=\" + jfrFile);\n+            logger.debug(startMessage);\n+\n+            consumeActivationEventsFromRingBufferAndWriteToFile(profilingDuration);\n+\n+            String stopMessage = asyncProfiler.execute(\"stop\");\n+            logger.debug(stopMessage);\n+\n+            processTraces(jfrFile);\n+        } catch (InterruptedException e) {\n+            asyncProfiler.stop();\n+            Thread.currentThread().interrupt();\n+        }\n+    }\n+\n+    private void consumeActivationEventsFromRingBufferAndWriteToFile(TimeDuration profilingDuration) throws Exception {\n+        resetActivationEventBuffer();\n+        long threshold = System.currentTimeMillis() + profilingDuration.getMillis();\n+        long initialSleep = 100_000;\n+        long maxSleep = 10_000_000;\n+        long sleep = initialSleep;\n+        while (System.currentTimeMillis() < threshold) {\n+            if (activationEventBuffer.hasRemaining()) {\n+                EventPoller.PollState poll = consumeActivationEventsFromRingBufferAndWriteToFile();\n+                if (poll == EventPoller.PollState.PROCESSING) {\n+                    sleep = initialSleep;\n+                } else {\n+                    if (sleep < maxSleep) {\n+                        sleep *= 2;\n+                    }\n+                }\n+                LockSupport.parkNanos(sleep);", "originalCommit": "d1f24f4fa0dc2589d2fcfdd5e243eb58c1446489", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIxODg3MA==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r374218870", "bodyText": "Good catch, there might be new data after poll returns.", "author": "felixbarny", "createdAt": "2020-02-03T16:54:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzA2MzY0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzA3Nzk0NA==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r373077944", "bodyText": "IMO, a regular List, sorted afterwards, will be more space-efficient, and will preserve StackTraceEvents with duplicate timestamps (although they are unlikely).", "author": "apangin", "createdAt": "2020-01-30T17:08:47Z", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/SamplingProfiler.java", "diffHunk": "@@ -0,0 +1,657 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.configuration.converter.TimeDuration;\n+import co.elastic.apm.agent.context.LifecycleListener;\n+import co.elastic.apm.agent.impl.ElasticApmTracer;\n+import co.elastic.apm.agent.impl.transaction.Span;\n+import co.elastic.apm.agent.impl.transaction.StackFrame;\n+import co.elastic.apm.agent.impl.transaction.TraceContext;\n+import co.elastic.apm.agent.impl.transaction.TraceContextHolder;\n+import co.elastic.apm.agent.matcher.WildcardMatcher;\n+import co.elastic.apm.agent.objectpool.Allocator;\n+import co.elastic.apm.agent.objectpool.ObjectPool;\n+import co.elastic.apm.agent.objectpool.impl.ListBasedObjectPool;\n+import co.elastic.apm.agent.profiler.asyncprofiler.AsyncProfiler;\n+import co.elastic.apm.agent.profiler.asyncprofiler.JfrParser;\n+import co.elastic.apm.agent.profiler.collections.Long2ObjectHashMap;\n+import co.elastic.apm.agent.profiler.collections.LongHashSet;\n+import co.elastic.apm.agent.util.ExecutorUtils;\n+import com.lmax.disruptor.EventFactory;\n+import com.lmax.disruptor.EventPoller;\n+import com.lmax.disruptor.EventTranslatorTwoArg;\n+import com.lmax.disruptor.RingBuffer;\n+import com.lmax.disruptor.Sequence;\n+import com.lmax.disruptor.SequenceBarrier;\n+import com.lmax.disruptor.WaitStrategy;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.LockSupport;\n+\n+/**\n+ * Correlates {@link ActivationEvent}s with {@link StackFrame}s which are recorded by {@link AsyncProfiler},\n+ * a native <a href=\"http://psy-lob-saw.blogspot.com/2016/06/the-pros-and-cons-of-agct.html\">{@code AsyncGetCallTree}</a>-based\n+ * (and therefore <a href=\"http://psy-lob-saw.blogspot.com/2016/02/why-most-sampling-java-profilers-are.html\"> non safepoint-biased</a>)\n+ * JVMTI agent.\n+ * <p>\n+ * Recording of {@link ActivationEvent}s:\n+ * </p>\n+ * <p>\n+ * The {@link #onActivation} and {@link #onDeactivation} methods are called by {@link ProfilingActivationListener}\n+ * which register an {@link ActivationEvent} in to a {@linkplain #eventBuffer ring buffer} whenever a {@link Span}\n+ * gets {@link Span#activate()}d or {@link Span#deactivate()}d while a {@linkplain #profilingSessionOngoing profiling session is ongoing}.\n+ * A background thread consumes the {@link ActivationEvent}s and writes them to a {@linkplain #activationEventBuffer memory-mapped file}.\n+ * That is necessary because within a profiling session (which lasts 10s by default) there may be many more {@link ActivationEvent}s\n+ * than the ring buffer can hold {@link #RING_BUFFER_SIZE}.\n+ * The file can hold {@link #ACTIVATION_EVENTS_IN_FILE} events and each is {@link ActivationEvent#SERIALIZED_SIZE} in size.\n+ * This process is completely garbage free thanks to the {@link RingBuffer} acting as an object pool for {@link ActivationEvent}s.\n+ * </p>\n+ * <p>\n+ * Recording stack traces:\n+ * </p>\n+ * <p>\n+ * The same background thread that processes the {@link ActivationEvent}s starts the wall clock profiler of async-profiler via\n+ * {@link AsyncProfiler#execute(String)}.\n+ * After the {@link ProfilingConfiguration#getProfilingDuration()} is over it stops the profiling and starts processing the JFR file created\n+ * by async-profiler with {@link JfrParser}.\n+ * </p>\n+ * <p>\n+ * Correlating {@link ActivationEvent}s with the traces recorded by {@link AsyncProfiler}:\n+ * </p>\n+ * <p>\n+ * After both the JFR file and the memory-mapped file containing the {@link ActivationEvent}s have been written,\n+ * it's now time to process them in tandem by correlating based on thread ids and timestamps.\n+ * The result of this correlation, performed by {@link #processTraces(File)},\n+ * are {@link CallTree}s which are created for each thread which has seen an {@linkplain Span#activate() activation}\n+ * and at least one stack trace.\n+ * Once {@linkplain ActivationEvent#handleDeactivationEvent(SamplingProfiler) handling the deactivation event} of the root span in a thread\n+ * (after which {@link ElasticApmTracer#getActive()} would return {@code null}),\n+ * the {@link CallTree} is {@linkplain CallTree#spanify(CallTree.Root, TraceContext) converted into regular spans}.\n+ * </p>\n+ * <p>\n+ * Overall, the allocation rate does not depend on the number of {@link ActivationEvent}s but only on\n+ * {@link ProfilingConfiguration#getProfilingInterval()} and {@link ProfilingConfiguration#getSamplingInterval()}.\n+ * Having said that, there are some optimizations so that the JFR file is not processed at all if there have not been any\n+ * {@link ActivationEvent} in a given profiling session.\n+ * Also, only if there's a {@link CallTree.Root} for a {@link StackTraceEvent},\n+ * we will {@link JfrParser#resolveStackTrace(long, boolean, List, int) resolve the full stack trace}.\n+ * </p>\n+ */\n+public class SamplingProfiler implements Runnable, LifecycleListener {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(SamplingProfiler.class);\n+    private static final int ACTIVATION_EVENTS_IN_FILE = 1_000_000;\n+    private static final int MAX_STACK_DEPTH = 256;\n+    private static final int PRE_ALLOCATE_ACTIVATION_EVENTS_FILE_MB = 10;\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> ACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder<?> active, TraceContextHolder<?> previouslyActive) {\n+                event.activation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    private final EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>> DEACTIVATION_EVENT_TRANSLATOR =\n+        new EventTranslatorTwoArg<ActivationEvent, TraceContextHolder<?>, TraceContextHolder<?>>() {\n+            @Override\n+            public void translateTo(ActivationEvent event, long sequence, TraceContextHolder active, TraceContextHolder previouslyActive) {\n+                event.deactivation(active, threadMapper.getNativeThreadId(), previouslyActive, nanoClock.nanoTime());\n+            }\n+        };\n+    // sizeof(ActivationEvent) is 176B so the ring buffer should be around 880KiB\n+    static final int RING_BUFFER_SIZE = 4 * 1024;\n+\n+    private final ProfilingConfiguration config;\n+    private final ScheduledExecutorService scheduler;\n+    private final Long2ObjectHashMap<CallTree.Root> profiledThreads = new Long2ObjectHashMap<>();\n+    private final RingBuffer<ActivationEvent> eventBuffer;\n+    private volatile boolean profilingSessionOngoing = false;\n+    private final Sequence sequence;\n+    private final ElasticApmTracer tracer;\n+    private final NanoClock nanoClock;\n+    private final ObjectPool<CallTree.Root> rootPool;\n+    private final NativeThreadIdToJavaThreadMapper threadMapper = new NativeThreadIdToJavaThreadMapper();\n+    private final MappedByteBuffer activationEventBuffer;\n+    private final EventPoller<ActivationEvent> poller;\n+    private final File activationEventsFile;\n+    private final File jfrFile;\n+    private final WriteActivationEventToFileHandler writeActivationEventToFileHandler = new WriteActivationEventToFileHandler();\n+    private final JfrParser jfrParser = new JfrParser();\n+    private volatile int profilingSessions;\n+\n+    public SamplingProfiler(ElasticApmTracer tracer, NanoClock nanoClock) throws IOException {\n+        this(tracer,\n+            tracer.getConfig(ProfilingConfiguration.class),\n+            ExecutorUtils.createSingleThreadSchedulingDeamonPool(\"sampling-profiler\"),\n+            nanoClock);\n+    }\n+\n+    SamplingProfiler(final ElasticApmTracer tracer, ProfilingConfiguration config, ScheduledExecutorService scheduler, NanoClock nanoClock) throws IOException {\n+        this.tracer = tracer;\n+        this.config = config;\n+        this.scheduler = scheduler;\n+        this.nanoClock = nanoClock;\n+        this.eventBuffer = createRingBuffer();\n+        this.sequence = new Sequence();\n+        // tells the ring buffer to not override slots which have not been read yet\n+        this.eventBuffer.addGatingSequences(sequence);\n+        this.poller = eventBuffer.newPoller();\n+        // call tree roots are pooled so that fast activations/deactivations with no associated stack traces don't cause allocations\n+        this.rootPool = ListBasedObjectPool.<CallTree.Root>ofRecyclable(new ArrayList<CallTree.Root>(), 512, new Allocator<CallTree.Root>() {\n+            @Override\n+            public CallTree.Root createInstance() {\n+                return new CallTree.Root(tracer);\n+            }\n+        });\n+        jfrFile = File.createTempFile(\"apm-traces-\", \".jfr\");\n+        activationEventsFile = File.createTempFile(\"apm-activation-events-\", \".bin\");\n+        try (RandomAccessFile randomAccessFile = new RandomAccessFile(activationEventsFile, \"rw\")) {\n+            activationEventBuffer = randomAccessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, ACTIVATION_EVENTS_IN_FILE * ActivationEvent.SERIALIZED_SIZE);\n+            preAllocate(activationEventBuffer, PRE_ALLOCATE_ACTIVATION_EVENTS_FILE_MB);\n+        }\n+    }\n+\n+    /**\n+     * Makes sure that the first blocks of the file are contiguous to provide fast sequential access\n+     */\n+    private static void preAllocate(MappedByteBuffer activationEventBuffer, int mb) {\n+        byte[] oneKb = new byte[1024];\n+        for (int i = 0; i < mb * 1024; i++) {\n+            activationEventBuffer.put(oneKb);\n+        }\n+        ((Buffer) activationEventBuffer).clear();\n+    }\n+\n+    private RingBuffer<ActivationEvent> createRingBuffer() {\n+        return RingBuffer.<ActivationEvent>createMultiProducer(\n+            new EventFactory<ActivationEvent>() {\n+                @Override\n+                public ActivationEvent newInstance() {\n+                    return new ActivationEvent();\n+                }\n+            },\n+            RING_BUFFER_SIZE,\n+            new NoWaitStrategy());\n+    }\n+\n+    /**\n+     * Called whenever a span is activated.\n+     * <p>\n+     * This and {@link #onDeactivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onActivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            boolean success = eventBuffer.tryPublishEvent(ACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+            if (!success && logger.isDebugEnabled()) {\n+                logger.debug(\"Could not add activation event to ring buffer as no slots are available\");\n+            }\n+            return success;\n+        }\n+        return false;\n+    }\n+\n+    /**\n+     * Called whenever a span is deactivated.\n+     * <p>\n+     * This and {@link #onActivation(TraceContextHolder, TraceContextHolder)} are the only methods which are executed in a multi-threaded\n+     * context.\n+     * </p>\n+     *\n+     * @param activeSpan       the span which is about to be activated\n+     * @param previouslyActive the span which has previously been activated\n+     * @return {@code true}, if the event could be processed, {@code false} if the internal event queue is full which means the event has been discarded\n+     */\n+    public boolean onDeactivation(TraceContextHolder<?> activeSpan, @Nullable TraceContextHolder<?> previouslyActive) {\n+        if (profilingSessionOngoing) {\n+            boolean success = eventBuffer.tryPublishEvent(DEACTIVATION_EVENT_TRANSLATOR, activeSpan, previouslyActive);\n+            if (!success && logger.isDebugEnabled()) {\n+                logger.debug(\"Could not add deactivation event to ring buffer as no slots are available\");\n+            }\n+            return success;\n+        }\n+        return false;\n+    }\n+\n+    @Override\n+    public void run() {\n+        profilingSessions++;\n+        if (config.isProfilingDisabled()) {\n+            scheduler.schedule(this, config.getProfilingInterval().getMillis(), TimeUnit.MILLISECONDS);\n+            return;\n+        }\n+\n+        TimeDuration sampleRate = config.getSamplingInterval();\n+        TimeDuration profilingDuration = config.getProfilingDuration();\n+\n+        setProfilingSessionOngoing(true);\n+\n+        logger.debug(\"Start profiling session\");\n+        try {\n+            profile(sampleRate, profilingDuration);\n+        } catch (Throwable t) {\n+            setProfilingSessionOngoing(false);\n+            logger.error(\"Stopping profiler\", t);\n+            return;\n+        }\n+        logger.debug(\"End profiling session\");\n+\n+        boolean interrupted = Thread.currentThread().isInterrupted();\n+        boolean continueProfilingSession = config.isNonStopProfiling() && !interrupted && config.isProfilingEnabled();\n+        setProfilingSessionOngoing(continueProfilingSession);\n+\n+        if (!interrupted) {\n+            long delay = config.getProfilingInterval().getMillis() - profilingDuration.getMillis();\n+            scheduler.schedule(this, delay, TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private void profile(TimeDuration sampleRate, TimeDuration profilingDuration) throws Exception {\n+        AsyncProfiler asyncProfiler = AsyncProfiler.getInstance();\n+        try {\n+            String startMessage = asyncProfiler.execute(\"start,jfr,event=wall,interval=\" + sampleRate.getMillis() + \"ms,alluser,file=\" + jfrFile);\n+            logger.debug(startMessage);\n+\n+            consumeActivationEventsFromRingBufferAndWriteToFile(profilingDuration);\n+\n+            String stopMessage = asyncProfiler.execute(\"stop\");\n+            logger.debug(stopMessage);\n+\n+            processTraces(jfrFile);\n+        } catch (InterruptedException e) {\n+            asyncProfiler.stop();\n+            Thread.currentThread().interrupt();\n+        }\n+    }\n+\n+    private void consumeActivationEventsFromRingBufferAndWriteToFile(TimeDuration profilingDuration) throws Exception {\n+        resetActivationEventBuffer();\n+        long threshold = System.currentTimeMillis() + profilingDuration.getMillis();\n+        long initialSleep = 100_000;\n+        long maxSleep = 10_000_000;\n+        long sleep = initialSleep;\n+        while (System.currentTimeMillis() < threshold) {\n+            if (activationEventBuffer.hasRemaining()) {\n+                EventPoller.PollState poll = consumeActivationEventsFromRingBufferAndWriteToFile();\n+                if (poll == EventPoller.PollState.PROCESSING) {\n+                    sleep = initialSleep;\n+                } else {\n+                    if (sleep < maxSleep) {\n+                        sleep *= 2;\n+                    }\n+                }\n+                LockSupport.parkNanos(sleep);\n+            } else {\n+                logger.warn(\"The activation events file is full. Try lowering the profiling_duration.\");\n+                // the file is full, sleep the rest of the profilingDuration\n+                Thread.sleep(Math.max(0, threshold - System.currentTimeMillis()));\n+            }\n+        }\n+    }\n+\n+    private void resetActivationEventBuffer() {\n+        ((Buffer) activationEventBuffer).clear();\n+    }\n+\n+    EventPoller.PollState consumeActivationEventsFromRingBufferAndWriteToFile() throws Exception {\n+        return poller.poll(writeActivationEventToFileHandler);\n+    }\n+\n+    private void processTraces(File file) throws IOException {\n+        if (activationEventBuffer.position() == 0) {\n+            logger.debug(\"No activation events during this period. Skip processing stack traces.\");\n+            return;\n+        }\n+        long start = System.nanoTime();\n+        List<WildcardMatcher> excludedClasses = config.getExcludedClasses();\n+        List<WildcardMatcher> includedClasses = config.getIncludedClasses();\n+        try {\n+            jfrParser.parse(file, excludedClasses, includedClasses);\n+            startProcessingActivationEventsFile();\n+            final SortedSet<StackTraceEvent> stackTraceEvents = getStackTraceEvents(jfrParser);\n+            if (logger.isDebugEnabled()) {\n+                logger.debug(\"Processing {} stack traces\", stackTraceEvents.size());\n+            }\n+            List<StackFrame> stackFrames = new ArrayList<>();\n+            ElasticApmTracer tracer = this.tracer;\n+            ActivationEvent event = new ActivationEvent();\n+            for (StackTraceEvent stackTrace : stackTraceEvents) {\n+                processActivationEventsUpTo(stackTrace.nanoTime, event);\n+                CallTree.Root root = profiledThreads.get(stackTrace.threadId);\n+                if (root != null) {\n+                    jfrParser.resolveStackTrace(stackTrace.stackTraceId, true, stackFrames, MAX_STACK_DEPTH);\n+                    if (stackFrames.size() == MAX_STACK_DEPTH) {\n+                        logger.debug(\"Max stack depth reached. Set profiling_included_classes or profiling_excluded_classes.\");\n+                    }\n+                    root.addStackTrace(tracer, stackFrames, stackTrace.nanoTime);\n+                }\n+                stackFrames.clear();\n+            }\n+        } finally {\n+            if (logger.isDebugEnabled()) {\n+                logger.debug(\"Processing traces took {}\u00b5s\", (System.nanoTime() - start) / 1000);\n+            }\n+            jfrParser.resetState();\n+        }\n+    }\n+\n+    /**\n+     * Returns stack trace events of relevant threads sorted by timestamp.\n+     * The events in the JFR file are not in order.\n+     * Even for the same thread, a more recent event might come before an older event.\n+     * In order to be able to correlate stack trace events and activation events, both need to be in order.\n+     *\n+     * Returns only events for threads where at least one activation happened\n+     */\n+    private SortedSet<StackTraceEvent> getStackTraceEvents(JfrParser jfrParser) throws IOException {\n+        final LongHashSet nativeThreadIds = threadMapper.getNativeThreadIds();\n+        final SortedSet<StackTraceEvent> stackTraceEvents = new TreeSet<>();", "originalCommit": "d1f24f4fa0dc2589d2fcfdd5e243eb58c1446489", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzA5ODQwOA==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r373098408", "bodyText": "Matching Java threads by native id looks a bit hacky. It probably makes sense for async-profiler to record Java thread id, too.", "author": "apangin", "createdAt": "2020-01-30T17:48:46Z", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/NativeThreadIdToJavaThreadMapper.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/*-\n+ * #%L\n+ * Elastic APM Java agent\n+ * %%\n+ * Copyright (C) 2018 - 2019 Elastic and contributors\n+ * %%\n+ * Licensed to Elasticsearch B.V. under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch B.V. licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ * #L%\n+ */\n+package co.elastic.apm.agent.profiler;\n+\n+import co.elastic.apm.agent.profiler.asyncprofiler.AsyncProfiler;\n+import co.elastic.apm.agent.profiler.collections.LongHashSet;\n+import com.blogspot.mydailyjava.weaklockfree.DetachedThreadLocal;\n+import com.blogspot.mydailyjava.weaklockfree.WeakConcurrentMap;\n+\n+import java.util.Map;\n+\n+public class NativeThreadIdToJavaThreadMapper {\n+\n+    private final DetachedThreadLocal<Long> threadToNativeThread = new DetachedThreadLocal<>(DetachedThreadLocal.Cleaner.INLINE);\n+\n+    /**\n+     * Returns the native thread id of the current thread\n+     */\n+    public long getNativeThreadId() {\n+        Long nativeThreadId = threadToNativeThread.get();\n+        if (nativeThreadId == null) {\n+            nativeThreadId = AsyncProfiler.getInstance().getNativeThreadId();\n+            threadToNativeThread.set(nativeThreadId);\n+        }\n+        return nativeThreadId;\n+    }", "originalCommit": "d1f24f4fa0dc2589d2fcfdd5e243eb58c1446489", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIxNzM2Ng==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r374217366", "bodyText": "Agree. See also jvm-profiling-tools/async-profiler#277 (comment)", "author": "felixbarny", "createdAt": "2020-02-03T16:52:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzA5ODQwOA=="}], "type": "inlineReview"}, {"oid": "b14253690f5eb1256bdd189eced6930ee683a7bf", "url": "https://github.com/elastic/apm-agent-java/commit/b14253690f5eb1256bdd189eced6930ee683a7bf", "message": "Apply Andrei's suggestions", "committedDate": "2020-02-03T17:01:46Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQ5MjEyNA==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r374492124", "bodyText": "Maybe switch to using the binary header functionalities for serialization (fillOutgoingTraceParentBinaryHeader) and deserialization (asChildOf(byte[])), with an extended byte array where you separately serialize/deserialize the clock and service name? Just so we don't need to maintain both", "author": "eyalkoren", "createdAt": "2020-02-04T06:22:47Z", "path": "apm-agent-core/src/main/java/co/elastic/apm/agent/impl/transaction/TraceContext.java", "diffHunk": "@@ -559,6 +575,51 @@ public ClassLoader getApplicationClassLoader() {\n         }\n     }\n \n+    public byte[] serialize() {\n+        byte[] result = new byte[SERIALIZED_LENGTH];\n+        serialize(result);\n+        return result;\n+    }\n+\n+    public void serialize(byte[] buffer) {", "originalCommit": "b14253690f5eb1256bdd189eced6930ee683a7bf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "1facfb4a5c1caaff2cff1bfec001a3ca0a9e77d8", "url": "https://github.com/elastic/apm-agent-java/commit/1facfb4a5c1caaff2cff1bfec001a3ca0a9e77d8", "message": "Check if frames from async-profiler are non-empty before adding to call tree\n\nOtherwise, we'd prematurely end branches\nSee also https://github.com/jvm-profiling-tools/async-profiler/issues/271#issuecomment-582430233", "committedDate": "2020-02-05T14:25:31Z", "type": "commit"}, {"oid": "cc2bde3a4df113602222358f73128a92cb3d2368", "url": "https://github.com/elastic/apm-agent-java/commit/cc2bde3a4df113602222358f73128a92cb3d2368", "message": "Only profile threads with active transactions", "committedDate": "2020-02-05T15:42:27Z", "type": "commit"}, {"oid": "e0a355ca3ab3cfb3b72cb1f2d63fb2e20b5af6f1", "url": "https://github.com/elastic/apm-agent-java/commit/e0a355ca3ab3cfb3b72cb1f2d63fb2e20b5af6f1", "message": "Don't use memory mapped file to read activation events", "committedDate": "2020-02-08T10:27:52Z", "type": "commit"}, {"oid": "5b2f7fc6470da903c113748d30c75747543ac845", "url": "https://github.com/elastic/apm-agent-java/commit/5b2f7fc6470da903c113748d30c75747543ac845", "message": "Increase activation events direct buffer to ~100kb", "committedDate": "2020-02-08T18:02:38Z", "type": "commit"}, {"oid": "cfa4e6f3c152f65add494e01f9f0bc566bfd6069", "url": "https://github.com/elastic/apm-agent-java/commit/cfa4e6f3c152f65add494e01f9f0bc566bfd6069", "message": "Use a moving DirectByteBuffer instead of MappedByteBuffer to read the file", "committedDate": "2020-02-10T15:53:45Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzIyODA0Ng==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r377228046", "bodyText": "Seems like we read redundant 4MB at the beginning, since after getting metadata offset, we immediately seek to the end of the file. Probably, read can accept another parameter - the maximum number of bytes to read.", "author": "apangin", "createdAt": "2020-02-10T18:08:01Z", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/BufferedFile.java", "diffHunk": "@@ -0,0 +1,244 @@\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+\n+/**\n+ * An abstraction similar to {@link MappedByteBuffer} that allows to read the content of a file with an API that is similar to\n+ * {@link ByteBuffer}.\n+ * <p>\n+ * Instances of this class hold a reusable buffer that contains a subset of the file,\n+ * or the whole file if the buffer's capacity is greater or equal to the file's size.\n+ * </p>\n+ * <p>\n+ * Whenever calling a method like {@link #getLong()} or {@link #position(long)} would exceed the currently buffered range\n+ * the same buffer is filled with a different range of the file.\n+ * </p>\n+ * <p>\n+ * The downside of {@link MappedByteBuffer} (and the reason for implementing this abstraction)\n+ * is that calling methods like {@link MappedByteBuffer#get()} can increase time-to-safepoint.\n+ * This is because these methods are implemented as JVM intrinsics.\n+ * When the JVM executes an intrinsic, it does not switch to the native execution context which means that it's not ready to enter a safepoint\n+ * whenever a intrinsic runs.\n+ * As reading a file from disk can get stuck (for example when the disk is busy) calling {@link MappedByteBuffer#get()} may take a while to execute.\n+ * While it's executing other threads have to wait for it to finish if the JVM wants to reach a safe point.\n+ * </p>\n+ */\n+class BufferedFile implements Recyclable {\n+\n+    private static final int SIZE_OF_BYTE = 1;\n+    private static final int SIZE_OF_SHORT = 2;\n+    private static final int SIZE_OF_INT = 4;\n+    private static final int SIZE_OF_LONG = 8;\n+    private final ByteBuffer buffer;\n+    private final int capacity;\n+    private long offset;\n+    private long limit;\n+    private boolean wholeFileInBuffer;\n+    @Nullable\n+    private RandomAccessFile randomAccessFile;\n+    @Nullable\n+    private FileChannel fileChannel;\n+\n+    public BufferedFile(ByteBuffer buffer) {\n+        this.buffer = buffer;\n+        capacity = buffer.capacity();\n+    }\n+\n+    /**\n+     * Starts reading the file into the {@linkplain #buffer buffer}\n+     *\n+     * @param file the file to read from\n+     * @throws IOException If some I/O error occurs\n+     */\n+    public void setFile(File file) throws IOException {\n+        randomAccessFile = new RandomAccessFile(file, \"r\");\n+        fileChannel = randomAccessFile.getChannel();\n+        read(0);", "originalCommit": "cfa4e6f3c152f65add494e01f9f0bc566bfd6069", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODg0MzEzOA==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r378843138", "bodyText": "good catch! done.", "author": "felixbarny", "createdAt": "2020-02-13T12:57:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzIyODA0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzIyOTg5MA==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r377229890", "bodyText": "A small note: RandomAccessFile is redundant, when it is used only to get FileChannel. You may directly call FileChannel.open instead.", "author": "apangin", "createdAt": "2020-02-10T18:11:35Z", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/BufferedFile.java", "diffHunk": "@@ -0,0 +1,244 @@\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.Buffer;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+\n+/**\n+ * An abstraction similar to {@link MappedByteBuffer} that allows to read the content of a file with an API that is similar to\n+ * {@link ByteBuffer}.\n+ * <p>\n+ * Instances of this class hold a reusable buffer that contains a subset of the file,\n+ * or the whole file if the buffer's capacity is greater or equal to the file's size.\n+ * </p>\n+ * <p>\n+ * Whenever calling a method like {@link #getLong()} or {@link #position(long)} would exceed the currently buffered range\n+ * the same buffer is filled with a different range of the file.\n+ * </p>\n+ * <p>\n+ * The downside of {@link MappedByteBuffer} (and the reason for implementing this abstraction)\n+ * is that calling methods like {@link MappedByteBuffer#get()} can increase time-to-safepoint.\n+ * This is because these methods are implemented as JVM intrinsics.\n+ * When the JVM executes an intrinsic, it does not switch to the native execution context which means that it's not ready to enter a safepoint\n+ * whenever a intrinsic runs.\n+ * As reading a file from disk can get stuck (for example when the disk is busy) calling {@link MappedByteBuffer#get()} may take a while to execute.\n+ * While it's executing other threads have to wait for it to finish if the JVM wants to reach a safe point.\n+ * </p>\n+ */\n+class BufferedFile implements Recyclable {\n+\n+    private static final int SIZE_OF_BYTE = 1;\n+    private static final int SIZE_OF_SHORT = 2;\n+    private static final int SIZE_OF_INT = 4;\n+    private static final int SIZE_OF_LONG = 8;\n+    private final ByteBuffer buffer;\n+    private final int capacity;\n+    private long offset;\n+    private long limit;\n+    private boolean wholeFileInBuffer;\n+    @Nullable\n+    private RandomAccessFile randomAccessFile;\n+    @Nullable\n+    private FileChannel fileChannel;\n+\n+    public BufferedFile(ByteBuffer buffer) {\n+        this.buffer = buffer;\n+        capacity = buffer.capacity();\n+    }\n+\n+    /**\n+     * Starts reading the file into the {@linkplain #buffer buffer}\n+     *\n+     * @param file the file to read from\n+     * @throws IOException If some I/O error occurs\n+     */\n+    public void setFile(File file) throws IOException {\n+        randomAccessFile = new RandomAccessFile(file, \"r\");\n+        fileChannel = randomAccessFile.getChannel();", "originalCommit": "cfa4e6f3c152f65add494e01f9f0bc566bfd6069", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzIzMTc0NQ==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r377231745", "bodyText": "I'd add & 0xffff to convert this to an unsigned short.\nThere hardly be a string larger than 32K, but just in case.\nThe same in skipString.", "author": "apangin", "createdAt": "2020-02-10T18:15:27Z", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/JfrParser.java", "diffHunk": "@@ -363,16 +339,17 @@ private StackFrame resolveStackFrame(int classId, int methodName) {\n         }\n     }\n \n-    private StringBuilder readUtf8String() {\n+    private StringBuilder readUtf8String() throws IOException {\n         return readUtf8String(false);\n     }\n \n-    private StringBuilder readUtf8String(boolean replaceSlashWithDot) {\n-        int size = buffer.getShort();\n+    private StringBuilder readUtf8String(boolean replaceSlashWithDot) throws IOException {\n+        int size = bufferedFile.getShort();", "originalCommit": "cfa4e6f3c152f65add494e01f9f0bc566bfd6069", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "96c0f80211cc5d30e9db759845f07c30b7095c0c", "url": "https://github.com/elastic/apm-agent-java/commit/96c0f80211cc5d30e9db759845f07c30b7095c0c", "message": "Make sure to not read redundant 4mb at the beginning\n\n- Remove RandomAccessFile with FileChannel.open\n- convert string length to unsigned short", "committedDate": "2020-02-13T12:57:03Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTU0MDIzNw==", "url": "https://github.com/elastic/apm-agent-java/pull/983#discussion_r379540237", "bodyText": "0xffff", "author": "apangin", "createdAt": "2020-02-14T16:57:21Z", "path": "apm-agent-plugins/apm-profiling-plugin/src/main/java/co/elastic/apm/agent/profiler/asyncprofiler/BufferedFile.java", "diffHunk": "@@ -0,0 +1,278 @@\n+package co.elastic.apm.agent.profiler.asyncprofiler;\n+\n+import co.elastic.apm.agent.objectpool.Recyclable;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.MappedByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.StandardOpenOption;\n+\n+/**\n+ * An abstraction similar to {@link MappedByteBuffer} that allows to read the content of a file with an API that is similar to\n+ * {@link ByteBuffer}.\n+ * <p>\n+ * Instances of this class hold a reusable buffer that contains a subset of the file,\n+ * or the whole file if the buffer's capacity is greater or equal to the file's size.\n+ * </p>\n+ * <p>\n+ * Whenever calling a method like {@link #getLong()} or {@link #position(long)} would exceed the currently buffered range\n+ * the same buffer is filled with a different range of the file.\n+ * </p>\n+ * <p>\n+ * The downside of {@link MappedByteBuffer} (and the reason for implementing this abstraction)\n+ * is that calling methods like {@link MappedByteBuffer#get()} can increase time-to-safepoint.\n+ * This is because these methods are implemented as JVM intrinsics.\n+ * When the JVM executes an intrinsic, it does not switch to the native execution context which means that it's not ready to enter a safepoint\n+ * whenever a intrinsic runs.\n+ * As reading a file from disk can get stuck (for example when the disk is busy) calling {@link MappedByteBuffer#get()} may take a while to execute.\n+ * While it's executing other threads have to wait for it to finish if the JVM wants to reach a safe point.\n+ * </p>\n+ */\n+class BufferedFile implements Recyclable {\n+\n+    private static final int SIZE_OF_BYTE = 1;\n+    private static final int SIZE_OF_SHORT = 2;\n+    private static final int SIZE_OF_INT = 4;\n+    private static final int SIZE_OF_LONG = 8;\n+    private final ByteBuffer buffer;\n+    private final int capacity;\n+    /**\n+     * The offset of the file from where the {@link #buffer} starts\n+     */\n+    private long offset;\n+    private boolean wholeFileInBuffer;\n+    @Nullable\n+    private FileChannel fileChannel;\n+\n+    public BufferedFile(ByteBuffer buffer) {\n+        this.buffer = buffer;\n+        capacity = buffer.capacity();\n+    }\n+\n+    /**\n+     * Starts reading the file into the {@linkplain #buffer buffer}\n+     *\n+     * @param file the file to read from\n+     * @throws IOException If some I/O error occurs\n+     */\n+    public void setFile(File file) throws IOException {\n+        fileChannel = FileChannel.open(file.toPath(), StandardOpenOption.READ);\n+        if (fileChannel.size() <= capacity) {\n+            read(0, capacity);\n+            wholeFileInBuffer = true;\n+        } else {\n+            buffer.flip();\n+        }\n+    }\n+\n+    /**\n+     * Returns the position of the file\n+     *\n+     * @return the position of the file\n+     */\n+    public long position() {\n+        return offset + buffer.position();\n+    }\n+\n+    /**\n+     * Skips the provided number of bytes in the file without reading new data.\n+     *\n+     * @param bytesToSkip the number of bytes to skip\n+     */\n+    public void skip(int bytesToSkip) {\n+        position(position() + bytesToSkip);\n+    }\n+\n+    /**\n+     * Sets the position of the file without reading new data.\n+     *\n+     * @param pos the new position\n+     */\n+    public void position(long pos) {\n+        long bufferDelta = pos - (offset + buffer.position());\n+        long newBufferPos = buffer.position() + bufferDelta;\n+        if (0 <= newBufferPos && newBufferPos <= buffer.capacity()) {\n+            buffer.position((int) newBufferPos);\n+        } else {\n+            // makes sure that the next ensureRemaining will load from file\n+            buffer.position(0);\n+            buffer.limit(0);\n+            offset = pos;\n+        }\n+    }\n+\n+    /**\n+     * Ensures that the provided number of bytes are available in the {@linkplain #buffer buffer}\n+     *\n+     * @param minRemaining the number of bytes which are guaranteed to be available in the {@linkplain #buffer buffer}\n+     * @throws IOException           If some I/O error occurs\n+     * @throws IllegalStateException If the provided number of bytes is greater thatn the buffer's capacity\n+     */\n+    public void ensureRemaining(int minRemaining) throws IOException {\n+        ensureRemaining(minRemaining, capacity);\n+    }\n+\n+    public void ensureRemaining(int minRemaining, int maxRead) throws IOException {\n+        if (wholeFileInBuffer) {\n+            return;\n+        }\n+        if (minRemaining > capacity) {\n+            throw new IllegalStateException(String.format(\"Length (%d) greater than buffer capacity (%d)\", minRemaining, capacity));\n+        }\n+        if (buffer.remaining() < minRemaining) {\n+            read(position(), maxRead);\n+        }\n+    }\n+\n+    /**\n+     * Gets a byte from the current {@linkplain #position() position} of this file.\n+     * If the {@linkplain #buffer buffer} does not fully contain this byte, loads another slice of the file into the buffer.\n+     *\n+     * @return The byte at the file's current position\n+     * @throws IOException If some I/O error occurs\n+     */\n+    public short get() throws IOException {\n+        ensureRemaining(SIZE_OF_BYTE);\n+        return buffer.get();\n+    }\n+\n+    /**\n+     * Gets a short from the current {@linkplain #position() position} of this file.\n+     * If the {@linkplain #buffer buffer} does not fully contain this short, loads another slice of the file into the buffer.\n+     *\n+     * @return The short at the file's current position\n+     * @throws IOException If some I/O error occurs\n+     */\n+    public short getShort() throws IOException {\n+        ensureRemaining(SIZE_OF_SHORT);\n+        return buffer.getShort();\n+    }\n+\n+    /**\n+     * Gets a short from the current {@linkplain #position() position} of this file.\n+     * If the {@linkplain #buffer buffer} does not fully contain this short, loads another slice of the file into the buffer.\n+     *\n+     * @return The short at the file's current position\n+     * @throws IOException If some I/O error occurs\n+     */\n+    public int getUnsignedShort() throws IOException {\n+        return getShort() & 0xff;", "originalCommit": "96c0f80211cc5d30e9db759845f07c30b7095c0c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "9fa6885b8571871229ee9bf62eae2fc0b1545888", "url": "https://github.com/elastic/apm-agent-java/commit/9fa6885b8571871229ee9bf62eae2fc0b1545888", "message": "Update to async-profiler 1.7.0-ea2\n\n- Fix restoring thread filter\n- async-profiler now includes Java thread id in the JFR file\n  we can get rid of mapping native thread ids to Java thread ids\n- Make SamplingProfilerTest more reliable\n- Fix bug in when removing thread from filter", "committedDate": "2020-02-15T15:50:24Z", "type": "commit"}, {"oid": "bc22c257a5bbdad945123ce209e0d1bf21b15512", "url": "https://github.com/elastic/apm-agent-java/commit/bc22c257a5bbdad945123ce209e0d1bf21b15512", "message": "Merge remote-tracking branch 'origin/master' into async-profiler", "committedDate": "2020-02-15T16:14:02Z", "type": "commit"}, {"oid": "2992aa91abc32c97e789eb7e8fab584481b0713a", "url": "https://github.com/elastic/apm-agent-java/commit/2992aa91abc32c97e789eb7e8fab584481b0713a", "message": "Don't write to disk if activation events fit into memory (4k events)", "committedDate": "2020-02-15T16:40:18Z", "type": "commit"}, {"oid": "863a1b285db7e45f163e28ecd73f92be7a026b69", "url": "https://github.com/elastic/apm-agent-java/commit/863a1b285db7e45f163e28ecd73f92be7a026b69", "message": "Use ThreadGroup.enumerate to restore filter state", "committedDate": "2020-02-15T21:01:04Z", "type": "commit"}, {"oid": "e01d68077c55d16fddde9142e0d709fb9f6d7df5", "url": "https://github.com/elastic/apm-agent-java/commit/e01d68077c55d16fddde9142e0d709fb9f6d7df5", "message": "Reduce allocations in JfrParser by 85%", "committedDate": "2020-02-15T21:40:49Z", "type": "commit"}, {"oid": "b6860c5aa32850a0bcf7596863d28e91736cd284", "url": "https://github.com/elastic/apm-agent-java/commit/b6860c5aa32850a0bcf7596863d28e91736cd284", "message": "Fix animal sniffer errors", "committedDate": "2020-02-15T21:46:33Z", "type": "commit"}, {"oid": "d4e0d33ad7cfe82e659cba6f09f341b2ae996b06", "url": "https://github.com/elastic/apm-agent-java/commit/d4e0d33ad7cfe82e659cba6f09f341b2ae996b06", "message": "Add benchmarks, performance improvements if file is larger than buffer", "committedDate": "2020-02-16T10:08:34Z", "type": "commit"}, {"oid": "ed311115e3db4a26dd1359bfbcd963ae0829356a", "url": "https://github.com/elastic/apm-agent-java/commit/ed311115e3db4a26dd1359bfbcd963ae0829356a", "message": "Pool CallTree nodes", "committedDate": "2020-02-17T13:33:59Z", "type": "commit"}, {"oid": "47b6f8c40eb9f10e96b2a574f205ef2d3b2683bc", "url": "https://github.com/elastic/apm-agent-java/commit/47b6f8c40eb9f10e96b2a574f205ef2d3b2683bc", "message": "Update to async-profiler 1.7.0-ea3\n\n- disable native frames\n  for the inferred spans use case, we're only interested in Java frames\n  disabling native frames reduces the JFR file size and reduces the profiling overhead a little\n- remove Byte Buddy shading hack", "committedDate": "2020-02-17T15:19:33Z", "type": "commit"}, {"oid": "6f82fca715e6ed976f2068afafa146deb8ae343d", "url": "https://github.com/elastic/apm-agent-java/commit/6f82fca715e6ed976f2068afafa146deb8ae343d", "message": "Make Java 7 compiler happy", "committedDate": "2020-02-17T15:38:52Z", "type": "commit"}, {"oid": "1691719f2b9b0b58944c515d65d1c7413f47adbe", "url": "https://github.com/elastic/apm-agent-java/commit/1691719f2b9b0b58944c515d65d1c7413f47adbe", "message": "Recycle on end\n\n- siginificantly reduces allocations\n- makes CallTree pool more effective", "committedDate": "2020-02-18T15:42:33Z", "type": "commit"}, {"oid": "982ea08559455374b2d8fee0d0a87b427135e47d", "url": "https://github.com/elastic/apm-agent-java/commit/982ea08559455374b2d8fee0d0a87b427135e47d", "message": "Update generated config docs", "committedDate": "2020-02-18T15:51:47Z", "type": "commit"}, {"oid": "b12ccd5d7d7b573d8df113348dd01028d7216499", "url": "https://github.com/elastic/apm-agent-java/commit/b12ccd5d7d7b573d8df113348dd01028d7216499", "message": "Fix Java 7 incompatibility", "committedDate": "2020-02-18T17:01:08Z", "type": "commit"}, {"oid": "cf58e7dda9dd1b60d264a31673df2201a20bf9fe", "url": "https://github.com/elastic/apm-agent-java/commit/cf58e7dda9dd1b60d264a31673df2201a20bf9fe", "message": "Release resources when not profiling\n\n- respect `active` config option\n- clear object pools\n- make JfrParser GC eligible", "committedDate": "2020-02-19T07:03:41Z", "type": "commit"}, {"oid": "a458343d8f057a331ca61ad970c4840d7827c761", "url": "https://github.com/elastic/apm-agent-java/commit/a458343d8f057a331ca61ad970c4840d7827c761", "message": "Avoid recycling of CallTrees while still needed in tests", "committedDate": "2020-02-19T09:46:29Z", "type": "commit"}, {"oid": "7ac04c75093e37f31213d7f2d00c354c36e536ab", "url": "https://github.com/elastic/apm-agent-java/commit/7ac04c75093e37f31213d7f2d00c354c36e536ab", "message": "Attempt to fix service name mismatch", "committedDate": "2020-02-19T15:37:30Z", "type": "commit"}]}