{"pr_number": 782, "pr_title": "PARQUET-1807: Encryption: Interop and Function test suite for Java version", "pr_createdAt": "2020-04-06T11:30:19Z", "pr_url": "https://github.com/apache/parquet-mr/pull/782", "timeline": [{"oid": "44de61ec1bff8fc29e69eb11637340beefa615f0", "url": "https://github.com/apache/parquet-mr/commit/44de61ec1bff8fc29e69eb11637340beefa615f0", "message": "Fix parquet-testing submodule to the latest with license fixes.\n\nAdd exclusion to rat license check for .gitmodules", "committedDate": "2020-05-10T21:08:56Z", "type": "forcePushed"}, {"oid": "9549e6bd42aceeba6242ad4a27edd612b4f3a238", "url": "https://github.com/apache/parquet-mr/commit/9549e6bd42aceeba6242ad4a27edd612b4f3a238", "message": "PARQUET-1807: Encryption: Interop and Function test suite for Java version\n\nDepends on PR #776 for [PARQUET-1229] and\non PR #12 in parquet-testing for [PARQUET-1807].\nJIRA: https://issues.apache.org/jira/browse/PARQUET-1807\nAdd a test for writing and reading parquet in a number of encryption\nand decryption configurations.\nAdd interop test that reads files from parquet-testing GitHub\nrepository, that were written by parquet-cpp.\nThis adds parquet-testing repo as a submodule.\nRun the following to populate the \"submodules/parquet-testing/\" folder:\n   git submodule update --init --recursive", "committedDate": "2020-05-29T21:35:55Z", "type": "commit"}, {"oid": "debc2a7facbd63640846153226ac2a8f9f8a2116", "url": "https://github.com/apache/parquet-mr/commit/debc2a7facbd63640846153226ac2a8f9f8a2116", "message": "Add the parquet-testing submodule definition", "committedDate": "2020-05-29T21:35:55Z", "type": "commit"}, {"oid": "668f67423e8ddd57deaeb969074975f582c619e5", "url": "https://github.com/apache/parquet-mr/commit/668f67423e8ddd57deaeb969074975f582c619e5", "message": "Fix parquet-testing submodule to the latest with license fixes.\n\nAdd exclusion to rat license check for .gitmodules", "committedDate": "2020-05-29T21:35:55Z", "type": "commit"}, {"oid": "4f61ddd8ea97f7255d603fe7f8594c4d5a3845d0", "url": "https://github.com/apache/parquet-mr/commit/4f61ddd8ea97f7255d603fe7f8594c4d5a3845d0", "message": "Add new dimension of isEncrypted to TestBloomFiltering and TestColumnIndexFiltering according to Gabor's suggestion.", "committedDate": "2020-05-29T21:35:55Z", "type": "commit"}, {"oid": "a6162c5cbb1c34512f0cd74b6e84ade1b0e696cf", "url": "https://github.com/apache/parquet-mr/commit/a6162c5cbb1c34512f0cd74b6e84ade1b0e696cf", "message": "Change TestEncryptionOptions to use non-deprecated ParquetWriter api.\nAddress review comments - rename variables and move enums to top.", "committedDate": "2020-05-29T21:35:55Z", "type": "commit"}, {"oid": "a6162c5cbb1c34512f0cd74b6e84ade1b0e696cf", "url": "https://github.com/apache/parquet-mr/commit/a6162c5cbb1c34512f0cd74b6e84ade1b0e696cf", "message": "Change TestEncryptionOptions to use non-deprecated ParquetWriter api.\nAddress review comments - rename variables and move enums to top.", "committedDate": "2020-05-29T21:35:55Z", "type": "forcePushed"}, {"oid": "dbfe9a74f103d4e2192af088c199567034c09d67", "url": "https://github.com/apache/parquet-mr/commit/dbfe9a74f103d4e2192af088c199567034c09d67", "message": "Move submodules file into top folder.", "committedDate": "2020-05-30T12:33:19Z", "type": "commit"}, {"oid": "d192f710ceddb794123a848746f9a63430052abc", "url": "https://github.com/apache/parquet-mr/commit/d192f710ceddb794123a848746f9a63430052abc", "message": "Disable automatic submodules init and do it manually.", "committedDate": "2020-05-30T15:20:09Z", "type": "commit"}, {"oid": "69ba6f78c1f5f8bdf0b5c679dea57cb36f84dfd9", "url": "https://github.com/apache/parquet-mr/commit/69ba6f78c1f5f8bdf0b5c679dea57cb36f84dfd9", "message": "Remove TestBloomEncryption and TestColumnIndexEncryption, since the tests are already included in TestBloomFiltering and TestColumnIndexEncryption", "committedDate": "2020-05-31T07:47:23Z", "type": "commit"}, {"oid": "5510126a0104e66cdb70b093a6a3c74238da821f", "url": "https://github.com/apache/parquet-mr/commit/5510126a0104e66cdb70b093a6a3c74238da821f", "message": "Revert \"Submodule addition and encryption interop test.\"", "committedDate": "2020-05-31T08:04:39Z", "type": "commit"}, {"oid": "4ca6a2febde567c7b8753100c1b80fe2831f403f", "url": "https://github.com/apache/parquet-mr/commit/4ca6a2febde567c7b8753100c1b80fe2831f403f", "message": "Add back submodule parquet-testing and encryption interop test.", "committedDate": "2020-05-31T12:20:35Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzc3Mjc5MA==", "url": "https://github.com/apache/parquet-mr/pull/782#discussion_r433772790", "bodyText": "I do not have experience on git submodules but this solution does not work by default on my machine (while it seems to be working in Travis). Can we do something (maven magic?) to ensure that the files from the submodule are there when the test is executed?", "author": "gszadovszky", "createdAt": "2020-06-02T10:21:00Z", "path": "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestEncryptionOptions.java", "diffHunk": "@@ -0,0 +1,660 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.parquet.hadoop;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.parquet.crypto.ColumnDecryptionProperties;\n+import org.apache.parquet.crypto.ColumnEncryptionProperties;\n+import org.apache.parquet.crypto.FileDecryptionProperties;\n+import org.apache.parquet.crypto.FileEncryptionProperties;\n+import org.apache.parquet.crypto.ParquetCipher;\n+import org.apache.parquet.crypto.DecryptionKeyRetriever;\n+import org.apache.parquet.example.data.Group;\n+import org.apache.parquet.example.data.simple.SimpleGroupFactory;\n+import org.apache.parquet.filter2.compat.FilterCompat;\n+import org.apache.parquet.hadoop.example.ExampleParquetWriter;\n+import org.apache.parquet.hadoop.example.GroupReadSupport;\n+import org.apache.parquet.hadoop.example.GroupWriteSupport;\n+import org.apache.parquet.hadoop.metadata.ColumnPath;\n+import org.apache.parquet.schema.MessageType;\n+import org.apache.parquet.schema.Types;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.ErrorCollector;\n+import org.junit.rules.TemporaryFolder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.parquet.hadoop.ParquetFileWriter.Mode.OVERWRITE;\n+import static org.apache.parquet.hadoop.metadata.CompressionCodecName.UNCOMPRESSED;\n+import static org.apache.parquet.schema.MessageTypeParser.parseMessageType;\n+import static org.apache.parquet.schema.PrimitiveType.PrimitiveTypeName.BOOLEAN;\n+import static org.apache.parquet.schema.PrimitiveType.PrimitiveTypeName.INT32;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+/*\n+ * This file contains samples for writing and reading encrypted Parquet files in different\n+ * encryption and decryption configurations. The samples have the following goals:\n+ * 1) Demonstrate usage of different options for data encryption and decryption.\n+ * 2) Produce encrypted files for interoperability tests with other (eg parquet-cpp)\n+ *    readers that support encryption.\n+ * 3) Produce encrypted files with plaintext footer, for testing the ability of legacy\n+ *    readers to parse the footer and read unencrypted columns.\n+ * 4) Perform interoperability tests with other (eg parquet-cpp) writers, by reading\n+ *    encrypted files produced by these writers.\n+ *\n+ * The write sample produces number of parquet files, each encrypted with a different\n+ * encryption configuration as described below.\n+ * The name of each file is in the form of:\n+ * tester<encryption config number>.parquet.encrypted.\n+ *\n+ * The read sample creates a set of decryption configurations and then uses each of them\n+ * to read all encrypted files in the input directory.\n+ *\n+ * The different encryption and decryption configurations are listed below.\n+ *\n+ *\n+ * A detailed description of the Parquet Modular Encryption specification can be found\n+ * here:\n+ * https://github.com/apache/parquet-format/blob/encryption/Encryption.md\n+ *\n+ * The write sample creates files with eight columns in the following\n+ * encryption configurations:\n+ *\n+ *  UNIFORM_ENCRYPTION:             Encrypt all columns and the footer with the same key.\n+ *                                  (uniform encryption)\n+ *  ENCRYPT_COLUMNS_AND_FOOTER:     Encrypt two columns and the footer, with different\n+ *                                  keys.\n+ *  ENCRYPT_COLUMNS_PLAINTEXT_FOOTER: Encrypt two columns, with different keys.\n+ *                                  Do not encrypt footer (to enable legacy readers)\n+ *                                  - plaintext footer mode.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_AAD: Encrypt two columns and the footer, with different\n+ *                                  keys. Supply aad_prefix for file identity\n+ *                                  verification.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE:   Encrypt two columns and the footer,\n+ *                                  with different keys. Supply aad_prefix, and call\n+ *                                  disable_aad_prefix_storage to prevent file\n+ *                                  identity storage in file metadata.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_CTR: Encrypt two columns and the footer, with different\n+ *                                  keys. Use the alternative (AES_GCM_CTR_V1) algorithm.\n+ *  NO_ENCRYPTION:                  Do not encrypt anything\n+ *\n+ *\n+ * The read sample uses each of the following decryption configurations to read every\n+ * encrypted files in the input directory:\n+ *\n+ *  DECRYPT_WITH_KEY_RETRIEVER:     Decrypt using key retriever that holds the keys of\n+ *                                  two encrypted columns and the footer key.\n+ *  DECRYPT_WITH_KEY_RETRIEVER_AAD: Decrypt using key retriever that holds the keys of\n+ *                                  two encrypted columns and the footer key. Supplies\n+ *                                  aad_prefix to verify file identity.\n+ *  DECRYPT_WITH_EXPLICIT_KEYS:     Decrypt using explicit column and footer keys\n+ *                                  (instead of key retrieval callback).\n+ *  NO_DECRYPTION:                  Do not decrypt anything.\n+ */\n+public class TestEncryptionOptions {\n+  private static final Logger LOG = LoggerFactory.getLogger(TestEncryptionOptions.class);\n+\n+  @Rule\n+  public TemporaryFolder temporaryFolder = new TemporaryFolder();\n+\n+  @Rule\n+  public ErrorCollector errorCollector = new ErrorCollector();\n+\n+  private static final byte[] FOOTER_ENCRYPTION_KEY = \"0123456789012345\".getBytes();\n+  private static final byte[] COLUMN_ENCRYPTION_KEY1 = \"1234567890123450\".getBytes();\n+  private static final byte[] COLUMN_ENCRYPTION_KEY2 = \"1234567890123451\".getBytes();\n+  private static final String FOOTER_ENCRYPTION_KEY_ID = \"kf\";\n+  private static final String COLUMN_ENCRYPTION_KEY1_ID = \"kc1\";\n+  private static final String COLUMN_ENCRYPTION_KEY2_ID = \"kc2\";\n+  private static final String AAD_PREFIX_STRING = \"tester\";\n+  private static final String BOOLEAN_FIELD_NAME = \"boolean_field\";\n+  private static final String INT32_FIELD_NAME = \"int32_field\";\n+  private static final String FLOAT_FIELD_NAME = \"float_field\";\n+  private static final String DOUBLE_FIELD_NAME = \"double_field\";\n+\n+  public enum EncryptionConfiguration {\n+    UNIFORM_ENCRYPTION(\"UNIFORM_ENCRYPTION\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER(\"ENCRYPT_COLUMNS_AND_FOOTER\"),\n+    ENCRYPT_COLUMNS_PLAINTEXT_FOOTER(\"ENCRYPT_COLUMNS_PLAINTEXT_FOOTER\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_AAD(\"ENCRYPT_COLUMNS_AND_FOOTER_AAD\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE(\"ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_CTR(\"ENCRYPT_COLUMNS_AND_FOOTER_CTR\"),\n+    NO_ENCRYPTION(\"NO_ENCRYPTION\");\n+\n+    private final String configurationName;\n+\n+    EncryptionConfiguration(String configurationName) {\n+      this.configurationName = configurationName;\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return configurationName;\n+    }\n+  }\n+\n+\n+  public enum DecryptionConfiguration {\n+    DECRYPT_WITH_KEY_RETRIEVER(\"DECRYPT_WITH_KEY_RETRIEVER\"),\n+    DECRYPT_WITH_KEY_RETRIEVER_AAD(\"DECRYPT_WITH_KEY_RETRIEVER_AAD\"),\n+    DECRYPT_WITH_EXPLICIT_KEYS(\"DECRYPT_WITH_EXPLICIT_KEYS\"),\n+    NO_DECRYPTION(\"NO_DECRYPTION\");\n+\n+    private final String configurationName;\n+\n+    DecryptionConfiguration(String configurationName) {\n+      this.configurationName = configurationName;\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return configurationName;\n+    }\n+  }\n+\n+  @Test\n+  public void testWriteReadEncryptedParquetFiles() throws IOException {\n+    Path rootPath = new Path(temporaryFolder.getRoot().getPath());\n+    LOG.info(\"======== testWriteReadEncryptedParquetFiles {} ========\", rootPath.toString());\n+    byte[] AADPrefix = AAD_PREFIX_STRING.getBytes(StandardCharsets.UTF_8);\n+    // This array will hold various encryption configuraions.\n+    Map<EncryptionConfiguration, FileEncryptionProperties> encryptionPropertiesMap =\n+      getEncryptionConfigurations(AADPrefix);\n+    testWriteEncryptedParquetFiles(rootPath, encryptionPropertiesMap);\n+    // This array will hold various decryption configurations.\n+    Map<DecryptionConfiguration, FileDecryptionProperties> decryptionPropertiesMap =\n+      getDecryptionConfigurations(AADPrefix);\n+    testReadEncryptedParquetFiles(rootPath, decryptionPropertiesMap);\n+  }\n+\n+  @Test\n+  public void testInteropReadEncryptedParquetFiles() throws IOException {\n+    Path rootPath = new Path(\"submodules/parquet-testing/data\");", "originalCommit": "4ca6a2febde567c7b8753100c1b80fe2831f403f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjgzNDM2Mg==", "url": "https://github.com/apache/parquet-mr/pull/782#discussion_r436834362", "bodyText": "I'm adding dev/submodule-update.sh script to clone the missing submodules and exec-maven-plugin to invoke it from maven.", "author": "andersonm-ibm", "createdAt": "2020-06-08T16:24:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzc3Mjc5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzc3NjgyNQ==", "url": "https://github.com/apache/parquet-mr/pull/782#discussion_r433776825", "bodyText": "What I don't like here is that if the folder is empty we do not test anything and there is no sign of these skipped tests. For example if parquet-testing is restructured and files moved to other folders there will be no sign of an issue and these tests will keep reporting that everything is fine with the encryption.\nnit: You may iterate on the elements directly by using the java foreach construct.", "author": "gszadovszky", "createdAt": "2020-06-02T10:28:53Z", "path": "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestEncryptionOptions.java", "diffHunk": "@@ -0,0 +1,660 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.parquet.hadoop;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.parquet.crypto.ColumnDecryptionProperties;\n+import org.apache.parquet.crypto.ColumnEncryptionProperties;\n+import org.apache.parquet.crypto.FileDecryptionProperties;\n+import org.apache.parquet.crypto.FileEncryptionProperties;\n+import org.apache.parquet.crypto.ParquetCipher;\n+import org.apache.parquet.crypto.DecryptionKeyRetriever;\n+import org.apache.parquet.example.data.Group;\n+import org.apache.parquet.example.data.simple.SimpleGroupFactory;\n+import org.apache.parquet.filter2.compat.FilterCompat;\n+import org.apache.parquet.hadoop.example.ExampleParquetWriter;\n+import org.apache.parquet.hadoop.example.GroupReadSupport;\n+import org.apache.parquet.hadoop.example.GroupWriteSupport;\n+import org.apache.parquet.hadoop.metadata.ColumnPath;\n+import org.apache.parquet.schema.MessageType;\n+import org.apache.parquet.schema.Types;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.ErrorCollector;\n+import org.junit.rules.TemporaryFolder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.parquet.hadoop.ParquetFileWriter.Mode.OVERWRITE;\n+import static org.apache.parquet.hadoop.metadata.CompressionCodecName.UNCOMPRESSED;\n+import static org.apache.parquet.schema.MessageTypeParser.parseMessageType;\n+import static org.apache.parquet.schema.PrimitiveType.PrimitiveTypeName.BOOLEAN;\n+import static org.apache.parquet.schema.PrimitiveType.PrimitiveTypeName.INT32;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+/*\n+ * This file contains samples for writing and reading encrypted Parquet files in different\n+ * encryption and decryption configurations. The samples have the following goals:\n+ * 1) Demonstrate usage of different options for data encryption and decryption.\n+ * 2) Produce encrypted files for interoperability tests with other (eg parquet-cpp)\n+ *    readers that support encryption.\n+ * 3) Produce encrypted files with plaintext footer, for testing the ability of legacy\n+ *    readers to parse the footer and read unencrypted columns.\n+ * 4) Perform interoperability tests with other (eg parquet-cpp) writers, by reading\n+ *    encrypted files produced by these writers.\n+ *\n+ * The write sample produces number of parquet files, each encrypted with a different\n+ * encryption configuration as described below.\n+ * The name of each file is in the form of:\n+ * tester<encryption config number>.parquet.encrypted.\n+ *\n+ * The read sample creates a set of decryption configurations and then uses each of them\n+ * to read all encrypted files in the input directory.\n+ *\n+ * The different encryption and decryption configurations are listed below.\n+ *\n+ *\n+ * A detailed description of the Parquet Modular Encryption specification can be found\n+ * here:\n+ * https://github.com/apache/parquet-format/blob/encryption/Encryption.md\n+ *\n+ * The write sample creates files with eight columns in the following\n+ * encryption configurations:\n+ *\n+ *  UNIFORM_ENCRYPTION:             Encrypt all columns and the footer with the same key.\n+ *                                  (uniform encryption)\n+ *  ENCRYPT_COLUMNS_AND_FOOTER:     Encrypt two columns and the footer, with different\n+ *                                  keys.\n+ *  ENCRYPT_COLUMNS_PLAINTEXT_FOOTER: Encrypt two columns, with different keys.\n+ *                                  Do not encrypt footer (to enable legacy readers)\n+ *                                  - plaintext footer mode.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_AAD: Encrypt two columns and the footer, with different\n+ *                                  keys. Supply aad_prefix for file identity\n+ *                                  verification.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE:   Encrypt two columns and the footer,\n+ *                                  with different keys. Supply aad_prefix, and call\n+ *                                  disable_aad_prefix_storage to prevent file\n+ *                                  identity storage in file metadata.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_CTR: Encrypt two columns and the footer, with different\n+ *                                  keys. Use the alternative (AES_GCM_CTR_V1) algorithm.\n+ *  NO_ENCRYPTION:                  Do not encrypt anything\n+ *\n+ *\n+ * The read sample uses each of the following decryption configurations to read every\n+ * encrypted files in the input directory:\n+ *\n+ *  DECRYPT_WITH_KEY_RETRIEVER:     Decrypt using key retriever that holds the keys of\n+ *                                  two encrypted columns and the footer key.\n+ *  DECRYPT_WITH_KEY_RETRIEVER_AAD: Decrypt using key retriever that holds the keys of\n+ *                                  two encrypted columns and the footer key. Supplies\n+ *                                  aad_prefix to verify file identity.\n+ *  DECRYPT_WITH_EXPLICIT_KEYS:     Decrypt using explicit column and footer keys\n+ *                                  (instead of key retrieval callback).\n+ *  NO_DECRYPTION:                  Do not decrypt anything.\n+ */\n+public class TestEncryptionOptions {\n+  private static final Logger LOG = LoggerFactory.getLogger(TestEncryptionOptions.class);\n+\n+  @Rule\n+  public TemporaryFolder temporaryFolder = new TemporaryFolder();\n+\n+  @Rule\n+  public ErrorCollector errorCollector = new ErrorCollector();\n+\n+  private static final byte[] FOOTER_ENCRYPTION_KEY = \"0123456789012345\".getBytes();\n+  private static final byte[] COLUMN_ENCRYPTION_KEY1 = \"1234567890123450\".getBytes();\n+  private static final byte[] COLUMN_ENCRYPTION_KEY2 = \"1234567890123451\".getBytes();\n+  private static final String FOOTER_ENCRYPTION_KEY_ID = \"kf\";\n+  private static final String COLUMN_ENCRYPTION_KEY1_ID = \"kc1\";\n+  private static final String COLUMN_ENCRYPTION_KEY2_ID = \"kc2\";\n+  private static final String AAD_PREFIX_STRING = \"tester\";\n+  private static final String BOOLEAN_FIELD_NAME = \"boolean_field\";\n+  private static final String INT32_FIELD_NAME = \"int32_field\";\n+  private static final String FLOAT_FIELD_NAME = \"float_field\";\n+  private static final String DOUBLE_FIELD_NAME = \"double_field\";\n+\n+  public enum EncryptionConfiguration {\n+    UNIFORM_ENCRYPTION(\"UNIFORM_ENCRYPTION\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER(\"ENCRYPT_COLUMNS_AND_FOOTER\"),\n+    ENCRYPT_COLUMNS_PLAINTEXT_FOOTER(\"ENCRYPT_COLUMNS_PLAINTEXT_FOOTER\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_AAD(\"ENCRYPT_COLUMNS_AND_FOOTER_AAD\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE(\"ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_CTR(\"ENCRYPT_COLUMNS_AND_FOOTER_CTR\"),\n+    NO_ENCRYPTION(\"NO_ENCRYPTION\");\n+\n+    private final String configurationName;\n+\n+    EncryptionConfiguration(String configurationName) {\n+      this.configurationName = configurationName;\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return configurationName;\n+    }\n+  }\n+\n+\n+  public enum DecryptionConfiguration {\n+    DECRYPT_WITH_KEY_RETRIEVER(\"DECRYPT_WITH_KEY_RETRIEVER\"),\n+    DECRYPT_WITH_KEY_RETRIEVER_AAD(\"DECRYPT_WITH_KEY_RETRIEVER_AAD\"),\n+    DECRYPT_WITH_EXPLICIT_KEYS(\"DECRYPT_WITH_EXPLICIT_KEYS\"),\n+    NO_DECRYPTION(\"NO_DECRYPTION\");\n+\n+    private final String configurationName;\n+\n+    DecryptionConfiguration(String configurationName) {\n+      this.configurationName = configurationName;\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return configurationName;\n+    }\n+  }\n+\n+  @Test\n+  public void testWriteReadEncryptedParquetFiles() throws IOException {\n+    Path rootPath = new Path(temporaryFolder.getRoot().getPath());\n+    LOG.info(\"======== testWriteReadEncryptedParquetFiles {} ========\", rootPath.toString());\n+    byte[] AADPrefix = AAD_PREFIX_STRING.getBytes(StandardCharsets.UTF_8);\n+    // This array will hold various encryption configuraions.\n+    Map<EncryptionConfiguration, FileEncryptionProperties> encryptionPropertiesMap =\n+      getEncryptionConfigurations(AADPrefix);\n+    testWriteEncryptedParquetFiles(rootPath, encryptionPropertiesMap);\n+    // This array will hold various decryption configurations.\n+    Map<DecryptionConfiguration, FileDecryptionProperties> decryptionPropertiesMap =\n+      getDecryptionConfigurations(AADPrefix);\n+    testReadEncryptedParquetFiles(rootPath, decryptionPropertiesMap);\n+  }\n+\n+  @Test\n+  public void testInteropReadEncryptedParquetFiles() throws IOException {\n+    Path rootPath = new Path(\"submodules/parquet-testing/data\");\n+    LOG.info(\"======== testInteropReadEncryptedParquetFiles {} ========\", rootPath.toString());\n+    byte[] AADPrefix = AAD_PREFIX_STRING.getBytes(StandardCharsets.UTF_8);\n+    // This array will hold various decryption configurations.\n+    Map<DecryptionConfiguration, FileDecryptionProperties> decryptionPropertiesMap =\n+      getDecryptionConfigurations(AADPrefix);\n+    testReadEncryptedParquetFiles(rootPath, decryptionPropertiesMap);\n+  }\n+\n+  private void testWriteEncryptedParquetFiles(Path root, Map<EncryptionConfiguration, FileEncryptionProperties> encryptionPropertiesMap) throws IOException {\n+    Configuration conf = new Configuration();\n+    int numberOfEncryptionModes = encryptionPropertiesMap.size();\n+\n+    MessageType schema = parseMessageType(\n+      \"message test { \"\n+        + \"required boolean \" + BOOLEAN_FIELD_NAME + \"; \"\n+        + \"required int32 \" + INT32_FIELD_NAME + \"; \"\n+        + \"required float \" + FLOAT_FIELD_NAME + \"; \"\n+        + \"required double \" + DOUBLE_FIELD_NAME + \"; \"\n+        + \"} \");\n+\n+    GroupWriteSupport.setSchema(schema, conf);\n+    SimpleGroupFactory f = new SimpleGroupFactory(schema);\n+\n+\n+    for (Map.Entry<EncryptionConfiguration, FileEncryptionProperties> encryptionConfigurationEntry : encryptionPropertiesMap.entrySet()) {\n+      EncryptionConfiguration encryptionConfiguration = encryptionConfigurationEntry.getKey();\n+      Path file = new Path(root, encryptionConfiguration.toString() + \".parquet.encrypted\");\n+\n+      LOG.info(\"\\nWrite \" + file.toString());\n+      ParquetWriter<Group> writer = ExampleParquetWriter.builder(file)\n+        .withWriteMode(OVERWRITE)\n+        .withType(schema)\n+        .withEncryption(encryptionConfigurationEntry.getValue())\n+        .build();\n+\n+      for (int i = 0; i < 100; i++) {\n+        boolean expect = false;\n+        if ((i % 2) == 0)\n+          expect = true;\n+        float float_val = (float) i * 1.1f;\n+        double double_val = (i * 1.1111111);\n+\n+        writer.write(\n+          f.newGroup()\n+            .append(BOOLEAN_FIELD_NAME, expect)\n+            .append(INT32_FIELD_NAME, i)\n+            .append(FLOAT_FIELD_NAME, float_val)\n+            .append(DOUBLE_FIELD_NAME, double_val));\n+\n+      }\n+      writer.close();\n+    }\n+  }\n+\n+  private void testReadEncryptedParquetFiles(Path root, Map<DecryptionConfiguration, FileDecryptionProperties> decryptionPropertiesMap) throws IOException {\n+    Configuration conf = new Configuration();\n+\n+    for (Map.Entry<DecryptionConfiguration, FileDecryptionProperties> decryptionConfigurationEntry : decryptionPropertiesMap.entrySet()) {\n+      DecryptionConfiguration decryptionConfiguration = decryptionConfigurationEntry.getKey();\n+      LOG.info(\"==> Decryption configuration {}\", decryptionConfiguration);\n+      FileDecryptionProperties fileDecryptionProperties = decryptionConfigurationEntry.getValue();\n+\n+      File folder = new File(root.toString());\n+      File[] listOfFiles = folder.listFiles();\n+\n+      for (int fileNum = 0; fileNum < listOfFiles.length; fileNum++) {", "originalCommit": "4ca6a2febde567c7b8753100c1b80fe2831f403f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjgzNzk3OQ==", "url": "https://github.com/apache/parquet-mr/pull/782#discussion_r436837979", "bodyText": "Thanks, changed the iteration to be over expected encryption configurations.", "author": "andersonm-ibm", "createdAt": "2020-06-08T16:30:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzc3NjgyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzgxOTA5Mw==", "url": "https://github.com/apache/parquet-mr/pull/782#discussion_r433819093", "bodyText": "Mocking objects are a great way if you have to deal with complex objects in your tests. Mocking an interface that have only one method seems a bit overkill and I don't think it is more readable. I think, implementing the interface even by an anonymous class would be more readable and shows a better example.", "author": "gszadovszky", "createdAt": "2020-06-02T11:54:58Z", "path": "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestBloomFiltering.java", "diffHunk": "@@ -157,8 +182,24 @@ private static Path createTempFile() {\n \n   private List<PhoneBookWriter.User> readUsers(FilterPredicate filter, boolean useOtherFiltering,\n                                                boolean useBloomFilter) throws IOException {\n+    FileDecryptionProperties fileDecryptionProperties = null;\n+    if (isEncrypted) {\n+      DecryptionKeyRetriever decryptionKeyRetrieverMock = mock(DecryptionKeyRetriever.class);\n+      when(decryptionKeyRetrieverMock.getKey(FOOTER_ENCRYPTION_KEY_ID.getBytes(StandardCharsets.UTF_8)))\n+        .thenReturn(FOOTER_ENCRYPTION_KEY);\n+      when(decryptionKeyRetrieverMock.getKey(COLUMN_ENCRYPTION_KEY1_ID.getBytes(StandardCharsets.UTF_8)))\n+        .thenReturn(COLUMN_ENCRYPTION_KEY1);\n+      when(decryptionKeyRetrieverMock.getKey(COLUMN_ENCRYPTION_KEY2_ID.getBytes(StandardCharsets.UTF_8)))\n+        .thenReturn(COLUMN_ENCRYPTION_KEY2);", "originalCommit": "4ca6a2febde567c7b8753100c1b80fe2831f403f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzgyMjgxNw==", "url": "https://github.com/apache/parquet-mr/pull/782#discussion_r433822817", "bodyText": "See above.", "author": "gszadovszky", "createdAt": "2020-06-02T12:01:58Z", "path": "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnIndexFiltering.java", "diffHunk": "@@ -214,24 +241,47 @@ private static Path createTempFile() {\n \n   private List<User> readUsers(Filter filter, boolean useOtherFiltering, boolean useColumnIndexFilter)\n       throws IOException {\n+    FileDecryptionProperties decryptionProperties = getFileDecryptionProperties();\n     return PhoneBookWriter.readUsers(ParquetReader.builder(new GroupReadSupport(), file)\n         .withFilter(filter)\n+        .withDecryption(decryptionProperties)\n         .useDictionaryFilter(useOtherFiltering)\n         .useStatsFilter(useOtherFiltering)\n         .useRecordFilter(useOtherFiltering)\n         .useColumnIndexFilter(useColumnIndexFilter));\n   }\n \n-  private List<User> readUsersWithProjection(Filter filter, MessageType schema, boolean useOtherFiltering, boolean useColumnIndexFilter) throws IOException {\n+  private List<User> readUsersWithProjection(Filter filter, MessageType schema, boolean useOtherFiltering,\n+                                             boolean useColumnIndexFilter) throws IOException {\n+    FileDecryptionProperties decryptionProperties = getFileDecryptionProperties();\n     return PhoneBookWriter.readUsers(ParquetReader.builder(new GroupReadSupport(), file)\n         .withFilter(filter)\n+        .withDecryption(decryptionProperties)\n         .useDictionaryFilter(useOtherFiltering)\n         .useStatsFilter(useOtherFiltering)\n         .useRecordFilter(useOtherFiltering)\n         .useColumnIndexFilter(useColumnIndexFilter)\n         .set(ReadSupport.PARQUET_READ_SCHEMA, schema.toString()));\n   }\n \n+  private FileDecryptionProperties getFileDecryptionProperties() {\n+    FileDecryptionProperties decryptionProperties = null;\n+    if (isEncrypted) {\n+      DecryptionKeyRetriever decryptionKeyRetrieverMock = mock(DecryptionKeyRetriever.class);\n+      when(decryptionKeyRetrieverMock.getKey(FOOTER_ENCRYPTION_KEY_ID.getBytes(StandardCharsets.UTF_8)))\n+        .thenReturn(FOOTER_ENCRYPTION_KEY);\n+      when(decryptionKeyRetrieverMock.getKey(COLUMN_ENCRYPTION_KEY1_ID.getBytes(StandardCharsets.UTF_8)))\n+        .thenReturn(COLUMN_ENCRYPTION_KEY1);\n+      when(decryptionKeyRetrieverMock.getKey(COLUMN_ENCRYPTION_KEY2_ID.getBytes(StandardCharsets.UTF_8)))\n+        .thenReturn(COLUMN_ENCRYPTION_KEY2);", "originalCommit": "4ca6a2febde567c7b8753100c1b80fe2831f403f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzg2MTk4NA==", "url": "https://github.com/apache/parquet-mr/pull/782#discussion_r433861984", "bodyText": "By default the toString method of an enum returns the name of the instance which is the exact one in the code. So, you do not need to repeat it as a string and return it in toString, it is enough to simple list the members of the enum.", "author": "gszadovszky", "createdAt": "2020-06-02T13:10:32Z", "path": "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestEncryptionOptions.java", "diffHunk": "@@ -0,0 +1,660 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.parquet.hadoop;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.parquet.crypto.ColumnDecryptionProperties;\n+import org.apache.parquet.crypto.ColumnEncryptionProperties;\n+import org.apache.parquet.crypto.FileDecryptionProperties;\n+import org.apache.parquet.crypto.FileEncryptionProperties;\n+import org.apache.parquet.crypto.ParquetCipher;\n+import org.apache.parquet.crypto.DecryptionKeyRetriever;\n+import org.apache.parquet.example.data.Group;\n+import org.apache.parquet.example.data.simple.SimpleGroupFactory;\n+import org.apache.parquet.filter2.compat.FilterCompat;\n+import org.apache.parquet.hadoop.example.ExampleParquetWriter;\n+import org.apache.parquet.hadoop.example.GroupReadSupport;\n+import org.apache.parquet.hadoop.example.GroupWriteSupport;\n+import org.apache.parquet.hadoop.metadata.ColumnPath;\n+import org.apache.parquet.schema.MessageType;\n+import org.apache.parquet.schema.Types;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.ErrorCollector;\n+import org.junit.rules.TemporaryFolder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.parquet.hadoop.ParquetFileWriter.Mode.OVERWRITE;\n+import static org.apache.parquet.hadoop.metadata.CompressionCodecName.UNCOMPRESSED;\n+import static org.apache.parquet.schema.MessageTypeParser.parseMessageType;\n+import static org.apache.parquet.schema.PrimitiveType.PrimitiveTypeName.BOOLEAN;\n+import static org.apache.parquet.schema.PrimitiveType.PrimitiveTypeName.INT32;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+/*\n+ * This file contains samples for writing and reading encrypted Parquet files in different\n+ * encryption and decryption configurations. The samples have the following goals:\n+ * 1) Demonstrate usage of different options for data encryption and decryption.\n+ * 2) Produce encrypted files for interoperability tests with other (eg parquet-cpp)\n+ *    readers that support encryption.\n+ * 3) Produce encrypted files with plaintext footer, for testing the ability of legacy\n+ *    readers to parse the footer and read unencrypted columns.\n+ * 4) Perform interoperability tests with other (eg parquet-cpp) writers, by reading\n+ *    encrypted files produced by these writers.\n+ *\n+ * The write sample produces number of parquet files, each encrypted with a different\n+ * encryption configuration as described below.\n+ * The name of each file is in the form of:\n+ * tester<encryption config number>.parquet.encrypted.\n+ *\n+ * The read sample creates a set of decryption configurations and then uses each of them\n+ * to read all encrypted files in the input directory.\n+ *\n+ * The different encryption and decryption configurations are listed below.\n+ *\n+ *\n+ * A detailed description of the Parquet Modular Encryption specification can be found\n+ * here:\n+ * https://github.com/apache/parquet-format/blob/encryption/Encryption.md\n+ *\n+ * The write sample creates files with eight columns in the following\n+ * encryption configurations:\n+ *\n+ *  UNIFORM_ENCRYPTION:             Encrypt all columns and the footer with the same key.\n+ *                                  (uniform encryption)\n+ *  ENCRYPT_COLUMNS_AND_FOOTER:     Encrypt two columns and the footer, with different\n+ *                                  keys.\n+ *  ENCRYPT_COLUMNS_PLAINTEXT_FOOTER: Encrypt two columns, with different keys.\n+ *                                  Do not encrypt footer (to enable legacy readers)\n+ *                                  - plaintext footer mode.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_AAD: Encrypt two columns and the footer, with different\n+ *                                  keys. Supply aad_prefix for file identity\n+ *                                  verification.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE:   Encrypt two columns and the footer,\n+ *                                  with different keys. Supply aad_prefix, and call\n+ *                                  disable_aad_prefix_storage to prevent file\n+ *                                  identity storage in file metadata.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_CTR: Encrypt two columns and the footer, with different\n+ *                                  keys. Use the alternative (AES_GCM_CTR_V1) algorithm.\n+ *  NO_ENCRYPTION:                  Do not encrypt anything\n+ *\n+ *\n+ * The read sample uses each of the following decryption configurations to read every\n+ * encrypted files in the input directory:\n+ *\n+ *  DECRYPT_WITH_KEY_RETRIEVER:     Decrypt using key retriever that holds the keys of\n+ *                                  two encrypted columns and the footer key.\n+ *  DECRYPT_WITH_KEY_RETRIEVER_AAD: Decrypt using key retriever that holds the keys of\n+ *                                  two encrypted columns and the footer key. Supplies\n+ *                                  aad_prefix to verify file identity.\n+ *  DECRYPT_WITH_EXPLICIT_KEYS:     Decrypt using explicit column and footer keys\n+ *                                  (instead of key retrieval callback).\n+ *  NO_DECRYPTION:                  Do not decrypt anything.\n+ */\n+public class TestEncryptionOptions {\n+  private static final Logger LOG = LoggerFactory.getLogger(TestEncryptionOptions.class);\n+\n+  @Rule\n+  public TemporaryFolder temporaryFolder = new TemporaryFolder();\n+\n+  @Rule\n+  public ErrorCollector errorCollector = new ErrorCollector();\n+\n+  private static final byte[] FOOTER_ENCRYPTION_KEY = \"0123456789012345\".getBytes();\n+  private static final byte[] COLUMN_ENCRYPTION_KEY1 = \"1234567890123450\".getBytes();\n+  private static final byte[] COLUMN_ENCRYPTION_KEY2 = \"1234567890123451\".getBytes();\n+  private static final String FOOTER_ENCRYPTION_KEY_ID = \"kf\";\n+  private static final String COLUMN_ENCRYPTION_KEY1_ID = \"kc1\";\n+  private static final String COLUMN_ENCRYPTION_KEY2_ID = \"kc2\";\n+  private static final String AAD_PREFIX_STRING = \"tester\";\n+  private static final String BOOLEAN_FIELD_NAME = \"boolean_field\";\n+  private static final String INT32_FIELD_NAME = \"int32_field\";\n+  private static final String FLOAT_FIELD_NAME = \"float_field\";\n+  private static final String DOUBLE_FIELD_NAME = \"double_field\";\n+\n+  public enum EncryptionConfiguration {\n+    UNIFORM_ENCRYPTION(\"UNIFORM_ENCRYPTION\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER(\"ENCRYPT_COLUMNS_AND_FOOTER\"),\n+    ENCRYPT_COLUMNS_PLAINTEXT_FOOTER(\"ENCRYPT_COLUMNS_PLAINTEXT_FOOTER\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_AAD(\"ENCRYPT_COLUMNS_AND_FOOTER_AAD\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE(\"ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_CTR(\"ENCRYPT_COLUMNS_AND_FOOTER_CTR\"),\n+    NO_ENCRYPTION(\"NO_ENCRYPTION\");\n+\n+    private final String configurationName;\n+\n+    EncryptionConfiguration(String configurationName) {\n+      this.configurationName = configurationName;\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return configurationName;\n+    }\n+  }\n+\n+\n+  public enum DecryptionConfiguration {\n+    DECRYPT_WITH_KEY_RETRIEVER(\"DECRYPT_WITH_KEY_RETRIEVER\"),\n+    DECRYPT_WITH_KEY_RETRIEVER_AAD(\"DECRYPT_WITH_KEY_RETRIEVER_AAD\"),\n+    DECRYPT_WITH_EXPLICIT_KEYS(\"DECRYPT_WITH_EXPLICIT_KEYS\"),\n+    NO_DECRYPTION(\"NO_DECRYPTION\");\n+\n+    private final String configurationName;\n+\n+    DecryptionConfiguration(String configurationName) {\n+      this.configurationName = configurationName;\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return configurationName;\n+    }\n+  }", "originalCommit": "4ca6a2febde567c7b8753100c1b80fe2831f403f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzg3NTgzNg==", "url": "https://github.com/apache/parquet-mr/pull/782#discussion_r433875836", "bodyText": "I can see only 4 columns in the schema.", "author": "gszadovszky", "createdAt": "2020-06-02T13:30:37Z", "path": "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestEncryptionOptions.java", "diffHunk": "@@ -0,0 +1,660 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.parquet.hadoop;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.parquet.crypto.ColumnDecryptionProperties;\n+import org.apache.parquet.crypto.ColumnEncryptionProperties;\n+import org.apache.parquet.crypto.FileDecryptionProperties;\n+import org.apache.parquet.crypto.FileEncryptionProperties;\n+import org.apache.parquet.crypto.ParquetCipher;\n+import org.apache.parquet.crypto.DecryptionKeyRetriever;\n+import org.apache.parquet.example.data.Group;\n+import org.apache.parquet.example.data.simple.SimpleGroupFactory;\n+import org.apache.parquet.filter2.compat.FilterCompat;\n+import org.apache.parquet.hadoop.example.ExampleParquetWriter;\n+import org.apache.parquet.hadoop.example.GroupReadSupport;\n+import org.apache.parquet.hadoop.example.GroupWriteSupport;\n+import org.apache.parquet.hadoop.metadata.ColumnPath;\n+import org.apache.parquet.schema.MessageType;\n+import org.apache.parquet.schema.Types;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.ErrorCollector;\n+import org.junit.rules.TemporaryFolder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.parquet.hadoop.ParquetFileWriter.Mode.OVERWRITE;\n+import static org.apache.parquet.hadoop.metadata.CompressionCodecName.UNCOMPRESSED;\n+import static org.apache.parquet.schema.MessageTypeParser.parseMessageType;\n+import static org.apache.parquet.schema.PrimitiveType.PrimitiveTypeName.BOOLEAN;\n+import static org.apache.parquet.schema.PrimitiveType.PrimitiveTypeName.INT32;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+/*\n+ * This file contains samples for writing and reading encrypted Parquet files in different\n+ * encryption and decryption configurations. The samples have the following goals:\n+ * 1) Demonstrate usage of different options for data encryption and decryption.\n+ * 2) Produce encrypted files for interoperability tests with other (eg parquet-cpp)\n+ *    readers that support encryption.\n+ * 3) Produce encrypted files with plaintext footer, for testing the ability of legacy\n+ *    readers to parse the footer and read unencrypted columns.\n+ * 4) Perform interoperability tests with other (eg parquet-cpp) writers, by reading\n+ *    encrypted files produced by these writers.\n+ *\n+ * The write sample produces number of parquet files, each encrypted with a different\n+ * encryption configuration as described below.\n+ * The name of each file is in the form of:\n+ * tester<encryption config number>.parquet.encrypted.\n+ *\n+ * The read sample creates a set of decryption configurations and then uses each of them\n+ * to read all encrypted files in the input directory.\n+ *\n+ * The different encryption and decryption configurations are listed below.\n+ *\n+ *\n+ * A detailed description of the Parquet Modular Encryption specification can be found\n+ * here:\n+ * https://github.com/apache/parquet-format/blob/encryption/Encryption.md\n+ *\n+ * The write sample creates files with eight columns in the following", "originalCommit": "4ca6a2febde567c7b8753100c1b80fe2831f403f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzg3ODQ5Mw==", "url": "https://github.com/apache/parquet-mr/pull/782#discussion_r433878493", "bodyText": "I think, a couple thousands of randomly generated data (with fixed seed) would be more convincing. Also, I would expect some more types as well. At least some binary (string) data.", "author": "gszadovszky", "createdAt": "2020-06-02T13:34:23Z", "path": "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestEncryptionOptions.java", "diffHunk": "@@ -0,0 +1,660 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.parquet.hadoop;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.parquet.crypto.ColumnDecryptionProperties;\n+import org.apache.parquet.crypto.ColumnEncryptionProperties;\n+import org.apache.parquet.crypto.FileDecryptionProperties;\n+import org.apache.parquet.crypto.FileEncryptionProperties;\n+import org.apache.parquet.crypto.ParquetCipher;\n+import org.apache.parquet.crypto.DecryptionKeyRetriever;\n+import org.apache.parquet.example.data.Group;\n+import org.apache.parquet.example.data.simple.SimpleGroupFactory;\n+import org.apache.parquet.filter2.compat.FilterCompat;\n+import org.apache.parquet.hadoop.example.ExampleParquetWriter;\n+import org.apache.parquet.hadoop.example.GroupReadSupport;\n+import org.apache.parquet.hadoop.example.GroupWriteSupport;\n+import org.apache.parquet.hadoop.metadata.ColumnPath;\n+import org.apache.parquet.schema.MessageType;\n+import org.apache.parquet.schema.Types;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.ErrorCollector;\n+import org.junit.rules.TemporaryFolder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.parquet.hadoop.ParquetFileWriter.Mode.OVERWRITE;\n+import static org.apache.parquet.hadoop.metadata.CompressionCodecName.UNCOMPRESSED;\n+import static org.apache.parquet.schema.MessageTypeParser.parseMessageType;\n+import static org.apache.parquet.schema.PrimitiveType.PrimitiveTypeName.BOOLEAN;\n+import static org.apache.parquet.schema.PrimitiveType.PrimitiveTypeName.INT32;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+/*\n+ * This file contains samples for writing and reading encrypted Parquet files in different\n+ * encryption and decryption configurations. The samples have the following goals:\n+ * 1) Demonstrate usage of different options for data encryption and decryption.\n+ * 2) Produce encrypted files for interoperability tests with other (eg parquet-cpp)\n+ *    readers that support encryption.\n+ * 3) Produce encrypted files with plaintext footer, for testing the ability of legacy\n+ *    readers to parse the footer and read unencrypted columns.\n+ * 4) Perform interoperability tests with other (eg parquet-cpp) writers, by reading\n+ *    encrypted files produced by these writers.\n+ *\n+ * The write sample produces number of parquet files, each encrypted with a different\n+ * encryption configuration as described below.\n+ * The name of each file is in the form of:\n+ * tester<encryption config number>.parquet.encrypted.\n+ *\n+ * The read sample creates a set of decryption configurations and then uses each of them\n+ * to read all encrypted files in the input directory.\n+ *\n+ * The different encryption and decryption configurations are listed below.\n+ *\n+ *\n+ * A detailed description of the Parquet Modular Encryption specification can be found\n+ * here:\n+ * https://github.com/apache/parquet-format/blob/encryption/Encryption.md\n+ *\n+ * The write sample creates files with eight columns in the following\n+ * encryption configurations:\n+ *\n+ *  UNIFORM_ENCRYPTION:             Encrypt all columns and the footer with the same key.\n+ *                                  (uniform encryption)\n+ *  ENCRYPT_COLUMNS_AND_FOOTER:     Encrypt two columns and the footer, with different\n+ *                                  keys.\n+ *  ENCRYPT_COLUMNS_PLAINTEXT_FOOTER: Encrypt two columns, with different keys.\n+ *                                  Do not encrypt footer (to enable legacy readers)\n+ *                                  - plaintext footer mode.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_AAD: Encrypt two columns and the footer, with different\n+ *                                  keys. Supply aad_prefix for file identity\n+ *                                  verification.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE:   Encrypt two columns and the footer,\n+ *                                  with different keys. Supply aad_prefix, and call\n+ *                                  disable_aad_prefix_storage to prevent file\n+ *                                  identity storage in file metadata.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_CTR: Encrypt two columns and the footer, with different\n+ *                                  keys. Use the alternative (AES_GCM_CTR_V1) algorithm.\n+ *  NO_ENCRYPTION:                  Do not encrypt anything\n+ *\n+ *\n+ * The read sample uses each of the following decryption configurations to read every\n+ * encrypted files in the input directory:\n+ *\n+ *  DECRYPT_WITH_KEY_RETRIEVER:     Decrypt using key retriever that holds the keys of\n+ *                                  two encrypted columns and the footer key.\n+ *  DECRYPT_WITH_KEY_RETRIEVER_AAD: Decrypt using key retriever that holds the keys of\n+ *                                  two encrypted columns and the footer key. Supplies\n+ *                                  aad_prefix to verify file identity.\n+ *  DECRYPT_WITH_EXPLICIT_KEYS:     Decrypt using explicit column and footer keys\n+ *                                  (instead of key retrieval callback).\n+ *  NO_DECRYPTION:                  Do not decrypt anything.\n+ */\n+public class TestEncryptionOptions {\n+  private static final Logger LOG = LoggerFactory.getLogger(TestEncryptionOptions.class);\n+\n+  @Rule\n+  public TemporaryFolder temporaryFolder = new TemporaryFolder();\n+\n+  @Rule\n+  public ErrorCollector errorCollector = new ErrorCollector();\n+\n+  private static final byte[] FOOTER_ENCRYPTION_KEY = \"0123456789012345\".getBytes();\n+  private static final byte[] COLUMN_ENCRYPTION_KEY1 = \"1234567890123450\".getBytes();\n+  private static final byte[] COLUMN_ENCRYPTION_KEY2 = \"1234567890123451\".getBytes();\n+  private static final String FOOTER_ENCRYPTION_KEY_ID = \"kf\";\n+  private static final String COLUMN_ENCRYPTION_KEY1_ID = \"kc1\";\n+  private static final String COLUMN_ENCRYPTION_KEY2_ID = \"kc2\";\n+  private static final String AAD_PREFIX_STRING = \"tester\";\n+  private static final String BOOLEAN_FIELD_NAME = \"boolean_field\";\n+  private static final String INT32_FIELD_NAME = \"int32_field\";\n+  private static final String FLOAT_FIELD_NAME = \"float_field\";\n+  private static final String DOUBLE_FIELD_NAME = \"double_field\";\n+\n+  public enum EncryptionConfiguration {\n+    UNIFORM_ENCRYPTION(\"UNIFORM_ENCRYPTION\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER(\"ENCRYPT_COLUMNS_AND_FOOTER\"),\n+    ENCRYPT_COLUMNS_PLAINTEXT_FOOTER(\"ENCRYPT_COLUMNS_PLAINTEXT_FOOTER\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_AAD(\"ENCRYPT_COLUMNS_AND_FOOTER_AAD\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE(\"ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_CTR(\"ENCRYPT_COLUMNS_AND_FOOTER_CTR\"),\n+    NO_ENCRYPTION(\"NO_ENCRYPTION\");\n+\n+    private final String configurationName;\n+\n+    EncryptionConfiguration(String configurationName) {\n+      this.configurationName = configurationName;\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return configurationName;\n+    }\n+  }\n+\n+\n+  public enum DecryptionConfiguration {\n+    DECRYPT_WITH_KEY_RETRIEVER(\"DECRYPT_WITH_KEY_RETRIEVER\"),\n+    DECRYPT_WITH_KEY_RETRIEVER_AAD(\"DECRYPT_WITH_KEY_RETRIEVER_AAD\"),\n+    DECRYPT_WITH_EXPLICIT_KEYS(\"DECRYPT_WITH_EXPLICIT_KEYS\"),\n+    NO_DECRYPTION(\"NO_DECRYPTION\");\n+\n+    private final String configurationName;\n+\n+    DecryptionConfiguration(String configurationName) {\n+      this.configurationName = configurationName;\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return configurationName;\n+    }\n+  }\n+\n+  @Test\n+  public void testWriteReadEncryptedParquetFiles() throws IOException {\n+    Path rootPath = new Path(temporaryFolder.getRoot().getPath());\n+    LOG.info(\"======== testWriteReadEncryptedParquetFiles {} ========\", rootPath.toString());\n+    byte[] AADPrefix = AAD_PREFIX_STRING.getBytes(StandardCharsets.UTF_8);\n+    // This array will hold various encryption configuraions.\n+    Map<EncryptionConfiguration, FileEncryptionProperties> encryptionPropertiesMap =\n+      getEncryptionConfigurations(AADPrefix);\n+    testWriteEncryptedParquetFiles(rootPath, encryptionPropertiesMap);\n+    // This array will hold various decryption configurations.\n+    Map<DecryptionConfiguration, FileDecryptionProperties> decryptionPropertiesMap =\n+      getDecryptionConfigurations(AADPrefix);\n+    testReadEncryptedParquetFiles(rootPath, decryptionPropertiesMap);\n+  }\n+\n+  @Test\n+  public void testInteropReadEncryptedParquetFiles() throws IOException {\n+    Path rootPath = new Path(\"submodules/parquet-testing/data\");\n+    LOG.info(\"======== testInteropReadEncryptedParquetFiles {} ========\", rootPath.toString());\n+    byte[] AADPrefix = AAD_PREFIX_STRING.getBytes(StandardCharsets.UTF_8);\n+    // This array will hold various decryption configurations.\n+    Map<DecryptionConfiguration, FileDecryptionProperties> decryptionPropertiesMap =\n+      getDecryptionConfigurations(AADPrefix);\n+    testReadEncryptedParquetFiles(rootPath, decryptionPropertiesMap);\n+  }\n+\n+  private void testWriteEncryptedParquetFiles(Path root, Map<EncryptionConfiguration, FileEncryptionProperties> encryptionPropertiesMap) throws IOException {\n+    Configuration conf = new Configuration();\n+    int numberOfEncryptionModes = encryptionPropertiesMap.size();\n+\n+    MessageType schema = parseMessageType(\n+      \"message test { \"\n+        + \"required boolean \" + BOOLEAN_FIELD_NAME + \"; \"\n+        + \"required int32 \" + INT32_FIELD_NAME + \"; \"\n+        + \"required float \" + FLOAT_FIELD_NAME + \"; \"\n+        + \"required double \" + DOUBLE_FIELD_NAME + \"; \"\n+        + \"} \");\n+\n+    GroupWriteSupport.setSchema(schema, conf);\n+    SimpleGroupFactory f = new SimpleGroupFactory(schema);\n+\n+\n+    for (Map.Entry<EncryptionConfiguration, FileEncryptionProperties> encryptionConfigurationEntry : encryptionPropertiesMap.entrySet()) {\n+      EncryptionConfiguration encryptionConfiguration = encryptionConfigurationEntry.getKey();\n+      Path file = new Path(root, encryptionConfiguration.toString() + \".parquet.encrypted\");\n+\n+      LOG.info(\"\\nWrite \" + file.toString());\n+      ParquetWriter<Group> writer = ExampleParquetWriter.builder(file)\n+        .withWriteMode(OVERWRITE)\n+        .withType(schema)\n+        .withEncryption(encryptionConfigurationEntry.getValue())\n+        .build();\n+\n+      for (int i = 0; i < 100; i++) {\n+        boolean expect = false;\n+        if ((i % 2) == 0)\n+          expect = true;\n+        float float_val = (float) i * 1.1f;\n+        double double_val = (i * 1.1111111);\n+\n+        writer.write(\n+          f.newGroup()\n+            .append(BOOLEAN_FIELD_NAME, expect)\n+            .append(INT32_FIELD_NAME, i)\n+            .append(FLOAT_FIELD_NAME, float_val)\n+            .append(DOUBLE_FIELD_NAME, double_val));\n+\n+      }", "originalCommit": "4ca6a2febde567c7b8753100c1b80fe2831f403f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzg4OTg4MQ==", "url": "https://github.com/apache/parquet-mr/pull/782#discussion_r433889881", "bodyText": "As you only test files that exactly match the configuration name what if we would iterate the other way around? By iterating on the encryption configurations and expecting the files to be there for that name would be less error prone.", "author": "gszadovszky", "createdAt": "2020-06-02T13:49:54Z", "path": "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestEncryptionOptions.java", "diffHunk": "@@ -0,0 +1,660 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.parquet.hadoop;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.parquet.crypto.ColumnDecryptionProperties;\n+import org.apache.parquet.crypto.ColumnEncryptionProperties;\n+import org.apache.parquet.crypto.FileDecryptionProperties;\n+import org.apache.parquet.crypto.FileEncryptionProperties;\n+import org.apache.parquet.crypto.ParquetCipher;\n+import org.apache.parquet.crypto.DecryptionKeyRetriever;\n+import org.apache.parquet.example.data.Group;\n+import org.apache.parquet.example.data.simple.SimpleGroupFactory;\n+import org.apache.parquet.filter2.compat.FilterCompat;\n+import org.apache.parquet.hadoop.example.ExampleParquetWriter;\n+import org.apache.parquet.hadoop.example.GroupReadSupport;\n+import org.apache.parquet.hadoop.example.GroupWriteSupport;\n+import org.apache.parquet.hadoop.metadata.ColumnPath;\n+import org.apache.parquet.schema.MessageType;\n+import org.apache.parquet.schema.Types;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.ErrorCollector;\n+import org.junit.rules.TemporaryFolder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.parquet.hadoop.ParquetFileWriter.Mode.OVERWRITE;\n+import static org.apache.parquet.hadoop.metadata.CompressionCodecName.UNCOMPRESSED;\n+import static org.apache.parquet.schema.MessageTypeParser.parseMessageType;\n+import static org.apache.parquet.schema.PrimitiveType.PrimitiveTypeName.BOOLEAN;\n+import static org.apache.parquet.schema.PrimitiveType.PrimitiveTypeName.INT32;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+/*\n+ * This file contains samples for writing and reading encrypted Parquet files in different\n+ * encryption and decryption configurations. The samples have the following goals:\n+ * 1) Demonstrate usage of different options for data encryption and decryption.\n+ * 2) Produce encrypted files for interoperability tests with other (eg parquet-cpp)\n+ *    readers that support encryption.\n+ * 3) Produce encrypted files with plaintext footer, for testing the ability of legacy\n+ *    readers to parse the footer and read unencrypted columns.\n+ * 4) Perform interoperability tests with other (eg parquet-cpp) writers, by reading\n+ *    encrypted files produced by these writers.\n+ *\n+ * The write sample produces number of parquet files, each encrypted with a different\n+ * encryption configuration as described below.\n+ * The name of each file is in the form of:\n+ * tester<encryption config number>.parquet.encrypted.\n+ *\n+ * The read sample creates a set of decryption configurations and then uses each of them\n+ * to read all encrypted files in the input directory.\n+ *\n+ * The different encryption and decryption configurations are listed below.\n+ *\n+ *\n+ * A detailed description of the Parquet Modular Encryption specification can be found\n+ * here:\n+ * https://github.com/apache/parquet-format/blob/encryption/Encryption.md\n+ *\n+ * The write sample creates files with eight columns in the following\n+ * encryption configurations:\n+ *\n+ *  UNIFORM_ENCRYPTION:             Encrypt all columns and the footer with the same key.\n+ *                                  (uniform encryption)\n+ *  ENCRYPT_COLUMNS_AND_FOOTER:     Encrypt two columns and the footer, with different\n+ *                                  keys.\n+ *  ENCRYPT_COLUMNS_PLAINTEXT_FOOTER: Encrypt two columns, with different keys.\n+ *                                  Do not encrypt footer (to enable legacy readers)\n+ *                                  - plaintext footer mode.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_AAD: Encrypt two columns and the footer, with different\n+ *                                  keys. Supply aad_prefix for file identity\n+ *                                  verification.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE:   Encrypt two columns and the footer,\n+ *                                  with different keys. Supply aad_prefix, and call\n+ *                                  disable_aad_prefix_storage to prevent file\n+ *                                  identity storage in file metadata.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_CTR: Encrypt two columns and the footer, with different\n+ *                                  keys. Use the alternative (AES_GCM_CTR_V1) algorithm.\n+ *  NO_ENCRYPTION:                  Do not encrypt anything\n+ *\n+ *\n+ * The read sample uses each of the following decryption configurations to read every\n+ * encrypted files in the input directory:\n+ *\n+ *  DECRYPT_WITH_KEY_RETRIEVER:     Decrypt using key retriever that holds the keys of\n+ *                                  two encrypted columns and the footer key.\n+ *  DECRYPT_WITH_KEY_RETRIEVER_AAD: Decrypt using key retriever that holds the keys of\n+ *                                  two encrypted columns and the footer key. Supplies\n+ *                                  aad_prefix to verify file identity.\n+ *  DECRYPT_WITH_EXPLICIT_KEYS:     Decrypt using explicit column and footer keys\n+ *                                  (instead of key retrieval callback).\n+ *  NO_DECRYPTION:                  Do not decrypt anything.\n+ */\n+public class TestEncryptionOptions {\n+  private static final Logger LOG = LoggerFactory.getLogger(TestEncryptionOptions.class);\n+\n+  @Rule\n+  public TemporaryFolder temporaryFolder = new TemporaryFolder();\n+\n+  @Rule\n+  public ErrorCollector errorCollector = new ErrorCollector();\n+\n+  private static final byte[] FOOTER_ENCRYPTION_KEY = \"0123456789012345\".getBytes();\n+  private static final byte[] COLUMN_ENCRYPTION_KEY1 = \"1234567890123450\".getBytes();\n+  private static final byte[] COLUMN_ENCRYPTION_KEY2 = \"1234567890123451\".getBytes();\n+  private static final String FOOTER_ENCRYPTION_KEY_ID = \"kf\";\n+  private static final String COLUMN_ENCRYPTION_KEY1_ID = \"kc1\";\n+  private static final String COLUMN_ENCRYPTION_KEY2_ID = \"kc2\";\n+  private static final String AAD_PREFIX_STRING = \"tester\";\n+  private static final String BOOLEAN_FIELD_NAME = \"boolean_field\";\n+  private static final String INT32_FIELD_NAME = \"int32_field\";\n+  private static final String FLOAT_FIELD_NAME = \"float_field\";\n+  private static final String DOUBLE_FIELD_NAME = \"double_field\";\n+\n+  public enum EncryptionConfiguration {\n+    UNIFORM_ENCRYPTION(\"UNIFORM_ENCRYPTION\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER(\"ENCRYPT_COLUMNS_AND_FOOTER\"),\n+    ENCRYPT_COLUMNS_PLAINTEXT_FOOTER(\"ENCRYPT_COLUMNS_PLAINTEXT_FOOTER\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_AAD(\"ENCRYPT_COLUMNS_AND_FOOTER_AAD\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE(\"ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_CTR(\"ENCRYPT_COLUMNS_AND_FOOTER_CTR\"),\n+    NO_ENCRYPTION(\"NO_ENCRYPTION\");\n+\n+    private final String configurationName;\n+\n+    EncryptionConfiguration(String configurationName) {\n+      this.configurationName = configurationName;\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return configurationName;\n+    }\n+  }\n+\n+\n+  public enum DecryptionConfiguration {\n+    DECRYPT_WITH_KEY_RETRIEVER(\"DECRYPT_WITH_KEY_RETRIEVER\"),\n+    DECRYPT_WITH_KEY_RETRIEVER_AAD(\"DECRYPT_WITH_KEY_RETRIEVER_AAD\"),\n+    DECRYPT_WITH_EXPLICIT_KEYS(\"DECRYPT_WITH_EXPLICIT_KEYS\"),\n+    NO_DECRYPTION(\"NO_DECRYPTION\");\n+\n+    private final String configurationName;\n+\n+    DecryptionConfiguration(String configurationName) {\n+      this.configurationName = configurationName;\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return configurationName;\n+    }\n+  }\n+\n+  @Test\n+  public void testWriteReadEncryptedParquetFiles() throws IOException {\n+    Path rootPath = new Path(temporaryFolder.getRoot().getPath());\n+    LOG.info(\"======== testWriteReadEncryptedParquetFiles {} ========\", rootPath.toString());\n+    byte[] AADPrefix = AAD_PREFIX_STRING.getBytes(StandardCharsets.UTF_8);\n+    // This array will hold various encryption configuraions.\n+    Map<EncryptionConfiguration, FileEncryptionProperties> encryptionPropertiesMap =\n+      getEncryptionConfigurations(AADPrefix);\n+    testWriteEncryptedParquetFiles(rootPath, encryptionPropertiesMap);\n+    // This array will hold various decryption configurations.\n+    Map<DecryptionConfiguration, FileDecryptionProperties> decryptionPropertiesMap =\n+      getDecryptionConfigurations(AADPrefix);\n+    testReadEncryptedParquetFiles(rootPath, decryptionPropertiesMap);\n+  }\n+\n+  @Test\n+  public void testInteropReadEncryptedParquetFiles() throws IOException {\n+    Path rootPath = new Path(\"submodules/parquet-testing/data\");\n+    LOG.info(\"======== testInteropReadEncryptedParquetFiles {} ========\", rootPath.toString());\n+    byte[] AADPrefix = AAD_PREFIX_STRING.getBytes(StandardCharsets.UTF_8);\n+    // This array will hold various decryption configurations.\n+    Map<DecryptionConfiguration, FileDecryptionProperties> decryptionPropertiesMap =\n+      getDecryptionConfigurations(AADPrefix);\n+    testReadEncryptedParquetFiles(rootPath, decryptionPropertiesMap);\n+  }\n+\n+  private void testWriteEncryptedParquetFiles(Path root, Map<EncryptionConfiguration, FileEncryptionProperties> encryptionPropertiesMap) throws IOException {\n+    Configuration conf = new Configuration();\n+    int numberOfEncryptionModes = encryptionPropertiesMap.size();\n+\n+    MessageType schema = parseMessageType(\n+      \"message test { \"\n+        + \"required boolean \" + BOOLEAN_FIELD_NAME + \"; \"\n+        + \"required int32 \" + INT32_FIELD_NAME + \"; \"\n+        + \"required float \" + FLOAT_FIELD_NAME + \"; \"\n+        + \"required double \" + DOUBLE_FIELD_NAME + \"; \"\n+        + \"} \");\n+\n+    GroupWriteSupport.setSchema(schema, conf);\n+    SimpleGroupFactory f = new SimpleGroupFactory(schema);\n+\n+\n+    for (Map.Entry<EncryptionConfiguration, FileEncryptionProperties> encryptionConfigurationEntry : encryptionPropertiesMap.entrySet()) {\n+      EncryptionConfiguration encryptionConfiguration = encryptionConfigurationEntry.getKey();\n+      Path file = new Path(root, encryptionConfiguration.toString() + \".parquet.encrypted\");\n+\n+      LOG.info(\"\\nWrite \" + file.toString());\n+      ParquetWriter<Group> writer = ExampleParquetWriter.builder(file)\n+        .withWriteMode(OVERWRITE)\n+        .withType(schema)\n+        .withEncryption(encryptionConfigurationEntry.getValue())\n+        .build();\n+\n+      for (int i = 0; i < 100; i++) {\n+        boolean expect = false;\n+        if ((i % 2) == 0)\n+          expect = true;\n+        float float_val = (float) i * 1.1f;\n+        double double_val = (i * 1.1111111);\n+\n+        writer.write(\n+          f.newGroup()\n+            .append(BOOLEAN_FIELD_NAME, expect)\n+            .append(INT32_FIELD_NAME, i)\n+            .append(FLOAT_FIELD_NAME, float_val)\n+            .append(DOUBLE_FIELD_NAME, double_val));\n+\n+      }\n+      writer.close();\n+    }\n+  }\n+\n+  private void testReadEncryptedParquetFiles(Path root, Map<DecryptionConfiguration, FileDecryptionProperties> decryptionPropertiesMap) throws IOException {\n+    Configuration conf = new Configuration();\n+\n+    for (Map.Entry<DecryptionConfiguration, FileDecryptionProperties> decryptionConfigurationEntry : decryptionPropertiesMap.entrySet()) {\n+      DecryptionConfiguration decryptionConfiguration = decryptionConfigurationEntry.getKey();\n+      LOG.info(\"==> Decryption configuration {}\", decryptionConfiguration);\n+      FileDecryptionProperties fileDecryptionProperties = decryptionConfigurationEntry.getValue();\n+\n+      File folder = new File(root.toString());\n+      File[] listOfFiles = folder.listFiles();\n+\n+      for (int fileNum = 0; fileNum < listOfFiles.length; fileNum++) {\n+        Path file = new Path(listOfFiles[fileNum].getAbsolutePath());\n+        if (!file.getName().endsWith(\"parquet.encrypted\")) { // Skip non encrypted files\n+          continue;\n+        }\n+        EncryptionConfiguration encryptionConfiguration = getEncryptionConfigurationFromFilename(file.getName());\n+        if (null == encryptionConfiguration) {", "originalCommit": "4ca6a2febde567c7b8753100c1b80fe2831f403f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzg5MTgyNg==", "url": "https://github.com/apache/parquet-mr/pull/782#discussion_r433891826", "bodyText": "I would suggest using the try-with-resources construct to ensure closing the writer in any case.", "author": "gszadovszky", "createdAt": "2020-06-02T13:52:29Z", "path": "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestEncryptionOptions.java", "diffHunk": "@@ -0,0 +1,660 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.parquet.hadoop;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.parquet.crypto.ColumnDecryptionProperties;\n+import org.apache.parquet.crypto.ColumnEncryptionProperties;\n+import org.apache.parquet.crypto.FileDecryptionProperties;\n+import org.apache.parquet.crypto.FileEncryptionProperties;\n+import org.apache.parquet.crypto.ParquetCipher;\n+import org.apache.parquet.crypto.DecryptionKeyRetriever;\n+import org.apache.parquet.example.data.Group;\n+import org.apache.parquet.example.data.simple.SimpleGroupFactory;\n+import org.apache.parquet.filter2.compat.FilterCompat;\n+import org.apache.parquet.hadoop.example.ExampleParquetWriter;\n+import org.apache.parquet.hadoop.example.GroupReadSupport;\n+import org.apache.parquet.hadoop.example.GroupWriteSupport;\n+import org.apache.parquet.hadoop.metadata.ColumnPath;\n+import org.apache.parquet.schema.MessageType;\n+import org.apache.parquet.schema.Types;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.ErrorCollector;\n+import org.junit.rules.TemporaryFolder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.parquet.hadoop.ParquetFileWriter.Mode.OVERWRITE;\n+import static org.apache.parquet.hadoop.metadata.CompressionCodecName.UNCOMPRESSED;\n+import static org.apache.parquet.schema.MessageTypeParser.parseMessageType;\n+import static org.apache.parquet.schema.PrimitiveType.PrimitiveTypeName.BOOLEAN;\n+import static org.apache.parquet.schema.PrimitiveType.PrimitiveTypeName.INT32;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+/*\n+ * This file contains samples for writing and reading encrypted Parquet files in different\n+ * encryption and decryption configurations. The samples have the following goals:\n+ * 1) Demonstrate usage of different options for data encryption and decryption.\n+ * 2) Produce encrypted files for interoperability tests with other (eg parquet-cpp)\n+ *    readers that support encryption.\n+ * 3) Produce encrypted files with plaintext footer, for testing the ability of legacy\n+ *    readers to parse the footer and read unencrypted columns.\n+ * 4) Perform interoperability tests with other (eg parquet-cpp) writers, by reading\n+ *    encrypted files produced by these writers.\n+ *\n+ * The write sample produces number of parquet files, each encrypted with a different\n+ * encryption configuration as described below.\n+ * The name of each file is in the form of:\n+ * tester<encryption config number>.parquet.encrypted.\n+ *\n+ * The read sample creates a set of decryption configurations and then uses each of them\n+ * to read all encrypted files in the input directory.\n+ *\n+ * The different encryption and decryption configurations are listed below.\n+ *\n+ *\n+ * A detailed description of the Parquet Modular Encryption specification can be found\n+ * here:\n+ * https://github.com/apache/parquet-format/blob/encryption/Encryption.md\n+ *\n+ * The write sample creates files with eight columns in the following\n+ * encryption configurations:\n+ *\n+ *  UNIFORM_ENCRYPTION:             Encrypt all columns and the footer with the same key.\n+ *                                  (uniform encryption)\n+ *  ENCRYPT_COLUMNS_AND_FOOTER:     Encrypt two columns and the footer, with different\n+ *                                  keys.\n+ *  ENCRYPT_COLUMNS_PLAINTEXT_FOOTER: Encrypt two columns, with different keys.\n+ *                                  Do not encrypt footer (to enable legacy readers)\n+ *                                  - plaintext footer mode.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_AAD: Encrypt two columns and the footer, with different\n+ *                                  keys. Supply aad_prefix for file identity\n+ *                                  verification.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE:   Encrypt two columns and the footer,\n+ *                                  with different keys. Supply aad_prefix, and call\n+ *                                  disable_aad_prefix_storage to prevent file\n+ *                                  identity storage in file metadata.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_CTR: Encrypt two columns and the footer, with different\n+ *                                  keys. Use the alternative (AES_GCM_CTR_V1) algorithm.\n+ *  NO_ENCRYPTION:                  Do not encrypt anything\n+ *\n+ *\n+ * The read sample uses each of the following decryption configurations to read every\n+ * encrypted files in the input directory:\n+ *\n+ *  DECRYPT_WITH_KEY_RETRIEVER:     Decrypt using key retriever that holds the keys of\n+ *                                  two encrypted columns and the footer key.\n+ *  DECRYPT_WITH_KEY_RETRIEVER_AAD: Decrypt using key retriever that holds the keys of\n+ *                                  two encrypted columns and the footer key. Supplies\n+ *                                  aad_prefix to verify file identity.\n+ *  DECRYPT_WITH_EXPLICIT_KEYS:     Decrypt using explicit column and footer keys\n+ *                                  (instead of key retrieval callback).\n+ *  NO_DECRYPTION:                  Do not decrypt anything.\n+ */\n+public class TestEncryptionOptions {\n+  private static final Logger LOG = LoggerFactory.getLogger(TestEncryptionOptions.class);\n+\n+  @Rule\n+  public TemporaryFolder temporaryFolder = new TemporaryFolder();\n+\n+  @Rule\n+  public ErrorCollector errorCollector = new ErrorCollector();\n+\n+  private static final byte[] FOOTER_ENCRYPTION_KEY = \"0123456789012345\".getBytes();\n+  private static final byte[] COLUMN_ENCRYPTION_KEY1 = \"1234567890123450\".getBytes();\n+  private static final byte[] COLUMN_ENCRYPTION_KEY2 = \"1234567890123451\".getBytes();\n+  private static final String FOOTER_ENCRYPTION_KEY_ID = \"kf\";\n+  private static final String COLUMN_ENCRYPTION_KEY1_ID = \"kc1\";\n+  private static final String COLUMN_ENCRYPTION_KEY2_ID = \"kc2\";\n+  private static final String AAD_PREFIX_STRING = \"tester\";\n+  private static final String BOOLEAN_FIELD_NAME = \"boolean_field\";\n+  private static final String INT32_FIELD_NAME = \"int32_field\";\n+  private static final String FLOAT_FIELD_NAME = \"float_field\";\n+  private static final String DOUBLE_FIELD_NAME = \"double_field\";\n+\n+  public enum EncryptionConfiguration {\n+    UNIFORM_ENCRYPTION(\"UNIFORM_ENCRYPTION\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER(\"ENCRYPT_COLUMNS_AND_FOOTER\"),\n+    ENCRYPT_COLUMNS_PLAINTEXT_FOOTER(\"ENCRYPT_COLUMNS_PLAINTEXT_FOOTER\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_AAD(\"ENCRYPT_COLUMNS_AND_FOOTER_AAD\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE(\"ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_CTR(\"ENCRYPT_COLUMNS_AND_FOOTER_CTR\"),\n+    NO_ENCRYPTION(\"NO_ENCRYPTION\");\n+\n+    private final String configurationName;\n+\n+    EncryptionConfiguration(String configurationName) {\n+      this.configurationName = configurationName;\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return configurationName;\n+    }\n+  }\n+\n+\n+  public enum DecryptionConfiguration {\n+    DECRYPT_WITH_KEY_RETRIEVER(\"DECRYPT_WITH_KEY_RETRIEVER\"),\n+    DECRYPT_WITH_KEY_RETRIEVER_AAD(\"DECRYPT_WITH_KEY_RETRIEVER_AAD\"),\n+    DECRYPT_WITH_EXPLICIT_KEYS(\"DECRYPT_WITH_EXPLICIT_KEYS\"),\n+    NO_DECRYPTION(\"NO_DECRYPTION\");\n+\n+    private final String configurationName;\n+\n+    DecryptionConfiguration(String configurationName) {\n+      this.configurationName = configurationName;\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return configurationName;\n+    }\n+  }\n+\n+  @Test\n+  public void testWriteReadEncryptedParquetFiles() throws IOException {\n+    Path rootPath = new Path(temporaryFolder.getRoot().getPath());\n+    LOG.info(\"======== testWriteReadEncryptedParquetFiles {} ========\", rootPath.toString());\n+    byte[] AADPrefix = AAD_PREFIX_STRING.getBytes(StandardCharsets.UTF_8);\n+    // This array will hold various encryption configuraions.\n+    Map<EncryptionConfiguration, FileEncryptionProperties> encryptionPropertiesMap =\n+      getEncryptionConfigurations(AADPrefix);\n+    testWriteEncryptedParquetFiles(rootPath, encryptionPropertiesMap);\n+    // This array will hold various decryption configurations.\n+    Map<DecryptionConfiguration, FileDecryptionProperties> decryptionPropertiesMap =\n+      getDecryptionConfigurations(AADPrefix);\n+    testReadEncryptedParquetFiles(rootPath, decryptionPropertiesMap);\n+  }\n+\n+  @Test\n+  public void testInteropReadEncryptedParquetFiles() throws IOException {\n+    Path rootPath = new Path(\"submodules/parquet-testing/data\");\n+    LOG.info(\"======== testInteropReadEncryptedParquetFiles {} ========\", rootPath.toString());\n+    byte[] AADPrefix = AAD_PREFIX_STRING.getBytes(StandardCharsets.UTF_8);\n+    // This array will hold various decryption configurations.\n+    Map<DecryptionConfiguration, FileDecryptionProperties> decryptionPropertiesMap =\n+      getDecryptionConfigurations(AADPrefix);\n+    testReadEncryptedParquetFiles(rootPath, decryptionPropertiesMap);\n+  }\n+\n+  private void testWriteEncryptedParquetFiles(Path root, Map<EncryptionConfiguration, FileEncryptionProperties> encryptionPropertiesMap) throws IOException {\n+    Configuration conf = new Configuration();\n+    int numberOfEncryptionModes = encryptionPropertiesMap.size();\n+\n+    MessageType schema = parseMessageType(\n+      \"message test { \"\n+        + \"required boolean \" + BOOLEAN_FIELD_NAME + \"; \"\n+        + \"required int32 \" + INT32_FIELD_NAME + \"; \"\n+        + \"required float \" + FLOAT_FIELD_NAME + \"; \"\n+        + \"required double \" + DOUBLE_FIELD_NAME + \"; \"\n+        + \"} \");\n+\n+    GroupWriteSupport.setSchema(schema, conf);\n+    SimpleGroupFactory f = new SimpleGroupFactory(schema);\n+\n+\n+    for (Map.Entry<EncryptionConfiguration, FileEncryptionProperties> encryptionConfigurationEntry : encryptionPropertiesMap.entrySet()) {\n+      EncryptionConfiguration encryptionConfiguration = encryptionConfigurationEntry.getKey();\n+      Path file = new Path(root, encryptionConfiguration.toString() + \".parquet.encrypted\");\n+\n+      LOG.info(\"\\nWrite \" + file.toString());\n+      ParquetWriter<Group> writer = ExampleParquetWriter.builder(file)\n+        .withWriteMode(OVERWRITE)\n+        .withType(schema)\n+        .withEncryption(encryptionConfigurationEntry.getValue())\n+        .build();\n+\n+      for (int i = 0; i < 100; i++) {\n+        boolean expect = false;\n+        if ((i % 2) == 0)\n+          expect = true;\n+        float float_val = (float) i * 1.1f;\n+        double double_val = (i * 1.1111111);\n+\n+        writer.write(\n+          f.newGroup()\n+            .append(BOOLEAN_FIELD_NAME, expect)\n+            .append(INT32_FIELD_NAME, i)\n+            .append(FLOAT_FIELD_NAME, float_val)\n+            .append(DOUBLE_FIELD_NAME, double_val));\n+\n+      }\n+      writer.close();\n+    }", "originalCommit": "4ca6a2febde567c7b8753100c1b80fe2831f403f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzg5MzI0Ng==", "url": "https://github.com/apache/parquet-mr/pull/782#discussion_r433893246", "bodyText": "I would suggest using the try-with-resources construct to ensure closing the reader in any case.", "author": "gszadovszky", "createdAt": "2020-06-02T13:54:18Z", "path": "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestEncryptionOptions.java", "diffHunk": "@@ -0,0 +1,660 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.parquet.hadoop;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.parquet.crypto.ColumnDecryptionProperties;\n+import org.apache.parquet.crypto.ColumnEncryptionProperties;\n+import org.apache.parquet.crypto.FileDecryptionProperties;\n+import org.apache.parquet.crypto.FileEncryptionProperties;\n+import org.apache.parquet.crypto.ParquetCipher;\n+import org.apache.parquet.crypto.DecryptionKeyRetriever;\n+import org.apache.parquet.example.data.Group;\n+import org.apache.parquet.example.data.simple.SimpleGroupFactory;\n+import org.apache.parquet.filter2.compat.FilterCompat;\n+import org.apache.parquet.hadoop.example.ExampleParquetWriter;\n+import org.apache.parquet.hadoop.example.GroupReadSupport;\n+import org.apache.parquet.hadoop.example.GroupWriteSupport;\n+import org.apache.parquet.hadoop.metadata.ColumnPath;\n+import org.apache.parquet.schema.MessageType;\n+import org.apache.parquet.schema.Types;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.ErrorCollector;\n+import org.junit.rules.TemporaryFolder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.parquet.hadoop.ParquetFileWriter.Mode.OVERWRITE;\n+import static org.apache.parquet.hadoop.metadata.CompressionCodecName.UNCOMPRESSED;\n+import static org.apache.parquet.schema.MessageTypeParser.parseMessageType;\n+import static org.apache.parquet.schema.PrimitiveType.PrimitiveTypeName.BOOLEAN;\n+import static org.apache.parquet.schema.PrimitiveType.PrimitiveTypeName.INT32;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+/*\n+ * This file contains samples for writing and reading encrypted Parquet files in different\n+ * encryption and decryption configurations. The samples have the following goals:\n+ * 1) Demonstrate usage of different options for data encryption and decryption.\n+ * 2) Produce encrypted files for interoperability tests with other (eg parquet-cpp)\n+ *    readers that support encryption.\n+ * 3) Produce encrypted files with plaintext footer, for testing the ability of legacy\n+ *    readers to parse the footer and read unencrypted columns.\n+ * 4) Perform interoperability tests with other (eg parquet-cpp) writers, by reading\n+ *    encrypted files produced by these writers.\n+ *\n+ * The write sample produces number of parquet files, each encrypted with a different\n+ * encryption configuration as described below.\n+ * The name of each file is in the form of:\n+ * tester<encryption config number>.parquet.encrypted.\n+ *\n+ * The read sample creates a set of decryption configurations and then uses each of them\n+ * to read all encrypted files in the input directory.\n+ *\n+ * The different encryption and decryption configurations are listed below.\n+ *\n+ *\n+ * A detailed description of the Parquet Modular Encryption specification can be found\n+ * here:\n+ * https://github.com/apache/parquet-format/blob/encryption/Encryption.md\n+ *\n+ * The write sample creates files with eight columns in the following\n+ * encryption configurations:\n+ *\n+ *  UNIFORM_ENCRYPTION:             Encrypt all columns and the footer with the same key.\n+ *                                  (uniform encryption)\n+ *  ENCRYPT_COLUMNS_AND_FOOTER:     Encrypt two columns and the footer, with different\n+ *                                  keys.\n+ *  ENCRYPT_COLUMNS_PLAINTEXT_FOOTER: Encrypt two columns, with different keys.\n+ *                                  Do not encrypt footer (to enable legacy readers)\n+ *                                  - plaintext footer mode.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_AAD: Encrypt two columns and the footer, with different\n+ *                                  keys. Supply aad_prefix for file identity\n+ *                                  verification.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE:   Encrypt two columns and the footer,\n+ *                                  with different keys. Supply aad_prefix, and call\n+ *                                  disable_aad_prefix_storage to prevent file\n+ *                                  identity storage in file metadata.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_CTR: Encrypt two columns and the footer, with different\n+ *                                  keys. Use the alternative (AES_GCM_CTR_V1) algorithm.\n+ *  NO_ENCRYPTION:                  Do not encrypt anything\n+ *\n+ *\n+ * The read sample uses each of the following decryption configurations to read every\n+ * encrypted files in the input directory:\n+ *\n+ *  DECRYPT_WITH_KEY_RETRIEVER:     Decrypt using key retriever that holds the keys of\n+ *                                  two encrypted columns and the footer key.\n+ *  DECRYPT_WITH_KEY_RETRIEVER_AAD: Decrypt using key retriever that holds the keys of\n+ *                                  two encrypted columns and the footer key. Supplies\n+ *                                  aad_prefix to verify file identity.\n+ *  DECRYPT_WITH_EXPLICIT_KEYS:     Decrypt using explicit column and footer keys\n+ *                                  (instead of key retrieval callback).\n+ *  NO_DECRYPTION:                  Do not decrypt anything.\n+ */\n+public class TestEncryptionOptions {\n+  private static final Logger LOG = LoggerFactory.getLogger(TestEncryptionOptions.class);\n+\n+  @Rule\n+  public TemporaryFolder temporaryFolder = new TemporaryFolder();\n+\n+  @Rule\n+  public ErrorCollector errorCollector = new ErrorCollector();\n+\n+  private static final byte[] FOOTER_ENCRYPTION_KEY = \"0123456789012345\".getBytes();\n+  private static final byte[] COLUMN_ENCRYPTION_KEY1 = \"1234567890123450\".getBytes();\n+  private static final byte[] COLUMN_ENCRYPTION_KEY2 = \"1234567890123451\".getBytes();\n+  private static final String FOOTER_ENCRYPTION_KEY_ID = \"kf\";\n+  private static final String COLUMN_ENCRYPTION_KEY1_ID = \"kc1\";\n+  private static final String COLUMN_ENCRYPTION_KEY2_ID = \"kc2\";\n+  private static final String AAD_PREFIX_STRING = \"tester\";\n+  private static final String BOOLEAN_FIELD_NAME = \"boolean_field\";\n+  private static final String INT32_FIELD_NAME = \"int32_field\";\n+  private static final String FLOAT_FIELD_NAME = \"float_field\";\n+  private static final String DOUBLE_FIELD_NAME = \"double_field\";\n+\n+  public enum EncryptionConfiguration {\n+    UNIFORM_ENCRYPTION(\"UNIFORM_ENCRYPTION\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER(\"ENCRYPT_COLUMNS_AND_FOOTER\"),\n+    ENCRYPT_COLUMNS_PLAINTEXT_FOOTER(\"ENCRYPT_COLUMNS_PLAINTEXT_FOOTER\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_AAD(\"ENCRYPT_COLUMNS_AND_FOOTER_AAD\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE(\"ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_CTR(\"ENCRYPT_COLUMNS_AND_FOOTER_CTR\"),\n+    NO_ENCRYPTION(\"NO_ENCRYPTION\");\n+\n+    private final String configurationName;\n+\n+    EncryptionConfiguration(String configurationName) {\n+      this.configurationName = configurationName;\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return configurationName;\n+    }\n+  }\n+\n+\n+  public enum DecryptionConfiguration {\n+    DECRYPT_WITH_KEY_RETRIEVER(\"DECRYPT_WITH_KEY_RETRIEVER\"),\n+    DECRYPT_WITH_KEY_RETRIEVER_AAD(\"DECRYPT_WITH_KEY_RETRIEVER_AAD\"),\n+    DECRYPT_WITH_EXPLICIT_KEYS(\"DECRYPT_WITH_EXPLICIT_KEYS\"),\n+    NO_DECRYPTION(\"NO_DECRYPTION\");\n+\n+    private final String configurationName;\n+\n+    DecryptionConfiguration(String configurationName) {\n+      this.configurationName = configurationName;\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return configurationName;\n+    }\n+  }\n+\n+  @Test\n+  public void testWriteReadEncryptedParquetFiles() throws IOException {\n+    Path rootPath = new Path(temporaryFolder.getRoot().getPath());\n+    LOG.info(\"======== testWriteReadEncryptedParquetFiles {} ========\", rootPath.toString());\n+    byte[] AADPrefix = AAD_PREFIX_STRING.getBytes(StandardCharsets.UTF_8);\n+    // This array will hold various encryption configuraions.\n+    Map<EncryptionConfiguration, FileEncryptionProperties> encryptionPropertiesMap =\n+      getEncryptionConfigurations(AADPrefix);\n+    testWriteEncryptedParquetFiles(rootPath, encryptionPropertiesMap);\n+    // This array will hold various decryption configurations.\n+    Map<DecryptionConfiguration, FileDecryptionProperties> decryptionPropertiesMap =\n+      getDecryptionConfigurations(AADPrefix);\n+    testReadEncryptedParquetFiles(rootPath, decryptionPropertiesMap);\n+  }\n+\n+  @Test\n+  public void testInteropReadEncryptedParquetFiles() throws IOException {\n+    Path rootPath = new Path(\"submodules/parquet-testing/data\");\n+    LOG.info(\"======== testInteropReadEncryptedParquetFiles {} ========\", rootPath.toString());\n+    byte[] AADPrefix = AAD_PREFIX_STRING.getBytes(StandardCharsets.UTF_8);\n+    // This array will hold various decryption configurations.\n+    Map<DecryptionConfiguration, FileDecryptionProperties> decryptionPropertiesMap =\n+      getDecryptionConfigurations(AADPrefix);\n+    testReadEncryptedParquetFiles(rootPath, decryptionPropertiesMap);\n+  }\n+\n+  private void testWriteEncryptedParquetFiles(Path root, Map<EncryptionConfiguration, FileEncryptionProperties> encryptionPropertiesMap) throws IOException {\n+    Configuration conf = new Configuration();\n+    int numberOfEncryptionModes = encryptionPropertiesMap.size();\n+\n+    MessageType schema = parseMessageType(\n+      \"message test { \"\n+        + \"required boolean \" + BOOLEAN_FIELD_NAME + \"; \"\n+        + \"required int32 \" + INT32_FIELD_NAME + \"; \"\n+        + \"required float \" + FLOAT_FIELD_NAME + \"; \"\n+        + \"required double \" + DOUBLE_FIELD_NAME + \"; \"\n+        + \"} \");\n+\n+    GroupWriteSupport.setSchema(schema, conf);\n+    SimpleGroupFactory f = new SimpleGroupFactory(schema);\n+\n+\n+    for (Map.Entry<EncryptionConfiguration, FileEncryptionProperties> encryptionConfigurationEntry : encryptionPropertiesMap.entrySet()) {\n+      EncryptionConfiguration encryptionConfiguration = encryptionConfigurationEntry.getKey();\n+      Path file = new Path(root, encryptionConfiguration.toString() + \".parquet.encrypted\");\n+\n+      LOG.info(\"\\nWrite \" + file.toString());\n+      ParquetWriter<Group> writer = ExampleParquetWriter.builder(file)\n+        .withWriteMode(OVERWRITE)\n+        .withType(schema)\n+        .withEncryption(encryptionConfigurationEntry.getValue())\n+        .build();\n+\n+      for (int i = 0; i < 100; i++) {\n+        boolean expect = false;\n+        if ((i % 2) == 0)\n+          expect = true;\n+        float float_val = (float) i * 1.1f;\n+        double double_val = (i * 1.1111111);\n+\n+        writer.write(\n+          f.newGroup()\n+            .append(BOOLEAN_FIELD_NAME, expect)\n+            .append(INT32_FIELD_NAME, i)\n+            .append(FLOAT_FIELD_NAME, float_val)\n+            .append(DOUBLE_FIELD_NAME, double_val));\n+\n+      }\n+      writer.close();\n+    }\n+  }\n+\n+  private void testReadEncryptedParquetFiles(Path root, Map<DecryptionConfiguration, FileDecryptionProperties> decryptionPropertiesMap) throws IOException {\n+    Configuration conf = new Configuration();\n+\n+    for (Map.Entry<DecryptionConfiguration, FileDecryptionProperties> decryptionConfigurationEntry : decryptionPropertiesMap.entrySet()) {\n+      DecryptionConfiguration decryptionConfiguration = decryptionConfigurationEntry.getKey();\n+      LOG.info(\"==> Decryption configuration {}\", decryptionConfiguration);\n+      FileDecryptionProperties fileDecryptionProperties = decryptionConfigurationEntry.getValue();\n+\n+      File folder = new File(root.toString());\n+      File[] listOfFiles = folder.listFiles();\n+\n+      for (int fileNum = 0; fileNum < listOfFiles.length; fileNum++) {\n+        Path file = new Path(listOfFiles[fileNum].getAbsolutePath());\n+        if (!file.getName().endsWith(\"parquet.encrypted\")) { // Skip non encrypted files\n+          continue;\n+        }\n+        EncryptionConfiguration encryptionConfiguration = getEncryptionConfigurationFromFilename(file.getName());\n+        if (null == encryptionConfiguration) {\n+          continue;\n+        }\n+        LOG.info(\"--> Read file {} {}\", file.toString(), encryptionConfiguration);\n+\n+        // Read only the non-encrypted columns\n+        if ((decryptionConfiguration == DecryptionConfiguration.NO_DECRYPTION) &&\n+          (encryptionConfiguration == EncryptionConfiguration.ENCRYPT_COLUMNS_PLAINTEXT_FOOTER)) {\n+          conf.set(\"parquet.read.schema\", Types.buildMessage()\n+            .required(BOOLEAN).named(BOOLEAN_FIELD_NAME)\n+            .required(INT32).named(INT32_FIELD_NAME)\n+            .named(\"FormatTestObject\").toString());\n+        }\n+\n+        ParquetReader<Group> reader = ParquetReader.builder(new GroupReadSupport(), file)\n+          .withConf(conf)\n+          .withDecryption(fileDecryptionProperties)\n+          .build();\n+\n+        try {\n+          for (int i = 0; i < 500; i++) {\n+            Group group = null;\n+            group = reader.read();\n+            boolean expect = false;\n+            if ((i % 2) == 0)\n+              expect = true;\n+            boolean bool_res = group.getBoolean(BOOLEAN_FIELD_NAME, 0);\n+            if (bool_res != expect)\n+              addErrorToErrorCollectorAndLog(\"Wrong bool\", encryptionConfiguration, decryptionConfiguration);\n+            int int_res = group.getInteger(INT32_FIELD_NAME, 0);\n+            if (int_res != i)\n+              addErrorToErrorCollectorAndLog(\"Wrong int\", encryptionConfiguration, decryptionConfiguration);\n+            if (decryptionConfiguration != DecryptionConfiguration.NO_DECRYPTION) {\n+              float float_res = group.getFloat(FLOAT_FIELD_NAME, 0);\n+              float tmp1 = (float) i * 1.1f;\n+              if (float_res != tmp1)\n+                addErrorToErrorCollectorAndLog(\"Wrong float\", encryptionConfiguration, decryptionConfiguration);\n+\n+              double double_res = group.getDouble(DOUBLE_FIELD_NAME, 0);\n+              double tmp = (i * 1.1111111);\n+              if (double_res != tmp)\n+                addErrorToErrorCollectorAndLog(\"Wrong double\", encryptionConfiguration, decryptionConfiguration);\n+            }\n+          }\n+        } catch (Exception e) {\n+          String errorMessage = e.getMessage();\n+          checkResult(file.getName(), decryptionConfiguration, (null == errorMessage ? \"\" : errorMessage));\n+        }", "originalCommit": "4ca6a2febde567c7b8753100c1b80fe2831f403f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzg5NDYwNA==", "url": "https://github.com/apache/parquet-mr/pull/782#discussion_r433894604", "bodyText": "You are writing 100 rows and reading 500?", "author": "gszadovszky", "createdAt": "2020-06-02T13:55:55Z", "path": "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestEncryptionOptions.java", "diffHunk": "@@ -0,0 +1,660 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.parquet.hadoop;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.parquet.crypto.ColumnDecryptionProperties;\n+import org.apache.parquet.crypto.ColumnEncryptionProperties;\n+import org.apache.parquet.crypto.FileDecryptionProperties;\n+import org.apache.parquet.crypto.FileEncryptionProperties;\n+import org.apache.parquet.crypto.ParquetCipher;\n+import org.apache.parquet.crypto.DecryptionKeyRetriever;\n+import org.apache.parquet.example.data.Group;\n+import org.apache.parquet.example.data.simple.SimpleGroupFactory;\n+import org.apache.parquet.filter2.compat.FilterCompat;\n+import org.apache.parquet.hadoop.example.ExampleParquetWriter;\n+import org.apache.parquet.hadoop.example.GroupReadSupport;\n+import org.apache.parquet.hadoop.example.GroupWriteSupport;\n+import org.apache.parquet.hadoop.metadata.ColumnPath;\n+import org.apache.parquet.schema.MessageType;\n+import org.apache.parquet.schema.Types;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.ErrorCollector;\n+import org.junit.rules.TemporaryFolder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.parquet.hadoop.ParquetFileWriter.Mode.OVERWRITE;\n+import static org.apache.parquet.hadoop.metadata.CompressionCodecName.UNCOMPRESSED;\n+import static org.apache.parquet.schema.MessageTypeParser.parseMessageType;\n+import static org.apache.parquet.schema.PrimitiveType.PrimitiveTypeName.BOOLEAN;\n+import static org.apache.parquet.schema.PrimitiveType.PrimitiveTypeName.INT32;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+/*\n+ * This file contains samples for writing and reading encrypted Parquet files in different\n+ * encryption and decryption configurations. The samples have the following goals:\n+ * 1) Demonstrate usage of different options for data encryption and decryption.\n+ * 2) Produce encrypted files for interoperability tests with other (eg parquet-cpp)\n+ *    readers that support encryption.\n+ * 3) Produce encrypted files with plaintext footer, for testing the ability of legacy\n+ *    readers to parse the footer and read unencrypted columns.\n+ * 4) Perform interoperability tests with other (eg parquet-cpp) writers, by reading\n+ *    encrypted files produced by these writers.\n+ *\n+ * The write sample produces number of parquet files, each encrypted with a different\n+ * encryption configuration as described below.\n+ * The name of each file is in the form of:\n+ * tester<encryption config number>.parquet.encrypted.\n+ *\n+ * The read sample creates a set of decryption configurations and then uses each of them\n+ * to read all encrypted files in the input directory.\n+ *\n+ * The different encryption and decryption configurations are listed below.\n+ *\n+ *\n+ * A detailed description of the Parquet Modular Encryption specification can be found\n+ * here:\n+ * https://github.com/apache/parquet-format/blob/encryption/Encryption.md\n+ *\n+ * The write sample creates files with eight columns in the following\n+ * encryption configurations:\n+ *\n+ *  UNIFORM_ENCRYPTION:             Encrypt all columns and the footer with the same key.\n+ *                                  (uniform encryption)\n+ *  ENCRYPT_COLUMNS_AND_FOOTER:     Encrypt two columns and the footer, with different\n+ *                                  keys.\n+ *  ENCRYPT_COLUMNS_PLAINTEXT_FOOTER: Encrypt two columns, with different keys.\n+ *                                  Do not encrypt footer (to enable legacy readers)\n+ *                                  - plaintext footer mode.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_AAD: Encrypt two columns and the footer, with different\n+ *                                  keys. Supply aad_prefix for file identity\n+ *                                  verification.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE:   Encrypt two columns and the footer,\n+ *                                  with different keys. Supply aad_prefix, and call\n+ *                                  disable_aad_prefix_storage to prevent file\n+ *                                  identity storage in file metadata.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_CTR: Encrypt two columns and the footer, with different\n+ *                                  keys. Use the alternative (AES_GCM_CTR_V1) algorithm.\n+ *  NO_ENCRYPTION:                  Do not encrypt anything\n+ *\n+ *\n+ * The read sample uses each of the following decryption configurations to read every\n+ * encrypted files in the input directory:\n+ *\n+ *  DECRYPT_WITH_KEY_RETRIEVER:     Decrypt using key retriever that holds the keys of\n+ *                                  two encrypted columns and the footer key.\n+ *  DECRYPT_WITH_KEY_RETRIEVER_AAD: Decrypt using key retriever that holds the keys of\n+ *                                  two encrypted columns and the footer key. Supplies\n+ *                                  aad_prefix to verify file identity.\n+ *  DECRYPT_WITH_EXPLICIT_KEYS:     Decrypt using explicit column and footer keys\n+ *                                  (instead of key retrieval callback).\n+ *  NO_DECRYPTION:                  Do not decrypt anything.\n+ */\n+public class TestEncryptionOptions {\n+  private static final Logger LOG = LoggerFactory.getLogger(TestEncryptionOptions.class);\n+\n+  @Rule\n+  public TemporaryFolder temporaryFolder = new TemporaryFolder();\n+\n+  @Rule\n+  public ErrorCollector errorCollector = new ErrorCollector();\n+\n+  private static final byte[] FOOTER_ENCRYPTION_KEY = \"0123456789012345\".getBytes();\n+  private static final byte[] COLUMN_ENCRYPTION_KEY1 = \"1234567890123450\".getBytes();\n+  private static final byte[] COLUMN_ENCRYPTION_KEY2 = \"1234567890123451\".getBytes();\n+  private static final String FOOTER_ENCRYPTION_KEY_ID = \"kf\";\n+  private static final String COLUMN_ENCRYPTION_KEY1_ID = \"kc1\";\n+  private static final String COLUMN_ENCRYPTION_KEY2_ID = \"kc2\";\n+  private static final String AAD_PREFIX_STRING = \"tester\";\n+  private static final String BOOLEAN_FIELD_NAME = \"boolean_field\";\n+  private static final String INT32_FIELD_NAME = \"int32_field\";\n+  private static final String FLOAT_FIELD_NAME = \"float_field\";\n+  private static final String DOUBLE_FIELD_NAME = \"double_field\";\n+\n+  public enum EncryptionConfiguration {\n+    UNIFORM_ENCRYPTION(\"UNIFORM_ENCRYPTION\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER(\"ENCRYPT_COLUMNS_AND_FOOTER\"),\n+    ENCRYPT_COLUMNS_PLAINTEXT_FOOTER(\"ENCRYPT_COLUMNS_PLAINTEXT_FOOTER\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_AAD(\"ENCRYPT_COLUMNS_AND_FOOTER_AAD\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE(\"ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_CTR(\"ENCRYPT_COLUMNS_AND_FOOTER_CTR\"),\n+    NO_ENCRYPTION(\"NO_ENCRYPTION\");\n+\n+    private final String configurationName;\n+\n+    EncryptionConfiguration(String configurationName) {\n+      this.configurationName = configurationName;\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return configurationName;\n+    }\n+  }\n+\n+\n+  public enum DecryptionConfiguration {\n+    DECRYPT_WITH_KEY_RETRIEVER(\"DECRYPT_WITH_KEY_RETRIEVER\"),\n+    DECRYPT_WITH_KEY_RETRIEVER_AAD(\"DECRYPT_WITH_KEY_RETRIEVER_AAD\"),\n+    DECRYPT_WITH_EXPLICIT_KEYS(\"DECRYPT_WITH_EXPLICIT_KEYS\"),\n+    NO_DECRYPTION(\"NO_DECRYPTION\");\n+\n+    private final String configurationName;\n+\n+    DecryptionConfiguration(String configurationName) {\n+      this.configurationName = configurationName;\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return configurationName;\n+    }\n+  }\n+\n+  @Test\n+  public void testWriteReadEncryptedParquetFiles() throws IOException {\n+    Path rootPath = new Path(temporaryFolder.getRoot().getPath());\n+    LOG.info(\"======== testWriteReadEncryptedParquetFiles {} ========\", rootPath.toString());\n+    byte[] AADPrefix = AAD_PREFIX_STRING.getBytes(StandardCharsets.UTF_8);\n+    // This array will hold various encryption configuraions.\n+    Map<EncryptionConfiguration, FileEncryptionProperties> encryptionPropertiesMap =\n+      getEncryptionConfigurations(AADPrefix);\n+    testWriteEncryptedParquetFiles(rootPath, encryptionPropertiesMap);\n+    // This array will hold various decryption configurations.\n+    Map<DecryptionConfiguration, FileDecryptionProperties> decryptionPropertiesMap =\n+      getDecryptionConfigurations(AADPrefix);\n+    testReadEncryptedParquetFiles(rootPath, decryptionPropertiesMap);\n+  }\n+\n+  @Test\n+  public void testInteropReadEncryptedParquetFiles() throws IOException {\n+    Path rootPath = new Path(\"submodules/parquet-testing/data\");\n+    LOG.info(\"======== testInteropReadEncryptedParquetFiles {} ========\", rootPath.toString());\n+    byte[] AADPrefix = AAD_PREFIX_STRING.getBytes(StandardCharsets.UTF_8);\n+    // This array will hold various decryption configurations.\n+    Map<DecryptionConfiguration, FileDecryptionProperties> decryptionPropertiesMap =\n+      getDecryptionConfigurations(AADPrefix);\n+    testReadEncryptedParquetFiles(rootPath, decryptionPropertiesMap);\n+  }\n+\n+  private void testWriteEncryptedParquetFiles(Path root, Map<EncryptionConfiguration, FileEncryptionProperties> encryptionPropertiesMap) throws IOException {\n+    Configuration conf = new Configuration();\n+    int numberOfEncryptionModes = encryptionPropertiesMap.size();\n+\n+    MessageType schema = parseMessageType(\n+      \"message test { \"\n+        + \"required boolean \" + BOOLEAN_FIELD_NAME + \"; \"\n+        + \"required int32 \" + INT32_FIELD_NAME + \"; \"\n+        + \"required float \" + FLOAT_FIELD_NAME + \"; \"\n+        + \"required double \" + DOUBLE_FIELD_NAME + \"; \"\n+        + \"} \");\n+\n+    GroupWriteSupport.setSchema(schema, conf);\n+    SimpleGroupFactory f = new SimpleGroupFactory(schema);\n+\n+\n+    for (Map.Entry<EncryptionConfiguration, FileEncryptionProperties> encryptionConfigurationEntry : encryptionPropertiesMap.entrySet()) {\n+      EncryptionConfiguration encryptionConfiguration = encryptionConfigurationEntry.getKey();\n+      Path file = new Path(root, encryptionConfiguration.toString() + \".parquet.encrypted\");\n+\n+      LOG.info(\"\\nWrite \" + file.toString());\n+      ParquetWriter<Group> writer = ExampleParquetWriter.builder(file)\n+        .withWriteMode(OVERWRITE)\n+        .withType(schema)\n+        .withEncryption(encryptionConfigurationEntry.getValue())\n+        .build();\n+\n+      for (int i = 0; i < 100; i++) {\n+        boolean expect = false;\n+        if ((i % 2) == 0)\n+          expect = true;\n+        float float_val = (float) i * 1.1f;\n+        double double_val = (i * 1.1111111);\n+\n+        writer.write(\n+          f.newGroup()\n+            .append(BOOLEAN_FIELD_NAME, expect)\n+            .append(INT32_FIELD_NAME, i)\n+            .append(FLOAT_FIELD_NAME, float_val)\n+            .append(DOUBLE_FIELD_NAME, double_val));\n+\n+      }\n+      writer.close();\n+    }\n+  }\n+\n+  private void testReadEncryptedParquetFiles(Path root, Map<DecryptionConfiguration, FileDecryptionProperties> decryptionPropertiesMap) throws IOException {\n+    Configuration conf = new Configuration();\n+\n+    for (Map.Entry<DecryptionConfiguration, FileDecryptionProperties> decryptionConfigurationEntry : decryptionPropertiesMap.entrySet()) {\n+      DecryptionConfiguration decryptionConfiguration = decryptionConfigurationEntry.getKey();\n+      LOG.info(\"==> Decryption configuration {}\", decryptionConfiguration);\n+      FileDecryptionProperties fileDecryptionProperties = decryptionConfigurationEntry.getValue();\n+\n+      File folder = new File(root.toString());\n+      File[] listOfFiles = folder.listFiles();\n+\n+      for (int fileNum = 0; fileNum < listOfFiles.length; fileNum++) {\n+        Path file = new Path(listOfFiles[fileNum].getAbsolutePath());\n+        if (!file.getName().endsWith(\"parquet.encrypted\")) { // Skip non encrypted files\n+          continue;\n+        }\n+        EncryptionConfiguration encryptionConfiguration = getEncryptionConfigurationFromFilename(file.getName());\n+        if (null == encryptionConfiguration) {\n+          continue;\n+        }\n+        LOG.info(\"--> Read file {} {}\", file.toString(), encryptionConfiguration);\n+\n+        // Read only the non-encrypted columns\n+        if ((decryptionConfiguration == DecryptionConfiguration.NO_DECRYPTION) &&\n+          (encryptionConfiguration == EncryptionConfiguration.ENCRYPT_COLUMNS_PLAINTEXT_FOOTER)) {\n+          conf.set(\"parquet.read.schema\", Types.buildMessage()\n+            .required(BOOLEAN).named(BOOLEAN_FIELD_NAME)\n+            .required(INT32).named(INT32_FIELD_NAME)\n+            .named(\"FormatTestObject\").toString());\n+        }\n+\n+        ParquetReader<Group> reader = ParquetReader.builder(new GroupReadSupport(), file)\n+          .withConf(conf)\n+          .withDecryption(fileDecryptionProperties)\n+          .build();\n+\n+        try {\n+          for (int i = 0; i < 500; i++) {", "originalCommit": "4ca6a2febde567c7b8753100c1b80fe2831f403f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTIzNzY2Mw==", "url": "https://github.com/apache/parquet-mr/pull/782#discussion_r435237663", "bodyText": "Thanks, Gabor, good catch!", "author": "andersonm-ibm", "createdAt": "2020-06-04T13:06:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzg5NDYwNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzg5NjgxNg==", "url": "https://github.com/apache/parquet-mr/pull/782#discussion_r433896816", "bodyText": "I would check the exception type (class) as well, not only the message. Message is usually a nice to have but the exception type is part of the API spec.", "author": "gszadovszky", "createdAt": "2020-06-02T13:58:58Z", "path": "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestEncryptionOptions.java", "diffHunk": "@@ -0,0 +1,660 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.parquet.hadoop;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.parquet.crypto.ColumnDecryptionProperties;\n+import org.apache.parquet.crypto.ColumnEncryptionProperties;\n+import org.apache.parquet.crypto.FileDecryptionProperties;\n+import org.apache.parquet.crypto.FileEncryptionProperties;\n+import org.apache.parquet.crypto.ParquetCipher;\n+import org.apache.parquet.crypto.DecryptionKeyRetriever;\n+import org.apache.parquet.example.data.Group;\n+import org.apache.parquet.example.data.simple.SimpleGroupFactory;\n+import org.apache.parquet.filter2.compat.FilterCompat;\n+import org.apache.parquet.hadoop.example.ExampleParquetWriter;\n+import org.apache.parquet.hadoop.example.GroupReadSupport;\n+import org.apache.parquet.hadoop.example.GroupWriteSupport;\n+import org.apache.parquet.hadoop.metadata.ColumnPath;\n+import org.apache.parquet.schema.MessageType;\n+import org.apache.parquet.schema.Types;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.ErrorCollector;\n+import org.junit.rules.TemporaryFolder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.parquet.hadoop.ParquetFileWriter.Mode.OVERWRITE;\n+import static org.apache.parquet.hadoop.metadata.CompressionCodecName.UNCOMPRESSED;\n+import static org.apache.parquet.schema.MessageTypeParser.parseMessageType;\n+import static org.apache.parquet.schema.PrimitiveType.PrimitiveTypeName.BOOLEAN;\n+import static org.apache.parquet.schema.PrimitiveType.PrimitiveTypeName.INT32;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+/*\n+ * This file contains samples for writing and reading encrypted Parquet files in different\n+ * encryption and decryption configurations. The samples have the following goals:\n+ * 1) Demonstrate usage of different options for data encryption and decryption.\n+ * 2) Produce encrypted files for interoperability tests with other (eg parquet-cpp)\n+ *    readers that support encryption.\n+ * 3) Produce encrypted files with plaintext footer, for testing the ability of legacy\n+ *    readers to parse the footer and read unencrypted columns.\n+ * 4) Perform interoperability tests with other (eg parquet-cpp) writers, by reading\n+ *    encrypted files produced by these writers.\n+ *\n+ * The write sample produces number of parquet files, each encrypted with a different\n+ * encryption configuration as described below.\n+ * The name of each file is in the form of:\n+ * tester<encryption config number>.parquet.encrypted.\n+ *\n+ * The read sample creates a set of decryption configurations and then uses each of them\n+ * to read all encrypted files in the input directory.\n+ *\n+ * The different encryption and decryption configurations are listed below.\n+ *\n+ *\n+ * A detailed description of the Parquet Modular Encryption specification can be found\n+ * here:\n+ * https://github.com/apache/parquet-format/blob/encryption/Encryption.md\n+ *\n+ * The write sample creates files with eight columns in the following\n+ * encryption configurations:\n+ *\n+ *  UNIFORM_ENCRYPTION:             Encrypt all columns and the footer with the same key.\n+ *                                  (uniform encryption)\n+ *  ENCRYPT_COLUMNS_AND_FOOTER:     Encrypt two columns and the footer, with different\n+ *                                  keys.\n+ *  ENCRYPT_COLUMNS_PLAINTEXT_FOOTER: Encrypt two columns, with different keys.\n+ *                                  Do not encrypt footer (to enable legacy readers)\n+ *                                  - plaintext footer mode.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_AAD: Encrypt two columns and the footer, with different\n+ *                                  keys. Supply aad_prefix for file identity\n+ *                                  verification.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE:   Encrypt two columns and the footer,\n+ *                                  with different keys. Supply aad_prefix, and call\n+ *                                  disable_aad_prefix_storage to prevent file\n+ *                                  identity storage in file metadata.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_CTR: Encrypt two columns and the footer, with different\n+ *                                  keys. Use the alternative (AES_GCM_CTR_V1) algorithm.\n+ *  NO_ENCRYPTION:                  Do not encrypt anything\n+ *\n+ *\n+ * The read sample uses each of the following decryption configurations to read every\n+ * encrypted files in the input directory:\n+ *\n+ *  DECRYPT_WITH_KEY_RETRIEVER:     Decrypt using key retriever that holds the keys of\n+ *                                  two encrypted columns and the footer key.\n+ *  DECRYPT_WITH_KEY_RETRIEVER_AAD: Decrypt using key retriever that holds the keys of\n+ *                                  two encrypted columns and the footer key. Supplies\n+ *                                  aad_prefix to verify file identity.\n+ *  DECRYPT_WITH_EXPLICIT_KEYS:     Decrypt using explicit column and footer keys\n+ *                                  (instead of key retrieval callback).\n+ *  NO_DECRYPTION:                  Do not decrypt anything.\n+ */\n+public class TestEncryptionOptions {\n+  private static final Logger LOG = LoggerFactory.getLogger(TestEncryptionOptions.class);\n+\n+  @Rule\n+  public TemporaryFolder temporaryFolder = new TemporaryFolder();\n+\n+  @Rule\n+  public ErrorCollector errorCollector = new ErrorCollector();\n+\n+  private static final byte[] FOOTER_ENCRYPTION_KEY = \"0123456789012345\".getBytes();\n+  private static final byte[] COLUMN_ENCRYPTION_KEY1 = \"1234567890123450\".getBytes();\n+  private static final byte[] COLUMN_ENCRYPTION_KEY2 = \"1234567890123451\".getBytes();\n+  private static final String FOOTER_ENCRYPTION_KEY_ID = \"kf\";\n+  private static final String COLUMN_ENCRYPTION_KEY1_ID = \"kc1\";\n+  private static final String COLUMN_ENCRYPTION_KEY2_ID = \"kc2\";\n+  private static final String AAD_PREFIX_STRING = \"tester\";\n+  private static final String BOOLEAN_FIELD_NAME = \"boolean_field\";\n+  private static final String INT32_FIELD_NAME = \"int32_field\";\n+  private static final String FLOAT_FIELD_NAME = \"float_field\";\n+  private static final String DOUBLE_FIELD_NAME = \"double_field\";\n+\n+  public enum EncryptionConfiguration {\n+    UNIFORM_ENCRYPTION(\"UNIFORM_ENCRYPTION\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER(\"ENCRYPT_COLUMNS_AND_FOOTER\"),\n+    ENCRYPT_COLUMNS_PLAINTEXT_FOOTER(\"ENCRYPT_COLUMNS_PLAINTEXT_FOOTER\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_AAD(\"ENCRYPT_COLUMNS_AND_FOOTER_AAD\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE(\"ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_CTR(\"ENCRYPT_COLUMNS_AND_FOOTER_CTR\"),\n+    NO_ENCRYPTION(\"NO_ENCRYPTION\");\n+\n+    private final String configurationName;\n+\n+    EncryptionConfiguration(String configurationName) {\n+      this.configurationName = configurationName;\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return configurationName;\n+    }\n+  }\n+\n+\n+  public enum DecryptionConfiguration {\n+    DECRYPT_WITH_KEY_RETRIEVER(\"DECRYPT_WITH_KEY_RETRIEVER\"),\n+    DECRYPT_WITH_KEY_RETRIEVER_AAD(\"DECRYPT_WITH_KEY_RETRIEVER_AAD\"),\n+    DECRYPT_WITH_EXPLICIT_KEYS(\"DECRYPT_WITH_EXPLICIT_KEYS\"),\n+    NO_DECRYPTION(\"NO_DECRYPTION\");\n+\n+    private final String configurationName;\n+\n+    DecryptionConfiguration(String configurationName) {\n+      this.configurationName = configurationName;\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return configurationName;\n+    }\n+  }\n+\n+  @Test\n+  public void testWriteReadEncryptedParquetFiles() throws IOException {\n+    Path rootPath = new Path(temporaryFolder.getRoot().getPath());\n+    LOG.info(\"======== testWriteReadEncryptedParquetFiles {} ========\", rootPath.toString());\n+    byte[] AADPrefix = AAD_PREFIX_STRING.getBytes(StandardCharsets.UTF_8);\n+    // This array will hold various encryption configuraions.\n+    Map<EncryptionConfiguration, FileEncryptionProperties> encryptionPropertiesMap =\n+      getEncryptionConfigurations(AADPrefix);\n+    testWriteEncryptedParquetFiles(rootPath, encryptionPropertiesMap);\n+    // This array will hold various decryption configurations.\n+    Map<DecryptionConfiguration, FileDecryptionProperties> decryptionPropertiesMap =\n+      getDecryptionConfigurations(AADPrefix);\n+    testReadEncryptedParquetFiles(rootPath, decryptionPropertiesMap);\n+  }\n+\n+  @Test\n+  public void testInteropReadEncryptedParquetFiles() throws IOException {\n+    Path rootPath = new Path(\"submodules/parquet-testing/data\");\n+    LOG.info(\"======== testInteropReadEncryptedParquetFiles {} ========\", rootPath.toString());\n+    byte[] AADPrefix = AAD_PREFIX_STRING.getBytes(StandardCharsets.UTF_8);\n+    // This array will hold various decryption configurations.\n+    Map<DecryptionConfiguration, FileDecryptionProperties> decryptionPropertiesMap =\n+      getDecryptionConfigurations(AADPrefix);\n+    testReadEncryptedParquetFiles(rootPath, decryptionPropertiesMap);\n+  }\n+\n+  private void testWriteEncryptedParquetFiles(Path root, Map<EncryptionConfiguration, FileEncryptionProperties> encryptionPropertiesMap) throws IOException {\n+    Configuration conf = new Configuration();\n+    int numberOfEncryptionModes = encryptionPropertiesMap.size();\n+\n+    MessageType schema = parseMessageType(\n+      \"message test { \"\n+        + \"required boolean \" + BOOLEAN_FIELD_NAME + \"; \"\n+        + \"required int32 \" + INT32_FIELD_NAME + \"; \"\n+        + \"required float \" + FLOAT_FIELD_NAME + \"; \"\n+        + \"required double \" + DOUBLE_FIELD_NAME + \"; \"\n+        + \"} \");\n+\n+    GroupWriteSupport.setSchema(schema, conf);\n+    SimpleGroupFactory f = new SimpleGroupFactory(schema);\n+\n+\n+    for (Map.Entry<EncryptionConfiguration, FileEncryptionProperties> encryptionConfigurationEntry : encryptionPropertiesMap.entrySet()) {\n+      EncryptionConfiguration encryptionConfiguration = encryptionConfigurationEntry.getKey();\n+      Path file = new Path(root, encryptionConfiguration.toString() + \".parquet.encrypted\");\n+\n+      LOG.info(\"\\nWrite \" + file.toString());\n+      ParquetWriter<Group> writer = ExampleParquetWriter.builder(file)\n+        .withWriteMode(OVERWRITE)\n+        .withType(schema)\n+        .withEncryption(encryptionConfigurationEntry.getValue())\n+        .build();\n+\n+      for (int i = 0; i < 100; i++) {\n+        boolean expect = false;\n+        if ((i % 2) == 0)\n+          expect = true;\n+        float float_val = (float) i * 1.1f;\n+        double double_val = (i * 1.1111111);\n+\n+        writer.write(\n+          f.newGroup()\n+            .append(BOOLEAN_FIELD_NAME, expect)\n+            .append(INT32_FIELD_NAME, i)\n+            .append(FLOAT_FIELD_NAME, float_val)\n+            .append(DOUBLE_FIELD_NAME, double_val));\n+\n+      }\n+      writer.close();\n+    }\n+  }\n+\n+  private void testReadEncryptedParquetFiles(Path root, Map<DecryptionConfiguration, FileDecryptionProperties> decryptionPropertiesMap) throws IOException {\n+    Configuration conf = new Configuration();\n+\n+    for (Map.Entry<DecryptionConfiguration, FileDecryptionProperties> decryptionConfigurationEntry : decryptionPropertiesMap.entrySet()) {\n+      DecryptionConfiguration decryptionConfiguration = decryptionConfigurationEntry.getKey();\n+      LOG.info(\"==> Decryption configuration {}\", decryptionConfiguration);\n+      FileDecryptionProperties fileDecryptionProperties = decryptionConfigurationEntry.getValue();\n+\n+      File folder = new File(root.toString());\n+      File[] listOfFiles = folder.listFiles();\n+\n+      for (int fileNum = 0; fileNum < listOfFiles.length; fileNum++) {\n+        Path file = new Path(listOfFiles[fileNum].getAbsolutePath());\n+        if (!file.getName().endsWith(\"parquet.encrypted\")) { // Skip non encrypted files\n+          continue;\n+        }\n+        EncryptionConfiguration encryptionConfiguration = getEncryptionConfigurationFromFilename(file.getName());\n+        if (null == encryptionConfiguration) {\n+          continue;\n+        }\n+        LOG.info(\"--> Read file {} {}\", file.toString(), encryptionConfiguration);\n+\n+        // Read only the non-encrypted columns\n+        if ((decryptionConfiguration == DecryptionConfiguration.NO_DECRYPTION) &&\n+          (encryptionConfiguration == EncryptionConfiguration.ENCRYPT_COLUMNS_PLAINTEXT_FOOTER)) {\n+          conf.set(\"parquet.read.schema\", Types.buildMessage()\n+            .required(BOOLEAN).named(BOOLEAN_FIELD_NAME)\n+            .required(INT32).named(INT32_FIELD_NAME)\n+            .named(\"FormatTestObject\").toString());\n+        }\n+\n+        ParquetReader<Group> reader = ParquetReader.builder(new GroupReadSupport(), file)\n+          .withConf(conf)\n+          .withDecryption(fileDecryptionProperties)\n+          .build();\n+\n+        try {\n+          for (int i = 0; i < 500; i++) {\n+            Group group = null;\n+            group = reader.read();\n+            boolean expect = false;\n+            if ((i % 2) == 0)\n+              expect = true;\n+            boolean bool_res = group.getBoolean(BOOLEAN_FIELD_NAME, 0);\n+            if (bool_res != expect)\n+              addErrorToErrorCollectorAndLog(\"Wrong bool\", encryptionConfiguration, decryptionConfiguration);\n+            int int_res = group.getInteger(INT32_FIELD_NAME, 0);\n+            if (int_res != i)\n+              addErrorToErrorCollectorAndLog(\"Wrong int\", encryptionConfiguration, decryptionConfiguration);\n+            if (decryptionConfiguration != DecryptionConfiguration.NO_DECRYPTION) {\n+              float float_res = group.getFloat(FLOAT_FIELD_NAME, 0);\n+              float tmp1 = (float) i * 1.1f;\n+              if (float_res != tmp1)\n+                addErrorToErrorCollectorAndLog(\"Wrong float\", encryptionConfiguration, decryptionConfiguration);\n+\n+              double double_res = group.getDouble(DOUBLE_FIELD_NAME, 0);\n+              double tmp = (i * 1.1111111);\n+              if (double_res != tmp)\n+                addErrorToErrorCollectorAndLog(\"Wrong double\", encryptionConfiguration, decryptionConfiguration);\n+            }\n+          }\n+        } catch (Exception e) {\n+          String errorMessage = e.getMessage();\n+          checkResult(file.getName(), decryptionConfiguration, (null == errorMessage ? \"\" : errorMessage));", "originalCommit": "4ca6a2febde567c7b8753100c1b80fe2831f403f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzg5OTI2Ng==", "url": "https://github.com/apache/parquet-mr/pull/782#discussion_r433899266", "bodyText": "You may shorten this method an maybe create more readable code if you convert the switch-case to a method implementation inside the EncryptionConfiguration enum.", "author": "gszadovszky", "createdAt": "2020-06-02T14:01:37Z", "path": "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestEncryptionOptions.java", "diffHunk": "@@ -0,0 +1,660 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.parquet.hadoop;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.parquet.crypto.ColumnDecryptionProperties;\n+import org.apache.parquet.crypto.ColumnEncryptionProperties;\n+import org.apache.parquet.crypto.FileDecryptionProperties;\n+import org.apache.parquet.crypto.FileEncryptionProperties;\n+import org.apache.parquet.crypto.ParquetCipher;\n+import org.apache.parquet.crypto.DecryptionKeyRetriever;\n+import org.apache.parquet.example.data.Group;\n+import org.apache.parquet.example.data.simple.SimpleGroupFactory;\n+import org.apache.parquet.filter2.compat.FilterCompat;\n+import org.apache.parquet.hadoop.example.ExampleParquetWriter;\n+import org.apache.parquet.hadoop.example.GroupReadSupport;\n+import org.apache.parquet.hadoop.example.GroupWriteSupport;\n+import org.apache.parquet.hadoop.metadata.ColumnPath;\n+import org.apache.parquet.schema.MessageType;\n+import org.apache.parquet.schema.Types;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.ErrorCollector;\n+import org.junit.rules.TemporaryFolder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.parquet.hadoop.ParquetFileWriter.Mode.OVERWRITE;\n+import static org.apache.parquet.hadoop.metadata.CompressionCodecName.UNCOMPRESSED;\n+import static org.apache.parquet.schema.MessageTypeParser.parseMessageType;\n+import static org.apache.parquet.schema.PrimitiveType.PrimitiveTypeName.BOOLEAN;\n+import static org.apache.parquet.schema.PrimitiveType.PrimitiveTypeName.INT32;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+/*\n+ * This file contains samples for writing and reading encrypted Parquet files in different\n+ * encryption and decryption configurations. The samples have the following goals:\n+ * 1) Demonstrate usage of different options for data encryption and decryption.\n+ * 2) Produce encrypted files for interoperability tests with other (eg parquet-cpp)\n+ *    readers that support encryption.\n+ * 3) Produce encrypted files with plaintext footer, for testing the ability of legacy\n+ *    readers to parse the footer and read unencrypted columns.\n+ * 4) Perform interoperability tests with other (eg parquet-cpp) writers, by reading\n+ *    encrypted files produced by these writers.\n+ *\n+ * The write sample produces number of parquet files, each encrypted with a different\n+ * encryption configuration as described below.\n+ * The name of each file is in the form of:\n+ * tester<encryption config number>.parquet.encrypted.\n+ *\n+ * The read sample creates a set of decryption configurations and then uses each of them\n+ * to read all encrypted files in the input directory.\n+ *\n+ * The different encryption and decryption configurations are listed below.\n+ *\n+ *\n+ * A detailed description of the Parquet Modular Encryption specification can be found\n+ * here:\n+ * https://github.com/apache/parquet-format/blob/encryption/Encryption.md\n+ *\n+ * The write sample creates files with eight columns in the following\n+ * encryption configurations:\n+ *\n+ *  UNIFORM_ENCRYPTION:             Encrypt all columns and the footer with the same key.\n+ *                                  (uniform encryption)\n+ *  ENCRYPT_COLUMNS_AND_FOOTER:     Encrypt two columns and the footer, with different\n+ *                                  keys.\n+ *  ENCRYPT_COLUMNS_PLAINTEXT_FOOTER: Encrypt two columns, with different keys.\n+ *                                  Do not encrypt footer (to enable legacy readers)\n+ *                                  - plaintext footer mode.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_AAD: Encrypt two columns and the footer, with different\n+ *                                  keys. Supply aad_prefix for file identity\n+ *                                  verification.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE:   Encrypt two columns and the footer,\n+ *                                  with different keys. Supply aad_prefix, and call\n+ *                                  disable_aad_prefix_storage to prevent file\n+ *                                  identity storage in file metadata.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_CTR: Encrypt two columns and the footer, with different\n+ *                                  keys. Use the alternative (AES_GCM_CTR_V1) algorithm.\n+ *  NO_ENCRYPTION:                  Do not encrypt anything\n+ *\n+ *\n+ * The read sample uses each of the following decryption configurations to read every\n+ * encrypted files in the input directory:\n+ *\n+ *  DECRYPT_WITH_KEY_RETRIEVER:     Decrypt using key retriever that holds the keys of\n+ *                                  two encrypted columns and the footer key.\n+ *  DECRYPT_WITH_KEY_RETRIEVER_AAD: Decrypt using key retriever that holds the keys of\n+ *                                  two encrypted columns and the footer key. Supplies\n+ *                                  aad_prefix to verify file identity.\n+ *  DECRYPT_WITH_EXPLICIT_KEYS:     Decrypt using explicit column and footer keys\n+ *                                  (instead of key retrieval callback).\n+ *  NO_DECRYPTION:                  Do not decrypt anything.\n+ */\n+public class TestEncryptionOptions {\n+  private static final Logger LOG = LoggerFactory.getLogger(TestEncryptionOptions.class);\n+\n+  @Rule\n+  public TemporaryFolder temporaryFolder = new TemporaryFolder();\n+\n+  @Rule\n+  public ErrorCollector errorCollector = new ErrorCollector();\n+\n+  private static final byte[] FOOTER_ENCRYPTION_KEY = \"0123456789012345\".getBytes();\n+  private static final byte[] COLUMN_ENCRYPTION_KEY1 = \"1234567890123450\".getBytes();\n+  private static final byte[] COLUMN_ENCRYPTION_KEY2 = \"1234567890123451\".getBytes();\n+  private static final String FOOTER_ENCRYPTION_KEY_ID = \"kf\";\n+  private static final String COLUMN_ENCRYPTION_KEY1_ID = \"kc1\";\n+  private static final String COLUMN_ENCRYPTION_KEY2_ID = \"kc2\";\n+  private static final String AAD_PREFIX_STRING = \"tester\";\n+  private static final String BOOLEAN_FIELD_NAME = \"boolean_field\";\n+  private static final String INT32_FIELD_NAME = \"int32_field\";\n+  private static final String FLOAT_FIELD_NAME = \"float_field\";\n+  private static final String DOUBLE_FIELD_NAME = \"double_field\";\n+\n+  public enum EncryptionConfiguration {\n+    UNIFORM_ENCRYPTION(\"UNIFORM_ENCRYPTION\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER(\"ENCRYPT_COLUMNS_AND_FOOTER\"),\n+    ENCRYPT_COLUMNS_PLAINTEXT_FOOTER(\"ENCRYPT_COLUMNS_PLAINTEXT_FOOTER\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_AAD(\"ENCRYPT_COLUMNS_AND_FOOTER_AAD\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE(\"ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_CTR(\"ENCRYPT_COLUMNS_AND_FOOTER_CTR\"),\n+    NO_ENCRYPTION(\"NO_ENCRYPTION\");\n+\n+    private final String configurationName;\n+\n+    EncryptionConfiguration(String configurationName) {\n+      this.configurationName = configurationName;\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return configurationName;\n+    }\n+  }\n+\n+\n+  public enum DecryptionConfiguration {\n+    DECRYPT_WITH_KEY_RETRIEVER(\"DECRYPT_WITH_KEY_RETRIEVER\"),\n+    DECRYPT_WITH_KEY_RETRIEVER_AAD(\"DECRYPT_WITH_KEY_RETRIEVER_AAD\"),\n+    DECRYPT_WITH_EXPLICIT_KEYS(\"DECRYPT_WITH_EXPLICIT_KEYS\"),\n+    NO_DECRYPTION(\"NO_DECRYPTION\");\n+\n+    private final String configurationName;\n+\n+    DecryptionConfiguration(String configurationName) {\n+      this.configurationName = configurationName;\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return configurationName;\n+    }\n+  }\n+\n+  @Test\n+  public void testWriteReadEncryptedParquetFiles() throws IOException {\n+    Path rootPath = new Path(temporaryFolder.getRoot().getPath());\n+    LOG.info(\"======== testWriteReadEncryptedParquetFiles {} ========\", rootPath.toString());\n+    byte[] AADPrefix = AAD_PREFIX_STRING.getBytes(StandardCharsets.UTF_8);\n+    // This array will hold various encryption configuraions.\n+    Map<EncryptionConfiguration, FileEncryptionProperties> encryptionPropertiesMap =\n+      getEncryptionConfigurations(AADPrefix);\n+    testWriteEncryptedParquetFiles(rootPath, encryptionPropertiesMap);\n+    // This array will hold various decryption configurations.\n+    Map<DecryptionConfiguration, FileDecryptionProperties> decryptionPropertiesMap =\n+      getDecryptionConfigurations(AADPrefix);\n+    testReadEncryptedParquetFiles(rootPath, decryptionPropertiesMap);\n+  }\n+\n+  @Test\n+  public void testInteropReadEncryptedParquetFiles() throws IOException {\n+    Path rootPath = new Path(\"submodules/parquet-testing/data\");\n+    LOG.info(\"======== testInteropReadEncryptedParquetFiles {} ========\", rootPath.toString());\n+    byte[] AADPrefix = AAD_PREFIX_STRING.getBytes(StandardCharsets.UTF_8);\n+    // This array will hold various decryption configurations.\n+    Map<DecryptionConfiguration, FileDecryptionProperties> decryptionPropertiesMap =\n+      getDecryptionConfigurations(AADPrefix);\n+    testReadEncryptedParquetFiles(rootPath, decryptionPropertiesMap);\n+  }\n+\n+  private void testWriteEncryptedParquetFiles(Path root, Map<EncryptionConfiguration, FileEncryptionProperties> encryptionPropertiesMap) throws IOException {\n+    Configuration conf = new Configuration();\n+    int numberOfEncryptionModes = encryptionPropertiesMap.size();\n+\n+    MessageType schema = parseMessageType(\n+      \"message test { \"\n+        + \"required boolean \" + BOOLEAN_FIELD_NAME + \"; \"\n+        + \"required int32 \" + INT32_FIELD_NAME + \"; \"\n+        + \"required float \" + FLOAT_FIELD_NAME + \"; \"\n+        + \"required double \" + DOUBLE_FIELD_NAME + \"; \"\n+        + \"} \");\n+\n+    GroupWriteSupport.setSchema(schema, conf);\n+    SimpleGroupFactory f = new SimpleGroupFactory(schema);\n+\n+\n+    for (Map.Entry<EncryptionConfiguration, FileEncryptionProperties> encryptionConfigurationEntry : encryptionPropertiesMap.entrySet()) {\n+      EncryptionConfiguration encryptionConfiguration = encryptionConfigurationEntry.getKey();\n+      Path file = new Path(root, encryptionConfiguration.toString() + \".parquet.encrypted\");\n+\n+      LOG.info(\"\\nWrite \" + file.toString());\n+      ParquetWriter<Group> writer = ExampleParquetWriter.builder(file)\n+        .withWriteMode(OVERWRITE)\n+        .withType(schema)\n+        .withEncryption(encryptionConfigurationEntry.getValue())\n+        .build();\n+\n+      for (int i = 0; i < 100; i++) {\n+        boolean expect = false;\n+        if ((i % 2) == 0)\n+          expect = true;\n+        float float_val = (float) i * 1.1f;\n+        double double_val = (i * 1.1111111);\n+\n+        writer.write(\n+          f.newGroup()\n+            .append(BOOLEAN_FIELD_NAME, expect)\n+            .append(INT32_FIELD_NAME, i)\n+            .append(FLOAT_FIELD_NAME, float_val)\n+            .append(DOUBLE_FIELD_NAME, double_val));\n+\n+      }\n+      writer.close();\n+    }\n+  }\n+\n+  private void testReadEncryptedParquetFiles(Path root, Map<DecryptionConfiguration, FileDecryptionProperties> decryptionPropertiesMap) throws IOException {\n+    Configuration conf = new Configuration();\n+\n+    for (Map.Entry<DecryptionConfiguration, FileDecryptionProperties> decryptionConfigurationEntry : decryptionPropertiesMap.entrySet()) {\n+      DecryptionConfiguration decryptionConfiguration = decryptionConfigurationEntry.getKey();\n+      LOG.info(\"==> Decryption configuration {}\", decryptionConfiguration);\n+      FileDecryptionProperties fileDecryptionProperties = decryptionConfigurationEntry.getValue();\n+\n+      File folder = new File(root.toString());\n+      File[] listOfFiles = folder.listFiles();\n+\n+      for (int fileNum = 0; fileNum < listOfFiles.length; fileNum++) {\n+        Path file = new Path(listOfFiles[fileNum].getAbsolutePath());\n+        if (!file.getName().endsWith(\"parquet.encrypted\")) { // Skip non encrypted files\n+          continue;\n+        }\n+        EncryptionConfiguration encryptionConfiguration = getEncryptionConfigurationFromFilename(file.getName());\n+        if (null == encryptionConfiguration) {\n+          continue;\n+        }\n+        LOG.info(\"--> Read file {} {}\", file.toString(), encryptionConfiguration);\n+\n+        // Read only the non-encrypted columns\n+        if ((decryptionConfiguration == DecryptionConfiguration.NO_DECRYPTION) &&\n+          (encryptionConfiguration == EncryptionConfiguration.ENCRYPT_COLUMNS_PLAINTEXT_FOOTER)) {\n+          conf.set(\"parquet.read.schema\", Types.buildMessage()\n+            .required(BOOLEAN).named(BOOLEAN_FIELD_NAME)\n+            .required(INT32).named(INT32_FIELD_NAME)\n+            .named(\"FormatTestObject\").toString());\n+        }\n+\n+        ParquetReader<Group> reader = ParquetReader.builder(new GroupReadSupport(), file)\n+          .withConf(conf)\n+          .withDecryption(fileDecryptionProperties)\n+          .build();\n+\n+        try {\n+          for (int i = 0; i < 500; i++) {\n+            Group group = null;\n+            group = reader.read();\n+            boolean expect = false;\n+            if ((i % 2) == 0)\n+              expect = true;\n+            boolean bool_res = group.getBoolean(BOOLEAN_FIELD_NAME, 0);\n+            if (bool_res != expect)\n+              addErrorToErrorCollectorAndLog(\"Wrong bool\", encryptionConfiguration, decryptionConfiguration);\n+            int int_res = group.getInteger(INT32_FIELD_NAME, 0);\n+            if (int_res != i)\n+              addErrorToErrorCollectorAndLog(\"Wrong int\", encryptionConfiguration, decryptionConfiguration);\n+            if (decryptionConfiguration != DecryptionConfiguration.NO_DECRYPTION) {\n+              float float_res = group.getFloat(FLOAT_FIELD_NAME, 0);\n+              float tmp1 = (float) i * 1.1f;\n+              if (float_res != tmp1)\n+                addErrorToErrorCollectorAndLog(\"Wrong float\", encryptionConfiguration, decryptionConfiguration);\n+\n+              double double_res = group.getDouble(DOUBLE_FIELD_NAME, 0);\n+              double tmp = (i * 1.1111111);\n+              if (double_res != tmp)\n+                addErrorToErrorCollectorAndLog(\"Wrong double\", encryptionConfiguration, decryptionConfiguration);\n+            }\n+          }\n+        } catch (Exception e) {\n+          String errorMessage = e.getMessage();\n+          checkResult(file.getName(), decryptionConfiguration, (null == errorMessage ? \"\" : errorMessage));\n+        }\n+        conf.unset(\"parquet.read.schema\");\n+      }\n+    }\n+  }\n+\n+\n+  /**\n+   * Create a number of Encryption configurations\n+   * @param AADPrefix\n+   * @return\n+   */\n+  private Map<EncryptionConfiguration, FileEncryptionProperties> getEncryptionConfigurations(byte[] AADPrefix) {", "originalCommit": "4ca6a2febde567c7b8753100c1b80fe2831f403f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzkwMDExMw==", "url": "https://github.com/apache/parquet-mr/pull/782#discussion_r433900113", "bodyText": "Similarly to the previous comment, you may add these to the DecryptionConfiguration enum.", "author": "gszadovszky", "createdAt": "2020-06-02T14:02:30Z", "path": "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestEncryptionOptions.java", "diffHunk": "@@ -0,0 +1,660 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.parquet.hadoop;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.parquet.crypto.ColumnDecryptionProperties;\n+import org.apache.parquet.crypto.ColumnEncryptionProperties;\n+import org.apache.parquet.crypto.FileDecryptionProperties;\n+import org.apache.parquet.crypto.FileEncryptionProperties;\n+import org.apache.parquet.crypto.ParquetCipher;\n+import org.apache.parquet.crypto.DecryptionKeyRetriever;\n+import org.apache.parquet.example.data.Group;\n+import org.apache.parquet.example.data.simple.SimpleGroupFactory;\n+import org.apache.parquet.filter2.compat.FilterCompat;\n+import org.apache.parquet.hadoop.example.ExampleParquetWriter;\n+import org.apache.parquet.hadoop.example.GroupReadSupport;\n+import org.apache.parquet.hadoop.example.GroupWriteSupport;\n+import org.apache.parquet.hadoop.metadata.ColumnPath;\n+import org.apache.parquet.schema.MessageType;\n+import org.apache.parquet.schema.Types;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.ErrorCollector;\n+import org.junit.rules.TemporaryFolder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.parquet.hadoop.ParquetFileWriter.Mode.OVERWRITE;\n+import static org.apache.parquet.hadoop.metadata.CompressionCodecName.UNCOMPRESSED;\n+import static org.apache.parquet.schema.MessageTypeParser.parseMessageType;\n+import static org.apache.parquet.schema.PrimitiveType.PrimitiveTypeName.BOOLEAN;\n+import static org.apache.parquet.schema.PrimitiveType.PrimitiveTypeName.INT32;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+/*\n+ * This file contains samples for writing and reading encrypted Parquet files in different\n+ * encryption and decryption configurations. The samples have the following goals:\n+ * 1) Demonstrate usage of different options for data encryption and decryption.\n+ * 2) Produce encrypted files for interoperability tests with other (eg parquet-cpp)\n+ *    readers that support encryption.\n+ * 3) Produce encrypted files with plaintext footer, for testing the ability of legacy\n+ *    readers to parse the footer and read unencrypted columns.\n+ * 4) Perform interoperability tests with other (eg parquet-cpp) writers, by reading\n+ *    encrypted files produced by these writers.\n+ *\n+ * The write sample produces number of parquet files, each encrypted with a different\n+ * encryption configuration as described below.\n+ * The name of each file is in the form of:\n+ * tester<encryption config number>.parquet.encrypted.\n+ *\n+ * The read sample creates a set of decryption configurations and then uses each of them\n+ * to read all encrypted files in the input directory.\n+ *\n+ * The different encryption and decryption configurations are listed below.\n+ *\n+ *\n+ * A detailed description of the Parquet Modular Encryption specification can be found\n+ * here:\n+ * https://github.com/apache/parquet-format/blob/encryption/Encryption.md\n+ *\n+ * The write sample creates files with eight columns in the following\n+ * encryption configurations:\n+ *\n+ *  UNIFORM_ENCRYPTION:             Encrypt all columns and the footer with the same key.\n+ *                                  (uniform encryption)\n+ *  ENCRYPT_COLUMNS_AND_FOOTER:     Encrypt two columns and the footer, with different\n+ *                                  keys.\n+ *  ENCRYPT_COLUMNS_PLAINTEXT_FOOTER: Encrypt two columns, with different keys.\n+ *                                  Do not encrypt footer (to enable legacy readers)\n+ *                                  - plaintext footer mode.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_AAD: Encrypt two columns and the footer, with different\n+ *                                  keys. Supply aad_prefix for file identity\n+ *                                  verification.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE:   Encrypt two columns and the footer,\n+ *                                  with different keys. Supply aad_prefix, and call\n+ *                                  disable_aad_prefix_storage to prevent file\n+ *                                  identity storage in file metadata.\n+ *  ENCRYPT_COLUMNS_AND_FOOTER_CTR: Encrypt two columns and the footer, with different\n+ *                                  keys. Use the alternative (AES_GCM_CTR_V1) algorithm.\n+ *  NO_ENCRYPTION:                  Do not encrypt anything\n+ *\n+ *\n+ * The read sample uses each of the following decryption configurations to read every\n+ * encrypted files in the input directory:\n+ *\n+ *  DECRYPT_WITH_KEY_RETRIEVER:     Decrypt using key retriever that holds the keys of\n+ *                                  two encrypted columns and the footer key.\n+ *  DECRYPT_WITH_KEY_RETRIEVER_AAD: Decrypt using key retriever that holds the keys of\n+ *                                  two encrypted columns and the footer key. Supplies\n+ *                                  aad_prefix to verify file identity.\n+ *  DECRYPT_WITH_EXPLICIT_KEYS:     Decrypt using explicit column and footer keys\n+ *                                  (instead of key retrieval callback).\n+ *  NO_DECRYPTION:                  Do not decrypt anything.\n+ */\n+public class TestEncryptionOptions {\n+  private static final Logger LOG = LoggerFactory.getLogger(TestEncryptionOptions.class);\n+\n+  @Rule\n+  public TemporaryFolder temporaryFolder = new TemporaryFolder();\n+\n+  @Rule\n+  public ErrorCollector errorCollector = new ErrorCollector();\n+\n+  private static final byte[] FOOTER_ENCRYPTION_KEY = \"0123456789012345\".getBytes();\n+  private static final byte[] COLUMN_ENCRYPTION_KEY1 = \"1234567890123450\".getBytes();\n+  private static final byte[] COLUMN_ENCRYPTION_KEY2 = \"1234567890123451\".getBytes();\n+  private static final String FOOTER_ENCRYPTION_KEY_ID = \"kf\";\n+  private static final String COLUMN_ENCRYPTION_KEY1_ID = \"kc1\";\n+  private static final String COLUMN_ENCRYPTION_KEY2_ID = \"kc2\";\n+  private static final String AAD_PREFIX_STRING = \"tester\";\n+  private static final String BOOLEAN_FIELD_NAME = \"boolean_field\";\n+  private static final String INT32_FIELD_NAME = \"int32_field\";\n+  private static final String FLOAT_FIELD_NAME = \"float_field\";\n+  private static final String DOUBLE_FIELD_NAME = \"double_field\";\n+\n+  public enum EncryptionConfiguration {\n+    UNIFORM_ENCRYPTION(\"UNIFORM_ENCRYPTION\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER(\"ENCRYPT_COLUMNS_AND_FOOTER\"),\n+    ENCRYPT_COLUMNS_PLAINTEXT_FOOTER(\"ENCRYPT_COLUMNS_PLAINTEXT_FOOTER\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_AAD(\"ENCRYPT_COLUMNS_AND_FOOTER_AAD\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE(\"ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE\"),\n+    ENCRYPT_COLUMNS_AND_FOOTER_CTR(\"ENCRYPT_COLUMNS_AND_FOOTER_CTR\"),\n+    NO_ENCRYPTION(\"NO_ENCRYPTION\");\n+\n+    private final String configurationName;\n+\n+    EncryptionConfiguration(String configurationName) {\n+      this.configurationName = configurationName;\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return configurationName;\n+    }\n+  }\n+\n+\n+  public enum DecryptionConfiguration {\n+    DECRYPT_WITH_KEY_RETRIEVER(\"DECRYPT_WITH_KEY_RETRIEVER\"),\n+    DECRYPT_WITH_KEY_RETRIEVER_AAD(\"DECRYPT_WITH_KEY_RETRIEVER_AAD\"),\n+    DECRYPT_WITH_EXPLICIT_KEYS(\"DECRYPT_WITH_EXPLICIT_KEYS\"),\n+    NO_DECRYPTION(\"NO_DECRYPTION\");\n+\n+    private final String configurationName;\n+\n+    DecryptionConfiguration(String configurationName) {\n+      this.configurationName = configurationName;\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return configurationName;\n+    }\n+  }\n+\n+  @Test\n+  public void testWriteReadEncryptedParquetFiles() throws IOException {\n+    Path rootPath = new Path(temporaryFolder.getRoot().getPath());\n+    LOG.info(\"======== testWriteReadEncryptedParquetFiles {} ========\", rootPath.toString());\n+    byte[] AADPrefix = AAD_PREFIX_STRING.getBytes(StandardCharsets.UTF_8);\n+    // This array will hold various encryption configuraions.\n+    Map<EncryptionConfiguration, FileEncryptionProperties> encryptionPropertiesMap =\n+      getEncryptionConfigurations(AADPrefix);\n+    testWriteEncryptedParquetFiles(rootPath, encryptionPropertiesMap);\n+    // This array will hold various decryption configurations.\n+    Map<DecryptionConfiguration, FileDecryptionProperties> decryptionPropertiesMap =\n+      getDecryptionConfigurations(AADPrefix);\n+    testReadEncryptedParquetFiles(rootPath, decryptionPropertiesMap);\n+  }\n+\n+  @Test\n+  public void testInteropReadEncryptedParquetFiles() throws IOException {\n+    Path rootPath = new Path(\"submodules/parquet-testing/data\");\n+    LOG.info(\"======== testInteropReadEncryptedParquetFiles {} ========\", rootPath.toString());\n+    byte[] AADPrefix = AAD_PREFIX_STRING.getBytes(StandardCharsets.UTF_8);\n+    // This array will hold various decryption configurations.\n+    Map<DecryptionConfiguration, FileDecryptionProperties> decryptionPropertiesMap =\n+      getDecryptionConfigurations(AADPrefix);\n+    testReadEncryptedParquetFiles(rootPath, decryptionPropertiesMap);\n+  }\n+\n+  private void testWriteEncryptedParquetFiles(Path root, Map<EncryptionConfiguration, FileEncryptionProperties> encryptionPropertiesMap) throws IOException {\n+    Configuration conf = new Configuration();\n+    int numberOfEncryptionModes = encryptionPropertiesMap.size();\n+\n+    MessageType schema = parseMessageType(\n+      \"message test { \"\n+        + \"required boolean \" + BOOLEAN_FIELD_NAME + \"; \"\n+        + \"required int32 \" + INT32_FIELD_NAME + \"; \"\n+        + \"required float \" + FLOAT_FIELD_NAME + \"; \"\n+        + \"required double \" + DOUBLE_FIELD_NAME + \"; \"\n+        + \"} \");\n+\n+    GroupWriteSupport.setSchema(schema, conf);\n+    SimpleGroupFactory f = new SimpleGroupFactory(schema);\n+\n+\n+    for (Map.Entry<EncryptionConfiguration, FileEncryptionProperties> encryptionConfigurationEntry : encryptionPropertiesMap.entrySet()) {\n+      EncryptionConfiguration encryptionConfiguration = encryptionConfigurationEntry.getKey();\n+      Path file = new Path(root, encryptionConfiguration.toString() + \".parquet.encrypted\");\n+\n+      LOG.info(\"\\nWrite \" + file.toString());\n+      ParquetWriter<Group> writer = ExampleParquetWriter.builder(file)\n+        .withWriteMode(OVERWRITE)\n+        .withType(schema)\n+        .withEncryption(encryptionConfigurationEntry.getValue())\n+        .build();\n+\n+      for (int i = 0; i < 100; i++) {\n+        boolean expect = false;\n+        if ((i % 2) == 0)\n+          expect = true;\n+        float float_val = (float) i * 1.1f;\n+        double double_val = (i * 1.1111111);\n+\n+        writer.write(\n+          f.newGroup()\n+            .append(BOOLEAN_FIELD_NAME, expect)\n+            .append(INT32_FIELD_NAME, i)\n+            .append(FLOAT_FIELD_NAME, float_val)\n+            .append(DOUBLE_FIELD_NAME, double_val));\n+\n+      }\n+      writer.close();\n+    }\n+  }\n+\n+  private void testReadEncryptedParquetFiles(Path root, Map<DecryptionConfiguration, FileDecryptionProperties> decryptionPropertiesMap) throws IOException {\n+    Configuration conf = new Configuration();\n+\n+    for (Map.Entry<DecryptionConfiguration, FileDecryptionProperties> decryptionConfigurationEntry : decryptionPropertiesMap.entrySet()) {\n+      DecryptionConfiguration decryptionConfiguration = decryptionConfigurationEntry.getKey();\n+      LOG.info(\"==> Decryption configuration {}\", decryptionConfiguration);\n+      FileDecryptionProperties fileDecryptionProperties = decryptionConfigurationEntry.getValue();\n+\n+      File folder = new File(root.toString());\n+      File[] listOfFiles = folder.listFiles();\n+\n+      for (int fileNum = 0; fileNum < listOfFiles.length; fileNum++) {\n+        Path file = new Path(listOfFiles[fileNum].getAbsolutePath());\n+        if (!file.getName().endsWith(\"parquet.encrypted\")) { // Skip non encrypted files\n+          continue;\n+        }\n+        EncryptionConfiguration encryptionConfiguration = getEncryptionConfigurationFromFilename(file.getName());\n+        if (null == encryptionConfiguration) {\n+          continue;\n+        }\n+        LOG.info(\"--> Read file {} {}\", file.toString(), encryptionConfiguration);\n+\n+        // Read only the non-encrypted columns\n+        if ((decryptionConfiguration == DecryptionConfiguration.NO_DECRYPTION) &&\n+          (encryptionConfiguration == EncryptionConfiguration.ENCRYPT_COLUMNS_PLAINTEXT_FOOTER)) {\n+          conf.set(\"parquet.read.schema\", Types.buildMessage()\n+            .required(BOOLEAN).named(BOOLEAN_FIELD_NAME)\n+            .required(INT32).named(INT32_FIELD_NAME)\n+            .named(\"FormatTestObject\").toString());\n+        }\n+\n+        ParquetReader<Group> reader = ParquetReader.builder(new GroupReadSupport(), file)\n+          .withConf(conf)\n+          .withDecryption(fileDecryptionProperties)\n+          .build();\n+\n+        try {\n+          for (int i = 0; i < 500; i++) {\n+            Group group = null;\n+            group = reader.read();\n+            boolean expect = false;\n+            if ((i % 2) == 0)\n+              expect = true;\n+            boolean bool_res = group.getBoolean(BOOLEAN_FIELD_NAME, 0);\n+            if (bool_res != expect)\n+              addErrorToErrorCollectorAndLog(\"Wrong bool\", encryptionConfiguration, decryptionConfiguration);\n+            int int_res = group.getInteger(INT32_FIELD_NAME, 0);\n+            if (int_res != i)\n+              addErrorToErrorCollectorAndLog(\"Wrong int\", encryptionConfiguration, decryptionConfiguration);\n+            if (decryptionConfiguration != DecryptionConfiguration.NO_DECRYPTION) {\n+              float float_res = group.getFloat(FLOAT_FIELD_NAME, 0);\n+              float tmp1 = (float) i * 1.1f;\n+              if (float_res != tmp1)\n+                addErrorToErrorCollectorAndLog(\"Wrong float\", encryptionConfiguration, decryptionConfiguration);\n+\n+              double double_res = group.getDouble(DOUBLE_FIELD_NAME, 0);\n+              double tmp = (i * 1.1111111);\n+              if (double_res != tmp)\n+                addErrorToErrorCollectorAndLog(\"Wrong double\", encryptionConfiguration, decryptionConfiguration);\n+            }\n+          }\n+        } catch (Exception e) {\n+          String errorMessage = e.getMessage();\n+          checkResult(file.getName(), decryptionConfiguration, (null == errorMessage ? \"\" : errorMessage));\n+        }\n+        conf.unset(\"parquet.read.schema\");\n+      }\n+    }\n+  }\n+\n+\n+  /**\n+   * Create a number of Encryption configurations\n+   * @param AADPrefix\n+   * @return\n+   */\n+  private Map<EncryptionConfiguration, FileEncryptionProperties> getEncryptionConfigurations(byte[] AADPrefix) {\n+    EncryptionConfiguration[] encryptionConfigurations = EncryptionConfiguration.values();\n+    Map<EncryptionConfiguration, FileEncryptionProperties> encryptionPropertiesMap = new HashMap<>(encryptionConfigurations.length);\n+\n+    String footerKeyName = FOOTER_ENCRYPTION_KEY_ID;\n+    byte[] footerKeyMetadata = footerKeyName.getBytes(StandardCharsets.UTF_8);\n+\n+    for (int i = 0; i < encryptionConfigurations.length; ++i) {\n+      EncryptionConfiguration encryptionConfiguration = encryptionConfigurations[i];\n+      switch (encryptionConfiguration) {\n+        case UNIFORM_ENCRYPTION:\n+          // Encryption configuration 1: Encrypt all columns and the footer with the same key.\n+          // (uniform encryption)\n+\n+          // Add to list of encryption configurations.\n+          encryptionPropertiesMap.put(EncryptionConfiguration.UNIFORM_ENCRYPTION,\n+            FileEncryptionProperties.builder(FOOTER_ENCRYPTION_KEY)\n+              .withFooterKeyMetadata(footerKeyMetadata).build());\n+\n+          break;\n+        case ENCRYPT_COLUMNS_AND_FOOTER:\n+          // Encryption configuration 2: Encrypt two columns and the footer, with different keys.\n+          ColumnEncryptionProperties columnProperties20 = ColumnEncryptionProperties\n+            .builder(DOUBLE_FIELD_NAME)\n+            .withKey(COLUMN_ENCRYPTION_KEY1)\n+            .withKeyID(COLUMN_ENCRYPTION_KEY1_ID)\n+            .build();\n+\n+          ColumnEncryptionProperties columnProperties21 = ColumnEncryptionProperties\n+            .builder(FLOAT_FIELD_NAME)\n+            .withKey(COLUMN_ENCRYPTION_KEY2)\n+            .withKeyID(COLUMN_ENCRYPTION_KEY2_ID)\n+            .build();\n+          Map<ColumnPath, ColumnEncryptionProperties> columnPropertiesMap2 = new HashMap<>();\n+\n+          columnPropertiesMap2.put(columnProperties20.getPath(), columnProperties20);\n+          columnPropertiesMap2.put(columnProperties21.getPath(), columnProperties21);\n+\n+          encryptionPropertiesMap.put(EncryptionConfiguration.ENCRYPT_COLUMNS_AND_FOOTER,\n+            FileEncryptionProperties.builder(FOOTER_ENCRYPTION_KEY)\n+              .withFooterKeyMetadata(footerKeyMetadata)\n+              .withEncryptedColumns(columnPropertiesMap2)\n+              .build());\n+          break;\n+\n+        case ENCRYPT_COLUMNS_PLAINTEXT_FOOTER:\n+          // Encryption configuration 3: Encrypt two columns, with different keys.\n+          // Don't encrypt footer.\n+          // (plaintext footer mode, readable by legacy readers)\n+          Map<ColumnPath, ColumnEncryptionProperties> columnPropertiesMap3 = new HashMap<>();\n+          ColumnEncryptionProperties columnProperties30 = ColumnEncryptionProperties\n+            .builder(DOUBLE_FIELD_NAME)\n+            .withKey(COLUMN_ENCRYPTION_KEY1)\n+            .withKeyID(COLUMN_ENCRYPTION_KEY1_ID)\n+            .build();\n+\n+          ColumnEncryptionProperties columnProperties31 = ColumnEncryptionProperties\n+            .builder(FLOAT_FIELD_NAME)\n+            .withKey(COLUMN_ENCRYPTION_KEY2)\n+            .withKeyID(COLUMN_ENCRYPTION_KEY2_ID)\n+            .build();\n+          columnPropertiesMap3.put(columnProperties30.getPath(), columnProperties30);\n+          columnPropertiesMap3.put(columnProperties31.getPath(), columnProperties31);\n+\n+          encryptionPropertiesMap.put(EncryptionConfiguration.ENCRYPT_COLUMNS_PLAINTEXT_FOOTER,\n+            FileEncryptionProperties.builder(FOOTER_ENCRYPTION_KEY)\n+              .withFooterKeyMetadata(footerKeyMetadata)\n+              .withEncryptedColumns(columnPropertiesMap3)\n+              .withPlaintextFooter()\n+              .build());\n+          break;\n+\n+        case ENCRYPT_COLUMNS_AND_FOOTER_AAD:\n+          // Encryption configuration 4: Encrypt two columns and the footer, with different keys.\n+          // Use aad_prefix.\n+          Map<ColumnPath, ColumnEncryptionProperties> columnPropertiesMap4 = new HashMap<>();\n+          ColumnEncryptionProperties columnProperties40 = ColumnEncryptionProperties\n+            .builder(DOUBLE_FIELD_NAME)\n+            .withKey(COLUMN_ENCRYPTION_KEY1)\n+            .withKeyID(COLUMN_ENCRYPTION_KEY1_ID)\n+            .build();\n+\n+          ColumnEncryptionProperties columnProperties41 = ColumnEncryptionProperties\n+            .builder(FLOAT_FIELD_NAME)\n+            .withKey(COLUMN_ENCRYPTION_KEY2)\n+            .withKeyID(COLUMN_ENCRYPTION_KEY2_ID)\n+            .build();\n+          columnPropertiesMap4.put(columnProperties40.getPath(), columnProperties40);\n+          columnPropertiesMap4.put(columnProperties41.getPath(), columnProperties41);\n+\n+          encryptionPropertiesMap.put(EncryptionConfiguration.ENCRYPT_COLUMNS_AND_FOOTER_AAD,\n+            FileEncryptionProperties.builder(FOOTER_ENCRYPTION_KEY)\n+              .withFooterKeyMetadata(footerKeyMetadata)\n+              .withEncryptedColumns(columnPropertiesMap4)\n+              .withAADPrefix(AADPrefix)\n+              .build());\n+          break;\n+\n+        case ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE:\n+          // Encryption configuration 5: Encrypt two columns and the footer, with different keys.\n+          // Use aad_prefix and disable_aad_prefix_storage.\n+          Map<ColumnPath, ColumnEncryptionProperties> columnPropertiesMap5 = new HashMap<>();\n+          ColumnEncryptionProperties columnProperties50 = ColumnEncryptionProperties\n+            .builder(DOUBLE_FIELD_NAME)\n+            .withKey(COLUMN_ENCRYPTION_KEY1)\n+            .withKeyID(COLUMN_ENCRYPTION_KEY1_ID)\n+            .build();\n+\n+          ColumnEncryptionProperties columnProperties51 = ColumnEncryptionProperties\n+            .builder(FLOAT_FIELD_NAME)\n+            .withKey(COLUMN_ENCRYPTION_KEY2)\n+            .withKeyID(COLUMN_ENCRYPTION_KEY2_ID)\n+            .build();\n+          columnPropertiesMap5.put(columnProperties50.getPath(), columnProperties50);\n+          columnPropertiesMap5.put(columnProperties51.getPath(), columnProperties51);\n+\n+          encryptionPropertiesMap.put(EncryptionConfiguration.ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE,\n+            FileEncryptionProperties.builder(FOOTER_ENCRYPTION_KEY)\n+              .withFooterKeyMetadata(footerKeyMetadata)\n+              .withEncryptedColumns(columnPropertiesMap5)\n+              .withAADPrefix(AADPrefix)\n+              .withoutAADPrefixStorage()\n+              .build());\n+          break;\n+\n+        case ENCRYPT_COLUMNS_AND_FOOTER_CTR:\n+          // Encryption configuration 6: Encrypt two columns and the footer, with different keys.\n+          // Use AES_GCM_CTR_V1 algorithm.\n+          Map<ColumnPath, ColumnEncryptionProperties> columnPropertiesMap6 = new HashMap<>();\n+          ColumnEncryptionProperties columnProperties60 = ColumnEncryptionProperties\n+            .builder(DOUBLE_FIELD_NAME)\n+            .withKey(COLUMN_ENCRYPTION_KEY1)\n+            .withKeyID(COLUMN_ENCRYPTION_KEY1_ID)\n+            .build();\n+\n+          ColumnEncryptionProperties columnProperties61 = ColumnEncryptionProperties\n+            .builder(FLOAT_FIELD_NAME)\n+            .withKey(COLUMN_ENCRYPTION_KEY2)\n+            .withKeyID(COLUMN_ENCRYPTION_KEY2_ID)\n+            .build();\n+          columnPropertiesMap6.put(columnProperties60.getPath(), columnProperties60);\n+          columnPropertiesMap6.put(columnProperties61.getPath(), columnProperties61);\n+\n+          encryptionPropertiesMap.put(EncryptionConfiguration.ENCRYPT_COLUMNS_AND_FOOTER_CTR,\n+            FileEncryptionProperties.builder(FOOTER_ENCRYPTION_KEY)\n+              .withFooterKeyMetadata(footerKeyMetadata)\n+              .withEncryptedColumns(columnPropertiesMap6)\n+              .withAlgorithm(ParquetCipher.AES_GCM_CTR_V1)\n+              .build());\n+          break;\n+\n+        case NO_ENCRYPTION:\n+          // Encryption configuration 7: Do not encrypt anything\n+          encryptionPropertiesMap.put(EncryptionConfiguration.NO_ENCRYPTION, null);\n+          break;\n+      }\n+    }\n+    return encryptionPropertiesMap;\n+  }\n+\n+  /**\n+   * Create a number of Decryption configurations\n+   * @param AADPrefix\n+   * @return\n+   */\n+  private Map<DecryptionConfiguration, FileDecryptionProperties>  getDecryptionConfigurations(byte[] AADPrefix) {", "originalCommit": "4ca6a2febde567c7b8753100c1b80fe2831f403f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "8ac65eed341f3bd9decbb8a92976b0ccc355b07a", "url": "https://github.com/apache/parquet-mr/commit/8ac65eed341f3bd9decbb8a92976b0ccc355b07a", "message": "Move parquet-testing up a directory", "committedDate": "2020-06-08T10:03:09Z", "type": "commit"}, {"oid": "35145c04a9afff4753bc6887d91d7a2b54050ee0", "url": "https://github.com/apache/parquet-mr/commit/35145c04a9afff4753bc6887d91d7a2b54050ee0", "message": "Address first review round", "committedDate": "2020-06-08T16:19:02Z", "type": "commit"}, {"oid": "24e8041c09b5fb628c5239bb444fb498e2de3c18", "url": "https://github.com/apache/parquet-mr/commit/24e8041c09b5fb628c5239bb444fb498e2de3c18", "message": "Add back missing constants", "committedDate": "2020-06-08T16:42:00Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzI0MDIzMg==", "url": "https://github.com/apache/parquet-mr/pull/782#discussion_r437240232", "bodyText": "It is strange that the RAT plugin (used for checking the license headers) did not catch this. Anyway, please add the license header at the very beginning of the file and the package after it.", "author": "gszadovszky", "createdAt": "2020-06-09T08:47:09Z", "path": "parquet-hadoop/src/test/java/org/apache/parquet/crypto/DecryptionKeyRetrieverMock.java", "diffHunk": "@@ -0,0 +1,43 @@\n+package org.apache.parquet.crypto;", "originalCommit": "24e8041c09b5fb628c5239bb444fb498e2de3c18", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzQyMjcwNw==", "url": "https://github.com/apache/parquet-mr/pull/782#discussion_r437422707", "bodyText": "What do you think about this way?\nimport static org.hamcrest.CoreMatchers.equalTo;\n// ...\n  if (null != rowExpected.plaintext_int32_field)\n    errorCollector.checkThat(\"Wrong int\", group.getInteger(PLAINTEXT_INT32_FIELD_NAME, 0), equalTo(rowExpected.plaintext_int32_field));\n  }\n\nSimilarly, you may do the check like that in any other places just like you would do with assertEquals. (You may find a couple of other matchers as well.)\nUPDATE: Meanwhile, I realized that you are not logging the values but the crypto configurations which are more relevant for this test. So, you may either skip my comment above or use it for creating another addErrorToCollectorAndLog like method.\nBTW, why do we need to check the expected value for null? Shouldn't be the actual value null as well?", "author": "gszadovszky", "createdAt": "2020-06-09T13:37:17Z", "path": "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestEncryptionOptions.java", "diffHunk": "@@ -125,150 +133,337 @@\n   @Rule\n   public ErrorCollector errorCollector = new ErrorCollector();\n \n+  private static String PARQUET_TESTING_PATH = \"../submodules/parquet-testing/data\";\n+  private static final int RANDOM_SEED = 42;\n+  private static final int FIXED_LENGTH = 10;\n+  private static final Random RANDOM = new Random(RANDOM_SEED);\n+  private static final RandomValues.IntGenerator intGenerator\n+    = new RandomValues.IntGenerator(RANDOM_SEED);\n+  private static final RandomValues.FloatGenerator floatGenerator\n+    = new RandomValues.FloatGenerator(RANDOM_SEED);\n+  private static final RandomValues.DoubleGenerator doubleGenerator\n+    = new RandomValues.DoubleGenerator(RANDOM_SEED);\n+  private static final RandomValues.BinaryGenerator binaryGenerator\n+    = new RandomValues.BinaryGenerator(RANDOM_SEED);\n+  private static final RandomValues.FixedGenerator fixedBinaryGenerator\n+    = new RandomValues.FixedGenerator(RANDOM_SEED, FIXED_LENGTH);\n+\n   private static final byte[] FOOTER_ENCRYPTION_KEY = \"0123456789012345\".getBytes();\n-  private static final byte[] COLUMN_ENCRYPTION_KEY1 = \"1234567890123450\".getBytes();\n-  private static final byte[] COLUMN_ENCRYPTION_KEY2 = \"1234567890123451\".getBytes();\n+  private static final byte[][] COLUMN_ENCRYPTION_KEYS = { \"1234567890123450\".getBytes(),\n+    \"1234567890123451\".getBytes(), \"1234567890123452\".getBytes(), \"1234567890123453\".getBytes(),\n+    \"1234567890123454\".getBytes(), \"1234567890123455\".getBytes()};\n+  private static final String[] COLUMN_ENCRYPTION_KEY_IDS = { \"kc1\", \"kc2\", \"kc3\", \"kc4\", \"kc5\", \"kc6\"};\n   private static final String FOOTER_ENCRYPTION_KEY_ID = \"kf\";\n-  private static final String COLUMN_ENCRYPTION_KEY1_ID = \"kc1\";\n-  private static final String COLUMN_ENCRYPTION_KEY2_ID = \"kc2\";\n   private static final String AAD_PREFIX_STRING = \"tester\";\n   private static final String BOOLEAN_FIELD_NAME = \"boolean_field\";\n   private static final String INT32_FIELD_NAME = \"int32_field\";\n   private static final String FLOAT_FIELD_NAME = \"float_field\";\n   private static final String DOUBLE_FIELD_NAME = \"double_field\";\n+  private static final String BINARY_FIELD_NAME = \"ba_field\";\n+  private static final String FIXED_LENGTH_BINARY_FIELD_NAME = \"flba_field\";\n+  private static final String PLAINTEXT_INT32_FIELD_NAME = \"plain_int32_field\";\n+\n+  private static final byte[] footerKeyMetadata = FOOTER_ENCRYPTION_KEY_ID.getBytes(StandardCharsets.UTF_8);\n+  private static final byte[] AADPrefix = AAD_PREFIX_STRING.getBytes(StandardCharsets.UTF_8);\n+\n+  private static final int ROW_COUNT = 10000;\n+  private static final List<SingleRow> DATA = Collections.unmodifiableList(generateRandomData(ROW_COUNT));\n+  private static final List<SingleRow> LINEAR_DATA = Collections.unmodifiableList(generateLinearData(250));\n+\n+  private static final MessageType SCHEMA =\n+    new MessageType(\"schema\",\n+      new PrimitiveType(REQUIRED, BOOLEAN, BOOLEAN_FIELD_NAME),\n+      new PrimitiveType(REQUIRED, INT32, INT32_FIELD_NAME),\n+      new PrimitiveType(REQUIRED, FLOAT, FLOAT_FIELD_NAME),\n+      new PrimitiveType(REQUIRED, DOUBLE, DOUBLE_FIELD_NAME),\n+      new PrimitiveType(OPTIONAL, BINARY, BINARY_FIELD_NAME),\n+      Types.required(FIXED_LEN_BYTE_ARRAY).length(FIXED_LENGTH).named(FIXED_LENGTH_BINARY_FIELD_NAME),\n+      new PrimitiveType(OPTIONAL, INT32, PLAINTEXT_INT32_FIELD_NAME));\n+\n+  private static final DecryptionKeyRetrieverMock decryptionKeyRetrieverMock = new DecryptionKeyRetrieverMock()\n+    .putKey(FOOTER_ENCRYPTION_KEY_ID, FOOTER_ENCRYPTION_KEY)\n+    .putKey(COLUMN_ENCRYPTION_KEY_IDS[0], COLUMN_ENCRYPTION_KEYS[0])\n+    .putKey(COLUMN_ENCRYPTION_KEY_IDS[1], COLUMN_ENCRYPTION_KEYS[1])\n+    .putKey(COLUMN_ENCRYPTION_KEY_IDS[2], COLUMN_ENCRYPTION_KEYS[2])\n+    .putKey(COLUMN_ENCRYPTION_KEY_IDS[3], COLUMN_ENCRYPTION_KEYS[3])\n+    .putKey(COLUMN_ENCRYPTION_KEY_IDS[4], COLUMN_ENCRYPTION_KEYS[4])\n+    .putKey(COLUMN_ENCRYPTION_KEY_IDS[5], COLUMN_ENCRYPTION_KEYS[5]);\n \n   public enum EncryptionConfiguration {\n-    UNIFORM_ENCRYPTION(\"UNIFORM_ENCRYPTION\"),\n-    ENCRYPT_COLUMNS_AND_FOOTER(\"ENCRYPT_COLUMNS_AND_FOOTER\"),\n-    ENCRYPT_COLUMNS_PLAINTEXT_FOOTER(\"ENCRYPT_COLUMNS_PLAINTEXT_FOOTER\"),\n-    ENCRYPT_COLUMNS_AND_FOOTER_AAD(\"ENCRYPT_COLUMNS_AND_FOOTER_AAD\"),\n-    ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE(\"ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE\"),\n-    ENCRYPT_COLUMNS_AND_FOOTER_CTR(\"ENCRYPT_COLUMNS_AND_FOOTER_CTR\"),\n-    NO_ENCRYPTION(\"NO_ENCRYPTION\");\n-\n-    private final String configurationName;\n-\n-    EncryptionConfiguration(String configurationName) {\n-      this.configurationName = configurationName;\n-    }\n+    UNIFORM_ENCRYPTION {\n+      public FileEncryptionProperties getEncryptionProperties() {\n+        return getUniformEncryptionEncryptionProperties();\n+      }\n+    },\n+    ENCRYPT_COLUMNS_AND_FOOTER {\n+      public FileEncryptionProperties getEncryptionProperties() {\n+        return getEncryptColumnsAndFooterEncryptionProperties();\n+      }\n+    },\n+    ENCRYPT_COLUMNS_PLAINTEXT_FOOTER {\n+      public FileEncryptionProperties getEncryptionProperties() {\n+        return getPlaintextFooterEncryptionProperties();\n+      }\n+    },\n+    ENCRYPT_COLUMNS_AND_FOOTER_AAD {\n+      public FileEncryptionProperties getEncryptionProperties() {\n+        return getEncryptWithAADEncryptionProperties();\n+      }\n+    },\n+    ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE {\n+      public FileEncryptionProperties getEncryptionProperties() {\n+        return getDisableAADStorageEncryptionProperties();\n+      }\n+    },\n+    ENCRYPT_COLUMNS_AND_FOOTER_CTR {\n+      public FileEncryptionProperties getEncryptionProperties() {\n+        return getCTREncryptionProperties();\n+      }\n+    },\n+    NO_ENCRYPTION {\n+      public FileEncryptionProperties getEncryptionProperties() {\n+        return null;\n+      }\n+    };\n \n-    @Override\n-    public String toString() {\n-      return configurationName;\n-    }\n+    abstract public FileEncryptionProperties getEncryptionProperties();\n   }\n \n-\n   public enum DecryptionConfiguration {\n-    DECRYPT_WITH_KEY_RETRIEVER(\"DECRYPT_WITH_KEY_RETRIEVER\"),\n-    DECRYPT_WITH_KEY_RETRIEVER_AAD(\"DECRYPT_WITH_KEY_RETRIEVER_AAD\"),\n-    DECRYPT_WITH_EXPLICIT_KEYS(\"DECRYPT_WITH_EXPLICIT_KEYS\"),\n-    NO_DECRYPTION(\"NO_DECRYPTION\");\n-\n-    private final String configurationName;\n-\n-    DecryptionConfiguration(String configurationName) {\n-      this.configurationName = configurationName;\n-    }\n+    DECRYPT_WITH_KEY_RETRIEVER {\n+      public FileDecryptionProperties getDecryptionProperties() {\n+        return getKeyRetrieverDecryptionProperties();\n+      }\n+    },\n+    DECRYPT_WITH_KEY_RETRIEVER_AAD {\n+      public FileDecryptionProperties getDecryptionProperties() {\n+        return getKeyRetrieverAADDecryptionProperties();\n+      }\n+    },\n+    DECRYPT_WITH_EXPLICIT_KEYS {\n+      public FileDecryptionProperties getDecryptionProperties() {\n+        return getExplicitKeysDecryptionProperties();\n+      }\n+    },\n+    NO_DECRYPTION {\n+      public FileDecryptionProperties getDecryptionProperties() {\n+        return null;\n+      }\n+    };\n \n-    @Override\n-    public String toString() {\n-      return configurationName;\n-    }\n+    abstract public FileDecryptionProperties getDecryptionProperties();\n   }\n \n   @Test\n   public void testWriteReadEncryptedParquetFiles() throws IOException {\n     Path rootPath = new Path(temporaryFolder.getRoot().getPath());\n     LOG.info(\"======== testWriteReadEncryptedParquetFiles {} ========\", rootPath.toString());\n     byte[] AADPrefix = AAD_PREFIX_STRING.getBytes(StandardCharsets.UTF_8);\n-    // This array will hold various encryption configuraions.\n-    Map<EncryptionConfiguration, FileEncryptionProperties> encryptionPropertiesMap =\n-      getEncryptionConfigurations(AADPrefix);\n-    testWriteEncryptedParquetFiles(rootPath, encryptionPropertiesMap);\n-    // This array will hold various decryption configurations.\n-    Map<DecryptionConfiguration, FileDecryptionProperties> decryptionPropertiesMap =\n-      getDecryptionConfigurations(AADPrefix);\n-    testReadEncryptedParquetFiles(rootPath, decryptionPropertiesMap);\n+    // Write using various encryption configuraions\n+    testWriteEncryptedParquetFiles(rootPath, DATA);\n+    // Read using various decryption configurations.\n+    testReadEncryptedParquetFiles(rootPath, DATA);\n   }\n \n   @Test\n   public void testInteropReadEncryptedParquetFiles() throws IOException {\n-    Path rootPath = new Path(\"submodules/parquet-testing/data\");\n+    Path rootPath = new Path(PARQUET_TESTING_PATH);\n     LOG.info(\"======== testInteropReadEncryptedParquetFiles {} ========\", rootPath.toString());\n     byte[] AADPrefix = AAD_PREFIX_STRING.getBytes(StandardCharsets.UTF_8);\n-    // This array will hold various decryption configurations.\n-    Map<DecryptionConfiguration, FileDecryptionProperties> decryptionPropertiesMap =\n-      getDecryptionConfigurations(AADPrefix);\n-    testReadEncryptedParquetFiles(rootPath, decryptionPropertiesMap);\n+    // Read using various decryption configurations.\n+    testInteropReadEncryptedParquetFiles(rootPath, true/*readOnlyEncrypted*/, LINEAR_DATA);\n   }\n \n-  private void testWriteEncryptedParquetFiles(Path root, Map<EncryptionConfiguration, FileEncryptionProperties> encryptionPropertiesMap) throws IOException {\n-    Configuration conf = new Configuration();\n-    int numberOfEncryptionModes = encryptionPropertiesMap.size();\n+  private static List<SingleRow> generateRandomData(int rowCount) {\n+    List<SingleRow> dataList = new ArrayList<>(rowCount);\n+    for (int row = 0; row < rowCount; ++row) {\n+      SingleRow newRow = new SingleRow(RANDOM.nextBoolean(),\n+        intGenerator.nextValue(),  floatGenerator.nextValue(),\n+        doubleGenerator.nextValue(), binaryGenerator.nextValue().getBytes(),\n+        fixedBinaryGenerator.nextValue().getBytes(), intGenerator.nextValue());\n+      dataList.add(newRow);\n+    }\n+    return dataList;\n+  }\n+\n+  private static List<SingleRow> generateLinearData(int rowCount) {\n+    List<SingleRow> dataList = new ArrayList<>(rowCount);\n+    String baseStr = \"parquet\";\n+    for (int row = 0; row < rowCount; ++row) {\n+      boolean boolean_val = ((row % 2) == 0) ? true : false;\n+      float float_val = (float) row * 1.1f;\n+      double double_val = (row * 1.1111111);\n+\n+      byte[] binary_val = null;\n+      if ((row % 2) == 0) {\n+        char firstChar = (char) ((int) '0' + row / 100);\n+        char secondChar = (char) ((int) '0' + (row / 10) % 10);\n+        char thirdChar = (char) ((int) '0' + row % 10);\n+        binary_val = (baseStr + firstChar + secondChar + thirdChar).getBytes(StandardCharsets.UTF_8);\n+      }\n+      char[] fixed = new char[FIXED_LENGTH];\n+      char[] aChar = Character.toChars(row);\n+      Arrays.fill(fixed, aChar[0]);\n+\n+      SingleRow newRow = new SingleRow(boolean_val,\n+        row, float_val, double_val,\n+        binary_val, new String(fixed).getBytes(StandardCharsets.UTF_8), null/*plaintext_int32_field*/);\n+      dataList.add(newRow);\n+    }\n+    return dataList;\n+  }\n \n-    MessageType schema = parseMessageType(\n-      \"message test { \"\n-        + \"required boolean \" + BOOLEAN_FIELD_NAME + \"; \"\n-        + \"required int32 \" + INT32_FIELD_NAME + \"; \"\n-        + \"required float \" + FLOAT_FIELD_NAME + \"; \"\n-        + \"required double \" + DOUBLE_FIELD_NAME + \"; \"\n-        + \"} \");\n+  public static class SingleRow {\n+    public final boolean boolean_field;\n+    public final int int32_field;\n+    public final float float_field;\n+    public final double double_field;\n+    public final byte[] ba_field;\n+    public final byte[] flba_field;\n+    public final Integer plaintext_int32_field; // Can be null, since it doesn't exist in C++-created files yet.\n+\n+    public SingleRow(boolean boolean_field,\n+                     int int32_field,\n+                     float float_field,\n+                     double double_field,\n+                     byte[] ba_field,\n+                     byte[] flba_field,\n+                     Integer plaintext_int32_field) {\n+      this.boolean_field = boolean_field;\n+      this.int32_field = int32_field;\n+      this.float_field = float_field;\n+      this.double_field = double_field;\n+      this.ba_field = ba_field;\n+      this.flba_field = flba_field;\n+      this.plaintext_int32_field = plaintext_int32_field;\n+    }\n+  }\n \n-    GroupWriteSupport.setSchema(schema, conf);\n-    SimpleGroupFactory f = new SimpleGroupFactory(schema);\n+  private void testWriteEncryptedParquetFiles(Path root, List<SingleRow> data) throws IOException {\n+    Configuration conf = new Configuration();\n \n+    int pageSize = data.size() / 10;     // Ensure that several pages will be created\n+    int rowGroupSize = pageSize * 6 * 5; // Ensure that there are more row-groups created\n \n-    for (Map.Entry<EncryptionConfiguration, FileEncryptionProperties> encryptionConfigurationEntry : encryptionPropertiesMap.entrySet()) {\n-      EncryptionConfiguration encryptionConfiguration = encryptionConfigurationEntry.getKey();\n-      Path file = new Path(root, encryptionConfiguration.toString() + \".parquet.encrypted\");\n+    SimpleGroupFactory f = new SimpleGroupFactory(SCHEMA);\n \n+    EncryptionConfiguration[] encryptionConfigurations = EncryptionConfiguration.values();\n+    for (EncryptionConfiguration encryptionConfiguration : encryptionConfigurations) {\n+      Path file = new Path(root, getFileName(encryptionConfiguration));\n+      FileEncryptionProperties encryptionProperties = encryptionConfiguration.getEncryptionProperties();\n       LOG.info(\"\\nWrite \" + file.toString());\n-      ParquetWriter<Group> writer = ExampleParquetWriter.builder(file)\n+      try (ParquetWriter<Group> writer = ExampleParquetWriter.builder(file)\n         .withWriteMode(OVERWRITE)\n-        .withType(schema)\n-        .withEncryption(encryptionConfigurationEntry.getValue())\n-        .build();\n-\n-      for (int i = 0; i < 100; i++) {\n-        boolean expect = false;\n-        if ((i % 2) == 0)\n-          expect = true;\n-        float float_val = (float) i * 1.1f;\n-        double double_val = (i * 1.1111111);\n-\n-        writer.write(\n-          f.newGroup()\n-            .append(BOOLEAN_FIELD_NAME, expect)\n-            .append(INT32_FIELD_NAME, i)\n-            .append(FLOAT_FIELD_NAME, float_val)\n-            .append(DOUBLE_FIELD_NAME, double_val));\n+        .withRowGroupSize(rowGroupSize)\n+        .withPageSize(pageSize)\n+        .withType(SCHEMA)\n+        .withConf(conf)\n+        .withEncryption(encryptionProperties)\n+        .build()) {\n+\n+        for (SingleRow singleRow : data) {\n+          writer.write(\n+            f.newGroup()\n+              .append(BOOLEAN_FIELD_NAME, singleRow.boolean_field)\n+              .append(INT32_FIELD_NAME, singleRow.int32_field)\n+              .append(FLOAT_FIELD_NAME, singleRow.float_field)\n+              .append(DOUBLE_FIELD_NAME, singleRow.double_field)\n+              .append(BINARY_FIELD_NAME, Binary.fromConstantByteArray(singleRow.ba_field))\n+              .append(FIXED_LENGTH_BINARY_FIELD_NAME, Binary.fromConstantByteArray(singleRow.flba_field))\n+              .append(PLAINTEXT_INT32_FIELD_NAME, singleRow.plaintext_int32_field));\n \n+        }\n       }\n-      writer.close();\n     }\n   }\n \n-  private void testReadEncryptedParquetFiles(Path root, Map<DecryptionConfiguration, FileDecryptionProperties> decryptionPropertiesMap) throws IOException {\n+  private String getFileName(EncryptionConfiguration encryptionConfiguration) {\n+    return encryptionConfiguration.toString().toLowerCase() + \".parquet.encrypted\";\n+  }\n+\n+  private void testReadEncryptedParquetFiles(Path root, List<SingleRow> data) {\n     Configuration conf = new Configuration();\n+    DecryptionConfiguration[] decryptionConfigurations = DecryptionConfiguration.values();\n+    for (DecryptionConfiguration decryptionConfiguration : decryptionConfigurations) {\n+      EncryptionConfiguration[] encryptionConfigurations = EncryptionConfiguration.values();\n+      for (EncryptionConfiguration encryptionConfiguration : encryptionConfigurations) {\n+        Path file = new Path(root, getFileName(encryptionConfiguration));\n+        LOG.info(\"==> Decryption configuration {}\", decryptionConfiguration);\n+        FileDecryptionProperties fileDecryptionProperties = decryptionConfiguration.getDecryptionProperties();\n \n-    for (Map.Entry<DecryptionConfiguration, FileDecryptionProperties> decryptionConfigurationEntry : decryptionPropertiesMap.entrySet()) {\n-      DecryptionConfiguration decryptionConfiguration = decryptionConfigurationEntry.getKey();\n-      LOG.info(\"==> Decryption configuration {}\", decryptionConfiguration);\n-      FileDecryptionProperties fileDecryptionProperties = decryptionConfigurationEntry.getValue();\n+        LOG.info(\"--> Read file {} {}\", file.toString(), encryptionConfiguration);\n \n-      File folder = new File(root.toString());\n-      File[] listOfFiles = folder.listFiles();\n+        // Read only the non-encrypted columns\n+        if ((decryptionConfiguration == DecryptionConfiguration.NO_DECRYPTION) &&\n+          (encryptionConfiguration == EncryptionConfiguration.ENCRYPT_COLUMNS_PLAINTEXT_FOOTER)) {\n+          conf.set(\"parquet.read.schema\", Types.buildMessage()\n+            .optional(INT32).named(PLAINTEXT_INT32_FIELD_NAME)\n+            .named(\"FormatTestObject\").toString());\n+        }\n \n-      for (int fileNum = 0; fileNum < listOfFiles.length; fileNum++) {\n-        Path file = new Path(listOfFiles[fileNum].getAbsolutePath());\n-        if (!file.getName().endsWith(\"parquet.encrypted\")) { // Skip non encrypted files\n-          continue;\n+        int rowNum = 0;\n+        try (ParquetReader<Group> reader = ParquetReader.builder(new GroupReadSupport(), file)\n+          .withConf(conf)\n+          .withDecryption(fileDecryptionProperties)\n+          .build()) {\n+          for (Group group = reader.read(); group != null; group = reader.read()) {\n+            SingleRow rowExpected = data.get(rowNum++);\n+            // plaintext columns\n+            if ((null != rowExpected.plaintext_int32_field) &&\n+              rowExpected.plaintext_int32_field != group.getInteger(PLAINTEXT_INT32_FIELD_NAME, 0)) {\n+              addErrorToErrorCollectorAndLog(\"Wrong int\", encryptionConfiguration, decryptionConfiguration);\n+            }", "originalCommit": "24e8041c09b5fb628c5239bb444fb498e2de3c18", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzU0NDUyNA==", "url": "https://github.com/apache/parquet-mr/pull/782#discussion_r437544524", "bodyText": "@gszadovszky, If you don't mind, I'd rather leave the method as it is, since it both adds an error to errorCollector for the final result and logs it for a more readable test progress log. If I let errorCollector.checkThat() do the comparison, I will need the current check anyway in order to add the test progress logging.\nThanks, I've removed the null check.", "author": "andersonm-1", "createdAt": "2020-06-09T16:00:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzQyMjcwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzQzNDA5NQ==", "url": "https://github.com/apache/parquet-mr/pull/782#discussion_r437434095", "bodyText": "nit:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              private static FileEncryptionProperties getUniformEncryptionEncryptionProperties() {\n          \n          \n            \n              private static FileEncryptionProperties getUniformEncryptionProperties() {", "author": "gszadovszky", "createdAt": "2020-06-09T13:49:02Z", "path": "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestEncryptionOptions.java", "diffHunk": "@@ -657,4 +617,201 @@ private void addErrorToErrorCollectorAndLog(String errorMessage, EncryptionConfi\n     errorCollector.addError(new Throwable(fullErrorMessage));\n     LOG.error(fullErrorMessage);\n   }\n+\n+  private static Map<ColumnPath, ColumnEncryptionProperties> getColumnEncryptionPropertiesMap() {\n+    Map<ColumnPath, ColumnEncryptionProperties> columnPropertiesMap = new HashMap<>();\n+\n+    ColumnEncryptionProperties columnPropertiesDouble = ColumnEncryptionProperties\n+      .builder(DOUBLE_FIELD_NAME)\n+      .withKey(COLUMN_ENCRYPTION_KEYS[0])\n+      .withKeyID(COLUMN_ENCRYPTION_KEY_IDS[0])\n+      .build();\n+    columnPropertiesMap.put(columnPropertiesDouble.getPath(), columnPropertiesDouble);\n+\n+    ColumnEncryptionProperties columnPropertiesFloat = ColumnEncryptionProperties\n+      .builder(FLOAT_FIELD_NAME)\n+      .withKey(COLUMN_ENCRYPTION_KEYS[1])\n+      .withKeyID(COLUMN_ENCRYPTION_KEY_IDS[1])\n+      .build();\n+    columnPropertiesMap.put(columnPropertiesFloat.getPath(), columnPropertiesFloat);\n+\n+    ColumnEncryptionProperties columnPropertiesBool = ColumnEncryptionProperties\n+      .builder(BOOLEAN_FIELD_NAME)\n+      .withKey(COLUMN_ENCRYPTION_KEYS[2])\n+      .withKeyID(COLUMN_ENCRYPTION_KEY_IDS[2])\n+      .build();\n+    columnPropertiesMap.put(columnPropertiesBool.getPath(), columnPropertiesBool);\n+\n+    ColumnEncryptionProperties columnPropertiesInt32 = ColumnEncryptionProperties\n+      .builder(INT32_FIELD_NAME)\n+      .withKey(COLUMN_ENCRYPTION_KEYS[3])\n+      .withKeyID(COLUMN_ENCRYPTION_KEY_IDS[3])\n+      .build();\n+    columnPropertiesMap.put(columnPropertiesInt32.getPath(), columnPropertiesInt32);\n+\n+    ColumnEncryptionProperties columnPropertiesBinary = ColumnEncryptionProperties\n+      .builder(BINARY_FIELD_NAME)\n+      .withKey(COLUMN_ENCRYPTION_KEYS[4])\n+      .withKeyID(COLUMN_ENCRYPTION_KEY_IDS[4])\n+      .build();\n+    columnPropertiesMap.put(columnPropertiesBinary.getPath(), columnPropertiesBinary);\n+\n+    ColumnEncryptionProperties columnPropertiesFixed = ColumnEncryptionProperties\n+      .builder(FIXED_LENGTH_BINARY_FIELD_NAME)\n+      .withKey(COLUMN_ENCRYPTION_KEYS[5])\n+      .withKeyID(COLUMN_ENCRYPTION_KEY_IDS[5])\n+      .build();\n+    columnPropertiesMap.put(columnPropertiesFixed.getPath(), columnPropertiesFixed);\n+\n+    return columnPropertiesMap;\n+  }\n+\n+  private static Map<ColumnPath, ColumnDecryptionProperties> getColumnDecryptionPropertiesMap() {\n+    Map<ColumnPath, ColumnDecryptionProperties> columnMap = new HashMap<>();\n+\n+    ColumnDecryptionProperties columnDecryptionPropsDouble = ColumnDecryptionProperties\n+      .builder(DOUBLE_FIELD_NAME)\n+      .withKey(COLUMN_ENCRYPTION_KEYS[0])\n+      .build();\n+    columnMap.put(columnDecryptionPropsDouble.getPath(), columnDecryptionPropsDouble);\n+\n+    ColumnDecryptionProperties columnDecryptionPropsFloat = ColumnDecryptionProperties\n+      .builder(FLOAT_FIELD_NAME)\n+      .withKey(COLUMN_ENCRYPTION_KEYS[1])\n+      .build();\n+    columnMap.put(columnDecryptionPropsFloat.getPath(), columnDecryptionPropsFloat);\n+\n+    ColumnDecryptionProperties columnDecryptionPropsBool = ColumnDecryptionProperties\n+      .builder(BOOLEAN_FIELD_NAME)\n+      .withKey(COLUMN_ENCRYPTION_KEYS[2])\n+      .build();\n+    columnMap.put(columnDecryptionPropsBool.getPath(), columnDecryptionPropsBool);\n+\n+    ColumnDecryptionProperties columnDecryptionPropsInt32 = ColumnDecryptionProperties\n+      .builder(INT32_FIELD_NAME)\n+      .withKey(COLUMN_ENCRYPTION_KEYS[3])\n+      .build();\n+    columnMap.put(columnDecryptionPropsInt32.getPath(), columnDecryptionPropsInt32);\n+\n+    ColumnDecryptionProperties columnDecryptionPropsBinary = ColumnDecryptionProperties\n+      .builder(BINARY_FIELD_NAME)\n+      .withKey(COLUMN_ENCRYPTION_KEYS[4])\n+      .build();\n+    columnMap.put(columnDecryptionPropsBinary.getPath(), columnDecryptionPropsBinary);\n+\n+    ColumnDecryptionProperties columnDecryptionPropsFixed = ColumnDecryptionProperties\n+      .builder(FIXED_LENGTH_BINARY_FIELD_NAME)\n+      .withKey(COLUMN_ENCRYPTION_KEYS[5])\n+      .build();\n+    columnMap.put(columnDecryptionPropsFixed.getPath(), columnDecryptionPropsFixed);\n+\n+    return columnMap;\n+  }\n+\n+  /**\n+   * Encryption configuration 1: Encrypt all columns and the footer with the same key.\n+   */\n+  private static FileEncryptionProperties getUniformEncryptionEncryptionProperties() {", "originalCommit": "24e8041c09b5fb628c5239bb444fb498e2de3c18", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzQzODQ2OQ==", "url": "https://github.com/apache/parquet-mr/pull/782#discussion_r437438469", "bodyText": "It is more a coding style question but I think it would be more readable to simple have the implementation here in the enums instead of adding new static methods. If you like it more as is I'm also fine with it.", "author": "gszadovszky", "createdAt": "2020-06-09T13:53:00Z", "path": "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestEncryptionOptions.java", "diffHunk": "@@ -125,150 +133,337 @@\n   @Rule\n   public ErrorCollector errorCollector = new ErrorCollector();\n \n+  private static String PARQUET_TESTING_PATH = \"../submodules/parquet-testing/data\";\n+  private static final int RANDOM_SEED = 42;\n+  private static final int FIXED_LENGTH = 10;\n+  private static final Random RANDOM = new Random(RANDOM_SEED);\n+  private static final RandomValues.IntGenerator intGenerator\n+    = new RandomValues.IntGenerator(RANDOM_SEED);\n+  private static final RandomValues.FloatGenerator floatGenerator\n+    = new RandomValues.FloatGenerator(RANDOM_SEED);\n+  private static final RandomValues.DoubleGenerator doubleGenerator\n+    = new RandomValues.DoubleGenerator(RANDOM_SEED);\n+  private static final RandomValues.BinaryGenerator binaryGenerator\n+    = new RandomValues.BinaryGenerator(RANDOM_SEED);\n+  private static final RandomValues.FixedGenerator fixedBinaryGenerator\n+    = new RandomValues.FixedGenerator(RANDOM_SEED, FIXED_LENGTH);\n+\n   private static final byte[] FOOTER_ENCRYPTION_KEY = \"0123456789012345\".getBytes();\n-  private static final byte[] COLUMN_ENCRYPTION_KEY1 = \"1234567890123450\".getBytes();\n-  private static final byte[] COLUMN_ENCRYPTION_KEY2 = \"1234567890123451\".getBytes();\n+  private static final byte[][] COLUMN_ENCRYPTION_KEYS = { \"1234567890123450\".getBytes(),\n+    \"1234567890123451\".getBytes(), \"1234567890123452\".getBytes(), \"1234567890123453\".getBytes(),\n+    \"1234567890123454\".getBytes(), \"1234567890123455\".getBytes()};\n+  private static final String[] COLUMN_ENCRYPTION_KEY_IDS = { \"kc1\", \"kc2\", \"kc3\", \"kc4\", \"kc5\", \"kc6\"};\n   private static final String FOOTER_ENCRYPTION_KEY_ID = \"kf\";\n-  private static final String COLUMN_ENCRYPTION_KEY1_ID = \"kc1\";\n-  private static final String COLUMN_ENCRYPTION_KEY2_ID = \"kc2\";\n   private static final String AAD_PREFIX_STRING = \"tester\";\n   private static final String BOOLEAN_FIELD_NAME = \"boolean_field\";\n   private static final String INT32_FIELD_NAME = \"int32_field\";\n   private static final String FLOAT_FIELD_NAME = \"float_field\";\n   private static final String DOUBLE_FIELD_NAME = \"double_field\";\n+  private static final String BINARY_FIELD_NAME = \"ba_field\";\n+  private static final String FIXED_LENGTH_BINARY_FIELD_NAME = \"flba_field\";\n+  private static final String PLAINTEXT_INT32_FIELD_NAME = \"plain_int32_field\";\n+\n+  private static final byte[] footerKeyMetadata = FOOTER_ENCRYPTION_KEY_ID.getBytes(StandardCharsets.UTF_8);\n+  private static final byte[] AADPrefix = AAD_PREFIX_STRING.getBytes(StandardCharsets.UTF_8);\n+\n+  private static final int ROW_COUNT = 10000;\n+  private static final List<SingleRow> DATA = Collections.unmodifiableList(generateRandomData(ROW_COUNT));\n+  private static final List<SingleRow> LINEAR_DATA = Collections.unmodifiableList(generateLinearData(250));\n+\n+  private static final MessageType SCHEMA =\n+    new MessageType(\"schema\",\n+      new PrimitiveType(REQUIRED, BOOLEAN, BOOLEAN_FIELD_NAME),\n+      new PrimitiveType(REQUIRED, INT32, INT32_FIELD_NAME),\n+      new PrimitiveType(REQUIRED, FLOAT, FLOAT_FIELD_NAME),\n+      new PrimitiveType(REQUIRED, DOUBLE, DOUBLE_FIELD_NAME),\n+      new PrimitiveType(OPTIONAL, BINARY, BINARY_FIELD_NAME),\n+      Types.required(FIXED_LEN_BYTE_ARRAY).length(FIXED_LENGTH).named(FIXED_LENGTH_BINARY_FIELD_NAME),\n+      new PrimitiveType(OPTIONAL, INT32, PLAINTEXT_INT32_FIELD_NAME));\n+\n+  private static final DecryptionKeyRetrieverMock decryptionKeyRetrieverMock = new DecryptionKeyRetrieverMock()\n+    .putKey(FOOTER_ENCRYPTION_KEY_ID, FOOTER_ENCRYPTION_KEY)\n+    .putKey(COLUMN_ENCRYPTION_KEY_IDS[0], COLUMN_ENCRYPTION_KEYS[0])\n+    .putKey(COLUMN_ENCRYPTION_KEY_IDS[1], COLUMN_ENCRYPTION_KEYS[1])\n+    .putKey(COLUMN_ENCRYPTION_KEY_IDS[2], COLUMN_ENCRYPTION_KEYS[2])\n+    .putKey(COLUMN_ENCRYPTION_KEY_IDS[3], COLUMN_ENCRYPTION_KEYS[3])\n+    .putKey(COLUMN_ENCRYPTION_KEY_IDS[4], COLUMN_ENCRYPTION_KEYS[4])\n+    .putKey(COLUMN_ENCRYPTION_KEY_IDS[5], COLUMN_ENCRYPTION_KEYS[5]);\n \n   public enum EncryptionConfiguration {\n-    UNIFORM_ENCRYPTION(\"UNIFORM_ENCRYPTION\"),\n-    ENCRYPT_COLUMNS_AND_FOOTER(\"ENCRYPT_COLUMNS_AND_FOOTER\"),\n-    ENCRYPT_COLUMNS_PLAINTEXT_FOOTER(\"ENCRYPT_COLUMNS_PLAINTEXT_FOOTER\"),\n-    ENCRYPT_COLUMNS_AND_FOOTER_AAD(\"ENCRYPT_COLUMNS_AND_FOOTER_AAD\"),\n-    ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE(\"ENCRYPT_COLUMNS_AND_FOOTER_DISABLE_AAD_STORAGE\"),\n-    ENCRYPT_COLUMNS_AND_FOOTER_CTR(\"ENCRYPT_COLUMNS_AND_FOOTER_CTR\"),\n-    NO_ENCRYPTION(\"NO_ENCRYPTION\");\n-\n-    private final String configurationName;\n-\n-    EncryptionConfiguration(String configurationName) {\n-      this.configurationName = configurationName;\n-    }\n+    UNIFORM_ENCRYPTION {\n+      public FileEncryptionProperties getEncryptionProperties() {\n+        return getUniformEncryptionEncryptionProperties();", "originalCommit": "24e8041c09b5fb628c5239bb444fb498e2de3c18", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "4b7e032b720c4f8ca8375b3d1a78228156828e95", "url": "https://github.com/apache/parquet-mr/commit/4b7e032b720c4f8ca8375b3d1a78228156828e95", "message": "Address second review round", "committedDate": "2020-06-09T15:41:16Z", "type": "commit"}]}