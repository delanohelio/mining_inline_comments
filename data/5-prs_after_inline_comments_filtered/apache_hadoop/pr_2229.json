{"pr_number": 2229, "pr_title": "HDFS-15533: Provide DFS API compatible class, but use ViewFileSystemOverloadScheme inside.", "pr_createdAt": "2020-08-15T01:36:16Z", "pr_url": "https://github.com/apache/hadoop/pull/2229", "timeline": [{"oid": "33902b0e36c9d1f41195d9fc31af21f5de5f222d", "url": "https://github.com/apache/hadoop/commit/33902b0e36c9d1f41195d9fc31af21f5de5f222d", "message": "HDFS-15533: Provide DFS API compatible class, but use ViewFileSystemOverloadScheme inside.", "committedDate": "2020-08-15T01:33:41Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkzNDYwNg==", "url": "https://github.com/apache/hadoop/pull/2229#discussion_r470934606", "bodyText": "Do we need to initialize twice? It is already done above at L132", "author": "ayushtkn", "createdAt": "2020-08-15T04:07:18Z", "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/ViewDistributedFileSystem.java", "diffHunk": "@@ -0,0 +1,1864 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.hadoop.HadoopIllegalArgumentException;\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.crypto.key.KeyProvider;\n+import org.apache.hadoop.fs.BlockLocation;\n+import org.apache.hadoop.fs.BlockStoragePolicySpi;\n+import org.apache.hadoop.fs.CacheFlag;\n+import org.apache.hadoop.fs.ContentSummary;\n+import org.apache.hadoop.fs.CreateFlag;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.FileChecksum;\n+import org.apache.hadoop.fs.FileEncryptionInfo;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.FsServerDefaults;\n+import org.apache.hadoop.fs.FsStatus;\n+import org.apache.hadoop.fs.LocatedFileStatus;\n+import org.apache.hadoop.fs.Options;\n+import org.apache.hadoop.fs.PartialListing;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.PathFilter;\n+import org.apache.hadoop.fs.PathHandle;\n+import org.apache.hadoop.fs.QuotaUsage;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.StorageType;\n+import org.apache.hadoop.fs.XAttrSetFlag;\n+import org.apache.hadoop.fs.permission.AclEntry;\n+import org.apache.hadoop.fs.permission.AclStatus;\n+import org.apache.hadoop.fs.permission.FsAction;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+import org.apache.hadoop.fs.viewfs.ViewFileSystem;\n+import org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme;\n+import org.apache.hadoop.hdfs.client.HdfsDataOutputStream;\n+import org.apache.hadoop.hdfs.protocol.AddErasureCodingPolicyResponse;\n+import org.apache.hadoop.hdfs.protocol.BlockStoragePolicy;\n+import org.apache.hadoop.hdfs.protocol.CacheDirectiveEntry;\n+import org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo;\n+import org.apache.hadoop.hdfs.protocol.CachePoolEntry;\n+import org.apache.hadoop.hdfs.protocol.CachePoolInfo;\n+import org.apache.hadoop.hdfs.protocol.DatanodeInfo;\n+import org.apache.hadoop.hdfs.protocol.ECTopologyVerifierResult;\n+import org.apache.hadoop.hdfs.protocol.EncryptionZone;\n+import org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy;\n+import org.apache.hadoop.hdfs.protocol.ErasureCodingPolicyInfo;\n+import org.apache.hadoop.hdfs.protocol.HdfsConstants;\n+import org.apache.hadoop.hdfs.protocol.HdfsPathHandle;\n+import org.apache.hadoop.hdfs.protocol.OpenFileEntry;\n+import org.apache.hadoop.hdfs.protocol.OpenFilesIterator;\n+import org.apache.hadoop.hdfs.protocol.RollingUpgradeInfo;\n+import org.apache.hadoop.hdfs.protocol.SnapshotDiffReport;\n+import org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing;\n+import org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus;\n+import org.apache.hadoop.hdfs.protocol.ZoneReencryptionStatus;\n+import org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenIdentifier;\n+import org.apache.hadoop.security.AccessControlException;\n+import org.apache.hadoop.security.token.DelegationTokenIssuer;\n+import org.apache.hadoop.security.token.Token;\n+import org.apache.hadoop.util.Progressable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+\n+import java.net.InetSocketAddress;\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.EnumSet;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * The ViewDistributedFileSystem is an extended class to DistributedFileSystem\n+ * with additional mounting functionality. The goal is to have better API\n+ * compatibility for HDFS users when using mounting\n+ * filesystem(ViewFileSystemOverloadScheme).\n+ * The ViewFileSystemOverloadScheme{@link ViewFileSystemOverloadScheme} is a new\n+ * filesystem with inherited mounting functionality from ViewFileSystem.\n+ * For the user who is using ViewFileSystemOverloadScheme by setting\n+ * fs.hdfs.impl=org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme, now\n+ * they can set fs.hdfs.impl=org.apache.hadoop.hdfs.ViewDistributedFileSystem.\n+ * So, that the hdfs users will get closely compatible API with mount\n+ * functionality. For the rest of all other schemes can continue to use\n+ * ViewFileSystemOverloadScheme class directly for mount functionality. Please\n+ * note that ViewFileSystemOverloadScheme provides only\n+ * ViewFileSystem{@link ViewFileSystem} APIs.\n+ * If user configured this class but no mount point configured? Then it will\n+ * simply work as existing DistributedFileSystem class. If user configured both\n+ * fs.hdfs.impl to this class and mount configurations, then users will be able\n+ * to make calls the APIs available in this class, they are nothing but DFS\n+ * APIs, but they will be delegated to viewfs functionality. Please note, APIs\n+ * without any path in arguments( ex: isInSafeMode), will be delegated to\n+ * default filesystem only, that is the configured fallback link. If you want to\n+ * make these API calls on specific child filesystem, you may want to initialize\n+ * them separately and call. In ViewDistributedFileSystem, linkFallBack is\n+ * mandatory when you ass mount links and it must be to your base cluster,\n+ * usually your current fs.defaultFS if that's pointing to hdfs.\n+ */\n+public class ViewDistributedFileSystem extends DistributedFileSystem {\n+  private static final Logger LOGGER =\n+      LoggerFactory.getLogger(ViewDistributedFileSystem.class);\n+\n+  // A mounting file system.\n+  private ViewFileSystemOverloadScheme vfs;\n+  // A default DFS, which should have set via linkFallback\n+  private DistributedFileSystem defaultDFS;\n+\n+  @Override\n+  public void initialize(URI uri, Configuration conf) throws IOException {\n+    super.initialize(uri, conf);\n+    try {\n+      this.vfs = tryInitializeMountingViewFs(uri, conf);\n+    } catch (IOException ioe) {\n+      LOGGER.debug(\n+          \"Mount tree initialization failed with the reason => {}. Falling\" +\n+              \" back to regular DFS initialization. Please\" + \" re-initialize\" +\n+              \" the fs after updating mount point.\",\n+          ioe.getMessage());\n+      // Re-initialize, so that initDFSClient will initialize DFSClient to work\n+      // same as DistributedFileSystem.\n+      super.initialize(uri, conf);", "originalCommit": "33902b0e36c9d1f41195d9fc31af21f5de5f222d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTA0ODIyNg==", "url": "https://github.com/apache/hadoop/pull/2229#discussion_r471048226", "bodyText": "The idea was, the first initialization should initing DFSClient as we may initialize vfs. Later if we failed to init vfs, then we will continue to initialize DfsClient to get regular DFS behavior.\nI corrected few things now and that may clear you things. Why I tried to init at first line was to make sure statistics initialized with correct class names. Otherwise I noticed, InternalViewFS also getting inited in statistics with hdfs scheme, that may create issues for the correctness..", "author": "umamaheswararao", "createdAt": "2020-08-16T00:34:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkzNDYwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkzNDk5OQ==", "url": "https://github.com/apache/hadoop/pull/2229#discussion_r470934999", "bodyText": "Does this make having a fallback mandatory and that too, to HDFS? May be people would want to have a different FS fallback, or not have a fallback, and they might not be using non-path API's as well. Can't we just not throw UnsupportedOperationException if defaultDFS is null?", "author": "ayushtkn", "createdAt": "2020-08-15T04:12:26Z", "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/ViewDistributedFileSystem.java", "diffHunk": "@@ -0,0 +1,1864 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.hadoop.HadoopIllegalArgumentException;\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.crypto.key.KeyProvider;\n+import org.apache.hadoop.fs.BlockLocation;\n+import org.apache.hadoop.fs.BlockStoragePolicySpi;\n+import org.apache.hadoop.fs.CacheFlag;\n+import org.apache.hadoop.fs.ContentSummary;\n+import org.apache.hadoop.fs.CreateFlag;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.FileChecksum;\n+import org.apache.hadoop.fs.FileEncryptionInfo;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.FsServerDefaults;\n+import org.apache.hadoop.fs.FsStatus;\n+import org.apache.hadoop.fs.LocatedFileStatus;\n+import org.apache.hadoop.fs.Options;\n+import org.apache.hadoop.fs.PartialListing;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.PathFilter;\n+import org.apache.hadoop.fs.PathHandle;\n+import org.apache.hadoop.fs.QuotaUsage;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.StorageType;\n+import org.apache.hadoop.fs.XAttrSetFlag;\n+import org.apache.hadoop.fs.permission.AclEntry;\n+import org.apache.hadoop.fs.permission.AclStatus;\n+import org.apache.hadoop.fs.permission.FsAction;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+import org.apache.hadoop.fs.viewfs.ViewFileSystem;\n+import org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme;\n+import org.apache.hadoop.hdfs.client.HdfsDataOutputStream;\n+import org.apache.hadoop.hdfs.protocol.AddErasureCodingPolicyResponse;\n+import org.apache.hadoop.hdfs.protocol.BlockStoragePolicy;\n+import org.apache.hadoop.hdfs.protocol.CacheDirectiveEntry;\n+import org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo;\n+import org.apache.hadoop.hdfs.protocol.CachePoolEntry;\n+import org.apache.hadoop.hdfs.protocol.CachePoolInfo;\n+import org.apache.hadoop.hdfs.protocol.DatanodeInfo;\n+import org.apache.hadoop.hdfs.protocol.ECTopologyVerifierResult;\n+import org.apache.hadoop.hdfs.protocol.EncryptionZone;\n+import org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy;\n+import org.apache.hadoop.hdfs.protocol.ErasureCodingPolicyInfo;\n+import org.apache.hadoop.hdfs.protocol.HdfsConstants;\n+import org.apache.hadoop.hdfs.protocol.HdfsPathHandle;\n+import org.apache.hadoop.hdfs.protocol.OpenFileEntry;\n+import org.apache.hadoop.hdfs.protocol.OpenFilesIterator;\n+import org.apache.hadoop.hdfs.protocol.RollingUpgradeInfo;\n+import org.apache.hadoop.hdfs.protocol.SnapshotDiffReport;\n+import org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing;\n+import org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus;\n+import org.apache.hadoop.hdfs.protocol.ZoneReencryptionStatus;\n+import org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenIdentifier;\n+import org.apache.hadoop.security.AccessControlException;\n+import org.apache.hadoop.security.token.DelegationTokenIssuer;\n+import org.apache.hadoop.security.token.Token;\n+import org.apache.hadoop.util.Progressable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+\n+import java.net.InetSocketAddress;\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.EnumSet;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * The ViewDistributedFileSystem is an extended class to DistributedFileSystem\n+ * with additional mounting functionality. The goal is to have better API\n+ * compatibility for HDFS users when using mounting\n+ * filesystem(ViewFileSystemOverloadScheme).\n+ * The ViewFileSystemOverloadScheme{@link ViewFileSystemOverloadScheme} is a new\n+ * filesystem with inherited mounting functionality from ViewFileSystem.\n+ * For the user who is using ViewFileSystemOverloadScheme by setting\n+ * fs.hdfs.impl=org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme, now\n+ * they can set fs.hdfs.impl=org.apache.hadoop.hdfs.ViewDistributedFileSystem.\n+ * So, that the hdfs users will get closely compatible API with mount\n+ * functionality. For the rest of all other schemes can continue to use\n+ * ViewFileSystemOverloadScheme class directly for mount functionality. Please\n+ * note that ViewFileSystemOverloadScheme provides only\n+ * ViewFileSystem{@link ViewFileSystem} APIs.\n+ * If user configured this class but no mount point configured? Then it will\n+ * simply work as existing DistributedFileSystem class. If user configured both\n+ * fs.hdfs.impl to this class and mount configurations, then users will be able\n+ * to make calls the APIs available in this class, they are nothing but DFS\n+ * APIs, but they will be delegated to viewfs functionality. Please note, APIs\n+ * without any path in arguments( ex: isInSafeMode), will be delegated to\n+ * default filesystem only, that is the configured fallback link. If you want to\n+ * make these API calls on specific child filesystem, you may want to initialize\n+ * them separately and call. In ViewDistributedFileSystem, linkFallBack is\n+ * mandatory when you ass mount links and it must be to your base cluster,\n+ * usually your current fs.defaultFS if that's pointing to hdfs.\n+ */\n+public class ViewDistributedFileSystem extends DistributedFileSystem {\n+  private static final Logger LOGGER =\n+      LoggerFactory.getLogger(ViewDistributedFileSystem.class);\n+\n+  // A mounting file system.\n+  private ViewFileSystemOverloadScheme vfs;\n+  // A default DFS, which should have set via linkFallback\n+  private DistributedFileSystem defaultDFS;\n+\n+  @Override\n+  public void initialize(URI uri, Configuration conf) throws IOException {\n+    super.initialize(uri, conf);\n+    try {\n+      this.vfs = tryInitializeMountingViewFs(uri, conf);\n+    } catch (IOException ioe) {\n+      LOGGER.debug(\n+          \"Mount tree initialization failed with the reason => {}. Falling\" +\n+              \" back to regular DFS initialization. Please\" + \" re-initialize\" +\n+              \" the fs after updating mount point.\",\n+          ioe.getMessage());\n+      // Re-initialize, so that initDFSClient will initialize DFSClient to work\n+      // same as DistributedFileSystem.\n+      super.initialize(uri, conf);\n+      return;\n+    }\n+    setConf(conf);\n+    // A child DFS with the current initialized URI. This must be same as\n+    // fallback fs. The fallback must point to root of your filesystems.\n+    // Some APIs(without path in argument, for example isInSafeMode) will\n+    // support only for base cluster filesystem. Only that APIs will use this\n+    // fs.\n+    defaultDFS = (DistributedFileSystem) this.vfs.getFallbackFileSystem();\n+    Preconditions\n+        .checkNotNull(\"In ViewHDFS fallback link is mandatory.\", defaultDFS);\n+    // Please don't access internal dfs directly except in tests.", "originalCommit": "33902b0e36c9d1f41195d9fc31af21f5de5f222d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTA0ODUwNQ==", "url": "https://github.com/apache/hadoop/pull/2229#discussion_r471048505", "bodyText": "Why I tried to make this mandatory was, there are few APIs currently we are delegating to defaultfs. I am just worried we will have too many behaviors. :-)\nLet me think on it.", "author": "umamaheswararao", "createdAt": "2020-08-16T00:37:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkzNDk5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkzNTgwMQ==", "url": "https://github.com/apache/hadoop/pull/2229#discussion_r470935801", "bodyText": "Why are we removing this? The logic still stays, Namenode Can not get initialized with a Non-DFS filesystems? Will HDFS-15450, not resurface, if something ViewFileSystemOverloadScheme is configured, not this new one?\nIt shouldn't be done with new one available, but still we should have logics to handle if not", "author": "ayushtkn", "createdAt": "2020-08-15T04:23:04Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java", "diffHunk": "@@ -727,11 +727,6 @@ protected void initialize(Configuration conf) throws IOException {\n           intervals);\n       }\n     }\n-    // Currently NN uses FileSystem.get to initialize DFS in startTrashEmptier.\n-    // If fs.hdfs.impl was overridden by core-site.xml, we may get other\n-    // filesystem. To make sure we get DFS, we are setting fs.hdfs.impl to DFS.\n-    // HDFS-15450\n-    conf.set(FS_HDFS_IMPL_KEY, DistributedFileSystem.class.getName());", "originalCommit": "33902b0e36c9d1f41195d9fc31af21f5de5f222d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTA0ODYyOQ==", "url": "https://github.com/apache/hadoop/pull/2229#discussion_r471048629", "bodyText": "Actually in ViewFileSystemOverloadScheme, we started auto assigning fallback link. So, we will have at least one link so, NN side init will succeed with that behavior. The tests added in HDFS-15450 passes now even with removing above line.", "author": "umamaheswararao", "createdAt": "2020-08-16T00:39:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkzNTgwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTA4NDMwMg==", "url": "https://github.com/apache/hadoop/pull/2229#discussion_r471084302", "bodyText": "Should be fine then, Thanx", "author": "ayushtkn", "createdAt": "2020-08-16T08:37:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkzNTgwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkzNzUwNA==", "url": "https://github.com/apache/hadoop/pull/2229#discussion_r470937504", "bodyText": "Can give result from DefaultDFS?\nIf not, correct the API name", "author": "ayushtkn", "createdAt": "2020-08-15T04:45:52Z", "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/ViewDistributedFileSystem.java", "diffHunk": "@@ -0,0 +1,1864 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.hadoop.HadoopIllegalArgumentException;\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.crypto.key.KeyProvider;\n+import org.apache.hadoop.fs.BlockLocation;\n+import org.apache.hadoop.fs.BlockStoragePolicySpi;\n+import org.apache.hadoop.fs.CacheFlag;\n+import org.apache.hadoop.fs.ContentSummary;\n+import org.apache.hadoop.fs.CreateFlag;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.FileChecksum;\n+import org.apache.hadoop.fs.FileEncryptionInfo;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.FsServerDefaults;\n+import org.apache.hadoop.fs.FsStatus;\n+import org.apache.hadoop.fs.LocatedFileStatus;\n+import org.apache.hadoop.fs.Options;\n+import org.apache.hadoop.fs.PartialListing;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.PathFilter;\n+import org.apache.hadoop.fs.PathHandle;\n+import org.apache.hadoop.fs.QuotaUsage;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.StorageType;\n+import org.apache.hadoop.fs.XAttrSetFlag;\n+import org.apache.hadoop.fs.permission.AclEntry;\n+import org.apache.hadoop.fs.permission.AclStatus;\n+import org.apache.hadoop.fs.permission.FsAction;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+import org.apache.hadoop.fs.viewfs.ViewFileSystem;\n+import org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme;\n+import org.apache.hadoop.hdfs.client.HdfsDataOutputStream;\n+import org.apache.hadoop.hdfs.protocol.AddErasureCodingPolicyResponse;\n+import org.apache.hadoop.hdfs.protocol.BlockStoragePolicy;\n+import org.apache.hadoop.hdfs.protocol.CacheDirectiveEntry;\n+import org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo;\n+import org.apache.hadoop.hdfs.protocol.CachePoolEntry;\n+import org.apache.hadoop.hdfs.protocol.CachePoolInfo;\n+import org.apache.hadoop.hdfs.protocol.DatanodeInfo;\n+import org.apache.hadoop.hdfs.protocol.ECTopologyVerifierResult;\n+import org.apache.hadoop.hdfs.protocol.EncryptionZone;\n+import org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy;\n+import org.apache.hadoop.hdfs.protocol.ErasureCodingPolicyInfo;\n+import org.apache.hadoop.hdfs.protocol.HdfsConstants;\n+import org.apache.hadoop.hdfs.protocol.HdfsPathHandle;\n+import org.apache.hadoop.hdfs.protocol.OpenFileEntry;\n+import org.apache.hadoop.hdfs.protocol.OpenFilesIterator;\n+import org.apache.hadoop.hdfs.protocol.RollingUpgradeInfo;\n+import org.apache.hadoop.hdfs.protocol.SnapshotDiffReport;\n+import org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing;\n+import org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus;\n+import org.apache.hadoop.hdfs.protocol.ZoneReencryptionStatus;\n+import org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenIdentifier;\n+import org.apache.hadoop.security.AccessControlException;\n+import org.apache.hadoop.security.token.DelegationTokenIssuer;\n+import org.apache.hadoop.security.token.Token;\n+import org.apache.hadoop.util.Progressable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+\n+import java.net.InetSocketAddress;\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.EnumSet;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * The ViewDistributedFileSystem is an extended class to DistributedFileSystem\n+ * with additional mounting functionality. The goal is to have better API\n+ * compatibility for HDFS users when using mounting\n+ * filesystem(ViewFileSystemOverloadScheme).\n+ * The ViewFileSystemOverloadScheme{@link ViewFileSystemOverloadScheme} is a new\n+ * filesystem with inherited mounting functionality from ViewFileSystem.\n+ * For the user who is using ViewFileSystemOverloadScheme by setting\n+ * fs.hdfs.impl=org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme, now\n+ * they can set fs.hdfs.impl=org.apache.hadoop.hdfs.ViewDistributedFileSystem.\n+ * So, that the hdfs users will get closely compatible API with mount\n+ * functionality. For the rest of all other schemes can continue to use\n+ * ViewFileSystemOverloadScheme class directly for mount functionality. Please\n+ * note that ViewFileSystemOverloadScheme provides only\n+ * ViewFileSystem{@link ViewFileSystem} APIs.\n+ * If user configured this class but no mount point configured? Then it will\n+ * simply work as existing DistributedFileSystem class. If user configured both\n+ * fs.hdfs.impl to this class and mount configurations, then users will be able\n+ * to make calls the APIs available in this class, they are nothing but DFS\n+ * APIs, but they will be delegated to viewfs functionality. Please note, APIs\n+ * without any path in arguments( ex: isInSafeMode), will be delegated to\n+ * default filesystem only, that is the configured fallback link. If you want to\n+ * make these API calls on specific child filesystem, you may want to initialize\n+ * them separately and call. In ViewDistributedFileSystem, linkFallBack is\n+ * mandatory when you ass mount links and it must be to your base cluster,\n+ * usually your current fs.defaultFS if that's pointing to hdfs.\n+ */\n+public class ViewDistributedFileSystem extends DistributedFileSystem {\n+  private static final Logger LOGGER =\n+      LoggerFactory.getLogger(ViewDistributedFileSystem.class);\n+\n+  // A mounting file system.\n+  private ViewFileSystemOverloadScheme vfs;\n+  // A default DFS, which should have set via linkFallback\n+  private DistributedFileSystem defaultDFS;\n+\n+  @Override\n+  public void initialize(URI uri, Configuration conf) throws IOException {\n+    super.initialize(uri, conf);\n+    try {\n+      this.vfs = tryInitializeMountingViewFs(uri, conf);\n+    } catch (IOException ioe) {\n+      LOGGER.debug(\n+          \"Mount tree initialization failed with the reason => {}. Falling\" +\n+              \" back to regular DFS initialization. Please\" + \" re-initialize\" +\n+              \" the fs after updating mount point.\",\n+          ioe.getMessage());\n+      // Re-initialize, so that initDFSClient will initialize DFSClient to work\n+      // same as DistributedFileSystem.\n+      super.initialize(uri, conf);\n+      return;\n+    }\n+    setConf(conf);\n+    // A child DFS with the current initialized URI. This must be same as\n+    // fallback fs. The fallback must point to root of your filesystems.\n+    // Some APIs(without path in argument, for example isInSafeMode) will\n+    // support only for base cluster filesystem. Only that APIs will use this\n+    // fs.\n+    defaultDFS = (DistributedFileSystem) this.vfs.getFallbackFileSystem();\n+    Preconditions\n+        .checkNotNull(\"In ViewHDFS fallback link is mandatory.\", defaultDFS);\n+    // Please don't access internal dfs directly except in tests.\n+    dfs = defaultDFS.dfs;\n+  }\n+\n+  @Override\n+  DFSClient initDFSClient(URI uri, Configuration conf) throws IOException {\n+    if(this.vfs==null) {\n+      return super.initDFSClient(uri, conf);\n+    }\n+    return null;\n+  }\n+\n+  public ViewDistributedFileSystem() {\n+  }\n+\n+  private ViewFileSystemOverloadScheme tryInitializeMountingViewFs(URI uri,\n+      Configuration conf) throws IOException {\n+    ViewFileSystemOverloadScheme vfs = new ViewFileSystemOverloadScheme();\n+    vfs.setSupportAutoAddingFallbackOnNoMounts(false);\n+    vfs.initialize(uri, conf);\n+    return vfs;\n+  }\n+\n+  @Override\n+  public URI getUri() {\n+    if (this.vfs == null) {\n+      return super.getUri();\n+    }\n+    return this.vfs.getUri();\n+  }\n+\n+  @Override\n+  public String getScheme() {\n+    if (this.vfs == null) {\n+      return super.getScheme();\n+    }\n+    return this.vfs.getScheme();\n+  }\n+\n+  @Override\n+  public Path getWorkingDirectory() {\n+    if (this.vfs == null) {\n+      return super.getWorkingDirectory();\n+    }\n+    return this.vfs.getWorkingDirectory();\n+  }\n+\n+  @Override\n+  public void setWorkingDirectory(Path dir) {\n+    if (this.vfs == null) {\n+      super.setWorkingDirectory(dir);\n+      return;\n+    }\n+    this.vfs.setWorkingDirectory(dir);\n+  }\n+\n+  @Override\n+  public Path getHomeDirectory() {\n+    if (this.vfs == null) {\n+      return super.getHomeDirectory();\n+    }\n+    return this.vfs.getHomeDirectory();\n+  }\n+\n+  @Override\n+  /**\n+   * Returns only default cluster getHedgedReadMetrics.\n+   */ public DFSHedgedReadMetrics getHedgedReadMetrics() {\n+     if(this.vfs==null){\n+       return super.getHedgedReadMetrics();\n+     }\n+    return defaultDFS.getHedgedReadMetrics();\n+  }\n+\n+  @Override\n+  public BlockLocation[] getFileBlockLocations(FileStatus fs, long start,\n+      long len) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getFileBlockLocations(fs, start, len);\n+    }\n+    return this.vfs.getFileBlockLocations(fs, start, len);\n+  }\n+\n+  @Override\n+  public BlockLocation[] getFileBlockLocations(Path p, final long start,\n+      final long len) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getFileBlockLocations(p, start, len);\n+    }\n+    return this.vfs.getFileBlockLocations(p, start, len);\n+  }\n+\n+  @Override\n+  public void setVerifyChecksum(final boolean verifyChecksum) {\n+    if (this.vfs == null) {\n+      super.setVerifyChecksum(verifyChecksum);\n+      return;\n+    }\n+    this.vfs.setVerifyChecksum(verifyChecksum);\n+  }\n+\n+  @Override\n+  public boolean recoverLease(final Path f) throws IOException {\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"recoverLease\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .recoverLease(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public FSDataInputStream open(final Path f, final int bufferSize)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.open(f, bufferSize);\n+    }\n+\n+    return this.vfs.open(f, bufferSize);\n+  }\n+\n+  @Override\n+  public FSDataInputStream open(PathHandle fd, int bufferSize)\n+      throws IOException {\n+    return this.vfs.open(fd, bufferSize);\n+  }\n+\n+  @Override\n+  protected HdfsPathHandle createPathHandle(FileStatus st,\n+      Options.HandleOpt... opts) {\n+    if (this.vfs == null) {\n+      return super.createPathHandle(st, opts);\n+    }\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public FSDataOutputStream append(final Path f, final int bufferSize,\n+      final Progressable progress) throws IOException {\n+    if (this.vfs == null) {\n+      return super.append(f, bufferSize, progress);\n+    }\n+    return this.vfs.append(f, bufferSize, progress);\n+  }\n+\n+  @Override\n+  public FSDataOutputStream append(Path f, final EnumSet<CreateFlag> flag,\n+      final int bufferSize, final Progressable progress) throws IOException {\n+    if (this.vfs == null) {\n+      return super.append(f, flag, bufferSize, progress);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"append\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .append(mountPathInfo.getPathOnTarget(), flag, bufferSize, progress);\n+  }\n+\n+  @Override\n+  public FSDataOutputStream append(Path f, final EnumSet<CreateFlag> flag,\n+      final int bufferSize, final Progressable progress,\n+      final InetSocketAddress[] favoredNodes) throws IOException {\n+    if (this.vfs == null) {\n+      return super.append(f, flag, bufferSize, progress, favoredNodes);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"append\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .append(mountPathInfo.getPathOnTarget(), flag, bufferSize, progress,\n+            favoredNodes);\n+  }\n+\n+  @Override\n+  public FSDataOutputStream create(Path f, FsPermission permission,\n+      boolean overwrite, int bufferSize, short replication, long blockSize,\n+      Progressable progress) throws IOException {\n+    if (this.vfs == null) {\n+      return super\n+          .create(f, permission, overwrite, bufferSize, replication, blockSize,\n+              progress);\n+    }\n+    return this.vfs\n+        .create(f, permission, overwrite, bufferSize, replication, blockSize,\n+            progress);\n+  }\n+\n+  @Override\n+  public HdfsDataOutputStream create(final Path f,\n+      final FsPermission permission, final boolean overwrite,\n+      final int bufferSize, final short replication, final long blockSize,\n+      final Progressable progress, final InetSocketAddress[] favoredNodes)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super\n+          .create(f, permission, overwrite, bufferSize, replication, blockSize,\n+              progress, favoredNodes);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"create\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .create(mountPathInfo.getPathOnTarget(), permission, overwrite,\n+            bufferSize, replication, blockSize, progress, favoredNodes);\n+  }\n+\n+  @Override\n+  //DFS specific API\n+  public FSDataOutputStream create(final Path f, final FsPermission permission,\n+      final EnumSet<CreateFlag> cflags, final int bufferSize,\n+      final short replication, final long blockSize,\n+      final Progressable progress, final Options.ChecksumOpt checksumOpt)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super\n+          .create(f, permission, cflags, bufferSize, replication, blockSize,\n+              progress, checksumOpt);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"create\");\n+    return mountPathInfo.getTargetFs()\n+        .create(mountPathInfo.getPathOnTarget(), permission, cflags, bufferSize,\n+            replication, blockSize, progress, checksumOpt);\n+  }\n+\n+  void checkDFS(FileSystem fs, String methodName) {\n+    if (!(fs instanceof DistributedFileSystem)) {\n+      throw new UnsupportedOperationException(\n+          \"This API:\" + methodName + \" is specific to DFS. Can't run on other fs:\" + fs\n+              .getUri());\n+    }\n+  }\n+\n+  @Override\n+  // DFS specific API\n+  protected HdfsDataOutputStream primitiveCreate(Path f,\n+      FsPermission absolutePermission, EnumSet<CreateFlag> flag, int bufferSize,\n+      short replication, long blockSize, Progressable progress,\n+      Options.ChecksumOpt checksumOpt) throws IOException {\n+    if (this.vfs == null) {\n+      return super\n+          .primitiveCreate(f, absolutePermission, flag, bufferSize, replication,\n+              blockSize, progress, checksumOpt);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"primitiveCreate\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .primitiveCreate(f, absolutePermission, flag, bufferSize, replication,\n+            blockSize, progress, checksumOpt);\n+  }\n+\n+  @Override\n+  public FSDataOutputStream createNonRecursive(Path f, FsPermission permission,\n+      EnumSet<CreateFlag> flags, int bufferSize, short replication,\n+      long blockSize, Progressable progress) throws IOException {\n+    if (this.vfs == null) {\n+      return super\n+          .createNonRecursive(f, permission, flags, bufferSize, replication,\n+              bufferSize, progress);\n+    }\n+    return this.vfs\n+        .createNonRecursive(f, permission, flags, bufferSize, replication,\n+            bufferSize, progress);\n+  }\n+\n+  @Override\n+  public boolean setReplication(final Path f, final short replication)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.setReplication(f, replication);\n+    }\n+    return this.vfs.setReplication(f, replication);\n+  }\n+\n+  @Override\n+  public void setStoragePolicy(Path src, String policyName) throws IOException {\n+    if (this.vfs == null) {\n+      super.setStoragePolicy(src, policyName);\n+      return;\n+    }\n+    this.vfs.setStoragePolicy(src, policyName);\n+  }\n+\n+  @Override\n+  public void unsetStoragePolicy(Path src) throws IOException {\n+    if (this.vfs == null) {\n+      super.unsetStoragePolicy(src);\n+      return;\n+    }\n+    this.vfs.unsetStoragePolicy(src);\n+  }\n+\n+  @Override\n+  public BlockStoragePolicySpi getStoragePolicy(Path src) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getStoragePolicy(src);\n+    }\n+    return this.vfs.getStoragePolicy(src);\n+  }\n+\n+  @Override\n+  public Collection<BlockStoragePolicy> getAllStoragePolicies()\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getAllStoragePolicies();\n+    }\n+    Collection<? extends BlockStoragePolicySpi> allStoragePolicies =\n+        this.vfs.getAllStoragePolicies();\n+    return (Collection<BlockStoragePolicy>) allStoragePolicies;\n+  }\n+\n+  @Override\n+  public long getBytesWithFutureGenerationStamps() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getBytesWithFutureGenerationStamps();\n+    }\n+    return defaultDFS.getBytesWithFutureGenerationStamps();\n+  }\n+\n+  @Deprecated\n+  @Override\n+  public BlockStoragePolicy[] getStoragePolicies() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getStoragePolicies();\n+    }\n+    return defaultDFS.getStoragePolicies();\n+  }\n+\n+  @Override\n+  //Make sure your target fs supports this API, otherwise you will get\n+  // Unsupported operation exception.\n+  public void concat(Path trg, Path[] psrcs) throws IOException {\n+    if (this.vfs == null) {\n+      super.concat(trg, psrcs);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(trg, getConf());\n+    mountPathInfo.getTargetFs().concat(mountPathInfo.getPathOnTarget(), psrcs);\n+  }\n+\n+  @SuppressWarnings(\"deprecation\")\n+  @Override\n+  public boolean rename(final Path src, final Path dst) throws IOException {\n+    if (this.vfs == null) {\n+      return super.rename(src, dst);\n+    }\n+    if (getMountPoints().length == 0) {\n+      return this.defaultDFS.rename(src, dst);\n+    }\n+    return this.vfs.rename(src, dst);\n+  }\n+\n+  @SuppressWarnings(\"deprecation\")\n+  @Override\n+  public void rename(Path src, Path dst, final Options.Rename... options)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      super.rename(src, dst, options);\n+      return;\n+    }\n+\n+    // TODO: revisit\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountSrcPathInfo =\n+        this.vfs.getMountPathInfo(src, getConf());\n+    checkDFS(mountSrcPathInfo.getTargetFs(), \"rename\");\n+\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountDstPathInfo =\n+        this.vfs.getMountPathInfo(src, getConf());\n+    checkDFS(mountDstPathInfo.getTargetFs(), \"rename\");\n+\n+    //Check both in same cluster.\n+    if (!mountSrcPathInfo.getTargetFs().getUri()\n+        .equals(mountDstPathInfo.getTargetFs().getUri())) {\n+      throw new HadoopIllegalArgumentException(\n+          \"Can't rename across file systems.\");\n+    }\n+\n+    ((DistributedFileSystem) mountSrcPathInfo.getTargetFs())\n+        .rename(mountSrcPathInfo.getPathOnTarget(),\n+            mountDstPathInfo.getPathOnTarget(), options);\n+  }\n+\n+  @Override\n+  public boolean truncate(final Path f, final long newLength)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.truncate(f, newLength);\n+    }\n+    return this.vfs.truncate(f, newLength);\n+  }\n+\n+  public boolean delete(final Path f, final boolean recursive)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.delete(f, recursive);\n+    }\n+    return this.vfs.delete(f, recursive);\n+  }\n+\n+  @Override\n+  public ContentSummary getContentSummary(Path f) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getContentSummary(f);\n+    }\n+    return this.vfs.getContentSummary(f);\n+  }\n+\n+  @Override\n+  public QuotaUsage getQuotaUsage(Path f) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getQuotaUsage(f);\n+    }\n+    return this.vfs.getQuotaUsage(f);\n+  }\n+\n+  @Override\n+  public void setQuota(Path src, final long namespaceQuota,\n+      final long storagespaceQuota) throws IOException {\n+    if (this.vfs == null) {\n+      super.setQuota(src, namespaceQuota, storagespaceQuota);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(src, getConf());\n+    mountPathInfo.getTargetFs()\n+        .setQuota(mountPathInfo.getPathOnTarget(), namespaceQuota,\n+            storagespaceQuota);\n+  }\n+\n+  @Override\n+  public void setQuotaByStorageType(Path src, final StorageType type,\n+      final long quota) throws IOException {\n+    if (this.vfs == null) {\n+      super.setQuotaByStorageType(src, type, quota);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(src, getConf());\n+    mountPathInfo.getTargetFs()\n+        .setQuotaByStorageType(mountPathInfo.getPathOnTarget(), type, quota);\n+  }\n+\n+  @Override\n+  public FileStatus[] listStatus(Path p) throws IOException {\n+    if (this.vfs == null) {\n+      return super.listStatus(p);\n+    }\n+    return this.vfs.listStatus(p);\n+  }\n+\n+  @Override\n+  public RemoteIterator<LocatedFileStatus> listLocatedStatus(final Path f,\n+      final PathFilter filter) throws FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.listLocatedStatus(f, filter);\n+    }\n+    return this.vfs.listLocatedStatus(f, filter);\n+  }\n+\n+  @Override\n+  public RemoteIterator<FileStatus> listStatusIterator(final Path p)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.listStatusIterator(p);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(p, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .listStatusIterator(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public RemoteIterator<PartialListing<FileStatus>> batchedListStatusIterator(\n+      final List<Path> paths) throws IOException {\n+    if (this.vfs == null) {\n+      return super.batchedListStatusIterator(paths);\n+    }\n+    // TODO: revisit for correct implementation.\n+    return this.defaultDFS.batchedListStatusIterator(paths);\n+  }\n+\n+  @Override\n+  public RemoteIterator<PartialListing<LocatedFileStatus>> batchedListLocatedStatusIterator(\n+      final List<Path> paths) throws IOException {\n+    if (this.vfs == null) {\n+      return super.batchedListLocatedStatusIterator(paths);\n+    }\n+    // TODO: revisit for correct implementation.\n+    return this.defaultDFS.batchedListLocatedStatusIterator(paths);\n+  }\n+\n+  public boolean mkdir(Path f, FsPermission permission) throws IOException {\n+    if (this.vfs == null) {\n+      return super.mkdir(f, permission);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"mkdir\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .mkdir(mountPathInfo.getPathOnTarget(), permission);\n+  }\n+\n+  @Override\n+  public boolean mkdirs(Path f, FsPermission permission) throws IOException {\n+    if (this.vfs == null) {\n+      return super.mkdirs(f, permission);\n+    }\n+    return this.vfs.mkdirs(f, permission);\n+  }\n+\n+  @SuppressWarnings(\"deprecation\")\n+  @Override\n+  protected boolean primitiveMkdir(Path f, FsPermission absolutePermission)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.primitiveMkdir(f, absolutePermission);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"primitiveMkdir\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .primitiveMkdir(mountPathInfo.getPathOnTarget(), absolutePermission);\n+  }\n+\n+  @Override\n+  public void close() throws IOException {\n+    if (this.vfs != null) {\n+      this.vfs.close();\n+    }\n+    super.close();\n+  }\n+\n+  @InterfaceAudience.Private\n+  public DFSClient getClient() {\n+    if (this.vfs == null) {\n+      return super.getClient();\n+    }\n+    return defaultDFS.getClient();\n+  }\n+\n+  @Override\n+  public FsStatus getStatus(Path p) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getStatus(p);\n+    }\n+    return this.vfs.getStatus(p);\n+  }\n+\n+  @Override\n+  public long getMissingBlocksCount() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getMissingBlocksCount();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getMissingBlocksCount is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public long getPendingDeletionBlocksCount() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getPendingDeletionBlocksCount();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getPendingDeletionBlocksCount is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public long getMissingReplOneBlocksCount() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getMissingReplOneBlocksCount();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getMissingReplOneBlocksCount is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public long getLowRedundancyBlocksCount() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getLowRedundancyBlocksCount();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getLowRedundancyBlocksCount is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public long getCorruptBlocksCount() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getCorruptBlocksCount();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getCorruptBlocksCount is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public RemoteIterator<Path> listCorruptFileBlocks(final Path path)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.listCorruptFileBlocks(path);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .listCorruptFileBlocks(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public DatanodeInfo[] getDataNodeStats() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getDataNodeStats();\n+    }\n+    return defaultDFS.getDataNodeStats();\n+  }\n+\n+  @Override\n+  public DatanodeInfo[] getDataNodeStats(\n+      final HdfsConstants.DatanodeReportType type) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getDataNodeStats(type);\n+    }\n+    return defaultDFS.getDataNodeStats(type);\n+  }\n+\n+  @Override\n+  public boolean setSafeMode(HdfsConstants.SafeModeAction action)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.setSafeMode(action);\n+    }\n+    return defaultDFS.setSafeMode(action);\n+  }\n+\n+  @Override\n+  public boolean setSafeMode(HdfsConstants.SafeModeAction action,\n+      boolean isChecked) throws IOException {\n+    if (this.vfs == null) {\n+      return super.setSafeMode(action, isChecked);\n+    }\n+    return defaultDFS.setSafeMode(action, isChecked);\n+  }\n+\n+  @Override\n+  public boolean saveNamespace(long timeWindow, long txGap) throws IOException {\n+    if (this.vfs == null) {\n+      return super.saveNamespace(timeWindow, txGap);\n+    }\n+    return defaultDFS.saveNamespace(timeWindow, txGap);\n+  }\n+\n+  @Override\n+  public void saveNamespace() throws IOException {\n+    if (this.vfs == null) {\n+      super.saveNamespace();\n+      return;\n+    }\n+    defaultDFS.saveNamespace();\n+  }\n+\n+  @Override\n+  public long rollEdits() throws IOException {\n+    if (this.vfs == null) {\n+      return super.rollEdits();\n+    }\n+    return defaultDFS.rollEdits();\n+  }\n+\n+  @Override\n+  public boolean restoreFailedStorage(String arg) throws IOException {\n+    if (this.vfs == null) {\n+      return super.restoreFailedStorage(arg);\n+    }\n+    return defaultDFS.restoreFailedStorage(arg);\n+  }\n+\n+  @Override\n+  public void refreshNodes() throws IOException {\n+    if (this.vfs == null) {\n+      super.refreshNodes();\n+      return;\n+    }\n+    defaultDFS.refreshNodes();\n+  }\n+\n+  @Override\n+  public void finalizeUpgrade() throws IOException {\n+    if (this.vfs == null) {\n+      super.finalizeUpgrade();\n+      return;\n+    }\n+    defaultDFS.finalizeUpgrade();\n+  }\n+\n+  @Override\n+  public boolean upgradeStatus() throws IOException {\n+    if (this.vfs == null) {\n+      return super.upgradeStatus();\n+    }\n+    return defaultDFS.upgradeStatus();\n+  }\n+\n+  @Override\n+  public RollingUpgradeInfo rollingUpgrade(\n+      HdfsConstants.RollingUpgradeAction action) throws IOException {\n+    if (this.vfs == null) {\n+      return super.rollingUpgrade(action);\n+    }\n+    return defaultDFS.rollingUpgrade(action);\n+  }\n+\n+  @Override\n+  public void metaSave(String pathname) throws IOException {\n+    if (this.vfs == null) {\n+      super.metaSave(pathname);\n+      return;\n+    }\n+    defaultDFS.metaSave(pathname);\n+  }\n+\n+  @Override\n+  public FsServerDefaults getServerDefaults() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getServerDefaults();\n+    }\n+    //TODO: Need to revisit.\n+    return defaultDFS.getServerDefaults();\n+  }\n+\n+  @Override\n+  public FileStatus getFileStatus(final Path f)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.getFileStatus(f);\n+    }\n+    return this.vfs.getFileStatus(f);\n+  }\n+\n+  @SuppressWarnings(\"deprecation\")\n+  @Override\n+  public void createSymlink(final Path target, final Path link,\n+      final boolean createParent) throws IOException {\n+     // Regular DFS behavior\n+    if (this.vfs == null) {\n+      super.createSymlink(target, link, createParent);\n+      return;\n+    }\n+\n+    // Mounting ViewHDFS behavior\n+    // TODO: revisit\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(target, getConf());\n+    mountPathInfo.getTargetFs()\n+        .createSymlink(mountPathInfo.getPathOnTarget(), link, createParent);\n+  }\n+\n+  @Override\n+  public boolean supportsSymlinks() {\n+    if (this.vfs == null) {\n+      return super.supportsSymlinks();\n+    }\n+    // TODO: we can enabled later if we want to support symlinks.\n+    return false;\n+  }\n+\n+  @Override\n+  public FileStatus getFileLinkStatus(final Path f) throws IOException {\n+     if(this.vfs==null){\n+       return super.getFileLinkStatus(f);\n+     }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .getFileLinkStatus(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public Path getLinkTarget(Path path) throws IOException {\n+    if(this.vfs==null){\n+      return super.getLinkTarget(path);\n+    }\n+    return this.vfs.getLinkTarget(path);\n+  }\n+\n+  @Override\n+  protected Path resolveLink(Path f) throws IOException {\n+    if(this.vfs==null){\n+      return super.resolveLink(f);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"resolveLink\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .resolveLink(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public FileChecksum getFileChecksum(final Path f)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.getFileChecksum(f);\n+    }\n+    return this.vfs.getFileChecksum(f);\n+  }\n+\n+  @Override\n+  public void setPermission(final Path f, final FsPermission permission)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      super.setPermission(f, permission);\n+      return;\n+    }\n+    this.vfs.setPermission(f, permission);\n+  }\n+\n+  @Override\n+  public void setOwner(final Path f, final String username,\n+      final String groupname)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      super.setOwner(f, username, groupname);\n+      return;\n+    }\n+    this.vfs.setOwner(f, username, groupname);\n+  }\n+\n+  @Override\n+  public void setTimes(final Path f, final long mtime, final long atime)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      super.setTimes(f, mtime, atime);\n+      return;\n+    }\n+    this.vfs.setTimes(f, mtime, atime);\n+  }\n+\n+  @Override\n+  // DFS specific API\n+  protected int getDefaultPort() {\n+    return super.getDefaultPort();\n+  }\n+\n+  @Override\n+  public Token<DelegationTokenIdentifier> getDelegationToken(String renewer)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getDelegationToken(renewer);\n+    }\n+    //Let applications call getDelegationTokenIssuers and get respective\n+    // delegation tokens from child fs.\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public void setBalancerBandwidth(long bandwidth) throws IOException {\n+    if (this.vfs == null) {\n+      super.setBalancerBandwidth(bandwidth);\n+      return;\n+    }\n+    defaultDFS.setBalancerBandwidth(bandwidth);\n+  }\n+\n+  @Override\n+  public String getCanonicalServiceName() {\n+    if (this.vfs == null) {\n+      return super.getCanonicalServiceName();\n+    }\n+    return defaultDFS.getCanonicalServiceName();\n+  }\n+\n+  @Override\n+  protected URI canonicalizeUri(URI uri) {\n+    if (this.vfs == null) {\n+      return super.canonicalizeUri(uri);\n+    }\n+\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo = null;\n+    try {\n+      mountPathInfo = this.vfs.getMountPathInfo(new Path(uri), getConf());\n+    } catch (IOException e) {\n+      //LOG.error(\"Failed to resolve the uri as mount path\", e);\n+      return null;\n+    }\n+    checkDFS(mountPathInfo.getTargetFs(), \"canonicalizeUri\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .canonicalizeUri(uri);\n+  }\n+\n+  @Override\n+  public boolean isInSafeMode() throws IOException {\n+    if (this.vfs == null) {\n+      return super.isInSafeMode();\n+    }\n+    return defaultDFS.isInSafeMode();\n+  }\n+\n+  @Override\n+  // DFS specific API\n+  public void allowSnapshot(Path path) throws IOException {\n+    if (this.vfs == null) {\n+      super.allowSnapshot(path);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"allowSnapshot\");\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .allowSnapshot(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public void disallowSnapshot(final Path path) throws IOException {\n+    if (this.vfs == null) {\n+      super.disallowSnapshot(path);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"disallowSnapshot\");\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .disallowSnapshot(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public Path createSnapshot(Path path, String snapshotName)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.createSnapshot(path, snapshotName);\n+    }\n+    return this.vfs.createSnapshot(path, snapshotName);\n+  }\n+\n+  @Override\n+  public void renameSnapshot(Path path, String snapshotOldName,\n+      String snapshotNewName) throws IOException {\n+    if (this.vfs == null) {\n+      super.renameSnapshot(path, snapshotOldName, snapshotOldName);\n+      return;\n+    }\n+    this.vfs.renameSnapshot(path, snapshotOldName, snapshotNewName);\n+  }\n+\n+  @Override\n+  //Ony for HDFS users\n+  public SnapshottableDirectoryStatus[] getSnapshottableDirListing()\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getSnapshottableDirListing();\n+    }\n+    return defaultDFS.getSnapshottableDirListing();\n+  }\n+\n+  @Override\n+  public void deleteSnapshot(Path path, String snapshotName)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      super.deleteSnapshot(path, snapshotName);\n+      return;\n+    }\n+    this.vfs.deleteSnapshot(path, snapshotName);\n+  }\n+\n+  @Override\n+  public RemoteIterator<SnapshotDiffReportListing> snapshotDiffReportListingRemoteIterator(\n+      final Path snapshotDir, final String fromSnapshot,\n+      final String toSnapshot) throws IOException {\n+     if(this.vfs ==null){\n+       return super.snapshotDiffReportListingRemoteIterator(snapshotDir, fromSnapshot,\n+           toSnapshot);\n+     }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(snapshotDir, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(),\n+        \"snapshotDiffReportListingRemoteIterator\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .snapshotDiffReportListingRemoteIterator(\n+            mountPathInfo.getPathOnTarget(), fromSnapshot, toSnapshot);\n+  }\n+\n+  @Override\n+  public SnapshotDiffReport getSnapshotDiffReport(final Path snapshotDir,\n+      final String fromSnapshot, final String toSnapshot) throws IOException {\n+    if(this.vfs ==null){\n+      return super.getSnapshotDiffReport(snapshotDir, fromSnapshot,\n+          toSnapshot);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(snapshotDir, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"getSnapshotDiffReport\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .getSnapshotDiffReport(snapshotDir, fromSnapshot,\n+            toSnapshot);\n+  }\n+\n+  @Override\n+  public boolean isFileClosed(final Path src) throws IOException {\n+    if (this.vfs == null) {\n+      return super.isFileClosed(src);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(src, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"isFileClosed\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .isFileClosed(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public long addCacheDirective(CacheDirectiveInfo info) throws IOException {\n+    if (this.vfs == null) {\n+      return super.addCacheDirective(info);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(info.getPath(), getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"addCacheDirective\");\n+\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .addCacheDirective(new CacheDirectiveInfo.Builder(info)\n+            .setPath(mountPathInfo.getPathOnTarget()).build());\n+  }\n+\n+  @Override\n+  public long addCacheDirective(CacheDirectiveInfo info,\n+      EnumSet<CacheFlag> flags) throws IOException {\n+    if (this.vfs == null) {\n+      return super.addCacheDirective(info, flags);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(info.getPath(), getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"addCacheDirective\");\n+\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .addCacheDirective(new CacheDirectiveInfo.Builder(info)\n+            .setPath(mountPathInfo.getPathOnTarget()).build(), flags);\n+  }\n+\n+  @Override\n+  public void modifyCacheDirective(CacheDirectiveInfo info) throws IOException {\n+    if (this.vfs == null) {\n+      super.modifyCacheDirective(info);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(info.getPath(), getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"modifyCacheDirective\");\n+\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs()).modifyCacheDirective(\n+        new CacheDirectiveInfo.Builder(info)\n+            .setPath(mountPathInfo.getPathOnTarget()).build());\n+  }\n+\n+  @Override\n+  public void modifyCacheDirective(CacheDirectiveInfo info,\n+      EnumSet<CacheFlag> flags) throws IOException {\n+    if (this.vfs == null) {\n+      super.modifyCacheDirective(info, flags);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(info.getPath(), getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"modifyCacheDirective\");\n+\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs()).modifyCacheDirective(\n+        new CacheDirectiveInfo.Builder(info)\n+            .setPath(mountPathInfo.getPathOnTarget()).build(), flags);\n+  }\n+\n+  @Override\n+  public void removeCacheDirective(long id) throws IOException {\n+    if (this.vfs == null) {\n+      super.removeCacheDirective(id);\n+      return;\n+    }\n+    //defaultDFS.removeCacheDirective(id);\n+    //TODO: ? this can create issues in default cluster\n+    // if user intention is to call on specific mount.\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public RemoteIterator<CacheDirectiveEntry> listCacheDirectives(\n+      CacheDirectiveInfo filter) throws IOException {\n+    if (this.vfs == null) {\n+      return super.listCacheDirectives(filter);\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listCacheDirectives is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public void addCachePool(CachePoolInfo info) throws IOException {\n+    if (this.vfs == null) {\n+      super.addCachePool(info);\n+      return;\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listCacheDirectives is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public void modifyCachePool(CachePoolInfo info) throws IOException {\n+    if (this.vfs == null) {\n+      super.modifyCachePool(info);\n+      return;\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listCacheDirectives is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public void removeCachePool(String poolName) throws IOException {\n+    if (this.vfs == null) {\n+      super.removeCachePool(poolName);\n+      return;\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listCacheDirectives is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public RemoteIterator<CachePoolEntry> listCachePools() throws IOException {\n+    if (this.vfs == null) {\n+      return super.listCachePools();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listCacheDirectives is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public void modifyAclEntries(Path path, List<AclEntry> aclSpec)\n+      throws IOException {\n+    this.vfs.modifyAclEntries(path, aclSpec);\n+  }\n+\n+  @Override\n+  public void removeAclEntries(Path path, List<AclEntry> aclSpec)\n+      throws IOException {\n+    this.vfs.removeAclEntries(path, aclSpec);\n+  }\n+\n+  @Override\n+  public void removeDefaultAcl(Path path) throws IOException {\n+    this.vfs.removeDefaultAcl(path);\n+  }\n+\n+  @Override\n+  public void removeAcl(Path path) throws IOException {\n+    this.vfs.removeAcl(path);\n+  }\n+\n+  @Override\n+  public void setAcl(Path path, List<AclEntry> aclSpec) throws IOException {\n+    if (this.vfs == null) {\n+      super.setAcl(path, aclSpec);\n+      return;\n+    }\n+    this.vfs.setAcl(path, aclSpec);\n+  }\n+\n+  @Override\n+  public AclStatus getAclStatus(Path path) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getAclStatus(path);\n+    }\n+    return this.vfs.getAclStatus(path);\n+  }\n+\n+  @Override\n+  public void createEncryptionZone(final Path path, final String keyName)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      super.createEncryptionZone(path, keyName);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"createEncryptionZone\");\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .createEncryptionZone(mountPathInfo.getPathOnTarget(), keyName);\n+  }\n+\n+  @Override\n+  public EncryptionZone getEZForPath(final Path path) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getEZForPath(path);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"getEZForPath\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .getEZForPath(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public RemoteIterator<EncryptionZone> listEncryptionZones()\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.listEncryptionZones();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listEncryptionZones is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public void reencryptEncryptionZone(final Path zone,\n+      final HdfsConstants.ReencryptAction action) throws IOException {\n+    if (this.vfs == null) {\n+      super.reencryptEncryptionZone(zone, action);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(zone, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"reencryptEncryptionZone\");\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .reencryptEncryptionZone(mountPathInfo.getPathOnTarget(), action);\n+  }\n+\n+  @Override\n+  public RemoteIterator<ZoneReencryptionStatus> listReencryptionStatus()\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.listReencryptionStatus();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listReencryptionStatus is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public FileEncryptionInfo getFileEncryptionInfo(final Path path)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getFileEncryptionInfo(path);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"getFileEncryptionInfo\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .getFileEncryptionInfo(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public void provisionEZTrash(final Path path,\n+      final FsPermission trashPermission) throws IOException {\n+    if (this.vfs == null) {\n+      super.provisionEZTrash(path, trashPermission);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"provisionEZTrash\");\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .provisionEZTrash(mountPathInfo.getPathOnTarget(), trashPermission);\n+  }\n+\n+  @Override\n+  public void setXAttr(Path path, String name, byte[] value,\n+      EnumSet<XAttrSetFlag> flag) throws IOException {\n+    if (this.vfs == null) {\n+      super.setXAttr(path, name, value, flag);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    mountPathInfo.getTargetFs()\n+        .setXAttr(mountPathInfo.getPathOnTarget(), name, value, flag);\n+  }\n+\n+  @Override\n+  public byte[] getXAttr(Path path, String name) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getXAttr(path, name);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .getXAttr(mountPathInfo.getPathOnTarget(), name);\n+  }\n+\n+  @Override\n+  public Map<String, byte[]> getXAttrs(Path path) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getXAttrs(path);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .getXAttrs(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public Map<String, byte[]> getXAttrs(Path path, List<String> names)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getXAttrs(path, names);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .getXAttrs(mountPathInfo.getPathOnTarget(), names);\n+  }\n+\n+  @Override\n+  public List<String> listXAttrs(Path path) throws IOException {\n+    if (this.vfs == null) {\n+      return super.listXAttrs(path);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .listXAttrs(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public void removeXAttr(Path path, String name) throws IOException {\n+    if (this.vfs == null) {\n+      super.removeXAttr(path, name);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    mountPathInfo.getTargetFs()\n+        .removeXAttr(mountPathInfo.getPathOnTarget(), name);\n+  }\n+\n+  @Override\n+  public void access(Path path, FsAction mode)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      super.access(path, mode);\n+      return;\n+    }\n+    this.vfs.access(path, mode);\n+  }\n+\n+  @Override\n+  public URI getKeyProviderUri() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getKeyProviderUri();\n+    }\n+    return defaultDFS.getKeyProviderUri();\n+  }\n+\n+  @Override\n+  public KeyProvider getKeyProvider() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getKeyProvider();\n+    }\n+    return defaultDFS.getKeyProvider();\n+  }\n+\n+  @Override\n+  public DelegationTokenIssuer[] getAdditionalTokenIssuers()\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getChildFileSystems();\n+    }\n+\n+    return this.vfs.getChildFileSystems();\n+  }\n+\n+  @Override\n+  public DFSInotifyEventInputStream getInotifyEventStream() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getInotifyEventStream();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getInotifyEventStream is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public DFSInotifyEventInputStream getInotifyEventStream(long lastReadTxid)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getInotifyEventStream();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getInotifyEventStream is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  // DFS only API.\n+  public void setErasureCodingPolicy(final Path path, final String ecPolicyName)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      super.setErasureCodingPolicy(path, ecPolicyName);\n+      return;\n+    }\n+\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"setErasureCodingPolicy\");\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .setErasureCodingPolicy(mountPathInfo.getPathOnTarget(), ecPolicyName);\n+  }\n+\n+  @Override\n+  public void satisfyStoragePolicy(Path src) throws IOException {\n+    if (this.vfs == null) {\n+      super.satisfyStoragePolicy(src);\n+      return;\n+    }\n+    this.vfs.satisfyStoragePolicy(src);\n+  }\n+\n+  @Override\n+  public ErasureCodingPolicy getErasureCodingPolicy(final Path path)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getErasureCodingPolicy(path);\n+    }\n+\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"getErasureCodingPolicy\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .getErasureCodingPolicy(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public Collection<ErasureCodingPolicyInfo> getAllErasureCodingPolicies()\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getAllErasureCodingPolicies();\n+    }\n+    return defaultDFS.getAllErasureCodingPolicies();\n+  }\n+\n+  @Override\n+  public Map<String, String> getAllErasureCodingCodecs() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getAllErasureCodingCodecs();\n+    }\n+    return defaultDFS.getAllErasureCodingCodecs();\n+  }\n+\n+  @Override\n+  public AddErasureCodingPolicyResponse[] addErasureCodingPolicies(\n+      ErasureCodingPolicy[] policies) throws IOException {\n+    if (this.vfs == null) {\n+      return super.addErasureCodingPolicies(policies);\n+    }\n+    return defaultDFS.addErasureCodingPolicies(policies);\n+  }\n+\n+  @Override\n+  public void removeErasureCodingPolicy(String ecPolicyName)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      super.removeErasureCodingPolicy(ecPolicyName);\n+      return;\n+    }\n+    defaultDFS.removeErasureCodingPolicy(ecPolicyName);\n+  }\n+\n+  @Override\n+  public void enableErasureCodingPolicy(String ecPolicyName)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      super.enableErasureCodingPolicy(ecPolicyName);\n+      return;\n+    }\n+    defaultDFS.enableErasureCodingPolicy(ecPolicyName);\n+  }\n+\n+  @Override\n+  public void disableErasureCodingPolicy(String ecPolicyName)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      super.disableErasureCodingPolicy(ecPolicyName);\n+      return;\n+    }\n+    defaultDFS.disableErasureCodingPolicy(ecPolicyName);\n+  }\n+\n+  @Override\n+  public void unsetErasureCodingPolicy(final Path path) throws IOException {\n+\n+    if (this.vfs == null) {\n+      super.unsetErasureCodingPolicy(path);\n+      return;\n+    }\n+\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"unsetErasureCodingPolicy\");\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .unsetErasureCodingPolicy(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public ECTopologyVerifierResult getECTopologyResultForPolicies(\n+      final String... policyNames) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getECTopologyResultForPolicies(policyNames);\n+    }\n+    throw new UnsupportedOperationException(\n+        \"unsetErasureCodingPolicy is not supported in ViewDFS\");\n+  }", "originalCommit": "33902b0e36c9d1f41195d9fc31af21f5de5f222d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTA0ODkxNw==", "url": "https://github.com/apache/hadoop/pull/2229#discussion_r471048917", "bodyText": "For now just delegated to defaultFS.", "author": "umamaheswararao", "createdAt": "2020-08-16T00:44:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkzNzUwNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkzNzc1Nw==", "url": "https://github.com/apache/hadoop/pull/2229#discussion_r470937757", "bodyText": "I doubt this. Shouldn't enable/disable/add/remove EC Policy go to all underlying child DFS rather than defaultDFS?", "author": "ayushtkn", "createdAt": "2020-08-15T04:49:41Z", "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/ViewDistributedFileSystem.java", "diffHunk": "@@ -0,0 +1,1864 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.hadoop.HadoopIllegalArgumentException;\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.crypto.key.KeyProvider;\n+import org.apache.hadoop.fs.BlockLocation;\n+import org.apache.hadoop.fs.BlockStoragePolicySpi;\n+import org.apache.hadoop.fs.CacheFlag;\n+import org.apache.hadoop.fs.ContentSummary;\n+import org.apache.hadoop.fs.CreateFlag;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.FileChecksum;\n+import org.apache.hadoop.fs.FileEncryptionInfo;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.FsServerDefaults;\n+import org.apache.hadoop.fs.FsStatus;\n+import org.apache.hadoop.fs.LocatedFileStatus;\n+import org.apache.hadoop.fs.Options;\n+import org.apache.hadoop.fs.PartialListing;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.PathFilter;\n+import org.apache.hadoop.fs.PathHandle;\n+import org.apache.hadoop.fs.QuotaUsage;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.StorageType;\n+import org.apache.hadoop.fs.XAttrSetFlag;\n+import org.apache.hadoop.fs.permission.AclEntry;\n+import org.apache.hadoop.fs.permission.AclStatus;\n+import org.apache.hadoop.fs.permission.FsAction;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+import org.apache.hadoop.fs.viewfs.ViewFileSystem;\n+import org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme;\n+import org.apache.hadoop.hdfs.client.HdfsDataOutputStream;\n+import org.apache.hadoop.hdfs.protocol.AddErasureCodingPolicyResponse;\n+import org.apache.hadoop.hdfs.protocol.BlockStoragePolicy;\n+import org.apache.hadoop.hdfs.protocol.CacheDirectiveEntry;\n+import org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo;\n+import org.apache.hadoop.hdfs.protocol.CachePoolEntry;\n+import org.apache.hadoop.hdfs.protocol.CachePoolInfo;\n+import org.apache.hadoop.hdfs.protocol.DatanodeInfo;\n+import org.apache.hadoop.hdfs.protocol.ECTopologyVerifierResult;\n+import org.apache.hadoop.hdfs.protocol.EncryptionZone;\n+import org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy;\n+import org.apache.hadoop.hdfs.protocol.ErasureCodingPolicyInfo;\n+import org.apache.hadoop.hdfs.protocol.HdfsConstants;\n+import org.apache.hadoop.hdfs.protocol.HdfsPathHandle;\n+import org.apache.hadoop.hdfs.protocol.OpenFileEntry;\n+import org.apache.hadoop.hdfs.protocol.OpenFilesIterator;\n+import org.apache.hadoop.hdfs.protocol.RollingUpgradeInfo;\n+import org.apache.hadoop.hdfs.protocol.SnapshotDiffReport;\n+import org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing;\n+import org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus;\n+import org.apache.hadoop.hdfs.protocol.ZoneReencryptionStatus;\n+import org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenIdentifier;\n+import org.apache.hadoop.security.AccessControlException;\n+import org.apache.hadoop.security.token.DelegationTokenIssuer;\n+import org.apache.hadoop.security.token.Token;\n+import org.apache.hadoop.util.Progressable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+\n+import java.net.InetSocketAddress;\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.EnumSet;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * The ViewDistributedFileSystem is an extended class to DistributedFileSystem\n+ * with additional mounting functionality. The goal is to have better API\n+ * compatibility for HDFS users when using mounting\n+ * filesystem(ViewFileSystemOverloadScheme).\n+ * The ViewFileSystemOverloadScheme{@link ViewFileSystemOverloadScheme} is a new\n+ * filesystem with inherited mounting functionality from ViewFileSystem.\n+ * For the user who is using ViewFileSystemOverloadScheme by setting\n+ * fs.hdfs.impl=org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme, now\n+ * they can set fs.hdfs.impl=org.apache.hadoop.hdfs.ViewDistributedFileSystem.\n+ * So, that the hdfs users will get closely compatible API with mount\n+ * functionality. For the rest of all other schemes can continue to use\n+ * ViewFileSystemOverloadScheme class directly for mount functionality. Please\n+ * note that ViewFileSystemOverloadScheme provides only\n+ * ViewFileSystem{@link ViewFileSystem} APIs.\n+ * If user configured this class but no mount point configured? Then it will\n+ * simply work as existing DistributedFileSystem class. If user configured both\n+ * fs.hdfs.impl to this class and mount configurations, then users will be able\n+ * to make calls the APIs available in this class, they are nothing but DFS\n+ * APIs, but they will be delegated to viewfs functionality. Please note, APIs\n+ * without any path in arguments( ex: isInSafeMode), will be delegated to\n+ * default filesystem only, that is the configured fallback link. If you want to\n+ * make these API calls on specific child filesystem, you may want to initialize\n+ * them separately and call. In ViewDistributedFileSystem, linkFallBack is\n+ * mandatory when you ass mount links and it must be to your base cluster,\n+ * usually your current fs.defaultFS if that's pointing to hdfs.\n+ */\n+public class ViewDistributedFileSystem extends DistributedFileSystem {\n+  private static final Logger LOGGER =\n+      LoggerFactory.getLogger(ViewDistributedFileSystem.class);\n+\n+  // A mounting file system.\n+  private ViewFileSystemOverloadScheme vfs;\n+  // A default DFS, which should have set via linkFallback\n+  private DistributedFileSystem defaultDFS;\n+\n+  @Override\n+  public void initialize(URI uri, Configuration conf) throws IOException {\n+    super.initialize(uri, conf);\n+    try {\n+      this.vfs = tryInitializeMountingViewFs(uri, conf);\n+    } catch (IOException ioe) {\n+      LOGGER.debug(\n+          \"Mount tree initialization failed with the reason => {}. Falling\" +\n+              \" back to regular DFS initialization. Please\" + \" re-initialize\" +\n+              \" the fs after updating mount point.\",\n+          ioe.getMessage());\n+      // Re-initialize, so that initDFSClient will initialize DFSClient to work\n+      // same as DistributedFileSystem.\n+      super.initialize(uri, conf);\n+      return;\n+    }\n+    setConf(conf);\n+    // A child DFS with the current initialized URI. This must be same as\n+    // fallback fs. The fallback must point to root of your filesystems.\n+    // Some APIs(without path in argument, for example isInSafeMode) will\n+    // support only for base cluster filesystem. Only that APIs will use this\n+    // fs.\n+    defaultDFS = (DistributedFileSystem) this.vfs.getFallbackFileSystem();\n+    Preconditions\n+        .checkNotNull(\"In ViewHDFS fallback link is mandatory.\", defaultDFS);\n+    // Please don't access internal dfs directly except in tests.\n+    dfs = defaultDFS.dfs;\n+  }\n+\n+  @Override\n+  DFSClient initDFSClient(URI uri, Configuration conf) throws IOException {\n+    if(this.vfs==null) {\n+      return super.initDFSClient(uri, conf);\n+    }\n+    return null;\n+  }\n+\n+  public ViewDistributedFileSystem() {\n+  }\n+\n+  private ViewFileSystemOverloadScheme tryInitializeMountingViewFs(URI uri,\n+      Configuration conf) throws IOException {\n+    ViewFileSystemOverloadScheme vfs = new ViewFileSystemOverloadScheme();\n+    vfs.setSupportAutoAddingFallbackOnNoMounts(false);\n+    vfs.initialize(uri, conf);\n+    return vfs;\n+  }\n+\n+  @Override\n+  public URI getUri() {\n+    if (this.vfs == null) {\n+      return super.getUri();\n+    }\n+    return this.vfs.getUri();\n+  }\n+\n+  @Override\n+  public String getScheme() {\n+    if (this.vfs == null) {\n+      return super.getScheme();\n+    }\n+    return this.vfs.getScheme();\n+  }\n+\n+  @Override\n+  public Path getWorkingDirectory() {\n+    if (this.vfs == null) {\n+      return super.getWorkingDirectory();\n+    }\n+    return this.vfs.getWorkingDirectory();\n+  }\n+\n+  @Override\n+  public void setWorkingDirectory(Path dir) {\n+    if (this.vfs == null) {\n+      super.setWorkingDirectory(dir);\n+      return;\n+    }\n+    this.vfs.setWorkingDirectory(dir);\n+  }\n+\n+  @Override\n+  public Path getHomeDirectory() {\n+    if (this.vfs == null) {\n+      return super.getHomeDirectory();\n+    }\n+    return this.vfs.getHomeDirectory();\n+  }\n+\n+  @Override\n+  /**\n+   * Returns only default cluster getHedgedReadMetrics.\n+   */ public DFSHedgedReadMetrics getHedgedReadMetrics() {\n+     if(this.vfs==null){\n+       return super.getHedgedReadMetrics();\n+     }\n+    return defaultDFS.getHedgedReadMetrics();\n+  }\n+\n+  @Override\n+  public BlockLocation[] getFileBlockLocations(FileStatus fs, long start,\n+      long len) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getFileBlockLocations(fs, start, len);\n+    }\n+    return this.vfs.getFileBlockLocations(fs, start, len);\n+  }\n+\n+  @Override\n+  public BlockLocation[] getFileBlockLocations(Path p, final long start,\n+      final long len) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getFileBlockLocations(p, start, len);\n+    }\n+    return this.vfs.getFileBlockLocations(p, start, len);\n+  }\n+\n+  @Override\n+  public void setVerifyChecksum(final boolean verifyChecksum) {\n+    if (this.vfs == null) {\n+      super.setVerifyChecksum(verifyChecksum);\n+      return;\n+    }\n+    this.vfs.setVerifyChecksum(verifyChecksum);\n+  }\n+\n+  @Override\n+  public boolean recoverLease(final Path f) throws IOException {\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"recoverLease\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .recoverLease(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public FSDataInputStream open(final Path f, final int bufferSize)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.open(f, bufferSize);\n+    }\n+\n+    return this.vfs.open(f, bufferSize);\n+  }\n+\n+  @Override\n+  public FSDataInputStream open(PathHandle fd, int bufferSize)\n+      throws IOException {\n+    return this.vfs.open(fd, bufferSize);\n+  }\n+\n+  @Override\n+  protected HdfsPathHandle createPathHandle(FileStatus st,\n+      Options.HandleOpt... opts) {\n+    if (this.vfs == null) {\n+      return super.createPathHandle(st, opts);\n+    }\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public FSDataOutputStream append(final Path f, final int bufferSize,\n+      final Progressable progress) throws IOException {\n+    if (this.vfs == null) {\n+      return super.append(f, bufferSize, progress);\n+    }\n+    return this.vfs.append(f, bufferSize, progress);\n+  }\n+\n+  @Override\n+  public FSDataOutputStream append(Path f, final EnumSet<CreateFlag> flag,\n+      final int bufferSize, final Progressable progress) throws IOException {\n+    if (this.vfs == null) {\n+      return super.append(f, flag, bufferSize, progress);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"append\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .append(mountPathInfo.getPathOnTarget(), flag, bufferSize, progress);\n+  }\n+\n+  @Override\n+  public FSDataOutputStream append(Path f, final EnumSet<CreateFlag> flag,\n+      final int bufferSize, final Progressable progress,\n+      final InetSocketAddress[] favoredNodes) throws IOException {\n+    if (this.vfs == null) {\n+      return super.append(f, flag, bufferSize, progress, favoredNodes);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"append\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .append(mountPathInfo.getPathOnTarget(), flag, bufferSize, progress,\n+            favoredNodes);\n+  }\n+\n+  @Override\n+  public FSDataOutputStream create(Path f, FsPermission permission,\n+      boolean overwrite, int bufferSize, short replication, long blockSize,\n+      Progressable progress) throws IOException {\n+    if (this.vfs == null) {\n+      return super\n+          .create(f, permission, overwrite, bufferSize, replication, blockSize,\n+              progress);\n+    }\n+    return this.vfs\n+        .create(f, permission, overwrite, bufferSize, replication, blockSize,\n+            progress);\n+  }\n+\n+  @Override\n+  public HdfsDataOutputStream create(final Path f,\n+      final FsPermission permission, final boolean overwrite,\n+      final int bufferSize, final short replication, final long blockSize,\n+      final Progressable progress, final InetSocketAddress[] favoredNodes)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super\n+          .create(f, permission, overwrite, bufferSize, replication, blockSize,\n+              progress, favoredNodes);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"create\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .create(mountPathInfo.getPathOnTarget(), permission, overwrite,\n+            bufferSize, replication, blockSize, progress, favoredNodes);\n+  }\n+\n+  @Override\n+  //DFS specific API\n+  public FSDataOutputStream create(final Path f, final FsPermission permission,\n+      final EnumSet<CreateFlag> cflags, final int bufferSize,\n+      final short replication, final long blockSize,\n+      final Progressable progress, final Options.ChecksumOpt checksumOpt)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super\n+          .create(f, permission, cflags, bufferSize, replication, blockSize,\n+              progress, checksumOpt);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"create\");\n+    return mountPathInfo.getTargetFs()\n+        .create(mountPathInfo.getPathOnTarget(), permission, cflags, bufferSize,\n+            replication, blockSize, progress, checksumOpt);\n+  }\n+\n+  void checkDFS(FileSystem fs, String methodName) {\n+    if (!(fs instanceof DistributedFileSystem)) {\n+      throw new UnsupportedOperationException(\n+          \"This API:\" + methodName + \" is specific to DFS. Can't run on other fs:\" + fs\n+              .getUri());\n+    }\n+  }\n+\n+  @Override\n+  // DFS specific API\n+  protected HdfsDataOutputStream primitiveCreate(Path f,\n+      FsPermission absolutePermission, EnumSet<CreateFlag> flag, int bufferSize,\n+      short replication, long blockSize, Progressable progress,\n+      Options.ChecksumOpt checksumOpt) throws IOException {\n+    if (this.vfs == null) {\n+      return super\n+          .primitiveCreate(f, absolutePermission, flag, bufferSize, replication,\n+              blockSize, progress, checksumOpt);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"primitiveCreate\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .primitiveCreate(f, absolutePermission, flag, bufferSize, replication,\n+            blockSize, progress, checksumOpt);\n+  }\n+\n+  @Override\n+  public FSDataOutputStream createNonRecursive(Path f, FsPermission permission,\n+      EnumSet<CreateFlag> flags, int bufferSize, short replication,\n+      long blockSize, Progressable progress) throws IOException {\n+    if (this.vfs == null) {\n+      return super\n+          .createNonRecursive(f, permission, flags, bufferSize, replication,\n+              bufferSize, progress);\n+    }\n+    return this.vfs\n+        .createNonRecursive(f, permission, flags, bufferSize, replication,\n+            bufferSize, progress);\n+  }\n+\n+  @Override\n+  public boolean setReplication(final Path f, final short replication)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.setReplication(f, replication);\n+    }\n+    return this.vfs.setReplication(f, replication);\n+  }\n+\n+  @Override\n+  public void setStoragePolicy(Path src, String policyName) throws IOException {\n+    if (this.vfs == null) {\n+      super.setStoragePolicy(src, policyName);\n+      return;\n+    }\n+    this.vfs.setStoragePolicy(src, policyName);\n+  }\n+\n+  @Override\n+  public void unsetStoragePolicy(Path src) throws IOException {\n+    if (this.vfs == null) {\n+      super.unsetStoragePolicy(src);\n+      return;\n+    }\n+    this.vfs.unsetStoragePolicy(src);\n+  }\n+\n+  @Override\n+  public BlockStoragePolicySpi getStoragePolicy(Path src) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getStoragePolicy(src);\n+    }\n+    return this.vfs.getStoragePolicy(src);\n+  }\n+\n+  @Override\n+  public Collection<BlockStoragePolicy> getAllStoragePolicies()\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getAllStoragePolicies();\n+    }\n+    Collection<? extends BlockStoragePolicySpi> allStoragePolicies =\n+        this.vfs.getAllStoragePolicies();\n+    return (Collection<BlockStoragePolicy>) allStoragePolicies;\n+  }\n+\n+  @Override\n+  public long getBytesWithFutureGenerationStamps() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getBytesWithFutureGenerationStamps();\n+    }\n+    return defaultDFS.getBytesWithFutureGenerationStamps();\n+  }\n+\n+  @Deprecated\n+  @Override\n+  public BlockStoragePolicy[] getStoragePolicies() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getStoragePolicies();\n+    }\n+    return defaultDFS.getStoragePolicies();\n+  }\n+\n+  @Override\n+  //Make sure your target fs supports this API, otherwise you will get\n+  // Unsupported operation exception.\n+  public void concat(Path trg, Path[] psrcs) throws IOException {\n+    if (this.vfs == null) {\n+      super.concat(trg, psrcs);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(trg, getConf());\n+    mountPathInfo.getTargetFs().concat(mountPathInfo.getPathOnTarget(), psrcs);\n+  }\n+\n+  @SuppressWarnings(\"deprecation\")\n+  @Override\n+  public boolean rename(final Path src, final Path dst) throws IOException {\n+    if (this.vfs == null) {\n+      return super.rename(src, dst);\n+    }\n+    if (getMountPoints().length == 0) {\n+      return this.defaultDFS.rename(src, dst);\n+    }\n+    return this.vfs.rename(src, dst);\n+  }\n+\n+  @SuppressWarnings(\"deprecation\")\n+  @Override\n+  public void rename(Path src, Path dst, final Options.Rename... options)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      super.rename(src, dst, options);\n+      return;\n+    }\n+\n+    // TODO: revisit\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountSrcPathInfo =\n+        this.vfs.getMountPathInfo(src, getConf());\n+    checkDFS(mountSrcPathInfo.getTargetFs(), \"rename\");\n+\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountDstPathInfo =\n+        this.vfs.getMountPathInfo(src, getConf());\n+    checkDFS(mountDstPathInfo.getTargetFs(), \"rename\");\n+\n+    //Check both in same cluster.\n+    if (!mountSrcPathInfo.getTargetFs().getUri()\n+        .equals(mountDstPathInfo.getTargetFs().getUri())) {\n+      throw new HadoopIllegalArgumentException(\n+          \"Can't rename across file systems.\");\n+    }\n+\n+    ((DistributedFileSystem) mountSrcPathInfo.getTargetFs())\n+        .rename(mountSrcPathInfo.getPathOnTarget(),\n+            mountDstPathInfo.getPathOnTarget(), options);\n+  }\n+\n+  @Override\n+  public boolean truncate(final Path f, final long newLength)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.truncate(f, newLength);\n+    }\n+    return this.vfs.truncate(f, newLength);\n+  }\n+\n+  public boolean delete(final Path f, final boolean recursive)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.delete(f, recursive);\n+    }\n+    return this.vfs.delete(f, recursive);\n+  }\n+\n+  @Override\n+  public ContentSummary getContentSummary(Path f) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getContentSummary(f);\n+    }\n+    return this.vfs.getContentSummary(f);\n+  }\n+\n+  @Override\n+  public QuotaUsage getQuotaUsage(Path f) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getQuotaUsage(f);\n+    }\n+    return this.vfs.getQuotaUsage(f);\n+  }\n+\n+  @Override\n+  public void setQuota(Path src, final long namespaceQuota,\n+      final long storagespaceQuota) throws IOException {\n+    if (this.vfs == null) {\n+      super.setQuota(src, namespaceQuota, storagespaceQuota);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(src, getConf());\n+    mountPathInfo.getTargetFs()\n+        .setQuota(mountPathInfo.getPathOnTarget(), namespaceQuota,\n+            storagespaceQuota);\n+  }\n+\n+  @Override\n+  public void setQuotaByStorageType(Path src, final StorageType type,\n+      final long quota) throws IOException {\n+    if (this.vfs == null) {\n+      super.setQuotaByStorageType(src, type, quota);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(src, getConf());\n+    mountPathInfo.getTargetFs()\n+        .setQuotaByStorageType(mountPathInfo.getPathOnTarget(), type, quota);\n+  }\n+\n+  @Override\n+  public FileStatus[] listStatus(Path p) throws IOException {\n+    if (this.vfs == null) {\n+      return super.listStatus(p);\n+    }\n+    return this.vfs.listStatus(p);\n+  }\n+\n+  @Override\n+  public RemoteIterator<LocatedFileStatus> listLocatedStatus(final Path f,\n+      final PathFilter filter) throws FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.listLocatedStatus(f, filter);\n+    }\n+    return this.vfs.listLocatedStatus(f, filter);\n+  }\n+\n+  @Override\n+  public RemoteIterator<FileStatus> listStatusIterator(final Path p)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.listStatusIterator(p);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(p, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .listStatusIterator(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public RemoteIterator<PartialListing<FileStatus>> batchedListStatusIterator(\n+      final List<Path> paths) throws IOException {\n+    if (this.vfs == null) {\n+      return super.batchedListStatusIterator(paths);\n+    }\n+    // TODO: revisit for correct implementation.\n+    return this.defaultDFS.batchedListStatusIterator(paths);\n+  }\n+\n+  @Override\n+  public RemoteIterator<PartialListing<LocatedFileStatus>> batchedListLocatedStatusIterator(\n+      final List<Path> paths) throws IOException {\n+    if (this.vfs == null) {\n+      return super.batchedListLocatedStatusIterator(paths);\n+    }\n+    // TODO: revisit for correct implementation.\n+    return this.defaultDFS.batchedListLocatedStatusIterator(paths);\n+  }\n+\n+  public boolean mkdir(Path f, FsPermission permission) throws IOException {\n+    if (this.vfs == null) {\n+      return super.mkdir(f, permission);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"mkdir\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .mkdir(mountPathInfo.getPathOnTarget(), permission);\n+  }\n+\n+  @Override\n+  public boolean mkdirs(Path f, FsPermission permission) throws IOException {\n+    if (this.vfs == null) {\n+      return super.mkdirs(f, permission);\n+    }\n+    return this.vfs.mkdirs(f, permission);\n+  }\n+\n+  @SuppressWarnings(\"deprecation\")\n+  @Override\n+  protected boolean primitiveMkdir(Path f, FsPermission absolutePermission)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.primitiveMkdir(f, absolutePermission);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"primitiveMkdir\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .primitiveMkdir(mountPathInfo.getPathOnTarget(), absolutePermission);\n+  }\n+\n+  @Override\n+  public void close() throws IOException {\n+    if (this.vfs != null) {\n+      this.vfs.close();\n+    }\n+    super.close();\n+  }\n+\n+  @InterfaceAudience.Private\n+  public DFSClient getClient() {\n+    if (this.vfs == null) {\n+      return super.getClient();\n+    }\n+    return defaultDFS.getClient();\n+  }\n+\n+  @Override\n+  public FsStatus getStatus(Path p) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getStatus(p);\n+    }\n+    return this.vfs.getStatus(p);\n+  }\n+\n+  @Override\n+  public long getMissingBlocksCount() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getMissingBlocksCount();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getMissingBlocksCount is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public long getPendingDeletionBlocksCount() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getPendingDeletionBlocksCount();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getPendingDeletionBlocksCount is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public long getMissingReplOneBlocksCount() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getMissingReplOneBlocksCount();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getMissingReplOneBlocksCount is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public long getLowRedundancyBlocksCount() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getLowRedundancyBlocksCount();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getLowRedundancyBlocksCount is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public long getCorruptBlocksCount() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getCorruptBlocksCount();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getCorruptBlocksCount is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public RemoteIterator<Path> listCorruptFileBlocks(final Path path)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.listCorruptFileBlocks(path);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .listCorruptFileBlocks(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public DatanodeInfo[] getDataNodeStats() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getDataNodeStats();\n+    }\n+    return defaultDFS.getDataNodeStats();\n+  }\n+\n+  @Override\n+  public DatanodeInfo[] getDataNodeStats(\n+      final HdfsConstants.DatanodeReportType type) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getDataNodeStats(type);\n+    }\n+    return defaultDFS.getDataNodeStats(type);\n+  }\n+\n+  @Override\n+  public boolean setSafeMode(HdfsConstants.SafeModeAction action)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.setSafeMode(action);\n+    }\n+    return defaultDFS.setSafeMode(action);\n+  }\n+\n+  @Override\n+  public boolean setSafeMode(HdfsConstants.SafeModeAction action,\n+      boolean isChecked) throws IOException {\n+    if (this.vfs == null) {\n+      return super.setSafeMode(action, isChecked);\n+    }\n+    return defaultDFS.setSafeMode(action, isChecked);\n+  }\n+\n+  @Override\n+  public boolean saveNamespace(long timeWindow, long txGap) throws IOException {\n+    if (this.vfs == null) {\n+      return super.saveNamespace(timeWindow, txGap);\n+    }\n+    return defaultDFS.saveNamespace(timeWindow, txGap);\n+  }\n+\n+  @Override\n+  public void saveNamespace() throws IOException {\n+    if (this.vfs == null) {\n+      super.saveNamespace();\n+      return;\n+    }\n+    defaultDFS.saveNamespace();\n+  }\n+\n+  @Override\n+  public long rollEdits() throws IOException {\n+    if (this.vfs == null) {\n+      return super.rollEdits();\n+    }\n+    return defaultDFS.rollEdits();\n+  }\n+\n+  @Override\n+  public boolean restoreFailedStorage(String arg) throws IOException {\n+    if (this.vfs == null) {\n+      return super.restoreFailedStorage(arg);\n+    }\n+    return defaultDFS.restoreFailedStorage(arg);\n+  }\n+\n+  @Override\n+  public void refreshNodes() throws IOException {\n+    if (this.vfs == null) {\n+      super.refreshNodes();\n+      return;\n+    }\n+    defaultDFS.refreshNodes();\n+  }\n+\n+  @Override\n+  public void finalizeUpgrade() throws IOException {\n+    if (this.vfs == null) {\n+      super.finalizeUpgrade();\n+      return;\n+    }\n+    defaultDFS.finalizeUpgrade();\n+  }\n+\n+  @Override\n+  public boolean upgradeStatus() throws IOException {\n+    if (this.vfs == null) {\n+      return super.upgradeStatus();\n+    }\n+    return defaultDFS.upgradeStatus();\n+  }\n+\n+  @Override\n+  public RollingUpgradeInfo rollingUpgrade(\n+      HdfsConstants.RollingUpgradeAction action) throws IOException {\n+    if (this.vfs == null) {\n+      return super.rollingUpgrade(action);\n+    }\n+    return defaultDFS.rollingUpgrade(action);\n+  }\n+\n+  @Override\n+  public void metaSave(String pathname) throws IOException {\n+    if (this.vfs == null) {\n+      super.metaSave(pathname);\n+      return;\n+    }\n+    defaultDFS.metaSave(pathname);\n+  }\n+\n+  @Override\n+  public FsServerDefaults getServerDefaults() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getServerDefaults();\n+    }\n+    //TODO: Need to revisit.\n+    return defaultDFS.getServerDefaults();\n+  }\n+\n+  @Override\n+  public FileStatus getFileStatus(final Path f)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.getFileStatus(f);\n+    }\n+    return this.vfs.getFileStatus(f);\n+  }\n+\n+  @SuppressWarnings(\"deprecation\")\n+  @Override\n+  public void createSymlink(final Path target, final Path link,\n+      final boolean createParent) throws IOException {\n+     // Regular DFS behavior\n+    if (this.vfs == null) {\n+      super.createSymlink(target, link, createParent);\n+      return;\n+    }\n+\n+    // Mounting ViewHDFS behavior\n+    // TODO: revisit\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(target, getConf());\n+    mountPathInfo.getTargetFs()\n+        .createSymlink(mountPathInfo.getPathOnTarget(), link, createParent);\n+  }\n+\n+  @Override\n+  public boolean supportsSymlinks() {\n+    if (this.vfs == null) {\n+      return super.supportsSymlinks();\n+    }\n+    // TODO: we can enabled later if we want to support symlinks.\n+    return false;\n+  }\n+\n+  @Override\n+  public FileStatus getFileLinkStatus(final Path f) throws IOException {\n+     if(this.vfs==null){\n+       return super.getFileLinkStatus(f);\n+     }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .getFileLinkStatus(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public Path getLinkTarget(Path path) throws IOException {\n+    if(this.vfs==null){\n+      return super.getLinkTarget(path);\n+    }\n+    return this.vfs.getLinkTarget(path);\n+  }\n+\n+  @Override\n+  protected Path resolveLink(Path f) throws IOException {\n+    if(this.vfs==null){\n+      return super.resolveLink(f);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"resolveLink\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .resolveLink(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public FileChecksum getFileChecksum(final Path f)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.getFileChecksum(f);\n+    }\n+    return this.vfs.getFileChecksum(f);\n+  }\n+\n+  @Override\n+  public void setPermission(final Path f, final FsPermission permission)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      super.setPermission(f, permission);\n+      return;\n+    }\n+    this.vfs.setPermission(f, permission);\n+  }\n+\n+  @Override\n+  public void setOwner(final Path f, final String username,\n+      final String groupname)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      super.setOwner(f, username, groupname);\n+      return;\n+    }\n+    this.vfs.setOwner(f, username, groupname);\n+  }\n+\n+  @Override\n+  public void setTimes(final Path f, final long mtime, final long atime)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      super.setTimes(f, mtime, atime);\n+      return;\n+    }\n+    this.vfs.setTimes(f, mtime, atime);\n+  }\n+\n+  @Override\n+  // DFS specific API\n+  protected int getDefaultPort() {\n+    return super.getDefaultPort();\n+  }\n+\n+  @Override\n+  public Token<DelegationTokenIdentifier> getDelegationToken(String renewer)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getDelegationToken(renewer);\n+    }\n+    //Let applications call getDelegationTokenIssuers and get respective\n+    // delegation tokens from child fs.\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public void setBalancerBandwidth(long bandwidth) throws IOException {\n+    if (this.vfs == null) {\n+      super.setBalancerBandwidth(bandwidth);\n+      return;\n+    }\n+    defaultDFS.setBalancerBandwidth(bandwidth);\n+  }\n+\n+  @Override\n+  public String getCanonicalServiceName() {\n+    if (this.vfs == null) {\n+      return super.getCanonicalServiceName();\n+    }\n+    return defaultDFS.getCanonicalServiceName();\n+  }\n+\n+  @Override\n+  protected URI canonicalizeUri(URI uri) {\n+    if (this.vfs == null) {\n+      return super.canonicalizeUri(uri);\n+    }\n+\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo = null;\n+    try {\n+      mountPathInfo = this.vfs.getMountPathInfo(new Path(uri), getConf());\n+    } catch (IOException e) {\n+      //LOG.error(\"Failed to resolve the uri as mount path\", e);\n+      return null;\n+    }\n+    checkDFS(mountPathInfo.getTargetFs(), \"canonicalizeUri\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .canonicalizeUri(uri);\n+  }\n+\n+  @Override\n+  public boolean isInSafeMode() throws IOException {\n+    if (this.vfs == null) {\n+      return super.isInSafeMode();\n+    }\n+    return defaultDFS.isInSafeMode();\n+  }\n+\n+  @Override\n+  // DFS specific API\n+  public void allowSnapshot(Path path) throws IOException {\n+    if (this.vfs == null) {\n+      super.allowSnapshot(path);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"allowSnapshot\");\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .allowSnapshot(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public void disallowSnapshot(final Path path) throws IOException {\n+    if (this.vfs == null) {\n+      super.disallowSnapshot(path);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"disallowSnapshot\");\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .disallowSnapshot(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public Path createSnapshot(Path path, String snapshotName)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.createSnapshot(path, snapshotName);\n+    }\n+    return this.vfs.createSnapshot(path, snapshotName);\n+  }\n+\n+  @Override\n+  public void renameSnapshot(Path path, String snapshotOldName,\n+      String snapshotNewName) throws IOException {\n+    if (this.vfs == null) {\n+      super.renameSnapshot(path, snapshotOldName, snapshotOldName);\n+      return;\n+    }\n+    this.vfs.renameSnapshot(path, snapshotOldName, snapshotNewName);\n+  }\n+\n+  @Override\n+  //Ony for HDFS users\n+  public SnapshottableDirectoryStatus[] getSnapshottableDirListing()\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getSnapshottableDirListing();\n+    }\n+    return defaultDFS.getSnapshottableDirListing();\n+  }\n+\n+  @Override\n+  public void deleteSnapshot(Path path, String snapshotName)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      super.deleteSnapshot(path, snapshotName);\n+      return;\n+    }\n+    this.vfs.deleteSnapshot(path, snapshotName);\n+  }\n+\n+  @Override\n+  public RemoteIterator<SnapshotDiffReportListing> snapshotDiffReportListingRemoteIterator(\n+      final Path snapshotDir, final String fromSnapshot,\n+      final String toSnapshot) throws IOException {\n+     if(this.vfs ==null){\n+       return super.snapshotDiffReportListingRemoteIterator(snapshotDir, fromSnapshot,\n+           toSnapshot);\n+     }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(snapshotDir, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(),\n+        \"snapshotDiffReportListingRemoteIterator\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .snapshotDiffReportListingRemoteIterator(\n+            mountPathInfo.getPathOnTarget(), fromSnapshot, toSnapshot);\n+  }\n+\n+  @Override\n+  public SnapshotDiffReport getSnapshotDiffReport(final Path snapshotDir,\n+      final String fromSnapshot, final String toSnapshot) throws IOException {\n+    if(this.vfs ==null){\n+      return super.getSnapshotDiffReport(snapshotDir, fromSnapshot,\n+          toSnapshot);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(snapshotDir, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"getSnapshotDiffReport\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .getSnapshotDiffReport(snapshotDir, fromSnapshot,\n+            toSnapshot);\n+  }\n+\n+  @Override\n+  public boolean isFileClosed(final Path src) throws IOException {\n+    if (this.vfs == null) {\n+      return super.isFileClosed(src);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(src, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"isFileClosed\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .isFileClosed(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public long addCacheDirective(CacheDirectiveInfo info) throws IOException {\n+    if (this.vfs == null) {\n+      return super.addCacheDirective(info);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(info.getPath(), getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"addCacheDirective\");\n+\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .addCacheDirective(new CacheDirectiveInfo.Builder(info)\n+            .setPath(mountPathInfo.getPathOnTarget()).build());\n+  }\n+\n+  @Override\n+  public long addCacheDirective(CacheDirectiveInfo info,\n+      EnumSet<CacheFlag> flags) throws IOException {\n+    if (this.vfs == null) {\n+      return super.addCacheDirective(info, flags);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(info.getPath(), getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"addCacheDirective\");\n+\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .addCacheDirective(new CacheDirectiveInfo.Builder(info)\n+            .setPath(mountPathInfo.getPathOnTarget()).build(), flags);\n+  }\n+\n+  @Override\n+  public void modifyCacheDirective(CacheDirectiveInfo info) throws IOException {\n+    if (this.vfs == null) {\n+      super.modifyCacheDirective(info);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(info.getPath(), getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"modifyCacheDirective\");\n+\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs()).modifyCacheDirective(\n+        new CacheDirectiveInfo.Builder(info)\n+            .setPath(mountPathInfo.getPathOnTarget()).build());\n+  }\n+\n+  @Override\n+  public void modifyCacheDirective(CacheDirectiveInfo info,\n+      EnumSet<CacheFlag> flags) throws IOException {\n+    if (this.vfs == null) {\n+      super.modifyCacheDirective(info, flags);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(info.getPath(), getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"modifyCacheDirective\");\n+\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs()).modifyCacheDirective(\n+        new CacheDirectiveInfo.Builder(info)\n+            .setPath(mountPathInfo.getPathOnTarget()).build(), flags);\n+  }\n+\n+  @Override\n+  public void removeCacheDirective(long id) throws IOException {\n+    if (this.vfs == null) {\n+      super.removeCacheDirective(id);\n+      return;\n+    }\n+    //defaultDFS.removeCacheDirective(id);\n+    //TODO: ? this can create issues in default cluster\n+    // if user intention is to call on specific mount.\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public RemoteIterator<CacheDirectiveEntry> listCacheDirectives(\n+      CacheDirectiveInfo filter) throws IOException {\n+    if (this.vfs == null) {\n+      return super.listCacheDirectives(filter);\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listCacheDirectives is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public void addCachePool(CachePoolInfo info) throws IOException {\n+    if (this.vfs == null) {\n+      super.addCachePool(info);\n+      return;\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listCacheDirectives is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public void modifyCachePool(CachePoolInfo info) throws IOException {\n+    if (this.vfs == null) {\n+      super.modifyCachePool(info);\n+      return;\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listCacheDirectives is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public void removeCachePool(String poolName) throws IOException {\n+    if (this.vfs == null) {\n+      super.removeCachePool(poolName);\n+      return;\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listCacheDirectives is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public RemoteIterator<CachePoolEntry> listCachePools() throws IOException {\n+    if (this.vfs == null) {\n+      return super.listCachePools();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listCacheDirectives is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public void modifyAclEntries(Path path, List<AclEntry> aclSpec)\n+      throws IOException {\n+    this.vfs.modifyAclEntries(path, aclSpec);\n+  }\n+\n+  @Override\n+  public void removeAclEntries(Path path, List<AclEntry> aclSpec)\n+      throws IOException {\n+    this.vfs.removeAclEntries(path, aclSpec);\n+  }\n+\n+  @Override\n+  public void removeDefaultAcl(Path path) throws IOException {\n+    this.vfs.removeDefaultAcl(path);\n+  }\n+\n+  @Override\n+  public void removeAcl(Path path) throws IOException {\n+    this.vfs.removeAcl(path);\n+  }\n+\n+  @Override\n+  public void setAcl(Path path, List<AclEntry> aclSpec) throws IOException {\n+    if (this.vfs == null) {\n+      super.setAcl(path, aclSpec);\n+      return;\n+    }\n+    this.vfs.setAcl(path, aclSpec);\n+  }\n+\n+  @Override\n+  public AclStatus getAclStatus(Path path) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getAclStatus(path);\n+    }\n+    return this.vfs.getAclStatus(path);\n+  }\n+\n+  @Override\n+  public void createEncryptionZone(final Path path, final String keyName)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      super.createEncryptionZone(path, keyName);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"createEncryptionZone\");\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .createEncryptionZone(mountPathInfo.getPathOnTarget(), keyName);\n+  }\n+\n+  @Override\n+  public EncryptionZone getEZForPath(final Path path) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getEZForPath(path);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"getEZForPath\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .getEZForPath(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public RemoteIterator<EncryptionZone> listEncryptionZones()\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.listEncryptionZones();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listEncryptionZones is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public void reencryptEncryptionZone(final Path zone,\n+      final HdfsConstants.ReencryptAction action) throws IOException {\n+    if (this.vfs == null) {\n+      super.reencryptEncryptionZone(zone, action);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(zone, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"reencryptEncryptionZone\");\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .reencryptEncryptionZone(mountPathInfo.getPathOnTarget(), action);\n+  }\n+\n+  @Override\n+  public RemoteIterator<ZoneReencryptionStatus> listReencryptionStatus()\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.listReencryptionStatus();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listReencryptionStatus is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public FileEncryptionInfo getFileEncryptionInfo(final Path path)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getFileEncryptionInfo(path);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"getFileEncryptionInfo\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .getFileEncryptionInfo(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public void provisionEZTrash(final Path path,\n+      final FsPermission trashPermission) throws IOException {\n+    if (this.vfs == null) {\n+      super.provisionEZTrash(path, trashPermission);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"provisionEZTrash\");\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .provisionEZTrash(mountPathInfo.getPathOnTarget(), trashPermission);\n+  }\n+\n+  @Override\n+  public void setXAttr(Path path, String name, byte[] value,\n+      EnumSet<XAttrSetFlag> flag) throws IOException {\n+    if (this.vfs == null) {\n+      super.setXAttr(path, name, value, flag);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    mountPathInfo.getTargetFs()\n+        .setXAttr(mountPathInfo.getPathOnTarget(), name, value, flag);\n+  }\n+\n+  @Override\n+  public byte[] getXAttr(Path path, String name) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getXAttr(path, name);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .getXAttr(mountPathInfo.getPathOnTarget(), name);\n+  }\n+\n+  @Override\n+  public Map<String, byte[]> getXAttrs(Path path) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getXAttrs(path);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .getXAttrs(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public Map<String, byte[]> getXAttrs(Path path, List<String> names)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getXAttrs(path, names);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .getXAttrs(mountPathInfo.getPathOnTarget(), names);\n+  }\n+\n+  @Override\n+  public List<String> listXAttrs(Path path) throws IOException {\n+    if (this.vfs == null) {\n+      return super.listXAttrs(path);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .listXAttrs(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public void removeXAttr(Path path, String name) throws IOException {\n+    if (this.vfs == null) {\n+      super.removeXAttr(path, name);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    mountPathInfo.getTargetFs()\n+        .removeXAttr(mountPathInfo.getPathOnTarget(), name);\n+  }\n+\n+  @Override\n+  public void access(Path path, FsAction mode)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      super.access(path, mode);\n+      return;\n+    }\n+    this.vfs.access(path, mode);\n+  }\n+\n+  @Override\n+  public URI getKeyProviderUri() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getKeyProviderUri();\n+    }\n+    return defaultDFS.getKeyProviderUri();\n+  }\n+\n+  @Override\n+  public KeyProvider getKeyProvider() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getKeyProvider();\n+    }\n+    return defaultDFS.getKeyProvider();\n+  }\n+\n+  @Override\n+  public DelegationTokenIssuer[] getAdditionalTokenIssuers()\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getChildFileSystems();\n+    }\n+\n+    return this.vfs.getChildFileSystems();\n+  }\n+\n+  @Override\n+  public DFSInotifyEventInputStream getInotifyEventStream() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getInotifyEventStream();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getInotifyEventStream is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public DFSInotifyEventInputStream getInotifyEventStream(long lastReadTxid)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getInotifyEventStream();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getInotifyEventStream is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  // DFS only API.\n+  public void setErasureCodingPolicy(final Path path, final String ecPolicyName)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      super.setErasureCodingPolicy(path, ecPolicyName);\n+      return;\n+    }\n+\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"setErasureCodingPolicy\");\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .setErasureCodingPolicy(mountPathInfo.getPathOnTarget(), ecPolicyName);\n+  }\n+\n+  @Override\n+  public void satisfyStoragePolicy(Path src) throws IOException {\n+    if (this.vfs == null) {\n+      super.satisfyStoragePolicy(src);\n+      return;\n+    }\n+    this.vfs.satisfyStoragePolicy(src);\n+  }\n+\n+  @Override\n+  public ErasureCodingPolicy getErasureCodingPolicy(final Path path)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getErasureCodingPolicy(path);\n+    }\n+\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"getErasureCodingPolicy\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .getErasureCodingPolicy(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public Collection<ErasureCodingPolicyInfo> getAllErasureCodingPolicies()\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getAllErasureCodingPolicies();\n+    }\n+    return defaultDFS.getAllErasureCodingPolicies();\n+  }\n+\n+  @Override\n+  public Map<String, String> getAllErasureCodingCodecs() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getAllErasureCodingCodecs();\n+    }\n+    return defaultDFS.getAllErasureCodingCodecs();\n+  }\n+\n+  @Override\n+  public AddErasureCodingPolicyResponse[] addErasureCodingPolicies(\n+      ErasureCodingPolicy[] policies) throws IOException {\n+    if (this.vfs == null) {\n+      return super.addErasureCodingPolicies(policies);\n+    }\n+    return defaultDFS.addErasureCodingPolicies(policies);\n+  }\n+\n+  @Override\n+  public void removeErasureCodingPolicy(String ecPolicyName)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      super.removeErasureCodingPolicy(ecPolicyName);\n+      return;\n+    }\n+    defaultDFS.removeErasureCodingPolicy(ecPolicyName);\n+  }\n+\n+  @Override\n+  public void enableErasureCodingPolicy(String ecPolicyName)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      super.enableErasureCodingPolicy(ecPolicyName);\n+      return;\n+    }\n+    defaultDFS.enableErasureCodingPolicy(ecPolicyName);", "originalCommit": "33902b0e36c9d1f41195d9fc31af21f5de5f222d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTA0OTkxOQ==", "url": "https://github.com/apache/hadoop/pull/2229#discussion_r471049919", "bodyText": "This is one point I was thinking what to do. One way I agree that running on all child hdfs-s make sense. But other I was thinking that if a user working on a specific mount and wants to call would make the call goes and disturb all other clusters also. However, Unfortunately  we don't have choice to choose specific cluster from the current API signatures.\nWhats your opinion?\nIdeally they should be done from admins command line as they are not part of FileSystem API. If they are from admin, users can use -fs option to run on specific child clusters.", "author": "umamaheswararao", "createdAt": "2020-08-16T00:58:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkzNzc1Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTA4MjcxMQ==", "url": "https://github.com/apache/hadoop/pull/2229#discussion_r471082711", "bodyText": "Well in any case, I think making a call to defaultDFS isn't going to help much. Somebody does an enablePolicy and post that if he tries setPolicy which goes to another FS it will fail, he might try listPolicies which will again go to defaultDFS and the policy would show as enabled there, so this behavior would be very confusing in that case.\nThere are two ways only IMO, we let the admin only do it using -fs and throw an UnsupportedExceptions for these API's,\nSecond solution is shooting calls to all child FS, This is what is done in case of RBF as well, I think in ViewFileSystem the getAllStoragePolicies API also does something like this.\nPersonally, I feel the second option would be little better, as post that the client operations shall work without any restrictions/issues", "author": "ayushtkn", "createdAt": "2020-08-16T08:20:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkzNzc1Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTI1NzQxNg==", "url": "https://github.com/apache/hadoop/pull/2229#discussion_r471257416", "bodyText": "@ayushtkn , Thank you for your opinion. I attempted to delegate EC calls to all child filesystems.\nTo the other approach the APIs delegated only defaultFS: if we don't delegate to defaultFS and simply throw USOE and if defautFS is same as the fs.defaultFS uri, then we will never be able to call this defaultFS. Because it will be resolved to same VDFS class and find mount points configured with same authority.\nSo, if we delegate to defaultFS in the current instance and for all other childFS, users can use -fs option. That will work as otherFS authority most probably will be different and they will be able to initialized successfully, but without any mounts.", "author": "umamaheswararao", "createdAt": "2020-08-17T06:32:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkzNzc1Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTMxMzM3NA==", "url": "https://github.com/apache/hadoop/pull/2229#discussion_r471313374", "bodyText": "Thanx @umamaheswararao\nI have a small doubt-\n  // A default DFS, which should have set via linkFallback private DistributedFileSystem defaultDFS;\nThe defaultDFS is the FS set via fallback, Correct?\n    viewFs.setSupportAutoAddingFallbackOnNoMounts(false);\nNow here we have disabled Auto adding fallback, So, in case corresponding mount entry isn't there, will a normal(read/write) call go to this defaultDFS? I think no?\n\nIf not then why to bother defaultDFS, if it is not handling client calls?\nif not, Why are we not allowing fallback? is it a planned followup, or some issues with it.\nif the fallback fs is there and is present amongst as a childFS, We could have eliminated the defaultDFS logic completely? Since now a call will go to that FS as well?\n\n\nSo, if we delegate to defaultFS in the current instance and for all other childFS\n\nWith  and you mean shoot calls to all childFS and then make a call to defaultDFS as well?\n\ndefautFS is same as the fs.defaultFS uri, then we will never be able to call this defaultFS. Because it will be resolved to same VDFS class and find mount points configured with same authority.\n\nIsn't this a client mis-config then? He configured it to get overloaded?\nWell seems like, I have bothered  you too much on this, If stuff above doesn't make sense, you can have same logic as EC for cachePool API's as well, since listCachePool seems a non-Admin API. Post that you can proceed ahead with concluding this. I don't think defaultDFS would be bothering much in prod cases, and rest everything already is pretty cool :-)", "author": "ayushtkn", "createdAt": "2020-08-17T08:12:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkzNzc1Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTM0NTU5OA==", "url": "https://github.com/apache/hadoop/pull/2229#discussion_r471345598", "bodyText": "@ayushtkn  Thanks a lot for your time and review. You made lot of good points, no issues let's conversations going on until things are making sense. :-)\n\nThe defaultDFS is the FS set via fallback, Correct?\n\nYes, you are right.\n\nviewFs.setSupportAutoAddingFallbackOnNoMounts(false);\n\nWhy I disabled this was, in ViewDistributedFileSystem, if no mount points configured in the system, everything should work as regular DistributedFileSystem. So, we can eventually make this class (fs.hdfs.impl=ViewDistributedFileSystem) enabled by default and just don't add mount points if they don't need mounting functionality. The existing users will not see any impact as this will work same as DistributedFileSystem as the existing users would not have configured any mount points. That's the expectation here. So, if we auto add fallback, vfs#init will never fail and we always go into mount way of functionality.\nThat's why every api checks vfs==null, and they use super.API() calls to get exactly same DistributedFileSystem Functionality.\nHope this clears your doubt.\n\nNow here we have disabled Auto adding fallback, So, in case corresponding mount entry isn't there, will a normal(read/write) call go to this defaultDFS? I think no?\n\nCase 1: user did not configure any mounts : works same as DistributedFileSystem.\nCase 2: user did configured mounts, but no fallback configured :  Whatever mount paths matching will delegate call to that fs. If no matches, it will fail with NotInMountPoint Exceptions. APIs like IsInSafeMode will fail as there is no defaultFS( that is fallback). User's can make use -fs from command line and call to specific child fs.\nCase 3: user did configured mounts and as well as fallback: Now whatever paths matching will go to target fs. If no matches, then fallback. For APIs without paths in argument like IsInSafeMode will simply make calls on that fallback fs. For the rest of other child file systems, they may need to do from command like with -fs option.\n\nif the fallback fs is there and is present amongst as a childFS, We could have eliminated the defaultDFS logic completely? Since now a call will go to that FS as well?\n\nThat's why I tried tp make it mandatory config from user perspective. But we did not auto configure for the above reason, where we can enable by default(in future) fs.hdfs.impl pointing ViewDistributedFileSystem without any impact to existing users.\n\nWith and you mean shoot calls to all childFS and then make a call to defaultDFS as well?\n\nWhat I meant was: example: you have\nfs.defaultFS = hdfs://ns1\nfallback(defaultFS) -> hdfs://ns1\n/user --> hdfs://ns2\nwhen you call isInSafeMode, you will get result from default cluster(fallback).\nTo get from other child's, you will get FileSystem.get(otherClusterURI, conf).isInSafeMode().\nIncase if we simply throw USOE without giving from defaultCluster, we can never call to default cluster because FileSystem.get(fallbackUri, conf).isInSafeMode() will always gets USOE because the fallback and fs.defaultFS uris are same.\n\nIsn't this a client mis-config then? He configured it to get overloaded?\n\nOne of the important use case is, if you have an existing cluster and you want to add mount points with respective to that cluster. Then you will use that existing cluster as fallback and you will continue to use same fs.defaultFS.\nSo, all ops go to your default cluster except the paths matching to mount points. That way existing users need not change uri, but they can simply add mounts with respective to that cluster by simply adding current cluster as fallback.\n\nyou can have same logic as EC for cachePool API's as well, since listCachePool seems a non-Admin API.\n\nI am thinking in similar lines. Let me add cachePool API shoot to all fss.\nBTW, please note currently getChildFileSystems does not include, fallback fs. It will be fixed with HDFS-15529\nThanks again for your review.", "author": "umamaheswararao", "createdAt": "2020-08-17T09:10:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkzNzc1Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTk2MjgwMw==", "url": "https://github.com/apache/hadoop/pull/2229#discussion_r471962803", "bodyText": "Thanx for the details. Makes sense.", "author": "ayushtkn", "createdAt": "2020-08-18T07:13:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkzNzc1Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjU3ODY5MQ==", "url": "https://github.com/apache/hadoop/pull/2229#discussion_r472578691", "bodyText": "Thanks", "author": "umamaheswararao", "createdAt": "2020-08-19T01:15:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkzNzc1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkzODAwMw==", "url": "https://github.com/apache/hadoop/pull/2229#discussion_r470938003", "bodyText": "API name in exception.\nWhy can't we support cache commands, similar to other ones?", "author": "ayushtkn", "createdAt": "2020-08-15T04:52:51Z", "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/ViewDistributedFileSystem.java", "diffHunk": "@@ -0,0 +1,1864 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.hadoop.HadoopIllegalArgumentException;\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.crypto.key.KeyProvider;\n+import org.apache.hadoop.fs.BlockLocation;\n+import org.apache.hadoop.fs.BlockStoragePolicySpi;\n+import org.apache.hadoop.fs.CacheFlag;\n+import org.apache.hadoop.fs.ContentSummary;\n+import org.apache.hadoop.fs.CreateFlag;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.FileChecksum;\n+import org.apache.hadoop.fs.FileEncryptionInfo;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.FsServerDefaults;\n+import org.apache.hadoop.fs.FsStatus;\n+import org.apache.hadoop.fs.LocatedFileStatus;\n+import org.apache.hadoop.fs.Options;\n+import org.apache.hadoop.fs.PartialListing;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.PathFilter;\n+import org.apache.hadoop.fs.PathHandle;\n+import org.apache.hadoop.fs.QuotaUsage;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.StorageType;\n+import org.apache.hadoop.fs.XAttrSetFlag;\n+import org.apache.hadoop.fs.permission.AclEntry;\n+import org.apache.hadoop.fs.permission.AclStatus;\n+import org.apache.hadoop.fs.permission.FsAction;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+import org.apache.hadoop.fs.viewfs.ViewFileSystem;\n+import org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme;\n+import org.apache.hadoop.hdfs.client.HdfsDataOutputStream;\n+import org.apache.hadoop.hdfs.protocol.AddErasureCodingPolicyResponse;\n+import org.apache.hadoop.hdfs.protocol.BlockStoragePolicy;\n+import org.apache.hadoop.hdfs.protocol.CacheDirectiveEntry;\n+import org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo;\n+import org.apache.hadoop.hdfs.protocol.CachePoolEntry;\n+import org.apache.hadoop.hdfs.protocol.CachePoolInfo;\n+import org.apache.hadoop.hdfs.protocol.DatanodeInfo;\n+import org.apache.hadoop.hdfs.protocol.ECTopologyVerifierResult;\n+import org.apache.hadoop.hdfs.protocol.EncryptionZone;\n+import org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy;\n+import org.apache.hadoop.hdfs.protocol.ErasureCodingPolicyInfo;\n+import org.apache.hadoop.hdfs.protocol.HdfsConstants;\n+import org.apache.hadoop.hdfs.protocol.HdfsPathHandle;\n+import org.apache.hadoop.hdfs.protocol.OpenFileEntry;\n+import org.apache.hadoop.hdfs.protocol.OpenFilesIterator;\n+import org.apache.hadoop.hdfs.protocol.RollingUpgradeInfo;\n+import org.apache.hadoop.hdfs.protocol.SnapshotDiffReport;\n+import org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing;\n+import org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus;\n+import org.apache.hadoop.hdfs.protocol.ZoneReencryptionStatus;\n+import org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenIdentifier;\n+import org.apache.hadoop.security.AccessControlException;\n+import org.apache.hadoop.security.token.DelegationTokenIssuer;\n+import org.apache.hadoop.security.token.Token;\n+import org.apache.hadoop.util.Progressable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+\n+import java.net.InetSocketAddress;\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.EnumSet;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * The ViewDistributedFileSystem is an extended class to DistributedFileSystem\n+ * with additional mounting functionality. The goal is to have better API\n+ * compatibility for HDFS users when using mounting\n+ * filesystem(ViewFileSystemOverloadScheme).\n+ * The ViewFileSystemOverloadScheme{@link ViewFileSystemOverloadScheme} is a new\n+ * filesystem with inherited mounting functionality from ViewFileSystem.\n+ * For the user who is using ViewFileSystemOverloadScheme by setting\n+ * fs.hdfs.impl=org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme, now\n+ * they can set fs.hdfs.impl=org.apache.hadoop.hdfs.ViewDistributedFileSystem.\n+ * So, that the hdfs users will get closely compatible API with mount\n+ * functionality. For the rest of all other schemes can continue to use\n+ * ViewFileSystemOverloadScheme class directly for mount functionality. Please\n+ * note that ViewFileSystemOverloadScheme provides only\n+ * ViewFileSystem{@link ViewFileSystem} APIs.\n+ * If user configured this class but no mount point configured? Then it will\n+ * simply work as existing DistributedFileSystem class. If user configured both\n+ * fs.hdfs.impl to this class and mount configurations, then users will be able\n+ * to make calls the APIs available in this class, they are nothing but DFS\n+ * APIs, but they will be delegated to viewfs functionality. Please note, APIs\n+ * without any path in arguments( ex: isInSafeMode), will be delegated to\n+ * default filesystem only, that is the configured fallback link. If you want to\n+ * make these API calls on specific child filesystem, you may want to initialize\n+ * them separately and call. In ViewDistributedFileSystem, linkFallBack is\n+ * mandatory when you ass mount links and it must be to your base cluster,\n+ * usually your current fs.defaultFS if that's pointing to hdfs.\n+ */\n+public class ViewDistributedFileSystem extends DistributedFileSystem {\n+  private static final Logger LOGGER =\n+      LoggerFactory.getLogger(ViewDistributedFileSystem.class);\n+\n+  // A mounting file system.\n+  private ViewFileSystemOverloadScheme vfs;\n+  // A default DFS, which should have set via linkFallback\n+  private DistributedFileSystem defaultDFS;\n+\n+  @Override\n+  public void initialize(URI uri, Configuration conf) throws IOException {\n+    super.initialize(uri, conf);\n+    try {\n+      this.vfs = tryInitializeMountingViewFs(uri, conf);\n+    } catch (IOException ioe) {\n+      LOGGER.debug(\n+          \"Mount tree initialization failed with the reason => {}. Falling\" +\n+              \" back to regular DFS initialization. Please\" + \" re-initialize\" +\n+              \" the fs after updating mount point.\",\n+          ioe.getMessage());\n+      // Re-initialize, so that initDFSClient will initialize DFSClient to work\n+      // same as DistributedFileSystem.\n+      super.initialize(uri, conf);\n+      return;\n+    }\n+    setConf(conf);\n+    // A child DFS with the current initialized URI. This must be same as\n+    // fallback fs. The fallback must point to root of your filesystems.\n+    // Some APIs(without path in argument, for example isInSafeMode) will\n+    // support only for base cluster filesystem. Only that APIs will use this\n+    // fs.\n+    defaultDFS = (DistributedFileSystem) this.vfs.getFallbackFileSystem();\n+    Preconditions\n+        .checkNotNull(\"In ViewHDFS fallback link is mandatory.\", defaultDFS);\n+    // Please don't access internal dfs directly except in tests.\n+    dfs = defaultDFS.dfs;\n+  }\n+\n+  @Override\n+  DFSClient initDFSClient(URI uri, Configuration conf) throws IOException {\n+    if(this.vfs==null) {\n+      return super.initDFSClient(uri, conf);\n+    }\n+    return null;\n+  }\n+\n+  public ViewDistributedFileSystem() {\n+  }\n+\n+  private ViewFileSystemOverloadScheme tryInitializeMountingViewFs(URI uri,\n+      Configuration conf) throws IOException {\n+    ViewFileSystemOverloadScheme vfs = new ViewFileSystemOverloadScheme();\n+    vfs.setSupportAutoAddingFallbackOnNoMounts(false);\n+    vfs.initialize(uri, conf);\n+    return vfs;\n+  }\n+\n+  @Override\n+  public URI getUri() {\n+    if (this.vfs == null) {\n+      return super.getUri();\n+    }\n+    return this.vfs.getUri();\n+  }\n+\n+  @Override\n+  public String getScheme() {\n+    if (this.vfs == null) {\n+      return super.getScheme();\n+    }\n+    return this.vfs.getScheme();\n+  }\n+\n+  @Override\n+  public Path getWorkingDirectory() {\n+    if (this.vfs == null) {\n+      return super.getWorkingDirectory();\n+    }\n+    return this.vfs.getWorkingDirectory();\n+  }\n+\n+  @Override\n+  public void setWorkingDirectory(Path dir) {\n+    if (this.vfs == null) {\n+      super.setWorkingDirectory(dir);\n+      return;\n+    }\n+    this.vfs.setWorkingDirectory(dir);\n+  }\n+\n+  @Override\n+  public Path getHomeDirectory() {\n+    if (this.vfs == null) {\n+      return super.getHomeDirectory();\n+    }\n+    return this.vfs.getHomeDirectory();\n+  }\n+\n+  @Override\n+  /**\n+   * Returns only default cluster getHedgedReadMetrics.\n+   */ public DFSHedgedReadMetrics getHedgedReadMetrics() {\n+     if(this.vfs==null){\n+       return super.getHedgedReadMetrics();\n+     }\n+    return defaultDFS.getHedgedReadMetrics();\n+  }\n+\n+  @Override\n+  public BlockLocation[] getFileBlockLocations(FileStatus fs, long start,\n+      long len) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getFileBlockLocations(fs, start, len);\n+    }\n+    return this.vfs.getFileBlockLocations(fs, start, len);\n+  }\n+\n+  @Override\n+  public BlockLocation[] getFileBlockLocations(Path p, final long start,\n+      final long len) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getFileBlockLocations(p, start, len);\n+    }\n+    return this.vfs.getFileBlockLocations(p, start, len);\n+  }\n+\n+  @Override\n+  public void setVerifyChecksum(final boolean verifyChecksum) {\n+    if (this.vfs == null) {\n+      super.setVerifyChecksum(verifyChecksum);\n+      return;\n+    }\n+    this.vfs.setVerifyChecksum(verifyChecksum);\n+  }\n+\n+  @Override\n+  public boolean recoverLease(final Path f) throws IOException {\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"recoverLease\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .recoverLease(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public FSDataInputStream open(final Path f, final int bufferSize)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.open(f, bufferSize);\n+    }\n+\n+    return this.vfs.open(f, bufferSize);\n+  }\n+\n+  @Override\n+  public FSDataInputStream open(PathHandle fd, int bufferSize)\n+      throws IOException {\n+    return this.vfs.open(fd, bufferSize);\n+  }\n+\n+  @Override\n+  protected HdfsPathHandle createPathHandle(FileStatus st,\n+      Options.HandleOpt... opts) {\n+    if (this.vfs == null) {\n+      return super.createPathHandle(st, opts);\n+    }\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public FSDataOutputStream append(final Path f, final int bufferSize,\n+      final Progressable progress) throws IOException {\n+    if (this.vfs == null) {\n+      return super.append(f, bufferSize, progress);\n+    }\n+    return this.vfs.append(f, bufferSize, progress);\n+  }\n+\n+  @Override\n+  public FSDataOutputStream append(Path f, final EnumSet<CreateFlag> flag,\n+      final int bufferSize, final Progressable progress) throws IOException {\n+    if (this.vfs == null) {\n+      return super.append(f, flag, bufferSize, progress);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"append\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .append(mountPathInfo.getPathOnTarget(), flag, bufferSize, progress);\n+  }\n+\n+  @Override\n+  public FSDataOutputStream append(Path f, final EnumSet<CreateFlag> flag,\n+      final int bufferSize, final Progressable progress,\n+      final InetSocketAddress[] favoredNodes) throws IOException {\n+    if (this.vfs == null) {\n+      return super.append(f, flag, bufferSize, progress, favoredNodes);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"append\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .append(mountPathInfo.getPathOnTarget(), flag, bufferSize, progress,\n+            favoredNodes);\n+  }\n+\n+  @Override\n+  public FSDataOutputStream create(Path f, FsPermission permission,\n+      boolean overwrite, int bufferSize, short replication, long blockSize,\n+      Progressable progress) throws IOException {\n+    if (this.vfs == null) {\n+      return super\n+          .create(f, permission, overwrite, bufferSize, replication, blockSize,\n+              progress);\n+    }\n+    return this.vfs\n+        .create(f, permission, overwrite, bufferSize, replication, blockSize,\n+            progress);\n+  }\n+\n+  @Override\n+  public HdfsDataOutputStream create(final Path f,\n+      final FsPermission permission, final boolean overwrite,\n+      final int bufferSize, final short replication, final long blockSize,\n+      final Progressable progress, final InetSocketAddress[] favoredNodes)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super\n+          .create(f, permission, overwrite, bufferSize, replication, blockSize,\n+              progress, favoredNodes);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"create\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .create(mountPathInfo.getPathOnTarget(), permission, overwrite,\n+            bufferSize, replication, blockSize, progress, favoredNodes);\n+  }\n+\n+  @Override\n+  //DFS specific API\n+  public FSDataOutputStream create(final Path f, final FsPermission permission,\n+      final EnumSet<CreateFlag> cflags, final int bufferSize,\n+      final short replication, final long blockSize,\n+      final Progressable progress, final Options.ChecksumOpt checksumOpt)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super\n+          .create(f, permission, cflags, bufferSize, replication, blockSize,\n+              progress, checksumOpt);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"create\");\n+    return mountPathInfo.getTargetFs()\n+        .create(mountPathInfo.getPathOnTarget(), permission, cflags, bufferSize,\n+            replication, blockSize, progress, checksumOpt);\n+  }\n+\n+  void checkDFS(FileSystem fs, String methodName) {\n+    if (!(fs instanceof DistributedFileSystem)) {\n+      throw new UnsupportedOperationException(\n+          \"This API:\" + methodName + \" is specific to DFS. Can't run on other fs:\" + fs\n+              .getUri());\n+    }\n+  }\n+\n+  @Override\n+  // DFS specific API\n+  protected HdfsDataOutputStream primitiveCreate(Path f,\n+      FsPermission absolutePermission, EnumSet<CreateFlag> flag, int bufferSize,\n+      short replication, long blockSize, Progressable progress,\n+      Options.ChecksumOpt checksumOpt) throws IOException {\n+    if (this.vfs == null) {\n+      return super\n+          .primitiveCreate(f, absolutePermission, flag, bufferSize, replication,\n+              blockSize, progress, checksumOpt);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"primitiveCreate\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .primitiveCreate(f, absolutePermission, flag, bufferSize, replication,\n+            blockSize, progress, checksumOpt);\n+  }\n+\n+  @Override\n+  public FSDataOutputStream createNonRecursive(Path f, FsPermission permission,\n+      EnumSet<CreateFlag> flags, int bufferSize, short replication,\n+      long blockSize, Progressable progress) throws IOException {\n+    if (this.vfs == null) {\n+      return super\n+          .createNonRecursive(f, permission, flags, bufferSize, replication,\n+              bufferSize, progress);\n+    }\n+    return this.vfs\n+        .createNonRecursive(f, permission, flags, bufferSize, replication,\n+            bufferSize, progress);\n+  }\n+\n+  @Override\n+  public boolean setReplication(final Path f, final short replication)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.setReplication(f, replication);\n+    }\n+    return this.vfs.setReplication(f, replication);\n+  }\n+\n+  @Override\n+  public void setStoragePolicy(Path src, String policyName) throws IOException {\n+    if (this.vfs == null) {\n+      super.setStoragePolicy(src, policyName);\n+      return;\n+    }\n+    this.vfs.setStoragePolicy(src, policyName);\n+  }\n+\n+  @Override\n+  public void unsetStoragePolicy(Path src) throws IOException {\n+    if (this.vfs == null) {\n+      super.unsetStoragePolicy(src);\n+      return;\n+    }\n+    this.vfs.unsetStoragePolicy(src);\n+  }\n+\n+  @Override\n+  public BlockStoragePolicySpi getStoragePolicy(Path src) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getStoragePolicy(src);\n+    }\n+    return this.vfs.getStoragePolicy(src);\n+  }\n+\n+  @Override\n+  public Collection<BlockStoragePolicy> getAllStoragePolicies()\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getAllStoragePolicies();\n+    }\n+    Collection<? extends BlockStoragePolicySpi> allStoragePolicies =\n+        this.vfs.getAllStoragePolicies();\n+    return (Collection<BlockStoragePolicy>) allStoragePolicies;\n+  }\n+\n+  @Override\n+  public long getBytesWithFutureGenerationStamps() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getBytesWithFutureGenerationStamps();\n+    }\n+    return defaultDFS.getBytesWithFutureGenerationStamps();\n+  }\n+\n+  @Deprecated\n+  @Override\n+  public BlockStoragePolicy[] getStoragePolicies() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getStoragePolicies();\n+    }\n+    return defaultDFS.getStoragePolicies();\n+  }\n+\n+  @Override\n+  //Make sure your target fs supports this API, otherwise you will get\n+  // Unsupported operation exception.\n+  public void concat(Path trg, Path[] psrcs) throws IOException {\n+    if (this.vfs == null) {\n+      super.concat(trg, psrcs);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(trg, getConf());\n+    mountPathInfo.getTargetFs().concat(mountPathInfo.getPathOnTarget(), psrcs);\n+  }\n+\n+  @SuppressWarnings(\"deprecation\")\n+  @Override\n+  public boolean rename(final Path src, final Path dst) throws IOException {\n+    if (this.vfs == null) {\n+      return super.rename(src, dst);\n+    }\n+    if (getMountPoints().length == 0) {\n+      return this.defaultDFS.rename(src, dst);\n+    }\n+    return this.vfs.rename(src, dst);\n+  }\n+\n+  @SuppressWarnings(\"deprecation\")\n+  @Override\n+  public void rename(Path src, Path dst, final Options.Rename... options)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      super.rename(src, dst, options);\n+      return;\n+    }\n+\n+    // TODO: revisit\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountSrcPathInfo =\n+        this.vfs.getMountPathInfo(src, getConf());\n+    checkDFS(mountSrcPathInfo.getTargetFs(), \"rename\");\n+\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountDstPathInfo =\n+        this.vfs.getMountPathInfo(src, getConf());\n+    checkDFS(mountDstPathInfo.getTargetFs(), \"rename\");\n+\n+    //Check both in same cluster.\n+    if (!mountSrcPathInfo.getTargetFs().getUri()\n+        .equals(mountDstPathInfo.getTargetFs().getUri())) {\n+      throw new HadoopIllegalArgumentException(\n+          \"Can't rename across file systems.\");\n+    }\n+\n+    ((DistributedFileSystem) mountSrcPathInfo.getTargetFs())\n+        .rename(mountSrcPathInfo.getPathOnTarget(),\n+            mountDstPathInfo.getPathOnTarget(), options);\n+  }\n+\n+  @Override\n+  public boolean truncate(final Path f, final long newLength)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.truncate(f, newLength);\n+    }\n+    return this.vfs.truncate(f, newLength);\n+  }\n+\n+  public boolean delete(final Path f, final boolean recursive)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.delete(f, recursive);\n+    }\n+    return this.vfs.delete(f, recursive);\n+  }\n+\n+  @Override\n+  public ContentSummary getContentSummary(Path f) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getContentSummary(f);\n+    }\n+    return this.vfs.getContentSummary(f);\n+  }\n+\n+  @Override\n+  public QuotaUsage getQuotaUsage(Path f) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getQuotaUsage(f);\n+    }\n+    return this.vfs.getQuotaUsage(f);\n+  }\n+\n+  @Override\n+  public void setQuota(Path src, final long namespaceQuota,\n+      final long storagespaceQuota) throws IOException {\n+    if (this.vfs == null) {\n+      super.setQuota(src, namespaceQuota, storagespaceQuota);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(src, getConf());\n+    mountPathInfo.getTargetFs()\n+        .setQuota(mountPathInfo.getPathOnTarget(), namespaceQuota,\n+            storagespaceQuota);\n+  }\n+\n+  @Override\n+  public void setQuotaByStorageType(Path src, final StorageType type,\n+      final long quota) throws IOException {\n+    if (this.vfs == null) {\n+      super.setQuotaByStorageType(src, type, quota);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(src, getConf());\n+    mountPathInfo.getTargetFs()\n+        .setQuotaByStorageType(mountPathInfo.getPathOnTarget(), type, quota);\n+  }\n+\n+  @Override\n+  public FileStatus[] listStatus(Path p) throws IOException {\n+    if (this.vfs == null) {\n+      return super.listStatus(p);\n+    }\n+    return this.vfs.listStatus(p);\n+  }\n+\n+  @Override\n+  public RemoteIterator<LocatedFileStatus> listLocatedStatus(final Path f,\n+      final PathFilter filter) throws FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.listLocatedStatus(f, filter);\n+    }\n+    return this.vfs.listLocatedStatus(f, filter);\n+  }\n+\n+  @Override\n+  public RemoteIterator<FileStatus> listStatusIterator(final Path p)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.listStatusIterator(p);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(p, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .listStatusIterator(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public RemoteIterator<PartialListing<FileStatus>> batchedListStatusIterator(\n+      final List<Path> paths) throws IOException {\n+    if (this.vfs == null) {\n+      return super.batchedListStatusIterator(paths);\n+    }\n+    // TODO: revisit for correct implementation.\n+    return this.defaultDFS.batchedListStatusIterator(paths);\n+  }\n+\n+  @Override\n+  public RemoteIterator<PartialListing<LocatedFileStatus>> batchedListLocatedStatusIterator(\n+      final List<Path> paths) throws IOException {\n+    if (this.vfs == null) {\n+      return super.batchedListLocatedStatusIterator(paths);\n+    }\n+    // TODO: revisit for correct implementation.\n+    return this.defaultDFS.batchedListLocatedStatusIterator(paths);\n+  }\n+\n+  public boolean mkdir(Path f, FsPermission permission) throws IOException {\n+    if (this.vfs == null) {\n+      return super.mkdir(f, permission);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"mkdir\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .mkdir(mountPathInfo.getPathOnTarget(), permission);\n+  }\n+\n+  @Override\n+  public boolean mkdirs(Path f, FsPermission permission) throws IOException {\n+    if (this.vfs == null) {\n+      return super.mkdirs(f, permission);\n+    }\n+    return this.vfs.mkdirs(f, permission);\n+  }\n+\n+  @SuppressWarnings(\"deprecation\")\n+  @Override\n+  protected boolean primitiveMkdir(Path f, FsPermission absolutePermission)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.primitiveMkdir(f, absolutePermission);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"primitiveMkdir\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .primitiveMkdir(mountPathInfo.getPathOnTarget(), absolutePermission);\n+  }\n+\n+  @Override\n+  public void close() throws IOException {\n+    if (this.vfs != null) {\n+      this.vfs.close();\n+    }\n+    super.close();\n+  }\n+\n+  @InterfaceAudience.Private\n+  public DFSClient getClient() {\n+    if (this.vfs == null) {\n+      return super.getClient();\n+    }\n+    return defaultDFS.getClient();\n+  }\n+\n+  @Override\n+  public FsStatus getStatus(Path p) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getStatus(p);\n+    }\n+    return this.vfs.getStatus(p);\n+  }\n+\n+  @Override\n+  public long getMissingBlocksCount() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getMissingBlocksCount();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getMissingBlocksCount is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public long getPendingDeletionBlocksCount() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getPendingDeletionBlocksCount();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getPendingDeletionBlocksCount is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public long getMissingReplOneBlocksCount() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getMissingReplOneBlocksCount();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getMissingReplOneBlocksCount is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public long getLowRedundancyBlocksCount() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getLowRedundancyBlocksCount();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getLowRedundancyBlocksCount is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public long getCorruptBlocksCount() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getCorruptBlocksCount();\n+    }\n+    throw new UnsupportedOperationException(\n+        \"getCorruptBlocksCount is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public RemoteIterator<Path> listCorruptFileBlocks(final Path path)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.listCorruptFileBlocks(path);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .listCorruptFileBlocks(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public DatanodeInfo[] getDataNodeStats() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getDataNodeStats();\n+    }\n+    return defaultDFS.getDataNodeStats();\n+  }\n+\n+  @Override\n+  public DatanodeInfo[] getDataNodeStats(\n+      final HdfsConstants.DatanodeReportType type) throws IOException {\n+    if (this.vfs == null) {\n+      return super.getDataNodeStats(type);\n+    }\n+    return defaultDFS.getDataNodeStats(type);\n+  }\n+\n+  @Override\n+  public boolean setSafeMode(HdfsConstants.SafeModeAction action)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.setSafeMode(action);\n+    }\n+    return defaultDFS.setSafeMode(action);\n+  }\n+\n+  @Override\n+  public boolean setSafeMode(HdfsConstants.SafeModeAction action,\n+      boolean isChecked) throws IOException {\n+    if (this.vfs == null) {\n+      return super.setSafeMode(action, isChecked);\n+    }\n+    return defaultDFS.setSafeMode(action, isChecked);\n+  }\n+\n+  @Override\n+  public boolean saveNamespace(long timeWindow, long txGap) throws IOException {\n+    if (this.vfs == null) {\n+      return super.saveNamespace(timeWindow, txGap);\n+    }\n+    return defaultDFS.saveNamespace(timeWindow, txGap);\n+  }\n+\n+  @Override\n+  public void saveNamespace() throws IOException {\n+    if (this.vfs == null) {\n+      super.saveNamespace();\n+      return;\n+    }\n+    defaultDFS.saveNamespace();\n+  }\n+\n+  @Override\n+  public long rollEdits() throws IOException {\n+    if (this.vfs == null) {\n+      return super.rollEdits();\n+    }\n+    return defaultDFS.rollEdits();\n+  }\n+\n+  @Override\n+  public boolean restoreFailedStorage(String arg) throws IOException {\n+    if (this.vfs == null) {\n+      return super.restoreFailedStorage(arg);\n+    }\n+    return defaultDFS.restoreFailedStorage(arg);\n+  }\n+\n+  @Override\n+  public void refreshNodes() throws IOException {\n+    if (this.vfs == null) {\n+      super.refreshNodes();\n+      return;\n+    }\n+    defaultDFS.refreshNodes();\n+  }\n+\n+  @Override\n+  public void finalizeUpgrade() throws IOException {\n+    if (this.vfs == null) {\n+      super.finalizeUpgrade();\n+      return;\n+    }\n+    defaultDFS.finalizeUpgrade();\n+  }\n+\n+  @Override\n+  public boolean upgradeStatus() throws IOException {\n+    if (this.vfs == null) {\n+      return super.upgradeStatus();\n+    }\n+    return defaultDFS.upgradeStatus();\n+  }\n+\n+  @Override\n+  public RollingUpgradeInfo rollingUpgrade(\n+      HdfsConstants.RollingUpgradeAction action) throws IOException {\n+    if (this.vfs == null) {\n+      return super.rollingUpgrade(action);\n+    }\n+    return defaultDFS.rollingUpgrade(action);\n+  }\n+\n+  @Override\n+  public void metaSave(String pathname) throws IOException {\n+    if (this.vfs == null) {\n+      super.metaSave(pathname);\n+      return;\n+    }\n+    defaultDFS.metaSave(pathname);\n+  }\n+\n+  @Override\n+  public FsServerDefaults getServerDefaults() throws IOException {\n+    if (this.vfs == null) {\n+      return super.getServerDefaults();\n+    }\n+    //TODO: Need to revisit.\n+    return defaultDFS.getServerDefaults();\n+  }\n+\n+  @Override\n+  public FileStatus getFileStatus(final Path f)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.getFileStatus(f);\n+    }\n+    return this.vfs.getFileStatus(f);\n+  }\n+\n+  @SuppressWarnings(\"deprecation\")\n+  @Override\n+  public void createSymlink(final Path target, final Path link,\n+      final boolean createParent) throws IOException {\n+     // Regular DFS behavior\n+    if (this.vfs == null) {\n+      super.createSymlink(target, link, createParent);\n+      return;\n+    }\n+\n+    // Mounting ViewHDFS behavior\n+    // TODO: revisit\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(target, getConf());\n+    mountPathInfo.getTargetFs()\n+        .createSymlink(mountPathInfo.getPathOnTarget(), link, createParent);\n+  }\n+\n+  @Override\n+  public boolean supportsSymlinks() {\n+    if (this.vfs == null) {\n+      return super.supportsSymlinks();\n+    }\n+    // TODO: we can enabled later if we want to support symlinks.\n+    return false;\n+  }\n+\n+  @Override\n+  public FileStatus getFileLinkStatus(final Path f) throws IOException {\n+     if(this.vfs==null){\n+       return super.getFileLinkStatus(f);\n+     }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    return mountPathInfo.getTargetFs()\n+        .getFileLinkStatus(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public Path getLinkTarget(Path path) throws IOException {\n+    if(this.vfs==null){\n+      return super.getLinkTarget(path);\n+    }\n+    return this.vfs.getLinkTarget(path);\n+  }\n+\n+  @Override\n+  protected Path resolveLink(Path f) throws IOException {\n+    if(this.vfs==null){\n+      return super.resolveLink(f);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(f, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"resolveLink\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .resolveLink(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public FileChecksum getFileChecksum(final Path f)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      return super.getFileChecksum(f);\n+    }\n+    return this.vfs.getFileChecksum(f);\n+  }\n+\n+  @Override\n+  public void setPermission(final Path f, final FsPermission permission)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      super.setPermission(f, permission);\n+      return;\n+    }\n+    this.vfs.setPermission(f, permission);\n+  }\n+\n+  @Override\n+  public void setOwner(final Path f, final String username,\n+      final String groupname)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      super.setOwner(f, username, groupname);\n+      return;\n+    }\n+    this.vfs.setOwner(f, username, groupname);\n+  }\n+\n+  @Override\n+  public void setTimes(final Path f, final long mtime, final long atime)\n+      throws AccessControlException, FileNotFoundException, IOException {\n+    if (this.vfs == null) {\n+      super.setTimes(f, mtime, atime);\n+      return;\n+    }\n+    this.vfs.setTimes(f, mtime, atime);\n+  }\n+\n+  @Override\n+  // DFS specific API\n+  protected int getDefaultPort() {\n+    return super.getDefaultPort();\n+  }\n+\n+  @Override\n+  public Token<DelegationTokenIdentifier> getDelegationToken(String renewer)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getDelegationToken(renewer);\n+    }\n+    //Let applications call getDelegationTokenIssuers and get respective\n+    // delegation tokens from child fs.\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public void setBalancerBandwidth(long bandwidth) throws IOException {\n+    if (this.vfs == null) {\n+      super.setBalancerBandwidth(bandwidth);\n+      return;\n+    }\n+    defaultDFS.setBalancerBandwidth(bandwidth);\n+  }\n+\n+  @Override\n+  public String getCanonicalServiceName() {\n+    if (this.vfs == null) {\n+      return super.getCanonicalServiceName();\n+    }\n+    return defaultDFS.getCanonicalServiceName();\n+  }\n+\n+  @Override\n+  protected URI canonicalizeUri(URI uri) {\n+    if (this.vfs == null) {\n+      return super.canonicalizeUri(uri);\n+    }\n+\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo = null;\n+    try {\n+      mountPathInfo = this.vfs.getMountPathInfo(new Path(uri), getConf());\n+    } catch (IOException e) {\n+      //LOG.error(\"Failed to resolve the uri as mount path\", e);\n+      return null;\n+    }\n+    checkDFS(mountPathInfo.getTargetFs(), \"canonicalizeUri\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .canonicalizeUri(uri);\n+  }\n+\n+  @Override\n+  public boolean isInSafeMode() throws IOException {\n+    if (this.vfs == null) {\n+      return super.isInSafeMode();\n+    }\n+    return defaultDFS.isInSafeMode();\n+  }\n+\n+  @Override\n+  // DFS specific API\n+  public void allowSnapshot(Path path) throws IOException {\n+    if (this.vfs == null) {\n+      super.allowSnapshot(path);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"allowSnapshot\");\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .allowSnapshot(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public void disallowSnapshot(final Path path) throws IOException {\n+    if (this.vfs == null) {\n+      super.disallowSnapshot(path);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(path, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"disallowSnapshot\");\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .disallowSnapshot(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public Path createSnapshot(Path path, String snapshotName)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.createSnapshot(path, snapshotName);\n+    }\n+    return this.vfs.createSnapshot(path, snapshotName);\n+  }\n+\n+  @Override\n+  public void renameSnapshot(Path path, String snapshotOldName,\n+      String snapshotNewName) throws IOException {\n+    if (this.vfs == null) {\n+      super.renameSnapshot(path, snapshotOldName, snapshotOldName);\n+      return;\n+    }\n+    this.vfs.renameSnapshot(path, snapshotOldName, snapshotNewName);\n+  }\n+\n+  @Override\n+  //Ony for HDFS users\n+  public SnapshottableDirectoryStatus[] getSnapshottableDirListing()\n+      throws IOException {\n+    if (this.vfs == null) {\n+      return super.getSnapshottableDirListing();\n+    }\n+    return defaultDFS.getSnapshottableDirListing();\n+  }\n+\n+  @Override\n+  public void deleteSnapshot(Path path, String snapshotName)\n+      throws IOException {\n+    if (this.vfs == null) {\n+      super.deleteSnapshot(path, snapshotName);\n+      return;\n+    }\n+    this.vfs.deleteSnapshot(path, snapshotName);\n+  }\n+\n+  @Override\n+  public RemoteIterator<SnapshotDiffReportListing> snapshotDiffReportListingRemoteIterator(\n+      final Path snapshotDir, final String fromSnapshot,\n+      final String toSnapshot) throws IOException {\n+     if(this.vfs ==null){\n+       return super.snapshotDiffReportListingRemoteIterator(snapshotDir, fromSnapshot,\n+           toSnapshot);\n+     }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(snapshotDir, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(),\n+        \"snapshotDiffReportListingRemoteIterator\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .snapshotDiffReportListingRemoteIterator(\n+            mountPathInfo.getPathOnTarget(), fromSnapshot, toSnapshot);\n+  }\n+\n+  @Override\n+  public SnapshotDiffReport getSnapshotDiffReport(final Path snapshotDir,\n+      final String fromSnapshot, final String toSnapshot) throws IOException {\n+    if(this.vfs ==null){\n+      return super.getSnapshotDiffReport(snapshotDir, fromSnapshot,\n+          toSnapshot);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(snapshotDir, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"getSnapshotDiffReport\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .getSnapshotDiffReport(snapshotDir, fromSnapshot,\n+            toSnapshot);\n+  }\n+\n+  @Override\n+  public boolean isFileClosed(final Path src) throws IOException {\n+    if (this.vfs == null) {\n+      return super.isFileClosed(src);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(src, getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"isFileClosed\");\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .isFileClosed(mountPathInfo.getPathOnTarget());\n+  }\n+\n+  @Override\n+  public long addCacheDirective(CacheDirectiveInfo info) throws IOException {\n+    if (this.vfs == null) {\n+      return super.addCacheDirective(info);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(info.getPath(), getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"addCacheDirective\");\n+\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .addCacheDirective(new CacheDirectiveInfo.Builder(info)\n+            .setPath(mountPathInfo.getPathOnTarget()).build());\n+  }\n+\n+  @Override\n+  public long addCacheDirective(CacheDirectiveInfo info,\n+      EnumSet<CacheFlag> flags) throws IOException {\n+    if (this.vfs == null) {\n+      return super.addCacheDirective(info, flags);\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(info.getPath(), getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"addCacheDirective\");\n+\n+    return ((DistributedFileSystem) mountPathInfo.getTargetFs())\n+        .addCacheDirective(new CacheDirectiveInfo.Builder(info)\n+            .setPath(mountPathInfo.getPathOnTarget()).build(), flags);\n+  }\n+\n+  @Override\n+  public void modifyCacheDirective(CacheDirectiveInfo info) throws IOException {\n+    if (this.vfs == null) {\n+      super.modifyCacheDirective(info);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(info.getPath(), getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"modifyCacheDirective\");\n+\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs()).modifyCacheDirective(\n+        new CacheDirectiveInfo.Builder(info)\n+            .setPath(mountPathInfo.getPathOnTarget()).build());\n+  }\n+\n+  @Override\n+  public void modifyCacheDirective(CacheDirectiveInfo info,\n+      EnumSet<CacheFlag> flags) throws IOException {\n+    if (this.vfs == null) {\n+      super.modifyCacheDirective(info, flags);\n+      return;\n+    }\n+    ViewFileSystemOverloadScheme.MountPathInfo<FileSystem> mountPathInfo =\n+        this.vfs.getMountPathInfo(info.getPath(), getConf());\n+    checkDFS(mountPathInfo.getTargetFs(), \"modifyCacheDirective\");\n+\n+    ((DistributedFileSystem) mountPathInfo.getTargetFs()).modifyCacheDirective(\n+        new CacheDirectiveInfo.Builder(info)\n+            .setPath(mountPathInfo.getPathOnTarget()).build(), flags);\n+  }\n+\n+  @Override\n+  public void removeCacheDirective(long id) throws IOException {\n+    if (this.vfs == null) {\n+      super.removeCacheDirective(id);\n+      return;\n+    }\n+    //defaultDFS.removeCacheDirective(id);\n+    //TODO: ? this can create issues in default cluster\n+    // if user intention is to call on specific mount.\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public RemoteIterator<CacheDirectiveEntry> listCacheDirectives(\n+      CacheDirectiveInfo filter) throws IOException {\n+    if (this.vfs == null) {\n+      return super.listCacheDirectives(filter);\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listCacheDirectives is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public void addCachePool(CachePoolInfo info) throws IOException {\n+    if (this.vfs == null) {\n+      super.addCachePool(info);\n+      return;\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listCacheDirectives is not supported in ViewDFS\");\n+  }\n+\n+  @Override\n+  public void modifyCachePool(CachePoolInfo info) throws IOException {\n+    if (this.vfs == null) {\n+      super.modifyCachePool(info);\n+      return;\n+    }\n+    throw new UnsupportedOperationException(\n+        \"listCacheDirectives is not supported in ViewDFS\");", "originalCommit": "33902b0e36c9d1f41195d9fc31af21f5de5f222d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTA1MDIwNg==", "url": "https://github.com/apache/hadoop/pull/2229#discussion_r471050206", "bodyText": "Other cache related APIs passing CacheDirectInfo which has path. But CachePool api are not passing. Any I just delegated them to defaultFS currently.", "author": "umamaheswararao", "createdAt": "2020-08-16T01:02:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkzODAwMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTA4MzgzNA==", "url": "https://github.com/apache/hadoop/pull/2229#discussion_r471083834", "bodyText": "if the cachePool API's are going to defaultDFS, it may impact the cacheDirective API's as well, I think while adding a cacheDirective there is an option of setPool in cacheDirectiveBuilder, so if we do a listCachePools it will show the cachePools from defaultDFS which eventually might not work for the other FS.\nIIRC listCachePools doesn't seems to have a superuser check as well, if so, we shouldn't block this call as well.", "author": "ayushtkn", "createdAt": "2020-08-16T08:32:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkzODAwMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjU3ODUxNw==", "url": "https://github.com/apache/hadoop/pull/2229#discussion_r472578517", "bodyText": "I did attempt to shoot to all child fs for cache pool apis. Please check if they are making sense.", "author": "umamaheswararao", "createdAt": "2020-08-19T01:14:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkzODAwMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgyMjE4OA==", "url": "https://github.com/apache/hadoop/pull/2229#discussion_r472822188", "bodyText": "Yahh, That looks good", "author": "ayushtkn", "createdAt": "2020-08-19T07:49:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkzODAwMw=="}], "type": "inlineReview"}, {"oid": "707e34ad43fb069d8fc5fc94a9d35804eb5eac43", "url": "https://github.com/apache/hadoop/commit/707e34ad43fb069d8fc5fc94a9d35804eb5eac43", "message": "HDFS-15533: Provide DFS API compatible class, but use ViewFileSystemOverloadScheme inside.", "committedDate": "2020-08-15T09:21:24Z", "type": "commit"}, {"oid": "dea727ce138877139190204a4e1b50c8106dbeb2", "url": "https://github.com/apache/hadoop/commit/dea727ce138877139190204a4e1b50c8106dbeb2", "message": "HDFS-15533: Provide DFS API compatible class, but use ViewFileSystemOverloadScheme inside.", "committedDate": "2020-08-16T00:00:48Z", "type": "commit"}, {"oid": "c79ce86b454329aa06ed8b9aa0346194e149a0f3", "url": "https://github.com/apache/hadoop/commit/c79ce86b454329aa06ed8b9aa0346194e149a0f3", "message": "HDFS-15533: All EC APIs will be delegated all child APIs.", "committedDate": "2020-08-16T23:52:59Z", "type": "commit"}, {"oid": "933b64846f25365dbea47dc438ec86f7abbd883c", "url": "https://github.com/apache/hadoop/commit/933b64846f25365dbea47dc438ec86f7abbd883c", "message": "HDFS-15533: All CachePool APIs changed to delegate to all childfs", "committedDate": "2020-08-18T22:43:26Z", "type": "commit"}]}