{"pr_number": 1964, "pr_title": "HDFS-15281. ZKFC ignores dfs.namenode.rpc-bind-host and uses dfs.namenode.rpc-address to bind to host address", "pr_createdAt": "2020-04-19T04:52:36Z", "pr_url": "https://github.com/apache/hadoop/pull/1964", "timeline": [{"oid": "ca13aaf4d0ca511f301c378cedca65876bbd2af0", "url": "https://github.com/apache/hadoop/commit/ca13aaf4d0ca511f301c378cedca65876bbd2af0", "message": "HDFS-15281: Make sure ZKFC uses dfs.namenode.rpc-address to bind to host address", "committedDate": "2020-04-19T04:43:50Z", "type": "commit"}, {"oid": "588e0e0a2bee7279156185c983318a0a74c5380d", "url": "https://github.com/apache/hadoop/commit/588e0e0a2bee7279156185c983318a0a74c5380d", "message": "Merge branch 'trunk' into HDFS-15281", "committedDate": "2020-04-19T04:45:47Z", "type": "commit"}, {"oid": "43cefff8950d452de22b06379bb90d2b8271015b", "url": "https://github.com/apache/hadoop/commit/43cefff8950d452de22b06379bb90d2b8271015b", "message": "HDFS-15281: Remove whitespaces", "committedDate": "2020-04-19T19:42:30Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTEwOTg0NQ==", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r411109845", "bodyText": "nit: this can be one blank line.", "author": "liuml07", "createdAt": "2020-04-20T05:51:18Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSZKFCRespectsBindHostKeys.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs.tools;\n+\n+import static org.hamcrest.core.IsNot.not;\n+import static org.hamcrest.core.Is.is;\n+import static org.junit.Assert.assertThat;\n+import org.apache.hadoop.hdfs.DFSConfigKeys;\n+import org.apache.hadoop.hdfs.MiniDFSNNTopology;\n+import org.apache.hadoop.net.ServerSocketUtil;\n+import org.junit.Test;\n+import java.io.IOException;\n+import org.apache.commons.logging.Log;\n+import org.apache.commons.logging.LogFactory;\n+import org.apache.hadoop.conf.Configuration;\n+import static org.apache.hadoop.hdfs.DFSConfigKeys.*;\n+\n+", "originalCommit": "43cefff8950d452de22b06379bb90d2b8271015b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTEyMDkwNQ==", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r411120905", "bodyText": "Alternatively, this test can go to TestDFSZKFailoverController? We may reuse existing setup and shutdown methods hopefully?", "author": "liuml07", "createdAt": "2020-04-20T06:20:15Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSZKFCRespectsBindHostKeys.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs.tools;\n+\n+import static org.hamcrest.core.IsNot.not;\n+import static org.hamcrest.core.Is.is;\n+import static org.junit.Assert.assertThat;\n+import org.apache.hadoop.hdfs.DFSConfigKeys;\n+import org.apache.hadoop.hdfs.MiniDFSNNTopology;\n+import org.apache.hadoop.net.ServerSocketUtil;\n+import org.junit.Test;\n+import java.io.IOException;\n+import org.apache.commons.logging.Log;\n+import org.apache.commons.logging.LogFactory;\n+import org.apache.hadoop.conf.Configuration;\n+import static org.apache.hadoop.hdfs.DFSConfigKeys.*;\n+\n+\n+import org.apache.hadoop.hdfs.HdfsConfiguration;\n+import org.apache.hadoop.hdfs.MiniDFSCluster;\n+\n+public class TestDFSZKFCRespectsBindHostKeys {", "originalCommit": "43cefff8950d452de22b06379bb90d2b8271015b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc0MzY3Nw==", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r412743677", "bodyText": "Fixed. I moved tests case to TestDFSZKFailoverController", "author": "dhirajh", "createdAt": "2020-04-22T07:36:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTEyMDkwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTEyMzI0NQ==", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r411123245", "bodyText": "nit: remove blank lines within try clause? Seems related statements. It's fine if you prefer keeping them.\nnit: line length is usually 80 characters. You can check the checkstyle reports from the QA comment, for e.g. https://builds.apache.org/job/hadoop-multibranch/job/PR-1964/2/artifact/out/diff-checkstyle-root.txt", "author": "liuml07", "createdAt": "2020-04-20T06:25:39Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSZKFCRespectsBindHostKeys.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs.tools;\n+\n+import static org.hamcrest.core.IsNot.not;\n+import static org.hamcrest.core.Is.is;\n+import static org.junit.Assert.assertThat;\n+import org.apache.hadoop.hdfs.DFSConfigKeys;\n+import org.apache.hadoop.hdfs.MiniDFSNNTopology;\n+import org.apache.hadoop.net.ServerSocketUtil;\n+import org.junit.Test;\n+import java.io.IOException;\n+import org.apache.commons.logging.Log;\n+import org.apache.commons.logging.LogFactory;\n+import org.apache.hadoop.conf.Configuration;\n+import static org.apache.hadoop.hdfs.DFSConfigKeys.*;\n+\n+\n+import org.apache.hadoop.hdfs.HdfsConfiguration;\n+import org.apache.hadoop.hdfs.MiniDFSCluster;\n+\n+public class TestDFSZKFCRespectsBindHostKeys {\n+    public static final Log LOG = LogFactory.getLog(TestDFSZKFCRespectsBindHostKeys.class);\n+    private static final String WILDCARD_ADDRESS = \"0.0.0.0\";\n+    private static final String LOCALHOST_SERVER_ADDRESS = \"127.0.0.1\";\n+\n+    @Test(timeout=300000)\n+    public void testRpcBindHostKey() throws IOException {\n+        Configuration conf = new HdfsConfiguration();\n+        MiniDFSCluster cluster = null;\n+        //conf.set(ZKFailoverController.ZK_QUORUM_KEY + \".ns1\", hostPort);\n+        conf.setInt(DFSConfigKeys.DFS_HA_ZKFC_PORT_KEY + \".ns1.nn1\",\n+                ServerSocketUtil.getPort(10023, 100));\n+        conf.setInt(DFSConfigKeys.DFS_HA_ZKFC_PORT_KEY + \".ns1.nn2\",\n+                ServerSocketUtil.getPort(10024, 100));\n+\n+        LOG.info(\"Testing without \" + DFS_NAMENODE_RPC_BIND_HOST_KEY);\n+\n+        // prefer non-ephemeral port to avoid port collision on restartNameNode\n+        MiniDFSNNTopology topology = new MiniDFSNNTopology()\n+                .addNameservice(new MiniDFSNNTopology.NSConf(\"ns1\")\n+                        .addNN(new MiniDFSNNTopology.NNConf(\"nn1\")\n+                                .setIpcPort(ServerSocketUtil.getPort(10021, 100)))\n+                        .addNN(new MiniDFSNNTopology.NNConf(\"nn2\")\n+                                .setIpcPort(ServerSocketUtil.getPort(10022, 100))));\n+        // ZKFC should not bind the wildcard address by default.\n+        try {\n+", "originalCommit": "43cefff8950d452de22b06379bb90d2b8271015b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc0NDEzNg==", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r412744136", "bodyText": "Fixed", "author": "dhirajh", "createdAt": "2020-04-22T07:36:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTEyMzI0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTEyNDU4Mg==", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r411124582", "bodyText": "nit: assertEquals is simpler.\nassertThat(\"Bind address not expected to be wildcard by default.\",\n    LOCALHOST_SERVER_ADDRESS, zkfc.getRpcAddressToBindTo().getHostString());", "author": "liuml07", "createdAt": "2020-04-20T06:28:40Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSZKFCRespectsBindHostKeys.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs.tools;\n+\n+import static org.hamcrest.core.IsNot.not;\n+import static org.hamcrest.core.Is.is;\n+import static org.junit.Assert.assertThat;\n+import org.apache.hadoop.hdfs.DFSConfigKeys;\n+import org.apache.hadoop.hdfs.MiniDFSNNTopology;\n+import org.apache.hadoop.net.ServerSocketUtil;\n+import org.junit.Test;\n+import java.io.IOException;\n+import org.apache.commons.logging.Log;\n+import org.apache.commons.logging.LogFactory;\n+import org.apache.hadoop.conf.Configuration;\n+import static org.apache.hadoop.hdfs.DFSConfigKeys.*;\n+\n+\n+import org.apache.hadoop.hdfs.HdfsConfiguration;\n+import org.apache.hadoop.hdfs.MiniDFSCluster;\n+\n+public class TestDFSZKFCRespectsBindHostKeys {\n+    public static final Log LOG = LogFactory.getLog(TestDFSZKFCRespectsBindHostKeys.class);\n+    private static final String WILDCARD_ADDRESS = \"0.0.0.0\";\n+    private static final String LOCALHOST_SERVER_ADDRESS = \"127.0.0.1\";\n+\n+    @Test(timeout=300000)\n+    public void testRpcBindHostKey() throws IOException {\n+        Configuration conf = new HdfsConfiguration();\n+        MiniDFSCluster cluster = null;\n+        //conf.set(ZKFailoverController.ZK_QUORUM_KEY + \".ns1\", hostPort);\n+        conf.setInt(DFSConfigKeys.DFS_HA_ZKFC_PORT_KEY + \".ns1.nn1\",\n+                ServerSocketUtil.getPort(10023, 100));\n+        conf.setInt(DFSConfigKeys.DFS_HA_ZKFC_PORT_KEY + \".ns1.nn2\",\n+                ServerSocketUtil.getPort(10024, 100));\n+\n+        LOG.info(\"Testing without \" + DFS_NAMENODE_RPC_BIND_HOST_KEY);\n+\n+        // prefer non-ephemeral port to avoid port collision on restartNameNode\n+        MiniDFSNNTopology topology = new MiniDFSNNTopology()\n+                .addNameservice(new MiniDFSNNTopology.NSConf(\"ns1\")\n+                        .addNN(new MiniDFSNNTopology.NNConf(\"nn1\")\n+                                .setIpcPort(ServerSocketUtil.getPort(10021, 100)))\n+                        .addNN(new MiniDFSNNTopology.NNConf(\"nn2\")\n+                                .setIpcPort(ServerSocketUtil.getPort(10022, 100))));\n+        // ZKFC should not bind the wildcard address by default.\n+        try {\n+\n+            cluster = new MiniDFSCluster.Builder(conf).nnTopology(topology).numDataNodes(0).build();\n+\n+            DFSZKFailoverController zkfc = DFSZKFailoverController.create(\n+                    conf);\n+\n+            assertThat(\"Bind address not expected to be wildcard by default.\",", "originalCommit": "43cefff8950d452de22b06379bb90d2b8271015b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc0NDI0NQ==", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r412744245", "bodyText": "Fixed.", "author": "dhirajh", "createdAt": "2020-04-22T07:36:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTEyNDU4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTEyNjIxMQ==", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r411126211", "bodyText": "If you like, you can use try-with on MiniDFSCluster, e.g.\ntry (MiniDFSCluster cluster = new MiniDFSCluster.Builder...) {\n    // some stuff using cluster\n}\n\nand later\ntry (MiniDFSCluster cluster = new MiniDFSCluster.Builder...) {\n    // some stuff using cluster\n}\n\nwithout name conflicts and no necessary to reset cluster to null in-between.\nBut if you move this to TestDFSZKFailoverController, we can split this test method into two methods and reuse the mini cluster defined there. I'm fine either way.", "author": "liuml07", "createdAt": "2020-04-20T06:32:31Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSZKFCRespectsBindHostKeys.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs.tools;\n+\n+import static org.hamcrest.core.IsNot.not;\n+import static org.hamcrest.core.Is.is;\n+import static org.junit.Assert.assertThat;\n+import org.apache.hadoop.hdfs.DFSConfigKeys;\n+import org.apache.hadoop.hdfs.MiniDFSNNTopology;\n+import org.apache.hadoop.net.ServerSocketUtil;\n+import org.junit.Test;\n+import java.io.IOException;\n+import org.apache.commons.logging.Log;\n+import org.apache.commons.logging.LogFactory;\n+import org.apache.hadoop.conf.Configuration;\n+import static org.apache.hadoop.hdfs.DFSConfigKeys.*;\n+\n+\n+import org.apache.hadoop.hdfs.HdfsConfiguration;\n+import org.apache.hadoop.hdfs.MiniDFSCluster;\n+\n+public class TestDFSZKFCRespectsBindHostKeys {\n+    public static final Log LOG = LogFactory.getLog(TestDFSZKFCRespectsBindHostKeys.class);\n+    private static final String WILDCARD_ADDRESS = \"0.0.0.0\";\n+    private static final String LOCALHOST_SERVER_ADDRESS = \"127.0.0.1\";\n+\n+    @Test(timeout=300000)\n+    public void testRpcBindHostKey() throws IOException {\n+        Configuration conf = new HdfsConfiguration();\n+        MiniDFSCluster cluster = null;\n+        //conf.set(ZKFailoverController.ZK_QUORUM_KEY + \".ns1\", hostPort);\n+        conf.setInt(DFSConfigKeys.DFS_HA_ZKFC_PORT_KEY + \".ns1.nn1\",\n+                ServerSocketUtil.getPort(10023, 100));\n+        conf.setInt(DFSConfigKeys.DFS_HA_ZKFC_PORT_KEY + \".ns1.nn2\",\n+                ServerSocketUtil.getPort(10024, 100));\n+\n+        LOG.info(\"Testing without \" + DFS_NAMENODE_RPC_BIND_HOST_KEY);\n+\n+        // prefer non-ephemeral port to avoid port collision on restartNameNode\n+        MiniDFSNNTopology topology = new MiniDFSNNTopology()\n+                .addNameservice(new MiniDFSNNTopology.NSConf(\"ns1\")\n+                        .addNN(new MiniDFSNNTopology.NNConf(\"nn1\")\n+                                .setIpcPort(ServerSocketUtil.getPort(10021, 100)))\n+                        .addNN(new MiniDFSNNTopology.NNConf(\"nn2\")\n+                                .setIpcPort(ServerSocketUtil.getPort(10022, 100))));\n+        // ZKFC should not bind the wildcard address by default.\n+        try {", "originalCommit": "43cefff8950d452de22b06379bb90d2b8271015b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc0MzgzNg==", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r412743836", "bodyText": "Went with the first suggestion", "author": "dhirajh", "createdAt": "2020-04-22T07:36:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTEyNjIxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTEzMjgwMw==", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r411132803", "bodyText": "nit: not used?", "author": "liuml07", "createdAt": "2020-04-20T06:47:03Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSZKFCRespectsBindHostKeys.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs.tools;\n+\n+import static org.hamcrest.core.IsNot.not;", "originalCommit": "43cefff8950d452de22b06379bb90d2b8271015b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc0MzQwMw==", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r412743403", "bodyText": "Fixed", "author": "dhirajh", "createdAt": "2020-04-22T07:35:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTEzMjgwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTEzMzE2OA==", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r411133168", "bodyText": "I'm thinking, since we care more about the service RPC binding host, this config should be setting that only.\nconf.set(DFS_NAMENODE_SERVICE_RPC_BIND_HOST_KEY, WILDCARD_ADDRESS);\n\nIs this agreed?", "author": "liuml07", "createdAt": "2020-04-20T06:47:52Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSZKFCRespectsBindHostKeys.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs.tools;\n+\n+import static org.hamcrest.core.IsNot.not;\n+import static org.hamcrest.core.Is.is;\n+import static org.junit.Assert.assertThat;\n+import org.apache.hadoop.hdfs.DFSConfigKeys;\n+import org.apache.hadoop.hdfs.MiniDFSNNTopology;\n+import org.apache.hadoop.net.ServerSocketUtil;\n+import org.junit.Test;\n+import java.io.IOException;\n+import org.apache.commons.logging.Log;\n+import org.apache.commons.logging.LogFactory;\n+import org.apache.hadoop.conf.Configuration;\n+import static org.apache.hadoop.hdfs.DFSConfigKeys.*;\n+\n+\n+import org.apache.hadoop.hdfs.HdfsConfiguration;\n+import org.apache.hadoop.hdfs.MiniDFSCluster;\n+\n+public class TestDFSZKFCRespectsBindHostKeys {\n+    public static final Log LOG = LogFactory.getLog(TestDFSZKFCRespectsBindHostKeys.class);\n+    private static final String WILDCARD_ADDRESS = \"0.0.0.0\";\n+    private static final String LOCALHOST_SERVER_ADDRESS = \"127.0.0.1\";\n+\n+    @Test(timeout=300000)\n+    public void testRpcBindHostKey() throws IOException {\n+        Configuration conf = new HdfsConfiguration();\n+        MiniDFSCluster cluster = null;\n+        //conf.set(ZKFailoverController.ZK_QUORUM_KEY + \".ns1\", hostPort);\n+        conf.setInt(DFSConfigKeys.DFS_HA_ZKFC_PORT_KEY + \".ns1.nn1\",\n+                ServerSocketUtil.getPort(10023, 100));\n+        conf.setInt(DFSConfigKeys.DFS_HA_ZKFC_PORT_KEY + \".ns1.nn2\",\n+                ServerSocketUtil.getPort(10024, 100));\n+\n+        LOG.info(\"Testing without \" + DFS_NAMENODE_RPC_BIND_HOST_KEY);\n+\n+        // prefer non-ephemeral port to avoid port collision on restartNameNode\n+        MiniDFSNNTopology topology = new MiniDFSNNTopology()\n+                .addNameservice(new MiniDFSNNTopology.NSConf(\"ns1\")\n+                        .addNN(new MiniDFSNNTopology.NNConf(\"nn1\")\n+                                .setIpcPort(ServerSocketUtil.getPort(10021, 100)))\n+                        .addNN(new MiniDFSNNTopology.NNConf(\"nn2\")\n+                                .setIpcPort(ServerSocketUtil.getPort(10022, 100))));\n+        // ZKFC should not bind the wildcard address by default.\n+        try {\n+\n+            cluster = new MiniDFSCluster.Builder(conf).nnTopology(topology).numDataNodes(0).build();\n+\n+            DFSZKFailoverController zkfc = DFSZKFailoverController.create(\n+                    conf);\n+\n+            assertThat(\"Bind address not expected to be wildcard by default.\",\n+                    zkfc.getRpcAddressToBindTo().getHostString(), is(LOCALHOST_SERVER_ADDRESS));\n+        } finally {\n+            if (cluster != null) {\n+                cluster.shutdown();\n+                cluster = null;\n+            }\n+        }\n+\n+        LOG.info(\"Testing with \" + DFS_NAMENODE_RPC_BIND_HOST_KEY);\n+\n+        // Tell NN to bind the wildcard address.\n+        conf.set(DFS_NAMENODE_RPC_BIND_HOST_KEY, WILDCARD_ADDRESS);", "originalCommit": "43cefff8950d452de22b06379bb90d2b8271015b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc0NDMyOQ==", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r412744329", "bodyText": "Fixed.", "author": "dhirajh", "createdAt": "2020-04-22T07:37:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTEzMzE2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTEzNTE2OA==", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r411135168", "bodyText": "This actually can be private static.\n\nFirst it can be static because it does not refer to this ZKFC object fields\nOther methods are protected I guess because they are overriding parent class ZKFailoverController methods. When overriding, we can not change the scope to a smaller one (aka weaker access privilege). So here we keep the protected keyword.", "author": "liuml07", "createdAt": "2020-04-20T06:51:50Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSZKFailoverController.java", "diffHunk": "@@ -111,21 +111,37 @@ protected HAServiceTarget dataToTarget(byte[] data) {\n   @Override\n   protected InetSocketAddress getRpcAddressToBindTo() {\n     int zkfcPort = getZkfcPort(conf);\n-    return new InetSocketAddress(localTarget.getAddress().getAddress(),\n-          zkfcPort);\n+    String zkfcBindAddr = getZkfcServerBindHost(conf);\n+    if (zkfcBindAddr == null || zkfcBindAddr.isEmpty()) {\n+      zkfcBindAddr = localTarget.getAddress().getAddress().getHostAddress();\n+    }\n+    return new InetSocketAddress(zkfcBindAddr, zkfcPort);\n   }\n-  \n \n   @Override\n   protected PolicyProvider getPolicyProvider() {\n     return new HDFSPolicyProvider();\n   }\n-  \n+\n   static int getZkfcPort(Configuration conf) {\n     return conf.getInt(DFSConfigKeys.DFS_HA_ZKFC_PORT_KEY,\n         DFSConfigKeys.DFS_HA_ZKFC_PORT_DEFAULT);\n   }\n-  \n+\n+  /** Given a configuration get the bind host that could be used by ZKFC.\n+   * We derive it from NN service rpc bind host or NN rpc bind host.\n+   */\n+  protected String getZkfcServerBindHost(Configuration conf) {", "originalCommit": "43cefff8950d452de22b06379bb90d2b8271015b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc0MzI4MQ==", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r412743281", "bodyText": "Fixed", "author": "dhirajh", "createdAt": "2020-04-22T07:35:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTEzNTE2OA=="}], "type": "inlineReview"}, {"oid": "d8b4db1fc0e59c183d0725e3754f1d8d0085f115", "url": "https://github.com/apache/hadoop/commit/d8b4db1fc0e59c183d0725e3754f1d8d0085f115", "message": "Address code review comments", "committedDate": "2020-04-22T08:21:00Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDk0NTA0MA==", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r410945040", "bodyText": "Use the logger format with {}", "author": "goiri", "createdAt": "2020-04-19T16:50:44Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ha/ZKFailoverController.java", "diffHunk": "@@ -321,6 +321,7 @@ private void initHM() {\n   \n   protected void initRPC() throws IOException {\n     InetSocketAddress bindAddr = getRpcAddressToBindTo();\n+    LOG.info(\"ZKFC RpcServer binding to \" + bindAddr);", "originalCommit": "588e0e0a2bee7279156185c983318a0a74c5380d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM5Mjk2Mg==", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r413392962", "bodyText": "Fixed", "author": "dhirajh", "createdAt": "2020-04-22T23:08:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDk0NTA0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDk0NTE3NQ==", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r410945175", "bodyText": "Use standard javadoc with a break line and add the param and the return.", "author": "goiri", "createdAt": "2020-04-19T16:51:22Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSZKFailoverController.java", "diffHunk": "@@ -125,7 +128,21 @@ static int getZkfcPort(Configuration conf) {\n     return conf.getInt(DFSConfigKeys.DFS_HA_ZKFC_PORT_KEY,\n         DFSConfigKeys.DFS_HA_ZKFC_PORT_DEFAULT);\n   }\n-  \n+ \n+  /** Given a configuration get the bind host that could be used by ZKFC.", "originalCommit": "588e0e0a2bee7279156185c983318a0a74c5380d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDk0NTYyNg==", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r410945626", "bodyText": "It kind of comes from HAUtil but let's make it right here.", "author": "goiri", "createdAt": "2020-04-19T16:54:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDk0NTE3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM5MzEyNA==", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r413393124", "bodyText": "Fixed. Added javadoc", "author": "dhirajh", "createdAt": "2020-04-22T23:08:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDk0NTE3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDk0NTgyNA==", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r410945824", "bodyText": "As this is already checking for ==null or isEmpty() this is redundant with getZkfcServerBindHost() we could just return the value instead of doing line 139.", "author": "goiri", "createdAt": "2020-04-19T16:55:53Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSZKFailoverController.java", "diffHunk": "@@ -111,8 +111,11 @@ protected HAServiceTarget dataToTarget(byte[] data) {\n   @Override\n   protected InetSocketAddress getRpcAddressToBindTo() {\n     int zkfcPort = getZkfcPort(conf);\n-    return new InetSocketAddress(localTarget.getAddress().getAddress(),\n-          zkfcPort);\n+    String zkfcBindAddr = getZkfcServerBindHost(conf);\n+    if (zkfcBindAddr == null || zkfcBindAddr.isEmpty()) {", "originalCommit": "588e0e0a2bee7279156185c983318a0a74c5380d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM5MzAzNQ==", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r413393035", "bodyText": "Fixed, removed the lines.", "author": "dhirajh", "createdAt": "2020-04-22T23:08:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDk0NTgyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDk0NTg5NQ==", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r410945895", "bodyText": "Use logger", "author": "goiri", "createdAt": "2020-04-19T16:56:08Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSZKFCRespectsBindHostKeys.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hdfs.tools;\n+\n+import static org.hamcrest.core.IsNot.not;\n+import static org.hamcrest.core.Is.is;\n+import static org.junit.Assert.assertThat;\n+import org.apache.hadoop.hdfs.DFSConfigKeys;\n+import org.apache.hadoop.hdfs.MiniDFSNNTopology;\n+import org.apache.hadoop.net.ServerSocketUtil;\n+import org.junit.Test;\n+import java.io.IOException;\n+import org.apache.commons.logging.Log;\n+import org.apache.commons.logging.LogFactory;\n+import org.apache.hadoop.conf.Configuration;\n+import static org.apache.hadoop.hdfs.DFSConfigKeys.*;\n+\n+\n+import org.apache.hadoop.hdfs.HdfsConfiguration;\n+import org.apache.hadoop.hdfs.MiniDFSCluster;\n+\n+public class TestDFSZKFCRespectsBindHostKeys {\n+    public static final Log LOG = LogFactory.getLog(TestDFSZKFCRespectsBindHostKeys.class);", "originalCommit": "588e0e0a2bee7279156185c983318a0a74c5380d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzMyOTY1Ng==", "url": "https://github.com/apache/hadoop/pull/1964#discussion_r413329656", "bodyText": "He has moved tests to the existing test class so this file is deleted.", "author": "liuml07", "createdAt": "2020-04-22T21:00:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDk0NTg5NQ=="}], "type": "inlineReview"}, {"oid": "455e972326fdd940b1114e86fd599397987d489e", "url": "https://github.com/apache/hadoop/commit/455e972326fdd940b1114e86fd599397987d489e", "message": "Address more code review comments", "committedDate": "2020-04-23T00:19:05Z", "type": "commit"}, {"oid": "5397caf93392612bcf4d7b41a064d320274a7258", "url": "https://github.com/apache/hadoop/commit/5397caf93392612bcf4d7b41a064d320274a7258", "message": "Fix style issue", "committedDate": "2020-04-24T07:11:44Z", "type": "commit"}]}