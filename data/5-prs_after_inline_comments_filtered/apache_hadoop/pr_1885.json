{"pr_number": 1885, "pr_title": "HDFS-13639. SlotReleaser is not fast enough", "pr_createdAt": "2020-03-08T09:11:00Z", "pr_url": "https://github.com/apache/hadoop/pull/1885", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwMDg4Mw==", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r425900883", "bodyText": "suggeset to use assertEquals()", "author": "jojochuang", "createdAt": "2020-05-15T16:04:57Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -909,4 +910,90 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test\n+  public void testDomainSocketClosedByDN() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf =\n+        createShortCircuitConf(\"testDomainSocketClosedByDN\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    Slot slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot2.getSlotId(), false);\n+\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    // make the DataXceiver timedout\n+    Thread.sleep(5000);\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(10000);\n+    Assert.assertTrue(cluster.getDataNodes().get(0).getShortCircuitRegistry()", "originalCommit": "49e8948ec052fcd2f45626e7f360c8553821654b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjI3ODU1Mg==", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r426278552", "bodyText": "done", "author": "leosunli", "createdAt": "2020-05-17T16:17:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwMDg4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwMDk5Mw==", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r425900993", "bodyText": "ditto", "author": "jojochuang", "createdAt": "2020-05-15T16:05:08Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -909,4 +910,90 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test\n+  public void testDomainSocketClosedByDN() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf =\n+        createShortCircuitConf(\"testDomainSocketClosedByDN\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    Slot slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot2.getSlotId(), false);\n+\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    // make the DataXceiver timedout\n+    Thread.sleep(5000);\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(10000);\n+    Assert.assertTrue(cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .getShmNum() == 0);\n+    Assert.assertTrue(cache.getDfsClientShmManager().getShmNum() == 0);", "originalCommit": "49e8948ec052fcd2f45626e7f360c8553821654b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjI3ODU0MQ==", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r426278541", "bodyText": "done", "author": "leosunli", "createdAt": "2020-05-17T16:17:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwMDk5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwMzY0Nw==", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r425903647", "bodyText": "please add test timeout", "author": "jojochuang", "createdAt": "2020-05-15T16:09:45Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -909,4 +910,90 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test", "originalCommit": "49e8948ec052fcd2f45626e7f360c8553821654b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjI3ODUyOQ==", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r426278529", "bodyText": "done", "author": "leosunli", "createdAt": "2020-05-17T16:17:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwMzY0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwMzgyNA==", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r425903824", "bodyText": "Can we make this sleep time shorter? Waiting for 15 seconds seems too excessive. You may have to change the timeout configuration.", "author": "jojochuang", "createdAt": "2020-05-15T16:10:01Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -909,4 +910,90 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test\n+  public void testDomainSocketClosedByDN() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf =\n+        createShortCircuitConf(\"testDomainSocketClosedByDN\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    Slot slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot2.getSlotId(), false);\n+\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    // make the DataXceiver timedout\n+    Thread.sleep(5000);\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(10000);", "originalCommit": "49e8948ec052fcd2f45626e7f360c8553821654b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjI3ODUxMQ==", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r426278511", "bodyText": "done", "author": "leosunli", "createdAt": "2020-05-17T16:17:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwMzgyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwNDgzMg==", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r425904832", "bodyText": "is the mini cluster required? starting a mini cluster takes time and prone to flaky failures. Would be nice to avoid using it.", "author": "jojochuang", "createdAt": "2020-05-15T16:11:54Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -909,4 +910,90 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test\n+  public void testDomainSocketClosedByDN() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf =\n+        createShortCircuitConf(\"testDomainSocketClosedByDN\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    Slot slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot2.getSlotId(), false);\n+\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    // make the DataXceiver timedout\n+    Thread.sleep(5000);\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(10000);\n+    Assert.assertTrue(cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .getShmNum() == 0);\n+    Assert.assertTrue(cache.getDfsClientShmManager().getShmNum() == 0);\n+    cluster.shutdown();\n+  }\n+\n+  @Test\n+  public void testDNRestart() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf = createShortCircuitConf(\"testDNRestart\", sockDir);\n+    MiniDFSCluster cluster =", "originalCommit": "49e8948ec052fcd2f45626e7f360c8553821654b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjI3ODQ5NQ==", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r426278495", "bodyText": "the mini cluster is required. i use the mini cluster in a lot ut.\nWould you have any good way to replace it\uff1f", "author": "leosunli", "createdAt": "2020-05-17T16:17:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwNDgzMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzU0MjU3Ng==", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r427542576", "bodyText": "Ok. That's fine.", "author": "jojochuang", "createdAt": "2020-05-19T19:19:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwNDgzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwNTA1MQ==", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r425905051", "bodyText": "assertEquals()", "author": "jojochuang", "createdAt": "2020-05-15T16:12:18Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -909,4 +910,90 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test\n+  public void testDomainSocketClosedByDN() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf =\n+        createShortCircuitConf(\"testDomainSocketClosedByDN\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    Slot slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot2.getSlotId(), false);\n+\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    // make the DataXceiver timedout\n+    Thread.sleep(5000);\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(10000);\n+    Assert.assertTrue(cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .getShmNum() == 0);\n+    Assert.assertTrue(cache.getDfsClientShmManager().getShmNum() == 0);\n+    cluster.shutdown();\n+  }\n+\n+  @Test\n+  public void testDNRestart() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf = createShortCircuitConf(\"testDNRestart\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    // restart the datanode to invalidate the cache\n+    cluster.restartDataNode(0);\n+    Thread.sleep(1000);\n+    // after the restart, new allocation and release should not be affect\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    Slot slot2 = null;\n+    try {\n+      slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+          \"testReleaseSlotReuseDomainSocket_client\");\n+    } catch (ClosedChannelException ce) {\n+\n+    }\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(2000);\n+    Assert.assertTrue(cluster.getDataNodes().get(0).getShortCircuitRegistry()", "originalCommit": "49e8948ec052fcd2f45626e7f360c8553821654b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjI3ODM2MQ==", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r426278361", "bodyText": "done", "author": "leosunli", "createdAt": "2020-05-17T16:15:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwNTA1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwNTE0NA==", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r425905144", "bodyText": "ditto", "author": "jojochuang", "createdAt": "2020-05-15T16:12:26Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -909,4 +910,90 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test\n+  public void testDomainSocketClosedByDN() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf =\n+        createShortCircuitConf(\"testDomainSocketClosedByDN\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    Slot slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot2.getSlotId(), false);\n+\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    // make the DataXceiver timedout\n+    Thread.sleep(5000);\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(10000);\n+    Assert.assertTrue(cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .getShmNum() == 0);\n+    Assert.assertTrue(cache.getDfsClientShmManager().getShmNum() == 0);\n+    cluster.shutdown();\n+  }\n+\n+  @Test\n+  public void testDNRestart() throws Exception {\n+    BlockReaderTestUtil.enableShortCircuitShmTracing();\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf = createShortCircuitConf(\"testDNRestart\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    cluster.waitActive();\n+    DistributedFileSystem fs = cluster.getFileSystem();\n+    final ShortCircuitCache cache =\n+        fs.getClient().getClientContext().getShortCircuitCache();\n+    DomainPeer peer = getDomainPeerToDn(conf);\n+    MutableBoolean usedPeer = new MutableBoolean(false);\n+    ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+    final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+        .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+    // Allocating the first shm slot requires using up a peer.\n+    Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+        \"testReleaseSlotReuseDomainSocket_client\");\n+\n+    cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+    // restart the datanode to invalidate the cache\n+    cluster.restartDataNode(0);\n+    Thread.sleep(1000);\n+    // after the restart, new allocation and release should not be affect\n+    cache.scheduleSlotReleaser(slot1);\n+\n+    Slot slot2 = null;\n+    try {\n+      slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+          \"testReleaseSlotReuseDomainSocket_client\");\n+    } catch (ClosedChannelException ce) {\n+\n+    }\n+    cache.scheduleSlotReleaser(slot2);\n+    Thread.sleep(2000);\n+    Assert.assertTrue(cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+        .getShmNum() == 0);\n+    Assert.assertTrue(cache.getDfsClientShmManager().getShmNum() == 0);", "originalCommit": "49e8948ec052fcd2f45626e7f360c8553821654b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjI3ODM0OQ==", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r426278349", "bodyText": "done", "author": "leosunli", "createdAt": "2020-05-17T16:15:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwNTE0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMDIxNw==", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r425910217", "bodyText": "not that familiar with short circuit read. Is true that it's single threaded?", "author": "jojochuang", "createdAt": "2020-05-15T16:21:17Z", "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java", "diffHunk": "@@ -181,25 +182,49 @@ public long getRateInMs() {\n \n     @Override\n     public void run() {\n+      if (slot == null) {\n+        return;\n+      }\n       LOG.trace(\"{}: about to release {}\", ShortCircuitCache.this, slot);\n       final DfsClientShm shm = (DfsClientShm)slot.getShm();\n       final DomainSocket shmSock = shm.getPeer().getDomainSocket();\n       final String path = shmSock.getPath();\n+      DataOutputStream out = null;\n       boolean success = false;\n-      try (DomainSocket sock = DomainSocket.connect(path);\n-           DataOutputStream out = new DataOutputStream(\n-               new BufferedOutputStream(sock.getOutputStream()))) {\n-        new Sender(out).releaseShortCircuitFds(slot.getSlotId());\n-        DataInputStream in = new DataInputStream(sock.getInputStream());\n-        ReleaseShortCircuitAccessResponseProto resp =\n-            ReleaseShortCircuitAccessResponseProto.parseFrom(\n-                PBHelperClient.vintPrefixed(in));\n-        if (resp.getStatus() != Status.SUCCESS) {\n-          String error = resp.hasError() ? resp.getError() : \"(unknown)\";\n-          throw new IOException(resp.getStatus().toString() + \": \" + error);\n+      int retries = 2;\n+      try {\n+        while (retries > 0) {\n+          try {\n+            if (domainSocket == null || !domainSocket.isOpen()) {\n+              // we are running in single thread mode, no protection needed for", "originalCommit": "49e8948ec052fcd2f45626e7f360c8553821654b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjI3NzkyNA==", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r426277924", "bodyText": "yeah, the SlotReleaser is running in single thread as follow code.\nShortCircuitCache#uref->replica.close()->cache.scheduleSlotReleaser(slot)->releaserExecutor.execute(new SlotReleaser(slot))-> SlotReleaser#run {\n...\ntry {\nif (domainSocket == null || !domainSocket.isOpen()) {\n// we are running in single thread mode, no protection needed for\n// domainSocket\ndomainSocket = DomainSocket.connect(path);\n}\n...\n}\nSince ShortCircuitCache#uref run in lock\uff0cthis code is run serially in a core thread of a thread pool.", "author": "leosunli", "createdAt": "2020-05-17T16:11:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMDIxNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjI3ODI5NA==", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r426278294", "bodyText": "ShortCircuitCache#unref->ShortCircuitReplica#close->cache.scheduleSlotReleaser(slot)->releaserExecutor.execute(new SlotReleaser(slot))->SlotReleaser#run {\n...\nif (domainSocket == null || !domainSocket.isOpen()) {\n// we are running in single thread mode, no protection needed for\n// domainSocket\ndomainSocket = DomainSocket.connect(path);\n}\n...\n}\nSince ShortCircuitCache#unref run in lock, this code is run serially in a thread of a thread pool.", "author": "leosunli", "createdAt": "2020-05-17T16:15:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMDIxNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzU0MTcwMQ==", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r427541701", "bodyText": "Got it. The release scheduler has only one thread.\n/**\n\nThe executor service that runs the cacheCleaner.\n*/\nprivate final ScheduledThreadPoolExecutor releaserExecutor\n= new ScheduledThreadPoolExecutor(1, new ThreadFactoryBuilder().\nsetDaemon(true).setNameFormat(\"ShortCircuitCache_SlotReleaser\").\nbuild());", "author": "jojochuang", "createdAt": "2020-05-19T19:18:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMDIxNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyNzIyMw==", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r425927223", "bodyText": "If retries becomes 0, the code would silently ignore the error. How should we handle this case better?", "author": "jojochuang", "createdAt": "2020-05-15T16:51:22Z", "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java", "diffHunk": "@@ -181,25 +182,49 @@ public long getRateInMs() {\n \n     @Override\n     public void run() {\n+      if (slot == null) {\n+        return;\n+      }\n       LOG.trace(\"{}: about to release {}\", ShortCircuitCache.this, slot);\n       final DfsClientShm shm = (DfsClientShm)slot.getShm();\n       final DomainSocket shmSock = shm.getPeer().getDomainSocket();\n       final String path = shmSock.getPath();\n+      DataOutputStream out = null;\n       boolean success = false;\n-      try (DomainSocket sock = DomainSocket.connect(path);\n-           DataOutputStream out = new DataOutputStream(\n-               new BufferedOutputStream(sock.getOutputStream()))) {\n-        new Sender(out).releaseShortCircuitFds(slot.getSlotId());\n-        DataInputStream in = new DataInputStream(sock.getInputStream());\n-        ReleaseShortCircuitAccessResponseProto resp =\n-            ReleaseShortCircuitAccessResponseProto.parseFrom(\n-                PBHelperClient.vintPrefixed(in));\n-        if (resp.getStatus() != Status.SUCCESS) {\n-          String error = resp.hasError() ? resp.getError() : \"(unknown)\";\n-          throw new IOException(resp.getStatus().toString() + \": \" + error);\n+      int retries = 2;\n+      try {\n+        while (retries > 0) {", "originalCommit": "49e8948ec052fcd2f45626e7f360c8553821654b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjI3ODMxOQ==", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r426278319", "bodyText": "done", "author": "leosunli", "createdAt": "2020-05-17T16:15:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyNzIyMw=="}], "type": "inlineReview"}, {"oid": "7fef36fc1eceb2850ee353bc2dddc0bdb95bd3fc", "url": "https://github.com/apache/hadoop/commit/7fef36fc1eceb2850ee353bc2dddc0bdb95bd3fc", "message": "SlotReleaser is not fast enough\n\nSigned-off-by: sunlisheng <sunlisheng@xiaomi.com>", "committedDate": "2020-05-19T13:31:11Z", "type": "commit"}, {"oid": "71670765213b2c51eeba01b01f74c283a2e6775e", "url": "https://github.com/apache/hadoop/commit/71670765213b2c51eeba01b01f74c283a2e6775e", "message": "Fix TestShortCircuitCache UT\n\nSigned-off-by: sunlisheng <sunlisheng@xiaomi.com>", "committedDate": "2020-05-19T13:31:11Z", "type": "commit"}, {"oid": "2f99cb12f9c4aa0824698d5426118de37ab8dd54", "url": "https://github.com/apache/hadoop/commit/2f99cb12f9c4aa0824698d5426118de37ab8dd54", "message": "Fix TestShortCircuitCache\n\nSigned-off-by: sunlisheng <lisheng.sun08@gmail.com>", "committedDate": "2020-05-19T13:31:11Z", "type": "forcePushed"}, {"oid": "f2c8c586801dec07d8e6b0302b43c012112fc92b", "url": "https://github.com/apache/hadoop/commit/f2c8c586801dec07d8e6b0302b43c012112fc92b", "message": "Fix TestShortCircuitCache\n\nSigned-off-by: sunlisheng <lisheng.sun08@gmail.com>", "committedDate": "2020-05-19T13:38:23Z", "type": "commit"}, {"oid": "f2c8c586801dec07d8e6b0302b43c012112fc92b", "url": "https://github.com/apache/hadoop/commit/f2c8c586801dec07d8e6b0302b43c012112fc92b", "message": "Fix TestShortCircuitCache\n\nSigned-off-by: sunlisheng <lisheng.sun08@gmail.com>", "committedDate": "2020-05-19T13:38:23Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzU0MzQzNA==", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r427543434", "bodyText": "This one doesn't look right. I think you want to remove \"== 0\"?", "author": "jojochuang", "createdAt": "2020-05-19T19:21:18Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java", "diffHunk": "@@ -910,4 +912,94 @@ public void testRequestFileDescriptorsWhenULimit() throws Exception {\n       }\n     }\n   }\n+\n+  @Test(timeout = 60000)\n+  public void testDomainSocketClosedByDN() throws Exception {\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf =\n+        createShortCircuitConf(\"testDomainSocketClosedByDN\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+\n+    try {\n+      cluster.waitActive();\n+      DistributedFileSystem fs = cluster.getFileSystem();\n+      final ShortCircuitCache cache =\n+          fs.getClient().getClientContext().getShortCircuitCache();\n+      DomainPeer peer = getDomainPeerToDn(conf);\n+      MutableBoolean usedPeer = new MutableBoolean(false);\n+      ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+      final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+          .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+      // Allocating the first shm slot requires using up a peer.\n+      Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+          \"testReleaseSlotReuseDomainSocket_client\");\n+\n+      cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+          .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+      Slot slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+          \"testReleaseSlotReuseDomainSocket_client\");\n+\n+      cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+          .registerSlot(blockId, slot2.getSlotId(), false);\n+\n+      cache.scheduleSlotReleaser(slot1);\n+\n+      Thread.sleep(2000);\n+      cache.scheduleSlotReleaser(slot2);\n+      Thread.sleep(2000);\n+      Assert.assertEquals(0,\n+          cluster.getDataNodes().get(0).getShortCircuitRegistry().getShmNum());\n+      Assert.assertEquals(0, cache.getDfsClientShmManager().getShmNum());\n+    } finally {\n+      cluster.shutdown();\n+    }\n+  }\n+\n+  @Test(timeout = 60000)\n+  public void testDNRestart() throws Exception {\n+    TemporarySocketDirectory sockDir = new TemporarySocketDirectory();\n+    Configuration conf = createShortCircuitConf(\"testDNRestart\", sockDir);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    try {\n+      cluster.waitActive();\n+      DistributedFileSystem fs = cluster.getFileSystem();\n+      final ShortCircuitCache cache =\n+          fs.getClient().getClientContext().getShortCircuitCache();\n+      DomainPeer peer = getDomainPeerToDn(conf);\n+      MutableBoolean usedPeer = new MutableBoolean(false);\n+      ExtendedBlockId blockId = new ExtendedBlockId(123, \"xyz\");\n+      final DatanodeInfo datanode = new DatanodeInfo.DatanodeInfoBuilder()\n+          .setNodeID(cluster.getDataNodes().get(0).getDatanodeId()).build();\n+      // Allocating the first shm slot requires using up a peer.\n+      Slot slot1 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+          \"testReleaseSlotReuseDomainSocket_client\");\n+\n+      cluster.getDataNodes().get(0).getShortCircuitRegistry()\n+          .registerSlot(blockId, slot1.getSlotId(), false);\n+\n+      // restart the datanode to invalidate the cache\n+      cluster.restartDataNode(0);\n+      Thread.sleep(1000);\n+      // after the restart, new allocation and release should not be affect\n+      cache.scheduleSlotReleaser(slot1);\n+\n+      Slot slot2 = null;\n+      try {\n+        slot2 = cache.allocShmSlot(datanode, peer, usedPeer, blockId,\n+            \"testReleaseSlotReuseDomainSocket_client\");\n+      } catch (ClosedChannelException ce) {\n+\n+      }\n+      cache.scheduleSlotReleaser(slot2);\n+      Thread.sleep(2000);\n+      Assert.assertEquals(0, cluster.getDataNodes().get(0)", "originalCommit": "f2c8c586801dec07d8e6b0302b43c012112fc92b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY5ODE3NA==", "url": "https://github.com/apache/hadoop/pull/1885#discussion_r427698174", "bodyText": "yeah, I really think so and update the patch.", "author": "leosunli", "createdAt": "2020-05-20T01:55:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzU0MzQzNA=="}], "type": "inlineReview"}, {"oid": "8652c1b4c4ca5e34598f45b05bcebe1aa679c48a", "url": "https://github.com/apache/hadoop/commit/8652c1b4c4ca5e34598f45b05bcebe1aa679c48a", "message": "Fix UT\n\nSigned-off-by: sunlisheng <lisheng.sun08@gmail.com>", "committedDate": "2020-05-20T01:56:47Z", "type": "commit"}, {"oid": "8652c1b4c4ca5e34598f45b05bcebe1aa679c48a", "url": "https://github.com/apache/hadoop/commit/8652c1b4c4ca5e34598f45b05bcebe1aa679c48a", "message": "Fix UT\n\nSigned-off-by: sunlisheng <lisheng.sun08@gmail.com>", "committedDate": "2020-05-20T01:56:47Z", "type": "forcePushed"}]}