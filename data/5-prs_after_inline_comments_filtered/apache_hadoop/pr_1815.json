{"pr_number": 1815, "pr_title": "HADOOP-16801: S3Guard-listFiles will not query s3 if all listings are\u2026", "pr_createdAt": "2020-01-22T01:49:53Z", "pr_url": "https://github.com/apache/hadoop/pull/1815", "timeline": [{"oid": "ac9ea612be14006a4a9b14494bf8f533e6774a8e", "url": "https://github.com/apache/hadoop/commit/ac9ea612be14006a4a9b14494bf8f533e6774a8e", "message": "HADOOP-16801: S3Guard-listFiles will not query s3 if all listings are authoritative", "committedDate": "2020-01-22T05:18:05Z", "type": "forcePushed"}, {"oid": "6b742c95ea5e5923b1d82a8b663514dce8ce5bd5", "url": "https://github.com/apache/hadoop/commit/6b742c95ea5e5923b1d82a8b663514dce8ce5bd5", "message": "HADOOP-16801: S3Guard-listFiles will not query s3 if all listings are authoritative", "committedDate": "2020-01-22T23:50:17Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMwNTAwMw==", "url": "https://github.com/apache/hadoop/pull/1815#discussion_r370305003", "bodyText": "nit: leave the empty line", "author": "steveloughran", "createdAt": "2020-01-23T19:15:11Z", "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/S3Guard.java", "diffHunk": "@@ -35,6 +35,7 @@\n \n import com.google.common.annotations.VisibleForTesting;\n import com.google.common.base.Preconditions;\n+import org.apache.hadoop.fs.RemoteIterator;", "originalCommit": "6b742c95ea5e5923b1d82a8b663514dce8ce5bd5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDQxMDU3Ng==", "url": "https://github.com/apache/hadoop/pull/1815#discussion_r370410576", "bodyText": "there was no empty line here", "author": "mustafaiman", "createdAt": "2020-01-23T23:34:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMwNTAwMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDgyNjM5Ng==", "url": "https://github.com/apache/hadoop/pull/1815#discussion_r370826396", "bodyText": "(add an empty line between the com.google. and org.apahce.hadoop imports. we group our imports for easier backporting)", "author": "bgaborg", "createdAt": "2020-01-24T20:23:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMwNTAwMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDgzMTk1NA==", "url": "https://github.com/apache/hadoop/pull/1815#discussion_r370831954", "bodyText": "thanks for clarification. will do", "author": "mustafaiman", "createdAt": "2020-01-24T20:38:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMwNTAwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMwNjE1Nw==", "url": "https://github.com/apache/hadoop/pull/1815#discussion_r370306157", "bodyText": "This test suite has made the leap to AssertJ assertions -please us them unless you can make the case against them. They're better, really", "author": "steveloughran", "createdAt": "2020-01-23T19:17:30Z", "path": "hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/s3guard/ITestDynamoDBMetadataStoreAuthoritativeMode.java", "diffHunk": "@@ -291,6 +295,102 @@ public void testListStatusMakesEmptyDirAuth() throws Throwable {\n     assertListDoesNotUpdateAuth(dir);\n   }\n \n+  @Test\n+  public void testListFilesRecursiveWhenAllListingsAreAuthoritative()\n+      throws Exception {\n+    describe(\"listFiles does not make further calls to the fs when\"\n+        + \"all nested directory listings are authoritative\");\n+    Set<Path> files = new HashSet<>();\n+\n+    Path parentDir = dir;\n+    Path parentFile = dirFile;\n+    Path nestedDir1 = new Path(dir, \"nested1\");\n+    Path nestedFile1 = new Path(nestedDir1, \"nestedFile1\");\n+    Path nestedDir2 = new Path(nestedDir1, \"nested2/\");\n+    Path nestedFile2 = new Path(nestedDir2, \"nestedFile2\");\n+\n+    files.add(parentFile);\n+    files.add(nestedFile1);\n+    files.add(nestedFile2);\n+\n+    authFS.mkdirs(parentDir);\n+    authFS.mkdirs(nestedDir1);\n+    authFS.mkdirs(nestedDir2);\n+    touchFile(parentFile);\n+    touchFile(nestedFile1);\n+    touchFile(nestedFile2);\n+\n+    // making listStatus call to mark directories authoritative\n+    authFS.listStatus(parentDir);\n+    authFS.listStatus(nestedDir1);\n+    authFS.listStatus(nestedDir2);\n+\n+    S3AStorageStatistics statistics = authFS.getStorageStatistics();\n+    statistics.reset();\n+\n+    RemoteIterator<LocatedFileStatus> statusIterator =\n+        authFS.listFiles(dir, true);\n+\n+    while (statusIterator.hasNext()) {\n+      LocatedFileStatus locatedFileStatus = statusIterator.next();\n+      assertTrue(\"This path does not exist in original listing: \" +", "originalCommit": "6b742c95ea5e5923b1d82a8b663514dce8ce5bd5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMwNzA2NQ==", "url": "https://github.com/apache/hadoop/pull/1815#discussion_r370307065", "bodyText": "assertJ's assert will list the array, so is needed here", "author": "steveloughran", "createdAt": "2020-01-23T19:19:23Z", "path": "hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/s3guard/ITestDynamoDBMetadataStoreAuthoritativeMode.java", "diffHunk": "@@ -291,6 +295,102 @@ public void testListStatusMakesEmptyDirAuth() throws Throwable {\n     assertListDoesNotUpdateAuth(dir);\n   }\n \n+  @Test\n+  public void testListFilesRecursiveWhenAllListingsAreAuthoritative()\n+      throws Exception {\n+    describe(\"listFiles does not make further calls to the fs when\"\n+        + \"all nested directory listings are authoritative\");\n+    Set<Path> files = new HashSet<>();\n+\n+    Path parentDir = dir;\n+    Path parentFile = dirFile;\n+    Path nestedDir1 = new Path(dir, \"nested1\");\n+    Path nestedFile1 = new Path(nestedDir1, \"nestedFile1\");\n+    Path nestedDir2 = new Path(nestedDir1, \"nested2/\");\n+    Path nestedFile2 = new Path(nestedDir2, \"nestedFile2\");\n+\n+    files.add(parentFile);\n+    files.add(nestedFile1);\n+    files.add(nestedFile2);\n+\n+    authFS.mkdirs(parentDir);\n+    authFS.mkdirs(nestedDir1);\n+    authFS.mkdirs(nestedDir2);\n+    touchFile(parentFile);\n+    touchFile(nestedFile1);\n+    touchFile(nestedFile2);\n+\n+    // making listStatus call to mark directories authoritative\n+    authFS.listStatus(parentDir);\n+    authFS.listStatus(nestedDir1);\n+    authFS.listStatus(nestedDir2);\n+\n+    S3AStorageStatistics statistics = authFS.getStorageStatistics();\n+    statistics.reset();\n+\n+    RemoteIterator<LocatedFileStatus> statusIterator =\n+        authFS.listFiles(dir, true);\n+\n+    while (statusIterator.hasNext()) {\n+      LocatedFileStatus locatedFileStatus = statusIterator.next();\n+      assertTrue(\"This path does not exist in original listing: \" +\n+          locatedFileStatus.getPath(),\n+          files.remove(locatedFileStatus.getPath()));\n+    }\n+    assertEquals(\"Some files were missing from authoritative listing:\"\n+        + Arrays.toString(files.toArray()), 0, files.size());", "originalCommit": "6b742c95ea5e5923b1d82a8b663514dce8ce5bd5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMwNzYwMQ==", "url": "https://github.com/apache/hadoop/pull/1815#discussion_r370307601", "bodyText": "good to see you've discovered using the metrics for your asserts -use MetricDiff to make it easier", "author": "steveloughran", "createdAt": "2020-01-23T19:20:31Z", "path": "hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/s3guard/ITestDynamoDBMetadataStoreAuthoritativeMode.java", "diffHunk": "@@ -291,6 +295,102 @@ public void testListStatusMakesEmptyDirAuth() throws Throwable {\n     assertListDoesNotUpdateAuth(dir);\n   }\n \n+  @Test\n+  public void testListFilesRecursiveWhenAllListingsAreAuthoritative()\n+      throws Exception {\n+    describe(\"listFiles does not make further calls to the fs when\"\n+        + \"all nested directory listings are authoritative\");\n+    Set<Path> files = new HashSet<>();\n+\n+    Path parentDir = dir;\n+    Path parentFile = dirFile;\n+    Path nestedDir1 = new Path(dir, \"nested1\");\n+    Path nestedFile1 = new Path(nestedDir1, \"nestedFile1\");\n+    Path nestedDir2 = new Path(nestedDir1, \"nested2/\");\n+    Path nestedFile2 = new Path(nestedDir2, \"nestedFile2\");\n+\n+    files.add(parentFile);\n+    files.add(nestedFile1);\n+    files.add(nestedFile2);\n+\n+    authFS.mkdirs(parentDir);\n+    authFS.mkdirs(nestedDir1);\n+    authFS.mkdirs(nestedDir2);\n+    touchFile(parentFile);\n+    touchFile(nestedFile1);\n+    touchFile(nestedFile2);\n+\n+    // making listStatus call to mark directories authoritative\n+    authFS.listStatus(parentDir);\n+    authFS.listStatus(nestedDir1);\n+    authFS.listStatus(nestedDir2);\n+\n+    S3AStorageStatistics statistics = authFS.getStorageStatistics();\n+    statistics.reset();\n+\n+    RemoteIterator<LocatedFileStatus> statusIterator =\n+        authFS.listFiles(dir, true);\n+\n+    while (statusIterator.hasNext()) {\n+      LocatedFileStatus locatedFileStatus = statusIterator.next();\n+      assertTrue(\"This path does not exist in original listing: \" +\n+          locatedFileStatus.getPath(),\n+          files.remove(locatedFileStatus.getPath()));\n+    }\n+    assertEquals(\"Some files were missing from authoritative listing:\"\n+        + Arrays.toString(files.toArray()), 0, files.size());\n+    assertEquals(\"There must not be any OBJECT_LIST requests\"\n+            + \"as all directory listings are authoritative.\",\n+        0, (long) statistics.getLong(OBJECT_LIST_REQUESTS.getSymbol()));", "originalCommit": "6b742c95ea5e5923b1d82a8b663514dce8ce5bd5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "252108adbd6d24ae4b0bfe6589ffaefc5c38fd39", "url": "https://github.com/apache/hadoop/commit/252108adbd6d24ae4b0bfe6589ffaefc5c38fd39", "message": "HADOOP-16801: S3Guard-listFiles will not query s3 if all listings are authoritative", "committedDate": "2020-01-23T23:32:27Z", "type": "forcePushed"}, {"oid": "f4a8515586521a6889aeb14994e2fc618e7a9f0c", "url": "https://github.com/apache/hadoop/commit/f4a8515586521a6889aeb14994e2fc618e7a9f0c", "message": "HADOOP-16801: S3Guard-listFiles will not query s3 if all listings are authoritative", "committedDate": "2020-01-24T07:31:38Z", "type": "forcePushed"}, {"oid": "638cbddefe7513f22cb81f66441dcc1e53d08230", "url": "https://github.com/apache/hadoop/commit/638cbddefe7513f22cb81f66441dcc1e53d08230", "message": "HADOOP-16801: S3Guard-listFiles will not query s3 if all listings are authoritative", "committedDate": "2020-01-27T18:59:22Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTgyNDEwOA==", "url": "https://github.com/apache/hadoop/pull/1815#discussion_r371824108", "bodyText": "Missing javadoc for rejectAuthoritative", "author": "bgaborg", "createdAt": "2020-01-28T14:11:35Z", "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/impl/OperationCallbacks.java", "diffHunk": "@@ -119,7 +119,8 @@ void deleteObjectAtPath(Path path,\n       Path path,\n       S3AFileStatus status,\n       boolean collectTombstones,\n-      boolean includeSelf) throws IOException;\n+      boolean includeSelf,\n+      boolean rejectAuthoritative) throws IOException;", "originalCommit": "638cbddefe7513f22cb81f66441dcc1e53d08230", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTgyNTgxMQ==", "url": "https://github.com/apache/hadoop/pull/1815#discussion_r371825811", "bodyText": "Also, I don't see any point for this interface change. Please justify.", "author": "bgaborg", "createdAt": "2020-01-28T14:14:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTgyNDEwOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjA3MDg4Mw==", "url": "https://github.com/apache/hadoop/pull/1815#discussion_r372070883", "bodyText": "You are right. At first I introduced the extra parameter because I thought some tools might use the improvement in this PR and other can continue to work the same way by forcing non-authoritative. Given that only Import tool use this method and it should force non-authoritative, implementers of this method should force non-authoritative. The flag has no use.", "author": "mustafaiman", "createdAt": "2020-01-28T21:35:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTgyNDEwOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjMxNzg3MA==", "url": "https://github.com/apache/hadoop/pull/1815#discussion_r372317870", "bodyText": "Thanks!", "author": "bgaborg", "createdAt": "2020-01-29T11:02:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTgyNDEwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTgyNTQ4NQ==", "url": "https://github.com/apache/hadoop/pull/1815#discussion_r371825485", "bodyText": "There's a call to this method in two places, and both of these places pass true for rejectAuthoritative.\nI don't see the point of modifying OperationCallbacks interface for this - just pass true from this method instead.", "author": "bgaborg", "createdAt": "2020-01-28T14:13:56Z", "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java", "diffHunk": "@@ -1444,15 +1444,17 @@ public void deleteObjectAtPath(final Path path,\n         final Path path,\n         final S3AFileStatus status,\n         final boolean collectTombstones,\n-        final boolean includeSelf) throws IOException {\n+        final boolean includeSelf,\n+        final boolean rejectAuthoritative) throws IOException {", "originalCommit": "638cbddefe7513f22cb81f66441dcc1e53d08230", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTgyNjQyNg==", "url": "https://github.com/apache/hadoop/pull/1815#discussion_r371826426", "bodyText": "please add a comment before this if in what it's doing - just a short summary, preferably one line.", "author": "bgaborg", "createdAt": "2020-01-28T14:15:35Z", "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java", "diffHunk": "@@ -4035,6 +4057,15 @@ public LocatedFileStatus next() throws IOException {\n               new MetadataStoreListFilesIterator(metadataStore, pm,\n                   allowAuthoritative);\n           tombstones = metadataStoreListFilesIterator.listTombstones();\n+          if (!forceNonAuthoritativeMS &&", "originalCommit": "638cbddefe7513f22cb81f66441dcc1e53d08230", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTgyNjgwOQ==", "url": "https://github.com/apache/hadoop/pull/1815#discussion_r371826809", "bodyText": "also extend the javadoc with this behaviour", "author": "bgaborg", "createdAt": "2020-01-28T14:16:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTgyNjQyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTg1ODI4MQ==", "url": "https://github.com/apache/hadoop/pull/1815#discussion_r371858281", "bodyText": "I would name this listFilesAndEmptyDirectoriesForceNonAuth", "author": "bgaborg", "createdAt": "2020-01-28T15:05:57Z", "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/ImportOperation.java", "diffHunk": "@@ -146,7 +146,7 @@ private long importDir() throws IOException {\n       long countOfFilesWritten = 0;\n       long countOfDirsWritten = 0;\n       RemoteIterator<S3ALocatedFileStatus> it = getFilesystem()\n-          .listFilesAndEmptyDirectories(basePath, true);\n+          .listFilesAndEmptyDirectoriesStrict(basePath, true);", "originalCommit": "638cbddefe7513f22cb81f66441dcc1e53d08230", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "e04538142aeeab20f8233d9f00d54083bfc2c690", "url": "https://github.com/apache/hadoop/commit/e04538142aeeab20f8233d9f00d54083bfc2c690", "message": "HADOOP-16801: S3Guard-listFiles will not query s3 if all listings are authoritative", "committedDate": "2020-01-28T21:59:03Z", "type": "commit"}, {"oid": "e04538142aeeab20f8233d9f00d54083bfc2c690", "url": "https://github.com/apache/hadoop/commit/e04538142aeeab20f8233d9f00d54083bfc2c690", "message": "HADOOP-16801: S3Guard-listFiles will not query s3 if all listings are authoritative", "committedDate": "2020-01-28T21:59:03Z", "type": "forcePushed"}]}