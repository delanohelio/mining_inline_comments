{"pr_number": 1993, "pr_title": "HADOOP-17021. Add concat fs command", "pr_createdAt": "2020-05-01T15:32:43Z", "pr_url": "https://github.com/apache/hadoop/pull/1993", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1MDEwMg==", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r454350102", "bodyText": "use the relevant ContractTestUtils assertion here, for better error reporting.", "author": "steveloughran", "createdAt": "2020-07-14T13:20:00Z", "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestFsShellConcat.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.FsShell;\n+import org.apache.hadoop.fs.LocalFileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.IOUtils;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.io.IOException;\n+import java.io.PrintStream;\n+import java.net.URI;\n+import java.util.Random;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Test Concat.\n+ */\n+public class TestFsShellConcat {\n+\n+  private static Configuration conf;\n+  private static FsShell shell;\n+  private static LocalFileSystem lfs;\n+  private static Path testRootDir;\n+  private static Path dstPath;\n+\n+  @Before\n+  public void before() throws IOException {\n+    conf = new Configuration();\n+    shell = new FsShell(conf);\n+    lfs = FileSystem.getLocal(conf);\n+    testRootDir = lfs.makeQualified(new Path(GenericTestUtils.getTempPath(\n+        \"testFsShellCopy\")));\n+\n+    if (lfs.exists(testRootDir)) {\n+      lfs.delete(testRootDir, true);\n+    }\n+    lfs.mkdirs(testRootDir);\n+    lfs.setWorkingDirectory(testRootDir);\n+    dstPath = new Path(testRootDir, \"dstFile\");\n+    lfs.create(dstPath).close();\n+\n+    Random random = new Random();\n+    for (int i = 0; i < 10; i++) {\n+      OutputStream out = lfs.create(new Path(testRootDir, \"file-\" + i));\n+      out.write(random.nextInt());\n+      out.close();\n+    }\n+  }\n+\n+  @Test\n+  public void testConcat() throws Exception {\n+    FileSystem mockFs = Mockito.mock(FileSystem.class);\n+    Mockito.doAnswer(invocation -> {\n+      Object[] args = invocation.getArguments();\n+      Path target = (Path)args[0];\n+      Path[] src = (Path[]) args[1];\n+      mockConcat(target, src);\n+      return null;\n+    }).when(mockFs).concat(any(Path.class), any(Path[].class));\n+    Concat.setTstFs(mockFs);\n+    shellRun(0, \"-concat\", dstPath.toString(), testRootDir+\"/file-*\");\n+\n+    assertTrue(lfs.exists(dstPath));", "originalCommit": "78baf53be883b8d61383f10cff6c0f760b1349c2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1MDY0NA==", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r454350644", "bodyText": "Prefer Assertions.assertThat for new tests, as it will generate a meaningful error message", "author": "steveloughran", "createdAt": "2020-07-14T13:20:51Z", "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestFsShellConcat.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.FsShell;\n+import org.apache.hadoop.fs.LocalFileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.IOUtils;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.io.IOException;\n+import java.io.PrintStream;\n+import java.net.URI;\n+import java.util.Random;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Test Concat.\n+ */\n+public class TestFsShellConcat {\n+\n+  private static Configuration conf;\n+  private static FsShell shell;\n+  private static LocalFileSystem lfs;\n+  private static Path testRootDir;\n+  private static Path dstPath;\n+\n+  @Before\n+  public void before() throws IOException {\n+    conf = new Configuration();\n+    shell = new FsShell(conf);\n+    lfs = FileSystem.getLocal(conf);\n+    testRootDir = lfs.makeQualified(new Path(GenericTestUtils.getTempPath(\n+        \"testFsShellCopy\")));\n+\n+    if (lfs.exists(testRootDir)) {\n+      lfs.delete(testRootDir, true);\n+    }\n+    lfs.mkdirs(testRootDir);\n+    lfs.setWorkingDirectory(testRootDir);\n+    dstPath = new Path(testRootDir, \"dstFile\");\n+    lfs.create(dstPath).close();\n+\n+    Random random = new Random();\n+    for (int i = 0; i < 10; i++) {\n+      OutputStream out = lfs.create(new Path(testRootDir, \"file-\" + i));\n+      out.write(random.nextInt());\n+      out.close();\n+    }\n+  }\n+\n+  @Test\n+  public void testConcat() throws Exception {\n+    FileSystem mockFs = Mockito.mock(FileSystem.class);\n+    Mockito.doAnswer(invocation -> {\n+      Object[] args = invocation.getArguments();\n+      Path target = (Path)args[0];\n+      Path[] src = (Path[]) args[1];\n+      mockConcat(target, src);\n+      return null;\n+    }).when(mockFs).concat(any(Path.class), any(Path[].class));\n+    Concat.setTstFs(mockFs);\n+    shellRun(0, \"-concat\", dstPath.toString(), testRootDir+\"/file-*\");\n+\n+    assertTrue(lfs.exists(dstPath));\n+    assertEquals(1, lfs.listStatus(testRootDir).length);\n+  }\n+\n+  @Test\n+  public void testUnsupportedFs() throws Exception {\n+    FileSystem mockFs = Mockito.mock(FileSystem.class);\n+    Mockito.doThrow(\n+        new UnsupportedOperationException(\"Mock unsupported exception.\"))\n+        .when(mockFs).concat(any(Path.class), any(Path[].class));\n+    Mockito.doAnswer(invocationOnMock -> new URI(\"mockfs:///\")).when(mockFs)\n+        .getUri();\n+    Concat.setTstFs(mockFs);\n+    PrintStream oldErr = System.err;\n+    final ByteArrayOutputStream err = new ByteArrayOutputStream();\n+    System.setErr(new PrintStream(err));\n+    shellRun(1, \"-concat\", dstPath.toString(), testRootDir + \"/file-*\");\n+    System.setErr(oldErr);\n+    System.err.print(err.toString());\n+    assertTrue(err.toString()", "originalCommit": "78baf53be883b8d61383f10cff6c0f760b1349c2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDgxODQ2MA==", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r490818460", "bodyText": "done", "author": "wojiaodoubao", "createdAt": "2020-09-18T09:24:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1MDY0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1MDk1Nw==", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r454350957", "bodyText": "try/finally here to always restore the error stream", "author": "steveloughran", "createdAt": "2020-07-14T13:21:20Z", "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestFsShellConcat.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.FsShell;\n+import org.apache.hadoop.fs.LocalFileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.IOUtils;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.io.IOException;\n+import java.io.PrintStream;\n+import java.net.URI;\n+import java.util.Random;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Test Concat.\n+ */\n+public class TestFsShellConcat {\n+\n+  private static Configuration conf;\n+  private static FsShell shell;\n+  private static LocalFileSystem lfs;\n+  private static Path testRootDir;\n+  private static Path dstPath;\n+\n+  @Before\n+  public void before() throws IOException {\n+    conf = new Configuration();\n+    shell = new FsShell(conf);\n+    lfs = FileSystem.getLocal(conf);\n+    testRootDir = lfs.makeQualified(new Path(GenericTestUtils.getTempPath(\n+        \"testFsShellCopy\")));\n+\n+    if (lfs.exists(testRootDir)) {\n+      lfs.delete(testRootDir, true);\n+    }\n+    lfs.mkdirs(testRootDir);\n+    lfs.setWorkingDirectory(testRootDir);\n+    dstPath = new Path(testRootDir, \"dstFile\");\n+    lfs.create(dstPath).close();\n+\n+    Random random = new Random();\n+    for (int i = 0; i < 10; i++) {\n+      OutputStream out = lfs.create(new Path(testRootDir, \"file-\" + i));\n+      out.write(random.nextInt());\n+      out.close();\n+    }\n+  }\n+\n+  @Test\n+  public void testConcat() throws Exception {\n+    FileSystem mockFs = Mockito.mock(FileSystem.class);\n+    Mockito.doAnswer(invocation -> {\n+      Object[] args = invocation.getArguments();\n+      Path target = (Path)args[0];\n+      Path[] src = (Path[]) args[1];\n+      mockConcat(target, src);\n+      return null;\n+    }).when(mockFs).concat(any(Path.class), any(Path[].class));\n+    Concat.setTstFs(mockFs);\n+    shellRun(0, \"-concat\", dstPath.toString(), testRootDir+\"/file-*\");\n+\n+    assertTrue(lfs.exists(dstPath));\n+    assertEquals(1, lfs.listStatus(testRootDir).length);\n+  }\n+\n+  @Test\n+  public void testUnsupportedFs() throws Exception {\n+    FileSystem mockFs = Mockito.mock(FileSystem.class);\n+    Mockito.doThrow(\n+        new UnsupportedOperationException(\"Mock unsupported exception.\"))\n+        .when(mockFs).concat(any(Path.class), any(Path[].class));\n+    Mockito.doAnswer(invocationOnMock -> new URI(\"mockfs:///\")).when(mockFs)\n+        .getUri();\n+    Concat.setTstFs(mockFs);\n+    PrintStream oldErr = System.err;\n+    final ByteArrayOutputStream err = new ByteArrayOutputStream();\n+    System.setErr(new PrintStream(err));", "originalCommit": "78baf53be883b8d61383f10cff6c0f760b1349c2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDgxODU4Nw==", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r490818587", "bodyText": "done", "author": "wojiaodoubao", "createdAt": "2020-09-18T09:24:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1MDk1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1MTg4OA==", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r454351888", "bodyText": "there's some ContractTestUtils helper method for writing files. If not, use try-with-resources", "author": "steveloughran", "createdAt": "2020-07-14T13:22:45Z", "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestFsShellConcat.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.FsShell;\n+import org.apache.hadoop.fs.LocalFileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.IOUtils;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.io.IOException;\n+import java.io.PrintStream;\n+import java.net.URI;\n+import java.util.Random;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Test Concat.\n+ */\n+public class TestFsShellConcat {\n+\n+  private static Configuration conf;\n+  private static FsShell shell;\n+  private static LocalFileSystem lfs;\n+  private static Path testRootDir;\n+  private static Path dstPath;\n+\n+  @Before\n+  public void before() throws IOException {\n+    conf = new Configuration();\n+    shell = new FsShell(conf);\n+    lfs = FileSystem.getLocal(conf);\n+    testRootDir = lfs.makeQualified(new Path(GenericTestUtils.getTempPath(\n+        \"testFsShellCopy\")));\n+\n+    if (lfs.exists(testRootDir)) {\n+      lfs.delete(testRootDir, true);\n+    }\n+    lfs.mkdirs(testRootDir);\n+    lfs.setWorkingDirectory(testRootDir);\n+    dstPath = new Path(testRootDir, \"dstFile\");\n+    lfs.create(dstPath).close();\n+\n+    Random random = new Random();\n+    for (int i = 0; i < 10; i++) {\n+      OutputStream out = lfs.create(new Path(testRootDir, \"file-\" + i));\n+      out.write(random.nextInt());\n+      out.close();\n+    }\n+  }\n+\n+  @Test\n+  public void testConcat() throws Exception {\n+    FileSystem mockFs = Mockito.mock(FileSystem.class);\n+    Mockito.doAnswer(invocation -> {\n+      Object[] args = invocation.getArguments();\n+      Path target = (Path)args[0];\n+      Path[] src = (Path[]) args[1];\n+      mockConcat(target, src);\n+      return null;\n+    }).when(mockFs).concat(any(Path.class), any(Path[].class));\n+    Concat.setTstFs(mockFs);\n+    shellRun(0, \"-concat\", dstPath.toString(), testRootDir+\"/file-*\");\n+\n+    assertTrue(lfs.exists(dstPath));\n+    assertEquals(1, lfs.listStatus(testRootDir).length);\n+  }\n+\n+  @Test\n+  public void testUnsupportedFs() throws Exception {\n+    FileSystem mockFs = Mockito.mock(FileSystem.class);\n+    Mockito.doThrow(\n+        new UnsupportedOperationException(\"Mock unsupported exception.\"))\n+        .when(mockFs).concat(any(Path.class), any(Path[].class));\n+    Mockito.doAnswer(invocationOnMock -> new URI(\"mockfs:///\")).when(mockFs)\n+        .getUri();\n+    Concat.setTstFs(mockFs);\n+    PrintStream oldErr = System.err;\n+    final ByteArrayOutputStream err = new ByteArrayOutputStream();\n+    System.setErr(new PrintStream(err));\n+    shellRun(1, \"-concat\", dstPath.toString(), testRootDir + \"/file-*\");\n+    System.setErr(oldErr);\n+    System.err.print(err.toString());\n+    assertTrue(err.toString()\n+        .contains(\"Dest filesystem 'mockfs' doesn't support concat\"));\n+  }\n+\n+  private void shellRun(int n, String... args) {\n+    assertEquals(n, shell.run(args));\n+  }\n+\n+  /**\n+   * Simple simulation of concat.\n+   */\n+  private void mockConcat(Path target, Path[] srcArray) throws IOException {\n+    Path tmp = new Path(target.getParent(), target.getName() + \".bak\");\n+    lfs.rename(target, tmp);\n+    OutputStream out = lfs.create(target);", "originalCommit": "78baf53be883b8d61383f10cff6c0f760b1349c2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDgxODY3NA==", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r490818674", "bodyText": "done", "author": "wojiaodoubao", "createdAt": "2020-09-18T09:24:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1MTg4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1Mjk0Mg==", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r454352942", "bodyText": "prefer an import ordering of\norg.java\n\nanything-not-org-apache (here junit and mockito)\n\norg.apache\n\nall static imports", "author": "steveloughran", "createdAt": "2020-07-14T13:24:21Z", "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestFsShellConcat.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import org.apache.hadoop.conf.Configuration;", "originalCommit": "78baf53be883b8d61383f10cff6c0f760b1349c2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDgxODc3NQ==", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r490818775", "bodyText": "done", "author": "wojiaodoubao", "createdAt": "2020-09-18T09:24:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1Mjk0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1MzUwMQ==", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r454353501", "bodyText": "make a subclass of AbstractHadoopTestBase for test timeout and thread naming", "author": "steveloughran", "createdAt": "2020-07-14T13:25:15Z", "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestFsShellConcat.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.FsShell;\n+import org.apache.hadoop.fs.LocalFileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.IOUtils;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.io.IOException;\n+import java.io.PrintStream;\n+import java.net.URI;\n+import java.util.Random;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Test Concat.\n+ */\n+public class TestFsShellConcat {", "originalCommit": "78baf53be883b8d61383f10cff6c0f760b1349c2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDgxODg2MA==", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r490818860", "bodyText": "done", "author": "wojiaodoubao", "createdAt": "2020-09-18T09:24:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1MzUwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1NDMzNw==", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r454354337", "bodyText": "just call delete with no probe. or use ContractTestUtils method which checks delete() return value", "author": "steveloughran", "createdAt": "2020-07-14T13:26:30Z", "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestFsShellConcat.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.FsShell;\n+import org.apache.hadoop.fs.LocalFileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.IOUtils;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.io.IOException;\n+import java.io.PrintStream;\n+import java.net.URI;\n+import java.util.Random;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Test Concat.\n+ */\n+public class TestFsShellConcat {\n+\n+  private static Configuration conf;\n+  private static FsShell shell;\n+  private static LocalFileSystem lfs;\n+  private static Path testRootDir;\n+  private static Path dstPath;\n+\n+  @Before\n+  public void before() throws IOException {\n+    conf = new Configuration();\n+    shell = new FsShell(conf);\n+    lfs = FileSystem.getLocal(conf);\n+    testRootDir = lfs.makeQualified(new Path(GenericTestUtils.getTempPath(\n+        \"testFsShellCopy\")));\n+\n+    if (lfs.exists(testRootDir)) {", "originalCommit": "78baf53be883b8d61383f10cff6c0f760b1349c2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1NDg3Mg==", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r454354872", "bodyText": "use String.format with a 0 prefix, e.g %02d for ordering", "author": "steveloughran", "createdAt": "2020-07-14T13:27:15Z", "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestFsShellConcat.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.FsShell;\n+import org.apache.hadoop.fs.LocalFileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.IOUtils;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.io.IOException;\n+import java.io.PrintStream;\n+import java.net.URI;\n+import java.util.Random;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Test Concat.\n+ */\n+public class TestFsShellConcat {\n+\n+  private static Configuration conf;\n+  private static FsShell shell;\n+  private static LocalFileSystem lfs;\n+  private static Path testRootDir;\n+  private static Path dstPath;\n+\n+  @Before\n+  public void before() throws IOException {\n+    conf = new Configuration();\n+    shell = new FsShell(conf);\n+    lfs = FileSystem.getLocal(conf);\n+    testRootDir = lfs.makeQualified(new Path(GenericTestUtils.getTempPath(\n+        \"testFsShellCopy\")));\n+\n+    if (lfs.exists(testRootDir)) {\n+      lfs.delete(testRootDir, true);\n+    }\n+    lfs.mkdirs(testRootDir);\n+    lfs.setWorkingDirectory(testRootDir);\n+    dstPath = new Path(testRootDir, \"dstFile\");\n+    lfs.create(dstPath).close();\n+\n+    Random random = new Random();\n+    for (int i = 0; i < 10; i++) {\n+      OutputStream out = lfs.create(new Path(testRootDir, \"file-\" + i));", "originalCommit": "78baf53be883b8d61383f10cff6c0f760b1349c2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1NjE5OA==", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r454356198", "bodyText": "include Usage text", "author": "steveloughran", "createdAt": "2020-07-14T13:29:21Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Concat.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+\n+import java.io.IOException;\n+import java.util.LinkedList;\n+\n+/**\n+ * Concat the given files.\n+ */\n+@InterfaceAudience.Private\n+@InterfaceStability.Unstable\n+public class Concat extends FsCommand {\n+  public static void registerCommands(CommandFactory factory) {\n+    factory.addClass(Concat.class, \"-concat\");\n+  }\n+\n+  public static final String NAME = \"concat\";\n+  public static final String USAGE = \"<target path> <src path> <src path> ...\";\n+  public static final String DESCRIPTION = \"Concatenate existing source files\"\n+      + \" into the target file. Target file and source files should be in the\"\n+      + \" same directory.\";\n+  private static FileSystem tstFs; // test only.\n+\n+  @Override\n+  protected void processArguments(LinkedList<PathData> args)\n+      throws IOException {\n+    if (args.size() < 1) {\n+      throw new IOException(\"Target path not specified.\");", "originalCommit": "78baf53be883b8d61383f10cff6c0f760b1349c2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1NjI2MQ==", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r454356261", "bodyText": "include Usage text", "author": "steveloughran", "createdAt": "2020-07-14T13:29:25Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Concat.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+\n+import java.io.IOException;\n+import java.util.LinkedList;\n+\n+/**\n+ * Concat the given files.\n+ */\n+@InterfaceAudience.Private\n+@InterfaceStability.Unstable\n+public class Concat extends FsCommand {\n+  public static void registerCommands(CommandFactory factory) {\n+    factory.addClass(Concat.class, \"-concat\");\n+  }\n+\n+  public static final String NAME = \"concat\";\n+  public static final String USAGE = \"<target path> <src path> <src path> ...\";\n+  public static final String DESCRIPTION = \"Concatenate existing source files\"\n+      + \" into the target file. Target file and source files should be in the\"\n+      + \" same directory.\";\n+  private static FileSystem tstFs; // test only.\n+\n+  @Override\n+  protected void processArguments(LinkedList<PathData> args)\n+      throws IOException {\n+    if (args.size() < 1) {\n+      throw new IOException(\"Target path not specified.\");\n+    }\n+    if (args.size() < 3) {\n+      throw new IOException(\"The number of source paths is less than 2.\");", "originalCommit": "78baf53be883b8d61383f10cff6c0f760b1349c2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1NjY4Nw==", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r454356687", "bodyText": "raise FileNotFoundException", "author": "steveloughran", "createdAt": "2020-07-14T13:30:03Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Concat.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+\n+import java.io.IOException;\n+import java.util.LinkedList;\n+\n+/**\n+ * Concat the given files.\n+ */\n+@InterfaceAudience.Private\n+@InterfaceStability.Unstable\n+public class Concat extends FsCommand {\n+  public static void registerCommands(CommandFactory factory) {\n+    factory.addClass(Concat.class, \"-concat\");\n+  }\n+\n+  public static final String NAME = \"concat\";\n+  public static final String USAGE = \"<target path> <src path> <src path> ...\";\n+  public static final String DESCRIPTION = \"Concatenate existing source files\"\n+      + \" into the target file. Target file and source files should be in the\"\n+      + \" same directory.\";\n+  private static FileSystem tstFs; // test only.\n+\n+  @Override\n+  protected void processArguments(LinkedList<PathData> args)\n+      throws IOException {\n+    if (args.size() < 1) {\n+      throw new IOException(\"Target path not specified.\");\n+    }\n+    if (args.size() < 3) {\n+      throw new IOException(\"The number of source paths is less than 2.\");\n+    }\n+    PathData target = args.removeFirst();\n+    LinkedList<PathData> srcList = args;\n+    if (!target.exists || !target.stat.isFile()) {\n+      throw new IOException(String.format(\"Target path %s does not exist or is\"", "originalCommit": "78baf53be883b8d61383f10cff6c0f760b1349c2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1Njc2Mg==", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r454356762", "bodyText": "raise FileNotFoundException", "author": "steveloughran", "createdAt": "2020-07-14T13:30:10Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Concat.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+\n+import java.io.IOException;\n+import java.util.LinkedList;\n+\n+/**\n+ * Concat the given files.\n+ */\n+@InterfaceAudience.Private\n+@InterfaceStability.Unstable\n+public class Concat extends FsCommand {\n+  public static void registerCommands(CommandFactory factory) {\n+    factory.addClass(Concat.class, \"-concat\");\n+  }\n+\n+  public static final String NAME = \"concat\";\n+  public static final String USAGE = \"<target path> <src path> <src path> ...\";\n+  public static final String DESCRIPTION = \"Concatenate existing source files\"\n+      + \" into the target file. Target file and source files should be in the\"\n+      + \" same directory.\";\n+  private static FileSystem tstFs; // test only.\n+\n+  @Override\n+  protected void processArguments(LinkedList<PathData> args)\n+      throws IOException {\n+    if (args.size() < 1) {\n+      throw new IOException(\"Target path not specified.\");\n+    }\n+    if (args.size() < 3) {\n+      throw new IOException(\"The number of source paths is less than 2.\");\n+    }\n+    PathData target = args.removeFirst();\n+    LinkedList<PathData> srcList = args;\n+    if (!target.exists || !target.stat.isFile()) {\n+      throw new IOException(String.format(\"Target path %s does not exist or is\"\n+              + \" not file.\", target.path));\n+    }\n+    Path[] srcArray = new Path[srcList.size()];\n+    for (int i = 0; i < args.size(); i++) {\n+      PathData src = srcList.get(i);\n+      if (!src.exists || !src.stat.isFile()) {\n+        throw new IOException(", "originalCommit": "78baf53be883b8d61383f10cff6c0f760b1349c2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1NzQ4Nw==", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r454357487", "bodyText": "throw PathIOException with full target path. Bits of a mounted FS may have different support for concat,\ninclude inner stack trace", "author": "steveloughran", "createdAt": "2020-07-14T13:31:12Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Concat.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+\n+import java.io.IOException;\n+import java.util.LinkedList;\n+\n+/**\n+ * Concat the given files.\n+ */\n+@InterfaceAudience.Private\n+@InterfaceStability.Unstable\n+public class Concat extends FsCommand {\n+  public static void registerCommands(CommandFactory factory) {\n+    factory.addClass(Concat.class, \"-concat\");\n+  }\n+\n+  public static final String NAME = \"concat\";\n+  public static final String USAGE = \"<target path> <src path> <src path> ...\";\n+  public static final String DESCRIPTION = \"Concatenate existing source files\"\n+      + \" into the target file. Target file and source files should be in the\"\n+      + \" same directory.\";\n+  private static FileSystem tstFs; // test only.\n+\n+  @Override\n+  protected void processArguments(LinkedList<PathData> args)\n+      throws IOException {\n+    if (args.size() < 1) {\n+      throw new IOException(\"Target path not specified.\");\n+    }\n+    if (args.size() < 3) {\n+      throw new IOException(\"The number of source paths is less than 2.\");\n+    }\n+    PathData target = args.removeFirst();\n+    LinkedList<PathData> srcList = args;\n+    if (!target.exists || !target.stat.isFile()) {\n+      throw new IOException(String.format(\"Target path %s does not exist or is\"\n+              + \" not file.\", target.path));\n+    }\n+    Path[] srcArray = new Path[srcList.size()];\n+    for (int i = 0; i < args.size(); i++) {\n+      PathData src = srcList.get(i);\n+      if (!src.exists || !src.stat.isFile()) {\n+        throw new IOException(\n+            String.format(\"%s does not exist or is not file.\", src.path));\n+      }\n+      srcArray[i] = src.path;\n+    }\n+    FileSystem fs = target.fs;\n+    if (tstFs != null) {\n+      fs = tstFs;\n+    }\n+    try {\n+      fs.concat(target.path, srcArray);\n+    } catch (UnsupportedOperationException exception) {\n+      throw new IOException(\"Dest filesystem '\" + fs.getUri().getScheme()", "originalCommit": "78baf53be883b8d61383f10cff6c0f760b1349c2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1OTIzNg==", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r454359236", "bodyText": "why can't localfs be used directly? is it because it doesn't actually support it?", "author": "steveloughran", "createdAt": "2020-07-14T13:34:01Z", "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestFsShellConcat.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.FsShell;\n+import org.apache.hadoop.fs.LocalFileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.IOUtils;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.io.IOException;\n+import java.io.PrintStream;\n+import java.net.URI;\n+import java.util.Random;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Test Concat.\n+ */\n+public class TestFsShellConcat {\n+\n+  private static Configuration conf;\n+  private static FsShell shell;\n+  private static LocalFileSystem lfs;\n+  private static Path testRootDir;\n+  private static Path dstPath;\n+\n+  @Before\n+  public void before() throws IOException {\n+    conf = new Configuration();\n+    shell = new FsShell(conf);\n+    lfs = FileSystem.getLocal(conf);\n+    testRootDir = lfs.makeQualified(new Path(GenericTestUtils.getTempPath(\n+        \"testFsShellCopy\")));\n+\n+    if (lfs.exists(testRootDir)) {\n+      lfs.delete(testRootDir, true);\n+    }\n+    lfs.mkdirs(testRootDir);\n+    lfs.setWorkingDirectory(testRootDir);\n+    dstPath = new Path(testRootDir, \"dstFile\");\n+    lfs.create(dstPath).close();\n+\n+    Random random = new Random();\n+    for (int i = 0; i < 10; i++) {\n+      OutputStream out = lfs.create(new Path(testRootDir, \"file-\" + i));\n+      out.write(random.nextInt());\n+      out.close();\n+    }\n+  }\n+\n+  @Test\n+  public void testConcat() throws Exception {\n+    FileSystem mockFs = Mockito.mock(FileSystem.class);", "originalCommit": "78baf53be883b8d61383f10cff6c0f760b1349c2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDgxOTMzNg==", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r490819336", "bodyText": "Yes, LocalFileSystem doesn't support concat.", "author": "wojiaodoubao", "createdAt": "2020-09-18T09:25:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1OTIzNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM1OTUxNw==", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r454359517", "bodyText": "save the list of concatenated paths and then verify that the list passed in is of the correct length and order.", "author": "steveloughran", "createdAt": "2020-07-14T13:34:27Z", "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestFsShellConcat.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.FsShell;\n+import org.apache.hadoop.fs.LocalFileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.IOUtils;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.io.IOException;\n+import java.io.PrintStream;\n+import java.net.URI;\n+import java.util.Random;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Test Concat.\n+ */\n+public class TestFsShellConcat {\n+\n+  private static Configuration conf;\n+  private static FsShell shell;\n+  private static LocalFileSystem lfs;\n+  private static Path testRootDir;\n+  private static Path dstPath;\n+\n+  @Before\n+  public void before() throws IOException {\n+    conf = new Configuration();\n+    shell = new FsShell(conf);\n+    lfs = FileSystem.getLocal(conf);\n+    testRootDir = lfs.makeQualified(new Path(GenericTestUtils.getTempPath(\n+        \"testFsShellCopy\")));\n+\n+    if (lfs.exists(testRootDir)) {\n+      lfs.delete(testRootDir, true);\n+    }\n+    lfs.mkdirs(testRootDir);\n+    lfs.setWorkingDirectory(testRootDir);\n+    dstPath = new Path(testRootDir, \"dstFile\");\n+    lfs.create(dstPath).close();\n+\n+    Random random = new Random();\n+    for (int i = 0; i < 10; i++) {\n+      OutputStream out = lfs.create(new Path(testRootDir, \"file-\" + i));\n+      out.write(random.nextInt());\n+      out.close();\n+    }\n+  }\n+\n+  @Test\n+  public void testConcat() throws Exception {\n+    FileSystem mockFs = Mockito.mock(FileSystem.class);\n+    Mockito.doAnswer(invocation -> {\n+      Object[] args = invocation.getArguments();\n+      Path target = (Path)args[0];\n+      Path[] src = (Path[]) args[1];\n+      mockConcat(target, src);", "originalCommit": "78baf53be883b8d61383f10cff6c0f760b1349c2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "3c6fa7eca2907df27892f33295118c311b9e080c", "url": "https://github.com/apache/hadoop/commit/3c6fa7eca2907df27892f33295118c311b9e080c", "message": "follow steve's suggestions", "committedDate": "2020-09-18T09:20:55Z", "type": "forcePushed"}, {"oid": "d64cbeb5d128ac02911a7580f98b9e9e8a27dd0b", "url": "https://github.com/apache/hadoop/commit/d64cbeb5d128ac02911a7580f98b9e9e8a27dd0b", "message": "follow steve's suggestions", "committedDate": "2020-09-21T09:59:24Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzc2OTIzNg==", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r493769236", "bodyText": "stick the java import block at the top. thanks", "author": "steveloughran", "createdAt": "2020-09-23T17:33:54Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Concat.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.PathIOException;\n+\n+import java.io.FileNotFoundException;", "originalCommit": "d64cbeb5d128ac02911a7580f98b9e9e8a27dd0b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDIxMjE4NQ==", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r494212185", "bodyText": "done", "author": "wojiaodoubao", "createdAt": "2020-09-24T10:38:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzc2OTIzNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzc2OTY5Mg==", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r493769692", "bodyText": "tstFs needs some vowels. How about testFs?", "author": "steveloughran", "createdAt": "2020-09-23T17:34:44Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Concat.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.PathIOException;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.util.LinkedList;\n+\n+/**\n+ * Concat the given files.\n+ */\n+@InterfaceAudience.Private\n+@InterfaceStability.Unstable\n+public class Concat extends FsCommand {\n+  public static void registerCommands(CommandFactory factory) {\n+    factory.addClass(Concat.class, \"-concat\");\n+  }\n+\n+  public static final String NAME = \"concat\";\n+  public static final String USAGE = \"<target path> <src path> <src path> ...\";\n+  public static final String DESCRIPTION = \"Concatenate existing source files\"\n+      + \" into the target file. Target file and source files should be in the\"\n+      + \" same directory.\";\n+  private static FileSystem tstFs; // test only.", "originalCommit": "d64cbeb5d128ac02911a7580f98b9e9e8a27dd0b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzc3MDIxNg==", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r493770216", "bodyText": "move the non java. imports to a block below java. and above the org.apache block", "author": "steveloughran", "createdAt": "2020-09-23T17:35:31Z", "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestFsShellConcat.java", "diffHunk": "@@ -0,0 +1,166 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import org.junit.Before;", "originalCommit": "d64cbeb5d128ac02911a7580f98b9e9e8a27dd0b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzc3MDY0OQ==", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r493770649", "bodyText": "consider AssertJ assertions here, as they will include the list contents in the error", "author": "steveloughran", "createdAt": "2020-09-23T17:36:17Z", "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestFsShellConcat.java", "diffHunk": "@@ -0,0 +1,166 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+import org.assertj.core.api.Assertions;\n+import java.io.ByteArrayOutputStream;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.io.IOException;\n+import java.io.PrintStream;\n+import java.net.URI;\n+import java.util.Random;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.FsShell;\n+import org.apache.hadoop.fs.LocalFileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.IOUtils;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.apache.hadoop.fs.contract.ContractTestUtils;\n+import org.apache.hadoop.test.AbstractHadoopTestBase;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.junit.Assert.assertEquals;\n+\n+/**\n+ * Test Concat.\n+ */\n+public class TestFsShellConcat extends AbstractHadoopTestBase {\n+\n+  private static Configuration conf;\n+  private static FsShell shell;\n+  private static LocalFileSystem lfs;\n+  private static Path testRootDir;\n+  private static Path dstPath;\n+\n+  @Before\n+  public void before() throws IOException {\n+    conf = new Configuration();\n+    shell = new FsShell(conf);\n+    lfs = FileSystem.getLocal(conf);\n+    testRootDir = lfs.makeQualified(new Path(GenericTestUtils.getTempPath(\n+        \"testFsShellCopy\")));\n+\n+    lfs.delete(testRootDir, true);\n+    lfs.mkdirs(testRootDir);\n+    lfs.setWorkingDirectory(testRootDir);\n+    dstPath = new Path(testRootDir, \"dstFile\");\n+    lfs.create(dstPath).close();\n+\n+    Random random = new Random();\n+    for (int i = 0; i < 10; i++) {\n+      OutputStream out =\n+          lfs.create(new Path(testRootDir, String.format(\"file-%02d\", i)));\n+      out.write(random.nextInt());\n+      out.close();\n+    }\n+  }\n+\n+  @Test\n+  public void testConcat() throws Exception {\n+    // Read concatenated files to build the expected file content.\n+    ByteArrayOutputStream out = new ByteArrayOutputStream();\n+    for (int i = 0; i < 10; i++) {\n+      try (InputStream in = lfs\n+          .open(new Path(testRootDir, String.format(\"file-%02d\", i)))) {\n+        IOUtils.copyBytes(in, out, 1024);\n+      }\n+    }\n+    byte[] expectContent = out.toByteArray();\n+\n+    // Do concat.\n+    FileSystem mockFs = Mockito.mock(FileSystem.class);\n+    Mockito.doAnswer(invocation -> {\n+      Object[] args = invocation.getArguments();\n+      Path target = (Path)args[0];\n+      Path[] src = (Path[]) args[1];\n+      mockConcat(target, src);\n+      return null;\n+    }).when(mockFs).concat(any(Path.class), any(Path[].class));\n+    Concat.setTstFs(mockFs);\n+    shellRun(0, \"-concat\", dstPath.toString(), testRootDir+\"/file-*\");\n+\n+    // Verify concat result.\n+    ContractTestUtils\n+        .assertPathExists(lfs, \"The target file doesn't exist.\", dstPath);\n+    assertEquals(1, lfs.listStatus(testRootDir).length);", "originalCommit": "d64cbeb5d128ac02911a7580f98b9e9e8a27dd0b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "b98dfbfd17cb9437742dd6aa45ddf76d8af835b5", "url": "https://github.com/apache/hadoop/commit/b98dfbfd17cb9437742dd6aa45ddf76d8af835b5", "message": "add command concat", "committedDate": "2020-09-24T10:38:06Z", "type": "commit"}, {"oid": "5d36f969a3395e1a9f2977d57aee3f0f1b0e3521", "url": "https://github.com/apache/hadoop/commit/5d36f969a3395e1a9f2977d57aee3f0f1b0e3521", "message": "1. Fix checkstyle.\n2. Fix unit test.\n3. Add license.\n4. Handle fs doesn't support concat.\n5. Add documntation.", "committedDate": "2020-09-24T10:38:06Z", "type": "commit"}, {"oid": "2ab61ae2c3e7b8dc42e0dcad930866c3bbbbe142", "url": "https://github.com/apache/hadoop/commit/2ab61ae2c3e7b8dc42e0dcad930866c3bbbbe142", "message": "follow steve's suggestions", "committedDate": "2020-09-24T10:38:06Z", "type": "commit"}, {"oid": "7e45760bbfdb2879c44be43cd1a7d14731e9b095", "url": "https://github.com/apache/hadoop/commit/7e45760bbfdb2879c44be43cd1a7d14731e9b095", "message": "v04", "committedDate": "2020-09-24T10:38:06Z", "type": "commit"}, {"oid": "7e45760bbfdb2879c44be43cd1a7d14731e9b095", "url": "https://github.com/apache/hadoop/commit/7e45760bbfdb2879c44be43cd1a7d14731e9b095", "message": "v04", "committedDate": "2020-09-24T10:38:06Z", "type": "forcePushed"}, {"oid": "58033012f536ff4dbcc1258a53af910e7d359730", "url": "https://github.com/apache/hadoop/commit/58033012f536ff4dbcc1258a53af910e7d359730", "message": "v05", "committedDate": "2020-09-24T11:48:25Z", "type": "commit"}, {"oid": "f04c7931565682f9301f74aceed43fd7defb600a", "url": "https://github.com/apache/hadoop/commit/f04c7931565682f9301f74aceed43fd7defb600a", "message": "triger yetus", "committedDate": "2020-09-27T06:34:26Z", "type": "commit"}, {"oid": "f4e8ddf5bbfb7c9c6c823f653c732ed5c3950115", "url": "https://github.com/apache/hadoop/commit/f4e8ddf5bbfb7c9c6c823f653c732ed5c3950115", "message": "trigger new ci check", "committedDate": "2020-09-29T14:32:54Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODI2MzkyNw==", "url": "https://github.com/apache/hadoop/pull/1993#discussion_r498263927", "bodyText": "change this to the PathIOE which takes the target.path.toString as the first param.\nThe command line tools aren't great for reporting failures -anything we can do to improve the reporting is worth trying", "author": "steveloughran", "createdAt": "2020-10-01T13:56:14Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Concat.java", "diffHunk": "@@ -0,0 +1,91 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.shell;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.util.LinkedList;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+\n+import org.apache.hadoop.classification.InterfaceAudience;\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.PathIOException;\n+\n+/**\n+ * Concat the given files.\n+ */\n+@InterfaceAudience.Private\n+@InterfaceStability.Unstable\n+public class Concat extends FsCommand {\n+  public static void registerCommands(CommandFactory factory) {\n+    factory.addClass(Concat.class, \"-concat\");\n+  }\n+\n+  public static final String NAME = \"concat\";\n+  public static final String USAGE = \"<target path> <src path> <src path> ...\";\n+  public static final String DESCRIPTION = \"Concatenate existing source files\"\n+      + \" into the target file. Target file and source files should be in the\"\n+      + \" same directory.\";\n+  private static FileSystem testFs; // test only.\n+\n+  @Override\n+  protected void processArguments(LinkedList<PathData> args)\n+      throws IOException {\n+    if (args.size() < 1) {\n+      throw new IOException(\"Target path not specified. \" + USAGE);\n+    }\n+    if (args.size() < 3) {\n+      throw new IOException(\n+          \"The number of source paths is less than 2. \" + USAGE);\n+    }\n+    PathData target = args.removeFirst();\n+    LinkedList<PathData> srcList = args;\n+    if (!target.exists || !target.stat.isFile()) {\n+      throw new FileNotFoundException(String\n+          .format(\"Target path %s does not exist or is\" + \" not file.\",\n+              target.path));\n+    }\n+    Path[] srcArray = new Path[srcList.size()];\n+    for (int i = 0; i < args.size(); i++) {\n+      PathData src = srcList.get(i);\n+      if (!src.exists || !src.stat.isFile()) {\n+        throw new FileNotFoundException(\n+            String.format(\"%s does not exist or is not file.\", src.path));\n+      }\n+      srcArray[i] = src.path;\n+    }\n+    FileSystem fs = target.fs;\n+    if (testFs != null) {\n+      fs = testFs;\n+    }\n+    try {\n+      fs.concat(target.path, srcArray);\n+    } catch (UnsupportedOperationException exception) {\n+      throw new PathIOException(\"Dest filesystem '\" + fs.getUri().getScheme()", "originalCommit": "f4e8ddf5bbfb7c9c6c823f653c732ed5c3950115", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}