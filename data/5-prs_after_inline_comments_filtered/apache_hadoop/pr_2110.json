{"pr_number": 2110, "pr_title": "HDFS-15447 RBF: Add top real owners metrics for delegation tokens", "pr_createdAt": "2020-06-30T08:02:02Z", "pr_url": "https://github.com/apache/hadoop/pull/2110", "timeline": [{"oid": "1696b5fbfe79b13a68c1a14b7c7fac2a5ffb00be", "url": "https://github.com/apache/hadoop/commit/1696b5fbfe79b13a68c1a14b7c7fac2a5ffb00be", "message": "Add top real owners metrics for token", "committedDate": "2020-06-30T07:59:53Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc0NTk4Nw==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r447745987", "bodyText": "is it necessary to import static?", "author": "Hexiaoqiao", "createdAt": "2020-06-30T14:51:47Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java", "diffHunk": "@@ -34,6 +38,8 @@\n import org.apache.hadoop.classification.InterfaceAudience;\n import org.apache.hadoop.classification.InterfaceStability;\n import org.apache.hadoop.io.Text;\n+import static org.apache.hadoop.metrics2.util.Metrics2Util.NameValuePair;", "originalCommit": "1696b5fbfe79b13a68c1a14b7c7fac2a5ffb00be", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk4NjI0MQ==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r447986241", "bodyText": "Inigo told me once about it and I think it can have the usage of member variables easier and cleaner.", "author": "fengnanli", "createdAt": "2020-06-30T21:20:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc0NTk4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODAwNDc0Mw==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r448004743", "bodyText": "If the method/class is very obvious like assertTrue(), it usually makes sense to do a static import.\nIn this case, I guess is fine either way.", "author": "goiri", "createdAt": "2020-06-30T22:02:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc0NTk4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODA2OTExNQ==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r448069115", "bodyText": "Not always the case but I'd say this is fine.", "author": "goiri", "createdAt": "2020-07-01T01:40:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc0NTk4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc0NzY5Mw==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r447747693", "bodyText": "we need to define this new configure item at hdfs-rbf-default.xml.", "author": "Hexiaoqiao", "createdAt": "2020-06-30T14:53:50Z", "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RBFConfigKeys.java", "diffHunk": "@@ -79,6 +79,10 @@\n   public static final Class<? extends RouterRpcMonitor>\n       DFS_ROUTER_METRICS_CLASS_DEFAULT =\n       FederationRPCPerformanceMonitor.class;\n+  public static final String DFS_ROUTER_METRICS_TOP_NUM_TOKEN_OWNERS_KEY =", "originalCommit": "1696b5fbfe79b13a68c1a14b7c7fac2a5ffb00be", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk2NTc5NA==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r447965794", "bodyText": "not sure if there is a metrics.md page for RBF - if so we should add there too.", "author": "sunchao", "createdAt": "2020-06-30T20:41:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc0NzY5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk4ODQ4Mw==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r447988483", "bodyText": "Sure. I will add it here: https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/resources/hdfs-rbf-default.xml", "author": "fengnanli", "createdAt": "2020-06-30T21:25:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc0NzY5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc0ODk1Mg==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r447748952", "bodyText": "just suggest to replace with single class imports.", "author": "Hexiaoqiao", "createdAt": "2020-06-30T14:55:20Z", "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/security/TestRouterSecurityManager.java", "diffHunk": "@@ -39,6 +39,7 @@\n import org.junit.Rule;\n import org.junit.Test;\n \n+import static org.apache.hadoop.metrics2.util.Metrics2Util.*;", "originalCommit": "1696b5fbfe79b13a68c1a14b7c7fac2a5ffb00be", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk4ODU2Mw==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r447988563", "bodyText": "Sure", "author": "fengnanli", "createdAt": "2020-06-30T21:25:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc0ODk1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk2NTA2MQ==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r447965061", "bodyText": "will this get pretty expensive if there are lots of tokens stored? as every metrics pull needs to iterate through all tokens.", "author": "sunchao", "createdAt": "2020-06-30T20:40:02Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java", "diffHunk": "@@ -726,4 +732,41 @@ public TokenIdent decodeTokenIdentifier(Token<TokenIdent> token) throws IOExcept\n     return token.decodeIdentifier();\n   }\n \n+  /**\n+   * Return top token real owners list as well as the tokens count.\n+   *\n+   * @param n top number of users\n+   * @return map of owners to counts\n+   */\n+  public List<NameValuePair> getTopTokenRealOwners(int n) {", "originalCommit": "1696b5fbfe79b13a68c1a14b7c7fac2a5ffb00be", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk5MzMzMQ==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r447993331", "bodyText": "I had similar thoughts as well but didn't come up with a better way. In namenode TopN metrics, it is doing so as well just at a lower frequency like every 5/15/25 minutes. We can potentially do that by reducing the metric reporting frequency.\nI also checked modern CPU for looping over 1M, which takes about 1ms-10ms.\nAnother one would be to maintain a data structure to dynamically maintain the ordering of users and edit ordering per getdelegationtoken and per canceldelegationtoken like stream processing. I am not sure about the cost overall since in reality we generally have < 1 Million tokens.", "author": "fengnanli", "createdAt": "2020-06-30T21:36:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk2NTA2MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODAyMDc3MA==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r448020770", "bodyText": "Can we update the TopN queue when creating/deleting tokens? we are just paying an extra constant cost for updating that which I think is fine. Even though it is using concurrent hashmap, I'm not sure how much performance impact will be if one thread is iterating over the key set while others want to updating the map.", "author": "sunchao", "createdAt": "2020-06-30T22:46:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk2NTA2MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODAzNjQ0OA==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r448036448", "bodyText": "I am fine with it. We also need to add an initialization step to make sure this structure has the initial information from currentTokens.", "author": "fengnanli", "createdAt": "2020-06-30T23:36:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk2NTA2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk2NTI3NQ==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r447965275", "bodyText": "any reason to use LinkedList instead of ArrayList? the latter is usually more performant.", "author": "sunchao", "createdAt": "2020-06-30T20:40:27Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java", "diffHunk": "@@ -726,4 +732,41 @@ public TokenIdent decodeTokenIdentifier(Token<TokenIdent> token) throws IOExcept\n     return token.decodeIdentifier();\n   }\n \n+  /**\n+   * Return top token real owners list as well as the tokens count.\n+   *\n+   * @param n top number of users\n+   * @return map of owners to counts\n+   */\n+  public List<NameValuePair> getTopTokenRealOwners(int n) {\n+    Map<String, Integer> tokenOwnerMap = new HashMap<>();\n+    for (TokenIdent id : currentTokens.keySet()) {\n+      String realUser;\n+      if (id.getRealUser() != null && !id.getRealUser().toString().isEmpty()) {\n+        realUser = id.getRealUser().toString();\n+      } else {\n+        // if there is no real user -> this is a non proxy user\n+        // the user itself is the real owner\n+        realUser = id.getUser().getUserName();\n+      }\n+      tokenOwnerMap.put(realUser, tokenOwnerMap.getOrDefault(realUser, 0)+1);\n+    }\n+    n = Math.min(n, tokenOwnerMap.size());\n+    if (n == 0) {\n+      return new LinkedList<>();\n+    }\n+\n+    TopN topN = new TopN(n);\n+    for (Map.Entry<String, Integer> entry : tokenOwnerMap.entrySet()) {\n+      topN.offer(new NameValuePair(\n+          entry.getKey(), entry.getValue()));\n+    }\n+\n+    List<NameValuePair> list = new LinkedList<>();", "originalCommit": "1696b5fbfe79b13a68c1a14b7c7fac2a5ffb00be", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk5MzgyNA==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r447993824", "bodyText": "There is a reverse op and I think reverse linked list is faster without additional space.\nNot sure how java implement the reverse array list, but I think it will introduce copy and reassign.", "author": "fengnanli", "createdAt": "2020-06-30T21:37:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk2NTI3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODAyMjUxOA==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r448022518", "bodyText": "Reverse shouldn't need extra space - it uses two indexes from begin and end of the array and swaps elements. I don't see real difference between the two for the reverse.", "author": "sunchao", "createdAt": "2020-06-30T22:51:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk2NTI3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk2NTkzNA==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r447965934", "bodyText": "nit: extra blank line", "author": "sunchao", "createdAt": "2020-06-30T20:41:33Z", "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/security/TestRouterSecurityManager.java", "diffHunk": "@@ -124,6 +126,71 @@ public void testDelegationTokens() throws IOException {\n     securityManager.renewDelegationToken(token);\n   }\n \n+  @Test\n+  public void testDelgationTokenTopOwners() throws Exception {\n+    List<NameValuePair> topOwners;\n+\n+    UserGroupInformation user = UserGroupInformation\n+        .createUserForTesting(\"abc\", new String[]{\"router_group\"});\n+    UserGroupInformation.setLoginUser(user);\n+    Token dt = securityManager.getDelegationToken(new Text(\"abc\"));\n+    topOwners = securityManager.getSecretManager().getTopTokenRealOwners(2);\n+    assertEquals(1, topOwners.size());\n+    assertEquals(\"abc\", topOwners.get(0).getName());\n+    assertEquals(1, topOwners.get(0).getValue());\n+\n+    securityManager.renewDelegationToken(dt);\n+    topOwners = securityManager.getSecretManager().getTopTokenRealOwners(2);\n+    assertEquals(1, topOwners.size());\n+    assertEquals(\"abc\", topOwners.get(0).getName());\n+    assertEquals(1, topOwners.get(0).getValue());\n+\n+    securityManager.cancelDelegationToken(dt);\n+    topOwners = securityManager.getSecretManager().getTopTokenRealOwners(2);\n+    assertEquals(0, topOwners.size());\n+\n+\n+    // Use proxy user - the code should use the proxy user as the real owner\n+    UserGroupInformation routerUser =\n+        UserGroupInformation.createRemoteUser(\"router\");\n+    UserGroupInformation proxyUser = UserGroupInformation\n+        .createProxyUserForTesting(\"abc\",\n+            routerUser,\n+            new String[]{\"router_group\"});\n+    UserGroupInformation.setLoginUser(proxyUser);\n+\n+    Token proxyDT = securityManager.getDelegationToken(new Text(\"router\"));\n+    topOwners = securityManager.getSecretManager().getTopTokenRealOwners(2);\n+    assertEquals(1, topOwners.size());\n+    assertEquals(\"router\", topOwners.get(0).getName());\n+    assertEquals(1, topOwners.get(0).getValue());\n+\n+    // router to renew tokens\n+    UserGroupInformation.setLoginUser(routerUser);\n+    securityManager.renewDelegationToken(proxyDT);\n+    topOwners = securityManager.getSecretManager().getTopTokenRealOwners(2);\n+    assertEquals(1, topOwners.size());\n+    assertEquals(\"router\", topOwners.get(0).getName());\n+    assertEquals(1, topOwners.get(0).getValue());\n+\n+    securityManager.cancelDelegationToken(proxyDT);\n+    topOwners = securityManager.getSecretManager().getTopTokenRealOwners(2);\n+    assertEquals(0, topOwners.size());\n+", "originalCommit": "1696b5fbfe79b13a68c1a14b7c7fac2a5ffb00be", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk5NDA4Mw==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r447994083", "bodyText": "will remove", "author": "fengnanli", "createdAt": "2020-06-30T21:37:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk2NTkzNA=="}], "type": "inlineReview"}, {"oid": "6f46d5ce915f9fa3227be12f94f7dd4a4f5200db", "url": "https://github.com/apache/hadoop/commit/6f46d5ce915f9fa3227be12f94f7dd4a4f5200db", "message": "Address comments; using streaming fashion to deal with structure updates", "committedDate": "2020-07-01T00:08:03Z", "type": "commit"}, {"oid": "64fcba5ccb29bee2a6b9159c758d9b5d3ceadd5d", "url": "https://github.com/apache/hadoop/commit/64fcba5ccb29bee2a6b9159c758d9b5d3ceadd5d", "message": "Fix checkstyle and unit tests", "committedDate": "2020-07-01T00:56:32Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcwMTI4OA==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r448701288", "bodyText": "top users -> top user metrics?", "author": "sunchao", "createdAt": "2020-07-02T01:39:02Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java", "diffHunk": "@@ -64,7 +69,13 @@ private String formatTokenId(TokenIdent id) {\n    */\n   protected final Map<TokenIdent, DelegationTokenInformation> currentTokens \n       = new ConcurrentHashMap<>();\n-  \n+\n+  /**\n+   * Map of token real owners to its token count. This is used to generate\n+   * top users by owned tokens.", "originalCommit": "64fcba5ccb29bee2a6b9159c758d9b5d3ceadd5d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc1Njc2OA==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r448756768", "bodyText": "nit: use capital 0L to make IDE happy", "author": "sunchao", "createdAt": "2020-07-02T05:28:54Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java", "diffHunk": "@@ -726,4 +741,86 @@ public TokenIdent decodeTokenIdentifier(Token<TokenIdent> token) throws IOExcept\n     return token.decodeIdentifier();\n   }\n \n+  /**\n+   * Return top token real owners list as well as the tokens count.\n+   *\n+   * @param n top number of users\n+   * @return map of owners to counts\n+   */\n+  public List<NameValuePair> getTopTokenRealOwners(int n) {\n+    n = Math.min(n, tokenOwnerStats.size());\n+    if (n == 0) {\n+      return new ArrayList<>();\n+    }\n+\n+    TopN topN = new TopN(n);\n+    for (Map.Entry<String, Long> entry : tokenOwnerStats.entrySet()) {\n+      topN.offer(new NameValuePair(\n+          entry.getKey(), entry.getValue()));\n+    }\n+\n+    List<NameValuePair> list = new ArrayList<>();\n+    while (!topN.isEmpty()) {\n+      list.add(topN.poll());\n+    }\n+    Collections.reverse(list);\n+    return list;\n+  }\n+\n+  /**\n+   * Return the real owner for a token. If this is a token from a proxy user,\n+   * the real/effective user will be returned.\n+   *\n+   * @param id\n+   * @return real owner\n+   */\n+  public String getTokenRealOwner(TokenIdent id) {\n+    String realUser;\n+    if (id.getRealUser() != null && !id.getRealUser().toString().isEmpty()) {\n+      realUser = id.getRealUser().toString();\n+    } else {\n+      // if there is no real user -> this is a non proxy user\n+      // the user itself is the real owner\n+      realUser = id.getUser().getUserName();\n+    }\n+    return realUser;\n+  }\n+\n+  /**\n+   * Add token stats to the owner to token count mapping.\n+   *\n+   * @param id\n+   */\n+  public void addTokenForOwnerStats(TokenIdent id) {\n+    String realOwner = getTokenRealOwner(id);\n+    tokenOwnerStats.put(realOwner,\n+        tokenOwnerStats.getOrDefault(realOwner, 0l)+1);", "originalCommit": "64fcba5ccb29bee2a6b9159c758d9b5d3ceadd5d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc1NzU4OQ==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r448757589", "bodyText": "Even though tokenOwnerStats is a concurrent map, you may run into race conditions if multiple threads operate on this method at the same time. We can potentially make the method synchronized to avoid that. Not sure we should care much though since this is only for metrics.", "author": "sunchao", "createdAt": "2020-07-02T05:31:56Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java", "diffHunk": "@@ -726,4 +741,86 @@ public TokenIdent decodeTokenIdentifier(Token<TokenIdent> token) throws IOExcept\n     return token.decodeIdentifier();\n   }\n \n+  /**\n+   * Return top token real owners list as well as the tokens count.\n+   *\n+   * @param n top number of users\n+   * @return map of owners to counts\n+   */\n+  public List<NameValuePair> getTopTokenRealOwners(int n) {\n+    n = Math.min(n, tokenOwnerStats.size());\n+    if (n == 0) {\n+      return new ArrayList<>();\n+    }\n+\n+    TopN topN = new TopN(n);\n+    for (Map.Entry<String, Long> entry : tokenOwnerStats.entrySet()) {\n+      topN.offer(new NameValuePair(\n+          entry.getKey(), entry.getValue()));\n+    }\n+\n+    List<NameValuePair> list = new ArrayList<>();\n+    while (!topN.isEmpty()) {\n+      list.add(topN.poll());\n+    }\n+    Collections.reverse(list);\n+    return list;\n+  }\n+\n+  /**\n+   * Return the real owner for a token. If this is a token from a proxy user,\n+   * the real/effective user will be returned.\n+   *\n+   * @param id\n+   * @return real owner\n+   */\n+  public String getTokenRealOwner(TokenIdent id) {\n+    String realUser;\n+    if (id.getRealUser() != null && !id.getRealUser().toString().isEmpty()) {\n+      realUser = id.getRealUser().toString();\n+    } else {\n+      // if there is no real user -> this is a non proxy user\n+      // the user itself is the real owner\n+      realUser = id.getUser().getUserName();\n+    }\n+    return realUser;\n+  }\n+\n+  /**\n+   * Add token stats to the owner to token count mapping.\n+   *\n+   * @param id\n+   */\n+  public void addTokenForOwnerStats(TokenIdent id) {\n+    String realOwner = getTokenRealOwner(id);\n+    tokenOwnerStats.put(realOwner,\n+        tokenOwnerStats.getOrDefault(realOwner, 0l)+1);\n+  }\n+\n+  /**\n+   * Remove token stats to the owner to token count mapping.\n+   *\n+   * @param id\n+   */\n+  public void removeTokenForOwnerStats(TokenIdent id) {\n+    String realOwner = getTokenRealOwner(id);\n+    if (tokenOwnerStats.containsKey(realOwner)) {\n+      // unlikely to be less than 1 but in case\n+      if (tokenOwnerStats.get(realOwner) <= 1) {", "originalCommit": "64fcba5ccb29bee2a6b9159c758d9b5d3ceadd5d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIyNzU1OQ==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r451227559", "bodyText": "The function is called from createPassword and cancelToken which are all synchronized so it is safe here. Similarly currentTokens is used in the pattern.", "author": "fengnanli", "createdAt": "2020-07-08T01:15:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc1NzU4OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc1Nzg3Nw==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r448757877", "bodyText": "It's slightly unfortunate that we need to expose NameValuePair in a public method here as it is scope = private, but I don't know an easy way to avoid this.", "author": "sunchao", "createdAt": "2020-07-02T05:33:15Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java", "diffHunk": "@@ -726,4 +741,86 @@ public TokenIdent decodeTokenIdentifier(Token<TokenIdent> token) throws IOExcept\n     return token.decodeIdentifier();\n   }\n \n+  /**\n+   * Return top token real owners list as well as the tokens count.\n+   *\n+   * @param n top number of users\n+   * @return map of owners to counts\n+   */\n+  public List<NameValuePair> getTopTokenRealOwners(int n) {", "originalCommit": "64fcba5ccb29bee2a6b9159c758d9b5d3ceadd5d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIyNjA0MA==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r451226040", "bodyText": "I will keep it as it is.", "author": "fengnanli", "createdAt": "2020-07-08T01:08:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc1Nzg3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc1ODUxMg==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r448758512", "bodyText": "can we swap the order and update the stats as last step?", "author": "sunchao", "createdAt": "2020-07-02T05:35:50Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java", "diffHunk": "@@ -292,6 +303,7 @@ protected DelegationTokenInformation getTokenInfo(TokenIdent ident) {\n   protected void storeToken(TokenIdent ident,\n       DelegationTokenInformation tokenInfo) throws IOException {\n     currentTokens.put(ident, tokenInfo);\n+    addTokenForOwnerStats(ident);", "originalCommit": "64fcba5ccb29bee2a6b9159c758d9b5d3ceadd5d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc1ODYyNA==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r448758624", "bodyText": "same here - swap order and update stats as the last step?", "author": "sunchao", "createdAt": "2020-07-02T05:36:08Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java", "diffHunk": "@@ -578,6 +591,7 @@ public synchronized TokenIdent cancelToken(Token<TokenIdent> token,\n     if (info == null) {\n       throw new InvalidToken(\"Token not found \" + formatTokenId(id));\n     }\n+    removeTokenForOwnerStats(id);", "originalCommit": "64fcba5ccb29bee2a6b9159c758d9b5d3ceadd5d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIyNzI5MQ==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r451227291", "bodyText": "The reason i left the order as this is that the metric is a in-memory reflection currentTokens so it can be calculated once the memory data structure is changed.\nThe procedure after is for persistent storage.", "author": "fengnanli", "createdAt": "2020-07-08T01:13:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc1ODYyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc1OTU4Mw==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r448759583", "bodyText": "This and a few others do not need to be public?", "author": "sunchao", "createdAt": "2020-07-02T05:39:42Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java", "diffHunk": "@@ -726,4 +741,86 @@ public TokenIdent decodeTokenIdentifier(Token<TokenIdent> token) throws IOExcept\n     return token.decodeIdentifier();\n   }\n \n+  /**\n+   * Return top token real owners list as well as the tokens count.\n+   *\n+   * @param n top number of users\n+   * @return map of owners to counts\n+   */\n+  public List<NameValuePair> getTopTokenRealOwners(int n) {\n+    n = Math.min(n, tokenOwnerStats.size());\n+    if (n == 0) {\n+      return new ArrayList<>();\n+    }\n+\n+    TopN topN = new TopN(n);\n+    for (Map.Entry<String, Long> entry : tokenOwnerStats.entrySet()) {\n+      topN.offer(new NameValuePair(\n+          entry.getKey(), entry.getValue()));\n+    }\n+\n+    List<NameValuePair> list = new ArrayList<>();\n+    while (!topN.isEmpty()) {\n+      list.add(topN.poll());\n+    }\n+    Collections.reverse(list);\n+    return list;\n+  }\n+\n+  /**\n+   * Return the real owner for a token. If this is a token from a proxy user,\n+   * the real/effective user will be returned.\n+   *\n+   * @param id\n+   * @return real owner\n+   */\n+  public String getTokenRealOwner(TokenIdent id) {\n+    String realUser;\n+    if (id.getRealUser() != null && !id.getRealUser().toString().isEmpty()) {\n+      realUser = id.getRealUser().toString();\n+    } else {\n+      // if there is no real user -> this is a non proxy user\n+      // the user itself is the real owner\n+      realUser = id.getUser().getUserName();\n+    }\n+    return realUser;\n+  }\n+\n+  /**\n+   * Add token stats to the owner to token count mapping.\n+   *\n+   * @param id\n+   */\n+  public void addTokenForOwnerStats(TokenIdent id) {\n+    String realOwner = getTokenRealOwner(id);\n+    tokenOwnerStats.put(realOwner,\n+        tokenOwnerStats.getOrDefault(realOwner, 0l)+1);\n+  }\n+\n+  /**\n+   * Remove token stats to the owner to token count mapping.\n+   *\n+   * @param id\n+   */\n+  public void removeTokenForOwnerStats(TokenIdent id) {", "originalCommit": "64fcba5ccb29bee2a6b9159c758d9b5d3ceadd5d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIyNzA2OQ==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r451227069", "bodyText": "this was fixed.", "author": "fengnanli", "createdAt": "2020-07-08T01:12:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc1OTU4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc2MjQwOQ==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r448762409", "bodyText": "Seems this won't be updated if a standby NN updates its own token info by pulling from edit log?", "author": "sunchao", "createdAt": "2020-07-02T05:50:11Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java", "diffHunk": "@@ -64,7 +69,13 @@ private String formatTokenId(TokenIdent id) {\n    */\n   protected final Map<TokenIdent, DelegationTokenInformation> currentTokens \n       = new ConcurrentHashMap<>();\n-  \n+\n+  /**\n+   * Map of token real owners to its token count. This is used to generate\n+   * top users by owned tokens.\n+   */\n+  protected final Map<String, Long> tokenOwnerStats = new ConcurrentHashMap<>();", "originalCommit": "64fcba5ccb29bee2a6b9159c758d9b5d3ceadd5d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIyNzAyNQ==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r451227025", "bodyText": "It depends on individual secret manager to initialize the currentTokens. In namenode, it is loading from edit log. In router, it is loading from ZK.\nI would have a separate ticket for namenode.", "author": "fengnanli", "createdAt": "2020-07-08T01:12:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc2MjQwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTcyOTA3MQ==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r451729071", "bodyText": "OK. Can you add a comment for this though indicating that this only support RBF for now?", "author": "sunchao", "createdAt": "2020-07-08T18:00:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc2MjQwOQ=="}], "type": "inlineReview"}, {"oid": "eee3bf835215916aaf1632920523d612bee5429f", "url": "https://github.com/apache/hadoop/commit/eee3bf835215916aaf1632920523d612bee5429f", "message": "Address more comments", "committedDate": "2020-07-05T22:19:49Z", "type": "commit"}, {"oid": "93caedbb9cd7bd3cf6f13a8e267e59ac23dd6442", "url": "https://github.com/apache/hadoop/commit/93caedbb9cd7bd3cf6f13a8e267e59ac23dd6442", "message": "Remove unrelated change", "committedDate": "2020-07-07T06:10:39Z", "type": "commit"}]}