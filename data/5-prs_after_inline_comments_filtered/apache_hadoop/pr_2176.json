{"pr_number": 2176, "pr_title": "HDFS-15492. Make trash root inside each snapshottable directory", "pr_createdAt": "2020-07-29T19:54:10Z", "pr_url": "https://github.com/apache/hadoop/pull/2176", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTQ4MzE5NQ==", "url": "https://github.com/apache/hadoop/pull/2176#discussion_r465483195", "bodyText": "u may also want to add it in hdfs-default.xml or want to maintain it as an internal config? This ls leading to a test failure TestHdfsConfigFields.testCompareConfigurationClassAgainstXml.\nI think its better to hide it and define the config in SnapshotManager itself similar to \"dfs.namenode.snapshot.deletion.ordered\"", "author": "bshashikant", "createdAt": "2020-08-05T05:34:08Z", "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/HdfsClientConfigKeys.java", "diffHunk": "@@ -244,6 +244,10 @@\n       \"dfs.namenode.snapshot.capture.openfiles\";\n   boolean DFS_NAMENODE_SNAPSHOT_CAPTURE_OPENFILES_DEFAULT = false;\n \n+  String DFS_NAMENODE_SNAPSHOT_TRASHROOT_ENABLED =\n+      \"dfs.namenode.snapshot.trashroot.enabled\";\n+  boolean DFS_NAMENODE_SNAPSHOT_TRASHROOT_ENABLED_DEFAULT = false;\n+\n   String DFS_PROVIDED_ALIASMAP_INMEMORY_RPC_ADDRESS =", "originalCommit": "75c4be0a352d2c115922040a00b8f8102340f9dd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk3NTgzMQ==", "url": "https://github.com/apache/hadoop/pull/2176#discussion_r465975831", "bodyText": "makes sense. will hide it from the client.\nbut we do want to put this in hdfs-default.xml so people can learn to enable this on NN right?", "author": "smengcl", "createdAt": "2020-08-05T20:11:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTQ4MzE5NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjE1MjYxNw==", "url": "https://github.com/apache/hadoop/pull/2176#discussion_r466152617", "bodyText": "If we hide it, i would prefer to not add it in hdfs-default.xml as well. We can make this an internal config which is required only if u want to restrict renames out of snapshottable root which can be turned on only if a requirement like this arises in certain use cases.", "author": "bshashikant", "createdAt": "2020-08-06T05:21:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTQ4MzE5NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjIzNjE3NQ==", "url": "https://github.com/apache/hadoop/pull/2176#discussion_r466236175", "bodyText": "You are right. Done in 6b0a258.", "author": "smengcl", "createdAt": "2020-08-06T08:30:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTQ4MzE5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTYwNTY4Mg==", "url": "https://github.com/apache/hadoop/pull/2176#discussion_r465605682", "bodyText": "Let's say we have a structure like /dir1/dir2 where dir1 is ez enabled  and dir2 is made snapshottable. In such cases, anything deleted under dir2 will be under trash location under dir2 while everything which is deleted within dir1 but not dir2, will exist in trash under dir1. Will it lead to any issues??", "author": "bshashikant", "createdAt": "2020-08-05T09:45:52Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDistributedFileSystem.java", "diffHunk": "@@ -2144,4 +2146,180 @@ public void testECCloseCommittedBlock() throws Exception {\n       LambdaTestUtils.intercept(IOException.class, \"\", () -> str.close());\n     }\n   }\n+\n+  @Test\n+  public void testGetTrashRoot() throws IOException {\n+    Configuration conf = getTestConfiguration();\n+    conf.setBoolean(DFS_NAMENODE_SNAPSHOT_TRASHROOT_ENABLED, true);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    try {\n+      DistributedFileSystem dfs = cluster.getFileSystem();\n+      Path testDir = new Path(\"/ssgtr/test1/\");\n+      Path file0path = new Path(testDir, \"file-0\");\n+      dfs.create(file0path);\n+\n+      Path trBeforeAllowSnapshot = dfs.getTrashRoot(file0path);\n+      String trBeforeAllowSnapshotStr = trBeforeAllowSnapshot.toUri().getPath();\n+      // The trash root should be in user home directory\n+      String homeDirStr = dfs.getHomeDirectory().toUri().getPath();\n+      assertTrue(trBeforeAllowSnapshotStr.startsWith(homeDirStr));\n+\n+      dfs.allowSnapshot(testDir);\n+\n+      Path trAfterAllowSnapshot = dfs.getTrashRoot(file0path);\n+      String trAfterAllowSnapshotStr = trAfterAllowSnapshot.toUri().getPath();\n+      // The trash root should now be in the snapshot root\n+      String testDirStr = testDir.toUri().getPath();\n+      assertTrue(trAfterAllowSnapshotStr.startsWith(testDirStr));\n+\n+      // Cleanup\n+      dfs.disallowSnapshot(testDir);\n+      dfs.delete(testDir, true);\n+    } finally {\n+      if (cluster != null) {\n+        cluster.shutdown();\n+      }\n+    }\n+  }\n+\n+  private boolean isPathInUserHome(String pathStr, DistributedFileSystem dfs) {\n+    String homeDirStr = dfs.getHomeDirectory().toUri().getPath();\n+    return pathStr.startsWith(homeDirStr);\n+  }\n+\n+  @Test\n+  public void testGetTrashRoots() throws IOException {\n+    Configuration conf = getTestConfiguration();\n+    conf.setBoolean(DFS_NAMENODE_SNAPSHOT_TRASHROOT_ENABLED, true);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    try {\n+      DistributedFileSystem dfs = cluster.getFileSystem();\n+      Path testDir = new Path(\"/ssgtr/test1/\");\n+      Path file0path = new Path(testDir, \"file-0\");\n+      dfs.create(file0path);\n+      // Create user trash\n+      Path currUserHome = dfs.getHomeDirectory();\n+      Path currUserTrash = new Path(currUserHome, FileSystem.TRASH_PREFIX);\n+      dfs.mkdirs(currUserTrash);\n+      // Create trash inside test directory\n+      Path testDirTrash = new Path(testDir, FileSystem.TRASH_PREFIX);\n+      Path testDirTrashCurrUser = new Path(testDirTrash,\n+          UserGroupInformation.getCurrentUser().getShortUserName());\n+      dfs.mkdirs(testDirTrashCurrUser);\n+\n+      Collection<FileStatus> trashRoots = dfs.getTrashRoots(false);\n+      // getTrashRoots should only return 1 empty user trash in the home dir now\n+      assertEquals(1, trashRoots.size());\n+      FileStatus firstFileStatus = trashRoots.iterator().next();\n+      String pathStr = firstFileStatus.getPath().toUri().getPath();\n+      assertTrue(isPathInUserHome(pathStr, dfs));\n+      // allUsers should not make a difference for now because we have one user\n+      Collection<FileStatus> trashRootsAllUsers = dfs.getTrashRoots(true);\n+      assertEquals(trashRoots, trashRootsAllUsers);\n+\n+      dfs.allowSnapshot(testDir);\n+\n+      Collection<FileStatus> trashRootsAfter = dfs.getTrashRoots(false);\n+      // getTrashRoots should return 1 more trash root inside snapshottable dir\n+      assertEquals(trashRoots.size() + 1, trashRootsAfter.size());\n+      boolean foundUserHomeTrash = false;\n+      boolean foundSnapDirUserTrash = false;\n+      String testDirStr = testDir.toUri().getPath();\n+      for (FileStatus fileStatus : trashRootsAfter) {\n+        String currPathStr = fileStatus.getPath().toUri().getPath();\n+        if (isPathInUserHome(currPathStr, dfs)) {\n+          foundUserHomeTrash = true;\n+        } else if (currPathStr.startsWith(testDirStr)) {\n+          foundSnapDirUserTrash = true;\n+        }\n+      }\n+      assertTrue(foundUserHomeTrash);\n+      assertTrue(foundSnapDirUserTrash);\n+      // allUsers should not make a difference for now because we have one user\n+      Collection<FileStatus> trashRootsAfterAllUsers = dfs.getTrashRoots(true);\n+      assertEquals(trashRootsAfter, trashRootsAfterAllUsers);\n+\n+      // Create trash root for user0\n+      UserGroupInformation ugi = UserGroupInformation.createRemoteUser(\"user0\");\n+      String user0HomeStr = DFSUtilClient.getHomeDirectory(conf, ugi);\n+      Path user0Trash = new Path(user0HomeStr, FileSystem.TRASH_PREFIX);\n+      dfs.mkdirs(user0Trash);\n+      // allUsers flag set to false should be unaffected\n+      Collection<FileStatus> trashRootsAfter2 = dfs.getTrashRoots(false);\n+      assertEquals(trashRootsAfter, trashRootsAfter2);\n+      // allUsers flag set to true should include new user's trash\n+      trashRootsAfter2 = dfs.getTrashRoots(true);\n+      assertEquals(trashRootsAfter.size() + 1, trashRootsAfter2.size());\n+\n+      // Create trash root inside the snapshottable directory for user0\n+      Path testDirTrashUser0 = new Path(testDirTrash, ugi.getShortUserName());\n+      dfs.mkdirs(testDirTrashUser0);\n+      Collection<FileStatus> trashRootsAfter3 = dfs.getTrashRoots(true);\n+      assertEquals(trashRootsAfter2.size() + 1, trashRootsAfter3.size());\n+\n+      // Cleanup\n+      dfs.disallowSnapshot(testDir);\n+      dfs.delete(testDir, true);\n+    } finally {\n+      if (cluster != null) {\n+        cluster.shutdown();\n+      }\n+    }\n+  }\n+\n+  @Test\n+  public void testGetTrashRootsOnSnapshottableDirWithEncryptionZone()", "originalCommit": "75c4be0a352d2c115922040a00b8f8102340f9dd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjIzMTgzNg==", "url": "https://github.com/apache/hadoop/pull/2176#discussion_r466231836", "bodyText": "With a288110, when a path given to getTrashRoot() is both inside an EZ and in a snapshottable dir, it should now choose the inner most trash.", "author": "smengcl", "createdAt": "2020-08-06T08:23:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTYwNTY4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjUxNzg3MQ==", "url": "https://github.com/apache/hadoop/pull/2176#discussion_r466517871", "bodyText": "can we change this to equals rather startsWith??", "author": "bshashikant", "createdAt": "2020-08-06T15:59:22Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDistributedFileSystem.java", "diffHunk": "@@ -2144,4 +2146,293 @@ public void testECCloseCommittedBlock() throws Exception {\n       LambdaTestUtils.intercept(IOException.class, \"\", () -> str.close());\n     }\n   }\n+\n+  @Test\n+  public void testGetTrashRoot() throws IOException {\n+    Configuration conf = getTestConfiguration();\n+    conf.setBoolean(DFS_NAMENODE_SNAPSHOT_TRASHROOT_ENABLED, true);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    try {\n+      DistributedFileSystem dfs = cluster.getFileSystem();\n+      Path testDir = new Path(\"/ssgtr/test1/\");\n+      Path file0path = new Path(testDir, \"file-0\");\n+      dfs.create(file0path);\n+\n+      Path trBeforeAllowSnapshot = dfs.getTrashRoot(file0path);\n+      String trBeforeAllowSnapshotStr = trBeforeAllowSnapshot.toUri().getPath();\n+      // The trash root should be in user home directory\n+      String homeDirStr = dfs.getHomeDirectory().toUri().getPath();\n+      assertTrue(trBeforeAllowSnapshotStr.startsWith(homeDirStr));\n+\n+      dfs.allowSnapshot(testDir);\n+\n+      Path trAfterAllowSnapshot = dfs.getTrashRoot(file0path);\n+      String trAfterAllowSnapshotStr = trAfterAllowSnapshot.toUri().getPath();\n+      // The trash root should now be in the snapshot root\n+      String testDirStr = testDir.toUri().getPath();\n+      assertTrue(trAfterAllowSnapshotStr.startsWith(testDirStr));\n+\n+      // Cleanup\n+      dfs.disallowSnapshot(testDir);\n+      dfs.delete(testDir, true);\n+    } finally {\n+      if (cluster != null) {\n+        cluster.shutdown();\n+      }\n+    }\n+  }\n+\n+  private boolean isPathInUserHome(String pathStr, DistributedFileSystem dfs) {\n+    String homeDirStr = dfs.getHomeDirectory().toUri().getPath();\n+    return pathStr.startsWith(homeDirStr);\n+  }\n+\n+  @Test\n+  public void testGetTrashRoots() throws IOException {\n+    Configuration conf = getTestConfiguration();\n+    conf.setBoolean(DFS_NAMENODE_SNAPSHOT_TRASHROOT_ENABLED, true);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    try {\n+      DistributedFileSystem dfs = cluster.getFileSystem();\n+      Path testDir = new Path(\"/ssgtr/test1/\");\n+      Path file0path = new Path(testDir, \"file-0\");\n+      dfs.create(file0path);\n+      // Create user trash\n+      Path currUserHome = dfs.getHomeDirectory();\n+      Path currUserTrash = new Path(currUserHome, FileSystem.TRASH_PREFIX);\n+      dfs.mkdirs(currUserTrash);\n+      // Create trash inside test directory\n+      Path testDirTrash = new Path(testDir, FileSystem.TRASH_PREFIX);\n+      Path testDirTrashCurrUser = new Path(testDirTrash,\n+          UserGroupInformation.getCurrentUser().getShortUserName());\n+      dfs.mkdirs(testDirTrashCurrUser);\n+\n+      Collection<FileStatus> trashRoots = dfs.getTrashRoots(false);\n+      // getTrashRoots should only return 1 empty user trash in the home dir now\n+      assertEquals(1, trashRoots.size());\n+      FileStatus firstFileStatus = trashRoots.iterator().next();\n+      String pathStr = firstFileStatus.getPath().toUri().getPath();\n+      assertTrue(isPathInUserHome(pathStr, dfs));\n+      // allUsers should not make a difference for now because we have one user\n+      Collection<FileStatus> trashRootsAllUsers = dfs.getTrashRoots(true);\n+      assertEquals(trashRoots, trashRootsAllUsers);\n+\n+      dfs.allowSnapshot(testDir);\n+\n+      Collection<FileStatus> trashRootsAfter = dfs.getTrashRoots(false);\n+      // getTrashRoots should return 1 more trash root inside snapshottable dir\n+      assertEquals(trashRoots.size() + 1, trashRootsAfter.size());\n+      boolean foundUserHomeTrash = false;\n+      boolean foundSnapDirUserTrash = false;\n+      String testDirStr = testDir.toUri().getPath();\n+      for (FileStatus fileStatus : trashRootsAfter) {\n+        String currPathStr = fileStatus.getPath().toUri().getPath();\n+        if (isPathInUserHome(currPathStr, dfs)) {\n+          foundUserHomeTrash = true;\n+        } else if (currPathStr.startsWith(testDirStr)) {\n+          foundSnapDirUserTrash = true;\n+        }\n+      }\n+      assertTrue(foundUserHomeTrash);\n+      assertTrue(foundSnapDirUserTrash);\n+      // allUsers should not make a difference for now because we have one user\n+      Collection<FileStatus> trashRootsAfterAllUsers = dfs.getTrashRoots(true);\n+      assertEquals(trashRootsAfter, trashRootsAfterAllUsers);\n+\n+      // Create trash root for user0\n+      UserGroupInformation ugi = UserGroupInformation.createRemoteUser(\"user0\");\n+      String user0HomeStr = DFSUtilClient.getHomeDirectory(conf, ugi);\n+      Path user0Trash = new Path(user0HomeStr, FileSystem.TRASH_PREFIX);\n+      dfs.mkdirs(user0Trash);\n+      // allUsers flag set to false should be unaffected\n+      Collection<FileStatus> trashRootsAfter2 = dfs.getTrashRoots(false);\n+      assertEquals(trashRootsAfter, trashRootsAfter2);\n+      // allUsers flag set to true should include new user's trash\n+      trashRootsAfter2 = dfs.getTrashRoots(true);\n+      assertEquals(trashRootsAfter.size() + 1, trashRootsAfter2.size());\n+\n+      // Create trash root inside the snapshottable directory for user0\n+      Path testDirTrashUser0 = new Path(testDirTrash, ugi.getShortUserName());\n+      dfs.mkdirs(testDirTrashUser0);\n+      Collection<FileStatus> trashRootsAfter3 = dfs.getTrashRoots(true);\n+      assertEquals(trashRootsAfter2.size() + 1, trashRootsAfter3.size());\n+\n+      // Cleanup\n+      dfs.disallowSnapshot(testDir);\n+      dfs.delete(testDir, true);\n+    } finally {\n+      if (cluster != null) {\n+        cluster.shutdown();\n+      }\n+    }\n+  }\n+\n+  @Test\n+  public void testGetTrashRootsOnSnapshottableDirWithEZ()\n+      throws IOException, NoSuchAlgorithmException {\n+    Configuration conf = getTestConfiguration();\n+    conf.setBoolean(DFS_NAMENODE_SNAPSHOT_TRASHROOT_ENABLED, true);\n+    // Set encryption zone config\n+    File tmpDir = GenericTestUtils.getTestDir(UUID.randomUUID().toString());\n+    final Path jksPath = new Path(tmpDir.toString(), \"test.jks\");\n+    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_KEY_PROVIDER_PATH,\n+        JavaKeyStoreProvider.SCHEME_NAME + \"://file\" + jksPath.toUri());\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    // Create key for EZ\n+    final KeyProvider provider =\n+        cluster.getNameNode().getNamesystem().getProvider();\n+    final KeyProvider.Options options = KeyProvider.options(conf);\n+    provider.createKey(\"key\", options);\n+    provider.flush();\n+\n+    try {\n+      DistributedFileSystem dfs = cluster.getFileSystem();\n+      Path testDir = new Path(\"/ssgtr/test2/\");\n+      dfs.mkdirs(testDir);\n+      dfs.createEncryptionZone(testDir, \"key\");\n+\n+      // Create trash inside test directory\n+      Path testDirTrash = new Path(testDir, FileSystem.TRASH_PREFIX);\n+      Path testDirTrashCurrUser = new Path(testDirTrash,\n+          UserGroupInformation.getCurrentUser().getShortUserName());\n+      dfs.mkdirs(testDirTrashCurrUser);\n+\n+      Collection<FileStatus> trashRoots = dfs.getTrashRoots(false);\n+      assertEquals(1, trashRoots.size());\n+      FileStatus firstFileStatus = trashRoots.iterator().next();\n+      String pathStr = firstFileStatus.getPath().toUri().getPath();\n+      String testDirStr = testDir.toUri().getPath();\n+      assertTrue(pathStr.startsWith(testDirStr));\n+\n+      dfs.allowSnapshot(testDir);\n+\n+      Collection<FileStatus> trashRootsAfter = dfs.getTrashRoots(false);\n+      // getTrashRoots should give the same result\n+      assertEquals(trashRoots, trashRootsAfter);\n+\n+      // Cleanup\n+      dfs.disallowSnapshot(testDir);\n+      dfs.delete(testDir, true);\n+    } finally {\n+      if (cluster != null) {\n+        cluster.shutdown();\n+      }\n+    }\n+  }\n+\n+  @Test\n+  public void testGetTrashRootOnSnapshottableDirInEZ()\n+      throws IOException, NoSuchAlgorithmException {\n+    Configuration conf = getTestConfiguration();\n+    conf.setBoolean(DFS_NAMENODE_SNAPSHOT_TRASHROOT_ENABLED, true);\n+    // Set EZ config\n+    File tmpDir = GenericTestUtils.getTestDir(UUID.randomUUID().toString());\n+    final Path jksPath = new Path(tmpDir.toString(), \"test.jks\");\n+    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_KEY_PROVIDER_PATH,\n+        JavaKeyStoreProvider.SCHEME_NAME + \"://file\" + jksPath.toUri());\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    // Create key for EZ\n+    final KeyProvider provider =\n+        cluster.getNameNode().getNamesystem().getProvider();\n+    final KeyProvider.Options options = KeyProvider.options(conf);\n+    provider.createKey(\"key\", options);\n+    provider.flush();\n+\n+    try {\n+      DistributedFileSystem dfs = cluster.getFileSystem();\n+\n+      Path testDir = new Path(\"/ssgtr/test3ez/\");\n+      dfs.mkdirs(testDir);\n+      dfs.createEncryptionZone(testDir, \"key\");\n+      Path testSubD = new Path(testDir, \"sssubdir\");\n+      Path file1Path = new Path(testSubD, \"file1\");\n+      dfs.create(file1Path);\n+\n+      final Path trBefore = dfs.getTrashRoot(file1Path);\n+      final String trBeforeStr = trBefore.toUri().getPath();\n+      // The trash root should be directly under testDir\n+      final Path testDirTrash = new Path(testDir, FileSystem.TRASH_PREFIX);\n+      final String testDirTrashStr = testDirTrash.toUri().getPath();\n+      assertTrue(trBeforeStr.startsWith(testDirTrashStr));\n+\n+      dfs.allowSnapshot(testSubD);\n+      final Path trAfter = dfs.getTrashRoot(file1Path);\n+      final String trAfterStr = trAfter.toUri().getPath();\n+      // The trash is now located in the dir inside\n+      final Path testSubDirTrash = new Path(testSubD, FileSystem.TRASH_PREFIX);\n+      final String testSubDirTrashStr = testSubDirTrash.toUri().getPath();\n+      assertTrue(trAfterStr.startsWith(testSubDirTrashStr));", "originalCommit": "6b0a2585e837d7386fc52f58fc32e668d2440f5d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzE4OTUzMA==", "url": "https://github.com/apache/hadoop/pull/2176#discussion_r467189530", "bodyText": "sure. done", "author": "smengcl", "createdAt": "2020-08-07T18:00:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjUxNzg3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjUxODMzOQ==", "url": "https://github.com/apache/hadoop/pull/2176#discussion_r466518339", "bodyText": "startsWith --> equals", "author": "bshashikant", "createdAt": "2020-08-06T16:00:01Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDistributedFileSystem.java", "diffHunk": "@@ -2144,4 +2146,293 @@ public void testECCloseCommittedBlock() throws Exception {\n       LambdaTestUtils.intercept(IOException.class, \"\", () -> str.close());\n     }\n   }\n+\n+  @Test\n+  public void testGetTrashRoot() throws IOException {\n+    Configuration conf = getTestConfiguration();\n+    conf.setBoolean(DFS_NAMENODE_SNAPSHOT_TRASHROOT_ENABLED, true);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    try {\n+      DistributedFileSystem dfs = cluster.getFileSystem();\n+      Path testDir = new Path(\"/ssgtr/test1/\");\n+      Path file0path = new Path(testDir, \"file-0\");\n+      dfs.create(file0path);\n+\n+      Path trBeforeAllowSnapshot = dfs.getTrashRoot(file0path);\n+      String trBeforeAllowSnapshotStr = trBeforeAllowSnapshot.toUri().getPath();\n+      // The trash root should be in user home directory\n+      String homeDirStr = dfs.getHomeDirectory().toUri().getPath();\n+      assertTrue(trBeforeAllowSnapshotStr.startsWith(homeDirStr));\n+\n+      dfs.allowSnapshot(testDir);\n+\n+      Path trAfterAllowSnapshot = dfs.getTrashRoot(file0path);\n+      String trAfterAllowSnapshotStr = trAfterAllowSnapshot.toUri().getPath();\n+      // The trash root should now be in the snapshot root\n+      String testDirStr = testDir.toUri().getPath();\n+      assertTrue(trAfterAllowSnapshotStr.startsWith(testDirStr));\n+\n+      // Cleanup\n+      dfs.disallowSnapshot(testDir);\n+      dfs.delete(testDir, true);\n+    } finally {\n+      if (cluster != null) {\n+        cluster.shutdown();\n+      }\n+    }\n+  }\n+\n+  private boolean isPathInUserHome(String pathStr, DistributedFileSystem dfs) {\n+    String homeDirStr = dfs.getHomeDirectory().toUri().getPath();\n+    return pathStr.startsWith(homeDirStr);\n+  }\n+\n+  @Test\n+  public void testGetTrashRoots() throws IOException {\n+    Configuration conf = getTestConfiguration();\n+    conf.setBoolean(DFS_NAMENODE_SNAPSHOT_TRASHROOT_ENABLED, true);\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    try {\n+      DistributedFileSystem dfs = cluster.getFileSystem();\n+      Path testDir = new Path(\"/ssgtr/test1/\");\n+      Path file0path = new Path(testDir, \"file-0\");\n+      dfs.create(file0path);\n+      // Create user trash\n+      Path currUserHome = dfs.getHomeDirectory();\n+      Path currUserTrash = new Path(currUserHome, FileSystem.TRASH_PREFIX);\n+      dfs.mkdirs(currUserTrash);\n+      // Create trash inside test directory\n+      Path testDirTrash = new Path(testDir, FileSystem.TRASH_PREFIX);\n+      Path testDirTrashCurrUser = new Path(testDirTrash,\n+          UserGroupInformation.getCurrentUser().getShortUserName());\n+      dfs.mkdirs(testDirTrashCurrUser);\n+\n+      Collection<FileStatus> trashRoots = dfs.getTrashRoots(false);\n+      // getTrashRoots should only return 1 empty user trash in the home dir now\n+      assertEquals(1, trashRoots.size());\n+      FileStatus firstFileStatus = trashRoots.iterator().next();\n+      String pathStr = firstFileStatus.getPath().toUri().getPath();\n+      assertTrue(isPathInUserHome(pathStr, dfs));\n+      // allUsers should not make a difference for now because we have one user\n+      Collection<FileStatus> trashRootsAllUsers = dfs.getTrashRoots(true);\n+      assertEquals(trashRoots, trashRootsAllUsers);\n+\n+      dfs.allowSnapshot(testDir);\n+\n+      Collection<FileStatus> trashRootsAfter = dfs.getTrashRoots(false);\n+      // getTrashRoots should return 1 more trash root inside snapshottable dir\n+      assertEquals(trashRoots.size() + 1, trashRootsAfter.size());\n+      boolean foundUserHomeTrash = false;\n+      boolean foundSnapDirUserTrash = false;\n+      String testDirStr = testDir.toUri().getPath();\n+      for (FileStatus fileStatus : trashRootsAfter) {\n+        String currPathStr = fileStatus.getPath().toUri().getPath();\n+        if (isPathInUserHome(currPathStr, dfs)) {\n+          foundUserHomeTrash = true;\n+        } else if (currPathStr.startsWith(testDirStr)) {\n+          foundSnapDirUserTrash = true;\n+        }\n+      }\n+      assertTrue(foundUserHomeTrash);\n+      assertTrue(foundSnapDirUserTrash);\n+      // allUsers should not make a difference for now because we have one user\n+      Collection<FileStatus> trashRootsAfterAllUsers = dfs.getTrashRoots(true);\n+      assertEquals(trashRootsAfter, trashRootsAfterAllUsers);\n+\n+      // Create trash root for user0\n+      UserGroupInformation ugi = UserGroupInformation.createRemoteUser(\"user0\");\n+      String user0HomeStr = DFSUtilClient.getHomeDirectory(conf, ugi);\n+      Path user0Trash = new Path(user0HomeStr, FileSystem.TRASH_PREFIX);\n+      dfs.mkdirs(user0Trash);\n+      // allUsers flag set to false should be unaffected\n+      Collection<FileStatus> trashRootsAfter2 = dfs.getTrashRoots(false);\n+      assertEquals(trashRootsAfter, trashRootsAfter2);\n+      // allUsers flag set to true should include new user's trash\n+      trashRootsAfter2 = dfs.getTrashRoots(true);\n+      assertEquals(trashRootsAfter.size() + 1, trashRootsAfter2.size());\n+\n+      // Create trash root inside the snapshottable directory for user0\n+      Path testDirTrashUser0 = new Path(testDirTrash, ugi.getShortUserName());\n+      dfs.mkdirs(testDirTrashUser0);\n+      Collection<FileStatus> trashRootsAfter3 = dfs.getTrashRoots(true);\n+      assertEquals(trashRootsAfter2.size() + 1, trashRootsAfter3.size());\n+\n+      // Cleanup\n+      dfs.disallowSnapshot(testDir);\n+      dfs.delete(testDir, true);\n+    } finally {\n+      if (cluster != null) {\n+        cluster.shutdown();\n+      }\n+    }\n+  }\n+\n+  @Test\n+  public void testGetTrashRootsOnSnapshottableDirWithEZ()\n+      throws IOException, NoSuchAlgorithmException {\n+    Configuration conf = getTestConfiguration();\n+    conf.setBoolean(DFS_NAMENODE_SNAPSHOT_TRASHROOT_ENABLED, true);\n+    // Set encryption zone config\n+    File tmpDir = GenericTestUtils.getTestDir(UUID.randomUUID().toString());\n+    final Path jksPath = new Path(tmpDir.toString(), \"test.jks\");\n+    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_KEY_PROVIDER_PATH,\n+        JavaKeyStoreProvider.SCHEME_NAME + \"://file\" + jksPath.toUri());\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    // Create key for EZ\n+    final KeyProvider provider =\n+        cluster.getNameNode().getNamesystem().getProvider();\n+    final KeyProvider.Options options = KeyProvider.options(conf);\n+    provider.createKey(\"key\", options);\n+    provider.flush();\n+\n+    try {\n+      DistributedFileSystem dfs = cluster.getFileSystem();\n+      Path testDir = new Path(\"/ssgtr/test2/\");\n+      dfs.mkdirs(testDir);\n+      dfs.createEncryptionZone(testDir, \"key\");\n+\n+      // Create trash inside test directory\n+      Path testDirTrash = new Path(testDir, FileSystem.TRASH_PREFIX);\n+      Path testDirTrashCurrUser = new Path(testDirTrash,\n+          UserGroupInformation.getCurrentUser().getShortUserName());\n+      dfs.mkdirs(testDirTrashCurrUser);\n+\n+      Collection<FileStatus> trashRoots = dfs.getTrashRoots(false);\n+      assertEquals(1, trashRoots.size());\n+      FileStatus firstFileStatus = trashRoots.iterator().next();\n+      String pathStr = firstFileStatus.getPath().toUri().getPath();\n+      String testDirStr = testDir.toUri().getPath();\n+      assertTrue(pathStr.startsWith(testDirStr));\n+\n+      dfs.allowSnapshot(testDir);\n+\n+      Collection<FileStatus> trashRootsAfter = dfs.getTrashRoots(false);\n+      // getTrashRoots should give the same result\n+      assertEquals(trashRoots, trashRootsAfter);\n+\n+      // Cleanup\n+      dfs.disallowSnapshot(testDir);\n+      dfs.delete(testDir, true);\n+    } finally {\n+      if (cluster != null) {\n+        cluster.shutdown();\n+      }\n+    }\n+  }\n+\n+  @Test\n+  public void testGetTrashRootOnSnapshottableDirInEZ()\n+      throws IOException, NoSuchAlgorithmException {\n+    Configuration conf = getTestConfiguration();\n+    conf.setBoolean(DFS_NAMENODE_SNAPSHOT_TRASHROOT_ENABLED, true);\n+    // Set EZ config\n+    File tmpDir = GenericTestUtils.getTestDir(UUID.randomUUID().toString());\n+    final Path jksPath = new Path(tmpDir.toString(), \"test.jks\");\n+    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_KEY_PROVIDER_PATH,\n+        JavaKeyStoreProvider.SCHEME_NAME + \"://file\" + jksPath.toUri());\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    // Create key for EZ\n+    final KeyProvider provider =\n+        cluster.getNameNode().getNamesystem().getProvider();\n+    final KeyProvider.Options options = KeyProvider.options(conf);\n+    provider.createKey(\"key\", options);\n+    provider.flush();\n+\n+    try {\n+      DistributedFileSystem dfs = cluster.getFileSystem();\n+\n+      Path testDir = new Path(\"/ssgtr/test3ez/\");\n+      dfs.mkdirs(testDir);\n+      dfs.createEncryptionZone(testDir, \"key\");\n+      Path testSubD = new Path(testDir, \"sssubdir\");\n+      Path file1Path = new Path(testSubD, \"file1\");\n+      dfs.create(file1Path);\n+\n+      final Path trBefore = dfs.getTrashRoot(file1Path);\n+      final String trBeforeStr = trBefore.toUri().getPath();\n+      // The trash root should be directly under testDir\n+      final Path testDirTrash = new Path(testDir, FileSystem.TRASH_PREFIX);\n+      final String testDirTrashStr = testDirTrash.toUri().getPath();\n+      assertTrue(trBeforeStr.startsWith(testDirTrashStr));\n+\n+      dfs.allowSnapshot(testSubD);\n+      final Path trAfter = dfs.getTrashRoot(file1Path);\n+      final String trAfterStr = trAfter.toUri().getPath();\n+      // The trash is now located in the dir inside\n+      final Path testSubDirTrash = new Path(testSubD, FileSystem.TRASH_PREFIX);\n+      final String testSubDirTrashStr = testSubDirTrash.toUri().getPath();\n+      assertTrue(trAfterStr.startsWith(testSubDirTrashStr));\n+\n+      // Cleanup\n+      dfs.disallowSnapshot(testSubD);\n+      dfs.delete(testDir, true);\n+    } finally {\n+      if (cluster != null) {\n+        cluster.shutdown();\n+      }\n+    }\n+  }\n+\n+  @Test\n+  public void testGetTrashRootOnEZInSnapshottableDir()\n+      throws IOException, NoSuchAlgorithmException {\n+    Configuration conf = getTestConfiguration();\n+    conf.setBoolean(DFS_NAMENODE_SNAPSHOT_TRASHROOT_ENABLED, true);\n+    // Set EZ config\n+    File tmpDir = GenericTestUtils.getTestDir(UUID.randomUUID().toString());\n+    final Path jksPath = new Path(tmpDir.toString(), \"test.jks\");\n+    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_KEY_PROVIDER_PATH,\n+        JavaKeyStoreProvider.SCHEME_NAME + \"://file\" + jksPath.toUri());\n+    MiniDFSCluster cluster =\n+        new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\n+    // Create key for EZ\n+    final KeyProvider provider =\n+        cluster.getNameNode().getNamesystem().getProvider();\n+    final KeyProvider.Options options = KeyProvider.options(conf);\n+    provider.createKey(\"key\", options);\n+    provider.flush();\n+\n+    try {\n+      DistributedFileSystem dfs = cluster.getFileSystem();\n+\n+      Path testDir = new Path(\"/ssgtr/test3ss/\");\n+      dfs.mkdirs(testDir);\n+      dfs.allowSnapshot(testDir);\n+      Path testSubD = new Path(testDir, \"ezsubdir\");\n+      dfs.mkdirs(testSubD);\n+      Path file1Path = new Path(testSubD, \"file1\");\n+      dfs.create(file1Path);\n+\n+      final Path trBefore = dfs.getTrashRoot(file1Path);\n+      final String trBeforeStr = trBefore.toUri().getPath();\n+      // The trash root should be directly under testDir\n+      final Path testDirTrash = new Path(testDir, FileSystem.TRASH_PREFIX);\n+      final String testDirTrashStr = testDirTrash.toUri().getPath();\n+      assertTrue(trBeforeStr.startsWith(testDirTrashStr));\n+\n+      // Need to remove the file inside the dir to establish EZ\n+      dfs.delete(file1Path, false);\n+      dfs.createEncryptionZone(testSubD, \"key\");\n+      dfs.create(file1Path);\n+\n+      final Path trAfter = dfs.getTrashRoot(file1Path);\n+      final String trAfterStr = trAfter.toUri().getPath();\n+      // The trash is now located in the dir inside\n+      final Path testSubDirTrash = new Path(testSubD, FileSystem.TRASH_PREFIX);\n+      final String testSubDirTrashStr = testSubDirTrash.toUri().getPath();\n+      assertTrue(trAfterStr.startsWith(testSubDirTrashStr));\n+", "originalCommit": "6b0a2585e837d7386fc52f58fc32e668d2440f5d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzE4OTU4Nw==", "url": "https://github.com/apache/hadoop/pull/2176#discussion_r467189587", "bodyText": "done", "author": "smengcl", "createdAt": "2020-08-07T18:00:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjUxODMzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjUyNTA5Mg==", "url": "https://github.com/apache/hadoop/pull/2176#discussion_r466525092", "bodyText": "i guess we need to define these configs in SnapshotManager if we intend not add it in hdfs-default.xml(which i would prefer). It leads to test failure here \"hadoop.tools.TestHdfsConfigFields\"", "author": "bshashikant", "createdAt": "2020-08-06T16:10:42Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSConfigKeys.java", "diffHunk": "@@ -516,6 +516,11 @@\n   public static final int\n       DFS_NAMENODE_SNAPSHOT_SKIPLIST_MAX_SKIP_LEVELS_DEFAULT = 0;\n \n+  public static final String DFS_NAMENODE_SNAPSHOT_TRASHROOT_ENABLED =\n+      \"dfs.namenode.snapshot.trashroot.enabled\";\n+  public static final boolean DFS_NAMENODE_SNAPSHOT_TRASHROOT_ENABLED_DEFAULT =", "originalCommit": "6b0a2585e837d7386fc52f58fc32e668d2440f5d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzIyMjEzMQ==", "url": "https://github.com/apache/hadoop/pull/2176#discussion_r467222131", "bodyText": "Got it. I will put it in FSNameSystem as private config then as it is used there, similar to HDFS-15481 did.", "author": "smengcl", "createdAt": "2020-08-07T19:10:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjUyNTA5Mg=="}], "type": "inlineReview"}, {"oid": "1aeb21b0d682bf7262409811b90b0fd584b71bc4", "url": "https://github.com/apache/hadoop/commit/1aeb21b0d682bf7262409811b90b0fd584b71bc4", "message": "First step, client shall now move to trash inside a snapshot.\n\nChange-Id: I43aeb4959c5d0b9140eaed8f899b2f93f642eb04", "committedDate": "2020-08-07T19:03:17Z", "type": "commit"}, {"oid": "265a17a8478277a1292c05bbeaf69a9cd63b3fd8", "url": "https://github.com/apache/hadoop/commit/265a17a8478277a1292c05bbeaf69a9cd63b3fd8", "message": "Fix javadoc.\n\nChange-Id: I29120bf9c946841615c0e7efaac5c0056f1f795c", "committedDate": "2020-08-07T19:03:17Z", "type": "commit"}, {"oid": "35e8a17c790539b6507480c92b7e5dd27e0864ad", "url": "https://github.com/apache/hadoop/commit/35e8a17c790539b6507480c92b7e5dd27e0864ad", "message": "Add new config key `dfs.namenode.snapshot.trashroot.enabled`.\n\nChange-Id: I7b497d7f10fcc9c37916abdab330c21c8bb05a16", "committedDate": "2020-08-07T19:03:17Z", "type": "commit"}, {"oid": "6fa4aafaca329bc158a5cacd96095a839af27f2b", "url": "https://github.com/apache/hadoop/commit/6fa4aafaca329bc158a5cacd96095a839af27f2b", "message": "Make the config `dfs.namenode.snapshot.trashroot.enabled` configurable on server-side only.\n\nChange-Id: I3d88fc5a437f8211755abe5d8b840de040a46099", "committedDate": "2020-08-07T19:03:17Z", "type": "commit"}, {"oid": "daa29f083d13cb2e1e8ecc2384384cb915f548f6", "url": "https://github.com/apache/hadoop/commit/daa29f083d13cb2e1e8ecc2384384cb915f548f6", "message": "Handle case where getSnapshottableDirListing gives null.\n\nChange-Id: Ic7c6078669925a3e13c6e462e6d0e51c3b9ff0fa", "committedDate": "2020-08-07T19:03:17Z", "type": "commit"}, {"oid": "5387f8a6658d30b062135aa5d7469a99878c5673", "url": "https://github.com/apache/hadoop/commit/5387f8a6658d30b062135aa5d7469a99878c5673", "message": "Added basic test case with new config enabled, before and after allowing snapshot on the test dir.\n\nChange-Id: I3dbe20785351b84375c644de6d06610c74d6e7d9", "committedDate": "2020-08-07T19:03:17Z", "type": "commit"}, {"oid": "7b7e88cef0cff54bfd72bf46adb2b2186c0663c4", "url": "https://github.com/apache/hadoop/commit/7b7e88cef0cff54bfd72bf46adb2b2186c0663c4", "message": "getTrashRoots done.\n\nChange-Id: I6c65115eb8f176bc948f38f7c91e417391f8cab8", "committedDate": "2020-08-07T19:03:18Z", "type": "commit"}, {"oid": "9ec4658a1e453588e26ab4804765b50e2b25fa09", "url": "https://github.com/apache/hadoop/commit/9ec4658a1e453588e26ab4804765b50e2b25fa09", "message": "Added test for getTrashRoots; getSnapshottableDirListing could return null.\n\nChange-Id: Iff9a24d76966857340eacb8586c88d7b991468f9", "committedDate": "2020-08-07T19:03:18Z", "type": "commit"}, {"oid": "1a7a2756615131ae7fc66186060fb18a7ddf2183", "url": "https://github.com/apache/hadoop/commit/1a7a2756615131ae7fc66186060fb18a7ddf2183", "message": "Use Set in DFS#getTrashRoots to avoid a directory with both snapshot and EZ enabled to be added to the result twice; added test case for this.\n\nChange-Id: Iecad971f0712ad6d1183bdc14fc7a05864d9e84b", "committedDate": "2020-08-07T19:03:18Z", "type": "commit"}, {"oid": "e373f75ea95eac25b6c3f51a8e58561846d8a71b", "url": "https://github.com/apache/hadoop/commit/e373f75ea95eac25b6c3f51a8e58561846d8a71b", "message": "Remove unused imports.\n\nChange-Id: Ib023bd014afa1496b90c678645cb868d9056c9ed", "committedDate": "2020-08-07T19:03:18Z", "type": "commit"}, {"oid": "534ebbb6dd037bafdb3e21432560bfa4efc11404", "url": "https://github.com/apache/hadoop/commit/534ebbb6dd037bafdb3e21432560bfa4efc11404", "message": "When a path given to getTrashRoot() is both inside an EZ and in a snapshottable dir, it should choose the inner most trash.\n\nChange-Id: Ibf58de1031c94b0166f27f623eb5e9ea1669bac0", "committedDate": "2020-08-07T19:03:18Z", "type": "commit"}, {"oid": "26b7b4a052552aede7728c3e9ad487569d58ba02", "url": "https://github.com/apache/hadoop/commit/26b7b4a052552aede7728c3e9ad487569d58ba02", "message": "Remove dfs.namenode.snapshot.trashroot.enabled from HdfsClientConfigKeys, since it the NN will be the only source of truth for this config.\n\nChange-Id: I5247537803c2017b5af860e7eac057123031a86f", "committedDate": "2020-08-07T19:03:18Z", "type": "commit"}, {"oid": "5b6fecb11d7e2d79514d3a14721ad798be8f203c", "url": "https://github.com/apache/hadoop/commit/5b6fecb11d7e2d79514d3a14721ad798be8f203c", "message": "Make findbugs happy.\n\nChange-Id: I6fd630e4d47fc9d403811d2bb92077322e7d4895", "committedDate": "2020-08-07T19:03:18Z", "type": "commit"}, {"oid": "577de510af5462393f23d29c6c61596c1518ba88", "url": "https://github.com/apache/hadoop/commit/577de510af5462393f23d29c6c61596c1518ba88", "message": "startsWith -> equals in some tests.\n\nChange-Id: Id3c130c4f94508d21c656602a867fc59f2e6126a", "committedDate": "2020-08-07T19:03:19Z", "type": "commit"}, {"oid": "56d3f188d138384c535d3d4869a8f124d6ed65c5", "url": "https://github.com/apache/hadoop/commit/56d3f188d138384c535d3d4869a8f124d6ed65c5", "message": "Make dfs.namenode.snapshot.trashroot.enabled a private config in FSNameSystem.\n\nChange-Id: Ife297d420156b9aafcb5d774ae419b6f3b6ce149", "committedDate": "2020-08-07T20:17:35Z", "type": "commit"}, {"oid": "56d3f188d138384c535d3d4869a8f124d6ed65c5", "url": "https://github.com/apache/hadoop/commit/56d3f188d138384c535d3d4869a8f124d6ed65c5", "message": "Make dfs.namenode.snapshot.trashroot.enabled a private config in FSNameSystem.\n\nChange-Id: Ife297d420156b9aafcb5d774ae419b6f3b6ce149", "committedDate": "2020-08-07T20:17:35Z", "type": "forcePushed"}]}