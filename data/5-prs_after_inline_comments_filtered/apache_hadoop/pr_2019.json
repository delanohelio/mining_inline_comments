{"pr_number": 2019, "pr_title": "HADOOP-17029. Return correct permission and owner for listing on internal directories in ViewFs", "pr_createdAt": "2020-05-13T12:17:17Z", "pr_url": "https://github.com/apache/hadoop/pull/2019", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzQ5MDIwMg==", "url": "https://github.com/apache/hadoop/pull/2019#discussion_r427490202", "bodyText": "two comments:\n\nseems to be some duplicate code, the \"else\" branch is pretty much the same, can we refactor here?\nNot sure if this is the best way when dealing with FileNotFoundException. If I understand this correctly, it is possible that some mounts does not have this path, so it can hit FileNotFoundException?\n\nIf this is the case, I wonder if it makes more sense to just skip this mount, by not adding a FileStatus for mount at all. So that clients do not get confused by an actually non-existing FileStatus, among other existing ones. But one issue here would be that result array is strictly the size of the # of mounts. Creating result as a list, append, and then return as a array may resolve this.", "author": "chliang71", "createdAt": "2020-05-19T17:52:01Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/viewfs/ViewFileSystem.java", "diffHunk": "@@ -1211,13 +1211,29 @@ public FileStatus getFileStatus(Path f) throws IOException {\n         INode<FileSystem> inode = iEntry.getValue();\n         if (inode.isLink()) {\n           INodeLink<FileSystem> link = (INodeLink<FileSystem>) inode;\n-\n-          result[i++] = new FileStatus(0, false, 0, 0,\n-            creationTime, creationTime, PERMISSION_555,\n-            ugi.getShortUserName(), ugi.getPrimaryGroupName(),\n-            link.getTargetLink(),\n-            new Path(inode.fullPath).makeQualified(\n-                myUri, null));\n+          // For MERGE or NFLY links, the first target link is considered\n+          // for fetching the FileStatus with an assumption that the permission\n+          // and the owner will be the same for all the target directories.\n+          Path linkedPath = new Path(link.targetDirLinkList[0].toString());\n+          ChRootedFileSystem linkedFs = (ChRootedFileSystem)\n+              link.getTargetFileSystem();\n+          try {\n+            FileStatus status = linkedFs.getMyFs().getFileStatus(linkedPath);\n+            result[i++] = new FileStatus(status.getLen(), false,\n+              status.getReplication(), status.getBlockSize(),\n+              status.getModificationTime(), status.getAccessTime(),\n+              status.getPermission(), status.getOwner(), status.getGroup(),\n+              link.getTargetLink(),\n+              new Path(inode.fullPath).makeQualified(\n+                  myUri, null));\n+          } catch (FileNotFoundException ex) {\n+            result[i++] = new FileStatus(0, false, 0, 0,\n+              creationTime, creationTime, PERMISSION_555,\n+              ugi.getShortUserName(), ugi.getPrimaryGroupName(),\n+              link.getTargetLink(),\n+              new Path(inode.fullPath).makeQualified(\n+                  myUri, null));", "originalCommit": "291e5ad8a2cf48d44f42ba83434e95ce297be8a9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDYyMzQ3Nw==", "url": "https://github.com/apache/hadoop/pull/2019#discussion_r430623477", "bodyText": "For # 2: The problem here I think we may not be able reset mount automatically, so until some one checks file exists or do op on target, we will not know whether the file exists or not. This will continue until user updates mount points accordingly.\nThis can be possible when some one deletes the target directory directly but not updated the mount tables accordingly. Please check one of my comment on behavior of ls in MAC. Also we have other issue:  isDir is inconsistent.", "author": "umamaheswararao", "createdAt": "2020-05-26T18:33:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzQ5MDIwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDM0MDc1Ng==", "url": "https://github.com/apache/hadoop/pull/2019#discussion_r434340756", "bodyText": "Sorry if I am missing anything. The change with catching the FileNotFoundException is good ? or I need to make a change.", "author": "abhishekdas99", "createdAt": "2020-06-03T06:42:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzQ5MDIwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDM0MTMxNg==", "url": "https://github.com/apache/hadoop/pull/2019#discussion_r434341316", "bodyText": "Sorry if I am missing anything. The change with catching the FileNotFoundException is good ? or I need to change something. @umamaheswararao", "author": "abhishekdas99", "createdAt": "2020-06-03T06:43:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzQ5MDIwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU5MzIxMw==", "url": "https://github.com/apache/hadoop/pull/2019#discussion_r435593213", "bodyText": "IMO, FileNotFoundException is fine. Please see my comment below https://github.com/apache/hadoop/pull/2019/files#r430611396\n@chliang71 , What do you say?", "author": "umamaheswararao", "createdAt": "2020-06-04T22:46:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzQ5MDIwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzQ5Mjk1MA==", "url": "https://github.com/apache/hadoop/pull/2019#discussion_r427492950", "bodyText": "similar comment regarding FileNotFoundException. I think in general, it's better to match behavior of non-federated client. If a path does not exist, just throw back FileNotFoundException.", "author": "chliang71", "createdAt": "2020-05-19T17:56:16Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/viewfs/ViewFs.java", "diffHunk": "@@ -915,11 +915,24 @@ public FileStatus getFileLinkStatus(final Path f)\n       if (inode.isLink()) {\n         INodeLink<AbstractFileSystem> inodelink = \n           (INodeLink<AbstractFileSystem>) inode;\n-        result = new FileStatus(0, false, 0, 0, creationTime, creationTime,\n+        Path linkedPath = new Path(inodelink.targetDirLinkList[0].toString());\n+        ChRootedFs linkedFs = (ChRootedFs) inodelink.getTargetFileSystem();\n+        try {\n+          FileStatus status = linkedFs.getMyFs().getFileStatus(linkedPath);\n+          result = new FileStatus(status.getLen(), false,\n+            status.getReplication(), status.getBlockSize(),\n+            status.getModificationTime(), status.getAccessTime(),\n+            status.getPermission(), status.getOwner(), status.getGroup(),\n+            inodelink.getTargetLink(),\n+            new Path(inode.fullPath).makeQualified(\n+                myUri, null));\n+        } catch (FileNotFoundException ex) {", "originalCommit": "291e5ad8a2cf48d44f42ba83434e95ce297be8a9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDYxMTM5Ng==", "url": "https://github.com/apache/hadoop/pull/2019#discussion_r430611396", "bodyText": "similar comment regarding FileNotFoundException. I think in general, it's better to match behavior of non-federated client. If a path does not exist, just throw back FileNotFoundException.\n\nI just verified symlinks. When target deleted,  ls on symlink does not throw FNFE.  Instead it is converted to file link. I tested dir->dir link.\nIt seems this behavior is correct when compared with other fs. I tested on my MAC.\nShould this be fixed in federated clusters is necessary ? Could you please validate this?\nIf we attempt to open that non existent link file, then we can throw out exception. But ls seems to simply pass.\nWork % mkdir linkTarget \nWork % ln -s linkTarget linkSrc\nWork % ls -l\nlrwxr-xr-x   1 umagangumalla  xxxx     10 May 26 11:08 linkSrc -> linkTarget\nWork % rm -rf linkTarget \nWork % ls -l            \nlrwxr-xr-x   1 umagangumalla  xxxx     10 May 26 11:08 linkSrc -> linkTarget\nWork % cd linkSrc\ncd: no such file or directory: linkSrc", "author": "umamaheswararao", "createdAt": "2020-05-26T18:12:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzQ5Mjk1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzQ5MzEzNQ==", "url": "https://github.com/apache/hadoop/pull/2019#discussion_r427493135", "bodyText": "same comment about FileNotFoundException  here", "author": "chliang71", "createdAt": "2020-05-19T17:56:34Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/viewfs/ViewFs.java", "diffHunk": "@@ -965,12 +978,25 @@ public int getUriDefaultPort() {\n           INodeLink<AbstractFileSystem> link = \n             (INodeLink<AbstractFileSystem>) inode;\n \n-          result[i++] = new FileStatus(0, false, 0, 0,\n-            creationTime, creationTime,\n-            PERMISSION_555, ugi.getShortUserName(), ugi.getPrimaryGroupName(),\n-            link.getTargetLink(),\n-            new Path(inode.fullPath).makeQualified(\n-                myUri, null));\n+          Path linkedPath = new Path(link.targetDirLinkList[0].toString());\n+          ChRootedFs linkedFs = (ChRootedFs) link.getTargetFileSystem();\n+          try {\n+            FileStatus status = linkedFs.getMyFs().getFileStatus(linkedPath);\n+            result[i++] = new FileStatus(status.getLen(), false,\n+              status.getReplication(), status.getBlockSize(),\n+              status.getModificationTime(), status.getAccessTime(),\n+              status.getPermission(), status.getOwner(), status.getGroup(),\n+              link.getTargetLink(),\n+              new Path(inode.fullPath).makeQualified(\n+                  myUri, null));\n+          } catch (FileNotFoundException ex) {", "originalCommit": "291e5ad8a2cf48d44f42ba83434e95ce297be8a9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzQ5MzY2NQ==", "url": "https://github.com/apache/hadoop/pull/2019#discussion_r427493665", "bodyText": "some javadoc, and comments in the code could be helpful", "author": "chliang71", "createdAt": "2020-05-19T17:57:24Z", "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestViewfsFileStatus.java", "diffHunk": "@@ -56,38 +69,71 @@ public void testFileStatusSerialziation()\n     File infile = new File(TEST_DIR, testfilename);\n     final byte[] content = \"dingos\".getBytes();\n \n-    FileOutputStream fos = null;\n-    try {\n-      fos = new FileOutputStream(infile);\n+    try (FileOutputStream fos =  new FileOutputStream(infile)) {\n       fos.write(content);\n-    } finally {\n-      if (fos != null) {\n-        fos.close();\n-      }\n     }\n     assertEquals((long)content.length, infile.length());\n \n     Configuration conf = new Configuration();\n     ConfigUtil.addLink(conf, \"/foo/bar/baz\", TEST_DIR.toURI());\n-    FileSystem vfs = FileSystem.get(FsConstants.VIEWFS_URI, conf);\n-    assertEquals(ViewFileSystem.class, vfs.getClass());\n-    Path path = new Path(\"/foo/bar/baz\", testfilename);\n-    FileStatus stat = vfs.getFileStatus(path);\n-    assertEquals(content.length, stat.getLen());\n-    ContractTestUtils.assertNotErasureCoded(vfs, path);\n-    assertTrue(path + \" should have erasure coding unset in \" +\n-            \"FileStatus#toString(): \" + stat,\n-        stat.toString().contains(\"isErasureCoded=false\"));\n-\n-    // check serialization/deserialization\n-    DataOutputBuffer dob = new DataOutputBuffer();\n-    stat.write(dob);\n-    DataInputBuffer dib = new DataInputBuffer();\n-    dib.reset(dob.getData(), 0, dob.getLength());\n-    FileStatus deSer = new FileStatus();\n-    deSer.readFields(dib);\n-    assertEquals(content.length, deSer.getLen());\n-    assertFalse(deSer.isErasureCoded());\n+    try (FileSystem vfs = FileSystem.get(FsConstants.VIEWFS_URI, conf)) {\n+      assertEquals(ViewFileSystem.class, vfs.getClass());\n+      Path path = new Path(\"/foo/bar/baz\", testfilename);\n+      FileStatus stat = vfs.getFileStatus(path);\n+      assertEquals(content.length, stat.getLen());\n+      ContractTestUtils.assertNotErasureCoded(vfs, path);\n+      assertTrue(path + \" should have erasure coding unset in \" +\n+          \"FileStatus#toString(): \" + stat,\n+          stat.toString().contains(\"isErasureCoded=false\"));\n+\n+      // check serialization/deserialization\n+      DataOutputBuffer dob = new DataOutputBuffer();\n+      stat.write(dob);\n+      DataInputBuffer dib = new DataInputBuffer();\n+      dib.reset(dob.getData(), 0, dob.getLength());\n+      FileStatus deSer = new FileStatus();\n+      deSer.readFields(dib);\n+      assertEquals(content.length, deSer.getLen());\n+      assertFalse(deSer.isErasureCoded());\n+    }\n+  }\n+\n+  @Test\n+  public void testListStatusACL()", "originalCommit": "291e5ad8a2cf48d44f42ba83434e95ce297be8a9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDU5NjkyMw==", "url": "https://github.com/apache/hadoop/pull/2019#discussion_r430596923", "bodyText": "instead of link.targetDirLinkList[0], link.getTargetFileSystem().getUri() should work?\nThis might work for nfly also I think. Because nfly has its own GetFileStatus impl, probably we should use that impl only instead of getting one targetDirLinkList[0]", "author": "umamaheswararao", "createdAt": "2020-05-26T17:50:07Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/viewfs/ViewFileSystem.java", "diffHunk": "@@ -1211,13 +1211,29 @@ public FileStatus getFileStatus(Path f) throws IOException {\n         INode<FileSystem> inode = iEntry.getValue();\n         if (inode.isLink()) {\n           INodeLink<FileSystem> link = (INodeLink<FileSystem>) inode;\n-\n-          result[i++] = new FileStatus(0, false, 0, 0,\n-            creationTime, creationTime, PERMISSION_555,\n-            ugi.getShortUserName(), ugi.getPrimaryGroupName(),\n-            link.getTargetLink(),\n-            new Path(inode.fullPath).makeQualified(\n-                myUri, null));\n+          // For MERGE or NFLY links, the first target link is considered\n+          // for fetching the FileStatus with an assumption that the permission\n+          // and the owner will be the same for all the target directories.\n+          Path linkedPath = new Path(link.targetDirLinkList[0].toString());", "originalCommit": "291e5ad8a2cf48d44f42ba83434e95ce297be8a9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDMyMDM5MQ==", "url": "https://github.com/apache/hadoop/pull/2019#discussion_r434320391", "bodyText": "In the new change , I have getting the filesystem by link.getTargetFileSystem() and calling getFileStatus on slash path.", "author": "abhishekdas99", "createdAt": "2020-06-03T05:43:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDU5NjkyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDYxNTQyNQ==", "url": "https://github.com/apache/hadoop/pull/2019#discussion_r430615425", "bodyText": "Can we change permission on target and assert whether its getting changed permissions or simply link permissions?", "author": "umamaheswararao", "createdAt": "2020-05-26T18:20:03Z", "path": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestViewfsFileStatus.java", "diffHunk": "@@ -56,38 +69,71 @@ public void testFileStatusSerialziation()\n     File infile = new File(TEST_DIR, testfilename);\n     final byte[] content = \"dingos\".getBytes();\n \n-    FileOutputStream fos = null;\n-    try {\n-      fos = new FileOutputStream(infile);\n+    try (FileOutputStream fos =  new FileOutputStream(infile)) {\n       fos.write(content);\n-    } finally {\n-      if (fos != null) {\n-        fos.close();\n-      }\n     }\n     assertEquals((long)content.length, infile.length());\n \n     Configuration conf = new Configuration();\n     ConfigUtil.addLink(conf, \"/foo/bar/baz\", TEST_DIR.toURI());\n-    FileSystem vfs = FileSystem.get(FsConstants.VIEWFS_URI, conf);\n-    assertEquals(ViewFileSystem.class, vfs.getClass());\n-    Path path = new Path(\"/foo/bar/baz\", testfilename);\n-    FileStatus stat = vfs.getFileStatus(path);\n-    assertEquals(content.length, stat.getLen());\n-    ContractTestUtils.assertNotErasureCoded(vfs, path);\n-    assertTrue(path + \" should have erasure coding unset in \" +\n-            \"FileStatus#toString(): \" + stat,\n-        stat.toString().contains(\"isErasureCoded=false\"));\n-\n-    // check serialization/deserialization\n-    DataOutputBuffer dob = new DataOutputBuffer();\n-    stat.write(dob);\n-    DataInputBuffer dib = new DataInputBuffer();\n-    dib.reset(dob.getData(), 0, dob.getLength());\n-    FileStatus deSer = new FileStatus();\n-    deSer.readFields(dib);\n-    assertEquals(content.length, deSer.getLen());\n-    assertFalse(deSer.isErasureCoded());\n+    try (FileSystem vfs = FileSystem.get(FsConstants.VIEWFS_URI, conf)) {\n+      assertEquals(ViewFileSystem.class, vfs.getClass());\n+      Path path = new Path(\"/foo/bar/baz\", testfilename);\n+      FileStatus stat = vfs.getFileStatus(path);\n+      assertEquals(content.length, stat.getLen());\n+      ContractTestUtils.assertNotErasureCoded(vfs, path);\n+      assertTrue(path + \" should have erasure coding unset in \" +\n+          \"FileStatus#toString(): \" + stat,\n+          stat.toString().contains(\"isErasureCoded=false\"));\n+\n+      // check serialization/deserialization\n+      DataOutputBuffer dob = new DataOutputBuffer();\n+      stat.write(dob);\n+      DataInputBuffer dib = new DataInputBuffer();\n+      dib.reset(dob.getData(), 0, dob.getLength());\n+      FileStatus deSer = new FileStatus();\n+      deSer.readFields(dib);\n+      assertEquals(content.length, deSer.getLen());\n+      assertFalse(deSer.isErasureCoded());\n+    }\n+  }\n+\n+  @Test\n+  public void testListStatusACL()\n+      throws IOException, URISyntaxException {\n+    String testfilename = \"testFileACL\";\n+    String childDirectoryName = \"testDirectoryACL\";\n+    TEST_DIR.mkdirs();\n+    File infile = new File(TEST_DIR, testfilename);\n+    final byte[] content = \"dingos\".getBytes();\n+\n+    try (FileOutputStream fos =  new FileOutputStream(infile)) {\n+      fos.write(content);\n+    }\n+    assertEquals((long)content.length, infile.length());\n+    File childDir = new File(TEST_DIR, childDirectoryName);\n+    childDir.mkdirs();\n+\n+    Configuration conf = new Configuration();\n+    ConfigUtil.addLink(conf, \"/file\", infile.toURI());\n+    ConfigUtil.addLink(conf, \"/dir\", childDir.toURI());\n+\n+    try (FileSystem vfs = FileSystem.get(FsConstants.VIEWFS_URI, conf)) {\n+      assertEquals(ViewFileSystem.class, vfs.getClass());\n+      FileStatus[] statuses = vfs.listStatus(new Path(\"/\"));\n+\n+      FileSystem localFs = FileSystem.getLocal(conf);\n+      FileStatus fileStat = localFs.getFileStatus(new Path(infile.getPath()));\n+      FileStatus dirStat = localFs.getFileStatus(new Path(childDir.getPath()));\n+\n+      for (FileStatus status : statuses) {\n+        if (status.getPath().getName().equals(\"file\")) {\n+          assertEquals(fileStat.getPermission(), status.getPermission());\n+        } else {", "originalCommit": "291e5ad8a2cf48d44f42ba83434e95ce297be8a9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDMyMDQ0Nw==", "url": "https://github.com/apache/hadoop/pull/2019#discussion_r434320447", "bodyText": "Done", "author": "abhishekdas99", "createdAt": "2020-06-03T05:43:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDYxNTQyNQ=="}], "type": "inlineReview"}, {"oid": "35cfe4e6eddfae9a10207b839d92040b01434162", "url": "https://github.com/apache/hadoop/commit/35cfe4e6eddfae9a10207b839d92040b01434162", "message": "HADOOP-17029. Return correct permission and owner for listing on internal directories in ViewFs", "committedDate": "2020-06-03T06:24:13Z", "type": "commit"}, {"oid": "0243a701637c6296f77eb3c7ad0e9f8ccb63c8c4", "url": "https://github.com/apache/hadoop/commit/0243a701637c6296f77eb3c7ad0e9f8ccb63c8c4", "message": "HADOOP-17029. Change in ViewFs to cover FileContext based fs impl.", "committedDate": "2020-06-03T06:24:13Z", "type": "commit"}, {"oid": "a7a7875038ca29f87d6f050547c35d081d9401e1", "url": "https://github.com/apache/hadoop/commit/a7a7875038ca29f87d6f050547c35d081d9401e1", "message": "HADOOP-17029. Fix for dangling links", "committedDate": "2020-06-03T06:24:13Z", "type": "commit"}, {"oid": "cf990e0b8e43c3a7c855ac103b8cedf450985204", "url": "https://github.com/apache/hadoop/commit/cf990e0b8e43c3a7c855ac103b8cedf450985204", "message": "HADOOP-17029. Addressed code review comments.", "committedDate": "2020-06-03T06:24:13Z", "type": "forcePushed"}, {"oid": "49071eb5c26be346b2a9b90cfa02d4273c91b97c", "url": "https://github.com/apache/hadoop/commit/49071eb5c26be346b2a9b90cfa02d4273c91b97c", "message": "HADOOP-17029. Addressed code review comments.", "committedDate": "2020-06-03T06:38:22Z", "type": "forcePushed"}, {"oid": "da1702af608f5f27d62d31dca4705c7872f2e6c3", "url": "https://github.com/apache/hadoop/commit/da1702af608f5f27d62d31dca4705c7872f2e6c3", "message": "HADOOP-17029. Addressed code review comments.", "committedDate": "2020-06-03T08:40:29Z", "type": "commit"}, {"oid": "da1702af608f5f27d62d31dca4705c7872f2e6c3", "url": "https://github.com/apache/hadoop/commit/da1702af608f5f27d62d31dca4705c7872f2e6c3", "message": "HADOOP-17029. Addressed code review comments.", "committedDate": "2020-06-03T08:40:29Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU5NTcwNw==", "url": "https://github.com/apache/hadoop/pull/2019#discussion_r435595707", "bodyText": "Why are we getting status on \"/\"? In practical scenario it should work. However what if the target uri is a file?\nShould we simply use link.getTargetFileSystem().getUri() ?\nCould you please check scenario? If this works, I have no other changes.\nThanks for update.", "author": "umamaheswararao", "createdAt": "2020-06-04T22:53:23Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/viewfs/ViewFileSystem.java", "diffHunk": "@@ -1200,13 +1200,24 @@ public FileStatus getFileStatus(Path f) throws IOException {\n         INode<FileSystem> inode = iEntry.getValue();\n         if (inode.isLink()) {\n           INodeLink<FileSystem> link = (INodeLink<FileSystem>) inode;\n-\n-          result[i++] = new FileStatus(0, false, 0, 0,\n-            creationTime, creationTime, PERMISSION_555,\n-            ugi.getShortUserName(), ugi.getPrimaryGroupName(),\n-            link.getTargetLink(),\n-            new Path(inode.fullPath).makeQualified(\n-                myUri, null));\n+          try {\n+            FileStatus status = link.getTargetFileSystem()\n+                .getFileStatus(new Path(\"/\"));", "originalCommit": "da1702af608f5f27d62d31dca4705c7872f2e6c3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTg1NjQ1MQ==", "url": "https://github.com/apache/hadoop/pull/2019#discussion_r435856451", "bodyText": "Changed to link.getTargetFileSystem().getUri(). Used ChRootedFileSystem to obtain the filestatus. ((ChRootedFileSystem)link.getTargetFileSystem()).getMyFs().getFileStatus().", "author": "abhishekdas99", "createdAt": "2020-06-05T11:20:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU5NTcwNw=="}], "type": "inlineReview"}, {"oid": "7d43b2932d38458041b2fc00c68b27b8ec0ee209", "url": "https://github.com/apache/hadoop/commit/7d43b2932d38458041b2fc00c68b27b8ec0ee209", "message": "HADOOP-17029. Used link.getTargetFileSystem().getUri() for path", "committedDate": "2020-06-05T11:16:27Z", "type": "commit"}]}