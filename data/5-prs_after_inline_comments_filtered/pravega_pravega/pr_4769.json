{"pr_number": 4769, "pr_title": "Issue 4676: (PDP-34 ) - Part 3 of 4 - TableBasedMetadataStore and hooking it up in StreamSegmentContainer.", "pr_createdAt": "2020-05-04T15:49:58Z", "pr_url": "https://github.com/pravega/pravega/pull/4769", "timeline": [{"oid": "7689cd8e1555921237aee4aa95bd4143c2be84a2", "url": "https://github.com/pravega/pravega/commit/7689cd8e1555921237aee4aa95bd4143c2be84a2", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - TableBasedMetadataStore and hooking it up in StreamSegmentContainer.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-06-05T00:04:42Z", "type": "forcePushed"}, {"oid": "8017d7fe4b0e1e499cc3ac21d9e4d06f94babd2b", "url": "https://github.com/pravega/pravega/commit/8017d7fe4b0e1e499cc3ac21d9e4d06f94babd2b", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - TableBasedMetadataStore and hooking it up in StreamSegmentContainer.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-06-12T15:34:24Z", "type": "forcePushed"}, {"oid": "d0b5de8556822817bce33ca050dae296c4d5f1ff", "url": "https://github.com/pravega/pravega/commit/d0b5de8556822817bce33ca050dae296c4d5f1ff", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - TableBasedMetadataStore and hooking it up in StreamSegmentContainer.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-06-25T17:48:23Z", "type": "forcePushed"}, {"oid": "75f5600813260a073b4b20796c958b3076630bd0", "url": "https://github.com/pravega/pravega/commit/75f5600813260a073b4b20796c958b3076630bd0", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Ignore StorageLoaderTests.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-07-08T20:13:41Z", "type": "forcePushed"}, {"oid": "2e589c6b564714c3b1d06e6812f0d8020f6579cb", "url": "https://github.com/pravega/pravega/commit/2e589c6b564714c3b1d06e6812f0d8020f6579cb", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Boot fix.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-07-14T23:41:49Z", "type": "forcePushed"}, {"oid": "e1c4bea922d076022d8fa338681f039ee4b290aa", "url": "https://github.com/pravega/pravega/commit/e1c4bea922d076022d8fa338681f039ee4b290aa", "message": "Issue 4676: (PDP-34) Initial Implementation (3 of 4) - Bug Fix -truncate should not lazyCommit.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-07-20T18:13:57Z", "type": "commit"}, {"oid": "2f4542abb18631733ddb0fab30e43f71ed9f121a", "url": "https://github.com/pravega/pravega/commit/2f4542abb18631733ddb0fab30e43f71ed9f121a", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - TableBasedMetadataStore and hooking it up in StreamSegmentContainer.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-07-20T18:13:57Z", "type": "commit"}, {"oid": "d768fff1f065330a439bbcb7ea49472e7318cf16", "url": "https://github.com/pravega/pravega/commit/d768fff1f065330a439bbcb7ea49472e7318cf16", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Fix tests.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-07-20T18:13:57Z", "type": "commit"}, {"oid": "e0281e13fb1602d279ac2064282546f02a07482b", "url": "https://github.com/pravega/pravega/commit/e0281e13fb1602d279ac2064282546f02a07482b", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Fix tests.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-07-20T19:02:38Z", "type": "commit"}, {"oid": "e0281e13fb1602d279ac2064282546f02a07482b", "url": "https://github.com/pravega/pravega/commit/e0281e13fb1602d279ac2064282546f02a07482b", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Fix tests.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-07-20T19:02:38Z", "type": "forcePushed"}, {"oid": "9de3f2e55a2bbcda51055f0e3be1e77ffc741106", "url": "https://github.com/pravega/pravega/commit/9de3f2e55a2bbcda51055f0e3be1e77ffc741106", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Rename and clean up.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-07-20T22:43:47Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyNDkyNQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457724925", "bodyText": "Tip: this constructor can be auto-generated if you annotate the class with @RequiredArgsConstructor and each field with @NonNull.", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:22:11Z", "path": "bindings/src/main/java/io/pravega/storage/extendeds3/ExtendedS3SimpleStorageFactory.java", "diffHunk": "@@ -0,0 +1,57 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.storage.extendeds3;\n+\n+import com.emc.object.s3.S3Client;\n+import com.emc.object.s3.S3Config;\n+import com.emc.object.s3.jersey.S3JerseyClient;\n+import com.google.common.base.Preconditions;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.chunklayer.ChunkedSegmentStorage;\n+import io.pravega.segmentstore.storage.chunklayer.ChunkedSegmentStorageConfig;\n+\n+import java.util.concurrent.ExecutorService;\n+\n+/**\n+ * Factory for ExtendedS3 {@link Storage} implemented using {@link ChunkedSegmentStorage} and {@link ExtendedS3ChunkStorage}.\n+ */\n+public class ExtendedS3SimpleStorageFactory implements StorageFactory {\n+    private final ExtendedS3StorageConfig config;\n+    private final ExecutorService executor;\n+\n+    /**\n+     * Creates a new instance of the {@link ExtendedS3SimpleStorageFactory} class.\n+     *\n+     * @param config   The Configuration to use.\n+     * @param executor An executor to use for background operations.\n+     */\n+    public ExtendedS3SimpleStorageFactory(ExtendedS3StorageConfig config, ExecutorService executor) {", "originalCommit": "e0281e13fb1602d279ac2064282546f02a07482b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQxNzE4OQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458417189", "bodyText": "fixed", "author": "sachin-j-joshi", "createdAt": "2020-07-21T22:08:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyNDkyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyNTM3Mg==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457725372", "bodyText": "TIP: You can annotate each field with @NonNull; Lombok will auto-generate the precondition checks.", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:23:26Z", "path": "bindings/src/main/java/io/pravega/storage/extendeds3/ExtendedS3StorageFactoryCreator.java", "diffHunk": "@@ -9,19 +9,43 @@\n  */\n package io.pravega.storage.extendeds3;\n \n+import com.google.common.base.Preconditions;\n import io.pravega.segmentstore.storage.ConfigSetup;\n import io.pravega.segmentstore.storage.StorageFactory;\n import io.pravega.segmentstore.storage.StorageFactoryCreator;\n+import io.pravega.segmentstore.storage.StorageFactoryInfo;\n+import io.pravega.segmentstore.storage.StorageManagerLayoutType;\n+import io.pravega.segmentstore.storage.StorageManagerType;\n+\n import java.util.concurrent.ScheduledExecutorService;\n \n public class ExtendedS3StorageFactoryCreator implements StorageFactoryCreator {\n     @Override\n-    public StorageFactory createFactory(ConfigSetup setup, ScheduledExecutorService executor) {\n-        return new ExtendedS3StorageFactory(setup.getConfig(ExtendedS3StorageConfig::builder), executor);\n+    public StorageFactory createFactory(StorageFactoryInfo storageFactoryInfo, ConfigSetup setup, ScheduledExecutorService executor) {\n+        Preconditions.checkNotNull(storageFactoryInfo, \"storageFactoryInfo\");", "originalCommit": "e0281e13fb1602d279ac2064282546f02a07482b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyNTY4Nw==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457725687", "bodyText": "Same in the other classes.", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:24:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyNTM3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI0MzEwMQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458243101", "bodyText": "Fixed.", "author": "sachin-j-joshi", "createdAt": "2020-07-21T16:48:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyNTM3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDEwNjc0OQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r460106749", "bodyText": "maybe I'm confused, @sachin-j-joshi have you actually done the change suggested?", "author": "RaulGracia", "createdAt": "2020-07-24T14:58:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyNTM3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyNzEzNw==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457727137", "bodyText": "Please put this ( on the previous line.", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:28:15Z", "path": "segmentstore/server/host/src/main/java/io/pravega/segmentstore/server/host/StorageLoader.java", "diffHunk": "@@ -28,18 +31,28 @@\n  */\n @Slf4j\n public class StorageLoader {\n-    public StorageFactory load(ConfigSetup setup, String storageImplementation, ScheduledExecutorService executor) {\n+    public StorageFactory load(ConfigSetup setup,\n+                               String storageImplementation,\n+                               StorageManagerType storageManagerType,\n+                               StorageManagerLayoutType storageManagerLayoutType,\n+                               ScheduledExecutorService executor) {\n         ServiceLoader<StorageFactoryCreator> loader = ServiceLoader.load(StorageFactoryCreator.class);\n         StorageExtraConfig noOpConfig = setup.getConfig(StorageExtraConfig::builder);\n         for (StorageFactoryCreator factoryCreator : loader) {\n-            log.info(\"Loading {}, trying {}\", storageImplementation, factoryCreator.getName());\n-            if (factoryCreator.getName().equals(storageImplementation)) {\n-                StorageFactory factory = factoryCreator.createFactory(setup, executor);\n-                if (!noOpConfig.isStorageNoOpMode()) {\n-                    return factory;\n-                } else { //The specified storage implementation is in No-Op mode.\n-                    log.warn(\"{} IS IN NO-OP MODE: DATA LOSS WILL HAPPEN! MAKE SURE IT IS BY FULL INTENTION FOR TESTING PURPOSE!\", storageImplementation);\n-                    return new NoOpStorageFactory(noOpConfig, executor, factory, null);\n+            val factories = factoryCreator.getStorageFactories();\n+            for (val factoryInfo : factories) {\n+                log.info(\"Loading {}, trying {}\", storageImplementation, factoryInfo);\n+                if (factoryInfo.getName().equals(storageImplementation)\n+                        && factoryInfo.getStorageManagerLayoutType() == storageManagerLayoutType\n+                        && factoryInfo.getStorageManagerType() == storageManagerType\n+                ) {", "originalCommit": "e0281e13fb1602d279ac2064282546f02a07482b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyODQzNw==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457728437", "bodyText": "And what it if it is null? Won't this be checked in the constructor of TableBasedMetadataStore below?", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:31:43Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentContainer.java", "diffHunk": "@@ -177,6 +180,29 @@ private MetadataStore createMetadataStore() {\n         return builder.build();\n     }\n \n+    /**\n+     * Initializes storage.\n+     *\n+     * @throws Exception\n+     */\n+    private void initializeStorage() throws Exception {\n+        this.storage.initialize(this.metadata.getContainerEpoch());\n+\n+        if (this.storage instanceof ChunkedSegmentStorage) {\n+            ChunkedSegmentStorage storageManager = (ChunkedSegmentStorage) this.storage;\n+\n+            // Initialize storage metadata table segment\n+            ContainerTableExtension tableExtension = getExtension(ContainerTableExtension.class);\n+            Preconditions.checkNotNull(tableExtension);", "originalCommit": "e0281e13fb1602d279ac2064282546f02a07482b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI0NzA0Mg==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458247042", "bodyText": "removed.", "author": "sachin-j-joshi", "createdAt": "2020-07-21T16:54:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyODQzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyOTg4Ng==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457729886", "bodyText": "Why don't we add these things to SegmentProperties interface so we don't have to remember to set them everywhere? You can just go back to StreamSegmentInformation and update the from method which should automatically take effect wherever it's used.", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:35:34Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentMetadata.java", "diffHunk": "@@ -353,7 +353,11 @@ public synchronized boolean isActive() {\n \n     @Override\n     public synchronized SegmentProperties getSnapshot() {\n-        return StreamSegmentInformation.from(this).attributes(new HashMap<>(getAttributes())).build();\n+        return StreamSegmentInformation.from(this)", "originalCommit": "e0281e13fb1602d279ac2064282546f02a07482b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODk3ODk0Ng==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458978946", "bodyText": "SegmentProperties is used in Storage interface and lots of other places. Changing the contract on that interface is a much bigger change that I don't want to do as part of this change.", "author": "sachin-j-joshi", "createdAt": "2020-07-22T17:56:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyOTg4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMDQ3Mg==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457730472", "bodyText": "Does this include the one you just removed from here? That's the container metadata segment which has nothing to do with chunks.", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:37:16Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/StreamSegmentContainerTests.java", "diffHunk": "@@ -1881,11 +1881,17 @@ private void checkActiveSegments(SegmentContainer container, int expectedCount)\n         val initialActiveSegments = container.getActiveSegments();\n         int ignoredSegments = 0;\n         for (SegmentProperties sp : initialActiveSegments) {\n-            if (sp.getName().equals(EXPECTED_METADATA_SEGMENT_NAME)) {\n+            boolean match = false;\n+            for (String systemSegment : SystemJournal.getChunkStorageSystemSegments(container.getId())) {", "originalCommit": "e0281e13fb1602d279ac2064282546f02a07482b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzc1MDI1OQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457750259", "bodyText": "initialActiveSegments includes EXPECTED_METADATA_SEGMENT_NAME.\nwhich is NameUtils.getMetadataSegmentName(CONTAINER_ID);", "author": "sachin-j-joshi", "createdAt": "2020-07-20T23:36:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMDQ3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMDYwMA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457730600", "bodyText": "Why?", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:37:39Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentServiceNoOpWriteOnlyTests.java", "diffHunk": "@@ -24,6 +25,7 @@\n  * because user segment write operation is no-oped.\n  */\n @Slf4j\n+@Ignore", "originalCommit": "e0281e13fb1602d279ac2064282546f02a07482b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTA1ODc1OA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r461058758", "bodyText": "NoOp storage does not yet support ChunkedSegmentStorage (aka SLTS)", "author": "sachin-j-joshi", "createdAt": "2020-07-27T17:40:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMDYwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTA1ODkzNg==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r461058936", "bodyText": "Ignoring only relevant tests now", "author": "sachin-j-joshi", "createdAt": "2020-07-27T17:40:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMDYwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMTE1MA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457731150", "bodyText": "private final; I don't think you have any reason to mutate this object.\neverywhere below too.", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:39:13Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/StorageFactoryInfo.java", "diffHunk": "@@ -0,0 +1,36 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage;\n+\n+import io.pravega.segmentstore.storage.chunklayer.ChunkedSegmentStorage;\n+import lombok.Builder;\n+import lombok.Data;\n+\n+/**\n+ * Information about the capabilities supported by a {@link StorageFactory}.\n+ */\n+@Data\n+@Builder\n+public class StorageFactoryInfo {\n+    /**\n+     * Name of storage binding.\n+     */\n+    String name;", "originalCommit": "e0281e13fb1602d279ac2064282546f02a07482b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI0NzMxNg==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458247316", "bodyText": "done", "author": "sachin-j-joshi", "createdAt": "2020-07-21T16:55:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMTE1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMTg4OA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457731888", "bodyText": "Do all of these calls result in LTS or Table Segment calls? You've added quite a bit of now.", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:41:06Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java", "diffHunk": "@@ -597,6 +614,7 @@ private void collectGarbage(Collection<String> chunksTodelete) {\n                 // Validate preconditions.\n                 checkSegmentExists(streamSegmentName, segmentMetadata);\n                 checkOwnership(streamSegmentName, segmentMetadata);\n+                checkChunksExist(txn, segmentMetadata);", "originalCommit": "e0281e13fb1602d279ac2064282546f02a07482b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzc1MDUxNw==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457750517", "bodyText": "I'll probably change it to int debugLevel", "author": "sachin-j-joshi", "createdAt": "2020-07-20T23:37:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMTg4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQxNzU2OQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458417569", "bodyText": "on second thought, I removed these checks - not really needed anymore.", "author": "sachin-j-joshi", "createdAt": "2020-07-21T22:09:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMTg4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMjA0NQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457732045", "bodyText": "This sounds pretty aggressive. 30s?", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:41:34Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.DataLogWriterNotPrimaryException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * {@link TableStore} based storage metadata store.\n+ */\n+@Slf4j\n+public class TableBasedMetadataStore extends BaseMetadataStore {\n+    private final TableStore tableStore;\n+    private final String tableName;\n+    private final Duration timeout = Duration.ofSeconds(1L);", "originalCommit": "e0281e13fb1602d279ac2064282546f02a07482b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI0NzYwMw==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458247603", "bodyText": "ok. done", "author": "sachin-j-joshi", "createdAt": "2020-07-21T16:55:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMjA0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMjYwMQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457732601", "bodyText": "getBytes will encode the string in whatever default charset happens to be on the machine. While nowadays it's UTF8, this doesn't mean it won't change at one point in the future.\nTo make sure our data is compatible between different hosts, let's keep a reference to Charsets.UTF8 and pass that to everywhere we are encoding or decoding String keys in this file.", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:43:09Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.DataLogWriterNotPrimaryException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * {@link TableStore} based storage metadata store.\n+ */\n+@Slf4j\n+public class TableBasedMetadataStore extends BaseMetadataStore {\n+    private final TableStore tableStore;\n+    private final String tableName;\n+    private final Duration timeout = Duration.ofSeconds(1L);\n+    private final AtomicBoolean isTableInitialized = new AtomicBoolean(false);\n+    private final BaseMetadataStore.TransactionData.TransactionDataSerializer serializer = new BaseMetadataStore.TransactionData.TransactionDataSerializer();\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param tableName Name of the table segment.\n+     * @param tableStore Instance of the {@link TableStore}.\n+     */\n+    public TableBasedMetadataStore(String tableName, TableStore tableStore) {\n+        this.tableStore = Preconditions.checkNotNull(tableStore, \"tableStore\");\n+        this.tableName = Preconditions.checkNotNull(tableName, \"tableName\");\n+    }\n+\n+    /**\n+     * Reads a metadata record for the given key.\n+     *\n+     * @param key Key for the metadata record.\n+     * @return Associated {@link io.pravega.segmentstore.storage.metadata.BaseMetadataStore.TransactionData}.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected TransactionData read(String key) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<BufferView> keys = new ArrayList<>();\n+        keys.add(new ByteArraySegment(key.getBytes()));", "originalCommit": "e0281e13fb1602d279ac2064282546f02a07482b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI0NzcwMA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458247700", "bodyText": "done.", "author": "sachin-j-joshi", "createdAt": "2020-07-21T16:55:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMjYwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMjgzMw==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457732833", "bodyText": "So what if it's not 1?", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:43:49Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.DataLogWriterNotPrimaryException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * {@link TableStore} based storage metadata store.\n+ */\n+@Slf4j\n+public class TableBasedMetadataStore extends BaseMetadataStore {\n+    private final TableStore tableStore;\n+    private final String tableName;\n+    private final Duration timeout = Duration.ofSeconds(1L);\n+    private final AtomicBoolean isTableInitialized = new AtomicBoolean(false);\n+    private final BaseMetadataStore.TransactionData.TransactionDataSerializer serializer = new BaseMetadataStore.TransactionData.TransactionDataSerializer();\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param tableName Name of the table segment.\n+     * @param tableStore Instance of the {@link TableStore}.\n+     */\n+    public TableBasedMetadataStore(String tableName, TableStore tableStore) {\n+        this.tableStore = Preconditions.checkNotNull(tableStore, \"tableStore\");\n+        this.tableName = Preconditions.checkNotNull(tableName, \"tableName\");\n+    }\n+\n+    /**\n+     * Reads a metadata record for the given key.\n+     *\n+     * @param key Key for the metadata record.\n+     * @return Associated {@link io.pravega.segmentstore.storage.metadata.BaseMetadataStore.TransactionData}.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected TransactionData read(String key) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<BufferView> keys = new ArrayList<>();\n+        keys.add(new ByteArraySegment(key.getBytes()));\n+        try {\n+            List<TableEntry> retValue = this.tableStore.get(tableName, keys, timeout).get();\n+            if (retValue.size() == 1) {", "originalCommit": "e0281e13fb1602d279ac2064282546f02a07482b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzc1MTQwOQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457751409", "bodyText": "The code falls through and it returns default \"not exists\" value.", "author": "sachin-j-joshi", "createdAt": "2020-07-20T23:40:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMjgzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY1MzE3NQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458653175", "bodyText": "By design, I understand that it should be either 0 or 1, but what if there is a bug in the logic and we get a value greater than 1? Is returning TableKey.NOT_EXISTS? Even if such a case is not expected, I'd say we should validate it.", "author": "fpj", "createdAt": "2020-07-22T09:15:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMjgzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODg4NjUyMQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458886521", "bodyText": "Ok. will add validation.", "author": "sachin-j-joshi", "createdAt": "2020-07-22T15:37:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMjgzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTExMTgzNA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r459111834", "bodyText": "Validation added.", "author": "sachin-j-joshi", "createdAt": "2020-07-22T22:08:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMjgzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU4MTIzOQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r459581239", "bodyText": "The contract clearly says that you will get a List of size equal to the size of the key List you requested, regardless of whether those keys exist or not. You will not get 0 and you will not get 2.\nIf you want, a simple assert retValue.size() == 1 will do (and will execute only in tests), and we can remove all these unnecessary checks.", "author": "andreipaduroiu", "createdAt": "2020-07-23T16:36:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMjgzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDA0OTk5Ng==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r460049996", "bodyText": "Ok, makes sense, the validation is moot in this case then. Thanks for clarifying, @andreipaduroiu .", "author": "fpj", "createdAt": "2020-07-24T13:25:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMjgzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTA1OTcxOQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r461059719", "bodyText": "Fixed.  it looks like this now\n           Preconditions.checkState(retValue.size() == 1, \"Unexpected number of values returned.\");\n           TableEntry entry = retValue.get(0);\n           if (null != entry) {\n             ...", "author": "sachin-j-joshi", "createdAt": "2020-07-27T17:41:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMjgzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMzM5Nw==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457733397", "bodyText": "encoding here\nUse TableKey.Unversioned if you want to specify NO_VERSION", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:45:14Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.DataLogWriterNotPrimaryException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * {@link TableStore} based storage metadata store.\n+ */\n+@Slf4j\n+public class TableBasedMetadataStore extends BaseMetadataStore {\n+    private final TableStore tableStore;\n+    private final String tableName;\n+    private final Duration timeout = Duration.ofSeconds(1L);\n+    private final AtomicBoolean isTableInitialized = new AtomicBoolean(false);\n+    private final BaseMetadataStore.TransactionData.TransactionDataSerializer serializer = new BaseMetadataStore.TransactionData.TransactionDataSerializer();\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param tableName Name of the table segment.\n+     * @param tableStore Instance of the {@link TableStore}.\n+     */\n+    public TableBasedMetadataStore(String tableName, TableStore tableStore) {\n+        this.tableStore = Preconditions.checkNotNull(tableStore, \"tableStore\");\n+        this.tableName = Preconditions.checkNotNull(tableName, \"tableName\");\n+    }\n+\n+    /**\n+     * Reads a metadata record for the given key.\n+     *\n+     * @param key Key for the metadata record.\n+     * @return Associated {@link io.pravega.segmentstore.storage.metadata.BaseMetadataStore.TransactionData}.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected TransactionData read(String key) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<BufferView> keys = new ArrayList<>();\n+        keys.add(new ByteArraySegment(key.getBytes()));\n+        try {\n+            List<TableEntry> retValue = this.tableStore.get(tableName, keys, timeout).get();\n+            if (retValue.size() == 1) {\n+                TableEntry entry = retValue.get(0);\n+                if (null != entry) {\n+                    val arr = entry.getValue();\n+                    TransactionData txnData = serializer.deserialize(arr);\n+                    txnData.setDbObject(entry.getKey().getVersion());\n+                    txnData.setPersisted(true);\n+                    return txnData;\n+                }\n+            }\n+        } catch (IllegalStateException e) {\n+            throw e;\n+        } catch (Exception e) {\n+            throw new StorageMetadataException(\"Error while reading\", e);\n+        }\n+\n+        return TransactionData.builder()\n+                .key(key)\n+                .persisted(true)\n+                .dbObject(TableKey.NOT_EXISTS)\n+                .build();\n+    }\n+\n+    /**\n+     * Writes transaction data from a given list to the metadata store.\n+     *\n+     * @param dataList List of transaction data to write.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected void writeAll(Collection<TransactionData> dataList) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<TableEntry> toUpdate = new ArrayList<>();\n+        HashMap<TableEntry, TransactionData> entryToTxnDataMap = new HashMap<TableEntry, TransactionData>();\n+        HashMap<TableKey, TransactionData> deletedKeyToTxnDataMap = new HashMap<TableKey, TransactionData>();\n+        List<TableKey> keysToDelete = new ArrayList<>();\n+        try {\n+            for (TransactionData txnData : dataList) {\n+                Preconditions.checkState(null != txnData.getDbObject());\n+\n+                long version = ((Long) txnData.getDbObject()).longValue();\n+                if (null == txnData.getValue()) {\n+                    val toDelete = TableKey.versioned(new ByteArraySegment(txnData.getKey().getBytes()),", "originalCommit": "e0281e13fb1602d279ac2064282546f02a07482b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMzY2Ng==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457733666", "bodyText": "Or did you mean to specify a version (you have a version variable)?", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:46:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMzM5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQxODA2MQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458418061", "bodyText": "Fixed", "author": "sachin-j-joshi", "createdAt": "2020-07-21T22:10:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMzM5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMzczMQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457733731", "bodyText": "encoding", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:46:09Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.DataLogWriterNotPrimaryException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * {@link TableStore} based storage metadata store.\n+ */\n+@Slf4j\n+public class TableBasedMetadataStore extends BaseMetadataStore {\n+    private final TableStore tableStore;\n+    private final String tableName;\n+    private final Duration timeout = Duration.ofSeconds(1L);\n+    private final AtomicBoolean isTableInitialized = new AtomicBoolean(false);\n+    private final BaseMetadataStore.TransactionData.TransactionDataSerializer serializer = new BaseMetadataStore.TransactionData.TransactionDataSerializer();\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param tableName Name of the table segment.\n+     * @param tableStore Instance of the {@link TableStore}.\n+     */\n+    public TableBasedMetadataStore(String tableName, TableStore tableStore) {\n+        this.tableStore = Preconditions.checkNotNull(tableStore, \"tableStore\");\n+        this.tableName = Preconditions.checkNotNull(tableName, \"tableName\");\n+    }\n+\n+    /**\n+     * Reads a metadata record for the given key.\n+     *\n+     * @param key Key for the metadata record.\n+     * @return Associated {@link io.pravega.segmentstore.storage.metadata.BaseMetadataStore.TransactionData}.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected TransactionData read(String key) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<BufferView> keys = new ArrayList<>();\n+        keys.add(new ByteArraySegment(key.getBytes()));\n+        try {\n+            List<TableEntry> retValue = this.tableStore.get(tableName, keys, timeout).get();\n+            if (retValue.size() == 1) {\n+                TableEntry entry = retValue.get(0);\n+                if (null != entry) {\n+                    val arr = entry.getValue();\n+                    TransactionData txnData = serializer.deserialize(arr);\n+                    txnData.setDbObject(entry.getKey().getVersion());\n+                    txnData.setPersisted(true);\n+                    return txnData;\n+                }\n+            }\n+        } catch (IllegalStateException e) {\n+            throw e;\n+        } catch (Exception e) {\n+            throw new StorageMetadataException(\"Error while reading\", e);\n+        }\n+\n+        return TransactionData.builder()\n+                .key(key)\n+                .persisted(true)\n+                .dbObject(TableKey.NOT_EXISTS)\n+                .build();\n+    }\n+\n+    /**\n+     * Writes transaction data from a given list to the metadata store.\n+     *\n+     * @param dataList List of transaction data to write.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected void writeAll(Collection<TransactionData> dataList) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<TableEntry> toUpdate = new ArrayList<>();\n+        HashMap<TableEntry, TransactionData> entryToTxnDataMap = new HashMap<TableEntry, TransactionData>();\n+        HashMap<TableKey, TransactionData> deletedKeyToTxnDataMap = new HashMap<TableKey, TransactionData>();\n+        List<TableKey> keysToDelete = new ArrayList<>();\n+        try {\n+            for (TransactionData txnData : dataList) {\n+                Preconditions.checkState(null != txnData.getDbObject());\n+\n+                long version = ((Long) txnData.getDbObject()).longValue();\n+                if (null == txnData.getValue()) {\n+                    val toDelete = TableKey.versioned(new ByteArraySegment(txnData.getKey().getBytes()),\n+                            TableKey.NO_VERSION);\n+                    keysToDelete.add(toDelete);\n+                    deletedKeyToTxnDataMap.put(toDelete, txnData);\n+                }\n+\n+                val arraySegment = serializer.serialize(txnData);\n+\n+                TableEntry tableEntry = TableEntry.versioned(\n+                        new ByteArraySegment(txnData.getKey().getBytes()),", "originalCommit": "e0281e13fb1602d279ac2064282546f02a07482b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNDExNA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457734114", "bodyText": "Do you really need to do this? This will block this thread and use another thread to execute that call. It is a recipe for running out of threads very very quickly.\nPlease rewrite this method to be a CompletableFuture (async) so it doesn't have this problem.", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:47:16Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.DataLogWriterNotPrimaryException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * {@link TableStore} based storage metadata store.\n+ */\n+@Slf4j\n+public class TableBasedMetadataStore extends BaseMetadataStore {\n+    private final TableStore tableStore;\n+    private final String tableName;\n+    private final Duration timeout = Duration.ofSeconds(1L);\n+    private final AtomicBoolean isTableInitialized = new AtomicBoolean(false);\n+    private final BaseMetadataStore.TransactionData.TransactionDataSerializer serializer = new BaseMetadataStore.TransactionData.TransactionDataSerializer();\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param tableName Name of the table segment.\n+     * @param tableStore Instance of the {@link TableStore}.\n+     */\n+    public TableBasedMetadataStore(String tableName, TableStore tableStore) {\n+        this.tableStore = Preconditions.checkNotNull(tableStore, \"tableStore\");\n+        this.tableName = Preconditions.checkNotNull(tableName, \"tableName\");\n+    }\n+\n+    /**\n+     * Reads a metadata record for the given key.\n+     *\n+     * @param key Key for the metadata record.\n+     * @return Associated {@link io.pravega.segmentstore.storage.metadata.BaseMetadataStore.TransactionData}.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected TransactionData read(String key) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<BufferView> keys = new ArrayList<>();\n+        keys.add(new ByteArraySegment(key.getBytes()));\n+        try {\n+            List<TableEntry> retValue = this.tableStore.get(tableName, keys, timeout).get();\n+            if (retValue.size() == 1) {\n+                TableEntry entry = retValue.get(0);\n+                if (null != entry) {\n+                    val arr = entry.getValue();\n+                    TransactionData txnData = serializer.deserialize(arr);\n+                    txnData.setDbObject(entry.getKey().getVersion());\n+                    txnData.setPersisted(true);\n+                    return txnData;\n+                }\n+            }\n+        } catch (IllegalStateException e) {\n+            throw e;\n+        } catch (Exception e) {\n+            throw new StorageMetadataException(\"Error while reading\", e);\n+        }\n+\n+        return TransactionData.builder()\n+                .key(key)\n+                .persisted(true)\n+                .dbObject(TableKey.NOT_EXISTS)\n+                .build();\n+    }\n+\n+    /**\n+     * Writes transaction data from a given list to the metadata store.\n+     *\n+     * @param dataList List of transaction data to write.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected void writeAll(Collection<TransactionData> dataList) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<TableEntry> toUpdate = new ArrayList<>();\n+        HashMap<TableEntry, TransactionData> entryToTxnDataMap = new HashMap<TableEntry, TransactionData>();\n+        HashMap<TableKey, TransactionData> deletedKeyToTxnDataMap = new HashMap<TableKey, TransactionData>();\n+        List<TableKey> keysToDelete = new ArrayList<>();\n+        try {\n+            for (TransactionData txnData : dataList) {\n+                Preconditions.checkState(null != txnData.getDbObject());\n+\n+                long version = ((Long) txnData.getDbObject()).longValue();\n+                if (null == txnData.getValue()) {\n+                    val toDelete = TableKey.versioned(new ByteArraySegment(txnData.getKey().getBytes()),\n+                            TableKey.NO_VERSION);\n+                    keysToDelete.add(toDelete);\n+                    deletedKeyToTxnDataMap.put(toDelete, txnData);\n+                }\n+\n+                val arraySegment = serializer.serialize(txnData);\n+\n+                TableEntry tableEntry = TableEntry.versioned(\n+                        new ByteArraySegment(txnData.getKey().getBytes()),\n+                        arraySegment,\n+                        version);\n+                entryToTxnDataMap.put(tableEntry, txnData);\n+                toUpdate.add(tableEntry);\n+            }\n+\n+            // Now put uploaded keys.\n+            List<Long> ret = this.tableStore.put(tableName, toUpdate, timeout).get();", "originalCommit": "e0281e13fb1602d279ac2064282546f02a07482b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI2MjY3OQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458262679", "bodyText": "Given the initial uncertainty with the approach and added complexity I decided to do inital implementation without async apis. Once things are solid we can very much turn everything into async relatively easily.  The point - the table segment access is already in a synchronized block to maintain consistency guarantees. So that waiting on future is not causing any additional stalls. In near future, I do absolutely plan to remove that big synchronization point and also turn this whole thing in async.", "author": "sachin-j-joshi", "createdAt": "2020-07-21T17:20:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNDExNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI2MjgzMw==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458262833", "bodyText": "I'll create an issue to track this.", "author": "sachin-j-joshi", "createdAt": "2020-07-21T17:20:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNDExNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY2NzQ3Ng==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458667476", "bodyText": "It also seems to be serializing the execution unnecessarily:\n\nput\nupdate versions after put\ndelete\nupdate version after delete\n\nwe can have a higher degree of parallelism here, which should be relevant for larger numbers of items in dataList. any idea of what we expect the size of dataList to be?", "author": "fpj", "createdAt": "2020-07-22T09:40:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNDExNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODg5MDg4MA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458890880", "bodyText": "The updates must succeed atomically. We can not have individual keys updated separately.\nCurrently table segment can not have update and delete as part of same transaction. (you can't add/update a few keys and also delete a few as part of same transaction.)\nThat is the reason why I have to delete the keys separately.\nFirst I update the keys with special \"deleted\" value. Then actually delete it separately.\nThe delete can not succeed if update fails earlier. Therefore it has to wait on update.\nAlso, most updates are with either 1 or 2 keys.\nTruncate , delete and concat affect more keys.", "author": "sachin-j-joshi", "createdAt": "2020-07-22T15:43:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNDExNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDA1NDE3NQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r460054175", "bodyText": "The updates must succeed atomically. We can not have individual keys updated separately.\n\nI was not clear, I was referring to updating and deleting concurrently.\n\nCurrently table segment can not have update and delete as part of same transaction.\n\nOk, but if we make the computation asynchronous, then can't we execute updates and deletes concurrently?", "author": "fpj", "createdAt": "2020-07-24T13:32:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNDExNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDEwNjY1OA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r460106658", "bodyText": "Delete is done in two steps .\n\nUpdate key with value corresponding to null .\nDelete the key\nAll keys in a single transaction are updated simultaneously. Update could fail because of any number of reason - eg. Version mismatch one of the (non-deleted) keys.\n\nIn all cases, the delete should not succeed if update fails earlier. Therefore it has to wait on update.", "author": "sachin-j-joshi", "createdAt": "2020-07-24T14:58:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNDExNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNDIyNw==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457734227", "bodyText": "same here", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:47:34Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.DataLogWriterNotPrimaryException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * {@link TableStore} based storage metadata store.\n+ */\n+@Slf4j\n+public class TableBasedMetadataStore extends BaseMetadataStore {\n+    private final TableStore tableStore;\n+    private final String tableName;\n+    private final Duration timeout = Duration.ofSeconds(1L);\n+    private final AtomicBoolean isTableInitialized = new AtomicBoolean(false);\n+    private final BaseMetadataStore.TransactionData.TransactionDataSerializer serializer = new BaseMetadataStore.TransactionData.TransactionDataSerializer();\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param tableName Name of the table segment.\n+     * @param tableStore Instance of the {@link TableStore}.\n+     */\n+    public TableBasedMetadataStore(String tableName, TableStore tableStore) {\n+        this.tableStore = Preconditions.checkNotNull(tableStore, \"tableStore\");\n+        this.tableName = Preconditions.checkNotNull(tableName, \"tableName\");\n+    }\n+\n+    /**\n+     * Reads a metadata record for the given key.\n+     *\n+     * @param key Key for the metadata record.\n+     * @return Associated {@link io.pravega.segmentstore.storage.metadata.BaseMetadataStore.TransactionData}.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected TransactionData read(String key) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<BufferView> keys = new ArrayList<>();\n+        keys.add(new ByteArraySegment(key.getBytes()));\n+        try {\n+            List<TableEntry> retValue = this.tableStore.get(tableName, keys, timeout).get();\n+            if (retValue.size() == 1) {\n+                TableEntry entry = retValue.get(0);\n+                if (null != entry) {\n+                    val arr = entry.getValue();\n+                    TransactionData txnData = serializer.deserialize(arr);\n+                    txnData.setDbObject(entry.getKey().getVersion());\n+                    txnData.setPersisted(true);\n+                    return txnData;\n+                }\n+            }\n+        } catch (IllegalStateException e) {\n+            throw e;\n+        } catch (Exception e) {\n+            throw new StorageMetadataException(\"Error while reading\", e);\n+        }\n+\n+        return TransactionData.builder()\n+                .key(key)\n+                .persisted(true)\n+                .dbObject(TableKey.NOT_EXISTS)\n+                .build();\n+    }\n+\n+    /**\n+     * Writes transaction data from a given list to the metadata store.\n+     *\n+     * @param dataList List of transaction data to write.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected void writeAll(Collection<TransactionData> dataList) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<TableEntry> toUpdate = new ArrayList<>();\n+        HashMap<TableEntry, TransactionData> entryToTxnDataMap = new HashMap<TableEntry, TransactionData>();\n+        HashMap<TableKey, TransactionData> deletedKeyToTxnDataMap = new HashMap<TableKey, TransactionData>();\n+        List<TableKey> keysToDelete = new ArrayList<>();\n+        try {\n+            for (TransactionData txnData : dataList) {\n+                Preconditions.checkState(null != txnData.getDbObject());\n+\n+                long version = ((Long) txnData.getDbObject()).longValue();\n+                if (null == txnData.getValue()) {\n+                    val toDelete = TableKey.versioned(new ByteArraySegment(txnData.getKey().getBytes()),\n+                            TableKey.NO_VERSION);\n+                    keysToDelete.add(toDelete);\n+                    deletedKeyToTxnDataMap.put(toDelete, txnData);\n+                }\n+\n+                val arraySegment = serializer.serialize(txnData);\n+\n+                TableEntry tableEntry = TableEntry.versioned(\n+                        new ByteArraySegment(txnData.getKey().getBytes()),\n+                        arraySegment,\n+                        version);\n+                entryToTxnDataMap.put(tableEntry, txnData);\n+                toUpdate.add(tableEntry);\n+            }\n+\n+            // Now put uploaded keys.\n+            List<Long> ret = this.tableStore.put(tableName, toUpdate, timeout).get();\n+\n+            // Update versions.\n+            int i = 0;\n+            for (TableEntry tableEntry : toUpdate) {\n+                entryToTxnDataMap.get(tableEntry).setDbObject(ret.get(i));\n+                i++;\n+            }\n+\n+            // Delete deleted keys.\n+            this.tableStore.remove(tableName, keysToDelete, timeout).get();", "originalCommit": "e0281e13fb1602d279ac2064282546f02a07482b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQxODE5MA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458418190", "bodyText": "same as above", "author": "sachin-j-joshi", "createdAt": "2020-07-21T22:10:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNDIyNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNDM2Mg==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457734362", "bodyText": "Aren't these two catch blocks the same?", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:47:58Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.DataLogWriterNotPrimaryException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * {@link TableStore} based storage metadata store.\n+ */\n+@Slf4j\n+public class TableBasedMetadataStore extends BaseMetadataStore {\n+    private final TableStore tableStore;\n+    private final String tableName;\n+    private final Duration timeout = Duration.ofSeconds(1L);\n+    private final AtomicBoolean isTableInitialized = new AtomicBoolean(false);\n+    private final BaseMetadataStore.TransactionData.TransactionDataSerializer serializer = new BaseMetadataStore.TransactionData.TransactionDataSerializer();\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param tableName Name of the table segment.\n+     * @param tableStore Instance of the {@link TableStore}.\n+     */\n+    public TableBasedMetadataStore(String tableName, TableStore tableStore) {\n+        this.tableStore = Preconditions.checkNotNull(tableStore, \"tableStore\");\n+        this.tableName = Preconditions.checkNotNull(tableName, \"tableName\");\n+    }\n+\n+    /**\n+     * Reads a metadata record for the given key.\n+     *\n+     * @param key Key for the metadata record.\n+     * @return Associated {@link io.pravega.segmentstore.storage.metadata.BaseMetadataStore.TransactionData}.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected TransactionData read(String key) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<BufferView> keys = new ArrayList<>();\n+        keys.add(new ByteArraySegment(key.getBytes()));\n+        try {\n+            List<TableEntry> retValue = this.tableStore.get(tableName, keys, timeout).get();\n+            if (retValue.size() == 1) {\n+                TableEntry entry = retValue.get(0);\n+                if (null != entry) {\n+                    val arr = entry.getValue();\n+                    TransactionData txnData = serializer.deserialize(arr);\n+                    txnData.setDbObject(entry.getKey().getVersion());\n+                    txnData.setPersisted(true);\n+                    return txnData;\n+                }\n+            }\n+        } catch (IllegalStateException e) {\n+            throw e;\n+        } catch (Exception e) {\n+            throw new StorageMetadataException(\"Error while reading\", e);\n+        }\n+\n+        return TransactionData.builder()\n+                .key(key)\n+                .persisted(true)\n+                .dbObject(TableKey.NOT_EXISTS)\n+                .build();\n+    }\n+\n+    /**\n+     * Writes transaction data from a given list to the metadata store.\n+     *\n+     * @param dataList List of transaction data to write.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected void writeAll(Collection<TransactionData> dataList) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<TableEntry> toUpdate = new ArrayList<>();\n+        HashMap<TableEntry, TransactionData> entryToTxnDataMap = new HashMap<TableEntry, TransactionData>();\n+        HashMap<TableKey, TransactionData> deletedKeyToTxnDataMap = new HashMap<TableKey, TransactionData>();\n+        List<TableKey> keysToDelete = new ArrayList<>();\n+        try {\n+            for (TransactionData txnData : dataList) {\n+                Preconditions.checkState(null != txnData.getDbObject());\n+\n+                long version = ((Long) txnData.getDbObject()).longValue();\n+                if (null == txnData.getValue()) {\n+                    val toDelete = TableKey.versioned(new ByteArraySegment(txnData.getKey().getBytes()),\n+                            TableKey.NO_VERSION);\n+                    keysToDelete.add(toDelete);\n+                    deletedKeyToTxnDataMap.put(toDelete, txnData);\n+                }\n+\n+                val arraySegment = serializer.serialize(txnData);\n+\n+                TableEntry tableEntry = TableEntry.versioned(\n+                        new ByteArraySegment(txnData.getKey().getBytes()),\n+                        arraySegment,\n+                        version);\n+                entryToTxnDataMap.put(tableEntry, txnData);\n+                toUpdate.add(tableEntry);\n+            }\n+\n+            // Now put uploaded keys.\n+            List<Long> ret = this.tableStore.put(tableName, toUpdate, timeout).get();\n+\n+            // Update versions.\n+            int i = 0;\n+            for (TableEntry tableEntry : toUpdate) {\n+                entryToTxnDataMap.get(tableEntry).setDbObject(ret.get(i));\n+                i++;\n+            }\n+\n+            // Delete deleted keys.\n+            this.tableStore.remove(tableName, keysToDelete, timeout).get();\n+            for (val deletedKey : keysToDelete) {\n+                deletedKeyToTxnDataMap.get(deletedKey).setDbObject(TableKey.NOT_EXISTS);\n+            }\n+        } catch (RuntimeException e) {\n+            throw e; // To make spotbugs happy.\n+        } catch (java.util.concurrent.ExecutionException e) {", "originalCommit": "e0281e13fb1602d279ac2064282546f02a07482b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNDQ3NQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457734475", "bodyText": "You can use Exceptions.unwrap to help here.", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:48:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNDM2Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI0NzkyOA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458247928", "bodyText": "done", "author": "sachin-j-joshi", "createdAt": "2020-07-21T16:56:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNDM2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNDYyNQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457734625", "bodyText": "I think this should be a WARN.", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:48:36Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.DataLogWriterNotPrimaryException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * {@link TableStore} based storage metadata store.\n+ */\n+@Slf4j\n+public class TableBasedMetadataStore extends BaseMetadataStore {\n+    private final TableStore tableStore;\n+    private final String tableName;\n+    private final Duration timeout = Duration.ofSeconds(1L);\n+    private final AtomicBoolean isTableInitialized = new AtomicBoolean(false);\n+    private final BaseMetadataStore.TransactionData.TransactionDataSerializer serializer = new BaseMetadataStore.TransactionData.TransactionDataSerializer();\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param tableName Name of the table segment.\n+     * @param tableStore Instance of the {@link TableStore}.\n+     */\n+    public TableBasedMetadataStore(String tableName, TableStore tableStore) {\n+        this.tableStore = Preconditions.checkNotNull(tableStore, \"tableStore\");\n+        this.tableName = Preconditions.checkNotNull(tableName, \"tableName\");\n+    }\n+\n+    /**\n+     * Reads a metadata record for the given key.\n+     *\n+     * @param key Key for the metadata record.\n+     * @return Associated {@link io.pravega.segmentstore.storage.metadata.BaseMetadataStore.TransactionData}.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected TransactionData read(String key) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<BufferView> keys = new ArrayList<>();\n+        keys.add(new ByteArraySegment(key.getBytes()));\n+        try {\n+            List<TableEntry> retValue = this.tableStore.get(tableName, keys, timeout).get();\n+            if (retValue.size() == 1) {\n+                TableEntry entry = retValue.get(0);\n+                if (null != entry) {\n+                    val arr = entry.getValue();\n+                    TransactionData txnData = serializer.deserialize(arr);\n+                    txnData.setDbObject(entry.getKey().getVersion());\n+                    txnData.setPersisted(true);\n+                    return txnData;\n+                }\n+            }\n+        } catch (IllegalStateException e) {\n+            throw e;\n+        } catch (Exception e) {\n+            throw new StorageMetadataException(\"Error while reading\", e);\n+        }\n+\n+        return TransactionData.builder()\n+                .key(key)\n+                .persisted(true)\n+                .dbObject(TableKey.NOT_EXISTS)\n+                .build();\n+    }\n+\n+    /**\n+     * Writes transaction data from a given list to the metadata store.\n+     *\n+     * @param dataList List of transaction data to write.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected void writeAll(Collection<TransactionData> dataList) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<TableEntry> toUpdate = new ArrayList<>();\n+        HashMap<TableEntry, TransactionData> entryToTxnDataMap = new HashMap<TableEntry, TransactionData>();\n+        HashMap<TableKey, TransactionData> deletedKeyToTxnDataMap = new HashMap<TableKey, TransactionData>();\n+        List<TableKey> keysToDelete = new ArrayList<>();\n+        try {\n+            for (TransactionData txnData : dataList) {\n+                Preconditions.checkState(null != txnData.getDbObject());\n+\n+                long version = ((Long) txnData.getDbObject()).longValue();\n+                if (null == txnData.getValue()) {\n+                    val toDelete = TableKey.versioned(new ByteArraySegment(txnData.getKey().getBytes()),\n+                            TableKey.NO_VERSION);\n+                    keysToDelete.add(toDelete);\n+                    deletedKeyToTxnDataMap.put(toDelete, txnData);\n+                }\n+\n+                val arraySegment = serializer.serialize(txnData);\n+\n+                TableEntry tableEntry = TableEntry.versioned(\n+                        new ByteArraySegment(txnData.getKey().getBytes()),\n+                        arraySegment,\n+                        version);\n+                entryToTxnDataMap.put(tableEntry, txnData);\n+                toUpdate.add(tableEntry);\n+            }\n+\n+            // Now put uploaded keys.\n+            List<Long> ret = this.tableStore.put(tableName, toUpdate, timeout).get();\n+\n+            // Update versions.\n+            int i = 0;\n+            for (TableEntry tableEntry : toUpdate) {\n+                entryToTxnDataMap.get(tableEntry).setDbObject(ret.get(i));\n+                i++;\n+            }\n+\n+            // Delete deleted keys.\n+            this.tableStore.remove(tableName, keysToDelete, timeout).get();\n+            for (val deletedKey : keysToDelete) {\n+                deletedKeyToTxnDataMap.get(deletedKey).setDbObject(TableKey.NOT_EXISTS);\n+            }\n+        } catch (RuntimeException e) {\n+            throw e; // To make spotbugs happy.\n+        } catch (java.util.concurrent.ExecutionException e) {\n+            handleException(e.getCause());\n+            return;\n+        } catch (Exception e) {\n+            handleException(e);\n+            return;\n+        }\n+\n+    }\n+\n+    private void handleException(Throwable e) throws StorageMetadataException {\n+        if (e instanceof DataLogWriterNotPrimaryException) {\n+            throw new StorageMetadataWritesFencedOutException(\"Transaction failed. Writer fenced off\", e);\n+        }\n+        if (e instanceof BadKeyVersionException) {\n+            throw new StorageMetadataVersionMismatchException(\"Transaction failed. Version Mismatch.\", e);\n+        }\n+        if (e.getCause() != null) {\n+            if (e.getCause().getCause() instanceof BadKeyVersionException) {\n+                throw new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\", e);\n+            }\n+            if (e.getCause().getCause() instanceof DataLogWriterNotPrimaryException) {\n+                throw new StorageMetadataVersionMismatchException(\"Transaction failed. Writer fenced off\", e);\n+            }\n+        } else {\n+            log.debug(\"e.getCause()=null\", e);", "originalCommit": "e0281e13fb1602d279ac2064282546f02a07482b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQxODI4MA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458418280", "bodyText": "fixed.", "author": "sachin-j-joshi", "createdAt": "2020-07-21T22:10:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNDYyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNDgyMA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457734820", "bodyText": "set e=Exceptions.unwrap(e) and simplify this code.", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:49:04Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.DataLogWriterNotPrimaryException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * {@link TableStore} based storage metadata store.\n+ */\n+@Slf4j\n+public class TableBasedMetadataStore extends BaseMetadataStore {\n+    private final TableStore tableStore;\n+    private final String tableName;\n+    private final Duration timeout = Duration.ofSeconds(1L);\n+    private final AtomicBoolean isTableInitialized = new AtomicBoolean(false);\n+    private final BaseMetadataStore.TransactionData.TransactionDataSerializer serializer = new BaseMetadataStore.TransactionData.TransactionDataSerializer();\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param tableName Name of the table segment.\n+     * @param tableStore Instance of the {@link TableStore}.\n+     */\n+    public TableBasedMetadataStore(String tableName, TableStore tableStore) {\n+        this.tableStore = Preconditions.checkNotNull(tableStore, \"tableStore\");\n+        this.tableName = Preconditions.checkNotNull(tableName, \"tableName\");\n+    }\n+\n+    /**\n+     * Reads a metadata record for the given key.\n+     *\n+     * @param key Key for the metadata record.\n+     * @return Associated {@link io.pravega.segmentstore.storage.metadata.BaseMetadataStore.TransactionData}.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected TransactionData read(String key) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<BufferView> keys = new ArrayList<>();\n+        keys.add(new ByteArraySegment(key.getBytes()));\n+        try {\n+            List<TableEntry> retValue = this.tableStore.get(tableName, keys, timeout).get();\n+            if (retValue.size() == 1) {\n+                TableEntry entry = retValue.get(0);\n+                if (null != entry) {\n+                    val arr = entry.getValue();\n+                    TransactionData txnData = serializer.deserialize(arr);\n+                    txnData.setDbObject(entry.getKey().getVersion());\n+                    txnData.setPersisted(true);\n+                    return txnData;\n+                }\n+            }\n+        } catch (IllegalStateException e) {\n+            throw e;\n+        } catch (Exception e) {\n+            throw new StorageMetadataException(\"Error while reading\", e);\n+        }\n+\n+        return TransactionData.builder()\n+                .key(key)\n+                .persisted(true)\n+                .dbObject(TableKey.NOT_EXISTS)\n+                .build();\n+    }\n+\n+    /**\n+     * Writes transaction data from a given list to the metadata store.\n+     *\n+     * @param dataList List of transaction data to write.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected void writeAll(Collection<TransactionData> dataList) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<TableEntry> toUpdate = new ArrayList<>();\n+        HashMap<TableEntry, TransactionData> entryToTxnDataMap = new HashMap<TableEntry, TransactionData>();\n+        HashMap<TableKey, TransactionData> deletedKeyToTxnDataMap = new HashMap<TableKey, TransactionData>();\n+        List<TableKey> keysToDelete = new ArrayList<>();\n+        try {\n+            for (TransactionData txnData : dataList) {\n+                Preconditions.checkState(null != txnData.getDbObject());\n+\n+                long version = ((Long) txnData.getDbObject()).longValue();\n+                if (null == txnData.getValue()) {\n+                    val toDelete = TableKey.versioned(new ByteArraySegment(txnData.getKey().getBytes()),\n+                            TableKey.NO_VERSION);\n+                    keysToDelete.add(toDelete);\n+                    deletedKeyToTxnDataMap.put(toDelete, txnData);\n+                }\n+\n+                val arraySegment = serializer.serialize(txnData);\n+\n+                TableEntry tableEntry = TableEntry.versioned(\n+                        new ByteArraySegment(txnData.getKey().getBytes()),\n+                        arraySegment,\n+                        version);\n+                entryToTxnDataMap.put(tableEntry, txnData);\n+                toUpdate.add(tableEntry);\n+            }\n+\n+            // Now put uploaded keys.\n+            List<Long> ret = this.tableStore.put(tableName, toUpdate, timeout).get();\n+\n+            // Update versions.\n+            int i = 0;\n+            for (TableEntry tableEntry : toUpdate) {\n+                entryToTxnDataMap.get(tableEntry).setDbObject(ret.get(i));\n+                i++;\n+            }\n+\n+            // Delete deleted keys.\n+            this.tableStore.remove(tableName, keysToDelete, timeout).get();\n+            for (val deletedKey : keysToDelete) {\n+                deletedKeyToTxnDataMap.get(deletedKey).setDbObject(TableKey.NOT_EXISTS);\n+            }\n+        } catch (RuntimeException e) {\n+            throw e; // To make spotbugs happy.\n+        } catch (java.util.concurrent.ExecutionException e) {\n+            handleException(e.getCause());\n+            return;\n+        } catch (Exception e) {\n+            handleException(e);\n+            return;\n+        }\n+\n+    }\n+\n+    private void handleException(Throwable e) throws StorageMetadataException {\n+        if (e instanceof DataLogWriterNotPrimaryException) {", "originalCommit": "e0281e13fb1602d279ac2064282546f02a07482b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI0NTI2MA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458245260", "bodyText": "Good tip. Thanks.\nDone", "author": "sachin-j-joshi", "createdAt": "2020-07-21T16:52:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNDgyMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNTA2MA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457735060", "bodyText": "Same comment here about making this be async.\nFurthermore, you use join here and above you use get.", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:49:42Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.DataLogWriterNotPrimaryException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * {@link TableStore} based storage metadata store.\n+ */\n+@Slf4j\n+public class TableBasedMetadataStore extends BaseMetadataStore {\n+    private final TableStore tableStore;\n+    private final String tableName;\n+    private final Duration timeout = Duration.ofSeconds(1L);\n+    private final AtomicBoolean isTableInitialized = new AtomicBoolean(false);\n+    private final BaseMetadataStore.TransactionData.TransactionDataSerializer serializer = new BaseMetadataStore.TransactionData.TransactionDataSerializer();\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param tableName Name of the table segment.\n+     * @param tableStore Instance of the {@link TableStore}.\n+     */\n+    public TableBasedMetadataStore(String tableName, TableStore tableStore) {\n+        this.tableStore = Preconditions.checkNotNull(tableStore, \"tableStore\");\n+        this.tableName = Preconditions.checkNotNull(tableName, \"tableName\");\n+    }\n+\n+    /**\n+     * Reads a metadata record for the given key.\n+     *\n+     * @param key Key for the metadata record.\n+     * @return Associated {@link io.pravega.segmentstore.storage.metadata.BaseMetadataStore.TransactionData}.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected TransactionData read(String key) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<BufferView> keys = new ArrayList<>();\n+        keys.add(new ByteArraySegment(key.getBytes()));\n+        try {\n+            List<TableEntry> retValue = this.tableStore.get(tableName, keys, timeout).get();\n+            if (retValue.size() == 1) {\n+                TableEntry entry = retValue.get(0);\n+                if (null != entry) {\n+                    val arr = entry.getValue();\n+                    TransactionData txnData = serializer.deserialize(arr);\n+                    txnData.setDbObject(entry.getKey().getVersion());\n+                    txnData.setPersisted(true);\n+                    return txnData;\n+                }\n+            }\n+        } catch (IllegalStateException e) {\n+            throw e;\n+        } catch (Exception e) {\n+            throw new StorageMetadataException(\"Error while reading\", e);\n+        }\n+\n+        return TransactionData.builder()\n+                .key(key)\n+                .persisted(true)\n+                .dbObject(TableKey.NOT_EXISTS)\n+                .build();\n+    }\n+\n+    /**\n+     * Writes transaction data from a given list to the metadata store.\n+     *\n+     * @param dataList List of transaction data to write.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected void writeAll(Collection<TransactionData> dataList) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<TableEntry> toUpdate = new ArrayList<>();\n+        HashMap<TableEntry, TransactionData> entryToTxnDataMap = new HashMap<TableEntry, TransactionData>();\n+        HashMap<TableKey, TransactionData> deletedKeyToTxnDataMap = new HashMap<TableKey, TransactionData>();\n+        List<TableKey> keysToDelete = new ArrayList<>();\n+        try {\n+            for (TransactionData txnData : dataList) {\n+                Preconditions.checkState(null != txnData.getDbObject());\n+\n+                long version = ((Long) txnData.getDbObject()).longValue();\n+                if (null == txnData.getValue()) {\n+                    val toDelete = TableKey.versioned(new ByteArraySegment(txnData.getKey().getBytes()),\n+                            TableKey.NO_VERSION);\n+                    keysToDelete.add(toDelete);\n+                    deletedKeyToTxnDataMap.put(toDelete, txnData);\n+                }\n+\n+                val arraySegment = serializer.serialize(txnData);\n+\n+                TableEntry tableEntry = TableEntry.versioned(\n+                        new ByteArraySegment(txnData.getKey().getBytes()),\n+                        arraySegment,\n+                        version);\n+                entryToTxnDataMap.put(tableEntry, txnData);\n+                toUpdate.add(tableEntry);\n+            }\n+\n+            // Now put uploaded keys.\n+            List<Long> ret = this.tableStore.put(tableName, toUpdate, timeout).get();\n+\n+            // Update versions.\n+            int i = 0;\n+            for (TableEntry tableEntry : toUpdate) {\n+                entryToTxnDataMap.get(tableEntry).setDbObject(ret.get(i));\n+                i++;\n+            }\n+\n+            // Delete deleted keys.\n+            this.tableStore.remove(tableName, keysToDelete, timeout).get();\n+            for (val deletedKey : keysToDelete) {\n+                deletedKeyToTxnDataMap.get(deletedKey).setDbObject(TableKey.NOT_EXISTS);\n+            }\n+        } catch (RuntimeException e) {\n+            throw e; // To make spotbugs happy.\n+        } catch (java.util.concurrent.ExecutionException e) {\n+            handleException(e.getCause());\n+            return;\n+        } catch (Exception e) {\n+            handleException(e);\n+            return;\n+        }\n+\n+    }\n+\n+    private void handleException(Throwable e) throws StorageMetadataException {\n+        if (e instanceof DataLogWriterNotPrimaryException) {\n+            throw new StorageMetadataWritesFencedOutException(\"Transaction failed. Writer fenced off\", e);\n+        }\n+        if (e instanceof BadKeyVersionException) {\n+            throw new StorageMetadataVersionMismatchException(\"Transaction failed. Version Mismatch.\", e);\n+        }\n+        if (e.getCause() != null) {\n+            if (e.getCause().getCause() instanceof BadKeyVersionException) {\n+                throw new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\", e);\n+            }\n+            if (e.getCause().getCause() instanceof DataLogWriterNotPrimaryException) {\n+                throw new StorageMetadataVersionMismatchException(\"Transaction failed. Writer fenced off\", e);\n+            }\n+        } else {\n+            log.debug(\"e.getCause()=null\", e);\n+        }\n+        throw new StorageMetadataException(\"Transaction failed\", e);\n+    }\n+\n+    private void ensureInitialized() {\n+        if (!isTableInitialized.get()) {\n+            try {\n+                this.tableStore.createSegment(tableName, timeout).join();", "originalCommit": "e0281e13fb1602d279ac2064282546f02a07482b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQxODM5Mw==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458418393", "bodyText": "same as above.", "author": "sachin-j-joshi", "createdAt": "2020-07-21T22:11:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNTA2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNTE1Ng==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457735156", "bodyText": "Exceptions.unwrap", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:49:55Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.DataLogWriterNotPrimaryException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * {@link TableStore} based storage metadata store.\n+ */\n+@Slf4j\n+public class TableBasedMetadataStore extends BaseMetadataStore {\n+    private final TableStore tableStore;\n+    private final String tableName;\n+    private final Duration timeout = Duration.ofSeconds(1L);\n+    private final AtomicBoolean isTableInitialized = new AtomicBoolean(false);\n+    private final BaseMetadataStore.TransactionData.TransactionDataSerializer serializer = new BaseMetadataStore.TransactionData.TransactionDataSerializer();\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param tableName Name of the table segment.\n+     * @param tableStore Instance of the {@link TableStore}.\n+     */\n+    public TableBasedMetadataStore(String tableName, TableStore tableStore) {\n+        this.tableStore = Preconditions.checkNotNull(tableStore, \"tableStore\");\n+        this.tableName = Preconditions.checkNotNull(tableName, \"tableName\");\n+    }\n+\n+    /**\n+     * Reads a metadata record for the given key.\n+     *\n+     * @param key Key for the metadata record.\n+     * @return Associated {@link io.pravega.segmentstore.storage.metadata.BaseMetadataStore.TransactionData}.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected TransactionData read(String key) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<BufferView> keys = new ArrayList<>();\n+        keys.add(new ByteArraySegment(key.getBytes()));\n+        try {\n+            List<TableEntry> retValue = this.tableStore.get(tableName, keys, timeout).get();\n+            if (retValue.size() == 1) {\n+                TableEntry entry = retValue.get(0);\n+                if (null != entry) {\n+                    val arr = entry.getValue();\n+                    TransactionData txnData = serializer.deserialize(arr);\n+                    txnData.setDbObject(entry.getKey().getVersion());\n+                    txnData.setPersisted(true);\n+                    return txnData;\n+                }\n+            }\n+        } catch (IllegalStateException e) {\n+            throw e;\n+        } catch (Exception e) {\n+            throw new StorageMetadataException(\"Error while reading\", e);\n+        }\n+\n+        return TransactionData.builder()\n+                .key(key)\n+                .persisted(true)\n+                .dbObject(TableKey.NOT_EXISTS)\n+                .build();\n+    }\n+\n+    /**\n+     * Writes transaction data from a given list to the metadata store.\n+     *\n+     * @param dataList List of transaction data to write.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected void writeAll(Collection<TransactionData> dataList) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<TableEntry> toUpdate = new ArrayList<>();\n+        HashMap<TableEntry, TransactionData> entryToTxnDataMap = new HashMap<TableEntry, TransactionData>();\n+        HashMap<TableKey, TransactionData> deletedKeyToTxnDataMap = new HashMap<TableKey, TransactionData>();\n+        List<TableKey> keysToDelete = new ArrayList<>();\n+        try {\n+            for (TransactionData txnData : dataList) {\n+                Preconditions.checkState(null != txnData.getDbObject());\n+\n+                long version = ((Long) txnData.getDbObject()).longValue();\n+                if (null == txnData.getValue()) {\n+                    val toDelete = TableKey.versioned(new ByteArraySegment(txnData.getKey().getBytes()),\n+                            TableKey.NO_VERSION);\n+                    keysToDelete.add(toDelete);\n+                    deletedKeyToTxnDataMap.put(toDelete, txnData);\n+                }\n+\n+                val arraySegment = serializer.serialize(txnData);\n+\n+                TableEntry tableEntry = TableEntry.versioned(\n+                        new ByteArraySegment(txnData.getKey().getBytes()),\n+                        arraySegment,\n+                        version);\n+                entryToTxnDataMap.put(tableEntry, txnData);\n+                toUpdate.add(tableEntry);\n+            }\n+\n+            // Now put uploaded keys.\n+            List<Long> ret = this.tableStore.put(tableName, toUpdate, timeout).get();\n+\n+            // Update versions.\n+            int i = 0;\n+            for (TableEntry tableEntry : toUpdate) {\n+                entryToTxnDataMap.get(tableEntry).setDbObject(ret.get(i));\n+                i++;\n+            }\n+\n+            // Delete deleted keys.\n+            this.tableStore.remove(tableName, keysToDelete, timeout).get();\n+            for (val deletedKey : keysToDelete) {\n+                deletedKeyToTxnDataMap.get(deletedKey).setDbObject(TableKey.NOT_EXISTS);\n+            }\n+        } catch (RuntimeException e) {\n+            throw e; // To make spotbugs happy.\n+        } catch (java.util.concurrent.ExecutionException e) {\n+            handleException(e.getCause());\n+            return;\n+        } catch (Exception e) {\n+            handleException(e);\n+            return;\n+        }\n+\n+    }\n+\n+    private void handleException(Throwable e) throws StorageMetadataException {\n+        if (e instanceof DataLogWriterNotPrimaryException) {\n+            throw new StorageMetadataWritesFencedOutException(\"Transaction failed. Writer fenced off\", e);\n+        }\n+        if (e instanceof BadKeyVersionException) {\n+            throw new StorageMetadataVersionMismatchException(\"Transaction failed. Version Mismatch.\", e);\n+        }\n+        if (e.getCause() != null) {\n+            if (e.getCause().getCause() instanceof BadKeyVersionException) {\n+                throw new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\", e);\n+            }\n+            if (e.getCause().getCause() instanceof DataLogWriterNotPrimaryException) {\n+                throw new StorageMetadataVersionMismatchException(\"Transaction failed. Writer fenced off\", e);\n+            }\n+        } else {\n+            log.debug(\"e.getCause()=null\", e);\n+        }\n+        throw new StorageMetadataException(\"Transaction failed\", e);\n+    }\n+\n+    private void ensureInitialized() {\n+        if (!isTableInitialized.get()) {\n+            try {\n+                this.tableStore.createSegment(tableName, timeout).join();\n+                log.info(\"Created table segment {}\", tableName);\n+            } catch (CompletionException e) {\n+                if (e.getCause() instanceof StreamSegmentExistsException) {", "originalCommit": "e0281e13fb1602d279ac2064282546f02a07482b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI0NTQzMA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458245430", "bodyText": "done", "author": "sachin-j-joshi", "createdAt": "2020-07-21T16:52:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNTE1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNTMzOA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457735338", "bodyText": "?", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:50:17Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/mocks/InMemorySimpleStorageFactory.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.mocks;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.chunklayer.ChunkedSegmentStorage;\n+import io.pravega.segmentstore.storage.chunklayer.ChunkedSegmentStorageConfig;\n+import io.pravega.segmentstore.storage.chunklayer.ChunkStorage;\n+\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.ScheduledExecutorService;\n+\n+/**\n+ * In-Memory mock for StorageFactory. Contents is destroyed when object is garbage collected.\n+ */\n+public class InMemorySimpleStorageFactory implements StorageFactory, AutoCloseable {\n+    @VisibleForTesting\n+    protected ScheduledExecutorService executor;\n+\n+    private Storage singletonStorage;\n+    private ChunkStorage singletonChunkStorage;\n+    private boolean reuseStorage;\n+\n+    public InMemorySimpleStorageFactory(ScheduledExecutorService executor) {\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n+    }\n+\n+    public InMemorySimpleStorageFactory() {\n+    }\n+\n+    public InMemorySimpleStorageFactory(ScheduledExecutorService executor, boolean reuseStorage) {\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n+        this.reuseStorage = reuseStorage;\n+    }\n+\n+    public InMemorySimpleStorageFactory(ScheduledExecutorService executor, Storage storage) {\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n+        this.singletonStorage = Preconditions.checkNotNull(storage, \"Storage\");\n+        this.reuseStorage = true;\n+    }\n+\n+    public InMemorySimpleStorageFactory(ScheduledExecutorService executor, ChunkStorage chunkStorage) {\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n+        this.singletonChunkStorage = Preconditions.checkNotNull(chunkStorage, \"chunkStorage\");\n+        this.reuseStorage = false;\n+    }\n+\n+    @Override\n+    public Storage createStorageAdapter() {\n+        synchronized (this) {\n+            if (reuseStorage) {\n+                if (null != singletonStorage) {\n+                    return singletonStorage;\n+                }\n+                singletonStorage = getStorage();\n+                return singletonStorage;\n+            }\n+            return getStorage();\n+        }\n+    }\n+\n+    private Storage getStorage() {\n+        if (null == singletonChunkStorage) {\n+            return newStorage(executor);\n+        } else {\n+            return newStorage(executor, singletonChunkStorage);\n+        }\n+    }\n+\n+    @Override\n+    public void close() {\n+        // ?", "originalCommit": "e0281e13fb1602d279ac2064282546f02a07482b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI0ODIzNA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458248234", "bodyText": ":) removed.", "author": "sachin-j-joshi", "createdAt": "2020-07-21T16:56:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNTMzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNTUwNw==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457735507", "bodyText": "Delete this commented out code", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:50:42Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/mocks/InMemorySimpleStorageFactory.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.mocks;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.chunklayer.ChunkedSegmentStorage;\n+import io.pravega.segmentstore.storage.chunklayer.ChunkedSegmentStorageConfig;\n+import io.pravega.segmentstore.storage.chunklayer.ChunkStorage;\n+\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.ScheduledExecutorService;\n+\n+/**\n+ * In-Memory mock for StorageFactory. Contents is destroyed when object is garbage collected.\n+ */\n+public class InMemorySimpleStorageFactory implements StorageFactory, AutoCloseable {\n+    @VisibleForTesting\n+    protected ScheduledExecutorService executor;\n+\n+    private Storage singletonStorage;\n+    private ChunkStorage singletonChunkStorage;\n+    private boolean reuseStorage;\n+\n+    public InMemorySimpleStorageFactory(ScheduledExecutorService executor) {\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n+    }\n+\n+    public InMemorySimpleStorageFactory() {\n+    }\n+\n+    public InMemorySimpleStorageFactory(ScheduledExecutorService executor, boolean reuseStorage) {\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n+        this.reuseStorage = reuseStorage;\n+    }\n+\n+    public InMemorySimpleStorageFactory(ScheduledExecutorService executor, Storage storage) {\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n+        this.singletonStorage = Preconditions.checkNotNull(storage, \"Storage\");\n+        this.reuseStorage = true;\n+    }\n+\n+    public InMemorySimpleStorageFactory(ScheduledExecutorService executor, ChunkStorage chunkStorage) {\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n+        this.singletonChunkStorage = Preconditions.checkNotNull(chunkStorage, \"chunkStorage\");\n+        this.reuseStorage = false;\n+    }\n+\n+    @Override\n+    public Storage createStorageAdapter() {\n+        synchronized (this) {\n+            if (reuseStorage) {\n+                if (null != singletonStorage) {\n+                    return singletonStorage;\n+                }\n+                singletonStorage = getStorage();\n+                return singletonStorage;\n+            }\n+            return getStorage();\n+        }\n+    }\n+\n+    private Storage getStorage() {\n+        if (null == singletonChunkStorage) {\n+            return newStorage(executor);\n+        } else {\n+            return newStorage(executor, singletonChunkStorage);\n+        }\n+    }\n+\n+    @Override\n+    public void close() {\n+        // ?\n+    }\n+\n+    /**\n+     * Creates a new InMemory Storage, without a rolling wrapper.\n+     *\n+     * @param executor An Executor to use for async operations.\n+     * @return A new InMemoryStorage.\n+     */\n+    @VisibleForTesting\n+    public static Storage newStorage(Executor executor) {\n+        return newStorage(executor, new InMemoryChunkStorage());\n+    }\n+\n+    /**\n+     * Creates a new InMemory Storage, without a rolling wrapper.\n+     *\n+     * @param executor     An Executor to use for async operations.\n+     * @param chunkStorage ChunkStorage to use.\n+     * @return A new InMemoryStorage.\n+     */\n+    @VisibleForTesting\n+    public static Storage newStorage(Executor executor, ChunkStorage chunkStorage) {\n+        //TableStore tableStore = new InMemoryTableStore(executor);", "originalCommit": "e0281e13fb1602d279ac2064282546f02a07482b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNjMzMg==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457736332", "bodyText": "What is wrong with TableStoreMock that already exists?", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:52:48Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/mocks/InMemoryTableStore.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.mocks;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.KeyNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import lombok.NonNull;\n+import lombok.RequiredArgsConstructor;\n+import lombok.SneakyThrows;\n+import lombok.val;\n+\n+import javax.annotation.concurrent.GuardedBy;\n+import javax.annotation.concurrent.ThreadSafe;\n+import java.time.Duration;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+@RequiredArgsConstructor\n+@ThreadSafe\n+public class InMemoryTableStore implements TableStore {", "originalCommit": "e0281e13fb1602d279ac2064282546f02a07482b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNjUwOA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457736508", "bodyText": "This class looks suspiciously similar to that one ...", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:53:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNjMzMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODMzOTI0MQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458339241", "bodyText": "I moved this class to tests. But still can't use  TableStoreMock  as it is defined in a different package that depends on this package.", "author": "sachin-j-joshi", "createdAt": "2020-07-21T19:33:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNjMzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNjc3MA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457736770", "bodyText": "When are you going to do it?", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:54:02Z", "path": "segmentstore/storage/src/test/java/io/pravega/segmentstore/storage/mocks/TableBasedMetadataSimpleStorageTests.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.mocks;\n+\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.chunklayer.ChunkedRollingStorageTests;\n+import io.pravega.segmentstore.storage.chunklayer.ChunkedSegmentStorageTests;\n+import io.pravega.segmentstore.storage.chunklayer.ChunkStorage;\n+import io.pravega.segmentstore.storage.chunklayer.SimpleStorageTests;\n+import io.pravega.segmentstore.storage.metadata.ChunkMetadataStore;\n+import io.pravega.segmentstore.storage.metadata.TableBasedMetadataStore;\n+import org.junit.Ignore;\n+import org.junit.Test;\n+\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+\n+/**\n+ * Unit tests for {@link TableBasedMetadataStore} with {@link InMemoryChunkStorage} using {@link SimpleStorageTests}.\n+ */\n+public class TableBasedMetadataSimpleStorageTests extends SimpleStorageTests {\n+\n+    protected ChunkStorage getChunkStorage() throws Exception {\n+        return new InMemoryChunkStorage();\n+    }\n+\n+    protected ChunkMetadataStore getMetadataStore() throws Exception {\n+        TableStore tableStore = new InMemoryTableStore(executorService());\n+        String tableName = \"TableBasedMetadataSimpleStorageTests\";\n+        return new TableBasedMetadataStore(tableName, tableStore);\n+    }\n+\n+    @Test\n+    @Override\n+    public void testZombieFencing() throws Exception {\n+        //TableBasedMetadataStore does not support clone.\n+    }\n+\n+    /**\n+     * Unit tests for {@link TableBasedMetadataStore} using {@link ChunkedRollingStorageTests}.\n+     */\n+    public static class InMemorySimpleStorageRollingTests extends ChunkedRollingStorageTests {\n+        protected ChunkStorage getChunkStorage() throws Exception {\n+            return new InMemoryChunkStorage();\n+        }\n+\n+        protected ChunkMetadataStore getMetadataStore() throws Exception {\n+            TableStore tableStore = new InMemoryTableStore(executorService());\n+            String tableName = \"TableBasedMetadataSimpleStorageTests\";\n+            return new TableBasedMetadataStore(tableName, tableStore);\n+        }\n+    }\n+\n+    /**\n+     * Unit tests for {@link TableBasedMetadataStore} using {@link ChunkedSegmentStorageTests}.\n+     */\n+    public static class InMemorySimpleStorage extends ChunkedSegmentStorageTests {\n+        @Override\n+        public ChunkMetadataStore createMetadataStore() throws Exception {\n+            TableStore tableStore = new InMemoryTableStore(Executors.newScheduledThreadPool(1));\n+            String tableName = \"TableBasedMetadataSimpleStorageTests\";\n+            return new TableBasedMetadataStore(tableName, tableStore);\n+        }\n+\n+        public TestContext getTestContext() throws Exception {\n+            return new InMemorySimpleStorageTestContext(executorService());\n+        }\n+\n+        @Test\n+        @Ignore(\"This is not implemented yet.\")", "originalCommit": "e0281e13fb1602d279ac2064282546f02a07482b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNjc5OQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457736799", "bodyText": "And below too.", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:54:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNjc3MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQxOTEzNw==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458419137", "bodyText": "Implemented.", "author": "sachin-j-joshi", "createdAt": "2020-07-21T22:12:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNjc3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNjk5MQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457736991", "bodyText": "most of the changes in this file look unrelated. Any chance you could revert them?", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:54:46Z", "path": "standalone/src/main/java/io/pravega/local/InProcPravegaCluster.java", "diffHunk": "@@ -421,14 +425,14 @@ public String getZkUrl() {\n     @Synchronized\n     public void close() throws Exception {\n         if (isInProcSegmentStore) {\n-            for ( ServiceStarter starter : this.nodeServiceStarter ) {\n+            for (ServiceStarter starter : this.nodeServiceStarter) {\n                 starter.shutdown();\n             }\n         }\n         if (isInProcController) {\n-            for ( ControllerServiceMain controller : this.controllerServers ) {\n-                    controller.stopAsync();\n-                }\n+            for (ControllerServiceMain controller : this.controllerServers) {", "originalCommit": "e0281e13fb1602d279ac2064282546f02a07482b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI0NjYwMw==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458246603", "bodyText": "my bad.\ndone", "author": "sachin-j-joshi", "createdAt": "2020-07-21T16:54:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNjk5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNzE2Ng==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457737166", "bodyText": "Delete commented out code", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:55:15Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java", "diffHunk": "@@ -241,50 +258,55 @@ void endToEndProcess(boolean verifySegmentContent) throws Exception {\n \n         // Phase 3: Force a recovery, immediately check reads, then truncate and read at the same time.\n         log.info(\"Starting Phase 3.\");\n-        try (val builder = createBuilder(++instanceId);\n-             val readOnlyBuilder = createReadOnlyBuilder(instanceId)) {\n+        try (val builder = createBuilder(++instanceId, useChunkStorage);) {\n             val segmentStore = builder.createStreamSegmentService();\n-            val readOnlySegmentStore = readOnlyBuilder.createStreamSegmentService();\n-\n             checkReads(segmentContents, segmentStore);\n             log.info(\"Finished checking reads.\");\n+        }\n \n-            if (verifySegmentContent) {\n+        if (verifySegmentContent) {\n+            try (val builder = createBuilder(++instanceId, useChunkStorage);) {\n+                val segmentStore = builder.createStreamSegmentService();\n                 // Wait for all the data to move to Storage.\n-                waitForSegmentsInStorage(segmentNames, segmentStore, readOnlySegmentStore)\n+                waitForSegmentsInStorage(segmentNames, segmentStore)\n                         .get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n                 log.info(\"Finished waiting for segments in Storage.\");\n \n-                checkStorage(segmentContents, segmentStore, readOnlySegmentStore);\n+                checkStorage(segmentContents, segmentStore);\n                 log.info(\"Finished Storage check.\");\n+                //}", "originalCommit": "e0281e13fb1602d279ac2064282546f02a07482b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNzIwOQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457737209", "bodyText": "and here", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:55:24Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java", "diffHunk": "@@ -241,50 +258,55 @@ void endToEndProcess(boolean verifySegmentContent) throws Exception {\n \n         // Phase 3: Force a recovery, immediately check reads, then truncate and read at the same time.\n         log.info(\"Starting Phase 3.\");\n-        try (val builder = createBuilder(++instanceId);\n-             val readOnlyBuilder = createReadOnlyBuilder(instanceId)) {\n+        try (val builder = createBuilder(++instanceId, useChunkStorage);) {\n             val segmentStore = builder.createStreamSegmentService();\n-            val readOnlySegmentStore = readOnlyBuilder.createStreamSegmentService();\n-\n             checkReads(segmentContents, segmentStore);\n             log.info(\"Finished checking reads.\");\n+        }\n \n-            if (verifySegmentContent) {\n+        if (verifySegmentContent) {\n+            try (val builder = createBuilder(++instanceId, useChunkStorage);) {\n+                val segmentStore = builder.createStreamSegmentService();\n                 // Wait for all the data to move to Storage.\n-                waitForSegmentsInStorage(segmentNames, segmentStore, readOnlySegmentStore)\n+                waitForSegmentsInStorage(segmentNames, segmentStore)\n                         .get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n                 log.info(\"Finished waiting for segments in Storage.\");\n \n-                checkStorage(segmentContents, segmentStore, readOnlySegmentStore);\n+                checkStorage(segmentContents, segmentStore);\n                 log.info(\"Finished Storage check.\");\n+                //}\n \n+                //try (val builder = createBuilder(++instanceId, useChunkStorage);) {\n+                //    val segmentStore = builder.createStreamSegmentService();\n                 checkReadsWhileTruncating(segmentContents, startOffsets, segmentStore);\n                 log.info(\"Finished checking reads while truncating.\");\n \n-                checkStorage(segmentContents, segmentStore, readOnlySegmentStore);\n+                checkStorage(segmentContents, segmentStore);\n                 log.info(\"Finished Phase 3.\");\n             }\n         }\n \n         // Phase 4: Force a recovery, seal segments and then delete them.\n         log.info(\"Starting Phase 4.\");\n-        try (val builder = createBuilder(++instanceId);\n-             val readOnlyBuilder = createReadOnlyBuilder(instanceId)) {\n+        try (val builder = createBuilder(++instanceId, useChunkStorage)) {\n             val segmentStore = builder.createStreamSegmentService();\n-            val readOnlySegmentStore = readOnlyBuilder.createStreamSegmentService();\n-\n             // Seals.\n             sealSegments(segmentNames, segmentStore).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n             log.info(\"Finished sealing.\");\n \n             checkSegmentStatus(lengths, startOffsets, true, false, expectedAttributeValue, segmentStore);\n-\n+            //}", "originalCommit": "e0281e13fb1602d279ac2064282546f02a07482b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI0Njc0NA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458246744", "bodyText": "done", "author": "sachin-j-joshi", "createdAt": "2020-07-21T16:54:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNzIwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNzIzNQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457737235", "bodyText": "and here", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:55:31Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java", "diffHunk": "@@ -241,50 +258,55 @@ void endToEndProcess(boolean verifySegmentContent) throws Exception {\n \n         // Phase 3: Force a recovery, immediately check reads, then truncate and read at the same time.\n         log.info(\"Starting Phase 3.\");\n-        try (val builder = createBuilder(++instanceId);\n-             val readOnlyBuilder = createReadOnlyBuilder(instanceId)) {\n+        try (val builder = createBuilder(++instanceId, useChunkStorage);) {\n             val segmentStore = builder.createStreamSegmentService();\n-            val readOnlySegmentStore = readOnlyBuilder.createStreamSegmentService();\n-\n             checkReads(segmentContents, segmentStore);\n             log.info(\"Finished checking reads.\");\n+        }\n \n-            if (verifySegmentContent) {\n+        if (verifySegmentContent) {\n+            try (val builder = createBuilder(++instanceId, useChunkStorage);) {\n+                val segmentStore = builder.createStreamSegmentService();\n                 // Wait for all the data to move to Storage.\n-                waitForSegmentsInStorage(segmentNames, segmentStore, readOnlySegmentStore)\n+                waitForSegmentsInStorage(segmentNames, segmentStore)\n                         .get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n                 log.info(\"Finished waiting for segments in Storage.\");\n \n-                checkStorage(segmentContents, segmentStore, readOnlySegmentStore);\n+                checkStorage(segmentContents, segmentStore);\n                 log.info(\"Finished Storage check.\");\n+                //}\n \n+                //try (val builder = createBuilder(++instanceId, useChunkStorage);) {\n+                //    val segmentStore = builder.createStreamSegmentService();\n                 checkReadsWhileTruncating(segmentContents, startOffsets, segmentStore);\n                 log.info(\"Finished checking reads while truncating.\");\n \n-                checkStorage(segmentContents, segmentStore, readOnlySegmentStore);\n+                checkStorage(segmentContents, segmentStore);\n                 log.info(\"Finished Phase 3.\");\n             }\n         }\n \n         // Phase 4: Force a recovery, seal segments and then delete them.\n         log.info(\"Starting Phase 4.\");\n-        try (val builder = createBuilder(++instanceId);\n-             val readOnlyBuilder = createReadOnlyBuilder(instanceId)) {\n+        try (val builder = createBuilder(++instanceId, useChunkStorage)) {\n             val segmentStore = builder.createStreamSegmentService();\n-            val readOnlySegmentStore = readOnlyBuilder.createStreamSegmentService();\n-\n             // Seals.\n             sealSegments(segmentNames, segmentStore).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n             log.info(\"Finished sealing.\");\n \n             checkSegmentStatus(lengths, startOffsets, true, false, expectedAttributeValue, segmentStore);\n-\n+            //}\n             if (verifySegmentContent) {\n-                waitForSegmentsInStorage(segmentNames, segmentStore, readOnlySegmentStore)\n+                //try (val builder = createBuilder(++instanceId, useChunkStorage)) {", "originalCommit": "e0281e13fb1602d279ac2064282546f02a07482b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNzU1OQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457737559", "bodyText": "remove", "author": "andreipaduroiu", "createdAt": "2020-07-20T22:56:27Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java", "diffHunk": "@@ -869,11 +898,33 @@ private void checkAppendLeaks(ArrayList<ByteBuf> buffers) {\n                 buffers.stream().allMatch(r -> r.refCnt() == 0));\n     }\n \n-    private CompletableFuture<Void> waitForSegmentsInStorage(Collection<String> segmentNames, StreamSegmentStore baseStore,\n+    private ArrayList<SegmentProperties> getStreamSegmentInfoList(Collection<String> segmentNames, StreamSegmentStore baseStore) {\n+        ArrayList<SegmentProperties> retValue = new ArrayList<>();\n+        for (String segmentName : segmentNames) {\n+            SegmentProperties sp = baseStore.getStreamSegmentInfo(segmentName, TIMEOUT).join();\n+            retValue.add(sp);\n+        }\n+\n+        return retValue;\n+    }\n+\n+    /*", "originalCommit": "e0281e13fb1602d279ac2064282546f02a07482b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "06e978a33ea9cc04de7b22ef7e86440866d00114", "url": "https://github.com/pravega/pravega/commit/06e978a33ea9cc04de7b22ef7e86440866d00114", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Address review comments.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-07-21T01:19:10Z", "type": "commit"}, {"oid": "7d729474da6cd83e992ca173ced69e6d55bacbd5", "url": "https://github.com/pravega/pravega/commit/7d729474da6cd83e992ca173ced69e6d55bacbd5", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Add covergage.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-07-21T19:58:37Z", "type": "commit"}, {"oid": "41449187e49b40df5392d774654dd29c4e4baf62", "url": "https://github.com/pravega/pravega/commit/41449187e49b40df5392d774654dd29c4e4baf62", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - More coverage.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-07-21T21:50:05Z", "type": "commit"}, {"oid": "cbb406d928ffeb9a0f44380a186e80ae27504ba0", "url": "https://github.com/pravega/pravega/commit/cbb406d928ffeb9a0f44380a186e80ae27504ba0", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - More coverage.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-07-21T21:53:03Z", "type": "commit"}, {"oid": "41c8da911d4823374ed171deba9bab7d6ee3a926", "url": "https://github.com/pravega/pravega/commit/41c8da911d4823374ed171deba9bab7d6ee3a926", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Remove debug check that all chunks exist.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-07-21T21:56:45Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY2NDEyNA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458664124", "bodyText": "There is no easy way to do this method.\n\nI'm not sure I get what is hard about it. If you are referring to visibility, then having the test class is in the same package should enable this method to be package protected.", "author": "fpj", "createdAt": "2020-07-22T09:34:20Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -0,0 +1,195 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Charsets;\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.DataLogWriterNotPrimaryException;\n+import lombok.Getter;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * {@link TableStore} based storage metadata store.\n+ */\n+@Slf4j\n+public class TableBasedMetadataStore extends BaseMetadataStore {\n+    /**\n+     * Instance of the {@link TableStore}.\n+     */\n+    @Getter\n+    private final TableStore tableStore;\n+\n+    /**\n+     * Name of the table segment.\n+     */\n+    @Getter\n+    private final String tableName;\n+    private final Duration timeout = Duration.ofSeconds(30);\n+    private final AtomicBoolean isTableInitialized = new AtomicBoolean(false);\n+    private final BaseMetadataStore.TransactionData.TransactionDataSerializer serializer = new BaseMetadataStore.TransactionData.TransactionDataSerializer();\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param tableName Name of the table segment.\n+     * @param tableStore Instance of the {@link TableStore}.\n+     */\n+    public TableBasedMetadataStore(String tableName, TableStore tableStore) {\n+        this.tableStore = Preconditions.checkNotNull(tableStore, \"tableStore\");\n+        this.tableName = Preconditions.checkNotNull(tableName, \"tableName\");\n+    }\n+\n+    /**\n+     * Reads a metadata record for the given key.\n+     *\n+     * @param key Key for the metadata record.\n+     * @return Associated {@link io.pravega.segmentstore.storage.metadata.BaseMetadataStore.TransactionData}.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected TransactionData read(String key) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<BufferView> keys = new ArrayList<>();\n+        keys.add(new ByteArraySegment(key.getBytes(Charsets.UTF_8)));\n+        try {\n+            List<TableEntry> retValue = this.tableStore.get(tableName, keys, timeout).get();\n+            if (retValue.size() == 1) {\n+                TableEntry entry = retValue.get(0);\n+                if (null != entry) {\n+                    val arr = entry.getValue();\n+                    TransactionData txnData = serializer.deserialize(arr);\n+                    txnData.setDbObject(entry.getKey().getVersion());\n+                    txnData.setPersisted(true);\n+                    return txnData;\n+                }\n+            }\n+        } catch (IllegalStateException e) {\n+            throw e;\n+        } catch (Exception e) {\n+            throw new StorageMetadataException(\"Error while reading\", e);\n+        }\n+\n+        return TransactionData.builder()\n+                .key(key)\n+                .persisted(true)\n+                .dbObject(TableKey.NOT_EXISTS)\n+                .build();\n+    }\n+\n+    /**\n+     * Writes transaction data from a given list to the metadata store.\n+     *\n+     * @param dataList List of transaction data to write.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected void writeAll(Collection<TransactionData> dataList) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<TableEntry> toUpdate = new ArrayList<>();\n+        HashMap<TableEntry, TransactionData> entryToTxnDataMap = new HashMap<TableEntry, TransactionData>();\n+        HashMap<TableKey, TransactionData> deletedKeyToTxnDataMap = new HashMap<TableKey, TransactionData>();\n+        List<TableKey> keysToDelete = new ArrayList<>();\n+        try {\n+            for (TransactionData txnData : dataList) {\n+                Preconditions.checkState(null != txnData.getDbObject());\n+\n+                long version = ((Long) txnData.getDbObject()).longValue();\n+                if (null == txnData.getValue()) {\n+                    val toDelete = TableKey.unversioned(new ByteArraySegment(txnData.getKey().getBytes(Charsets.UTF_8)));\n+                    keysToDelete.add(toDelete);\n+                    deletedKeyToTxnDataMap.put(toDelete, txnData);\n+                }\n+\n+                val arraySegment = serializer.serialize(txnData);\n+\n+                TableEntry tableEntry = TableEntry.versioned(\n+                        new ByteArraySegment(txnData.getKey().getBytes(Charsets.UTF_8)),\n+                        arraySegment,\n+                        version);\n+                entryToTxnDataMap.put(tableEntry, txnData);\n+                toUpdate.add(tableEntry);\n+            }\n+\n+            // Now put uploaded keys.\n+            List<Long> ret = this.tableStore.put(tableName, toUpdate, timeout).get();\n+\n+            // Update versions.\n+            int i = 0;\n+            for (TableEntry tableEntry : toUpdate) {\n+                entryToTxnDataMap.get(tableEntry).setDbObject(ret.get(i));\n+                i++;\n+            }\n+\n+            // Delete deleted keys.\n+            this.tableStore.remove(tableName, keysToDelete, timeout).get();\n+            for (val deletedKey : keysToDelete) {\n+                deletedKeyToTxnDataMap.get(deletedKey).setDbObject(TableKey.NOT_EXISTS);\n+            }\n+        } catch (RuntimeException e) {\n+            throw handleException(e); // Make spotbugs happy.\n+        } catch (Exception e) {\n+            throw handleException(e);\n+        }\n+    }\n+\n+    private StorageMetadataException handleException(Throwable e) throws StorageMetadataException {\n+        e  = Exceptions.unwrap(e);\n+        if (e instanceof DataLogWriterNotPrimaryException) {\n+            return new StorageMetadataWritesFencedOutException(\"Transaction failed. Writer fenced off\", e);\n+        }\n+        if (e instanceof BadKeyVersionException) {\n+            return new StorageMetadataVersionMismatchException(\"Transaction failed. Version Mismatch.\", e);\n+        }\n+        return new StorageMetadataException(\"Transaction failed\", e);\n+    }\n+\n+    private void ensureInitialized() {\n+        if (!isTableInitialized.get()) {\n+            try {\n+                this.tableStore.createSegment(tableName, timeout).join();\n+                log.info(\"Created table segment {}\", tableName);\n+            } catch (CompletionException e) {\n+                if (e.getCause() instanceof StreamSegmentExistsException) {\n+                    log.info(\"Table segment {} already exists.\", tableName);\n+                }\n+            }\n+            isTableInitialized.set(true);\n+        }\n+    }\n+\n+    /**\n+     * Copy the version of one instance to other.\n+     * This only for test purposes. There is no easy way to do this method.", "originalCommit": "41c8da911d4823374ed171deba9bab7d6ee3a926", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTYzNjk5NA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r459636994", "bodyText": "tests moved to different package.", "author": "sachin-j-joshi", "createdAt": "2020-07-23T18:12:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY2NDEyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY3NTg1NQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458675855", "bodyText": "I see that you have created a Simple class for each storage option. I understand that you have done to be able to create chunk-based storage adaptors. Why have you chosen this path rather than say having a single factory per option and configure using the configuration that we pass to the factory?\nWhat's the plan going forward? Once we deprecate and remove rolling storage, we keep the Simple term in the name, rename it, or what else?", "author": "fpj", "createdAt": "2020-07-22T09:54:42Z", "path": "bindings/src/main/java/io/pravega/storage/extendeds3/ExtendedS3SimpleStorageFactory.java", "diffHunk": "@@ -0,0 +1,49 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.storage.extendeds3;\n+\n+import com.emc.object.s3.S3Client;\n+import com.emc.object.s3.S3Config;\n+import com.emc.object.s3.jersey.S3JerseyClient;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.chunklayer.ChunkedSegmentStorage;\n+import io.pravega.segmentstore.storage.chunklayer.ChunkedSegmentStorageConfig;\n+import lombok.NonNull;\n+import lombok.RequiredArgsConstructor;\n+\n+import java.util.concurrent.ExecutorService;\n+\n+/**\n+ * Factory for ExtendedS3 {@link Storage} implemented using {@link ChunkedSegmentStorage} and {@link ExtendedS3ChunkStorage}.\n+ */\n+@RequiredArgsConstructor\n+public class ExtendedS3SimpleStorageFactory implements StorageFactory {", "originalCommit": "41c8da911d4823374ed171deba9bab7d6ee3a926", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODg3MTAzOA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458871038", "bodyText": "The StorageFactory is created during initialization sequence. This is current design and I did not want to make big changes to current initialization sequence and wanted the change to be as small as it could be. There is no good way to pass in the configurations to the factory without changing factory interface or otherwise make factory stateful (which is not a good idea).\nThat is the reason why i chose this path.\nIn next few iterations we'll remove the old code and at that time we can rename the factory etc. Until then old and new code must live side by side.", "author": "sachin-j-joshi", "createdAt": "2020-07-22T15:16:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY3NTg1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY4MDA0Mw==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458680043", "bodyText": "The indentation looks incorrect.", "author": "fpj", "createdAt": "2020-07-22T10:01:46Z", "path": "segmentstore/server/host/src/test/java/io/pravega/segmentstore/server/host/StorageLoaderTest.java", "diffHunk": "@@ -49,16 +61,88 @@ public void testNoOpWithWithInMemoryStorage() throws Exception {\n \n         configBuilder\n                 .include(StorageExtraConfig.builder()\n-                .with(StorageExtraConfig.STORAGE_NO_OP_MODE, false));\n+                        .with(StorageExtraConfig.STORAGE_NO_OP_MODE, false));", "originalCommit": "41c8da911d4823374ed171deba9bab7d6ee3a926", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODg5NDgxMA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458894810", "bodyText": "should be\n.include(StorageExtraConfig.builder()                \n                       .with(StorageExtraConfig.STORAGE_NO_OP_MODE, false));", "author": "sachin-j-joshi", "createdAt": "2020-07-22T15:49:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY4MDA0Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTYzNzUwMA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r459637500", "bodyText": "fixed.", "author": "sachin-j-joshi", "createdAt": "2020-07-23T18:13:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY4MDA0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY4MDYwOQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458680609", "bodyText": "Why is this being ignored? I actually see a few test cases ignored in this class.", "author": "fpj", "createdAt": "2020-07-22T10:02:47Z", "path": "segmentstore/server/host/src/test/java/io/pravega/segmentstore/server/host/StorageLoaderTest.java", "diffHunk": "@@ -49,16 +61,88 @@ public void testNoOpWithWithInMemoryStorage() throws Exception {\n \n         configBuilder\n                 .include(StorageExtraConfig.builder()\n-                .with(StorageExtraConfig.STORAGE_NO_OP_MODE, false));\n+                        .with(StorageExtraConfig.STORAGE_NO_OP_MODE, false));\n \n         builder = ServiceBuilder.newInMemoryBuilder(configBuilder.build())\n                 .withStorageFactory(setup -> {\n                     StorageLoader loader = new StorageLoader();\n-                    expectedFactory = loader.load(setup, \"INMEMORY\", executor);\n+                    expectedFactory = loader.load(setup, \"INMEMORY\", StorageLayoutType.ROLLING_STORAGE, StorageMetadataFormat.HEADER_BASED, executor);\n                     return expectedFactory;\n                 });\n         builder.initialize();\n         assertTrue(expectedFactory instanceof InMemoryStorageFactory);\n         builder.close();\n     }\n+\n+    @Test\n+    public void testFileSystemStorage() throws Exception {\n+        val storageType = ServiceConfig.StorageType.FILESYSTEM;\n+        ServiceBuilder builder = getStorageFactory(storageType, \"FILESYSTEM\", StorageLayoutType.ROLLING_STORAGE, StorageMetadataFormat.HEADER_BASED);\n+        assertTrue(expectedFactory instanceof FileSystemStorageFactory);\n+        builder.close();\n+    }\n+\n+    @Ignore", "originalCommit": "41c8da911d4823374ed171deba9bab7d6ee3a926", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODg4MzYzNg==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458883636", "bodyText": "The tests need to be fixed.", "author": "sachin-j-joshi", "createdAt": "2020-07-22T15:33:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY4MDYwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY4MTY0OA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458681648", "bodyText": "Is it intentional to remove this getName() method? I guess it is fine as otherwise the build would fail...", "author": "fpj", "createdAt": "2020-07-22T10:04:34Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/StorageFactoryCreator.java", "diffHunk": "@@ -18,14 +18,17 @@\n public interface StorageFactoryCreator {\n     /**\n      * API to create a storage factory with given configuration.\n-     * @param setup     Configuration for the factory.\n-     * @param executor  The storage factory is expected to use this ExecutorService for execution of its tasks.\n+     *\n+     * @param storageFactoryInfo Properties of storage factory to create.\n+     * @param setup              Configuration for the factory.\n+     * @param executor           The storage factory is expected to use this ExecutorService for execution of its tasks.\n      */\n-    StorageFactory createFactory(ConfigSetup setup, ScheduledExecutorService executor);\n+    StorageFactory createFactory(StorageFactoryInfo storageFactoryInfo, ConfigSetup setup, ScheduledExecutorService executor);\n \n     /**\n-     * The unique name for the storage factory.\n-     * @return  Unique name for the storage factory.\n+     * The properties of the available storage factories.\n+     *\n+     * @return The array of StorageFactoryInfo.\n      */\n-    String getName();", "originalCommit": "41c8da911d4823374ed171deba9bab7d6ee3a926", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODg4NDg2NA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458884864", "bodyText": "The interface has been changed.\nThe implementation is now supposed to return array of valid option via\npublic StorageFactoryInfo[] getStorageFactories() {", "author": "sachin-j-joshi", "createdAt": "2020-07-22T15:35:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY4MTY0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY4NDI3Ng==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458684276", "bodyText": "I don't understand what this exception path is doing, why is it correct to update the metadata and commit given that we suspect that there is a new owner?", "author": "fpj", "createdAt": "2020-07-22T10:09:30Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java", "diffHunk": "@@ -244,23 +239,42 @@ private void claimOwnership(MetadataTransaction txn, SegmentMetadata segmentMeta\n                     segmentMetadata.getName(),\n                     lastChunk.getName(),\n                     lastChunk.getLength());\n-            ChunkInfo chunkInfo = chunkStorage.getInfo(lastChunkName);\n-            Preconditions.checkState(chunkInfo != null);\n-            Preconditions.checkState(lastChunk != null);\n-            // Adjust its length;\n-            if (chunkInfo.getLength() != lastChunk.getLength()) {\n-                Preconditions.checkState(chunkInfo.getLength() > lastChunk.getLength());\n-                // Whatever length you see right now is the final \"sealed\" length of the last chunk.\n-                lastChunk.setLength(chunkInfo.getLength());\n-                segmentMetadata.setLength(segmentMetadata.getLastChunkStartOffset() + lastChunk.getLength());\n-                txn.update(lastChunk);\n-                log.debug(\"{} claimOwnership - Length of last chunk adjusted - segment={}, last chunk={}, Length={}.\",\n+            try {\n+                ChunkInfo chunkInfo = chunkStorage.getInfo(lastChunkName);\n+                Preconditions.checkState(chunkInfo != null);\n+                Preconditions.checkState(lastChunk != null);\n+                // Adjust its length;\n+                if (chunkInfo.getLength() != lastChunk.getLength()) {\n+                    Preconditions.checkState(chunkInfo.getLength() > lastChunk.getLength());\n+                    // Whatever length you see right now is the final \"sealed\" length of the last chunk.\n+                    lastChunk.setLength(chunkInfo.getLength());\n+                    segmentMetadata.setLength(segmentMetadata.getLastChunkStartOffset() + lastChunk.getLength());\n+                    txn.update(lastChunk);\n+                    log.debug(\"{} claimOwnership - Length of last chunk adjusted - segment={}, last chunk={}, Length={}.\",\n+                            logPrefix,\n+                            segmentMetadata.getName(),\n+                            lastChunk.getName(),\n+                            chunkInfo.getLength());\n+                }\n+            } catch (ChunkNotFoundException e) {\n+                // This probably means that this instance is fenced out and newer instance truncated this segment.\n+                // Try a commit of unmodified data to fail fast.\n+                log.debug(\"{} claimOwnership - Last chunk was missing, failing fast - segment={}, last chunk={}.\",\n                         logPrefix,\n                         segmentMetadata.getName(),\n-                        lastChunk.getName(),\n-                        chunkInfo.getLength());\n+                        lastChunk.getName());\n+                txn.update(segmentMetadata);", "originalCommit": "41c8da911d4823374ed171deba9bab7d6ee3a926", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODg1MDg0MA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458850840", "bodyText": "During openRead or openWrite we try to reconcile the chunk length in metadata with the actual length on LTS.\nThere is a failover case where segment was last written by a segment store instance that is no more valid, and therefore needs ownership change. Then the current instance itself fails over to even newer segment store instance during the open calls. This most recent instance truncates the segment removing some of the chunks.\nThis causes open to fail with missing chunks exception. Therefore it does not attempt to write to metadata store and does not detect it has been fenced out. This error is \"sticky\" - it is tried again and again and we can't recover from it. Although it does not allow zombie instance to incorrectly write any new data, it still causes quite a few logs to get written. and sometimes it takes a while to detect failover.\nThe change basically forces instances to write to metadata store where it will immediately get exceptions related to being fenced out.", "author": "sachin-j-joshi", "createdAt": "2020-07-22T14:49:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY4NDI3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDA2MTYxNw==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r460061617", "bodyText": "The change basically forces instances to write to metadata store where it will immediately get exceptions related to being fenced out.\n\nIf we are making the metadata change only to get the exception, then why not just throw directly? Is there any case in which the metadata change actually goes through?", "author": "fpj", "createdAt": "2020-07-24T13:45:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY4NDI3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDExNTEyMQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r460115121", "bodyText": "ChunkNotFoundException in this case is only possible indication that , not confirmation.\nMissing chunk when metadata say it should exist is a pretty serious issue in normal circumstances and it should never ever happen. But it does happen in a very specific corner case when newer instance truncates segment without the zombie instance knowing about it. In this case ChunkNotFoundException shadows the underlying issue which is that this instance is no more valid - but because of the ChunkNotFoundException  it never commits and doesn't detect immediately.\nThis causes quite a bit spamming of logs until the instance detects that it is no longer a valid instance by some other means.\nBy trying to commit unchanged metadata, we force early detection of fencing out.\nIn case the metadata update actually succeeds then that means this instance is still the owner. In this case we simply throw the original exception as it might be a true issue. (The metadata update is a \"no-op\" as it doesn't change anything)\n} catch (ChunkNotFoundException e) {\n                // This probably means that this instance is fenced out and newer instance truncated this segment.\n                // Try a commit of unmodified data to fail fast.\n                log.debug(\"{} claimOwnership - Last chunk was missing, failing fast - segment={}, last chunk={}.\",\n                        logPrefix,\n                        segmentMetadata.getName(),\n                        lastChunk.getName());\n                txn.update(segmentMetadata);\n                txn.commit();\n                throw e;\n            }", "author": "sachin-j-joshi", "createdAt": "2020-07-24T15:11:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY4NDI3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDkwMjQwNg==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r460902406", "bodyText": "This is a convoluted way to disambiguate the scenario. My understanding is that:\n1- If the ChunkNotFoundException is due to the instance being fenced out, then we expect txn.update(segmentMetadata) (or maybe txn.commit()) to throw.\n2- If the ChunkNotFoundException is due to some other problem, then the original exception is rethrown, and the commit is essentially a no-op.\nAssuming this is correct, is there a more direct way of executing (1)?", "author": "fpj", "createdAt": "2020-07-27T13:48:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY4NDI3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDk1NDQxOQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r460954419", "bodyText": "In normal scenario, whenever an instance is fenced out then any further calls to txn.commit() throw StorageMetadataWritesFencedOutException .\nHowever if we encounter any other problem/exception then code doesn't reach txn.commit(). This is how we want it and this is how it works. In this particular scenario also, exactly the same is supposed to happen- attempt to change metadata should result in table store update (BK write) and fenced out exception.\nHowever, claimOwnership method is called from openRead/openWrite calls which requires us to check the length of last chunk.\nIn corner case when new instance truncates first and later zombie instance tries to open the same segment , the zombie instance finds the chunks missing and starts throwing exceptions. This prevents it from committing (and therefore detecting fencing out in this case).\nOptions -\n\n\nDo not change - results in quite a bit spam in logs with ChunkNotFound exceptions. This will continue until zombie instance is able to contact ZK and detect that container assignment has changed. This takes time.\n\n\nAttempt to fail early by committing  \"no-op\" change. If this instance is not fenced out, then commit will succeed, in this case throw original exception.\n\n\nI do not think there is an easier way to achieve this.", "author": "sachin-j-joshi", "createdAt": "2020-07-27T14:58:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY4NDI3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTE1NDIxNg==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r461154216", "bodyText": "The logic I think you are trying to implement is:\n           } catch (ChunkNotFoundException e) {\n                // This probably means that this instance is fenced out and newer instance truncated this segment.\n                // Try a commit of unmodified data to fail fast.\n                log.debug(\"{} claimOwnership - Last chunk was missing, failing fast - segment={}, last chunk={}.\",\n                        logPrefix,\n                        segmentMetadata.getName(),\n                        lastChunk.getName());\n                if(amIFencedOut()) {\n                    throw new StorageMetadataWritesFencedOutException();\n                } else {\n                    throw e;\n                }\n            }\n\nAssuming this is right, you are implementing this if block using txn update and commit. My question is why you are not throwing the exception you want directly rather than inducing via this no-op transaction. It clearly requires determining whether this instance is fenced out, is it not doable?", "author": "fpj", "createdAt": "2020-07-27T20:36:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY4NDI3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTE4MDkxMw==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r461180913", "bodyText": "Yes your code snippet is correct.\nhere is what is happening ...\nprivate void claimOwnership(MetadataTransaction txn, SegmentMetadata segmentMetadata) throws ChunkStorageException, StorageMetadataException {\n\n        // Get the last chunk\n        String lastChunkName = segmentMetadata.getLastChunk();\n        if (null != lastChunkName) {\n            ChunkMetadata lastChunk = (ChunkMetadata) txn.get(lastChunkName);\n            try {\n                ChunkInfo chunkInfo = chunkStorage.getInfo(lastChunkName);   ========> throws exception\n                // Adjust its length;\n                if (chunkInfo.getLength() != lastChunk.getLength()) {\n                         // Adjust metadata  \n                        //  Without this update part , we have serious problem of data loss/corruption.\n                }\n             } catch (ChunkNotFoundException e) {\n                    throw e;\n              }\n         }\n            // Claim ownership.\n            // This is safe because the previous instance is definitely not an owner anymore. (even if this instance is no more owner)\n          // If this instance is no more owner, then transaction commit will fail.So it is still safe.\n         segmentMetadata.setOwnerEpoch(this.epoch);  \n         segmentMetadata.setOwnershipChanged(true); ===> metadata update.\n\n         // Update and commit\n         // If This instance is fenced this update will fail.\n         txn.commit();  =======>can't reach here because exception is thrown. \n}\n\nIf exception is thrown the normal txn.commit(); is not executed as that exception bubbles up.\nWe can't ignore ChunkNotFoundException and proceed to commit, because in case the commit succeeds then we have committed wrong/incomplete metadata and ignored a potentially serious error.\n\nBy committing no-change metadata - we are just forcing a write to BK that triggers StorageMetadataWritesFencedOutException being thrown.   If this commit succeeds then metadata is not incorrectly changed, and we then throw original exception .\nI think the limitation here is that the only way to figure out amIFencedOut() is to actually commit something.\nWe could also commit something useless data that is not used anywhere. But instead I am committing unchanged record.", "author": "sachin-j-joshi", "createdAt": "2020-07-27T21:28:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY4NDI3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQ4MzAzNw==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r461483037", "bodyText": "The level of indirection is hacky because there is really no need to have a transaction in this exception handling. If a new instance has taken over, then I understand that previous ledgers have been fenced and closed, in which case, we can check that directly with BookKeeper#isClosed(ledgerId) and there isn't a need to attempt an add entry:\nhttps://bookkeeper.apache.org/docs/4.9.2/api/javadoc/org/apache/bookkeeper/client/BookKeeper.html#isClosed--\nI understand that while the new instance is trying to take over, there is a period in which the ledger is recovering, and consequently the state is not closed. However, when the new instance takes over ownership and starts making changes to chunk metadata, the process of closing ledgers from former owners must have completed.\nThis is not a blocker, but I'd say we should consider fixing it and throwing the exception directly rather than going through a txn update and commit. If you agree, please create an issue to fix it. There might be other parts of the code that could benefit from such a change.", "author": "fpj", "createdAt": "2020-07-28T10:34:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY4NDI3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTgxNDQ1OA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r461814458", "bodyText": "Created tracking issue - #4987", "author": "sachin-j-joshi", "createdAt": "2020-07-28T19:17:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY4NDI3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY4NDQ0Mw==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458684443", "bodyText": "I don't understand this change, can you elaborate, please?", "author": "fpj", "createdAt": "2020-07-22T10:09:50Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java", "diffHunk": "@@ -1045,7 +1059,7 @@ private void concatUsingAppend(ConcatArgument[] concatArgs) throws ChunkStorageE\n                 }\n \n                 // Finally commit.\n-                txn.commit(chunksToDelete.size() == 0); // if layout did not change then commit with lazyWrite.\n+                txn.commit();", "originalCommit": "41c8da911d4823374ed171deba9bab7d6ee3a926", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODgzODkxMw==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458838913", "bodyText": "This is a fix for a bug that I found during the testing.\nQuick background -\nWhen we commit using lazyCommit, we do not write changes to the table store immediately, but instead keep updated records in the memory and keep reusing/updating these in memory copies. This is done to avoid updating records when we are appending to the same chunk again and again. Such write operation causes chunk length and  segment length in metadata to change but otherwise nothing else changes.\nNow, in case of fail over this data stored in memory is lost.  But this very specific information can be reconstructed by looking at the actual chunk length and adjusting the metadata while doing openRead or openWrite.\nFor any other changes (addition/deletion of chunks, metadata updates like sealed etc) we must commit the updated record to the underlying store immediately because those changes are not reconstructible.\nWhat was the bug ?\nI was incorrectly handling the \"corner case\"  where segment is truncated but first chunk is not removed. In this case only the start offset recorded in metadata changes but nothing else changes.\nI was incorrectly committing with lazyCommit for truncate operation thinking if the layout (i.e chunks in the segment) did not change then we don't have to commit eagerly.\nThis is incorrect because in case of fail over the start offset changes but will be lost and this change is not recoverable.\nWhat is the fix ?\nAlways commit eagerly as it is required in all cases.", "author": "sachin-j-joshi", "createdAt": "2020-07-22T14:33:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY4NDQ0Mw=="}], "type": "inlineReview"}, {"oid": "54d71e184a464532a9547d3c3871164f3c8f7216", "url": "https://github.com/pravega/pravega/commit/54d71e184a464532a9547d3c3871164f3c8f7216", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Fix StorageLoaderTests.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-07-22T17:33:12Z", "type": "commit"}, {"oid": "a739c45202b885b80082d2c9b2e386b17a75bdae", "url": "https://github.com/pravega/pravega/commit/a739c45202b885b80082d2c9b2e386b17a75bdae", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Move all TableBasedMetadataStore related tests to TableBasedMetadataStoreTests.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-07-22T18:57:49Z", "type": "commit"}, {"oid": "88434db59cc483cf51008b10edc7a6eb48cc2848", "url": "https://github.com/pravega/pravega/commit/88434db59cc483cf51008b10edc7a6eb48cc2848", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Remove unused code.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-07-22T21:38:50Z", "type": "commit"}, {"oid": "4b2c256d17a74ac3d16a6b6831c90b9b4ec120eb", "url": "https://github.com/pravega/pravega/commit/4b2c256d17a74ac3d16a6b6831c90b9b4ec120eb", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Fix white space.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-07-22T22:01:03Z", "type": "commit"}, {"oid": "5c0d20dc7d564d13604bc69e454841f05dafc9bf", "url": "https://github.com/pravega/pravega/commit/5c0d20dc7d564d13604bc69e454841f05dafc9bf", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Even more coverage.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-07-23T00:21:31Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU3ODgwOQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r459578809", "bodyText": "Remove this please", "author": "andreipaduroiu", "createdAt": "2020-07-23T16:32:25Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java", "diffHunk": "@@ -274,10 +274,7 @@ void endToEndProcess(boolean verifySegmentContent, boolean useChunkStorage) thro\n \n                 checkStorage(segmentContents, segmentStore);\n                 log.info(\"Finished Storage check.\");\n-                //}", "originalCommit": "5c0d20dc7d564d13604bc69e454841f05dafc9bf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU3ODg2NQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r459578865", "bodyText": "and below", "author": "andreipaduroiu", "createdAt": "2020-07-23T16:32:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU3ODgwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTYyNzgyOQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r459627829", "bodyText": "this is already removed.", "author": "sachin-j-joshi", "createdAt": "2020-07-23T17:56:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU3ODgwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU3ODk1MA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r459578950", "bodyText": "Remove this", "author": "andreipaduroiu", "createdAt": "2020-07-23T16:32:41Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java", "diffHunk": "@@ -338,24 +332,23 @@ public void testEndToEndWithFencing() throws Exception {\n      * @throws Exception If an exception occurred.\n      */\n     @Test\n-    //@Ignore", "originalCommit": "5c0d20dc7d564d13604bc69e454841f05dafc9bf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTYyNzcwMw==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r459627703", "bodyText": "this is already removed.", "author": "sachin-j-joshi", "createdAt": "2020-07-23T17:55:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU3ODk1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU3OTA3Nw==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r459579077", "bodyText": "and this", "author": "andreipaduroiu", "createdAt": "2020-07-23T16:32:52Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java", "diffHunk": "@@ -908,18 +901,6 @@ private void checkAppendLeaks(ArrayList<ByteBuf> buffers) {\n         return retValue;\n     }\n \n-    /*", "originalCommit": "5c0d20dc7d564d13604bc69e454841f05dafc9bf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTYyNzY0OA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r459627648", "bodyText": "this is already removed.", "author": "sachin-j-joshi", "createdAt": "2020-07-23T17:55:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU3OTA3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU4Mzk1NA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r459583954", "bodyText": "Why did we add all these extra lines?", "author": "andreipaduroiu", "createdAt": "2020-07-23T16:41:01Z", "path": "standalone/src/main/java/io/pravega/local/InProcPravegaCluster.java", "diffHunk": "@@ -88,6 +86,7 @@\n     private int segmentStoreCount;\n     private int[] segmentStorePorts;\n \n+", "originalCommit": "5c0d20dc7d564d13604bc69e454841f05dafc9bf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTA1NjUwMw==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r461056503", "bodyText": "Fixed. Reverted change.", "author": "sachin-j-joshi", "createdAt": "2020-07-27T17:35:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU4Mzk1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU4NDA3Nw==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r459584077", "bodyText": "Extra space.", "author": "andreipaduroiu", "createdAt": "2020-07-23T16:41:14Z", "path": "standalone/src/main/java/io/pravega/local/InProcPravegaCluster.java", "diffHunk": "@@ -161,7 +161,7 @@ public InProcPravegaCluster build() {\n \n     @Synchronized\n     public void setControllerPorts(int[] controllerPorts) {\n-        this.controllerPorts = Arrays.copyOf(controllerPorts, controllerPorts.length);\n+        this.controllerPorts = Arrays.copyOf( controllerPorts, controllerPorts.length);", "originalCommit": "5c0d20dc7d564d13604bc69e454841f05dafc9bf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTA1NjM5MQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r461056391", "bodyText": "Fixed. Reverted change.", "author": "sachin-j-joshi", "createdAt": "2020-07-27T17:35:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU4NDA3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU4NDIxOA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r459584218", "bodyText": "space", "author": "andreipaduroiu", "createdAt": "2020-07-23T16:41:28Z", "path": "standalone/src/main/java/io/pravega/local/InProcPravegaCluster.java", "diffHunk": "@@ -228,7 +228,7 @@ private void cleanUpZK() {\n         @Cleanup\n         CuratorFramework zclient = builder.build();\n         zclient.start();\n-        for (String path : pathsTobeCleaned) {\n+        for ( String path : pathsTobeCleaned ) {", "originalCommit": "5c0d20dc7d564d13604bc69e454841f05dafc9bf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTA1NjI4Mw==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r461056283", "bodyText": "Fixed. Reverted change.", "author": "sachin-j-joshi", "createdAt": "2020-07-27T17:35:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU4NDIxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU4NDI3Nw==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r459584277", "bodyText": "and here", "author": "andreipaduroiu", "createdAt": "2020-07-23T16:41:36Z", "path": "standalone/src/main/java/io/pravega/local/InProcPravegaCluster.java", "diffHunk": "@@ -425,12 +425,12 @@ public String getZkUrl() {\n     @Synchronized\n     public void close() throws Exception {\n         if (isInProcSegmentStore) {\n-            for (ServiceStarter starter : this.nodeServiceStarter) {\n+            for ( ServiceStarter starter : this.nodeServiceStarter ) {", "originalCommit": "5c0d20dc7d564d13604bc69e454841f05dafc9bf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTA1NjIyOQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r461056229", "bodyText": "Fixed. Reverted change.", "author": "sachin-j-joshi", "createdAt": "2020-07-27T17:35:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU4NDI3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU4NDM0NA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r459584344", "bodyText": "and here", "author": "andreipaduroiu", "createdAt": "2020-07-23T16:41:41Z", "path": "standalone/src/main/java/io/pravega/local/InProcPravegaCluster.java", "diffHunk": "@@ -425,12 +425,12 @@ public String getZkUrl() {\n     @Synchronized\n     public void close() throws Exception {\n         if (isInProcSegmentStore) {\n-            for (ServiceStarter starter : this.nodeServiceStarter) {\n+            for ( ServiceStarter starter : this.nodeServiceStarter ) {\n                 starter.shutdown();\n             }\n         }\n         if (isInProcController) {\n-            for (ControllerServiceMain controller : this.controllerServers) {\n+            for ( ControllerServiceMain controller : this.controllerServers ) {", "originalCommit": "5c0d20dc7d564d13604bc69e454841f05dafc9bf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTYzNTkzOQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r459635939", "bodyText": "fixed b939678", "author": "sachin-j-joshi", "createdAt": "2020-07-23T18:10:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU4NDM0NA=="}], "type": "inlineReview"}, {"oid": "f3935b46788108c5bcf1a5e9800845e785deae5d", "url": "https://github.com/pravega/pravega/commit/f3935b46788108c5bcf1a5e9800845e785deae5d", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - More coverage.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-07-23T17:28:30Z", "type": "commit"}, {"oid": "b93967814181a08081b8c3025588ecba5c6331e9", "url": "https://github.com/pravega/pravega/commit/b93967814181a08081b8c3025588ecba5c6331e9", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Revert unitented whitespace in InProcPravegaCluster.java.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-07-23T18:06:59Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDEwODQ0Ng==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r460108446", "bodyText": "This piece of code seems the same as ExtendedS3StorageFactoryCreator and perhaps other places. Wondering if we can do this in a common method, and then pass the specific instance on each implementation instead of repeating the same logic everywhere.", "author": "RaulGracia", "createdAt": "2020-07-24T15:00:52Z", "path": "bindings/src/main/java/io/pravega/storage/filesystem/FileSystemStorageFactoryCreator.java", "diffHunk": "@@ -9,20 +9,44 @@\n  */\n package io.pravega.storage.filesystem;\n \n+import com.google.common.base.Preconditions;\n import io.pravega.segmentstore.storage.ConfigSetup;\n import io.pravega.segmentstore.storage.StorageFactory;\n import io.pravega.segmentstore.storage.StorageFactoryCreator;\n+import io.pravega.segmentstore.storage.StorageFactoryInfo;\n+import io.pravega.segmentstore.storage.StorageMetadataFormat;\n+import io.pravega.segmentstore.storage.StorageLayoutType;\n+\n import java.util.concurrent.ScheduledExecutorService;\n \n public class FileSystemStorageFactoryCreator implements StorageFactoryCreator {\n \n     @Override\n-    public String getName() {\n-        return \"FILESYSTEM\";\n+    public StorageFactoryInfo[] getStorageFactories() {\n+        return new StorageFactoryInfo[]{\n+                StorageFactoryInfo.builder()\n+                        .name(\"FILESYSTEM\")\n+                        .storageMetadataFormat(StorageMetadataFormat.TABLE_BASED)\n+                        .storageLayoutType(StorageLayoutType.CHUNKED_STORAGE)\n+                        .build(),\n+                StorageFactoryInfo.builder()\n+                        .name(\"FILESYSTEM\")\n+                        .storageMetadataFormat(StorageMetadataFormat.HEADER_BASED)\n+                        .storageLayoutType(StorageLayoutType.ROLLING_STORAGE)\n+                        .build()\n+        };\n     }\n \n     @Override\n-    public StorageFactory createFactory(ConfigSetup setup, ScheduledExecutorService executor) {\n-        return new FileSystemStorageFactory(setup.getConfig(FileSystemStorageConfig::builder), executor);\n+    public StorageFactory createFactory(StorageFactoryInfo storageFactoryInfo, ConfigSetup setup, ScheduledExecutorService executor) {", "originalCommit": "b93967814181a08081b8c3025588ecba5c6331e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDEzNzExMA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r460137110", "bodyText": "I think it would be ugly looking method which takes two Supplier lambdas that possibly take other lambdas etc .\nThis is unnecessarily complex. I already dislike the round about way things get initialized.\nI think the medicine is more harmful than illness itself in this case :)\npublic StorageFactory createFactory(StorageFactoryInfo storageFactoryInfo, ConfigSetup setup, ScheduledExecutorService executor) {\n      return commonFunction(()-> new ExtendedS3SimpleStorageFactory(setup.getConfig(ChunkedSegmentStorageConfig::builder),\n                    setup.getConfig(ExtendedS3StorageConfig::builder),\n                    executor),\n                         ()-> return new ExtendedS3StorageFactory(setup.getConfig(ExtendedS3StorageConfig::builder), executor);\n)", "author": "sachin-j-joshi", "createdAt": "2020-07-24T15:48:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDEwODQ0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDEwOTI3NA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r460109274", "bodyText": "Is this change necessary? The previous indentation seemed ok.", "author": "RaulGracia", "createdAt": "2020-07-24T15:02:07Z", "path": "segmentstore/contracts/src/main/java/io/pravega/segmentstore/contracts/StreamSegmentInformation.java", "diffHunk": "@@ -76,21 +91,21 @@ private StreamSegmentInformation(String name, long startOffset, long length, boo\n      */\n     public static StreamSegmentInformationBuilder from(SegmentProperties base) {\n         return StreamSegmentInformation.builder()\n-                                       .name(base.getName())\n-                                       .startOffset(base.getStartOffset())\n-                                       .length(base.getLength())\n-                                       .sealed(base.isSealed())\n-                                       .deleted(base.isDeleted())\n-                                       .lastModified(base.getLastModified())\n-                                       .attributes(base.getAttributes());\n+                .name(base.getName())", "originalCommit": "b93967814181a08081b8c3025588ecba5c6331e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDEzNzg0OA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r460137848", "bodyText": "this change is harmless too.", "author": "sachin-j-joshi", "createdAt": "2020-07-24T15:49:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDEwOTI3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDE3NDgwMA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r460174800", "bodyText": "reverted white space change.", "author": "sachin-j-joshi", "createdAt": "2020-07-24T16:56:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDEwOTI3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDExMzEzMA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r460113130", "bodyText": "Isn't this equivalent to what it was before? A boolean set to true and then if (checkClosed).", "author": "RaulGracia", "createdAt": "2020-07-24T15:08:11Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java", "diffHunk": "@@ -671,19 +686,25 @@ private void checkReads(HashMap<String, ByteArrayOutputStream> segmentContents,\n             // This is gracefully handled by retries in AppendProcessor and/or Client, but in this case, we simply have to\n             // do the retries ourselves, hoping that the callback eventually executes.\n             Retry.withExpBackoff(100, 2, 10, TIMEOUT.toMillis() / 5)\n-                 .retryWhen(ex -> Exceptions.unwrap(ex) instanceof StreamSegmentNotExistsException)\n-                 .run(() -> {\n-                     checkSegmentReads(segmentName, expectedCurrentOffset, segmentLength, store, expectedData);\n-                     return null;\n-                 });\n+                    .retryWhen(ex -> Exceptions.unwrap(ex) instanceof StreamSegmentNotExistsException || info.get().getLength() != info.get().getStorageLength())\n+                    .run(() -> {\n+                        val latestInfo =  (StreamSegmentInformation) store.getStreamSegmentInfo(segmentName, TIMEOUT).join();\n+                        try {\n+                            checkSegmentReads(segmentName, expectedCurrentOffset, info.get().getLength(), store, expectedData);\n+                        } catch (Exception ex2) {\n+                            log.debug(\"Exception during checkReads\", ex2);\n+                        }\n+                        info.set(latestInfo);\n+                        return null;\n+                    });\n         }\n     }\n \n     private void checkSegmentReads(String segmentName, AtomicLong expectedCurrentOffset, long segmentLength, StreamSegmentStore store, byte[] expectedData) throws Exception {\n         @Cleanup\n         ReadResult readResult = store.read(segmentName, expectedCurrentOffset.get(), (int) (segmentLength - expectedCurrentOffset.get()), TIMEOUT).join();\n         Assert.assertTrue(\"Empty read result for segment \" + segmentName, readResult.hasNext());\n-\n+        boolean checkClosed = true;", "originalCommit": "b93967814181a08081b8c3025588ecba5c6331e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDE0Mjg1NA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r460142854", "bodyText": "I thought I had removed it.\nLooks I lost that change during merge.\nFixing it.", "author": "sachin-j-joshi", "createdAt": "2020-07-24T15:57:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDExMzEzMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDE3NDU4MA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r460174580", "bodyText": "Fixed.", "author": "sachin-j-joshi", "createdAt": "2020-07-24T16:56:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDExMzEzMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDEzMzc1OA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r460133758", "bodyText": "we are not dealing with InterruptedException here", "author": "eolivelli", "createdAt": "2020-07-24T15:42:21Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentContainer.java", "diffHunk": "@@ -253,7 +278,11 @@ protected void doStart() {\n     }\n \n     private CompletableFuture<Void> initializeSecondaryServices() {\n-        this.storage.initialize(this.metadata.getContainerEpoch());\n+        try {\n+            initializeStorage();\n+        } catch (Exception ex) {", "originalCommit": "b93967814181a08081b8c3025588ecba5c6331e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDE0NTE0OA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r460145148", "bodyText": "The caller handles it.", "author": "sachin-j-joshi", "createdAt": "2020-07-24T16:01:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDEzMzc1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDE0OTI3MQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r460149271", "bodyText": "You are returning a CompletableFuture so the result won't be handled in this thread.\nAs usual we should call Theead.currentThread().interrupt()\notherwise we are going to mask that flag", "author": "eolivelli", "createdAt": "2020-07-24T16:08:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDEzMzc1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDk4NjU4MQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r460986581", "bodyText": "Not sure why we need to do this.\nThis task was executed on this thread and received thread interrupted exception - which we are returning as failed future.\nThis thread is now supposed to pickup some other work and complete it. What happens if we don't call Thread.currentThread().interrupt() ?", "author": "sachin-j-joshi", "createdAt": "2020-07-27T15:44:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDEzMzc1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDk5NzMyMw==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r460997323", "bodyText": "you can't know who the caller is, because we can refactor this code in the future\nand as when you catch an InterruptedException you reset the 'interrupted' flag on the Java thread,\nif you do not set again that flag the caller won't be notified about this InterruptedException\neven if I am not a fan of InterruptedException and how it works IMHO we should handle it consistently (using Exceptions#handleInterrupted)", "author": "eolivelli", "createdAt": "2020-07-27T16:00:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDEzMzc1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY2NzgzMA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r461667830", "bodyText": "We do not do this anywhere else in the code. If this must be changed, then we should do it throughout the codebase, not just here.\n@sachin-j-joshi I would suggest to clean this up and add a follow-up issue that will add a helper in Futures to do this.", "author": "andreipaduroiu", "createdAt": "2020-07-28T15:22:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDEzMzc1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTgxMzM1Mw==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r461813353", "bodyText": "Created a tracking issue #4986", "author": "sachin-j-joshi", "createdAt": "2020-07-28T19:16:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDEzMzc1OA=="}], "type": "inlineReview"}, {"oid": "5edcd82ff198b871e342562c43769b919b340f0e", "url": "https://github.com/pravega/pravega/commit/5edcd82ff198b871e342562c43769b919b340f0e", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - address review comments.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-07-24T16:41:30Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDk4Njg2NQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r460986865", "bodyText": "Why is this ignored?", "author": "andreipaduroiu", "createdAt": "2020-07-27T15:44:49Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentServiceNoOpWriteOnlyTests.java", "diffHunk": "@@ -69,7 +70,14 @@ protected ServiceBuilder createBuilder(ServiceBuilderConfig.Builder builderConfi\n     @Override\n     @Test\n     public void testEndToEnd() throws Exception {\n-        endToEndProcess(false);\n+        endToEndProcess(false, false);\n+    }\n+\n+    @Override\n+    @Test\n+    @Ignore", "originalCommit": "5edcd82ff198b871e342562c43769b919b340f0e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTA1NTg2Nw==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r461055867", "bodyText": "NoOpStorage does not support ChunkedSegmentStorage yet.", "author": "sachin-j-joshi", "createdAt": "2020-07-27T17:34:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDk4Njg2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDk4Njk2NA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r460986964", "bodyText": "And here", "author": "andreipaduroiu", "createdAt": "2020-07-27T15:44:56Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentServiceNoOpWriteOnlyTests.java", "diffHunk": "@@ -79,6 +87,13 @@ public void testEndToEnd() throws Exception {\n     @Override\n     @Test\n     public void testEndToEndWithFencing() throws Exception {\n-        endToEndProcessWithFencing(false);\n+        endToEndProcessWithFencing(false, false);\n+    }\n+\n+    @Override\n+    @Test\n+    @Ignore", "originalCommit": "5edcd82ff198b871e342562c43769b919b340f0e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTA1NTgyMw==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r461055823", "bodyText": "NoOpStorage does not support ChunkedSegmentStorage yet.", "author": "sachin-j-joshi", "createdAt": "2020-07-27T17:34:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDk4Njk2NA=="}], "type": "inlineReview"}, {"oid": "ee9ee28b3c0bd7db7347ee5601ab13032c1a8ddf", "url": "https://github.com/pravega/pravega/commit/ee9ee28b3c0bd7db7347ee5601ab13032c1a8ddf", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Remove storage fromat as config option.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-07-27T17:26:18Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY2NDkwNQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r461664905", "bodyText": "Since you've added this, I want to add a precondition check to validate that 0<=storageLength<=length (see above how we do it for startOffset.", "author": "andreipaduroiu", "createdAt": "2020-07-28T15:18:14Z", "path": "segmentstore/contracts/src/main/java/io/pravega/segmentstore/contracts/StreamSegmentInformation.java", "diffHunk": "@@ -46,24 +53,30 @@\n     /**\n      * Creates a new instance of the StreamSegmentInformation class.\n      *\n-     * @param name         The name of the StreamSegment.\n-     * @param startOffset  The first available offset in this StreamSegment.\n-     * @param length       The length of the StreamSegment.\n-     * @param sealed       Whether the StreamSegment is sealed (for modifications).\n-     * @param deleted      Whether the StreamSegment is deleted (does not exist).\n-     * @param attributes   The attributes of this StreamSegment.\n-     * @param lastModified The last time the StreamSegment was modified.\n+     * @param name             The name of the StreamSegment.\n+     * @param startOffset      The first available offset in this StreamSegment.\n+     * @param length           The length of the StreamSegment.\n+     * @param sealed           Whether the StreamSegment is sealed (for modifications).\n+     * @param deleted          Whether the StreamSegment is deleted (does not exist).\n+     * @param storageLength    Storage length.\n+     * @param sealedInStorage  Whether the StreamSegment is sealed (for modifications) in storage.\n+     * @param deletedInStorage Whether the StreamSegment is deleted (does not exist) in storage.\n+     * @param attributes       The attributes of this StreamSegment.\n+     * @param lastModified     The last time the StreamSegment was modified.\n      */\n     @Builder\n-    private StreamSegmentInformation(String name, long startOffset, long length, boolean sealed, boolean deleted,\n-                                    Map<UUID, Long> attributes, ImmutableDate lastModified) {\n+    private StreamSegmentInformation(String name, long startOffset, long length, long storageLength, boolean sealed, boolean deleted,\n+                                     boolean sealedInStorage, boolean deletedInStorage, Map<UUID, Long> attributes, ImmutableDate lastModified) {\n         Preconditions.checkArgument(startOffset >= 0, \"startOffset must be a non-negative number.\");\n         Preconditions.checkArgument(length >= startOffset, \"length must be a non-negative number and greater than startOffset.\");\n         this.name = Exceptions.checkNotNullOrEmpty(name, \"name\");\n         this.startOffset = startOffset;\n         this.length = length;\n+        this.storageLength = storageLength;", "originalCommit": "ee9ee28b3c0bd7db7347ee5601ab13032c1a8ddf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTgwNTMzMg==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r461805332", "bodyText": "StreamSegmentMetadata constructor sets the storageLength to -1.  So not testing 0<=storageLength .", "author": "sachin-j-joshi", "createdAt": "2020-07-28T19:02:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY2NDkwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY2NTMxNQ==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r461665315", "bodyText": "Precondition check. If deletedInStorage == true, then deleted must be true as well.", "author": "andreipaduroiu", "createdAt": "2020-07-28T15:18:48Z", "path": "segmentstore/contracts/src/main/java/io/pravega/segmentstore/contracts/StreamSegmentInformation.java", "diffHunk": "@@ -46,24 +53,30 @@\n     /**\n      * Creates a new instance of the StreamSegmentInformation class.\n      *\n-     * @param name         The name of the StreamSegment.\n-     * @param startOffset  The first available offset in this StreamSegment.\n-     * @param length       The length of the StreamSegment.\n-     * @param sealed       Whether the StreamSegment is sealed (for modifications).\n-     * @param deleted      Whether the StreamSegment is deleted (does not exist).\n-     * @param attributes   The attributes of this StreamSegment.\n-     * @param lastModified The last time the StreamSegment was modified.\n+     * @param name             The name of the StreamSegment.\n+     * @param startOffset      The first available offset in this StreamSegment.\n+     * @param length           The length of the StreamSegment.\n+     * @param sealed           Whether the StreamSegment is sealed (for modifications).\n+     * @param deleted          Whether the StreamSegment is deleted (does not exist).\n+     * @param storageLength    Storage length.\n+     * @param sealedInStorage  Whether the StreamSegment is sealed (for modifications) in storage.\n+     * @param deletedInStorage Whether the StreamSegment is deleted (does not exist) in storage.\n+     * @param attributes       The attributes of this StreamSegment.\n+     * @param lastModified     The last time the StreamSegment was modified.\n      */\n     @Builder\n-    private StreamSegmentInformation(String name, long startOffset, long length, boolean sealed, boolean deleted,\n-                                    Map<UUID, Long> attributes, ImmutableDate lastModified) {\n+    private StreamSegmentInformation(String name, long startOffset, long length, long storageLength, boolean sealed, boolean deleted,\n+                                     boolean sealedInStorage, boolean deletedInStorage, Map<UUID, Long> attributes, ImmutableDate lastModified) {\n         Preconditions.checkArgument(startOffset >= 0, \"startOffset must be a non-negative number.\");\n         Preconditions.checkArgument(length >= startOffset, \"length must be a non-negative number and greater than startOffset.\");\n         this.name = Exceptions.checkNotNullOrEmpty(name, \"name\");\n         this.startOffset = startOffset;\n         this.length = length;\n+        this.storageLength = storageLength;\n         this.sealed = sealed;\n+        this.sealedInStorage = sealedInStorage;\n         this.deleted = deleted;\n+        this.deletedInStorage = deletedInStorage;", "originalCommit": "ee9ee28b3c0bd7db7347ee5601ab13032c1a8ddf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTgwMDA0Mw==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r461800043", "bodyText": "Updated", "author": "sachin-j-joshi", "createdAt": "2020-07-28T18:53:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY2NTMxNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY3MDI5OA==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r461670298", "bodyText": "Can you make 42 and 10 class-level constants? They are used everywhere in these tests.", "author": "andreipaduroiu", "createdAt": "2020-07-28T15:25:34Z", "path": "segmentstore/storage/src/test/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorageTests.java", "diffHunk": "@@ -1505,6 +1502,191 @@ private void testTruncate(long maxChunkLength, long truncateAt, int chunksCountB\n         TestUtils.checkChunksExistInStorage(testContext.storageProvider, testContext.metadataStore, testSegmentName);\n     }\n \n+    /**\n+     * Test read and write with multiple failovers.\n+     *\n+     * @throws Exception Exception if any.\n+     */\n+    @Test\n+    public void testReadWriteWithMultipleFailovers() throws Exception {\n+        String testSegmentName = \"foo\";\n+        TestContext testContext = getTestContext();\n+\n+        // Create\n+        testContext.storageManager.create(testSegmentName, null).get();\n+\n+        // Write some data.\n+        long writeAt = 0;\n+        long epoch = 42;\n+        ArrayList<Long> lengths = new ArrayList<>();\n+        for (int i = 1; i < 5; i++) {\n+            // Create a new test context and initialize with new epoch.\n+            val hWrite =  testContext.storageManager.openWrite(testSegmentName).get();\n+            testContext.storageManager.write(hWrite, writeAt, new ByteArrayInputStream(new byte[i]), i, null).join();\n+            writeAt += i;\n+            lengths.add((long) i);\n+\n+            // Read in same epoch.\n+            checkDataRead(testSegmentName, testContext, 0, writeAt);\n+\n+            TestUtils.checkSegmentLayout(testContext.metadataStore, testSegmentName, Longs.toArray(lengths));\n+\n+            // Fork the context.\n+            val oldTestCotext = testContext;\n+            testContext = oldTestCotext.fork(epoch++);\n+            TestUtils.checkSegmentLayout(testContext.metadataStore, testSegmentName, Longs.toArray(lengths));\n+\n+            // Fence out old store.\n+            oldTestCotext.metadataStore.markFenced();\n+\n+            // Read in new epoch.\n+            checkDataRead(testSegmentName, testContext, 0, writeAt);\n+        }\n+\n+        int total = 10;\n+\n+        // Create a new test context and initialize with new epoch.\n+        testContext = testContext.fork(epoch++);\n+\n+        checkDataRead(testSegmentName, testContext, 0, total);\n+    }\n+\n+    /**\n+     * Test read and write with multiple failovers.\n+     *\n+     * @throws Exception Exception if any.\n+     */\n+    @Test\n+    public void testReadWriteWithMultipleFailoversWithGarbage() throws Exception {\n+        String testSegmentName = \"foo\";\n+        TestContext testContext = getTestContext();\n+\n+        // Create\n+        testContext.storageManager.create(testSegmentName, null).get();\n+\n+        // Write some data.\n+        long writeAt = 0;\n+        long epoch = 42;\n+        SegmentHandle hWrite =  testContext.storageManager.openWrite(testSegmentName).get();\n+        ArrayList<Long> lengths = new ArrayList<>();\n+        for (int i = 1; i < 5; i++) {\n+            // Create a new test context and initialize with new epoch.\n+            testContext.storageManager.write(hWrite, writeAt, new ByteArrayInputStream(new byte[i]), i, null).join();\n+            writeAt += i;\n+            lengths.add((long) i);\n+\n+            // Read in same epoch.\n+            checkDataRead(testSegmentName, testContext, 0, writeAt);\n+\n+            TestUtils.checkSegmentLayout(testContext.metadataStore, testSegmentName, Longs.toArray(lengths));\n+\n+            // Fork the context.\n+            val oldTestCotext = testContext;\n+            testContext = oldTestCotext.fork(epoch++);\n+            TestUtils.checkSegmentLayout(testContext.metadataStore, testSegmentName, Longs.toArray(lengths));\n+\n+            // Make sure to open segment with new instance before writing garbage to old instance.\n+            hWrite =  testContext.storageManager.openWrite(testSegmentName).get();\n+\n+            // Write some garbage\n+            oldTestCotext.storageManager.write(hWrite, writeAt, new ByteArrayInputStream(new byte[10]), 10, null).join();\n+\n+            // Fence out old store.\n+            boolean exceptionThrown = false;\n+            oldTestCotext.metadataStore.markFenced();\n+\n+            AssertExtensions.assertFutureThrows(\"conact() allowed for invalid parameters\",\n+                    oldTestCotext.storageManager.write(hWrite, writeAt + 10, new ByteArrayInputStream(new byte[10]), 10, null),\n+                    ex -> ex instanceof StorageNotPrimaryException);\n+            // Read in new epoch.\n+            checkDataRead(testSegmentName, testContext, 0, writeAt);\n+        }\n+\n+        int total = 10;\n+\n+        // Create a new test context and initialize with new epoch.\n+        testContext = testContext.fork(epoch++);\n+\n+        checkDataRead(testSegmentName, testContext, 0, total);\n+    }\n+\n+    /**\n+     * Test truncate, read and write with multiple failovers.\n+     *\n+     * @throws Exception Exception if any.\n+     */\n+    @Test\n+    public void testTruncateWithMultipleFailoversWithGarbage() throws Exception {\n+        String testSegmentName = \"foo\";\n+        TestContext testContext = getTestContext();\n+\n+        // Create\n+        testContext.storageManager.create(testSegmentName, null).get();\n+\n+        // Write some data.\n+        long writeAt = 0;\n+        long truncateAt = 0;\n+        long epoch = 42;", "originalCommit": "ee9ee28b3c0bd7db7347ee5601ab13032c1a8ddf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTgxMDIzMg==", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r461810232", "bodyText": "Fixed for 42.\nNumber 10 is used in each test with different meaning in different tests. So using common test wide contsnat isn't much useful. so living it as it is.", "author": "sachin-j-joshi", "createdAt": "2020-07-28T19:11:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY3MDI5OA=="}], "type": "inlineReview"}, {"oid": "abc00aed5ee5b78eb0335f7e0c82506383412faf", "url": "https://github.com/pravega/pravega/commit/abc00aed5ee5b78eb0335f7e0c82506383412faf", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Address review comments.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-07-28T17:59:41Z", "type": "commit"}]}