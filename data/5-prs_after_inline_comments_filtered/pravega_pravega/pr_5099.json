{"pr_number": 5099, "pr_title": "Issue 5095: DR Integration tests included for multiple containers and Transactional writers", "pr_createdAt": "2020-08-25T07:22:50Z", "pr_url": "https://github.com/pravega/pravega/pull/5099", "timeline": [{"oid": "c01acc4c732c1881895887de6ad76aca11fbc02d", "url": "https://github.com/pravega/pravega/commit/c01acc4c732c1881895887de6ad76aca11fbc02d", "message": "Integration test with multiple containers.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-25T03:12:18Z", "type": "commit"}, {"oid": "a5b59e2b4f5b32690fef7e68c1995a4efe5fbdd9", "url": "https://github.com/pravega/pravega/commit/a5b59e2b4f5b32690fef7e68c1995a4efe5fbdd9", "message": "Adding DR integration test with Transactional Writer.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-25T07:04:29Z", "type": "commit"}, {"oid": "1be7b9cc66f2bccfc5fadd7a9df1a5dbf5e52aa8", "url": "https://github.com/pravega/pravega/commit/1be7b9cc66f2bccfc5fadd7a9df1a5dbf5e52aa8", "message": "Updating.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-25T07:42:19Z", "type": "commit"}, {"oid": "e5f7806d2a402e23485a23a3d136c91bca5f8ac3", "url": "https://github.com/pravega/pravega/commit/e5f7806d2a402e23485a23a3d136c91bca5f8ac3", "message": "Changing serializer.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-25T08:54:52Z", "type": "commit"}, {"oid": "bf6b7df145818463df4355a6543c465772df2df0", "url": "https://github.com/pravega/pravega/commit/bf6b7df145818463df4355a6543c465772df2df0", "message": "Catch StreamSegmentNotExists exception on transational writer segments.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-25T17:11:40Z", "type": "commit"}, {"oid": "8a62b16f0c20d2c1b212f0fa7ea08da377982fea", "url": "https://github.com/pravega/pravega/commit/8a62b16f0c20d2c1b212f0fa7ea08da377982fea", "message": "Updating Javadoc.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-25T18:59:16Z", "type": "commit"}, {"oid": "9a49c1f2f0f68baed9e56779b7d3b24074a3a0ad", "url": "https://github.com/pravega/pravega/commit/9a49c1f2f0f68baed9e56779b7d3b24074a3a0ad", "message": "Updating.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-25T19:18:07Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ4Nzg3Mw==", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r479487873", "bodyText": "Instead of duplicating code , please extract out method that takes two parameters - number of containers and boolean for whether or not to use transactions.\nGenerally try to follow the DRY (Don't Repeat Yourself)  principle by extracting common functionality in smaller methods,", "author": "sachin-j-joshi", "createdAt": "2020-08-28T19:10:50Z", "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -423,8 +435,312 @@ public void testDurableDataLogFail() throws Exception {\n         log.info(\"Segments have been recovered.\");\n \n         // Start a new segment store and controller\n-        this.segmentStoreStarter = startSegmentStore(this.storageFactory, this.dataLogFactory);\n-        controllerStarter = startController(this.bookKeeperStarter.bkPort, this.segmentStoreStarter.servicePort);\n+        segmentStoreStarter = startSegmentStore(this.storageFactory, this.dataLogFactory, containerCount);\n+        controllerStarter = startController(this.bookKeeperStarter.bkPort, segmentStoreStarter.servicePort, containerCount);\n+        log.info(\"Started segment store and controller again.\");\n+\n+        connectionFactory = new SocketConnectionFactoryImpl(ClientConfig.builder()\n+                .controllerURI(controllerStarter.controllerURI).build());\n+        clientFactory = new ClientFactoryImpl(SCOPE, controllerStarter.controller, connectionFactory);\n+        readerGroupManager = new ReaderGroupManagerImpl(SCOPE, controllerStarter.controller, clientFactory);\n+\n+        // Try creating the same segments again with the new controller\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM1);\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM2);\n+\n+        // Try reading all events again\n+        readAllEvents(STREAM1, clientFactory, readerGroupManager, \"RG\" + RANDOM.nextInt(Integer.MAX_VALUE),\n+                \"R\" + RANDOM.nextInt(Integer.MAX_VALUE));\n+        readAllEvents(STREAM2, clientFactory, readerGroupManager, \"RG\" + RANDOM.nextInt(Integer.MAX_VALUE),\n+                \"R\" + RANDOM.nextInt(Integer.MAX_VALUE));\n+        log.info(\"Read all events again to verify that segments were recovered.\");\n+    }\n+\n+    /**\n+     * Tests the data recovery scenario with multiple segment containers. Segments recovery is attained using multiple\n+     * debug segment containers as well.\n+     *  What test does, step by step:\n+     *  1. Starts Pravega locally with just 4 segment containers.\n+     *  2. Writes 300 events to two different segments.\n+     *  3. Waits for all segments created to be flushed to the long term storage.\n+     *  4. Shuts down the controller, segment store and bookeeper/zookeeper.\n+     *  5. Deletes container metadata segment and its attribute segment from the old LTS.\n+     *  5. Starts 4 debug segment containers using a new bookeeper/zookeeper and the old LTS.\n+     *  6. Re-creates the container metadata segment in Tier1 and let's it flushed to the LTS.\n+     *  7. Starts segment store and controller.\n+     *  8. Reads all 600 events again.\n+     * @throws Exception    In case of an exception occurred while execution.\n+     */\n+    @Test(timeout = 180000)\n+    public void testDurableDataLogFailRecoveryMultipleContainers() throws Exception {\n+        int instanceId = 0;\n+        int containerCount = 4;\n+        // Creating a long term storage only once here.\n+        this.storageFactory = new InMemoryStorageFactory(executorService());\n+        log.info(\"Created a long term storage.\");\n+\n+        // Start a new BK & ZK, segment store and controller\n+        this.bookKeeperStarter = setUpNewBK(instanceId++);\n+        @Cleanup\n+        SegmentStoreStarter segmentStoreStarter = startSegmentStore(this.storageFactory, null, containerCount);\n+        @Cleanup\n+        ControllerStarter controllerStarter = startController(this.bookKeeperStarter.bkPort, segmentStoreStarter.servicePort,\n+                containerCount);\n+\n+        // Create two streams for writing data onto two different segments\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM1);\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM2);\n+        log.info(\"Created two streams.\");\n+\n+        @Cleanup\n+        ConnectionFactory connectionFactory = new SocketConnectionFactoryImpl(ClientConfig.builder()\n+                .controllerURI(controllerStarter.controllerURI).build());\n+        @Cleanup\n+        ClientFactoryImpl clientFactory = new ClientFactoryImpl(SCOPE, controllerStarter.controller, connectionFactory);\n+        @Cleanup\n+        ReaderGroupManager readerGroupManager = new ReaderGroupManagerImpl(SCOPE, controllerStarter.controller, clientFactory);\n+\n+        log.info(\"Writing events on to stream: {}\", STREAM1);\n+        writeEvents(STREAM1, clientFactory); // write 300 events on one segment", "originalCommit": "9a49c1f2f0f68baed9e56779b7d3b24074a3a0ad", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTI3MTk4Ng==", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r481271986", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-09-01T16:19:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ4Nzg3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ4ODI3MA==", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r479488270", "bodyText": "take a boolean parameter for whether to use transactions or not.", "author": "sachin-j-joshi", "createdAt": "2020-08-28T19:11:47Z", "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -423,8 +435,312 @@ public void testDurableDataLogFail() throws Exception {\n         log.info(\"Segments have been recovered.\");\n \n         // Start a new segment store and controller\n-        this.segmentStoreStarter = startSegmentStore(this.storageFactory, this.dataLogFactory);\n-        controllerStarter = startController(this.bookKeeperStarter.bkPort, this.segmentStoreStarter.servicePort);\n+        segmentStoreStarter = startSegmentStore(this.storageFactory, this.dataLogFactory, containerCount);\n+        controllerStarter = startController(this.bookKeeperStarter.bkPort, segmentStoreStarter.servicePort, containerCount);\n+        log.info(\"Started segment store and controller again.\");\n+\n+        connectionFactory = new SocketConnectionFactoryImpl(ClientConfig.builder()\n+                .controllerURI(controllerStarter.controllerURI).build());\n+        clientFactory = new ClientFactoryImpl(SCOPE, controllerStarter.controller, connectionFactory);\n+        readerGroupManager = new ReaderGroupManagerImpl(SCOPE, controllerStarter.controller, clientFactory);\n+\n+        // Try creating the same segments again with the new controller\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM1);\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM2);\n+\n+        // Try reading all events again\n+        readAllEvents(STREAM1, clientFactory, readerGroupManager, \"RG\" + RANDOM.nextInt(Integer.MAX_VALUE),\n+                \"R\" + RANDOM.nextInt(Integer.MAX_VALUE));\n+        readAllEvents(STREAM2, clientFactory, readerGroupManager, \"RG\" + RANDOM.nextInt(Integer.MAX_VALUE),\n+                \"R\" + RANDOM.nextInt(Integer.MAX_VALUE));\n+        log.info(\"Read all events again to verify that segments were recovered.\");\n+    }\n+\n+    /**\n+     * Tests the data recovery scenario with multiple segment containers. Segments recovery is attained using multiple\n+     * debug segment containers as well.\n+     *  What test does, step by step:\n+     *  1. Starts Pravega locally with just 4 segment containers.\n+     *  2. Writes 300 events to two different segments.\n+     *  3. Waits for all segments created to be flushed to the long term storage.\n+     *  4. Shuts down the controller, segment store and bookeeper/zookeeper.\n+     *  5. Deletes container metadata segment and its attribute segment from the old LTS.\n+     *  5. Starts 4 debug segment containers using a new bookeeper/zookeeper and the old LTS.\n+     *  6. Re-creates the container metadata segment in Tier1 and let's it flushed to the LTS.\n+     *  7. Starts segment store and controller.\n+     *  8. Reads all 600 events again.\n+     * @throws Exception    In case of an exception occurred while execution.\n+     */\n+    @Test(timeout = 180000)\n+    public void testDurableDataLogFailRecoveryMultipleContainers() throws Exception {\n+        int instanceId = 0;\n+        int containerCount = 4;\n+        // Creating a long term storage only once here.\n+        this.storageFactory = new InMemoryStorageFactory(executorService());\n+        log.info(\"Created a long term storage.\");\n+\n+        // Start a new BK & ZK, segment store and controller\n+        this.bookKeeperStarter = setUpNewBK(instanceId++);\n+        @Cleanup\n+        SegmentStoreStarter segmentStoreStarter = startSegmentStore(this.storageFactory, null, containerCount);\n+        @Cleanup\n+        ControllerStarter controllerStarter = startController(this.bookKeeperStarter.bkPort, segmentStoreStarter.servicePort,\n+                containerCount);\n+\n+        // Create two streams for writing data onto two different segments\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM1);\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM2);\n+        log.info(\"Created two streams.\");\n+\n+        @Cleanup\n+        ConnectionFactory connectionFactory = new SocketConnectionFactoryImpl(ClientConfig.builder()\n+                .controllerURI(controllerStarter.controllerURI).build());\n+        @Cleanup\n+        ClientFactoryImpl clientFactory = new ClientFactoryImpl(SCOPE, controllerStarter.controller, connectionFactory);\n+        @Cleanup\n+        ReaderGroupManager readerGroupManager = new ReaderGroupManagerImpl(SCOPE, controllerStarter.controller, clientFactory);\n+\n+        log.info(\"Writing events on to stream: {}\", STREAM1);\n+        writeEvents(STREAM1, clientFactory); // write 300 events on one segment\n+        log.info(\"Writing events on to stream: {}\", STREAM2);\n+        writeEvents(STREAM2, clientFactory); // write 300 events on other segment\n+\n+        // Verify events write by reading them.\n+        readAllEvents(STREAM1, clientFactory, readerGroupManager, \"RG\" + RANDOM.nextInt(Integer.MAX_VALUE),\n+                \"R\" + RANDOM.nextInt(Integer.MAX_VALUE));\n+        readAllEvents(STREAM2, clientFactory, readerGroupManager, \"RG\" + RANDOM.nextInt(Integer.MAX_VALUE),\n+                \"R\" + RANDOM.nextInt(Integer.MAX_VALUE));\n+        log.info(\"Verified that events were written, by reading them.\");\n+\n+        readerGroupManager.close();\n+        clientFactory.close();\n+\n+        controllerStarter.close(); // Shut down the controller\n+\n+        // Get names of all the segments created.\n+        ConcurrentHashMap<String, Boolean> allSegments = segmentStoreStarter.segmentsTracker.getSegments();\n+        log.info(\"No. of segments created = {}\", allSegments.size());\n+\n+        // Get the long term storage from the running pravega instance\n+        @Cleanup\n+        Storage storage = new AsyncStorageWrapper(new RollingStorage(this.storageFactory.createSyncStorage(),\n+                new SegmentRollingPolicy(DEFAULT_ROLLING_SIZE)), executorService());\n+\n+        // wait for all segments to be flushed to the long term storage.\n+        waitForSegmentsInStorage(allSegments.keySet(), segmentStoreStarter.segmentsTracker, storage)\n+                .get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        segmentStoreStarter.close(); // Shutdown SegmentStore\n+        log.info(\"Segment Store Shutdown\");\n+\n+        this.bookKeeperStarter.close(); // Shutdown BookKeeper & ZooKeeper\n+        this.bookKeeperStarter = null;\n+        log.info(\"BookKeeper & ZooKeeper shutdown\");\n+\n+        // start a new BookKeeper and ZooKeeper.\n+        this.bookKeeperStarter = setUpNewBK(instanceId++);\n+        this.dataLogFactory = new BookKeeperLogFactory(this.bookKeeperStarter.bkConfig.get(), this.bookKeeperStarter.zkClient.get(),\n+                executorService());\n+        this.dataLogFactory.initialize();\n+        log.info(\"Started a new BookKeeper and ZooKeeper.\");\n+\n+        // Create the environment for DebugSegmentContainer.\n+        @Cleanup\n+        DebugStreamSegmentContainerTests.TestContext context = DebugStreamSegmentContainerTests.createContext(executorService());\n+        // Use dataLogFactory from new BK instance.\n+        OperationLogFactory localDurableLogFactory = new DurableLogFactory(DURABLE_LOG_CONFIG, this.dataLogFactory,\n+                executorService());\n+\n+        // Start a debug segment container corresponding to the given container Id and put it in the Hashmap with the Id.\n+        Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainerMap = new HashMap<>();\n+\n+        // Create a debug segment container instances using a new dataLog and old storage.\n+        for (int containerId = 0; containerId < containerCount; containerId++) {\n+            DebugStreamSegmentContainerTests.MetadataCleanupContainer debugStreamSegmentContainer = new\n+                    DebugStreamSegmentContainerTests.MetadataCleanupContainer(containerId, CONTAINER_CONFIG, localDurableLogFactory,\n+                    context.readIndexFactory, context.attributeIndexFactory, context.writerFactory, this.storageFactory,\n+                    context.getDefaultExtensions(), executorService());\n+\n+            Services.startAsync(debugStreamSegmentContainer, executorService()).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            debugStreamSegmentContainerMap.put(containerId, debugStreamSegmentContainer);\n+\n+            // Delete container metadata segment and attributes index segment corresponding to the container Id from the long term storage\n+            ContainerRecoveryUtils.deleteMetadataAndAttributeSegments(storage, containerId).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+        }\n+\n+        // List segments from storage and recover them using debug segment container instance.\n+        ContainerRecoveryUtils.recoverAllSegments(storage, debugStreamSegmentContainerMap, executorService());\n+\n+        for (int containerId = 0; containerId < containerCount; containerId++) {\n+            // Wait for metadata segment to be flushed to LTS\n+            String metadataSegmentName = NameUtils.getMetadataSegmentName(containerId);\n+            waitForSegmentsInStorage(Collections.singleton(metadataSegmentName), debugStreamSegmentContainerMap.get(containerId),\n+                    storage)\n+                    .get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            log.info(\"Long term storage has been update with a new container metadata segment.\");\n+\n+            // Stop the debug segment container\n+            Services.stopAsync(debugStreamSegmentContainerMap.get(containerId), executorService()).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            debugStreamSegmentContainerMap.get(containerId).close();\n+        }\n+        log.info(\"Segments have been recovered.\");\n+\n+        this.dataLogFactory.close();\n+        // Start a new segment store and controller\n+        segmentStoreStarter = startSegmentStore(this.storageFactory, this.dataLogFactory, containerCount);\n+        controllerStarter = startController(this.bookKeeperStarter.bkPort, segmentStoreStarter.servicePort, containerCount);\n+        log.info(\"Started segment store and controller again.\");\n+\n+        connectionFactory = new SocketConnectionFactoryImpl(ClientConfig.builder()\n+                .controllerURI(controllerStarter.controllerURI).build());\n+        clientFactory = new ClientFactoryImpl(SCOPE, controllerStarter.controller, connectionFactory);\n+        readerGroupManager = new ReaderGroupManagerImpl(SCOPE, controllerStarter.controller, clientFactory);\n+\n+        // Try creating the same segments again with the new controller\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM1);\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM2);\n+\n+        // Try reading all events again\n+        readAllEvents(STREAM1, clientFactory, readerGroupManager, \"RG\" + RANDOM.nextInt(Integer.MAX_VALUE),\n+                \"R\" + RANDOM.nextInt(Integer.MAX_VALUE));\n+        readAllEvents(STREAM2, clientFactory, readerGroupManager, \"RG\" + RANDOM.nextInt(Integer.MAX_VALUE),\n+                \"R\" + RANDOM.nextInt(Integer.MAX_VALUE));\n+        log.info(\"Read all events again to verify that segments were recovered.\");\n+    }\n+\n+    /**\n+     * Tests the data recovery scenario with transactional writer. Events are written using a transactional writer.\n+     *  What test does, step by step:\n+     *  1. Starts Pravega locally with just 4 segment containers.\n+     *  2. Writes 300 events to two different segments.\n+     *  3. Waits for all segments created to be flushed to the long term storage.\n+     *  4. Shuts down the controller, segment store and bookeeper/zookeeper.\n+     *  5. Deletes container metadata segment and its attribute segment from the old LTS.\n+     *  5. Starts 4 debug segment containers using a new bookeeper/zookeeper and the old LTS.\n+     *  6. Re-creates the container metadata segment in Tier1 and let's it flushed to the LTS.\n+     *  7. Starts segment store and controller.\n+     *  8. Reads all 600 events again.\n+     * @throws Exception    In case of an exception occurred while execution.\n+     */\n+    @Test(timeout = 180000)\n+    public void testDurableDataLogFailRecoveryTransactionalWriter() throws Exception {\n+        int instanceId = 0;\n+        int containerCount = 4;\n+\n+        // Creating a long term storage only once here.\n+        this.storageFactory = new InMemoryStorageFactory(executorService());\n+        log.info(\"Created a long term storage.\");\n+\n+        // Start a new BK & ZK, segment store and controller\n+        this.bookKeeperStarter = setUpNewBK(instanceId++);\n+        @Cleanup\n+        SegmentStoreStarter segmentStoreStarter = startSegmentStore(this.storageFactory, null, containerCount);\n+        @Cleanup\n+        ControllerStarter controllerStarter = startController(this.bookKeeperStarter.bkPort, segmentStoreStarter.servicePort,\n+                containerCount);\n+\n+        // Create two streams for writing data onto two different segments\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM1);\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM2);\n+        log.info(\"Created two streams.\");\n+\n+        @Cleanup\n+        ConnectionFactory connectionFactory = new SocketConnectionFactoryImpl(ClientConfig.builder()\n+                .controllerURI(controllerStarter.controllerURI).build());\n+        @Cleanup\n+        ClientFactoryImpl clientFactory = new ClientFactoryImpl(SCOPE, controllerStarter.controller, connectionFactory);\n+        @Cleanup\n+        ReaderGroupManager readerGroupManager = new ReaderGroupManagerImpl(SCOPE, controllerStarter.controller, clientFactory);\n+\n+        log.info(\"Writing events on to stream: {}\", STREAM1);\n+        writeTransactionalEvents(STREAM1, clientFactory); // write 300 events on one segment", "originalCommit": "9a49c1f2f0f68baed9e56779b7d3b24074a3a0ad", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTI3MjA1MQ==", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r481272051", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-09-01T16:19:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ4ODI3MA=="}], "type": "inlineReview"}, {"oid": "e93b0b35a278eb98aeb5efcd633fabb3c31227bb", "url": "https://github.com/pravega/pravega/commit/e93b0b35a278eb98aeb5efcd633fabb3c31227bb", "message": "Avoiding repetition of code.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-09-01T16:02:30Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQyMDg0MQ==", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r481420841", "bodyText": "replace magic number with const.", "author": "sachin-j-joshi", "createdAt": "2020-09-01T20:46:11Z", "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -469,6 +543,21 @@ private void writeEvents(String streamName, ClientFactoryImpl clientFactory) {\n         writer.close();\n     }\n \n+    private void writeTransactionalEvents(String streamName, ClientFactoryImpl clientFactory) throws TxnFailedException {\n+        EventWriterConfig writerConfig = EventWriterConfig.builder().transactionTimeoutTime(10000).build();", "originalCommit": "e93b0b35a278eb98aeb5efcd633fabb3c31227bb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTc5NDUwMw==", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r481794503", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-09-02T06:43:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQyMDg0MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQyMjYzMA==", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r481422630", "bodyText": "Do we need this method ?\nwhy not just call new SegmentStoreStarter(storageFactory, dataLogFactory, containerCount);  directly where it is needed?", "author": "sachin-j-joshi", "createdAt": "2020-09-01T20:49:34Z", "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -247,8 +236,9 @@ public void close() throws Exception {\n         }\n     }\n \n-    SegmentStoreStarter startSegmentStore(StorageFactory storageFactory, BookKeeperLogFactory dataLogFactory) throws DurableDataLogException {\n-        return new SegmentStoreStarter(storageFactory, dataLogFactory);\n+    SegmentStoreStarter startSegmentStore(StorageFactory storageFactory, BookKeeperLogFactory dataLogFactory, int containerCount)", "originalCommit": "e93b0b35a278eb98aeb5efcd633fabb3c31227bb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTc5NDU5NQ==", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r481794595", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-09-02T06:43:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQyMjYzMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQyMjk3OA==", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r481422978", "bodyText": "Do we need this method ?\nwhy not just call new ControllerStarter(bkPort, servicePort, containerCount)directly where it is needed?", "author": "sachin-j-joshi", "createdAt": "2020-09-01T20:50:16Z", "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -287,8 +282,8 @@ public void close() {\n         }\n     }\n \n-    ControllerStarter startController(int bkPort, int servicePort) throws InterruptedException {\n-        return new ControllerStarter(bkPort, servicePort);\n+    ControllerStarter startController(int bkPort, int servicePort, int containerCount) throws InterruptedException {\n+        return new ControllerStarter(bkPort, servicePort, containerCount);", "originalCommit": "e93b0b35a278eb98aeb5efcd633fabb3c31227bb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTc5NDY5NQ==", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r481794695", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-09-02T06:43:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQyMjk3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQyMzIwNg==", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r481423206", "bodyText": "nice!", "author": "sachin-j-joshi", "createdAt": "2020-09-01T20:50:40Z", "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -314,18 +309,86 @@ public void close() throws Exception {\n         }\n     }\n \n+    /**\n+     * Tests the data recovery scenario with just one segment container. Segments recovery is attained using just one\n+     * debug segment container.\n+     *  What test does, step by step:\n+     *  1. Starts Pravega locally with just one segment container.\n+     *  2. Writes 300 events to two different segments.\n+     *  3. Waits for all segments created to be flushed to the long term storage.\n+     *  4. Shuts down the controller, segment store and bookeeper/zookeeper.\n+     *  5. Deletes container metadata segment and its attribute segment from the old LTS.\n+     *  5. Starts just one debug segment container using a new bookeeper/zookeeper and the old LTS.\n+     *  6. Re-creates the container metadata segment in Tier1 and let's it flushed to the LTS.\n+     *  7. Starts segment store and controller.\n+     *  8. Reads all 600 events again.\n+     * @throws Exception    In case of an exception occurred while execution.\n+     */\n+    @Test(timeout = 180000)\n+    public void testDurableDataLogFailRecoverySingleContainer() throws Exception {\n+        testRecovery(1, false);", "originalCommit": "e93b0b35a278eb98aeb5efcd633fabb3c31227bb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQyMzQxMA==", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r481423410", "bodyText": "nice!", "author": "sachin-j-joshi", "createdAt": "2020-09-01T20:51:03Z", "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -340,10 +403,17 @@ public void testDurableDataLogFail() throws Exception {\n         @Cleanup\n         ReaderGroupManager readerGroupManager = new ReaderGroupManagerImpl(SCOPE, controllerStarter.controller, clientFactory);\n \n-        log.info(\"Writing events on to stream: {}\", STREAM1);\n-        writeEvents(STREAM1, clientFactory); // write 300 events on one segment\n-        log.info(\"Writing events on to stream: {}\", STREAM2);\n-        writeEvents(STREAM2, clientFactory); // write 300 events on other segment\n+        if (withTransaction) {", "originalCommit": "e93b0b35a278eb98aeb5efcd633fabb3c31227bb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQzMjIwNg==", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r481432206", "bodyText": "make final wherever possible.", "author": "sachin-j-joshi", "createdAt": "2020-09-01T21:08:00Z", "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -149,7 +144,6 @@\n \n     private StorageFactory storageFactory;", "originalCommit": "e93b0b35a278eb98aeb5efcd633fabb3c31227bb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTc5NDgxNQ==", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r481794815", "bodyText": "Made.", "author": "ManishKumarKeshri", "createdAt": "2020-09-02T06:43:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQzMjIwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQzMjk3NA==", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r481432974", "bodyText": "try to see if we can break it into small methods", "author": "sachin-j-joshi", "createdAt": "2020-09-01T21:09:34Z", "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -395,36 +464,41 @@ public void testDurableDataLogFail() throws Exception {\n         // Start a debug segment container corresponding to the given container Id and put it in the Hashmap with the Id.\n         Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainerMap = new HashMap<>();\n \n-        // Create a debug segment container instance using a new dataLog and old storage.\n-        DebugStreamSegmentContainerTests.MetadataCleanupContainer debugStreamSegmentContainer = new\n-                DebugStreamSegmentContainerTests.MetadataCleanupContainer(CONTAINER_ID, CONTAINER_CONFIG, localDurableLogFactory,\n-                context.readIndexFactory, context.attributeIndexFactory, context.writerFactory, this.storageFactory,\n-                context.getDefaultExtensions(), executorService());\n+        // Create a debug segment container instances using a new dataLog and old storage.\n+        for (int containerId = 0; containerId < containerCount; containerId++) {\n+            DebugStreamSegmentContainerTests.MetadataCleanupContainer debugStreamSegmentContainer = new\n+                    DebugStreamSegmentContainerTests.MetadataCleanupContainer(containerId, CONTAINER_CONFIG, localDurableLogFactory,\n+                    context.readIndexFactory, context.attributeIndexFactory, context.writerFactory, this.storageFactory,\n+                    context.getDefaultExtensions(), executorService());\n \n-        Services.startAsync(debugStreamSegmentContainer, executorService()).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n-        debugStreamSegmentContainerMap.put(CONTAINER_ID, debugStreamSegmentContainer);\n+            Services.startAsync(debugStreamSegmentContainer, executorService()).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            debugStreamSegmentContainerMap.put(containerId, debugStreamSegmentContainer);\n \n-        // Delete container metadata segment and attributes index segment corresponding to the container Id from the long term storage\n-        ContainerRecoveryUtils.deleteMetadataAndAttributeSegments(storage, CONTAINER_ID).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            // Delete container metadata segment and attributes index segment corresponding to the container Id from the long term storage\n+            ContainerRecoveryUtils.deleteMetadataAndAttributeSegments(storage, containerId).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+        }", "originalCommit": "e93b0b35a278eb98aeb5efcd633fabb3c31227bb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTc5NTY0NA==", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r481795644", "bodyText": "Broke it into few.", "author": "ManishKumarKeshri", "createdAt": "2020-09-02T06:44:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQzMjk3NA=="}], "type": "inlineReview"}, {"oid": "1ca7a160970b4abaae24c51483955bffcfa80aff", "url": "https://github.com/pravega/pravega/commit/1ca7a160970b4abaae24c51483955bffcfa80aff", "message": "Fixing comments.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-09-02T06:36:00Z", "type": "commit"}, {"oid": "f96814758a5c208acca40b401f50be25b7d68db3", "url": "https://github.com/pravega/pravega/commit/f96814758a5c208acca40b401f50be25b7d68db3", "message": "Updating transaction timeout.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-09-02T06:38:59Z", "type": "commit"}, {"oid": "1bbd94f83515c323eb7e1eed766ec81bb325dad9", "url": "https://github.com/pravega/pravega/commit/1bbd94f83515c323eb7e1eed766ec81bb325dad9", "message": "Fixing comments.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-09-02T22:38:58Z", "type": "commit"}, {"oid": "d23f85385cfad61df9777daf399ffa6ad3cc2605", "url": "https://github.com/pravega/pravega/commit/d23f85385cfad61df9777daf399ffa6ad3cc2605", "message": "Updating comment.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-09-02T22:44:34Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjYwNjQyNA==", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r482606424", "bodyText": "what happens when there are exceptions here ?\nLet's make sure test exits cleanly.\nI suggest we use\ntry {\n} catch (Exception e) {\n   this.close()\n}", "author": "sachin-j-joshi", "createdAt": "2020-09-02T23:56:23Z", "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -175,30 +159,27 @@ protected int getThreadPoolSize() {\n         return 100;\n     }\n \n-    BookKeeperStarter setUpNewBK(int instanceId) throws Exception {\n-        return new BookKeeperStarter(instanceId);\n-    }\n-\n     /**\n      * Sets up a new BookKeeper & ZooKeeper.\n      */\n-    private static class BookKeeperStarter implements AutoCloseable {\n-        private final int bookieCount = 1;\n-        private AtomicReference<BookKeeperConfig> bkConfig = new AtomicReference<>();\n-        private AtomicReference<CuratorFramework> zkClient = new AtomicReference<>();\n-        private BookKeeperServiceRunner bookKeeperServiceRunner;\n-        private AtomicReference<BookKeeperServiceRunner> bkService = new AtomicReference<>();\n-        private int bkPort;\n-\n-        BookKeeperStarter(int instanceId) throws Exception {\n+    private static class BookKeeperRunner implements AutoCloseable {\n+        private final int bkPort;\n+        private final BookKeeperServiceRunner bookKeeperServiceRunner;\n+        private final AtomicReference<BookKeeperConfig> bkConfig = new AtomicReference<>();\n+        private final AtomicReference<CuratorFramework> zkClient = new AtomicReference<>();\n+        private final AtomicReference<BookKeeperServiceRunner> bkService = new AtomicReference<>();\n+\n+        BookKeeperRunner(int instanceId, int bookieCount) throws Exception {", "originalCommit": "d23f85385cfad61df9777daf399ffa6ad3cc2605", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjcxNTExOA==", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r482715118", "bodyText": "this.close() also throws Exception.", "author": "ManishKumarKeshri", "createdAt": "2020-09-03T05:37:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjYwNjQyNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzAzMjEyNA==", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r483032124", "bodyText": "Which is okay. Goal is to call close so that we correctly call close  on bk and process.\nThis also means we need to fix close so that it doesn't leak.", "author": "sachin-j-joshi", "createdAt": "2020-09-03T14:41:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjYwNjQyNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzExMTE3NA==", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r483111174", "bodyText": "Ok. Calling close if bookKeeper start fails.", "author": "ManishKumarKeshri", "createdAt": "2020-09-03T16:35:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjYwNjQyNA=="}], "type": "inlineReview"}, {"oid": "646fd48d74d3d6df39f88a4365c1911621e8883e", "url": "https://github.com/pravega/pravega/commit/646fd48d74d3d6df39f88a4365c1911621e8883e", "message": "Handling bookKeeper start exception.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-09-03T16:32:53Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzE3MjgzOQ==", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r483172839", "bodyText": "please rethrow exception otherwise it will just continue as if nothing happened.", "author": "sachin-j-joshi", "createdAt": "2020-09-03T18:25:28Z", "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -175,32 +159,33 @@ protected int getThreadPoolSize() {\n         return 100;\n     }\n \n-    BookKeeperStarter setUpNewBK(int instanceId) throws Exception {\n-        return new BookKeeperStarter(instanceId);\n-    }\n-\n     /**\n      * Sets up a new BookKeeper & ZooKeeper.\n      */\n-    private static class BookKeeperStarter implements AutoCloseable {\n-        private final int bookieCount = 1;\n-        private AtomicReference<BookKeeperConfig> bkConfig = new AtomicReference<>();\n-        private AtomicReference<CuratorFramework> zkClient = new AtomicReference<>();\n-        private BookKeeperServiceRunner bookKeeperServiceRunner;\n-        private AtomicReference<BookKeeperServiceRunner> bkService = new AtomicReference<>();\n-        private int bkPort;\n-\n-        BookKeeperStarter(int instanceId) throws Exception {\n+    private static class BookKeeperRunner implements AutoCloseable {\n+        private final int bkPort;\n+        private final BookKeeperServiceRunner bookKeeperServiceRunner;\n+        private final AtomicReference<BookKeeperConfig> bkConfig = new AtomicReference<>();\n+        private final AtomicReference<CuratorFramework> zkClient = new AtomicReference<>();\n+        private final AtomicReference<BookKeeperServiceRunner> bkService = new AtomicReference<>();\n+\n+        BookKeeperRunner(int instanceId, int bookieCount) throws Exception {\n             bkPort = TestUtils.getAvailableListenPort();\n-            val bookiePort = new ArrayList<>(Arrays.asList(TestUtils.getAvailableListenPort()));\n-\n+            val bookiePorts = new ArrayList<Integer>();\n+            for (int i = 0; i < bookieCount; i++) {\n+                bookiePorts.add(TestUtils.getAvailableListenPort());\n+            }\n             this.bookKeeperServiceRunner = BookKeeperServiceRunner.builder()\n                     .startZk(true)\n                     .zkPort(bkPort)\n                     .ledgersPath(\"/pravega/bookkeeper/ledgers\")\n-                    .bookiePorts(bookiePort)\n+                    .bookiePorts(bookiePorts)\n                     .build();\n-            this.bookKeeperServiceRunner.startAll();\n+            try {\n+                this.bookKeeperServiceRunner.startAll();\n+            } catch (Exception e) {\n+                this.close();", "originalCommit": "646fd48d74d3d6df39f88a4365c1911621e8883e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzE3MzQzMQ==", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r483173431", "bodyText": "we need similar try cache block around this.zkClient.get().start(); as well", "author": "sachin-j-joshi", "createdAt": "2020-09-03T18:26:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzE3MjgzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzE4NDcxOQ==", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r483184719", "bodyText": "sure. Throwing it now. Though, this.zkClient.get().start() doesn't throw any exception.", "author": "ManishKumarKeshri", "createdAt": "2020-09-03T18:45:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzE3MjgzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzE4OTI1OQ==", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r483189259", "bodyText": "ok.", "author": "sachin-j-joshi", "createdAt": "2020-09-03T18:54:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzE3MjgzOQ=="}], "type": "inlineReview"}, {"oid": "e062dcfe9966e8296e6341719d7d089452805906", "url": "https://github.com/pravega/pravega/commit/e062dcfe9966e8296e6341719d7d089452805906", "message": "Throwing exception caught.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-09-03T18:45:58Z", "type": "commit"}]}