{"pr_number": 4552, "pr_title": "[PDS-109527 FLUP] TimeLock Invariant Enforcement Part 1: Only One Leader Allowed", "pr_createdAt": "2020-02-05T20:26:09Z", "pr_url": "https://github.com/palantir/atlasdb/pull/4552", "timeline": [{"oid": "621f5f7766478d851aeb36efc949b12369ca9238", "url": "https://github.com/palantir/atlasdb/commit/621f5f7766478d851aeb36efc949b12369ca9238", "message": "Invariants", "committedDate": "2020-01-30T16:39:18Z", "type": "commit"}, {"oid": "05a665172a2cb7efcbe60f096b55289848214ea9", "url": "https://github.com/palantir/atlasdb/commit/05a665172a2cb7efcbe60f096b55289848214ea9", "message": "stash", "committedDate": "2020-02-04T21:34:14Z", "type": "commit"}, {"oid": "2314f1eedff796d9bebf94cb40ef907501481f96", "url": "https://github.com/palantir/atlasdb/commit/2314f1eedff796d9bebf94cb40ef907501481f96", "message": "Wire up check", "committedDate": "2020-02-05T11:25:27Z", "type": "commit"}, {"oid": "5bfc940bbca8a9c17832d234d7c7380137dfaf95", "url": "https://github.com/palantir/atlasdb/commit/5bfc940bbca8a9c17832d234d7c7380137dfaf95", "message": "Checkstyle", "committedDate": "2020-02-05T11:33:38Z", "type": "commit"}, {"oid": "64f884d8c7a6a24e6830c67a65657b1d87c68458", "url": "https://github.com/palantir/atlasdb/commit/64f884d8c7a6a24e6830c67a65657b1d87c68458", "message": "Switch to delegating model", "committedDate": "2020-02-05T13:56:21Z", "type": "commit"}, {"oid": "7aed4df64644be774052c6ff8cc70df5fa8f3018", "url": "https://github.com/palantir/atlasdb/commit/7aed4df64644be774052c6ff8cc70df5fa8f3018", "message": "Tests", "committedDate": "2020-02-05T18:30:30Z", "type": "commit"}, {"oid": "6a8d72f7392a1ea8ea36682ccee4e85d5fd9138e", "url": "https://github.com/palantir/atlasdb/commit/6a8d72f7392a1ea8ea36682ccee4e85d5fd9138e", "message": "Refactor", "committedDate": "2020-02-05T19:05:12Z", "type": "commit"}, {"oid": "1df297ede1602eda8c4fe77b99488a08eb3e429d", "url": "https://github.com/palantir/atlasdb/commit/1df297ede1602eda8c4fe77b99488a08eb3e429d", "message": "Add generated changelog entries", "committedDate": "2020-02-05T20:14:33Z", "type": "commit"}, {"oid": "46d4eadd2e8b9815f1b9374f7d7d489d57c36528", "url": "https://github.com/palantir/atlasdb/commit/46d4eadd2e8b9815f1b9374f7d7d489d57c36528", "message": "bugfix", "committedDate": "2020-02-05T20:21:47Z", "type": "commit"}, {"oid": "86c86dab09f06aa684755e4fa86b7310dd1c374b", "url": "https://github.com/palantir/atlasdb/commit/86c86dab09f06aa684755e4fa86b7310dd1c374b", "message": "Imports", "committedDate": "2020-02-05T20:27:50Z", "type": "commit"}, {"oid": "b97d147f2b23fdcf46b00676a6dcffd296f591ad", "url": "https://github.com/palantir/atlasdb/commit/b97d147f2b23fdcf46b00676a6dcffd296f591ad", "message": "Merge branch 'jkong/timelock-sanity-checker' of github.com:palantir/atlasdb into jkong/timelock-sanity-checker", "committedDate": "2020-02-05T20:28:22Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjMzOTUzMg==", "url": "https://github.com/palantir/atlasdb/pull/4552#discussion_r376339532", "bodyText": "Is this actually reachable under some conditions or is it to make IntelliJ happy?", "author": "gmaretic", "createdAt": "2020-02-07T11:15:21Z", "path": "timelock-agent/src/main/java/com/palantir/timelock/invariants/ServerKiller.java", "diffHunk": "@@ -0,0 +1,37 @@\n+/*\n+ * (c) Copyright 2020 Palantir Technologies Inc. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.palantir.timelock.invariants;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.palantir.logsafe.exceptions.SafeIllegalStateException;\n+\n+public final class ServerKiller {\n+    private static final Logger log = LoggerFactory.getLogger(ServerKiller.class);\n+\n+    private ServerKiller() {\n+        // no\n+    }\n+\n+    public static Error killMeNow(Throwable error) {\n+        log.error(\"Something bad happened and we can't continue safely, so we're preemptively killing the server.\",\n+                error);\n+        System.exit(1);\n+        throw new SafeIllegalStateException(\"We should have exited before we get to this point\", error);", "originalCommit": "b97d147f2b23fdcf46b00676a6dcffd296f591ad", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQxODU5OQ==", "url": "https://github.com/palantir/atlasdb/pull/4552#discussion_r376418599", "bodyText": "Don't think it's reachable: System.exit() should never return normally (it could throw a SecurityException but that will be propagated anyway)", "author": "jeremyk-91", "createdAt": "2020-02-07T14:29:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjMzOTUzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjM0MTA5NA==", "url": "https://github.com/palantir/atlasdb/pull/4552#discussion_r376341094", "bodyText": "Ah, so the TACs are single node clients, which will throw NCLEs when we request a timestamp if they are not leaders, correct?", "author": "gmaretic", "createdAt": "2020-02-07T11:19:34Z", "path": "timelock-agent/src/main/java/com/palantir/timelock/invariants/TimeLockActivityCheckerFactory.java", "diffHunk": "@@ -0,0 +1,69 @@\n+/*\n+ * (c) Copyright 2020 Palantir Technologies Inc. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.palantir.timelock.invariants;\n+\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import com.palantir.atlasdb.config.ImmutableServerListConfig;\n+import com.palantir.atlasdb.config.RemotingClientConfigs;\n+import com.palantir.atlasdb.config.ServerListConfig;\n+import com.palantir.atlasdb.factory.ServiceCreator;\n+import com.palantir.atlasdb.util.MetricsManager;\n+import com.palantir.conjure.java.api.config.service.UserAgent;\n+import com.palantir.lock.v2.TimelockRpcClient;\n+import com.palantir.timelock.config.TimeLockInstallConfiguration;\n+import com.palantir.timelock.paxos.PaxosRemotingUtils;\n+\n+public class TimeLockActivityCheckerFactory {\n+    private final TimeLockInstallConfiguration installConfiguration;\n+    private final MetricsManager metricsManager;\n+    private final UserAgent userAgent;\n+\n+    public TimeLockActivityCheckerFactory(\n+            TimeLockInstallConfiguration installConfiguration, MetricsManager metricsManager, UserAgent userAgent) {\n+        this.installConfiguration = installConfiguration;\n+        this.metricsManager = metricsManager;\n+        this.userAgent = userAgent;\n+    }\n+\n+    public List<TimeLockActivityChecker> getTimeLockActivityCheckers() {\n+        return installConfiguration.cluster()", "originalCommit": "b97d147f2b23fdcf46b00676a6dcffd296f591ad", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjM0NDQ1MQ==", "url": "https://github.com/palantir/atlasdb/pull/4552#discussion_r376344451", "bodyText": "just filter instead of map + filter", "author": "gmaretic", "createdAt": "2020-02-07T11:28:44Z", "path": "timelock-agent/src/main/java/com/palantir/timelock/invariants/NoSimultaneousServiceCheck.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * (c) Copyright 2020 Palantir Technologies Inc. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.palantir.timelock.invariants;\n+\n+import java.time.Duration;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Consumer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.util.concurrent.Uninterruptibles;\n+import com.palantir.atlasdb.timelock.paxos.Client;\n+import com.palantir.common.concurrent.PTExecutors;\n+import com.palantir.logsafe.SafeArg;\n+import com.palantir.timelock.TimeLockStatus;\n+import com.palantir.timelock.paxos.HealthCheckDigest;\n+\n+public final class NoSimultaneousServiceCheck {\n+    private static final Logger log = LoggerFactory.getLogger(NoSimultaneousServiceCheck.class);\n+\n+    private static final int REQUIRED_CONSECUTIVE_VIOLATIONS_BEFORE_FAIL = 5;\n+    private static final Duration BACKOFF = Duration.ofMillis(1337);\n+\n+    private final List<TimeLockActivityChecker> timeLockActivityCheckers;\n+    private final Consumer<String> failureMechanism;\n+    private final ExecutorService executorService;\n+\n+    @VisibleForTesting\n+    NoSimultaneousServiceCheck(\n+            List<TimeLockActivityChecker> timeLockActivityCheckers,\n+            Consumer<String> failureMechanism,\n+            ExecutorService executorService) {\n+        this.timeLockActivityCheckers = timeLockActivityCheckers;\n+        this.failureMechanism = failureMechanism;\n+        this.executorService = executorService;\n+    }\n+\n+    public static NoSimultaneousServiceCheck create(List<TimeLockActivityChecker> timeLockActivityCheckers) {\n+        ExecutorService executorService = PTExecutors.newSingleThreadExecutor(\n+                PTExecutors.newNamedThreadFactory(false));\n+        return new NoSimultaneousServiceCheck(timeLockActivityCheckers,\n+                client -> {\n+                    // TODO (jkong): Gather confidence and then change to ServerKiller, so that we ACTUALLY shoot\n+                    // ourselves in the head.\n+                    log.error(\"We observed that multiple services were consistently serving timestamps, for the\"\n+                            + \" client {}. This is potentially indicative of SEVERE DATA CORRUPTION, and should\"\n+                            + \" never happen in a correct TimeLock implementation. If you see this message, please\"\n+                            + \" check the frequency of leader elections on your stack: if they are very frequent,\"\n+                            + \" consider increasing the leader election timeout. Otherwise, please contact support -\"\n+                            + \" your stack may have been compromised\",\n+                            SafeArg.of(\"client\", client));\n+                },\n+                executorService);\n+    }\n+\n+    public void processHealthCheckDigest(HealthCheckDigest digest) {\n+        Set<Client> clientsWithMultipleLeaders = digest.statusesToClient().get(TimeLockStatus.MULTIPLE_LEADERS);\n+        if (clientsWithMultipleLeaders.isEmpty()) {\n+            return;\n+        }\n+\n+        log.info(\"Clients {} appear to have multiple leaders based on the leader ping health check. Scheduling\"\n+                + \" checks on these specific clients now.\", SafeArg.of(\"clients\", clientsWithMultipleLeaders));\n+        clientsWithMultipleLeaders.forEach(this::scheduleCheckOnSpecificClient);\n+    }\n+\n+    private void scheduleCheckOnSpecificClient(Client client) {\n+        executorService.submit(() -> {\n+            try {\n+                performCheckOnSpecificClientUnsafe(client);\n+            } catch (Exception e) {\n+                log.info(\"No-simultaneous service check failed, suppressing exception to allow future checks\", e);\n+            }\n+        });\n+    }\n+\n+    private void performCheckOnSpecificClientUnsafe(Client client) {\n+        // Only fail on repeated violations, since it is possible for there to be a leader election between checks that\n+        // could legitimately cause false positives if we failed after one such issue. However, given the number of\n+        // checks it is unlikely that *that* many elections would occur.\n+        for (int attempt = 1; attempt <= REQUIRED_CONSECUTIVE_VIOLATIONS_BEFORE_FAIL; attempt++) {\n+            long numberOfNodesServingTimestamps = timeLockActivityCheckers.stream()\n+                    .map(timeLockActivityChecker ->", "originalCommit": "b97d147f2b23fdcf46b00676a6dcffd296f591ad", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjM0NjMzOA==", "url": "https://github.com/palantir/atlasdb/pull/4552#discussion_r376346338", "bodyText": "Is this actually useful? We don't need to suppress because there are not scheduled. Also if something went wrong with TACs but we keep trying to check, we will never really figure out something is wrong", "author": "gmaretic", "createdAt": "2020-02-07T11:34:09Z", "path": "timelock-agent/src/main/java/com/palantir/timelock/invariants/NoSimultaneousServiceCheck.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * (c) Copyright 2020 Palantir Technologies Inc. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.palantir.timelock.invariants;\n+\n+import java.time.Duration;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Consumer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.util.concurrent.Uninterruptibles;\n+import com.palantir.atlasdb.timelock.paxos.Client;\n+import com.palantir.common.concurrent.PTExecutors;\n+import com.palantir.logsafe.SafeArg;\n+import com.palantir.timelock.TimeLockStatus;\n+import com.palantir.timelock.paxos.HealthCheckDigest;\n+\n+public final class NoSimultaneousServiceCheck {\n+    private static final Logger log = LoggerFactory.getLogger(NoSimultaneousServiceCheck.class);\n+\n+    private static final int REQUIRED_CONSECUTIVE_VIOLATIONS_BEFORE_FAIL = 5;\n+    private static final Duration BACKOFF = Duration.ofMillis(1337);\n+\n+    private final List<TimeLockActivityChecker> timeLockActivityCheckers;\n+    private final Consumer<String> failureMechanism;\n+    private final ExecutorService executorService;\n+\n+    @VisibleForTesting\n+    NoSimultaneousServiceCheck(\n+            List<TimeLockActivityChecker> timeLockActivityCheckers,\n+            Consumer<String> failureMechanism,\n+            ExecutorService executorService) {\n+        this.timeLockActivityCheckers = timeLockActivityCheckers;\n+        this.failureMechanism = failureMechanism;\n+        this.executorService = executorService;\n+    }\n+\n+    public static NoSimultaneousServiceCheck create(List<TimeLockActivityChecker> timeLockActivityCheckers) {\n+        ExecutorService executorService = PTExecutors.newSingleThreadExecutor(\n+                PTExecutors.newNamedThreadFactory(false));\n+        return new NoSimultaneousServiceCheck(timeLockActivityCheckers,\n+                client -> {\n+                    // TODO (jkong): Gather confidence and then change to ServerKiller, so that we ACTUALLY shoot\n+                    // ourselves in the head.\n+                    log.error(\"We observed that multiple services were consistently serving timestamps, for the\"\n+                            + \" client {}. This is potentially indicative of SEVERE DATA CORRUPTION, and should\"\n+                            + \" never happen in a correct TimeLock implementation. If you see this message, please\"\n+                            + \" check the frequency of leader elections on your stack: if they are very frequent,\"\n+                            + \" consider increasing the leader election timeout. Otherwise, please contact support -\"\n+                            + \" your stack may have been compromised\",\n+                            SafeArg.of(\"client\", client));\n+                },\n+                executorService);\n+    }\n+\n+    public void processHealthCheckDigest(HealthCheckDigest digest) {\n+        Set<Client> clientsWithMultipleLeaders = digest.statusesToClient().get(TimeLockStatus.MULTIPLE_LEADERS);\n+        if (clientsWithMultipleLeaders.isEmpty()) {\n+            return;\n+        }\n+\n+        log.info(\"Clients {} appear to have multiple leaders based on the leader ping health check. Scheduling\"\n+                + \" checks on these specific clients now.\", SafeArg.of(\"clients\", clientsWithMultipleLeaders));\n+        clientsWithMultipleLeaders.forEach(this::scheduleCheckOnSpecificClient);\n+    }\n+\n+    private void scheduleCheckOnSpecificClient(Client client) {\n+        executorService.submit(() -> {\n+            try {\n+                performCheckOnSpecificClientUnsafe(client);\n+            } catch (Exception e) {\n+                log.info(\"No-simultaneous service check failed, suppressing exception to allow future checks\", e);", "originalCommit": "b97d147f2b23fdcf46b00676a6dcffd296f591ad", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjM0NjY4Mw==", "url": "https://github.com/palantir/atlasdb/pull/4552#discussion_r376346683", "bodyText": "You are already in a for loop, you don't need the if/else", "author": "gmaretic", "createdAt": "2020-02-07T11:35:10Z", "path": "timelock-agent/src/main/java/com/palantir/timelock/invariants/NoSimultaneousServiceCheck.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * (c) Copyright 2020 Palantir Technologies Inc. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.palantir.timelock.invariants;\n+\n+import java.time.Duration;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Consumer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.util.concurrent.Uninterruptibles;\n+import com.palantir.atlasdb.timelock.paxos.Client;\n+import com.palantir.common.concurrent.PTExecutors;\n+import com.palantir.logsafe.SafeArg;\n+import com.palantir.timelock.TimeLockStatus;\n+import com.palantir.timelock.paxos.HealthCheckDigest;\n+\n+public final class NoSimultaneousServiceCheck {\n+    private static final Logger log = LoggerFactory.getLogger(NoSimultaneousServiceCheck.class);\n+\n+    private static final int REQUIRED_CONSECUTIVE_VIOLATIONS_BEFORE_FAIL = 5;\n+    private static final Duration BACKOFF = Duration.ofMillis(1337);\n+\n+    private final List<TimeLockActivityChecker> timeLockActivityCheckers;\n+    private final Consumer<String> failureMechanism;\n+    private final ExecutorService executorService;\n+\n+    @VisibleForTesting\n+    NoSimultaneousServiceCheck(\n+            List<TimeLockActivityChecker> timeLockActivityCheckers,\n+            Consumer<String> failureMechanism,\n+            ExecutorService executorService) {\n+        this.timeLockActivityCheckers = timeLockActivityCheckers;\n+        this.failureMechanism = failureMechanism;\n+        this.executorService = executorService;\n+    }\n+\n+    public static NoSimultaneousServiceCheck create(List<TimeLockActivityChecker> timeLockActivityCheckers) {\n+        ExecutorService executorService = PTExecutors.newSingleThreadExecutor(\n+                PTExecutors.newNamedThreadFactory(false));\n+        return new NoSimultaneousServiceCheck(timeLockActivityCheckers,\n+                client -> {\n+                    // TODO (jkong): Gather confidence and then change to ServerKiller, so that we ACTUALLY shoot\n+                    // ourselves in the head.\n+                    log.error(\"We observed that multiple services were consistently serving timestamps, for the\"\n+                            + \" client {}. This is potentially indicative of SEVERE DATA CORRUPTION, and should\"\n+                            + \" never happen in a correct TimeLock implementation. If you see this message, please\"\n+                            + \" check the frequency of leader elections on your stack: if they are very frequent,\"\n+                            + \" consider increasing the leader election timeout. Otherwise, please contact support -\"\n+                            + \" your stack may have been compromised\",\n+                            SafeArg.of(\"client\", client));\n+                },\n+                executorService);\n+    }\n+\n+    public void processHealthCheckDigest(HealthCheckDigest digest) {\n+        Set<Client> clientsWithMultipleLeaders = digest.statusesToClient().get(TimeLockStatus.MULTIPLE_LEADERS);\n+        if (clientsWithMultipleLeaders.isEmpty()) {\n+            return;\n+        }\n+\n+        log.info(\"Clients {} appear to have multiple leaders based on the leader ping health check. Scheduling\"\n+                + \" checks on these specific clients now.\", SafeArg.of(\"clients\", clientsWithMultipleLeaders));\n+        clientsWithMultipleLeaders.forEach(this::scheduleCheckOnSpecificClient);\n+    }\n+\n+    private void scheduleCheckOnSpecificClient(Client client) {\n+        executorService.submit(() -> {\n+            try {\n+                performCheckOnSpecificClientUnsafe(client);\n+            } catch (Exception e) {\n+                log.info(\"No-simultaneous service check failed, suppressing exception to allow future checks\", e);\n+            }\n+        });\n+    }\n+\n+    private void performCheckOnSpecificClientUnsafe(Client client) {\n+        // Only fail on repeated violations, since it is possible for there to be a leader election between checks that\n+        // could legitimately cause false positives if we failed after one such issue. However, given the number of\n+        // checks it is unlikely that *that* many elections would occur.\n+        for (int attempt = 1; attempt <= REQUIRED_CONSECUTIVE_VIOLATIONS_BEFORE_FAIL; attempt++) {\n+            long numberOfNodesServingTimestamps = timeLockActivityCheckers.stream()\n+                    .map(timeLockActivityChecker ->\n+                            timeLockActivityChecker.isThisNodeActivelyServingTimestampsForClient(client.value()))\n+                    .filter(x -> x)\n+                    .count();\n+            if (numberOfNodesServingTimestamps <= 1) {\n+                // Accept 0: the cluster being in such a bad state is not a terminal condition, could just be a\n+                // network partition or legitimate no-quorum situation. No reason to kill the server then.\n+                log.info(\"We don't think services were simultaneously serving timestamps for client {}\",\n+                        SafeArg.of(\"client\", client));\n+                return;\n+            }\n+\n+            if (attempt < REQUIRED_CONSECUTIVE_VIOLATIONS_BEFORE_FAIL) {", "originalCommit": "b97d147f2b23fdcf46b00676a6dcffd296f591ad", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "ea327bcec31d75f1c29ef55c45232e3674525db5", "url": "https://github.com/palantir/atlasdb/commit/ea327bcec31d75f1c29ef55c45232e3674525db5", "message": "Actually track issued timestamps, update tests to reflect that", "committedDate": "2020-02-07T13:29:10Z", "type": "commit"}, {"oid": "ad651dd364a2566de152090c8788e5a24cdbf3c3", "url": "https://github.com/palantir/atlasdb/commit/ad651dd364a2566de152090c8788e5a24cdbf3c3", "message": "Add generated changelog entries", "committedDate": "2020-02-07T13:29:10Z", "type": "commit"}, {"oid": "19922c22c3ebb1179da86cb247287beaf25abc32", "url": "https://github.com/palantir/atlasdb/commit/19922c22c3ebb1179da86cb247287beaf25abc32", "message": "Add generated changelog entries", "committedDate": "2020-02-07T13:29:10Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQxNzI4Ng==", "url": "https://github.com/palantir/atlasdb/pull/4552#discussion_r376417286", "bodyText": "I think we want the attempt number?", "author": "jeremyk-91", "createdAt": "2020-02-07T14:27:27Z", "path": "timelock-agent/src/main/java/com/palantir/timelock/invariants/NoSimultaneousServiceCheck.java", "diffHunk": "@@ -97,30 +103,36 @@ private void performCheckOnSpecificClientUnsafe(Client client) {\n         // Only fail on repeated violations, since it is possible for there to be a leader election between checks that\n         // could legitimately cause false positives if we failed after one such issue. However, given the number of\n         // checks it is unlikely that *that* many elections would occur.\n-        for (int attempt = 1; attempt <= REQUIRED_CONSECUTIVE_VIOLATIONS_BEFORE_FAIL; attempt++) {\n-            long numberOfNodesServingTimestamps = timeLockActivityCheckers.stream()\n+        long timestampBound = Long.MIN_VALUE;\n+\n+        for (int attempt = 1; attempt <= REQUIRED_ATTEMPTS_BEFORE_GIVING_UP; attempt++) {\n+            List<Long> timestamps = timeLockActivityCheckers.stream()\n                     .map(timeLockActivityChecker ->\n-                            timeLockActivityChecker.isThisNodeActivelyServingTimestampsForClient(client.value()))\n-                    .filter(x -> x)\n-                    .count();\n-            if (numberOfNodesServingTimestamps <= 1) {\n+                            timeLockActivityChecker.getFreshTimestampFromNodeForClient(client.value()))\n+                    .filter(OptionalLong::isPresent)\n+                    .map(OptionalLong::getAsLong)\n+                    .collect(Collectors.toList());\n+            if (timestamps.size() <= 1) {\n                 // Accept 0: the cluster being in such a bad state is not a terminal condition, could just be a\n                 // network partition or legitimate no-quorum situation. No reason to kill the server then.\n                 log.info(\"We don't think services were simultaneously serving timestamps for client {}\",\n                         SafeArg.of(\"client\", client));\n                 return;\n             }\n \n-            if (attempt < REQUIRED_CONSECUTIVE_VIOLATIONS_BEFORE_FAIL) {\n-                log.info(\"We observed on attempt {} of {} that multiple services were serving timestamps. We'll try\"\n-                                + \" again in {} ms to see if this remains the case.\",\n-                        SafeArg.of(\"attemptNumber\", attempt),\n-                        SafeArg.of(\"maximumAttempts\", REQUIRED_CONSECUTIVE_VIOLATIONS_BEFORE_FAIL),\n-                        SafeArg.of(\"backoffMillis\", BACKOFF.toMillis()));\n-                Uninterruptibles.sleepUninterruptibly(BACKOFF.toMillis(), TimeUnit.MILLISECONDS);\n-            } else {\n+            if (!Ordering.natural().isStrictlyOrdered(timestamps) || timestamps.get(0) <= timestampBound) {\n                 failureMechanism.accept(client.value());\n+                return;\n             }\n+\n+            timestampBound = timestamps.get(timestamps.size() - 1);\n+            log.info(\"We observed on attempt that multiple services were serving timestamps, but the timestamps were\"", "originalCommit": "ea327bcec31d75f1c29ef55c45232e3674525db5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}