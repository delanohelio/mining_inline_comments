{"pr_number": 4524, "pr_title": "Extract caching from the specific timestamp cache", "pr_createdAt": "2020-01-20T18:01:27Z", "pr_url": "https://github.com/palantir/atlasdb/pull/4524", "timeline": [{"oid": "38b04958bf11cdf1bf74053f8579d10fb5f27d42", "url": "https://github.com/palantir/atlasdb/commit/38b04958bf11cdf1bf74053f8579d10fb5f27d42", "message": "Fix rebasing.", "committedDate": "2020-01-23T11:48:59Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEyODI5OA==", "url": "https://github.com/palantir/atlasdb/pull/4524#discussion_r370128298", "bodyText": "make this public as you'll need it to construct a DefaultOffHeapCache. Also move it to the top please.", "author": "felixdesouza", "createdAt": "2020-01-23T13:52:44Z", "path": "atlasdb-client/src/main/java/com/palantir/atlasdb/cache/DefaultOffHeapCache.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * (c) Copyright 2020 Palantir Technologies Inc. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.palantir.atlasdb.cache;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.LongSupplier;\n+import java.util.stream.Collectors;\n+\n+import org.immutables.value.Value;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.codahale.metrics.Counter;\n+import com.codahale.metrics.Gauge;\n+import com.codahale.metrics.Meter;\n+import com.codahale.metrics.MetricRegistry;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Maps;\n+import com.google.common.collect.Sets;\n+import com.google.common.util.concurrent.Futures;\n+import com.palantir.atlasdb.autobatch.Autobatchers;\n+import com.palantir.atlasdb.autobatch.CoalescingRequestFunction;\n+import com.palantir.atlasdb.autobatch.DisruptorAutobatcher;\n+import com.palantir.atlasdb.persistent.api.PersistentStore;\n+import com.palantir.common.streams.KeyedStream;\n+import com.palantir.logsafe.exceptions.SafeIllegalArgumentException;\n+import com.palantir.tritium.metrics.registry.MetricName;\n+import com.palantir.tritium.metrics.registry.TaggedMetricRegistry;\n+\n+import okio.ByteString;\n+\n+public final class DefaultOffHeapCache<K, V> implements OffHeapCache<K, V> {\n+    private static final Logger log = LoggerFactory.getLogger(DefaultOffHeapCache.class);\n+    private static final String BATCHER_PURPOSE = \"off-heap-cache\";\n+    private static final MetricName CACHE_HIT = constructCacheMetricName(\"cacheHit\");\n+    private static final MetricName CACHE_MISS = constructCacheMetricName(\"cacheMiss\");\n+    private static final MetricName CACHE_NUKE = constructCacheMetricName(\"cacheNuke\");\n+    private static final MetricName CACHE_SIZE = constructCacheMetricName(\"cacheSize\");\n+\n+    private final PersistentStore persistentStore;\n+    private final EntryMapper<K, V> entryMapper;\n+    private final LongSupplier maxSize;\n+    private final AtomicReference<CacheDescriptor> cacheDescriptor = new AtomicReference<>();\n+    private final DisruptorAutobatcher<Map.Entry<K, V>, Void> valuePutter;\n+    private final Meter cacheHit;\n+    private final Meter cacheMiss;\n+    private final Counter cacheNuke;\n+\n+    public static <K, V> OffHeapCache<K, V> create(\n+            PersistentStore persistentStore,\n+            EntryMapper<K, V> entryMapper,\n+            TaggedMetricRegistry taggedMetricRegistry,\n+            LongSupplier maxSize) {\n+        PersistentStore.Handle handle = persistentStore.createSpace();\n+\n+        CacheDescriptor cacheDescriptor = ImmutableCacheDescriptor.builder()\n+                .currentSize(new AtomicInteger())\n+                .handle(handle)\n+                .build();\n+\n+        return new DefaultOffHeapCache(\n+                persistentStore,\n+                entryMapper,\n+                cacheDescriptor,\n+                maxSize,\n+                taggedMetricRegistry);\n+    }\n+\n+    private DefaultOffHeapCache(\n+            PersistentStore persistentStore,\n+            EntryMapper<K, V> entryMapper,\n+            CacheDescriptor cacheDescriptor,\n+            LongSupplier maxSize,\n+            TaggedMetricRegistry taggedMetricRegistry) {\n+        this.persistentStore = persistentStore;\n+        this.entryMapper = entryMapper;\n+        this.cacheDescriptor.set(cacheDescriptor);\n+        this.maxSize = maxSize;\n+        this.cacheHit = taggedMetricRegistry.meter(CACHE_HIT);\n+        this.cacheMiss = taggedMetricRegistry.meter(CACHE_MISS);\n+        this.cacheNuke = taggedMetricRegistry.counter(CACHE_NUKE);\n+        this.valuePutter = Autobatchers.coalescing(new WriteBatcher<>(this))\n+                .safeLoggablePurpose(BATCHER_PURPOSE)\n+                .build();\n+        Gauge<Integer> cacheSizeGauge = () -> this.cacheDescriptor.get().currentSize().intValue();\n+        taggedMetricRegistry.gauge(CACHE_SIZE, cacheSizeGauge);\n+    }\n+\n+    @Override\n+    public void clear() {\n+        CacheDescriptor proposedCacheDescriptor = createNamespaceAndConstructCacheProposal(persistentStore);\n+\n+        CacheDescriptor previous = cacheDescriptor.getAndUpdate(prev -> proposedCacheDescriptor);\n+        if (previous != null) {\n+            persistentStore.dropStoreSpace(previous.handle());\n+        }\n+    }\n+\n+    @Override\n+    public void put(K key, V value) {\n+        Futures.getUnchecked(valuePutter.apply(Maps.immutableEntry(key, value)));\n+    }\n+\n+    @Override\n+    public Optional<V> get(K key) {\n+        ByteString serializedKey = entryMapper.serializeKey(key);\n+        Optional<ByteString> value = persistentStore.get(cacheDescriptor.get().handle(), serializedKey);\n+        getCacheMeter(value.isPresent()).mark();\n+        return value.map(v -> entryMapper.deserializeValue(serializedKey, v));\n+    }\n+\n+    private Meter getCacheMeter(boolean cacheOutcome) {\n+        return cacheOutcome ? cacheHit : cacheMiss;\n+    }\n+\n+    private static CacheDescriptor createNamespaceAndConstructCacheProposal(PersistentStore persistentStore) {\n+        PersistentStore.Handle proposal = persistentStore.createSpace();\n+        return ImmutableCacheDescriptor.builder()\n+                .currentSize(new AtomicInteger())\n+                .handle(proposal)\n+                .build();\n+    }\n+\n+    private static MetricName constructCacheMetricName(String metricSuffix) {\n+        return MetricName.builder()\n+                .safeName(MetricRegistry.name(DefaultOffHeapCache.class, metricSuffix))\n+                .build();\n+    }\n+\n+    private static class WriteBatcher<K, V> implements CoalescingRequestFunction<Map.Entry<K, V>, Void> {\n+        DefaultOffHeapCache<K, V> offHeapCache;\n+\n+        WriteBatcher(DefaultOffHeapCache<K, V> offHeapCache) {\n+            this.offHeapCache = offHeapCache;\n+        }\n+\n+        @Override\n+        public Map<Map.Entry<K, V>, Void> apply(Set<Map.Entry<K, V>> request) {\n+            CacheDescriptor cacheDescriptor = offHeapCache.cacheDescriptor.get();\n+            if (cacheDescriptor.currentSize().get() >= offHeapCache.maxSize.getAsLong()) {\n+                offHeapCache.cacheNuke.inc();\n+                offHeapCache.clear();\n+            }\n+            cacheDescriptor = offHeapCache.cacheDescriptor.get();\n+            Set<Map.Entry<ByteString, ByteString>> serializedRequest = request.stream()\n+                    .map(this::serializeEntry)\n+                    .collect(Collectors.toSet());\n+            try {\n+                List<ByteString> toWrite = serializedRequest.stream()\n+                        .map(Map.Entry::getKey)\n+                        .collect(Collectors.toList());\n+                Map<ByteString, ByteString> response =\n+                        offHeapCache.persistentStore.get(cacheDescriptor.handle(), toWrite);\n+\n+                int sizeIncrease = Sets.difference(request, response.entrySet()).size();\n+                cacheDescriptor.currentSize().addAndGet(sizeIncrease);\n+                offHeapCache.persistentStore.put(\n+                        cacheDescriptor.handle(),\n+                        ImmutableMap.copyOf(serializedRequest));\n+            } catch (SafeIllegalArgumentException exception) {\n+                // happens when a store is dropped by a concurrent call to clear\n+                log.warn(\"Clear called concurrently, writing failed\", exception);\n+            }\n+            return KeyedStream.of(request.stream()).<Void>map(value -> null).collectToMap();\n+        }\n+\n+        private Map.Entry<ByteString, ByteString> serializeEntry(Map.Entry<K, V> entry) {\n+            return Maps.immutableEntry(\n+                    offHeapCache.entryMapper.serializeKey(entry.getKey()),\n+                    offHeapCache.entryMapper.serializeValue(entry.getKey(), entry.getValue()));\n+        }\n+    }\n+\n+    interface EntryMapper<K, V> {", "originalCommit": "38b04958bf11cdf1bf74053f8579d10fb5f27d42", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "d267fada293b48d187949a65814461a49ff88d7a", "url": "https://github.com/palantir/atlasdb/commit/d267fada293b48d187949a65814461a49ff88d7a", "message": "Refactor mapper.", "committedDate": "2020-01-23T14:23:20Z", "type": "forcePushed"}, {"oid": "994f9fba4a607966092026b18ac67752a5772041", "url": "https://github.com/palantir/atlasdb/commit/994f9fba4a607966092026b18ac67752a5772041", "message": "Renamed.", "committedDate": "2020-01-23T15:23:15Z", "type": "commit"}, {"oid": "0e64e2997c12feead992644b4168b438c9e9603c", "url": "https://github.com/palantir/atlasdb/commit/0e64e2997c12feead992644b4168b438c9e9603c", "message": "Main part of refactoring.", "committedDate": "2020-01-23T15:23:15Z", "type": "commit"}, {"oid": "babecb25ebe5d62e0dae4b31409542e51fe5290f", "url": "https://github.com/palantir/atlasdb/commit/babecb25ebe5d62e0dae4b31409542e51fe5290f", "message": "Remove a line.", "committedDate": "2020-01-23T15:23:15Z", "type": "commit"}, {"oid": "0f24be10f4b80a636b930b00a558db4f6061ddf8", "url": "https://github.com/palantir/atlasdb/commit/0f24be10f4b80a636b930b00a558db4f6061ddf8", "message": "Fix rebasing.", "committedDate": "2020-01-23T15:23:15Z", "type": "commit"}, {"oid": "df5ffc0f094b3bba508fdef8d1e90ef79a4bd8c9", "url": "https://github.com/palantir/atlasdb/commit/df5ffc0f094b3bba508fdef8d1e90ef79a4bd8c9", "message": "Refactor mapper.", "committedDate": "2020-01-23T15:23:15Z", "type": "commit"}, {"oid": "8e2896e73e2c3107e12a1990c7b795f124f944ff", "url": "https://github.com/palantir/atlasdb/commit/8e2896e73e2c3107e12a1990c7b795f124f944ff", "message": "Remove import.", "committedDate": "2020-01-23T15:23:16Z", "type": "commit"}, {"oid": "db26deb896a064e646f21f111908853afc72423d", "url": "https://github.com/palantir/atlasdb/commit/db26deb896a064e646f21f111908853afc72423d", "message": "Fixed tests.", "committedDate": "2020-01-23T15:23:16Z", "type": "commit"}, {"oid": "db26deb896a064e646f21f111908853afc72423d", "url": "https://github.com/palantir/atlasdb/commit/db26deb896a064e646f21f111908853afc72423d", "message": "Fixed tests.", "committedDate": "2020-01-23T15:23:16Z", "type": "forcePushed"}]}