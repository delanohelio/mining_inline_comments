{"pr_number": 10243, "pr_title": "Add maxNumFiles to splitHintSpec", "pr_createdAt": "2020-08-05T18:29:58Z", "pr_url": "https://github.com/apache/druid/pull/10243", "timeline": [{"oid": "ed01dc16aec9b50d954e6aef84627bcd614aa190", "url": "https://github.com/apache/druid/commit/ed01dc16aec9b50d954e6aef84627bcd614aa190", "message": "Add maxNumFiles to splitHintSpec", "committedDate": "2020-08-05T18:24:40Z", "type": "commit"}, {"oid": "d8477cf9c28d56ca876d81fcc4d1014e185f9cb3", "url": "https://github.com/apache/druid/commit/d8477cf9c28d56ca876d81fcc4d1014e185f9cb3", "message": "missing link", "committedDate": "2020-08-05T18:27:47Z", "type": "commit"}, {"oid": "a69fe7c33cfa29ae746ba3ba688a1b97f40799c6", "url": "https://github.com/apache/druid/commit/a69fe7c33cfa29ae746ba3ba688a1b97f40799c6", "message": "fix build failure; use maxNumFiles for integration tests", "committedDate": "2020-08-05T21:46:26Z", "type": "commit"}, {"oid": "34c620e5d1ce50f66e0e4676a3c6904ed25bf03f", "url": "https://github.com/apache/druid/commit/34c620e5d1ce50f66e0e4676a3c6904ed25bf03f", "message": "spelling", "committedDate": "2020-08-05T22:47:46Z", "type": "commit"}, {"oid": "93a6f45cf0b64d8e0ab6eca097a4e9bccaab65e9", "url": "https://github.com/apache/druid/commit/93a6f45cf0b64d8e0ab6eca097a4e9bccaab65e9", "message": "lower default", "committedDate": "2020-08-13T18:30:30Z", "type": "commit"}, {"oid": "65657f6eec028817ce32f90dcea15e382e3ed3ef", "url": "https://github.com/apache/druid/commit/65657f6eec028817ce32f90dcea15e382e3ed3ef", "message": "Update docs/ingestion/native-batch.md\n\nCo-authored-by: Abhishek Agarwal <1477457+abhishekagarwal87@users.noreply.github.com>", "committedDate": "2020-08-14T18:01:31Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg5MDYzNg==", "url": "https://github.com/apache/druid/pull/10243#discussion_r470890636", "bodyText": "This is a great comment! Thank you!", "author": "suneet-s", "createdAt": "2020-08-14T22:28:16Z", "path": "core/src/main/java/org/apache/druid/data/input/MaxSizeSplitHintSpec.java", "diffHunk": "@@ -43,22 +44,53 @@\n   public static final String TYPE = \"maxSize\";\n \n   @VisibleForTesting\n-  static final long DEFAULT_MAX_SPLIT_SIZE = 512 * 1024 * 1024;\n+  static final HumanReadableBytes DEFAULT_MAX_SPLIT_SIZE = new HumanReadableBytes(\"512MiB\");\n \n-  private final long maxSplitSize;\n+  /**\n+   * There are two known issues when a split contains a large list of files.\n+   *\n+   * - 'jute.maxbuffer' in ZooKeeper. This system property controls the max size of ZNode. As its default is 500KB,\n+   *   task allocation can fail if the serialized ingestion spec is larger than this limit.\n+   * - 'max_allowed_packet' in MySQL. This is the max size of a communication packet sent to a MySQL server.\n+   *   The default is either 64MB or 4MB depending on MySQL version. Updating metadata store can fail if the serialized\n+   *   ingestion spec is larger than this limit.\n+   *\n+   * The default is consertively chosen as 1000.\n+   */", "originalCommit": "65657f6eec028817ce32f90dcea15e382e3ed3ef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg5MzA5MQ==", "url": "https://github.com/apache/druid/pull/10243#discussion_r470893091", "bodyText": "Should we add a preconditionCheck on maxNumFiles? If the user has entered maxNumFiles, it should be a positive number >= 1\nI think what you've implemented works even with negative numbers, but maybe it's better to tell the user they're doing something strange.", "author": "suneet-s", "createdAt": "2020-08-14T22:37:46Z", "path": "core/src/main/java/org/apache/druid/data/input/MaxSizeSplitHintSpec.java", "diffHunk": "@@ -43,22 +44,53 @@\n   public static final String TYPE = \"maxSize\";\n \n   @VisibleForTesting\n-  static final long DEFAULT_MAX_SPLIT_SIZE = 512 * 1024 * 1024;\n+  static final HumanReadableBytes DEFAULT_MAX_SPLIT_SIZE = new HumanReadableBytes(\"512MiB\");\n \n-  private final long maxSplitSize;\n+  /**\n+   * There are two known issues when a split contains a large list of files.\n+   *\n+   * - 'jute.maxbuffer' in ZooKeeper. This system property controls the max size of ZNode. As its default is 500KB,\n+   *   task allocation can fail if the serialized ingestion spec is larger than this limit.\n+   * - 'max_allowed_packet' in MySQL. This is the max size of a communication packet sent to a MySQL server.\n+   *   The default is either 64MB or 4MB depending on MySQL version. Updating metadata store can fail if the serialized\n+   *   ingestion spec is larger than this limit.\n+   *\n+   * The default is consertively chosen as 1000.\n+   */\n+  @VisibleForTesting\n+  static final int DEFAULT_MAX_NUM_FILES = 1000;\n+\n+  private final HumanReadableBytes maxSplitSize;\n+  private final int maxNumFiles;\n \n   @JsonCreator\n-  public MaxSizeSplitHintSpec(@JsonProperty(\"maxSplitSize\") @Nullable Long maxSplitSize)\n+  public MaxSizeSplitHintSpec(\n+      @JsonProperty(\"maxSplitSize\") @Nullable HumanReadableBytes maxSplitSize,\n+      @JsonProperty(\"maxNumFiles\") @Nullable Integer maxNumFiles\n+  )\n   {\n     this.maxSplitSize = maxSplitSize == null ? DEFAULT_MAX_SPLIT_SIZE : maxSplitSize;\n+    this.maxNumFiles = maxNumFiles == null ? DEFAULT_MAX_NUM_FILES : maxNumFiles;", "originalCommit": "65657f6eec028817ce32f90dcea15e382e3ed3ef", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg2MzM5Mw==", "url": "https://github.com/apache/druid/pull/10243#discussion_r471863393", "bodyText": "Good call. Added a check for both maxSplitsize and maxNumFiles.", "author": "jihoonson", "createdAt": "2020-08-18T01:34:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg5MzA5MQ=="}], "type": "inlineReview"}, {"oid": "9b62a55e97ed62a00fc24196090f84b8d5b36b82", "url": "https://github.com/apache/druid/commit/9b62a55e97ed62a00fc24196090f84b8d5b36b82", "message": "address comments; change default maxSplitSize", "committedDate": "2020-08-18T01:34:41Z", "type": "commit"}, {"oid": "c0ab886fe77729b4b5e3626e03779edea40f79b8", "url": "https://github.com/apache/druid/commit/c0ab886fe77729b4b5e3626e03779edea40f79b8", "message": "spelling", "committedDate": "2020-08-18T03:39:15Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTk0NDQ0OA==", "url": "https://github.com/apache/druid/pull/10243#discussion_r471944448", "bodyText": "This change seems reasonable to me, but since we're changing the default behavior from 512 MiB to 1GiB, can we add a system property to override this default value. In case users are doing an upgrade to 0.20 and want the old behavior, the system property would give them a way. to have the previous default.", "author": "suneet-s", "createdAt": "2020-08-18T06:32:44Z", "path": "core/src/main/java/org/apache/druid/data/input/MaxSizeSplitHintSpec.java", "diffHunk": "@@ -44,7 +45,7 @@\n   public static final String TYPE = \"maxSize\";\n \n   @VisibleForTesting\n-  static final HumanReadableBytes DEFAULT_MAX_SPLIT_SIZE = new HumanReadableBytes(\"512MiB\");\n+  static final HumanReadableBytes DEFAULT_MAX_SPLIT_SIZE = new HumanReadableBytes(\"1GiB\");", "originalCommit": "c0ab886fe77729b4b5e3626e03779edea40f79b8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjU0NTQ1Mg==", "url": "https://github.com/apache/druid/pull/10243#discussion_r472545452", "bodyText": "Hmm, good question. I would say it could be more useful to have a way to apply different default configurations per datasource since the maxSplitSize should be adjusted based on the shape of input data and partitioning scheme of output data. But for this, I think it could be better to add a supervisor which periodically performs batch ingestion based on the user-provided configurations.\nParticularly regarding keeping the previous default, I'm not sure when it would be good to do. maxSplitSize is mostly for controlling the parallelism of the phase which reads data from inputSource in parallel indexing, but it also affects the number of segments created after the input-read phase. So, there is a trade-off between them. However, I would say increasing maxSplitSize 512 MB to 1 GB wouldn't change things dramatically. If you have a cluster where all subtasks split by the previous default can run at the same time but not with the new default, you might want to use the previous default because, in theory, it will give you 2 times better read performance. However, in practice, you would likely have more than one task to run at the same time, which the cluster resource should be shared across.\nWhat do you think?", "author": "jihoonson", "createdAt": "2020-08-18T23:19:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTk0NDQ0OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjY4NzY2OQ==", "url": "https://github.com/apache/druid/pull/10243#discussion_r472687669", "bodyText": "Thinking about this more, I can't think of a good reason to have a cluster wide fallback option, other than my paranoia \ud83d\ude05\nYour analysis makes sense to me, and while adding the ability to automatically adjust this based on the shape and partitioning scheme of the data sounds really cool, it's definitely beyond the scope of this change", "author": "suneet-s", "createdAt": "2020-08-19T04:46:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTk0NDQ0OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzE3NDc4Nw==", "url": "https://github.com/apache/druid/pull/10243#discussion_r473174787", "bodyText": "Your analysis makes sense to me, and while adding the ability to automatically adjust this based on the shape and partitioning scheme of the data sounds really cool, it's definitely beyond the scope of this change\n\nOh, I originally meant a supervisor working based on fixed user configurations, but yeah auto adjusting would be nice.", "author": "jihoonson", "createdAt": "2020-08-19T16:45:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTk0NDQ0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzMxMTg5NQ==", "url": "https://github.com/apache/druid/pull/10243#discussion_r473311895", "bodyText": "is this a typo: 'consertively' -> 'conservatively'?", "author": "clintropolis", "createdAt": "2020-08-19T20:52:58Z", "path": "core/src/main/java/org/apache/druid/data/input/MaxSizeSplitHintSpec.java", "diffHunk": "@@ -43,22 +45,55 @@\n   public static final String TYPE = \"maxSize\";\n \n   @VisibleForTesting\n-  static final long DEFAULT_MAX_SPLIT_SIZE = 512 * 1024 * 1024;\n+  static final HumanReadableBytes DEFAULT_MAX_SPLIT_SIZE = new HumanReadableBytes(\"1GiB\");\n \n-  private final long maxSplitSize;\n+  /**\n+   * There are two known issues when a split contains a large list of files.\n+   *\n+   * - 'jute.maxbuffer' in ZooKeeper. This system property controls the max size of ZNode. As its default is 500KB,\n+   *   task allocation can fail if the serialized ingestion spec is larger than this limit.\n+   * - 'max_allowed_packet' in MySQL. This is the max size of a communication packet sent to a MySQL server.\n+   *   The default is either 64MB or 4MB depending on MySQL version. Updating metadata store can fail if the serialized\n+   *   ingestion spec is larger than this limit.\n+   *\n+   * The default is consertively chosen as 1000.", "originalCommit": "c0ab886fe77729b4b5e3626e03779edea40f79b8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzY5MTE5Mg==", "url": "https://github.com/apache/druid/pull/10243#discussion_r473691192", "bodyText": "Oops, thanks.", "author": "jihoonson", "createdAt": "2020-08-20T07:26:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzMxMTg5NQ=="}], "type": "inlineReview"}, {"oid": "c363df0e175fdce431e9d1f7581453aff851a8c9", "url": "https://github.com/apache/druid/commit/c363df0e175fdce431e9d1f7581453aff851a8c9", "message": "typos and doc", "committedDate": "2020-08-20T07:26:26Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mzc5NzA4NQ==", "url": "https://github.com/apache/druid/pull/10243#discussion_r473797085", "bodyText": "Should SegmentsSplitHintSpec be updated to accept HumanReadableBytes for maxInputSegmentBytesPerTask as well?", "author": "clintropolis", "createdAt": "2020-08-20T09:11:36Z", "path": "core/src/main/java/org/apache/druid/data/input/MaxSizeSplitHintSpec.java", "diffHunk": "@@ -43,22 +45,55 @@\n   public static final String TYPE = \"maxSize\";\n \n   @VisibleForTesting\n-  static final long DEFAULT_MAX_SPLIT_SIZE = 512 * 1024 * 1024;\n+  static final HumanReadableBytes DEFAULT_MAX_SPLIT_SIZE = new HumanReadableBytes(\"1GiB\");\n \n-  private final long maxSplitSize;\n+  /**\n+   * There are two known issues when a split contains a large list of files.\n+   *\n+   * - 'jute.maxbuffer' in ZooKeeper. This system property controls the max size of ZNode. As its default is 500KB,\n+   *   task allocation can fail if the serialized ingestion spec is larger than this limit.\n+   * - 'max_allowed_packet' in MySQL. This is the max size of a communication packet sent to a MySQL server.\n+   *   The default is either 64MB or 4MB depending on MySQL version. Updating metadata store can fail if the serialized\n+   *   ingestion spec is larger than this limit.\n+   *\n+   * The default is conservatively chosen as 1000.\n+   */\n+  @VisibleForTesting\n+  static final int DEFAULT_MAX_NUM_FILES = 1000;\n+\n+  private final HumanReadableBytes maxSplitSize;\n+  private final int maxNumFiles;\n \n   @JsonCreator\n-  public MaxSizeSplitHintSpec(@JsonProperty(\"maxSplitSize\") @Nullable Long maxSplitSize)\n+  public MaxSizeSplitHintSpec(\n+      @JsonProperty(\"maxSplitSize\") @Nullable HumanReadableBytes maxSplitSize,\n+      @JsonProperty(\"maxNumFiles\") @Nullable Integer maxNumFiles\n+  )\n   {\n     this.maxSplitSize = maxSplitSize == null ? DEFAULT_MAX_SPLIT_SIZE : maxSplitSize;\n+    this.maxNumFiles = maxNumFiles == null ? DEFAULT_MAX_NUM_FILES : maxNumFiles;\n+    Preconditions.checkArgument(this.maxSplitSize.getBytes() > 0, \"maxSplitSize should be larger than 0\");\n+    Preconditions.checkArgument(this.maxNumFiles > 0, \"maxNumFiles should be larger than 0\");\n+  }\n+\n+  @VisibleForTesting\n+  public MaxSizeSplitHintSpec(long maxSplitSize, @Nullable Integer maxNumFiles)\n+  {\n+    this(new HumanReadableBytes(maxSplitSize), maxNumFiles);\n   }\n \n   @JsonProperty\n-  public long getMaxSplitSize()\n+  public HumanReadableBytes getMaxSplitSize()", "originalCommit": "c363df0e175fdce431e9d1f7581453aff851a8c9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE3MTU2MA==", "url": "https://github.com/apache/druid/pull/10243#discussion_r474171560", "bodyText": "Ah good idea. It actually needs the same change because it needs to be identical to maxSize splitHintSpec at least for now. We could implement a better split based on stats in the future.", "author": "jihoonson", "createdAt": "2020-08-20T17:58:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mzc5NzA4NQ=="}], "type": "inlineReview"}, {"oid": "fbcb142303ff1e57f0e55d045e96fb7b2c6fbeb7", "url": "https://github.com/apache/druid/commit/fbcb142303ff1e57f0e55d045e96fb7b2c6fbeb7", "message": "same change for segments splitHintSpec", "committedDate": "2020-08-20T17:56:16Z", "type": "commit"}, {"oid": "da709d0c369ab73a0617b639fae79b27bcf41dc4", "url": "https://github.com/apache/druid/commit/da709d0c369ab73a0617b639fae79b27bcf41dc4", "message": "fix build", "committedDate": "2020-08-20T20:26:01Z", "type": "commit"}, {"oid": "8742c30ec0c1aa871afa54d1907ba5ce8ad30d10", "url": "https://github.com/apache/druid/commit/8742c30ec0c1aa871afa54d1907ba5ce8ad30d10", "message": "Merge branch 'master' of github.com:apache/druid into max-num-files-split", "committedDate": "2020-08-20T20:31:43Z", "type": "commit"}, {"oid": "ea184a565914ef7523f8d9aac932cafad078f92d", "url": "https://github.com/apache/druid/commit/ea184a565914ef7523f8d9aac932cafad078f92d", "message": "fix build", "committedDate": "2020-08-20T20:36:21Z", "type": "commit"}]}