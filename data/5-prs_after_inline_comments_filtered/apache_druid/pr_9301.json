{"pr_number": 9301, "pr_title": "Join filter pushdown initial implementation", "pr_createdAt": "2020-01-31T21:48:24Z", "pr_url": "https://github.com/apache/druid/pull/9301", "timeline": [{"oid": "3c1c6749a3f94f0f8abf617cfafabd10973df9eb", "url": "https://github.com/apache/druid/commit/3c1c6749a3f94f0f8abf617cfafabd10973df9eb", "message": "Join filter pushdown initial implementation", "committedDate": "2020-02-01T00:25:29Z", "type": "commit"}, {"oid": "443d7274a49c71429d87afce3667b96d35dba517", "url": "https://github.com/apache/druid/commit/443d7274a49c71429d87afce3667b96d35dba517", "message": "Fix test and spotbugs check", "committedDate": "2020-02-01T00:25:29Z", "type": "commit"}, {"oid": "443d7274a49c71429d87afce3667b96d35dba517", "url": "https://github.com/apache/druid/commit/443d7274a49c71429d87afce3667b96d35dba517", "message": "Fix test and spotbugs check", "committedDate": "2020-02-01T00:25:29Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI3OTk1MQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374279951", "bodyText": "Do you want to add a unit test to AndFilterTest that uses EqualsVerifier (similar to https://github.com/apache/druid/blob/master/processing/src/test/java/org/apache/druid/query/QueryDataSourceTest.java#L142)", "author": "ccaominh", "createdAt": "2020-02-03T18:58:03Z", "path": "processing/src/main/java/org/apache/druid/segment/filter/AndFilter.java", "diffHunk": "@@ -234,4 +235,23 @@ public ReadableVectorMatch match(final ReadableVectorMatch mask)\n       }\n     };\n   }\n+\n+  @Override\n+  public boolean equals(Object o)", "originalCommit": "443d7274a49c71429d87afce3667b96d35dba517", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk5NjQ5OA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374996498", "bodyText": "Added an EqualsVerifier test", "author": "jon-wei", "createdAt": "2020-02-05T00:14:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI3OTk1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI4MDUwNA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374280504", "bodyText": "Similar comment about testing with EqualsVerifier", "author": "ccaominh", "createdAt": "2020-02-03T18:59:07Z", "path": "processing/src/main/java/org/apache/druid/segment/filter/BoundFilter.java", "diffHunk": "@@ -306,4 +307,26 @@ private boolean doesMatch(String input)\n     }\n     return (lowerComparing >= 0) && (upperComparing >= 0);\n   }\n+\n+  @Override\n+  public boolean equals(Object o)", "originalCommit": "443d7274a49c71429d87afce3667b96d35dba517", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk5NjUyNQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374996525", "bodyText": "Added an EqualsVerifier test", "author": "jon-wei", "createdAt": "2020-02-05T00:14:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI4MDUwNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI4MDY3Nw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374280677", "bodyText": "Similar comment about testing with EqualsVerifier", "author": "ccaominh", "createdAt": "2020-02-03T18:59:30Z", "path": "processing/src/main/java/org/apache/druid/segment/filter/InFilter.java", "diffHunk": "@@ -235,4 +236,26 @@ public DruidDoublePredicate makeDoublePredicate()\n       }\n     };\n   }\n+\n+  @Override\n+  public boolean equals(Object o)", "originalCommit": "443d7274a49c71429d87afce3667b96d35dba517", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk5NjU1Mw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374996553", "bodyText": "Added an EqualsVerifier test", "author": "jon-wei", "createdAt": "2020-02-05T00:14:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI4MDY3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI4MDg1OQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374280859", "bodyText": "Similar comment about testing with EqualsVerifier", "author": "ccaominh", "createdAt": "2020-02-03T18:59:53Z", "path": "processing/src/main/java/org/apache/druid/segment/filter/OrFilter.java", "diffHunk": "@@ -218,4 +219,23 @@ public ReadableVectorMatch match(final ReadableVectorMatch mask)\n       }\n     };\n   }\n+\n+  @Override\n+  public boolean equals(Object o)", "originalCommit": "443d7274a49c71429d87afce3667b96d35dba517", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk5NjY0MA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374996640", "bodyText": "There was no OrFilterTest class, I added one and an EqualsVerifier test", "author": "jon-wei", "createdAt": "2020-02-05T00:15:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI4MDg1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI4MTA0OA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374281048", "bodyText": "Similar comment about testing with EqualsVerifier", "author": "ccaominh", "createdAt": "2020-02-03T19:00:19Z", "path": "processing/src/main/java/org/apache/druid/segment/filter/SelectorFilter.java", "diffHunk": "@@ -127,4 +128,35 @@ public String toString()\n   {\n     return StringUtils.format(\"%s = %s\", dimension, value);\n   }\n+\n+  public String getDimension()\n+  {\n+    return dimension;\n+  }\n+\n+  public String getValue()\n+  {\n+    return value;\n+  }\n+\n+  @Override\n+  public boolean equals(Object o)", "originalCommit": "443d7274a49c71429d87afce3667b96d35dba517", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk5NjY3MA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374996670", "bodyText": "Added an EqualsVerifier test", "author": "jon-wei", "createdAt": "2020-02-05T00:15:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI4MTA0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMwNTgwNg==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374305806", "bodyText": "Maybe use Collections.singletonList() instead", "author": "ccaominh", "createdAt": "2020-02-03T19:50:56Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,739 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+\n+  public static JoinFilterSplit splitFilter(\n+      Filter originalFilter,\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      List<JoinableClause> clauses\n+  )\n+  {\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : clauses) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = new ArrayList<>();\n+      normalizedOrClauses.add(normalizedFilter);", "originalCommit": "443d7274a49c71429d87afce3667b96d35dba517", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk5NjcyNQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374996725", "bodyText": "Changed to Collections.singletonList()", "author": "jon-wei", "createdAt": "2020-02-05T00:15:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMwNTgwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMwODM2MA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374308360", "bodyText": "Similar comment about testing with EqualsVerifier", "author": "ccaominh", "createdAt": "2020-02-03T19:56:02Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,739 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+\n+  public static JoinFilterSplit splitFilter(\n+      Filter originalFilter,\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      List<JoinableClause> clauses\n+  )\n+  {\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : clauses) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = new ArrayList<>();\n+      normalizedOrClauses.add(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          baseAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)", "originalCommit": "443d7274a49c71429d87afce3667b96d35dba517", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk5Njg1Ng==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374996856", "bodyText": "Added an EqualsVerifier test in the new JoinFilterAnalyzerTest class", "author": "jon-wei", "createdAt": "2020-02-05T00:15:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMwODM2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMxMDEzNQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374310135", "bodyText": "Can AllNullColumnSelectorFactory be made a private class variable so it does not need to be allocated each time?", "author": "ccaominh", "createdAt": "2020-02-03T19:59:22Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,739 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+\n+  public static JoinFilterSplit splitFilter(\n+      Filter originalFilter,\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      List<JoinableClause> clauses\n+  )\n+  {\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : clauses) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = new ArrayList<>();\n+      normalizedOrClauses.add(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          baseAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  @Nullable\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param filter           Filter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      Filter filter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    assert (filter instanceof SelectorFilter);\n+    SelectorFilter selectorFilter = (SelectorFilter) filter;\n+\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n+        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+            prefixAndClause.getKey(),\n+            p -> findCorrelatedBaseTableColumns(\n+                baseAdapter,\n+                p,\n+                prefixes.get(p),\n+                equiconditions\n+            )\n+        );\n+\n+        if (correlations == null) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filter);\n+        }\n+\n+        List<Filter> newFilters = new ArrayList<>();\n+        List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+          if (correlationAnalysis.supportsPushDown()) {\n+            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+                selectorFilter.getDimension(),\n+                selectorFilter.getValue(),\n+                correlationAnalysis.getJoinColumn(),\n+                prefixAndClause.getValue()\n+            );\n+\n+            if (correlatedValues == null) {\n+              return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+            }\n+\n+            for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  correlatedBaseColumn,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+\n+            for (Expr correlatedBaseExpr : correlationAnalysis.getBaseExpressions()) {\n+              // need to create a virtual column for the expressions when pushing down\n+              String vcName = getCorrelatedBaseExprVirtualColumnName(pushdownVirtualColumns.size());\n+\n+              VirtualColumn correlatedBaseExprVirtualColumn = new ExpressionVirtualColumn(\n+                  vcName,\n+                  correlatedBaseExpr,\n+                  ValueType.STRING\n+              );\n+              pushdownVirtualColumns.add(correlatedBaseExprVirtualColumn);\n+\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  vcName,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+          }\n+        }\n+\n+        if (newFilters.isEmpty()) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filter);\n+        }\n+\n+        return new JoinFilterAnalysis(\n+            true,\n+            true,\n+            filter,\n+            newFilters.size() == 1 ? newFilters.get(0) : new AndFilter(newFilters),\n+            pushdownVirtualColumns\n+        );\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filter,\n+        filter,\n+        null\n+    );\n+  }\n+\n+  private static String getCorrelatedBaseExprVirtualColumnName(int counter)\n+  {\n+    // May want to have this check other column names to absolutely prevent name conflicts\n+    return PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE + counter;\n+  }\n+\n+  /**\n+   * Helper method for rewriting filters on join table columns into filters on base table columns.\n+   *\n+   * @param filterColumn           A join table column that we're filtering on\n+   * @param filterValue            The value to filter on\n+   * @param correlatedJoinColumn   A join table column that appears as the RHS of an equicondition, which we can correlate\n+   *                               with a column on the base table\n+   * @param clauseForFilteredTable The joinable clause that corresponds to the join table being filtered on\n+   *\n+   * @return A list of values of the correlatedJoinColumn that appear in rows where filterColumn = filterValue\n+   * Returns null if we cannot determine the correlated values.\n+   */\n+  @Nullable\n+  private static List<String> getCorrelatedValuesForPushDown(\n+      String filterColumn,\n+      String filterValue,\n+      String correlatedJoinColumn,\n+      JoinableClause clauseForFilteredTable\n+  )\n+  {\n+    String filterColumnNoPrefix = filterColumn.substring(clauseForFilteredTable.getPrefix().length());\n+    String correlatedColumnNoPrefix = correlatedJoinColumn.substring(clauseForFilteredTable.getPrefix().length());\n+\n+    // would be good to allow non-key column indices on the Joinables for better perf\n+    if (clauseForFilteredTable.getJoinable() instanceof LookupJoinable) {\n+      LookupJoinable lookupJoinable = (LookupJoinable) clauseForFilteredTable.getJoinable();\n+      List<String> correlatedValues;\n+      if (LookupColumnSelectorFactory.KEY_COLUMN.equals(filterColumnNoPrefix)) {\n+        if (LookupColumnSelectorFactory.KEY_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = ImmutableList.of(lookupJoinable.getExtractor().apply(filterColumnNoPrefix));\n+        }\n+      } else {\n+        if (LookupColumnSelectorFactory.VALUE_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = lookupJoinable.getExtractor().unapply(filterValue);\n+        }\n+      }\n+      return correlatedValues;\n+    }\n+\n+    if (clauseForFilteredTable.getJoinable() instanceof IndexedTableJoinable) {\n+      IndexedTableJoinable indexedTableJoinable = (IndexedTableJoinable) clauseForFilteredTable.getJoinable();\n+      IndexedTable indexedTable = indexedTableJoinable.getTable();\n+\n+      int filterColumnPosition = indexedTable.allColumns().indexOf(filterColumnNoPrefix);\n+      int correlatedColumnPosition = indexedTable.allColumns().indexOf(correlatedColumnNoPrefix);\n+\n+      if (filterColumnPosition < 0 || correlatedColumnPosition < 0) {\n+        return null;\n+      }\n+\n+      if (indexedTable.keyColumns().contains(filterColumnNoPrefix)) {\n+        IndexedTable.Index index = indexedTable.columnIndex(filterColumnPosition);\n+        IndexedTable.Reader reader = indexedTable.columnReader(correlatedColumnPosition);\n+        IntList rowIndex = index.find(filterValue);\n+        List<String> correlatedValues = new ArrayList<>();\n+        for (int i = 0; i < rowIndex.size(); i++) {\n+          int rowNum = rowIndex.getInt(i);\n+          correlatedValues.add(reader.read(rowNum).toString());\n+        }\n+        return correlatedValues;\n+      } else {\n+        IndexedTable.Reader dimNameReader = indexedTable.columnReader(filterColumnPosition);\n+        IndexedTable.Reader correlatedColumnReader = indexedTable.columnReader(correlatedColumnPosition);\n+        Set<String> correlatedValueSet = new HashSet<>();\n+        for (int i = 0; i < indexedTable.numRows(); i++) {\n+          if (filterValue.equals(dimNameReader.read(i).toString())) {\n+            correlatedValueSet.add(correlatedColumnReader.read(i).toString());\n+          }\n+        }\n+\n+        return new ArrayList<>(correlatedValueSet);\n+      }\n+    }\n+\n+    return null;\n+  }\n+\n+  /**\n+   * For all RHS columns that appear in the join's equiconditions, correlate them with base table columns if possible.\n+   *\n+   * @param adapter              The adapter for the join. Used to determine if a column is a base table column.\n+   * @param tablePrefix          Prefix for a join table\n+   * @param clauseForTablePrefix Joinable clause for the prefix\n+   * @param equiconditions       Map of equiconditions, keyed by the right hand columns\n+   *\n+   * @return A list of correlatation analyses for the equicondition RHS columns that reside in the table associated with\n+   * the tablePrefix\n+   */\n+  @Nullable\n+  private static List<JoinFilterColumnCorrelationAnalysis> findCorrelatedBaseTableColumns(\n+      HashJoinSegmentStorageAdapter adapter,\n+      String tablePrefix,\n+      JoinableClause clauseForTablePrefix,\n+      Map<String, Expr> equiconditions\n+  )\n+  {\n+    JoinConditionAnalysis jca = clauseForTablePrefix.getCondition();\n+\n+    List<String> rhsColumns = new ArrayList<>();\n+    for (Equality eq : jca.getEquiConditions()) {\n+      rhsColumns.add(tablePrefix + eq.getRightColumn());\n+    }\n+\n+    List<JoinFilterColumnCorrelationAnalysis> correlations = new ArrayList<>();\n+\n+    for (String rhsColumn : rhsColumns) {\n+      List<String> correlatedBaseColumns = new ArrayList<>();\n+      List<Expr> correlatedBaseExpressions = new ArrayList<>();\n+      boolean terminate = false;\n+\n+      String findMappingFor = rhsColumn;\n+      while (!terminate) {\n+        Expr lhs = equiconditions.get(findMappingFor);\n+        if (lhs == null) {\n+          break;\n+        }\n+        String identifier = lhs.getBindingIfIdentifier();\n+        if (identifier == null) {\n+          // We push down if the function only requires base table columns\n+          Expr.BindingDetails bindingDetails = lhs.analyzeInputs();\n+          Set<String> requiredBindings = bindingDetails.getRequiredBindings();\n+          for (String requiredBinding : requiredBindings) {\n+            if (!adapter.isBaseColumn(requiredBinding)) {\n+              return null;\n+            }\n+          }\n+\n+          terminate = true;\n+          correlatedBaseExpressions.add(lhs);\n+        } else {\n+          // simple identifier, see if we can correlate it with a column on the base table\n+          findMappingFor = identifier;\n+          if (adapter.isBaseColumn(identifier)) {\n+            terminate = true;\n+            correlatedBaseColumns.add(findMappingFor);\n+          }\n+        }\n+      }\n+\n+      if (correlatedBaseColumns.isEmpty() && correlatedBaseExpressions.isEmpty()) {\n+        return null;\n+      }\n+\n+      correlations.add(\n+          new JoinFilterColumnCorrelationAnalysis(\n+              rhsColumn,\n+              correlatedBaseColumns,\n+              correlatedBaseExpressions\n+          )\n+      );\n+    }\n+\n+    return correlations;\n+  }\n+\n+  private static boolean filterMatchesNull(Filter filter)\n+  {\n+    ValueMatcher valueMatcher = filter.makeMatcher(new AllNullColumnSelectorFactory());", "originalCommit": "443d7274a49c71429d87afce3667b96d35dba517", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk5NzA2Mw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374997063", "bodyText": "Whoops, made a private static AllNullColumnSelectorFactory", "author": "jon-wei", "createdAt": "2020-02-05T00:16:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMxMDEzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMxMjExMg==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374312112", "bodyText": "Would you still need this if JoinFilterAnalyzerTest was created and had unit tests for JoinFilterAnalyzer?", "author": "ccaominh", "createdAt": "2020-02-03T20:03:25Z", "path": "processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java", "diffHunk": "@@ -52,6 +54,11 @@\n   private final StorageAdapter baseAdapter;\n   private final List<JoinableClause> clauses;\n \n+  // A reference to the last JoinFilterSplit created during a makeCursors call,\n+  // saved and exposed so that tests can verify the filter splitting behavior.\n+  @VisibleForTesting\n+  private JoinFilterAnalyzer.JoinFilterSplit previousJoinFilterSplitForTesting;", "originalCommit": "443d7274a49c71429d87afce3667b96d35dba517", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk5ODAyMw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374998023", "bodyText": "I restructured the tests in JoinFilterAnalyzerTest to call JoinFilterAnalyzer.splitFilter directly, and got rid of this testing hook.\nThis means the filter split would be calculated twice in the tests (since I still call verifyCursors later), but I think that's fine for tests.", "author": "jon-wei", "createdAt": "2020-02-05T00:20:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMxMjExMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMxMjc1OA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374312758", "bodyText": "Can remove since this method never returns null", "author": "ccaominh", "createdAt": "2020-02-03T20:04:48Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,739 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+\n+  public static JoinFilterSplit splitFilter(\n+      Filter originalFilter,\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      List<JoinableClause> clauses\n+  )\n+  {\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : clauses) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = new ArrayList<>();\n+      normalizedOrClauses.add(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          baseAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  @Nullable", "originalCommit": "443d7274a49c71429d87afce3667b96d35dba517", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk5NzcyMw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374997723", "bodyText": "Removed the unnecessary @Nullable", "author": "jon-wei", "createdAt": "2020-02-05T00:19:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMxMjc1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMxNDM4MQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374314381", "bodyText": "Can rewriteSelectorFilter's filter parameter be of type SelectorFilter instead?", "author": "ccaominh", "createdAt": "2020-02-03T20:08:22Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,739 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+\n+  public static JoinFilterSplit splitFilter(\n+      Filter originalFilter,\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      List<JoinableClause> clauses\n+  )\n+  {\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : clauses) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = new ArrayList<>();\n+      normalizedOrClauses.add(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          baseAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  @Nullable\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param filter           Filter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      Filter filter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    assert (filter instanceof SelectorFilter);\n+    SelectorFilter selectorFilter = (SelectorFilter) filter;", "originalCommit": "443d7274a49c71429d87afce3667b96d35dba517", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk5NzUzNQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374997535", "bodyText": "Changed to SelectorFilter", "author": "jon-wei", "createdAt": "2020-02-05T00:18:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMxNDM4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMxOTkyOQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374319929", "bodyText": "The test coverage of the filter push down code is great!\nWhat do you think about making many of these test cases as unit tests in JoinFilterAnalyzerTest instead? That way it's more straightforward to map the test case to the relevant code.", "author": "ccaominh", "createdAt": "2020-02-03T20:20:14Z", "path": "processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java", "diffHunk": "@@ -1288,103 +1313,1163 @@ public void test_makeCursors_errorOnNonKeyBasedJoin()\n     );\n   }\n \n-  private JoinableClause factToCountryNameUsingIsoCodeLookup(final JoinType joinType)\n+  // Filter push down tests", "originalCommit": "443d7274a49c71429d87afce3667b96d35dba517", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk5NzQ5Mw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374997493", "bodyText": "Thanks!\nI split out the segment setup and some helper methods out of HashJoinSegmentStorageAdapterTest into BaseHashJoinSegmentStorageAdapterTest since the JoinFilterAnalyzer needs a HashJoinSegmentStorageAdapter, both JoinFilterAnalyzerTest and HashJoinSegmentStorageAdapterTest now extend the base.\nThe filter push down tests have been moved into JoinFilterAnalyzerTest", "author": "jon-wei", "createdAt": "2020-02-05T00:18:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMxOTkyOQ=="}], "type": "inlineReview"}, {"oid": "2150436af7691541d0462c39a9caa5e9a46e5c29", "url": "https://github.com/apache/druid/commit/2150436af7691541d0462c39a9caa5e9a46e5c29", "message": "Address PR comments", "committedDate": "2020-02-05T00:02:32Z", "type": "commit"}, {"oid": "b31fbddcd678b5f9faf705a2def1864072188929", "url": "https://github.com/apache/druid/commit/b31fbddcd678b5f9faf705a2def1864072188929", "message": "More PR comments", "committedDate": "2020-02-05T00:12:03Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk5ODQ5OQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r374998499", "bodyText": "I just realized there's a bug with this part (it needs to create a globally unique virtual column name), will fix in a follow-on PR.", "author": "jon-wei", "createdAt": "2020-02-05T00:22:10Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          (SelectorFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              (SelectorFilter) filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param selectorFilter   SelectorFilter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      SelectorFilter selectorFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n+        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+            prefixAndClause.getKey(),\n+            p -> findCorrelatedBaseTableColumns(\n+                baseAdapter,\n+                p,\n+                prefixes.get(p),\n+                equiconditions\n+            )\n+        );\n+\n+        if (correlations == null) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        List<Filter> newFilters = new ArrayList<>();\n+        List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+          if (correlationAnalysis.supportsPushDown()) {\n+            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+                selectorFilter.getDimension(),\n+                selectorFilter.getValue(),\n+                correlationAnalysis.getJoinColumn(),\n+                prefixAndClause.getValue()\n+            );\n+\n+            if (correlatedValues == null) {\n+              return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+            }\n+\n+            for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  correlatedBaseColumn,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+\n+            for (Expr correlatedBaseExpr : correlationAnalysis.getBaseExpressions()) {\n+              // need to create a virtual column for the expressions when pushing down\n+              String vcName = getCorrelatedBaseExprVirtualColumnName(pushdownVirtualColumns.size());", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAwNzI3NQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375007275", "bodyText": "It would be great to have a javadoc here describing what kind of analysis this class is trying to do, and why. Something like the javadocs at the top of JoinConditionAnalysis and DataSourceAnalysis.", "author": "gianm", "createdAt": "2020-02-05T00:55:20Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2NTc4MA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375665780", "bodyText": "Added javadoc here describing the goal and details about the push down and rewrites", "author": "jon-wei", "createdAt": "2020-02-06T06:54:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAwNzI3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjA0OTkxNg==", "url": "https://github.com/apache/druid/pull/9301#discussion_r376049916", "bodyText": "Thanks!", "author": "gianm", "createdAt": "2020-02-06T19:56:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAwNzI3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAwNzg3Nw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375007877", "bodyText": "Skimming a bit, it seems like this would work if it was given a List<JoinableClause> instead of a HashJoinSegmentStorageAdapter. If so, that'd be a good change (it's better for methods like this to take conceptually smaller objects \u2014\u00a0unit testing is easier, and it makes it clearer what the 'real' dependencies are of the computation it is doing).", "author": "gianm", "createdAt": "2020-02-05T00:57:27Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2NjI3MQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375666271", "bodyText": "Right now it could be changed to just accept a list of joinable clauses, but in the future I think the filter analysis would likely need to check the column capabilities and other info from the adapter, so I think it should accept the adapter instead", "author": "jon-wei", "createdAt": "2020-02-06T06:56:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAwNzg3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAwOTMyMw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375009323", "bodyText": "This code assumes that no two clauses have the same prefix, and (maybe also?) that the prefixes don't shadow each other. I don't think anything currently verifies either of those preconditions. It'd be good to add validation somewhere. Maybe right here, or maybe in HashJoinSegment's constructor. Maybe add a Joinables function that verifies it and call it wherever might care.", "author": "gianm", "createdAt": "2020-02-05T01:02:49Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2NjUzMg==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375666532", "bodyText": "Hm, that sounds good, but can we address this in a follow-on PR since it's not specific to the filtering code?", "author": "jon-wei", "createdAt": "2020-02-06T06:58:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAwOTMyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjA1MjA3OA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r376052078", "bodyText": "I think it is specific to the filtering code, because it's handled consistently elsewhere. (The clauses check in order whether they match and the first one wins.) So this patch is introducing an inconsistency in behavior that didn't used to exist. But I do think it's fine to do in a follow on. Please raise a github issue and add a comment pointing to it.", "author": "gianm", "createdAt": "2020-02-06T20:01:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAwOTMyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjEyOTA5OA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r376129098", "bodyText": "I opened #9329 and linked it in a comment here", "author": "jon-wei", "createdAt": "2020-02-06T22:58:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAwOTMyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxMDcyOA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375010728", "bodyText": "Maybe clearer to say that this single clause is expected to be either an OR or a leaf filter.", "author": "gianm", "createdAt": "2020-02-05T01:07:55Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2NjU5NA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375666594", "bodyText": "Adjusted the wording to the suggested", "author": "jon-wei", "createdAt": "2020-02-06T06:58:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxMDcyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxMjQ4OA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375012488", "bodyText": "Would be nice to say why (I presume it's something like: conditions that match NULL are tricky to push down when doing OUTER JOINs, and we'd rather not worry about that right now).", "author": "gianm", "createdAt": "2020-02-05T01:15:05Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2NjcwMQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375666701", "bodyText": "Added a comment about why NULL matching conditions are not handled now", "author": "jon-wei", "createdAt": "2020-02-06T06:58:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxMjQ4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxMzQxNA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375013414", "bodyText": "It looks like it's expected that callers will modify this parameter. It'd be good to note that (and any other case where it's expected that parameters will be modified).", "author": "gianm", "createdAt": "2020-02-05T01:18:30Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2Njc4NA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375666784", "bodyText": "Added a note about the cache being modified", "author": "jon-wei", "createdAt": "2020-02-06T06:58:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxMzQxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNDczMA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375014730", "bodyText": "Instead of doing an instanceof, could you add a method to Joinable that enables this use case? The interface is still really new and we should be evolving it to meet our needs.", "author": "gianm", "createdAt": "2020-02-05T01:23:16Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          (SelectorFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              (SelectorFilter) filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param selectorFilter   SelectorFilter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      SelectorFilter selectorFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n+        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+            prefixAndClause.getKey(),\n+            p -> findCorrelatedBaseTableColumns(\n+                baseAdapter,\n+                p,\n+                prefixes.get(p),\n+                equiconditions\n+            )\n+        );\n+\n+        if (correlations == null) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        List<Filter> newFilters = new ArrayList<>();\n+        List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+          if (correlationAnalysis.supportsPushDown()) {\n+            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+                selectorFilter.getDimension(),\n+                selectorFilter.getValue(),\n+                correlationAnalysis.getJoinColumn(),\n+                prefixAndClause.getValue()\n+            );\n+\n+            if (correlatedValues == null) {\n+              return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+            }\n+\n+            for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  correlatedBaseColumn,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+\n+            for (Expr correlatedBaseExpr : correlationAnalysis.getBaseExpressions()) {\n+              // need to create a virtual column for the expressions when pushing down\n+              String vcName = getCorrelatedBaseExprVirtualColumnName(pushdownVirtualColumns.size());\n+\n+              VirtualColumn correlatedBaseExprVirtualColumn = new ExpressionVirtualColumn(\n+                  vcName,\n+                  correlatedBaseExpr,\n+                  ValueType.STRING\n+              );\n+              pushdownVirtualColumns.add(correlatedBaseExprVirtualColumn);\n+\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  vcName,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+          }\n+        }\n+\n+        if (newFilters.isEmpty()) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        return new JoinFilterAnalysis(\n+            true,\n+            true,\n+            selectorFilter,\n+            newFilters.size() == 1 ? newFilters.get(0) : new AndFilter(newFilters),\n+            pushdownVirtualColumns\n+        );\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        selectorFilter,\n+        selectorFilter,\n+        null\n+    );\n+  }\n+\n+  private static String getCorrelatedBaseExprVirtualColumnName(int counter)\n+  {\n+    // May want to have this check other column names to absolutely prevent name conflicts\n+    return PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE + counter;\n+  }\n+\n+  /**\n+   * Helper method for rewriting filters on join table columns into filters on base table columns.\n+   *\n+   * @param filterColumn           A join table column that we're filtering on\n+   * @param filterValue            The value to filter on\n+   * @param correlatedJoinColumn   A join table column that appears as the RHS of an equicondition, which we can correlate\n+   *                               with a column on the base table\n+   * @param clauseForFilteredTable The joinable clause that corresponds to the join table being filtered on\n+   *\n+   * @return A list of values of the correlatedJoinColumn that appear in rows where filterColumn = filterValue\n+   * Returns null if we cannot determine the correlated values.\n+   */\n+  @Nullable\n+  private static List<String> getCorrelatedValuesForPushDown(\n+      String filterColumn,\n+      String filterValue,\n+      String correlatedJoinColumn,\n+      JoinableClause clauseForFilteredTable\n+  )\n+  {\n+    String filterColumnNoPrefix = filterColumn.substring(clauseForFilteredTable.getPrefix().length());\n+    String correlatedColumnNoPrefix = correlatedJoinColumn.substring(clauseForFilteredTable.getPrefix().length());\n+\n+    // would be good to allow non-key column indices on the Joinables for better perf\n+    if (clauseForFilteredTable.getJoinable() instanceof LookupJoinable) {", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2Njg2OQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375666869", "bodyText": "Added a getCorrelatedColumnValues method on Joinable", "author": "jon-wei", "createdAt": "2020-02-06T06:59:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNDczMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjA2MTA0MQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r376061041", "bodyText": "I just read the javadoc. Could you please clarify (or rename) what \"main column\" means and also where \"correlationColumnName\" is supposed to come from? They're concepts that haven't been defined elsewhere in the class and it's not immediately clear to me what they mean. I'm guessing both columns are from the Joinable itself, and \"main column\" means the one being searched and \"correlation column\" means the one being retrieved.\nCurrently it says:\n\nGiven a key column name and value, return all the values of the column denoted by correlationColumnName that appear in rows where the main column has the provided main column value.\n\nIf my guesses are right then how about:\n\nSearches a column from this Joinable for a particular value, finds rows that match and returns values of a second column for those rows.\nArguments \"searchColumn\", \"searchValue\", \"retrievalColumn\"", "author": "gianm", "createdAt": "2020-02-06T20:20:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNDczMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjEyOTI2MQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r376129261", "bodyText": "Thanks, those are much better names, changed to the suggested description and names", "author": "jon-wei", "createdAt": "2020-02-06T22:58:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNDczMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNjgxMQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375016811", "bodyText": "Do people outside this class need to be able to make their own? Could be private if not.", "author": "gianm", "createdAt": "2020-02-05T01:31:22Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2NzA2Mg==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375667062", "bodyText": "I moved this into a separate file, the tests need to be able to create expected splits so the new class is public", "author": "jon-wei", "createdAt": "2020-02-06T07:00:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNjgxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNzA4Mw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375017083", "bodyText": "This should be @Nullable given the annotation in the constructor.\nAlternatively, consider Optional<Filter> rather than @Nullable Filter.", "author": "gianm", "createdAt": "2020-02-05T01:32:31Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2NzE2MQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375667161", "bodyText": "Adjusted this to return Optional<Filter> for the filter getters", "author": "jon-wei", "createdAt": "2020-02-06T07:00:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNzA4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjA2MTI1OA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r376061258", "bodyText": "Rad.", "author": "gianm", "createdAt": "2020-02-06T20:21:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNzA4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxOTc2Nw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375019767", "bodyText": "nit: Inconsistent spelling of \"pushdown\" (or \"pushDown\"?) between isCanPushDown, getPushdownFilter.", "author": "gianm", "createdAt": "2020-02-05T01:43:06Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2NzIyMw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375667223", "bodyText": "Made these use pushDown consistently", "author": "jon-wei", "createdAt": "2020-02-06T07:00:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxOTc2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyMDIwOQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375020209", "bodyText": "It looks like this is the only spot getPushdownVirtualColumns is null-guarded, and in this case, using an empty list instead of null would have the same effect. Maybe nix the nullability and use an empty list instead?", "author": "gianm", "createdAt": "2020-02-05T01:44:53Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2NzMwNA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375667304", "bodyText": "Adjusted getPushdownVirtualColumns to use an empty list instead", "author": "jon-wei", "createdAt": "2020-02-06T07:01:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyMDIwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyMDc3Ng==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375020776", "bodyText": "Small suggestion: might be nice to make this a helper method like Filters.and(List<Filter>). This logic is duplicated in QueryableIndexStroageAdapter, so they could both use such a helper.", "author": "gianm", "createdAt": "2020-02-05T01:47:12Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2NzM5Mg==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375667392", "bodyText": "Added a Filters.and method and adjusted this and QueryableIndexStroageAdapter", "author": "jon-wei", "createdAt": "2020-02-06T07:01:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyMDc3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyMjI2Nw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375022267", "bodyText": "Should use prefixAndClause.getValue().includesColumn(filteringColumn) \u2014\u00a0it's more semantically intentful and also the logic is slightly different.", "author": "gianm", "createdAt": "2020-02-05T01:53:24Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          (SelectorFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              (SelectorFilter) filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param selectorFilter   SelectorFilter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      SelectorFilter selectorFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2NzQyNw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375667427", "bodyText": "Changed to the suggested", "author": "jon-wei", "createdAt": "2020-02-06T07:01:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyMjI2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyMzA0MQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375023041", "bodyText": "null is used for two things here:\n(a) correlationCache hasn't been populated yet\n(b) correlationCache has been populated, but findCorrelatedBaseTableColumns returned null\nWould it make sense to have findCorrelatedBaseTableColumns return Optional<List<JoinFilterColumnCorrelationAnalysis>> rather than @Nullable List<JoinFilterColumnCorrelationAnalysis>?", "author": "gianm", "createdAt": "2020-02-05T01:56:41Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          (SelectorFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              (SelectorFilter) filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param selectorFilter   SelectorFilter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      SelectorFilter selectorFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n+        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+            prefixAndClause.getKey(),\n+            p -> findCorrelatedBaseTableColumns(", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2NzUyNg==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375667526", "bodyText": "Hm, good point, I changed the map values to Optional<List<JoinFilterColumnCorrelationAnalysis>>", "author": "jon-wei", "createdAt": "2020-02-06T07:01:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyMzA0MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNDYyNg==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375024626", "bodyText": "This class is pretty jam packed with different concepts and inner classes, maybe it would make sense to put it in its own org.apache.druid.segment.join.filter package and split it up into different classes? (Sort of like DataSourceAnalysis and its friend PreJoinableClause in org.apache.druid.query.planning, but this one is even more complex)", "author": "gianm", "createdAt": "2020-02-05T02:03:20Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          (SelectorFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              (SelectorFilter) filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param selectorFilter   SelectorFilter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      SelectorFilter selectorFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n+        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+            prefixAndClause.getKey(),\n+            p -> findCorrelatedBaseTableColumns(\n+                baseAdapter,\n+                p,\n+                prefixes.get(p),\n+                equiconditions\n+            )\n+        );\n+\n+        if (correlations == null) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        List<Filter> newFilters = new ArrayList<>();\n+        List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+          if (correlationAnalysis.supportsPushDown()) {\n+            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+                selectorFilter.getDimension(),\n+                selectorFilter.getValue(),\n+                correlationAnalysis.getJoinColumn(),\n+                prefixAndClause.getValue()\n+            );\n+\n+            if (correlatedValues == null) {\n+              return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+            }\n+\n+            for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  correlatedBaseColumn,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+\n+            for (Expr correlatedBaseExpr : correlationAnalysis.getBaseExpressions()) {\n+              // need to create a virtual column for the expressions when pushing down\n+              String vcName = getCorrelatedBaseExprVirtualColumnName(pushdownVirtualColumns.size());\n+\n+              VirtualColumn correlatedBaseExprVirtualColumn = new ExpressionVirtualColumn(\n+                  vcName,\n+                  correlatedBaseExpr,\n+                  ValueType.STRING\n+              );\n+              pushdownVirtualColumns.add(correlatedBaseExprVirtualColumn);\n+\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  vcName,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+          }\n+        }\n+\n+        if (newFilters.isEmpty()) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        return new JoinFilterAnalysis(\n+            true,\n+            true,\n+            selectorFilter,\n+            newFilters.size() == 1 ? newFilters.get(0) : new AndFilter(newFilters),\n+            pushdownVirtualColumns\n+        );\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        selectorFilter,\n+        selectorFilter,\n+        null\n+    );\n+  }\n+\n+  private static String getCorrelatedBaseExprVirtualColumnName(int counter)\n+  {\n+    // May want to have this check other column names to absolutely prevent name conflicts\n+    return PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE + counter;\n+  }\n+\n+  /**\n+   * Helper method for rewriting filters on join table columns into filters on base table columns.\n+   *\n+   * @param filterColumn           A join table column that we're filtering on\n+   * @param filterValue            The value to filter on\n+   * @param correlatedJoinColumn   A join table column that appears as the RHS of an equicondition, which we can correlate\n+   *                               with a column on the base table\n+   * @param clauseForFilteredTable The joinable clause that corresponds to the join table being filtered on\n+   *\n+   * @return A list of values of the correlatedJoinColumn that appear in rows where filterColumn = filterValue\n+   * Returns null if we cannot determine the correlated values.\n+   */\n+  @Nullable\n+  private static List<String> getCorrelatedValuesForPushDown(\n+      String filterColumn,\n+      String filterValue,\n+      String correlatedJoinColumn,\n+      JoinableClause clauseForFilteredTable\n+  )\n+  {\n+    String filterColumnNoPrefix = filterColumn.substring(clauseForFilteredTable.getPrefix().length());\n+    String correlatedColumnNoPrefix = correlatedJoinColumn.substring(clauseForFilteredTable.getPrefix().length());\n+\n+    // would be good to allow non-key column indices on the Joinables for better perf\n+    if (clauseForFilteredTable.getJoinable() instanceof LookupJoinable) {\n+      LookupJoinable lookupJoinable = (LookupJoinable) clauseForFilteredTable.getJoinable();\n+      List<String> correlatedValues;\n+      if (LookupColumnSelectorFactory.KEY_COLUMN.equals(filterColumnNoPrefix)) {\n+        if (LookupColumnSelectorFactory.KEY_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = ImmutableList.of(lookupJoinable.getExtractor().apply(filterColumnNoPrefix));\n+        }\n+      } else {\n+        if (LookupColumnSelectorFactory.VALUE_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = lookupJoinable.getExtractor().unapply(filterValue);\n+        }\n+      }\n+      return correlatedValues;\n+    }\n+\n+    if (clauseForFilteredTable.getJoinable() instanceof IndexedTableJoinable) {\n+      IndexedTableJoinable indexedTableJoinable = (IndexedTableJoinable) clauseForFilteredTable.getJoinable();\n+      IndexedTable indexedTable = indexedTableJoinable.getTable();\n+\n+      int filterColumnPosition = indexedTable.allColumns().indexOf(filterColumnNoPrefix);\n+      int correlatedColumnPosition = indexedTable.allColumns().indexOf(correlatedColumnNoPrefix);\n+\n+      if (filterColumnPosition < 0 || correlatedColumnPosition < 0) {\n+        return null;\n+      }\n+\n+      if (indexedTable.keyColumns().contains(filterColumnNoPrefix)) {\n+        IndexedTable.Index index = indexedTable.columnIndex(filterColumnPosition);\n+        IndexedTable.Reader reader = indexedTable.columnReader(correlatedColumnPosition);\n+        IntList rowIndex = index.find(filterValue);\n+        List<String> correlatedValues = new ArrayList<>();\n+        for (int i = 0; i < rowIndex.size(); i++) {\n+          int rowNum = rowIndex.getInt(i);\n+          correlatedValues.add(reader.read(rowNum).toString());\n+        }\n+        return correlatedValues;\n+      } else {\n+        IndexedTable.Reader dimNameReader = indexedTable.columnReader(filterColumnPosition);\n+        IndexedTable.Reader correlatedColumnReader = indexedTable.columnReader(correlatedColumnPosition);\n+        Set<String> correlatedValueSet = new HashSet<>();\n+        for (int i = 0; i < indexedTable.numRows(); i++) {\n+          if (filterValue.equals(dimNameReader.read(i).toString())) {\n+            correlatedValueSet.add(correlatedColumnReader.read(i).toString());\n+          }\n+        }\n+\n+        return new ArrayList<>(correlatedValueSet);\n+      }\n+    }\n+\n+    return null;\n+  }\n+\n+  /**\n+   * For all RHS columns that appear in the join's equiconditions, correlate them with base table columns if possible.\n+   *\n+   * @param adapter              The adapter for the join. Used to determine if a column is a base table column.\n+   * @param tablePrefix          Prefix for a join table\n+   * @param clauseForTablePrefix Joinable clause for the prefix\n+   * @param equiconditions       Map of equiconditions, keyed by the right hand columns\n+   *\n+   * @return A list of correlatation analyses for the equicondition RHS columns that reside in the table associated with\n+   * the tablePrefix\n+   */\n+  @Nullable\n+  private static List<JoinFilterColumnCorrelationAnalysis> findCorrelatedBaseTableColumns(\n+      HashJoinSegmentStorageAdapter adapter,\n+      String tablePrefix,\n+      JoinableClause clauseForTablePrefix,\n+      Map<String, Expr> equiconditions\n+  )\n+  {\n+    JoinConditionAnalysis jca = clauseForTablePrefix.getCondition();\n+\n+    List<String> rhsColumns = new ArrayList<>();\n+    for (Equality eq : jca.getEquiConditions()) {\n+      rhsColumns.add(tablePrefix + eq.getRightColumn());\n+    }\n+\n+    List<JoinFilterColumnCorrelationAnalysis> correlations = new ArrayList<>();\n+\n+    for (String rhsColumn : rhsColumns) {\n+      List<String> correlatedBaseColumns = new ArrayList<>();\n+      List<Expr> correlatedBaseExpressions = new ArrayList<>();\n+      boolean terminate = false;\n+\n+      String findMappingFor = rhsColumn;\n+      while (!terminate) {\n+        Expr lhs = equiconditions.get(findMappingFor);\n+        if (lhs == null) {\n+          break;\n+        }\n+        String identifier = lhs.getBindingIfIdentifier();\n+        if (identifier == null) {\n+          // We push down if the function only requires base table columns\n+          Expr.BindingDetails bindingDetails = lhs.analyzeInputs();\n+          Set<String> requiredBindings = bindingDetails.getRequiredBindings();\n+          for (String requiredBinding : requiredBindings) {\n+            if (!adapter.isBaseColumn(requiredBinding)) {\n+              return null;\n+            }\n+          }\n+\n+          terminate = true;\n+          correlatedBaseExpressions.add(lhs);\n+        } else {\n+          // simple identifier, see if we can correlate it with a column on the base table\n+          findMappingFor = identifier;\n+          if (adapter.isBaseColumn(identifier)) {\n+            terminate = true;\n+            correlatedBaseColumns.add(findMappingFor);\n+          }\n+        }\n+      }\n+\n+      if (correlatedBaseColumns.isEmpty() && correlatedBaseExpressions.isEmpty()) {\n+        return null;\n+      }\n+\n+      correlations.add(\n+          new JoinFilterColumnCorrelationAnalysis(\n+              rhsColumn,\n+              correlatedBaseColumns,\n+              correlatedBaseExpressions\n+          )\n+      );\n+    }\n+\n+    return correlations;\n+  }\n+\n+  private static boolean filterMatchesNull(Filter filter)\n+  {\n+    ValueMatcher valueMatcher = filter.makeMatcher(ALL_NULL_COLUMN_SELECTOR_FACTORY);\n+    return valueMatcher.matches();\n+  }\n+\n+  private static class AllNullColumnSelectorFactory implements ColumnSelectorFactory", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2NzY0Mg==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375667642", "bodyText": "I split out the inner classes and JoinFilterAnalyzer into a new package org.apache.druid.segment.join.filter", "author": "jon-wei", "createdAt": "2020-02-06T07:02:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNDYyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNTMyNg==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375025326", "bodyText": "equiConditions would match the spelling from JoinConditionAnalysis.", "author": "gianm", "createdAt": "2020-02-05T02:06:19Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          (SelectorFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              (SelectorFilter) filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param selectorFilter   SelectorFilter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      SelectorFilter selectorFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n+        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+            prefixAndClause.getKey(),\n+            p -> findCorrelatedBaseTableColumns(\n+                baseAdapter,\n+                p,\n+                prefixes.get(p),\n+                equiconditions\n+            )\n+        );\n+\n+        if (correlations == null) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        List<Filter> newFilters = new ArrayList<>();\n+        List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+          if (correlationAnalysis.supportsPushDown()) {\n+            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+                selectorFilter.getDimension(),\n+                selectorFilter.getValue(),\n+                correlationAnalysis.getJoinColumn(),\n+                prefixAndClause.getValue()\n+            );\n+\n+            if (correlatedValues == null) {\n+              return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+            }\n+\n+            for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  correlatedBaseColumn,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+\n+            for (Expr correlatedBaseExpr : correlationAnalysis.getBaseExpressions()) {\n+              // need to create a virtual column for the expressions when pushing down\n+              String vcName = getCorrelatedBaseExprVirtualColumnName(pushdownVirtualColumns.size());\n+\n+              VirtualColumn correlatedBaseExprVirtualColumn = new ExpressionVirtualColumn(\n+                  vcName,\n+                  correlatedBaseExpr,\n+                  ValueType.STRING\n+              );\n+              pushdownVirtualColumns.add(correlatedBaseExprVirtualColumn);\n+\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  vcName,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+          }\n+        }\n+\n+        if (newFilters.isEmpty()) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        return new JoinFilterAnalysis(\n+            true,\n+            true,\n+            selectorFilter,\n+            newFilters.size() == 1 ? newFilters.get(0) : new AndFilter(newFilters),\n+            pushdownVirtualColumns\n+        );\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        selectorFilter,\n+        selectorFilter,\n+        null\n+    );\n+  }\n+\n+  private static String getCorrelatedBaseExprVirtualColumnName(int counter)\n+  {\n+    // May want to have this check other column names to absolutely prevent name conflicts\n+    return PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE + counter;\n+  }\n+\n+  /**\n+   * Helper method for rewriting filters on join table columns into filters on base table columns.\n+   *\n+   * @param filterColumn           A join table column that we're filtering on\n+   * @param filterValue            The value to filter on\n+   * @param correlatedJoinColumn   A join table column that appears as the RHS of an equicondition, which we can correlate\n+   *                               with a column on the base table\n+   * @param clauseForFilteredTable The joinable clause that corresponds to the join table being filtered on\n+   *\n+   * @return A list of values of the correlatedJoinColumn that appear in rows where filterColumn = filterValue\n+   * Returns null if we cannot determine the correlated values.\n+   */\n+  @Nullable\n+  private static List<String> getCorrelatedValuesForPushDown(\n+      String filterColumn,\n+      String filterValue,\n+      String correlatedJoinColumn,\n+      JoinableClause clauseForFilteredTable\n+  )\n+  {\n+    String filterColumnNoPrefix = filterColumn.substring(clauseForFilteredTable.getPrefix().length());\n+    String correlatedColumnNoPrefix = correlatedJoinColumn.substring(clauseForFilteredTable.getPrefix().length());\n+\n+    // would be good to allow non-key column indices on the Joinables for better perf\n+    if (clauseForFilteredTable.getJoinable() instanceof LookupJoinable) {\n+      LookupJoinable lookupJoinable = (LookupJoinable) clauseForFilteredTable.getJoinable();\n+      List<String> correlatedValues;\n+      if (LookupColumnSelectorFactory.KEY_COLUMN.equals(filterColumnNoPrefix)) {\n+        if (LookupColumnSelectorFactory.KEY_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = ImmutableList.of(lookupJoinable.getExtractor().apply(filterColumnNoPrefix));\n+        }\n+      } else {\n+        if (LookupColumnSelectorFactory.VALUE_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = lookupJoinable.getExtractor().unapply(filterValue);\n+        }\n+      }\n+      return correlatedValues;\n+    }\n+\n+    if (clauseForFilteredTable.getJoinable() instanceof IndexedTableJoinable) {\n+      IndexedTableJoinable indexedTableJoinable = (IndexedTableJoinable) clauseForFilteredTable.getJoinable();\n+      IndexedTable indexedTable = indexedTableJoinable.getTable();\n+\n+      int filterColumnPosition = indexedTable.allColumns().indexOf(filterColumnNoPrefix);\n+      int correlatedColumnPosition = indexedTable.allColumns().indexOf(correlatedColumnNoPrefix);\n+\n+      if (filterColumnPosition < 0 || correlatedColumnPosition < 0) {\n+        return null;\n+      }\n+\n+      if (indexedTable.keyColumns().contains(filterColumnNoPrefix)) {\n+        IndexedTable.Index index = indexedTable.columnIndex(filterColumnPosition);\n+        IndexedTable.Reader reader = indexedTable.columnReader(correlatedColumnPosition);\n+        IntList rowIndex = index.find(filterValue);\n+        List<String> correlatedValues = new ArrayList<>();\n+        for (int i = 0; i < rowIndex.size(); i++) {\n+          int rowNum = rowIndex.getInt(i);\n+          correlatedValues.add(reader.read(rowNum).toString());\n+        }\n+        return correlatedValues;\n+      } else {\n+        IndexedTable.Reader dimNameReader = indexedTable.columnReader(filterColumnPosition);\n+        IndexedTable.Reader correlatedColumnReader = indexedTable.columnReader(correlatedColumnPosition);\n+        Set<String> correlatedValueSet = new HashSet<>();\n+        for (int i = 0; i < indexedTable.numRows(); i++) {\n+          if (filterValue.equals(dimNameReader.read(i).toString())) {\n+            correlatedValueSet.add(correlatedColumnReader.read(i).toString());\n+          }\n+        }\n+\n+        return new ArrayList<>(correlatedValueSet);\n+      }\n+    }\n+\n+    return null;\n+  }\n+\n+  /**\n+   * For all RHS columns that appear in the join's equiconditions, correlate them with base table columns if possible.\n+   *\n+   * @param adapter              The adapter for the join. Used to determine if a column is a base table column.\n+   * @param tablePrefix          Prefix for a join table\n+   * @param clauseForTablePrefix Joinable clause for the prefix\n+   * @param equiconditions       Map of equiconditions, keyed by the right hand columns\n+   *\n+   * @return A list of correlatation analyses for the equicondition RHS columns that reside in the table associated with\n+   * the tablePrefix\n+   */\n+  @Nullable\n+  private static List<JoinFilterColumnCorrelationAnalysis> findCorrelatedBaseTableColumns(\n+      HashJoinSegmentStorageAdapter adapter,\n+      String tablePrefix,\n+      JoinableClause clauseForTablePrefix,\n+      Map<String, Expr> equiconditions", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2NzY4OQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375667689", "bodyText": "Adjusted spelling to equiConditions", "author": "jon-wei", "createdAt": "2020-02-06T07:02:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNTMyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNTQxOA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375025418", "bodyText": "Two conditions can refer to the same rhs column. Should this be a Set?", "author": "gianm", "createdAt": "2020-02-05T02:06:37Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          (SelectorFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              (SelectorFilter) filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param selectorFilter   SelectorFilter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      SelectorFilter selectorFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n+        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+            prefixAndClause.getKey(),\n+            p -> findCorrelatedBaseTableColumns(\n+                baseAdapter,\n+                p,\n+                prefixes.get(p),\n+                equiconditions\n+            )\n+        );\n+\n+        if (correlations == null) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        List<Filter> newFilters = new ArrayList<>();\n+        List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+          if (correlationAnalysis.supportsPushDown()) {\n+            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+                selectorFilter.getDimension(),\n+                selectorFilter.getValue(),\n+                correlationAnalysis.getJoinColumn(),\n+                prefixAndClause.getValue()\n+            );\n+\n+            if (correlatedValues == null) {\n+              return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+            }\n+\n+            for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  correlatedBaseColumn,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+\n+            for (Expr correlatedBaseExpr : correlationAnalysis.getBaseExpressions()) {\n+              // need to create a virtual column for the expressions when pushing down\n+              String vcName = getCorrelatedBaseExprVirtualColumnName(pushdownVirtualColumns.size());\n+\n+              VirtualColumn correlatedBaseExprVirtualColumn = new ExpressionVirtualColumn(\n+                  vcName,\n+                  correlatedBaseExpr,\n+                  ValueType.STRING\n+              );\n+              pushdownVirtualColumns.add(correlatedBaseExprVirtualColumn);\n+\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  vcName,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+          }\n+        }\n+\n+        if (newFilters.isEmpty()) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        return new JoinFilterAnalysis(\n+            true,\n+            true,\n+            selectorFilter,\n+            newFilters.size() == 1 ? newFilters.get(0) : new AndFilter(newFilters),\n+            pushdownVirtualColumns\n+        );\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        selectorFilter,\n+        selectorFilter,\n+        null\n+    );\n+  }\n+\n+  private static String getCorrelatedBaseExprVirtualColumnName(int counter)\n+  {\n+    // May want to have this check other column names to absolutely prevent name conflicts\n+    return PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE + counter;\n+  }\n+\n+  /**\n+   * Helper method for rewriting filters on join table columns into filters on base table columns.\n+   *\n+   * @param filterColumn           A join table column that we're filtering on\n+   * @param filterValue            The value to filter on\n+   * @param correlatedJoinColumn   A join table column that appears as the RHS of an equicondition, which we can correlate\n+   *                               with a column on the base table\n+   * @param clauseForFilteredTable The joinable clause that corresponds to the join table being filtered on\n+   *\n+   * @return A list of values of the correlatedJoinColumn that appear in rows where filterColumn = filterValue\n+   * Returns null if we cannot determine the correlated values.\n+   */\n+  @Nullable\n+  private static List<String> getCorrelatedValuesForPushDown(\n+      String filterColumn,\n+      String filterValue,\n+      String correlatedJoinColumn,\n+      JoinableClause clauseForFilteredTable\n+  )\n+  {\n+    String filterColumnNoPrefix = filterColumn.substring(clauseForFilteredTable.getPrefix().length());\n+    String correlatedColumnNoPrefix = correlatedJoinColumn.substring(clauseForFilteredTable.getPrefix().length());\n+\n+    // would be good to allow non-key column indices on the Joinables for better perf\n+    if (clauseForFilteredTable.getJoinable() instanceof LookupJoinable) {\n+      LookupJoinable lookupJoinable = (LookupJoinable) clauseForFilteredTable.getJoinable();\n+      List<String> correlatedValues;\n+      if (LookupColumnSelectorFactory.KEY_COLUMN.equals(filterColumnNoPrefix)) {\n+        if (LookupColumnSelectorFactory.KEY_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = ImmutableList.of(lookupJoinable.getExtractor().apply(filterColumnNoPrefix));\n+        }\n+      } else {\n+        if (LookupColumnSelectorFactory.VALUE_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = lookupJoinable.getExtractor().unapply(filterValue);\n+        }\n+      }\n+      return correlatedValues;\n+    }\n+\n+    if (clauseForFilteredTable.getJoinable() instanceof IndexedTableJoinable) {\n+      IndexedTableJoinable indexedTableJoinable = (IndexedTableJoinable) clauseForFilteredTable.getJoinable();\n+      IndexedTable indexedTable = indexedTableJoinable.getTable();\n+\n+      int filterColumnPosition = indexedTable.allColumns().indexOf(filterColumnNoPrefix);\n+      int correlatedColumnPosition = indexedTable.allColumns().indexOf(correlatedColumnNoPrefix);\n+\n+      if (filterColumnPosition < 0 || correlatedColumnPosition < 0) {\n+        return null;\n+      }\n+\n+      if (indexedTable.keyColumns().contains(filterColumnNoPrefix)) {\n+        IndexedTable.Index index = indexedTable.columnIndex(filterColumnPosition);\n+        IndexedTable.Reader reader = indexedTable.columnReader(correlatedColumnPosition);\n+        IntList rowIndex = index.find(filterValue);\n+        List<String> correlatedValues = new ArrayList<>();\n+        for (int i = 0; i < rowIndex.size(); i++) {\n+          int rowNum = rowIndex.getInt(i);\n+          correlatedValues.add(reader.read(rowNum).toString());\n+        }\n+        return correlatedValues;\n+      } else {\n+        IndexedTable.Reader dimNameReader = indexedTable.columnReader(filterColumnPosition);\n+        IndexedTable.Reader correlatedColumnReader = indexedTable.columnReader(correlatedColumnPosition);\n+        Set<String> correlatedValueSet = new HashSet<>();\n+        for (int i = 0; i < indexedTable.numRows(); i++) {\n+          if (filterValue.equals(dimNameReader.read(i).toString())) {\n+            correlatedValueSet.add(correlatedColumnReader.read(i).toString());\n+          }\n+        }\n+\n+        return new ArrayList<>(correlatedValueSet);\n+      }\n+    }\n+\n+    return null;\n+  }\n+\n+  /**\n+   * For all RHS columns that appear in the join's equiconditions, correlate them with base table columns if possible.\n+   *\n+   * @param adapter              The adapter for the join. Used to determine if a column is a base table column.\n+   * @param tablePrefix          Prefix for a join table\n+   * @param clauseForTablePrefix Joinable clause for the prefix\n+   * @param equiconditions       Map of equiconditions, keyed by the right hand columns\n+   *\n+   * @return A list of correlatation analyses for the equicondition RHS columns that reside in the table associated with\n+   * the tablePrefix\n+   */\n+  @Nullable\n+  private static List<JoinFilterColumnCorrelationAnalysis> findCorrelatedBaseTableColumns(\n+      HashJoinSegmentStorageAdapter adapter,\n+      String tablePrefix,\n+      JoinableClause clauseForTablePrefix,\n+      Map<String, Expr> equiconditions\n+  )\n+  {\n+    JoinConditionAnalysis jca = clauseForTablePrefix.getCondition();\n+\n+    List<String> rhsColumns = new ArrayList<>();", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2Nzc1OA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375667758", "bodyText": "Ah, changed this to Set", "author": "jon-wei", "createdAt": "2020-02-06T07:02:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNTQxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNTg0MA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375025840", "bodyText": "There could be more than one equi-condition for the same rhs column. It looks like this code disregards that possibility.", "author": "gianm", "createdAt": "2020-02-05T02:08:12Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2Nzc5NQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375667795", "bodyText": "I'm still looking into this comment", "author": "jon-wei", "createdAt": "2020-02-06T07:03:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNTg0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY4OTkwMw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375689903", "bodyText": "I tried a test where I had the following join condition:\n\"r1.regionIsoCode\" == regionIsoCode && \"r1.regionIsoCode\" == countryIsoCode\n\nIn one of the Equality objects in the equiConditions, the right hand column ends up as regionIsoCode_0 with an extra _0 suffix, and the query fails with:\n\"Cannot build hash-join matcher on non-key-based condition: Equality{leftExpr=countryIsoCode, rightColumn='regionIsoCode_0'}\"\n\nI added a new test which shows this (JoinFilterAnalyzerTest.test_filterPushDown_factToRegionTwoColumnsToOneRHSColumnAndFilterOnRHS)\nCan we address this in a follow-on PR?", "author": "jon-wei", "createdAt": "2020-02-06T08:14:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNTg0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjA2MTgwNA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r376061804", "bodyText": "Sure, but please raise a github issue and mention it in a comment.", "author": "gianm", "createdAt": "2020-02-06T20:22:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNTg0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjEyOTYzNw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r376129637", "bodyText": "I opened #9327 to track the query failure issue and #9328 to track the adjustments needed here", "author": "jon-wei", "createdAt": "2020-02-06T22:59:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNTg0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNjE4Mg==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375026182", "bodyText": "small suggestion: !requiredBindings.stream().allMatch( blah blah blah ) may be more readable", "author": "gianm", "createdAt": "2020-02-05T02:09:44Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          (SelectorFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              (SelectorFilter) filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param selectorFilter   SelectorFilter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      SelectorFilter selectorFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n+        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+            prefixAndClause.getKey(),\n+            p -> findCorrelatedBaseTableColumns(\n+                baseAdapter,\n+                p,\n+                prefixes.get(p),\n+                equiconditions\n+            )\n+        );\n+\n+        if (correlations == null) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        List<Filter> newFilters = new ArrayList<>();\n+        List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+          if (correlationAnalysis.supportsPushDown()) {\n+            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+                selectorFilter.getDimension(),\n+                selectorFilter.getValue(),\n+                correlationAnalysis.getJoinColumn(),\n+                prefixAndClause.getValue()\n+            );\n+\n+            if (correlatedValues == null) {\n+              return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+            }\n+\n+            for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  correlatedBaseColumn,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+\n+            for (Expr correlatedBaseExpr : correlationAnalysis.getBaseExpressions()) {\n+              // need to create a virtual column for the expressions when pushing down\n+              String vcName = getCorrelatedBaseExprVirtualColumnName(pushdownVirtualColumns.size());\n+\n+              VirtualColumn correlatedBaseExprVirtualColumn = new ExpressionVirtualColumn(\n+                  vcName,\n+                  correlatedBaseExpr,\n+                  ValueType.STRING\n+              );\n+              pushdownVirtualColumns.add(correlatedBaseExprVirtualColumn);\n+\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  vcName,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+          }\n+        }\n+\n+        if (newFilters.isEmpty()) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        return new JoinFilterAnalysis(\n+            true,\n+            true,\n+            selectorFilter,\n+            newFilters.size() == 1 ? newFilters.get(0) : new AndFilter(newFilters),\n+            pushdownVirtualColumns\n+        );\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        selectorFilter,\n+        selectorFilter,\n+        null\n+    );\n+  }\n+\n+  private static String getCorrelatedBaseExprVirtualColumnName(int counter)\n+  {\n+    // May want to have this check other column names to absolutely prevent name conflicts\n+    return PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE + counter;\n+  }\n+\n+  /**\n+   * Helper method for rewriting filters on join table columns into filters on base table columns.\n+   *\n+   * @param filterColumn           A join table column that we're filtering on\n+   * @param filterValue            The value to filter on\n+   * @param correlatedJoinColumn   A join table column that appears as the RHS of an equicondition, which we can correlate\n+   *                               with a column on the base table\n+   * @param clauseForFilteredTable The joinable clause that corresponds to the join table being filtered on\n+   *\n+   * @return A list of values of the correlatedJoinColumn that appear in rows where filterColumn = filterValue\n+   * Returns null if we cannot determine the correlated values.\n+   */\n+  @Nullable\n+  private static List<String> getCorrelatedValuesForPushDown(\n+      String filterColumn,\n+      String filterValue,\n+      String correlatedJoinColumn,\n+      JoinableClause clauseForFilteredTable\n+  )\n+  {\n+    String filterColumnNoPrefix = filterColumn.substring(clauseForFilteredTable.getPrefix().length());\n+    String correlatedColumnNoPrefix = correlatedJoinColumn.substring(clauseForFilteredTable.getPrefix().length());\n+\n+    // would be good to allow non-key column indices on the Joinables for better perf\n+    if (clauseForFilteredTable.getJoinable() instanceof LookupJoinable) {\n+      LookupJoinable lookupJoinable = (LookupJoinable) clauseForFilteredTable.getJoinable();\n+      List<String> correlatedValues;\n+      if (LookupColumnSelectorFactory.KEY_COLUMN.equals(filterColumnNoPrefix)) {\n+        if (LookupColumnSelectorFactory.KEY_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = ImmutableList.of(lookupJoinable.getExtractor().apply(filterColumnNoPrefix));\n+        }\n+      } else {\n+        if (LookupColumnSelectorFactory.VALUE_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = lookupJoinable.getExtractor().unapply(filterValue);\n+        }\n+      }\n+      return correlatedValues;\n+    }\n+\n+    if (clauseForFilteredTable.getJoinable() instanceof IndexedTableJoinable) {\n+      IndexedTableJoinable indexedTableJoinable = (IndexedTableJoinable) clauseForFilteredTable.getJoinable();\n+      IndexedTable indexedTable = indexedTableJoinable.getTable();\n+\n+      int filterColumnPosition = indexedTable.allColumns().indexOf(filterColumnNoPrefix);\n+      int correlatedColumnPosition = indexedTable.allColumns().indexOf(correlatedColumnNoPrefix);\n+\n+      if (filterColumnPosition < 0 || correlatedColumnPosition < 0) {\n+        return null;\n+      }\n+\n+      if (indexedTable.keyColumns().contains(filterColumnNoPrefix)) {\n+        IndexedTable.Index index = indexedTable.columnIndex(filterColumnPosition);\n+        IndexedTable.Reader reader = indexedTable.columnReader(correlatedColumnPosition);\n+        IntList rowIndex = index.find(filterValue);\n+        List<String> correlatedValues = new ArrayList<>();\n+        for (int i = 0; i < rowIndex.size(); i++) {\n+          int rowNum = rowIndex.getInt(i);\n+          correlatedValues.add(reader.read(rowNum).toString());\n+        }\n+        return correlatedValues;\n+      } else {\n+        IndexedTable.Reader dimNameReader = indexedTable.columnReader(filterColumnPosition);\n+        IndexedTable.Reader correlatedColumnReader = indexedTable.columnReader(correlatedColumnPosition);\n+        Set<String> correlatedValueSet = new HashSet<>();\n+        for (int i = 0; i < indexedTable.numRows(); i++) {\n+          if (filterValue.equals(dimNameReader.read(i).toString())) {\n+            correlatedValueSet.add(correlatedColumnReader.read(i).toString());\n+          }\n+        }\n+\n+        return new ArrayList<>(correlatedValueSet);\n+      }\n+    }\n+\n+    return null;\n+  }\n+\n+  /**\n+   * For all RHS columns that appear in the join's equiconditions, correlate them with base table columns if possible.\n+   *\n+   * @param adapter              The adapter for the join. Used to determine if a column is a base table column.\n+   * @param tablePrefix          Prefix for a join table\n+   * @param clauseForTablePrefix Joinable clause for the prefix\n+   * @param equiconditions       Map of equiconditions, keyed by the right hand columns\n+   *\n+   * @return A list of correlatation analyses for the equicondition RHS columns that reside in the table associated with\n+   * the tablePrefix\n+   */\n+  @Nullable\n+  private static List<JoinFilterColumnCorrelationAnalysis> findCorrelatedBaseTableColumns(\n+      HashJoinSegmentStorageAdapter adapter,\n+      String tablePrefix,\n+      JoinableClause clauseForTablePrefix,\n+      Map<String, Expr> equiconditions\n+  )\n+  {\n+    JoinConditionAnalysis jca = clauseForTablePrefix.getCondition();\n+\n+    List<String> rhsColumns = new ArrayList<>();\n+    for (Equality eq : jca.getEquiConditions()) {\n+      rhsColumns.add(tablePrefix + eq.getRightColumn());\n+    }\n+\n+    List<JoinFilterColumnCorrelationAnalysis> correlations = new ArrayList<>();\n+\n+    for (String rhsColumn : rhsColumns) {\n+      List<String> correlatedBaseColumns = new ArrayList<>();\n+      List<Expr> correlatedBaseExpressions = new ArrayList<>();\n+      boolean terminate = false;\n+\n+      String findMappingFor = rhsColumn;\n+      while (!terminate) {\n+        Expr lhs = equiconditions.get(findMappingFor);\n+        if (lhs == null) {\n+          break;\n+        }\n+        String identifier = lhs.getBindingIfIdentifier();\n+        if (identifier == null) {\n+          // We push down if the function only requires base table columns\n+          Expr.BindingDetails bindingDetails = lhs.analyzeInputs();\n+          Set<String> requiredBindings = bindingDetails.getRequiredBindings();\n+          for (String requiredBinding : requiredBindings) {", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2NzgyNg==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375667826", "bodyText": "Changed to the suggested stream usage", "author": "jon-wei", "createdAt": "2020-02-06T07:03:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNjE4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNjU0Mg==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375026542", "bodyText": "What case is this meant to handle? I don't understand why we'd need to switch findMappingFor from a rhs column to a lhs column.", "author": "gianm", "createdAt": "2020-02-05T02:11:33Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          (SelectorFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              (SelectorFilter) filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param selectorFilter   SelectorFilter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      SelectorFilter selectorFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n+        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+            prefixAndClause.getKey(),\n+            p -> findCorrelatedBaseTableColumns(\n+                baseAdapter,\n+                p,\n+                prefixes.get(p),\n+                equiconditions\n+            )\n+        );\n+\n+        if (correlations == null) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        List<Filter> newFilters = new ArrayList<>();\n+        List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+          if (correlationAnalysis.supportsPushDown()) {\n+            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+                selectorFilter.getDimension(),\n+                selectorFilter.getValue(),\n+                correlationAnalysis.getJoinColumn(),\n+                prefixAndClause.getValue()\n+            );\n+\n+            if (correlatedValues == null) {\n+              return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+            }\n+\n+            for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  correlatedBaseColumn,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+\n+            for (Expr correlatedBaseExpr : correlationAnalysis.getBaseExpressions()) {\n+              // need to create a virtual column for the expressions when pushing down\n+              String vcName = getCorrelatedBaseExprVirtualColumnName(pushdownVirtualColumns.size());\n+\n+              VirtualColumn correlatedBaseExprVirtualColumn = new ExpressionVirtualColumn(\n+                  vcName,\n+                  correlatedBaseExpr,\n+                  ValueType.STRING\n+              );\n+              pushdownVirtualColumns.add(correlatedBaseExprVirtualColumn);\n+\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  vcName,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+          }\n+        }\n+\n+        if (newFilters.isEmpty()) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        return new JoinFilterAnalysis(\n+            true,\n+            true,\n+            selectorFilter,\n+            newFilters.size() == 1 ? newFilters.get(0) : new AndFilter(newFilters),\n+            pushdownVirtualColumns\n+        );\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        selectorFilter,\n+        selectorFilter,\n+        null\n+    );\n+  }\n+\n+  private static String getCorrelatedBaseExprVirtualColumnName(int counter)\n+  {\n+    // May want to have this check other column names to absolutely prevent name conflicts\n+    return PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE + counter;\n+  }\n+\n+  /**\n+   * Helper method for rewriting filters on join table columns into filters on base table columns.\n+   *\n+   * @param filterColumn           A join table column that we're filtering on\n+   * @param filterValue            The value to filter on\n+   * @param correlatedJoinColumn   A join table column that appears as the RHS of an equicondition, which we can correlate\n+   *                               with a column on the base table\n+   * @param clauseForFilteredTable The joinable clause that corresponds to the join table being filtered on\n+   *\n+   * @return A list of values of the correlatedJoinColumn that appear in rows where filterColumn = filterValue\n+   * Returns null if we cannot determine the correlated values.\n+   */\n+  @Nullable\n+  private static List<String> getCorrelatedValuesForPushDown(\n+      String filterColumn,\n+      String filterValue,\n+      String correlatedJoinColumn,\n+      JoinableClause clauseForFilteredTable\n+  )\n+  {\n+    String filterColumnNoPrefix = filterColumn.substring(clauseForFilteredTable.getPrefix().length());\n+    String correlatedColumnNoPrefix = correlatedJoinColumn.substring(clauseForFilteredTable.getPrefix().length());\n+\n+    // would be good to allow non-key column indices on the Joinables for better perf\n+    if (clauseForFilteredTable.getJoinable() instanceof LookupJoinable) {\n+      LookupJoinable lookupJoinable = (LookupJoinable) clauseForFilteredTable.getJoinable();\n+      List<String> correlatedValues;\n+      if (LookupColumnSelectorFactory.KEY_COLUMN.equals(filterColumnNoPrefix)) {\n+        if (LookupColumnSelectorFactory.KEY_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = ImmutableList.of(lookupJoinable.getExtractor().apply(filterColumnNoPrefix));\n+        }\n+      } else {\n+        if (LookupColumnSelectorFactory.VALUE_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = lookupJoinable.getExtractor().unapply(filterValue);\n+        }\n+      }\n+      return correlatedValues;\n+    }\n+\n+    if (clauseForFilteredTable.getJoinable() instanceof IndexedTableJoinable) {\n+      IndexedTableJoinable indexedTableJoinable = (IndexedTableJoinable) clauseForFilteredTable.getJoinable();\n+      IndexedTable indexedTable = indexedTableJoinable.getTable();\n+\n+      int filterColumnPosition = indexedTable.allColumns().indexOf(filterColumnNoPrefix);\n+      int correlatedColumnPosition = indexedTable.allColumns().indexOf(correlatedColumnNoPrefix);\n+\n+      if (filterColumnPosition < 0 || correlatedColumnPosition < 0) {\n+        return null;\n+      }\n+\n+      if (indexedTable.keyColumns().contains(filterColumnNoPrefix)) {\n+        IndexedTable.Index index = indexedTable.columnIndex(filterColumnPosition);\n+        IndexedTable.Reader reader = indexedTable.columnReader(correlatedColumnPosition);\n+        IntList rowIndex = index.find(filterValue);\n+        List<String> correlatedValues = new ArrayList<>();\n+        for (int i = 0; i < rowIndex.size(); i++) {\n+          int rowNum = rowIndex.getInt(i);\n+          correlatedValues.add(reader.read(rowNum).toString());\n+        }\n+        return correlatedValues;\n+      } else {\n+        IndexedTable.Reader dimNameReader = indexedTable.columnReader(filterColumnPosition);\n+        IndexedTable.Reader correlatedColumnReader = indexedTable.columnReader(correlatedColumnPosition);\n+        Set<String> correlatedValueSet = new HashSet<>();\n+        for (int i = 0; i < indexedTable.numRows(); i++) {\n+          if (filterValue.equals(dimNameReader.read(i).toString())) {\n+            correlatedValueSet.add(correlatedColumnReader.read(i).toString());\n+          }\n+        }\n+\n+        return new ArrayList<>(correlatedValueSet);\n+      }\n+    }\n+\n+    return null;\n+  }\n+\n+  /**\n+   * For all RHS columns that appear in the join's equiconditions, correlate them with base table columns if possible.\n+   *\n+   * @param adapter              The adapter for the join. Used to determine if a column is a base table column.\n+   * @param tablePrefix          Prefix for a join table\n+   * @param clauseForTablePrefix Joinable clause for the prefix\n+   * @param equiconditions       Map of equiconditions, keyed by the right hand columns\n+   *\n+   * @return A list of correlatation analyses for the equicondition RHS columns that reside in the table associated with\n+   * the tablePrefix\n+   */\n+  @Nullable\n+  private static List<JoinFilterColumnCorrelationAnalysis> findCorrelatedBaseTableColumns(\n+      HashJoinSegmentStorageAdapter adapter,\n+      String tablePrefix,\n+      JoinableClause clauseForTablePrefix,\n+      Map<String, Expr> equiconditions\n+  )\n+  {\n+    JoinConditionAnalysis jca = clauseForTablePrefix.getCondition();\n+\n+    List<String> rhsColumns = new ArrayList<>();\n+    for (Equality eq : jca.getEquiConditions()) {\n+      rhsColumns.add(tablePrefix + eq.getRightColumn());\n+    }\n+\n+    List<JoinFilterColumnCorrelationAnalysis> correlations = new ArrayList<>();\n+\n+    for (String rhsColumn : rhsColumns) {\n+      List<String> correlatedBaseColumns = new ArrayList<>();\n+      List<Expr> correlatedBaseExpressions = new ArrayList<>();\n+      boolean terminate = false;\n+\n+      String findMappingFor = rhsColumn;\n+      while (!terminate) {\n+        Expr lhs = equiconditions.get(findMappingFor);\n+        if (lhs == null) {\n+          break;\n+        }\n+        String identifier = lhs.getBindingIfIdentifier();\n+        if (identifier == null) {\n+          // We push down if the function only requires base table columns\n+          Expr.BindingDetails bindingDetails = lhs.analyzeInputs();\n+          Set<String> requiredBindings = bindingDetails.getRequiredBindings();\n+          for (String requiredBinding : requiredBindings) {\n+            if (!adapter.isBaseColumn(requiredBinding)) {\n+              return null;\n+            }\n+          }\n+\n+          terminate = true;\n+          correlatedBaseExpressions.add(lhs);\n+        } else {\n+          // simple identifier, see if we can correlate it with a column on the base table\n+          findMappingFor = identifier;", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2ODk5OQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375668999", "bodyText": "This is for cases like the fact->region->country joins in the tests, where the three tables are all joined on countryIsoCode, but the last table is joined to the second table, instead of the base table, and we have a filter on a column from the last table in the chain.\nJoinFilterAnalyzerTest.test_filterPushDown_factToRegionToCountryLeftFilterOnChannelAndCountryName is an example where this is used.", "author": "jon-wei", "createdAt": "2020-02-06T07:08:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNjU0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjA2NzQyOA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r376067428", "bodyText": "Hmm, I see.\nWould you mind adding some comments to findCorrelatedBaseTableColumns explaining the idea behind the logic?", "author": "gianm", "createdAt": "2020-02-06T20:35:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNjU0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjEyOTg0Nw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r376129847", "bodyText": "I added more description and examples to the javadoc for findCorrelatedBaseTableColumns, hopefully it's more clear now", "author": "jon-wei", "createdAt": "2020-02-06T23:00:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNjU0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNzkyMg==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375027922", "bodyText": "When would there be more than one base column?", "author": "gianm", "createdAt": "2020-02-05T02:17:39Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          (SelectorFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              (SelectorFilter) filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param selectorFilter   SelectorFilter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      SelectorFilter selectorFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n+        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+            prefixAndClause.getKey(),\n+            p -> findCorrelatedBaseTableColumns(\n+                baseAdapter,\n+                p,\n+                prefixes.get(p),\n+                equiconditions\n+            )\n+        );\n+\n+        if (correlations == null) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        List<Filter> newFilters = new ArrayList<>();\n+        List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+          if (correlationAnalysis.supportsPushDown()) {\n+            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+                selectorFilter.getDimension(),\n+                selectorFilter.getValue(),\n+                correlationAnalysis.getJoinColumn(),\n+                prefixAndClause.getValue()\n+            );\n+\n+            if (correlatedValues == null) {\n+              return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+            }\n+\n+            for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2OTEyMw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375669123", "bodyText": "Still looking into this comment", "author": "jon-wei", "createdAt": "2020-02-06T07:08:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNzkyMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY5MTkzMg==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375691932", "bodyText": "My original intent was related to the comment here about handling cases where one RHS column is joined to multiple columns: #9301 (comment)\nIt's not implemented right now in JoinFilterAnalyzer.findCorrelatedBaseTableColumns (and should be), but in that case there would be multiple base columns correlated to the RHS filtering column.\nSince a query of that type doesn't run successfully right now, can we address this in a follow-on PR?", "author": "jon-wei", "createdAt": "2020-02-06T08:19:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNzkyMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjA0MTk3MA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r376041970", "bodyText": "I think doing it in a follow-on is OK. Please just add a comment about the known limitation and create a followup github issue (the comment could just link to the issue).", "author": "gianm", "createdAt": "2020-02-06T19:40:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNzkyMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjEyOTk4Mg==", "url": "https://github.com/apache/druid/pull/9301#discussion_r376129982", "bodyText": "I opened #9327 to track the query failure issue and #9328 to track the adjustments needed here", "author": "jon-wei", "createdAt": "2020-02-06T23:00:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNzkyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyOTg1MQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375029851", "bodyText": "This code is nasty for the reason you mentioned in your comment. I don't think it'd be good to leave it like this, since it means any attempt to serialize this virtual column will yield something unusable, potentially leading to latent bugs.\nI'd almost consider not supporting pushdown of filters where the lhs is an expression until we have a way to actually convert parsed expressions to strings.\nAnother option:\n\nMake a single private constructor of ExpressionVirtualColumn that takes a nullable 'expression' and an optional pre-parsed expression.\nMake a @JsonCreator static factory method that Jackson will use.\nMake another static factory method that accepts a pre-parsed expression, and stores null for the 'expression'.\nMake getExpression() throw an exception if 'expression' is null. This means anyone trying to serialize it will realize what is going on before getting hit by latent bugs.\nMake sure to note in the javadoc of JoinFilterAnalysis that the virtual columns are not serializable.\n\nOpen to other ideas.", "author": "gianm", "createdAt": "2020-02-05T02:25:57Z", "path": "processing/src/main/java/org/apache/druid/segment/virtual/ExpressionVirtualColumn.java", "diffHunk": "@@ -62,6 +64,23 @@ public ExpressionVirtualColumn(\n     this.parsedExpression = Suppliers.memoize(() -> Parser.parse(expression, macroTable));\n   }\n \n+  /**\n+   * Constructor for creating an ExpressionVirtualColumn from a pre-parsed expression.\n+   */\n+  public ExpressionVirtualColumn(\n+      String name,\n+      Expr parsedExpression,\n+      ValueType outputType\n+  )\n+  {\n+    this.name = Preconditions.checkNotNull(name, \"name\");\n+    // Unfortunately this string representation can't be reparsed into the same expression, might be useful\n+    // if the expression system supported that\n+    this.expression = parsedExpression.toString();", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2OTgxMQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375669811", "bodyText": "I decided to just disable lhs expression push down for now (JoinFilterColumnCorrelationAnalysis.supportsPushDown returns false now if there are lhs expressions), but kept the rest of the code there and added an @Ignore annotation to tests that have lhs expressions (since the \"only\" thing blocking it is the lack of support from the expression system)", "author": "jon-wei", "createdAt": "2020-02-06T07:11:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyOTg1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjA0MTEwMQ==", "url": "https://github.com/apache/druid/pull/9301#discussion_r376041101", "bodyText": "I think this is a reasonable course of action. Could you please also raise a followup github issue.", "author": "gianm", "createdAt": "2020-02-06T19:38:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyOTg1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjEzMDEzOA==", "url": "https://github.com/apache/druid/pull/9301#discussion_r376130138", "bodyText": "I opened #9326 to track the expressions enhancement and mentioned it in a comment here", "author": "jon-wei", "createdAt": "2020-02-06T23:01:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyOTg1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAzMDU5Mw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375030593", "bodyText": "Is there a reason for this cast? Seems like we could let it go in to newFilters as an uncast Filter.", "author": "gianm", "createdAt": "2020-02-05T02:29:19Z", "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          (SelectorFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              (SelectorFilter) filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param selectorFilter   SelectorFilter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      SelectorFilter selectorFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n+        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+            prefixAndClause.getKey(),\n+            p -> findCorrelatedBaseTableColumns(\n+                baseAdapter,\n+                p,\n+                prefixes.get(p),\n+                equiconditions\n+            )\n+        );\n+\n+        if (correlations == null) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        List<Filter> newFilters = new ArrayList<>();\n+        List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+          if (correlationAnalysis.supportsPushDown()) {\n+            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+                selectorFilter.getDimension(),\n+                selectorFilter.getValue(),\n+                correlationAnalysis.getJoinColumn(),\n+                prefixAndClause.getValue()\n+            );\n+\n+            if (correlatedValues == null) {\n+              return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+            }\n+\n+            for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(", "originalCommit": "b31fbddcd678b5f9faf705a2def1864072188929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY2OTk5Nw==", "url": "https://github.com/apache/druid/pull/9301#discussion_r375669997", "bodyText": "Hm, it must have been a relic from an earlier version of the code, adjusted as suggested", "author": "jon-wei", "createdAt": "2020-02-06T07:12:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAzMDU5Mw=="}], "type": "inlineReview"}, {"oid": "0de4d0f4019ae7aeed5180281722fee9b9ef8c27", "url": "https://github.com/apache/druid/commit/0de4d0f4019ae7aeed5180281722fee9b9ef8c27", "message": "Merge remote-tracking branch 'upstream/master' into join_filter_pushdowns2", "committedDate": "2020-02-06T01:39:32Z", "type": "commit"}, {"oid": "d3e603321d5a8239ddb9addd5396c5c94e8b8893", "url": "https://github.com/apache/druid/commit/d3e603321d5a8239ddb9addd5396c5c94e8b8893", "message": "Address some PR comments", "committedDate": "2020-02-06T06:42:32Z", "type": "commit"}, {"oid": "194a1ef09a7ac70f26159eff40581a3184a4926d", "url": "https://github.com/apache/druid/commit/194a1ef09a7ac70f26159eff40581a3184a4926d", "message": "Address more PR comments", "committedDate": "2020-02-06T08:22:06Z", "type": "commit"}, {"oid": "dcbbcb09b8d8e98f37d237cdd6f5b028d9718433", "url": "https://github.com/apache/druid/commit/dcbbcb09b8d8e98f37d237cdd6f5b028d9718433", "message": "Fix TC failures and address PR comments", "committedDate": "2020-02-06T22:56:51Z", "type": "commit"}]}