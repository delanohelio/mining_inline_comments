{"pr_number": 9360, "pr_title": "Create splits of multiple files for parallel indexing", "pr_createdAt": "2020-02-13T21:03:01Z", "pr_url": "https://github.com/apache/druid/pull/9360", "timeline": [{"oid": "6c839bb8db3abe92c2d3e6b1b0f493d8880ed269", "url": "https://github.com/apache/druid/commit/6c839bb8db3abe92c2d3e6b1b0f493d8880ed269", "message": "Create splits of multiple files for parallel indexing", "committedDate": "2020-02-13T20:53:46Z", "type": "commit"}, {"oid": "4b78cf8b7fd49a8329499eb65f8fe314a536e81a", "url": "https://github.com/apache/druid/commit/4b78cf8b7fd49a8329499eb65f8fe314a536e81a", "message": "fix wrong import and npe in test", "committedDate": "2020-02-13T22:33:36Z", "type": "commit"}, {"oid": "6f812cd05f18b67339ce1745c51cb8adb8fdcdce", "url": "https://github.com/apache/druid/commit/6f812cd05f18b67339ce1745c51cb8adb8fdcdce", "message": "use the single file split in tests", "committedDate": "2020-02-14T05:26:36Z", "type": "commit"}, {"oid": "c00cc533905b33050fe66773783853a262d8a68b", "url": "https://github.com/apache/druid/commit/c00cc533905b33050fe66773783853a262d8a68b", "message": "Merge branch 'master' of github.com:apache/druid into split-files", "committedDate": "2020-02-19T04:48:15Z", "type": "commit"}, {"oid": "8ae5271afc95e82a24a41c6b267feca018edd327", "url": "https://github.com/apache/druid/commit/8ae5271afc95e82a24a41c6b267feca018edd327", "message": "rename", "committedDate": "2020-02-19T05:24:11Z", "type": "commit"}, {"oid": "0210ba15127a05a68e51d2e2c87691f8c7627133", "url": "https://github.com/apache/druid/commit/0210ba15127a05a68e51d2e2c87691f8c7627133", "message": "import order", "committedDate": "2020-02-19T18:31:59Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTU5MzkwMA==", "url": "https://github.com/apache/druid/pull/9360#discussion_r381593900", "bodyText": "If it isn't too much trouble, it seems like this would be better to just be a part of LocalInputSource to be more consistent with the cloud file input sources, rather than introducing a new type. Though if it is needlessly complicated then is probably fine as is.", "author": "clintropolis", "createdAt": "2020-02-19T22:52:29Z", "path": "core/src/main/java/org/apache/druid/data/input/impl/SpecificFilesLocalInputSource.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.data.input.impl;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Iterators;\n+import org.apache.druid.data.input.AbstractInputSource;\n+import org.apache.druid.data.input.InputFileAttribute;\n+import org.apache.druid.data.input.InputFormat;\n+import org.apache.druid.data.input.InputRowSchema;\n+import org.apache.druid.data.input.InputSource;\n+import org.apache.druid.data.input.InputSourceReader;\n+import org.apache.druid.data.input.InputSplit;\n+import org.apache.druid.data.input.SplitHintSpec;\n+import org.apache.druid.utils.CollectionUtils;\n+import org.apache.druid.utils.Streams;\n+\n+import javax.annotation.Nullable;\n+import java.io.File;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.stream.Stream;\n+\n+public class SpecificFilesLocalInputSource extends AbstractInputSource implements SplittableInputSource<List<File>>", "originalCommit": "0210ba15127a05a68e51d2e2c87691f8c7627133", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "605ffb2ff1ef01fbfe43895f79e356233250c7c7", "url": "https://github.com/apache/druid/commit/605ffb2ff1ef01fbfe43895f79e356233250c7c7", "message": "Remove specific local input source", "committedDate": "2020-02-20T06:34:52Z", "type": "commit"}, {"oid": "383d2569332b4e369dfb1642aa1d2ef08ed54a8b", "url": "https://github.com/apache/druid/commit/383d2569332b4e369dfb1642aa1d2ef08ed54a8b", "message": "Update docs/ingestion/native-batch.md\n\nCo-Authored-By: sthetland <steve.hetland@imply.io>", "committedDate": "2020-02-20T06:46:33Z", "type": "commit"}, {"oid": "76fb01c8c51efbd16562e79ff083ead309db0718", "url": "https://github.com/apache/druid/commit/76fb01c8c51efbd16562e79ff083ead309db0718", "message": "Update docs/ingestion/native-batch.md\n\nCo-Authored-By: sthetland <steve.hetland@imply.io>", "committedDate": "2020-02-20T06:46:46Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTgyOTA0MQ==", "url": "https://github.com/apache/druid/pull/9360#discussion_r381829041", "bodyText": "Is this better to accept both baseDir + filter and explicit files list, or should you specify one or the other exclusively?\nIf you think accepting both is better then this exception message should probably say 'At least one of ...' instead of 'Either one of'.", "author": "clintropolis", "createdAt": "2020-02-20T07:45:04Z", "path": "core/src/main/java/org/apache/druid/data/input/impl/LocalInputSource.java", "diffHunk": "@@ -34,28 +39,46 @@\n import org.apache.druid.data.input.InputSourceReader;\n import org.apache.druid.data.input.InputSplit;\n import org.apache.druid.data.input.SplitHintSpec;\n+import org.apache.druid.java.util.common.IAE;\n+import org.apache.druid.utils.CollectionUtils;\n import org.apache.druid.utils.Streams;\n \n import javax.annotation.Nullable;\n import java.io.File;\n+import java.util.Collections;\n+import java.util.HashSet;\n import java.util.Iterator;\n import java.util.List;\n import java.util.Objects;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n import java.util.stream.Stream;\n \n public class LocalInputSource extends AbstractInputSource implements SplittableInputSource<List<File>>\n {\n   private final File baseDir;\n   private final String filter;\n+  private final Set<File> files;\n \n   @JsonCreator\n   public LocalInputSource(\n       @JsonProperty(\"baseDir\") File baseDir,\n-      @JsonProperty(\"filter\") String filter\n+      @JsonProperty(\"filter\") String filter,\n+      @JsonProperty(\"files\") Set<File> files\n   )\n   {\n-    this.baseDir = Preconditions.checkNotNull(baseDir, \"baseDir\");\n-    this.filter = Preconditions.checkNotNull(filter, \"filter\");\n+    this.baseDir = baseDir;\n+    this.filter = baseDir != null ? Preconditions.checkNotNull(filter, \"filter\") : filter;\n+    this.files = files;\n+\n+    if (baseDir == null && CollectionUtils.isNullOrEmpty(files)) {\n+      throw new IAE(\"Either one of baseDir or files should be specified\");", "originalCommit": "76fb01c8c51efbd16562e79ff083ead309db0718", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjIzMzAxNw==", "url": "https://github.com/apache/druid/pull/9360#discussion_r382233017", "bodyText": "Oops, thanks. I'm not sure why we cannot have both at the same time as long as we don't process the same file more than once. It can be more aligned with the cloud input sources though.. (Also, why do we do this?)", "author": "jihoonson", "createdAt": "2020-02-20T20:13:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTgyOTA0MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjI1OTE5NA==", "url": "https://github.com/apache/druid/pull/9360#discussion_r382259194", "bodyText": "Yeah, I think actually it probably would be better to allow both uris and prefixes in the cloud file input sources and any others that match this pattern, not sure why we do only one or the other currently..", "author": "clintropolis", "createdAt": "2020-02-20T21:08:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTgyOTA0MQ=="}], "type": "inlineReview"}, {"oid": "8623f10291c4490f2c9cf2bba8020d4a1eb99cf8", "url": "https://github.com/apache/druid/commit/8623f10291c4490f2c9cf2bba8020d4a1eb99cf8", "message": "doc and error msg", "committedDate": "2020-02-20T20:03:27Z", "type": "commit"}, {"oid": "bcbb345b0cc6fc65b205b8912c675c3467338f51", "url": "https://github.com/apache/druid/commit/bcbb345b0cc6fc65b205b8912c675c3467338f51", "message": "Merge branch 'master' of github.com:apache/druid into split-files", "committedDate": "2020-02-21T23:09:20Z", "type": "commit"}, {"oid": "689d4671588b8e069cb17e99e1be195ccbb0ef11", "url": "https://github.com/apache/druid/commit/689d4671588b8e069cb17e99e1be195ccbb0ef11", "message": "fix build", "committedDate": "2020-02-22T00:31:19Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg2MDkyMw==", "url": "https://github.com/apache/druid/pull/9360#discussion_r382860923", "bodyText": "Looks like the splitSize + size < maxSplitSize and current.isEmpty() block can be combined", "author": "jon-wei", "createdAt": "2020-02-22T00:07:42Z", "path": "core/src/main/java/org/apache/druid/data/input/MaxSizeSplitHintSpec.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.data.input;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.google.common.annotations.VisibleForTesting;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.function.Function;\n+\n+/**\n+ * A SplitHintSpec that can create splits of multiple files.\n+ * A split created by this class can have one or more input files.\n+ * If there is only one file in the split, its size can be larger than {@link #maxSplitSize}.\n+ * If there are two or more files in the split, their total size cannot be larger than {@link #maxSplitSize}.\n+ */\n+public class MaxSizeSplitHintSpec implements SplitHintSpec\n+{\n+  public static final String TYPE = \"maxSize\";\n+\n+  @VisibleForTesting\n+  static final long DEFAULT_MAX_SPLIT_SIZE = 512 * 1024 * 1024;\n+\n+  private final long maxSplitSize;\n+\n+  @JsonCreator\n+  public MaxSizeSplitHintSpec(@JsonProperty(\"maxSplitSize\") @Nullable Long maxSplitSize)\n+  {\n+    this.maxSplitSize = maxSplitSize == null ? DEFAULT_MAX_SPLIT_SIZE : maxSplitSize;\n+  }\n+\n+  @JsonProperty\n+  public long getMaxSplitSize()\n+  {\n+    return maxSplitSize;\n+  }\n+\n+  @Override\n+  public <T> Iterator<List<T>> split(Iterator<T> inputIterator, Function<T, InputFileAttribute> inputAttributeExtractor)\n+  {\n+    return new Iterator<List<T>>()\n+    {\n+      private T peeking;\n+\n+      @Override\n+      public boolean hasNext()\n+      {\n+        return peeking != null || inputIterator.hasNext();\n+      }\n+\n+      @Override\n+      public List<T> next()\n+      {\n+        final List<T> current = new ArrayList<>();\n+        long splitSize = 0;\n+        while (splitSize < maxSplitSize && (peeking != null || inputIterator.hasNext())) {\n+          if (peeking == null) {\n+            peeking = inputIterator.next();\n+          }\n+          final long size = inputAttributeExtractor.apply(peeking).getSize();\n+          if (current.isEmpty()) {\n+            current.add(peeking);\n+            splitSize += size;\n+            peeking = null;\n+          } else if (splitSize + size < maxSplitSize) {", "originalCommit": "bcbb345b0cc6fc65b205b8912c675c3467338f51", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ3OTU2Nw==", "url": "https://github.com/apache/druid/pull/9360#discussion_r383479567", "bodyText": "Ah good catch. Fixed.", "author": "jihoonson", "createdAt": "2020-02-24T19:52:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg2MDkyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg2OTk2OA==", "url": "https://github.com/apache/druid/pull/9360#discussion_r382869968", "bodyText": "Can you add this new property to the LocalInputSource property docs?", "author": "jon-wei", "createdAt": "2020-02-22T01:04:49Z", "path": "core/src/main/java/org/apache/druid/data/input/impl/LocalInputSource.java", "diffHunk": "@@ -21,40 +21,64 @@\n \n import com.fasterxml.jackson.annotation.JsonCreator;\n import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.google.common.annotations.VisibleForTesting;\n import com.google.common.base.Preconditions;\n import com.google.common.collect.Iterators;\n import org.apache.commons.io.FileUtils;\n+import org.apache.commons.io.IOCase;\n+import org.apache.commons.io.filefilter.AndFileFilter;\n+import org.apache.commons.io.filefilter.IOFileFilter;\n+import org.apache.commons.io.filefilter.NameFileFilter;\n+import org.apache.commons.io.filefilter.NotFileFilter;\n import org.apache.commons.io.filefilter.TrueFileFilter;\n import org.apache.commons.io.filefilter.WildcardFileFilter;\n import org.apache.druid.data.input.AbstractInputSource;\n+import org.apache.druid.data.input.InputFileAttribute;\n import org.apache.druid.data.input.InputFormat;\n import org.apache.druid.data.input.InputRowSchema;\n import org.apache.druid.data.input.InputSourceReader;\n import org.apache.druid.data.input.InputSplit;\n import org.apache.druid.data.input.SplitHintSpec;\n+import org.apache.druid.java.util.common.IAE;\n+import org.apache.druid.utils.CollectionUtils;\n+import org.apache.druid.utils.Streams;\n \n import javax.annotation.Nullable;\n import java.io.File;\n+import java.util.Collections;\n+import java.util.HashSet;\n import java.util.Iterator;\n+import java.util.List;\n import java.util.Objects;\n-import java.util.Spliterator;\n-import java.util.Spliterators;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n import java.util.stream.Stream;\n-import java.util.stream.StreamSupport;\n \n-public class LocalInputSource extends AbstractInputSource implements SplittableInputSource<File>\n+public class LocalInputSource extends AbstractInputSource implements SplittableInputSource<List<File>>\n {\n   private final File baseDir;\n   private final String filter;\n+  private final Set<File> files;\n \n   @JsonCreator\n   public LocalInputSource(\n       @JsonProperty(\"baseDir\") File baseDir,\n-      @JsonProperty(\"filter\") String filter\n+      @JsonProperty(\"filter\") String filter,\n+      @JsonProperty(\"files\") Set<File> files", "originalCommit": "689d4671588b8e069cb17e99e1be195ccbb0ef11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ3OTU5MA==", "url": "https://github.com/apache/druid/pull/9360#discussion_r383479590", "bodyText": "Oops, added.", "author": "jihoonson", "createdAt": "2020-02-24T19:52:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg2OTk2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg3MDEyOA==", "url": "https://github.com/apache/druid/pull/9360#discussion_r382870128", "bodyText": "nit: could call this sourceIterator", "author": "jon-wei", "createdAt": "2020-02-22T01:06:01Z", "path": "core/src/main/java/org/apache/druid/data/input/impl/InputEntityIteratingReader.java", "diffHunk": "@@ -48,23 +48,23 @@\n   public InputEntityIteratingReader(\n       InputRowSchema inputRowSchema,\n       InputFormat inputFormat,\n-      Stream<InputEntity> sourceStream,\n+      Iterator<? extends InputEntity> sourceStream,", "originalCommit": "689d4671588b8e069cb17e99e1be195ccbb0ef11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ3OTYxMQ==", "url": "https://github.com/apache/druid/pull/9360#discussion_r383479611", "bodyText": "Fixed.", "author": "jihoonson", "createdAt": "2020-02-24T19:52:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg3MDEyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg3MDE1Nw==", "url": "https://github.com/apache/druid/pull/9360#discussion_r382870157", "bodyText": "nit: could call this sourceCloseableIterator", "author": "jon-wei", "createdAt": "2020-02-22T01:06:17Z", "path": "core/src/main/java/org/apache/druid/data/input/impl/InputEntityIteratingReader.java", "diffHunk": "@@ -48,23 +48,23 @@\n   public InputEntityIteratingReader(\n       InputRowSchema inputRowSchema,\n       InputFormat inputFormat,\n-      Stream<InputEntity> sourceStream,\n+      Iterator<? extends InputEntity> sourceStream,\n       File temporaryDirectory\n   )\n   {\n-    this(inputRowSchema, inputFormat, CloseableIterators.withEmptyBaggage(sourceStream.iterator()), temporaryDirectory);\n+    this(inputRowSchema, inputFormat, CloseableIterators.withEmptyBaggage(sourceStream), temporaryDirectory);\n   }\n \n   public InputEntityIteratingReader(\n       InputRowSchema inputRowSchema,\n       InputFormat inputFormat,\n-      CloseableIterator<InputEntity> sourceIterator,\n+      CloseableIterator<? extends InputEntity> sourceIterator,", "originalCommit": "689d4671588b8e069cb17e99e1be195ccbb0ef11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ3OTYzMg==", "url": "https://github.com/apache/druid/pull/9360#discussion_r383479632", "bodyText": "Fixed.", "author": "jihoonson", "createdAt": "2020-02-24T19:52:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg3MDE1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg3MDY5NQ==", "url": "https://github.com/apache/druid/pull/9360#discussion_r382870695", "bodyText": "Can add a @Nullable here", "author": "jon-wei", "createdAt": "2020-02-22T01:10:25Z", "path": "core/src/main/java/org/apache/druid/data/input/impl/LocalInputSource.java", "diffHunk": "@@ -21,40 +21,64 @@\n \n import com.fasterxml.jackson.annotation.JsonCreator;\n import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.google.common.annotations.VisibleForTesting;\n import com.google.common.base.Preconditions;\n import com.google.common.collect.Iterators;\n import org.apache.commons.io.FileUtils;\n+import org.apache.commons.io.IOCase;\n+import org.apache.commons.io.filefilter.AndFileFilter;\n+import org.apache.commons.io.filefilter.IOFileFilter;\n+import org.apache.commons.io.filefilter.NameFileFilter;\n+import org.apache.commons.io.filefilter.NotFileFilter;\n import org.apache.commons.io.filefilter.TrueFileFilter;\n import org.apache.commons.io.filefilter.WildcardFileFilter;\n import org.apache.druid.data.input.AbstractInputSource;\n+import org.apache.druid.data.input.InputFileAttribute;\n import org.apache.druid.data.input.InputFormat;\n import org.apache.druid.data.input.InputRowSchema;\n import org.apache.druid.data.input.InputSourceReader;\n import org.apache.druid.data.input.InputSplit;\n import org.apache.druid.data.input.SplitHintSpec;\n+import org.apache.druid.java.util.common.IAE;\n+import org.apache.druid.utils.CollectionUtils;\n+import org.apache.druid.utils.Streams;\n \n import javax.annotation.Nullable;\n import java.io.File;\n+import java.util.Collections;\n+import java.util.HashSet;\n import java.util.Iterator;\n+import java.util.List;\n import java.util.Objects;\n-import java.util.Spliterator;\n-import java.util.Spliterators;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n import java.util.stream.Stream;\n-import java.util.stream.StreamSupport;\n \n-public class LocalInputSource extends AbstractInputSource implements SplittableInputSource<File>\n+public class LocalInputSource extends AbstractInputSource implements SplittableInputSource<List<File>>\n {\n   private final File baseDir;\n   private final String filter;\n+  private final Set<File> files;\n \n   @JsonCreator\n   public LocalInputSource(\n       @JsonProperty(\"baseDir\") File baseDir,\n-      @JsonProperty(\"filter\") String filter\n+      @JsonProperty(\"filter\") String filter,\n+      @JsonProperty(\"files\") Set<File> files", "originalCommit": "689d4671588b8e069cb17e99e1be195ccbb0ef11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ3OTY1OA==", "url": "https://github.com/apache/druid/pull/9360#discussion_r383479658", "bodyText": "Added.", "author": "jihoonson", "createdAt": "2020-02-24T19:52:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg3MDY5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg3MTcyMg==", "url": "https://github.com/apache/druid/pull/9360#discussion_r382871722", "bodyText": "Should this propagate the exception instead? If we get an object with a byte size that can't be stored in a long, something seems very wrong", "author": "jon-wei", "createdAt": "2020-02-22T01:18:57Z", "path": "extensions-core/google-extensions/src/main/java/org/apache/druid/data/input/google/GoogleCloudStorageInputSource.java", "diffHunk": "@@ -59,23 +65,42 @@ public GoogleCloudStorageInputSource(\n   }\n \n   @Override\n-  protected GoogleCloudStorageEntity createEntity(InputSplit<CloudObjectLocation> split)\n+  protected InputEntity createEntity(CloudObjectLocation location)\n   {\n-    return new GoogleCloudStorageEntity(storage, split.get());\n+    return new GoogleCloudStorageEntity(storage, location);\n   }\n \n   @Override\n-  protected Stream<InputSplit<CloudObjectLocation>> getPrefixesSplitStream()\n+  protected Stream<InputSplit<List<CloudObjectLocation>>> getPrefixesSplitStream(@Nonnull SplitHintSpec splitHintSpec)\n   {\n-    return StreamSupport.stream(storageObjectIterable().spliterator(), false)\n-                        .map(this::byteSourceFromStorageObject)\n-                        .map(InputSplit::new);\n+    final Iterator<List<StorageObject>> splitIterator = splitHintSpec.split(\n+        storageObjectIterable().iterator(),\n+        storageObject -> {\n+          final BigInteger sizeInBigInteger = storageObject.getSize();\n+          long sizeInLong;\n+          if (sizeInBigInteger == null) {\n+            sizeInLong = Long.MAX_VALUE;\n+          } else {\n+            try {\n+              sizeInLong = sizeInBigInteger.longValueExact();\n+            }\n+            catch (ArithmeticException e) {\n+              sizeInLong = Long.MAX_VALUE;", "originalCommit": "689d4671588b8e069cb17e99e1be195ccbb0ef11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ3OTcxOQ==", "url": "https://github.com/apache/druid/pull/9360#discussion_r383479719", "bodyText": "The length of a google storage object is the unsigned long type (https://cloud.google.com/storage/docs/json_api/v1/objects#resource-representations). I think it's better to work instead of failing. Added a warning log about the exception.", "author": "jihoonson", "createdAt": "2020-02-24T19:52:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg3MTcyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg3MjQwMA==", "url": "https://github.com/apache/druid/pull/9360#discussion_r382872400", "bodyText": "Since it would get converted into a MaxSizeSplitHintSpec in createSplit, could this create a MaxSizeSplitHintSpec directly? (Does this also mean SegmentsSplitHintSpec is deprecated?)", "author": "jon-wei", "createdAt": "2020-02-22T01:25:30Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/input/DruidInputSource.java", "diffHunk": "@@ -228,13 +232,15 @@ protected InputSourceReader fixedFormatReader(InputRowSchema inputRowSchema, @Nu\n     // segmentIds is supposed to be specified by the supervisor task during the parallel indexing.\n     // If it's not null, segments are already split by the supervisor task and further split won't happen.\n     if (segmentIds == null) {\n-      return createSplits(\n-          coordinatorClient,\n-          retryPolicyFactory,\n-          dataSource,\n-          interval,\n-          splitHintSpec == null ? new SegmentsSplitHintSpec(null) : splitHintSpec\n-      ).stream();\n+      return Streams.sequentialStreamFrom(\n+          createSplits(\n+              coordinatorClient,\n+              retryPolicyFactory,\n+              dataSource,\n+              interval,\n+              splitHintSpec == null ? new SegmentsSplitHintSpec(null) : splitHintSpec", "originalCommit": "689d4671588b8e069cb17e99e1be195ccbb0ef11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ3OTc3Ng==", "url": "https://github.com/apache/druid/pull/9360#discussion_r383479776", "bodyText": "Changed to create MaxSizeSplitHintSpec directly.\n\nDoes this also mean SegmentsSplitHintSpec is deprecated?\n\nGood question. MaxSizeSplitHintSpec and SegmentsSplitHintSpec work exactly same for now, but I think SegmentsSplitHintSpec can be further optimized in the future. Added some comment about the future improvement.", "author": "jihoonson", "createdAt": "2020-02-24T19:53:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg3MjQwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk0OTI4NQ==", "url": "https://github.com/apache/druid/pull/9360#discussion_r382949285", "bodyText": "I think you should make spec classes be pure data objects (or beans). Adding methods like split to them makes them complicated and adds logic that makes it hard to version them in the future. We should think of data objects as literals, not as objects with business logic.", "author": "jnaous", "createdAt": "2020-02-22T23:23:19Z", "path": "core/src/main/java/org/apache/druid/data/input/MaxSizeSplitHintSpec.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.data.input;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.google.common.annotations.VisibleForTesting;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.function.Function;\n+\n+/**\n+ * A SplitHintSpec that can create splits of multiple files.\n+ * A split created by this class can have one or more input files.\n+ * If there is only one file in the split, its size can be larger than {@link #maxSplitSize}.\n+ * If there are two or more files in the split, their total size cannot be larger than {@link #maxSplitSize}.\n+ */\n+public class MaxSizeSplitHintSpec implements SplitHintSpec", "originalCommit": "689d4671588b8e069cb17e99e1be195ccbb0ef11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ3OTg0Mg==", "url": "https://github.com/apache/druid/pull/9360#discussion_r383479842", "bodyText": "Good point. I agree it is a better structure, but the problem is there are too many classes doing this kind of things especially on the ingestion side. I don't think it's possible to apply the suggested design to all classes anytime soon. Also, I think it's better to promote SQL for ingestion as well so that Druid users don't have to worry about the API changes.", "author": "jihoonson", "createdAt": "2020-02-24T19:53:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk0OTI4NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk0OTgyMQ==", "url": "https://github.com/apache/druid/pull/9360#discussion_r382949821", "bodyText": "I think you can simplify the logic of the next method below if you initialize peeking to inputIterator.next(), and only set peeking to null when inputIterator.hasNext() is false. In your next() below, you would just keeping shifting values from inputIterator into current after each iteration as long as there are more inputs.", "author": "jnaous", "createdAt": "2020-02-22T23:33:57Z", "path": "core/src/main/java/org/apache/druid/data/input/MaxSizeSplitHintSpec.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.data.input;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.google.common.annotations.VisibleForTesting;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.function.Function;\n+\n+/**\n+ * A SplitHintSpec that can create splits of multiple files.\n+ * A split created by this class can have one or more input files.\n+ * If there is only one file in the split, its size can be larger than {@link #maxSplitSize}.\n+ * If there are two or more files in the split, their total size cannot be larger than {@link #maxSplitSize}.\n+ */\n+public class MaxSizeSplitHintSpec implements SplitHintSpec\n+{\n+  public static final String TYPE = \"maxSize\";\n+\n+  @VisibleForTesting\n+  static final long DEFAULT_MAX_SPLIT_SIZE = 512 * 1024 * 1024;\n+\n+  private final long maxSplitSize;\n+\n+  @JsonCreator\n+  public MaxSizeSplitHintSpec(@JsonProperty(\"maxSplitSize\") @Nullable Long maxSplitSize)\n+  {\n+    this.maxSplitSize = maxSplitSize == null ? DEFAULT_MAX_SPLIT_SIZE : maxSplitSize;\n+  }\n+\n+  @JsonProperty\n+  public long getMaxSplitSize()\n+  {\n+    return maxSplitSize;\n+  }\n+\n+  @Override\n+  public <T> Iterator<List<T>> split(Iterator<T> inputIterator, Function<T, InputFileAttribute> inputAttributeExtractor)\n+  {\n+    return new Iterator<List<T>>()\n+    {\n+      private T peeking;", "originalCommit": "689d4671588b8e069cb17e99e1be195ccbb0ef11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ3OTg4Nw==", "url": "https://github.com/apache/druid/pull/9360#discussion_r383479887", "bodyText": "I don't understand how it works. peeking is to keep the last fetched input from the underlying iterator because it can be returned or not based on the total size of inputs in the current list. If the last fetched input was not added, it should be returned in the following next() call.", "author": "jihoonson", "createdAt": "2020-02-24T19:53:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk0OTgyMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk0OTg0Mg==", "url": "https://github.com/apache/druid/pull/9360#discussion_r382949842", "bodyText": "equals and hashCode need unit tests", "author": "jnaous", "createdAt": "2020-02-22T23:34:34Z", "path": "core/src/main/java/org/apache/druid/data/input/MaxSizeSplitHintSpec.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.data.input;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.google.common.annotations.VisibleForTesting;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.function.Function;\n+\n+/**\n+ * A SplitHintSpec that can create splits of multiple files.\n+ * A split created by this class can have one or more input files.\n+ * If there is only one file in the split, its size can be larger than {@link #maxSplitSize}.\n+ * If there are two or more files in the split, their total size cannot be larger than {@link #maxSplitSize}.\n+ */\n+public class MaxSizeSplitHintSpec implements SplitHintSpec\n+{\n+  public static final String TYPE = \"maxSize\";\n+\n+  @VisibleForTesting\n+  static final long DEFAULT_MAX_SPLIT_SIZE = 512 * 1024 * 1024;\n+\n+  private final long maxSplitSize;\n+\n+  @JsonCreator\n+  public MaxSizeSplitHintSpec(@JsonProperty(\"maxSplitSize\") @Nullable Long maxSplitSize)\n+  {\n+    this.maxSplitSize = maxSplitSize == null ? DEFAULT_MAX_SPLIT_SIZE : maxSplitSize;\n+  }\n+\n+  @JsonProperty\n+  public long getMaxSplitSize()\n+  {\n+    return maxSplitSize;\n+  }\n+\n+  @Override\n+  public <T> Iterator<List<T>> split(Iterator<T> inputIterator, Function<T, InputFileAttribute> inputAttributeExtractor)\n+  {\n+    return new Iterator<List<T>>()\n+    {\n+      private T peeking;\n+\n+      @Override\n+      public boolean hasNext()\n+      {\n+        return peeking != null || inputIterator.hasNext();\n+      }\n+\n+      @Override\n+      public List<T> next()\n+      {\n+        final List<T> current = new ArrayList<>();\n+        long splitSize = 0;\n+        while (splitSize < maxSplitSize && (peeking != null || inputIterator.hasNext())) {\n+          if (peeking == null) {\n+            peeking = inputIterator.next();\n+          }\n+          final long size = inputAttributeExtractor.apply(peeking).getSize();\n+          if (current.isEmpty()) {\n+            current.add(peeking);\n+            splitSize += size;\n+            peeking = null;\n+          } else if (splitSize + size < maxSplitSize) {\n+            current.add(peeking);\n+            splitSize += size;\n+            peeking = null;\n+          } else {\n+            break;\n+          }\n+        }\n+        assert !current.isEmpty();\n+        return current;\n+      }\n+    };\n+  }\n+\n+  @Override\n+  public boolean equals(Object o)\n+  {\n+    if (this == o) {\n+      return true;\n+    }\n+    if (o == null || getClass() != o.getClass()) {\n+      return false;\n+    }\n+    MaxSizeSplitHintSpec that = (MaxSizeSplitHintSpec) o;\n+    return maxSplitSize == that.maxSplitSize;\n+  }\n+\n+  @Override\n+  public int hashCode()\n+  {\n+    return Objects.hash(maxSplitSize);\n+  }\n+}", "originalCommit": "689d4671588b8e069cb17e99e1be195ccbb0ef11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ3OTkxNw==", "url": "https://github.com/apache/druid/pull/9360#discussion_r383479917", "bodyText": "Added.", "author": "jihoonson", "createdAt": "2020-02-24T19:53:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk0OTg0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk0OTk4Mw==", "url": "https://github.com/apache/druid/pull/9360#discussion_r382949983", "bodyText": "Seems like this method really doesn't belong here if not all subclasses or implementation need it? Or should this class be abstract instead?", "author": "jnaous", "createdAt": "2020-02-22T23:37:42Z", "path": "core/src/main/java/org/apache/druid/data/input/SegmentsSplitHintSpec.java", "diffHunk": "@@ -56,6 +57,12 @@ public long getMaxInputSegmentBytesPerTask()\n     return maxInputSegmentBytesPerTask;\n   }\n \n+  @Override\n+  public <T> Iterator<List<T>> split(Iterator<T> inputIterator, Function<T, InputFileAttribute> inputAttributeExtractor)", "originalCommit": "689d4671588b8e069cb17e99e1be195ccbb0ef11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ3OTk1Ng==", "url": "https://github.com/apache/druid/pull/9360#discussion_r383479956", "bodyText": "Added comment about it.", "author": "jihoonson", "createdAt": "2020-02-24T19:53:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk0OTk4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk1MDI3MA==", "url": "https://github.com/apache/druid/pull/9360#discussion_r382950270", "bodyText": "equals and hashCode need unit tests for maintainability.", "author": "jnaous", "createdAt": "2020-02-22T23:43:37Z", "path": "core/src/main/java/org/apache/druid/data/input/impl/LocalInputSource.java", "diffHunk": "@@ -131,14 +197,15 @@ public boolean equals(Object o)\n     if (o == null || getClass() != o.getClass()) {\n       return false;\n     }\n-    LocalInputSource source = (LocalInputSource) o;\n-    return Objects.equals(baseDir, source.baseDir) &&\n-           Objects.equals(filter, source.filter);\n+    LocalInputSource that = (LocalInputSource) o;\n+    return Objects.equals(baseDir, that.baseDir) &&\n+           Objects.equals(filter, that.filter) &&\n+           Objects.equals(files, that.files);\n   }\n \n   @Override\n   public int hashCode()\n   {\n-    return Objects.hash(baseDir, filter);\n+    return Objects.hash(baseDir, filter, files);\n   }", "originalCommit": "689d4671588b8e069cb17e99e1be195ccbb0ef11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ3OTk3Mg==", "url": "https://github.com/apache/druid/pull/9360#discussion_r383479972", "bodyText": "Added.", "author": "jihoonson", "createdAt": "2020-02-24T19:53:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk1MDI3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk1MDQ4MA==", "url": "https://github.com/apache/druid/pull/9360#discussion_r382950480", "bodyText": "tests for equals and hashcode please.", "author": "jnaous", "createdAt": "2020-02-22T23:48:06Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/firehose/WindowedSegmentId.java", "diffHunk": "@@ -56,6 +63,35 @@ public String getSegmentId()\n   @JsonProperty\n   public List<Interval> getIntervals()\n   {\n-    return intervals;\n+    return Collections.unmodifiableList(intervals);\n+  }\n+\n+  @Override\n+  public boolean equals(Object o)\n+  {\n+    if (this == o) {\n+      return true;\n+    }\n+    if (o == null || getClass() != o.getClass()) {\n+      return false;\n+    }\n+    WindowedSegmentId segmentId1 = (WindowedSegmentId) o;\n+    return Objects.equals(segmentId, segmentId1.segmentId) &&\n+           Objects.equals(intervals, segmentId1.intervals);\n+  }\n+\n+  @Override\n+  public int hashCode()\n+  {\n+    return Objects.hash(segmentId, intervals);\n+  }", "originalCommit": "689d4671588b8e069cb17e99e1be195ccbb0ef11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ3OTk4OA==", "url": "https://github.com/apache/druid/pull/9360#discussion_r383479988", "bodyText": "Added.", "author": "jihoonson", "createdAt": "2020-02-24T19:53:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk1MDQ4MA=="}], "type": "inlineReview"}, {"oid": "c10552a040a6e16ce725037bd1dc79f1ed374e9e", "url": "https://github.com/apache/druid/commit/c10552a040a6e16ce725037bd1dc79f1ed374e9e", "message": "Merge branch 'master' of github.com:apache/druid into split-files", "committedDate": "2020-02-24T18:34:33Z", "type": "commit"}, {"oid": "acaa8486ff8ca8476598ea7606b2c8466e456f1b", "url": "https://github.com/apache/druid/commit/acaa8486ff8ca8476598ea7606b2c8466e456f1b", "message": "fix a test and address comments", "committedDate": "2020-02-24T19:52:23Z", "type": "commit"}]}