{"pr_number": 10518, "pr_title": "Add grouping_id function", "pr_createdAt": "2020-10-19T11:41:25Z", "pr_url": "https://github.com/apache/druid/pull/10518", "timeline": [{"oid": "9e494a192de4f4ea3e52e45367b3ebe0ebbe5704", "url": "https://github.com/apache/druid/commit/9e494a192de4f4ea3e52e45367b3ebe0ebbe5704", "message": "First draft of grouping_id function", "committedDate": "2020-10-17T11:51:06Z", "type": "commit"}, {"oid": "60f1041472a1b14cfd98359fcddca27e07bd9da0", "url": "https://github.com/apache/druid/commit/60f1041472a1b14cfd98359fcddca27e07bd9da0", "message": "Add more tests and documentation", "committedDate": "2020-10-19T11:41:37Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDk1MzcwOA==", "url": "https://github.com/apache/druid/pull/10518#discussion_r514953708", "bodyText": "It probably doesn't matter, but since this is a relatively hot path of the code, it might be worth measuring if this if statement here has any performance impact on group by queries which do not having a grouping aggregator. If it is actually visible, it might be worth pulling out a separate code path to handle the grouping sets case so that this does not negatively impact performance.", "author": "clintropolis", "createdAt": "2020-10-30T09:00:11Z", "path": "processing/src/main/java/org/apache/druid/query/groupby/epinephelinae/RowBasedGrouperHelper.java", "diffHunk": "@@ -576,7 +594,12 @@ private static ValueExtractFunction makeValueExtractFunction(\n           // Add aggregations.\n           final int resultRowAggregatorStart = query.getResultRowAggregatorStart();\n           for (int i = 0; i < entry.getValues().length; i++) {\n-            resultRow.set(resultRowAggregatorStart + i, entry.getValues()[i]);\n+            if (dimsToInclude != null && groupingAggregatorsBitSet.get(i)) {", "originalCommit": "60f1041472a1b14cfd98359fcddca27e07bd9da0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTk0NTc2Nw==", "url": "https://github.com/apache/druid/pull/10518#discussion_r515945767", "bodyText": "Right. This is one change I am a bit anxious about. is there any existing benchmark I could use?", "author": "abhishekagarwal87", "createdAt": "2020-11-02T12:44:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDk1MzcwOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjk0MTIxNg==", "url": "https://github.com/apache/druid/pull/10518#discussion_r532941216", "bodyText": "I think this if clause is probably fine. However, if I'm reading code correctly, the new aggregators seem to do nothing and even their result is not in use but those aggregators are still involved in hash aggregation. I'm more worrying about this because it involves serializing/deserializing the aggregator values to/from off-heap memory which is pretty expensive. Because GroupingAggregatorFactory is a special aggregator type which cannot be computed by regular aggregation, can we rewrite the query to not compute them in hash aggregation but add the aggregation results as what you do now?\n\nRight. This is one change I am a bit anxious about. is there any existing benchmark I could use?\n\nGroupByBenchmark will be the easiest place for such benchmarks, but it's not probably the best place because it benchmarks the query performance of historicals. I would like to suggest to add a new one for broker performance, but this comment is not a blocker. I'm OK with adding a new benchmark in GroupByBenchmark for now.", "author": "jihoonson", "createdAt": "2020-11-30T22:20:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDk1MzcwOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzE0MjI0Mg==", "url": "https://github.com/apache/druid/pull/10518#discussion_r533142242", "bodyText": "In the current Long*Aggregator implementations, there is no serialization/deserialization. Aggregations are no-op and get call just returns the value passed in the constructor. am I missing any code path here?\nI also wanted to limit the places where there is special handling for GroupingAggregatorFactory.", "author": "abhishekagarwal87", "createdAt": "2020-12-01T08:11:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDk1MzcwOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTcxODA0MA==", "url": "https://github.com/apache/druid/pull/10518#discussion_r535718040", "bodyText": "I talked to @abhishekagarwal87 offline. My biggest concern is that the special handling for GroupingAggregatorFactory seems pretty magical because the behaviour of the factory and its aggregators is different from others. What I suggested above is making it more special but less magical, because I think it's less confusing. @abhishekagarwal87's concern is mostly around the complexity of query rewriting which requires adjusting result row signature (because the result of grouping function will be missing at certain points during a query after rewrite). I think we can still handle this but maybe it could be fragile because we don't have a systemic way to handle result row signature changes during a query and thus the logic to handle them will be ad-hoc. I agree with this view, so the current structure seems reasonable even though I still think, ideally, we should not involve GroupingAggregatorFactory in hash aggregation. Maybe we can do in the future once we have some better way to handle query writing and result row signature changes.", "author": "jihoonson", "createdAt": "2020-12-03T23:19:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDk1MzcwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTAyOTE4Mg==", "url": "https://github.com/apache/druid/pull/10518#discussion_r515029182", "bodyText": "I think when other databases have differences in functionality so that there doesn't seem to be a consistent behavior, we typically follow the PostgreSQL behavior instead of others (#7950 (comment), #9337, #9488 (comment), #10006, etc), which seems to be the opposite of this where 0 means membership of the grouping set and 1 is not.\nI think we should be consistent with the PostgreSQL behavior here as well.", "author": "clintropolis", "createdAt": "2020-10-30T11:23:53Z", "path": "processing/src/main/java/org/apache/druid/query/aggregation/GroupingAggregatorFactory.java", "diffHunk": "@@ -0,0 +1,282 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.query.aggregation;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n+import org.apache.druid.annotations.EverythingIsNonnullByDefault;\n+import org.apache.druid.query.aggregation.constant.LongConstantAggregator;\n+import org.apache.druid.query.aggregation.constant.LongConstantBufferAggregator;\n+import org.apache.druid.query.aggregation.constant.LongConstantVectorAggregator;\n+import org.apache.druid.query.cache.CacheKeyBuilder;\n+import org.apache.druid.segment.ColumnInspector;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.vector.VectorColumnSelectorFactory;\n+import org.apache.druid.utils.CollectionUtils;\n+\n+import javax.annotation.Nullable;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+@EverythingIsNonnullByDefault\n+public class GroupingAggregatorFactory extends AggregatorFactory\n+{\n+  private static final Comparator<Long> VALUE_COMPARATOR = Long::compare;\n+  private final String name;\n+  private final List<String> groupings;\n+  private final long value;\n+  @Nullable\n+  private final Set<String> keyDimensions;\n+\n+  @JsonCreator\n+  public GroupingAggregatorFactory(\n+      @JsonProperty(\"name\") String name,\n+      @JsonProperty(\"groupings\") List<String> groupings\n+  )\n+  {\n+    this(name, groupings, null);\n+  }\n+\n+  @VisibleForTesting\n+  GroupingAggregatorFactory(\n+      String name,\n+      List<String> groupings,\n+      @Nullable Set<String> keyDimensions\n+  )\n+  {\n+    Preconditions.checkNotNull(name, \"Must have a valid, non-null aggregator name\");\n+    this.name = name;\n+    this.groupings = groupings;\n+    this.keyDimensions = keyDimensions;\n+    value = groupingId(groupings, keyDimensions);\n+  }\n+\n+  @Override\n+  public Aggregator factorize(ColumnSelectorFactory metricFactory)\n+  {\n+    return new LongConstantAggregator(value);\n+  }\n+\n+  @Override\n+  public BufferAggregator factorizeBuffered(ColumnSelectorFactory metricFactory)\n+  {\n+    return new LongConstantBufferAggregator(value);\n+  }\n+\n+  @Override\n+  public VectorAggregator factorizeVector(VectorColumnSelectorFactory selectorFactory)\n+  {\n+    return new LongConstantVectorAggregator(value);\n+  }\n+\n+  @Override\n+  public boolean canVectorize(ColumnInspector columnInspector)\n+  {\n+    return true;\n+  }\n+\n+  /**\n+   * Replace the param {@code keyDimensions} with the new set of key dimensions\n+   */\n+  public GroupingAggregatorFactory withKeyDimensions(Set<String> newKeyDimensions)\n+  {\n+    return new GroupingAggregatorFactory(name, groupings, newKeyDimensions);\n+  }\n+\n+  @Override\n+  public Comparator getComparator()\n+  {\n+    return VALUE_COMPARATOR;\n+  }\n+\n+  @JsonProperty\n+  public List<String> getGroupings()\n+  {\n+    return groupings;\n+  }\n+\n+  @Override\n+  @JsonProperty\n+  public String getName()\n+  {\n+    return name;\n+  }\n+\n+  public long getValue()\n+  {\n+    return value;\n+  }\n+\n+  @Nullable\n+  @Override\n+  public Object combine(@Nullable Object lhs, @Nullable Object rhs)\n+  {\n+    if (null == lhs) {\n+      return rhs;\n+    }\n+    return lhs;\n+  }\n+\n+  @Override\n+  public AggregatorFactory getCombiningFactory()\n+  {\n+    return new GroupingAggregatorFactory(name, groupings, keyDimensions);\n+  }\n+\n+  @Override\n+  public List<AggregatorFactory> getRequiredColumns()\n+  {\n+    return Collections.singletonList(new GroupingAggregatorFactory(name, groupings, keyDimensions));\n+  }\n+\n+  @Override\n+  public Object deserialize(Object object)\n+  {\n+    return object;\n+  }\n+\n+  @Nullable\n+  @Override\n+  public Object finalizeComputation(@Nullable Object object)\n+  {\n+    return object;\n+  }\n+\n+  @Override\n+  public List<String> requiredFields()\n+  {\n+    // The aggregator doesn't need to read any fields.\n+    return Collections.emptyList();\n+  }\n+\n+  @Override\n+  public ValueType getType()\n+  {\n+    return ValueType.LONG;\n+  }\n+\n+  @Override\n+  public ValueType getFinalizedType()\n+  {\n+    return ValueType.LONG;\n+  }\n+\n+  @Override\n+  public int getMaxIntermediateSize()\n+  {\n+    return Long.BYTES;\n+  }\n+\n+  @Override\n+  public byte[] getCacheKey()\n+  {\n+    CacheKeyBuilder keyBuilder = new CacheKeyBuilder(AggregatorUtil.GROUPING_CACHE_TYPE_ID)\n+        .appendStrings(groupings);\n+    if (null != keyDimensions) {\n+      keyBuilder.appendStrings(keyDimensions);\n+    }\n+    return keyBuilder.build();\n+  }\n+\n+  /**\n+   * Gives the list of grouping dimensions, return a long value where each bit at position X in the returned value\n+   * corresponds to the dimension in groupings at same position X. X is the position relative to the right end. if\n+   * keyDimensions contain the grouping dimension at position X, the bit is set to 1 at position X, otherwise it is\n+   * set to 0. An example adapted from Microsoft SQL documentation", "originalCommit": "60f1041472a1b14cfd98359fcddca27e07bd9da0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTk0NzYwMA==", "url": "https://github.com/apache/druid/pull/10518#discussion_r515947600", "bodyText": "I have seen that. Though it seems weird that 0 bit indicates that dimension is present, it seems it's not just postgres. I also checked that a commercial data warehouse follows the same logic as Postgres. will change this.", "author": "abhishekagarwal87", "createdAt": "2020-11-02T12:47:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTAyOTE4Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzg0ODM1Mg==", "url": "https://github.com/apache/druid/pull/10518#discussion_r517848352", "bodyText": "I checked this further @clintropolis . Few things\n\nMysql and postgres don't have the grouping functions that take more than one argument.\nHere is calcite documentation\n\n* <p>Accepts 1 or more arguments.\n* Example: {@code GROUPING(deptno, gender)} returns\n* 3 if both deptno and gender are being grouped,\n* 2 if only deptno is being grouped,\n* 1 if only gender is being groped,\n* 0 if neither deptno nor gender are being grouped.\n*\n\nI am now thinking that we should stick with how calcite intends it to be.  what do you think?", "author": "abhishekagarwal87", "createdAt": "2020-11-05T07:48:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTAyOTE4Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjk1MTAwMQ==", "url": "https://github.com/apache/druid/pull/10518#discussion_r532951001", "bodyText": "MySQL and Postgres do seem to take more than one expressions. Check out the docs of postgres and mysql. Their behaviour seems consistent across popular database systems such as oracle and sql server. One exception is that sql server supports both grouping() and grouping_id() which behaves in an opposite way to each other. Calcite's behaviour is also consistent. Perhaps you were looking at an old version of the comment. I think Druid's behaviour should also match to most of other database systems.", "author": "jihoonson", "createdAt": "2020-11-30T22:41:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTAyOTE4Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzExODMzMw==", "url": "https://github.com/apache/druid/pull/10518#discussion_r533118333", "bodyText": "Good catch @jihoonson. The doc is fixed in the most recent version. I will change our impl as well.", "author": "abhishekagarwal87", "createdAt": "2020-12-01T07:19:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTAyOTE4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA0NDQ1NA==", "url": "https://github.com/apache/druid/pull/10518#discussion_r515044454", "bodyText": "It might be worth making it so these constant aggregators use the no-op aggregators as base classes, so that only the get methods need to be overridden, to let these implementations be a bit more concise.", "author": "clintropolis", "createdAt": "2020-10-30T11:52:41Z", "path": "processing/src/main/java/org/apache/druid/query/aggregation/constant/LongConstantAggregator.java", "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.query.aggregation.constant;\n+\n+import org.apache.druid.query.aggregation.Aggregator;\n+\n+public class LongConstantAggregator implements Aggregator", "originalCommit": "60f1041472a1b14cfd98359fcddca27e07bd9da0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTk0NzY5OQ==", "url": "https://github.com/apache/druid/pull/10518#discussion_r515947699", "bodyText": "Ack", "author": "abhishekagarwal87", "createdAt": "2020-11-02T12:48:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA0NDQ1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTk0OTI0NQ==", "url": "https://github.com/apache/druid/pull/10518#discussion_r515949245", "bodyText": "Those No-op aggregators are final classes so can't be extended. I don't see a clear reason why they are declared final. do you?", "author": "abhishekagarwal87", "createdAt": "2020-11-02T12:50:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA0NDQ1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjk1MjA0Nw==", "url": "https://github.com/apache/druid/pull/10518#discussion_r532952047", "bodyText": "If we rewrite the query to not include GroupingAggregatorFactory as I commented below, these aggregators won't be no longer in use.  GroupingAggregatorFactory can throw an exception instead when factorize() is called.", "author": "jihoonson", "createdAt": "2020-11-30T22:44:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA0NDQ1NA=="}], "type": "inlineReview"}, {"oid": "b36161f92c3651c028294f3ab96b9153bb9747be", "url": "https://github.com/apache/druid/commit/b36161f92c3651c028294f3ab96b9153bb9747be", "message": "Add calcite tests", "committedDate": "2020-11-17T08:02:29Z", "type": "commit"}, {"oid": "18ec231dc043f845b884ebb7f7d4948bf08b0f37", "url": "https://github.com/apache/druid/commit/18ec231dc043f845b884ebb7f7d4948bf08b0f37", "message": "Fix travis failures", "committedDate": "2020-11-19T07:18:33Z", "type": "commit"}, {"oid": "1ae99fc38e42da00853fd9343b777f95e793df89", "url": "https://github.com/apache/druid/commit/1ae99fc38e42da00853fd9343b777f95e793df89", "message": "bit of a change", "committedDate": "2020-12-01T07:53:47Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTcwMDY3Mg==", "url": "https://github.com/apache/druid/pull/10518#discussion_r535700672", "bodyText": "Please add some javadoc. It would be nice to include but not necessarily limited to the followings.\n\nThis factory is for computing grouping function.\nThis factory can create LongConstant*Aggregators. Unlike other aggregators, these LongConstant*Aggregators created by this factory does nothing with computing grouping function. Instead, they are used just to hold the positions of grouping results in the ResultRow.\nThe actual computation of grouping function is done before processing each subtotal. The result of LongConstant*Aggregators is not used but replaced with the precomputed result when iterating the result of subtotal computation. See RowBasedGrouperHelper.makeGrouperIterator() for more details.\nThere could be some different approach to implement the same functionality. We chose this approach because it seems more stable and less complex than others. See #10518 (comment) for more details.", "author": "jihoonson", "createdAt": "2020-12-03T22:47:26Z", "path": "processing/src/main/java/org/apache/druid/query/aggregation/GroupingAggregatorFactory.java", "diffHunk": "@@ -0,0 +1,282 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.query.aggregation;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n+import org.apache.druid.annotations.EverythingIsNonnullByDefault;\n+import org.apache.druid.query.aggregation.constant.LongConstantAggregator;\n+import org.apache.druid.query.aggregation.constant.LongConstantBufferAggregator;\n+import org.apache.druid.query.aggregation.constant.LongConstantVectorAggregator;\n+import org.apache.druid.query.cache.CacheKeyBuilder;\n+import org.apache.druid.segment.ColumnInspector;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.vector.VectorColumnSelectorFactory;\n+import org.apache.druid.utils.CollectionUtils;\n+\n+import javax.annotation.Nullable;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+@EverythingIsNonnullByDefault\n+public class GroupingAggregatorFactory extends AggregatorFactory", "originalCommit": "1ae99fc38e42da00853fd9343b777f95e793df89", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTcxOTIwNg==", "url": "https://github.com/apache/druid/pull/10518#discussion_r535719206", "bodyText": "I think we can just drop the last statement here. It's opposite to what their documentation says anyway.", "author": "jihoonson", "createdAt": "2020-12-03T23:22:33Z", "path": "processing/src/main/java/org/apache/druid/query/aggregation/GroupingAggregatorFactory.java", "diffHunk": "@@ -0,0 +1,282 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.query.aggregation;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n+import org.apache.druid.annotations.EverythingIsNonnullByDefault;\n+import org.apache.druid.query.aggregation.constant.LongConstantAggregator;\n+import org.apache.druid.query.aggregation.constant.LongConstantBufferAggregator;\n+import org.apache.druid.query.aggregation.constant.LongConstantVectorAggregator;\n+import org.apache.druid.query.cache.CacheKeyBuilder;\n+import org.apache.druid.segment.ColumnInspector;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.vector.VectorColumnSelectorFactory;\n+import org.apache.druid.utils.CollectionUtils;\n+\n+import javax.annotation.Nullable;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+@EverythingIsNonnullByDefault\n+public class GroupingAggregatorFactory extends AggregatorFactory\n+{\n+  private static final Comparator<Long> VALUE_COMPARATOR = Long::compare;\n+  private final String name;\n+  private final List<String> groupings;\n+  private final long value;\n+  @Nullable\n+  private final Set<String> keyDimensions;\n+\n+  @JsonCreator\n+  public GroupingAggregatorFactory(\n+      @JsonProperty(\"name\") String name,\n+      @JsonProperty(\"groupings\") List<String> groupings\n+  )\n+  {\n+    this(name, groupings, null);\n+  }\n+\n+  @VisibleForTesting\n+  GroupingAggregatorFactory(\n+      String name,\n+      List<String> groupings,\n+      @Nullable Set<String> keyDimensions\n+  )\n+  {\n+    Preconditions.checkNotNull(name, \"Must have a valid, non-null aggregator name\");\n+    this.name = name;\n+    this.groupings = groupings;\n+    this.keyDimensions = keyDimensions;\n+    value = groupingId(groupings, keyDimensions);\n+  }\n+\n+  @Override\n+  public Aggregator factorize(ColumnSelectorFactory metricFactory)\n+  {\n+    return new LongConstantAggregator(value);\n+  }\n+\n+  @Override\n+  public BufferAggregator factorizeBuffered(ColumnSelectorFactory metricFactory)\n+  {\n+    return new LongConstantBufferAggregator(value);\n+  }\n+\n+  @Override\n+  public VectorAggregator factorizeVector(VectorColumnSelectorFactory selectorFactory)\n+  {\n+    return new LongConstantVectorAggregator(value);\n+  }\n+\n+  @Override\n+  public boolean canVectorize(ColumnInspector columnInspector)\n+  {\n+    return true;\n+  }\n+\n+  /**\n+   * Replace the param {@code keyDimensions} with the new set of key dimensions\n+   */\n+  public GroupingAggregatorFactory withKeyDimensions(Set<String> newKeyDimensions)\n+  {\n+    return new GroupingAggregatorFactory(name, groupings, newKeyDimensions);\n+  }\n+\n+  @Override\n+  public Comparator getComparator()\n+  {\n+    return VALUE_COMPARATOR;\n+  }\n+\n+  @JsonProperty\n+  public List<String> getGroupings()\n+  {\n+    return groupings;\n+  }\n+\n+  @Override\n+  @JsonProperty\n+  public String getName()\n+  {\n+    return name;\n+  }\n+\n+  public long getValue()\n+  {\n+    return value;\n+  }\n+\n+  @Nullable\n+  @Override\n+  public Object combine(@Nullable Object lhs, @Nullable Object rhs)\n+  {\n+    if (null == lhs) {\n+      return rhs;\n+    }\n+    return lhs;\n+  }\n+\n+  @Override\n+  public AggregatorFactory getCombiningFactory()\n+  {\n+    return new GroupingAggregatorFactory(name, groupings, keyDimensions);\n+  }\n+\n+  @Override\n+  public List<AggregatorFactory> getRequiredColumns()\n+  {\n+    return Collections.singletonList(new GroupingAggregatorFactory(name, groupings, keyDimensions));\n+  }\n+\n+  @Override\n+  public Object deserialize(Object object)\n+  {\n+    return object;\n+  }\n+\n+  @Nullable\n+  @Override\n+  public Object finalizeComputation(@Nullable Object object)\n+  {\n+    return object;\n+  }\n+\n+  @Override\n+  public List<String> requiredFields()\n+  {\n+    // The aggregator doesn't need to read any fields.\n+    return Collections.emptyList();\n+  }\n+\n+  @Override\n+  public ValueType getType()\n+  {\n+    return ValueType.LONG;\n+  }\n+\n+  @Override\n+  public ValueType getFinalizedType()\n+  {\n+    return ValueType.LONG;\n+  }\n+\n+  @Override\n+  public int getMaxIntermediateSize()\n+  {\n+    return Long.BYTES;\n+  }\n+\n+  @Override\n+  public byte[] getCacheKey()\n+  {\n+    CacheKeyBuilder keyBuilder = new CacheKeyBuilder(AggregatorUtil.GROUPING_CACHE_TYPE_ID)\n+        .appendStrings(groupings);\n+    if (null != keyDimensions) {\n+      keyBuilder.appendStrings(keyDimensions);\n+    }\n+    return keyBuilder.build();\n+  }\n+\n+  /**\n+   * Given the list of grouping dimensions, returns a long value where each bit at position X in the returned value\n+   * corresponds to the dimension in groupings at same position X. X is the position relative to the right end. if\n+   * keyDimensions contain the grouping dimension at position X, the bit is set to 0 at position X, otherwise it is\n+   * set to 1. An example adapted from Microsoft SQL documentation", "originalCommit": "1ae99fc38e42da00853fd9343b777f95e793df89", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTcyMDEzOQ==", "url": "https://github.com/apache/druid/pull/10518#discussion_r535720139", "bodyText": "Please add some comment about what is happening here.", "author": "jihoonson", "createdAt": "2020-12-03T23:24:47Z", "path": "processing/src/main/java/org/apache/druid/query/groupby/epinephelinae/RowBasedGrouperHelper.java", "diffHunk": "@@ -576,7 +594,12 @@ private static ValueExtractFunction makeValueExtractFunction(\n           // Add aggregations.\n           final int resultRowAggregatorStart = query.getResultRowAggregatorStart();\n           for (int i = 0; i < entry.getValues().length; i++) {\n-            resultRow.set(resultRowAggregatorStart + i, entry.getValues()[i]);\n+            if (dimsToInclude != null && groupingAggregatorsBitSet.get(i)) {\n+              resultRow.set(resultRowAggregatorStart + i, groupingAggregatorValues[i]);", "originalCommit": "1ae99fc38e42da00853fd9343b777f95e793df89", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "6dd363203dd13d21657ebf38af0a837df96218e4", "url": "https://github.com/apache/druid/commit/6dd363203dd13d21657ebf38af0a837df96218e4", "message": "Add documentation", "committedDate": "2020-12-04T11:33:09Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ1MTY2Nw==", "url": "https://github.com/apache/druid/pull/10518#discussion_r536451667", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n             *                             {@code groupings0}. This argument cannot be passed by the user. It is set by druid engine\n          \n          \n            \n             *                             {@code groupings}. This argument cannot be passed by the user. It is set by druid engine", "author": "jihoonson", "createdAt": "2020-12-04T23:57:32Z", "path": "processing/src/main/java/org/apache/druid/query/aggregation/GroupingAggregatorFactory.java", "diffHunk": "@@ -41,6 +41,40 @@\n import java.util.Objects;\n import java.util.Set;\n \n+/**\n+ * This class implements {@code grouping_id} function to determine the grouping that a row is part of. Different rows\n+ * in same result could have different grouping columns when subtotals are used.\n+ *\n+ * It takes following arguments\n+ *  - {@code name} - Name of aggregators\n+ *  - {code groupings} - List of dimensions that user is interested in tracking\n+ *  - {@code keyDimensions} - The list of grouping dimensions being included in the result row. This list is a subset of\n+ *                             {@code groupings0}. This argument cannot be passed by the user. It is set by druid engine", "originalCommit": "6dd363203dd13d21657ebf38af0a837df96218e4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ1MTg3NA==", "url": "https://github.com/apache/druid/pull/10518#discussion_r536451874", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n             *  - {code groupings} - List of dimensions that user is interested in tracking\n          \n          \n            \n             *  - {@code groupings} - List of dimensions that user is interested in tracking", "author": "jihoonson", "createdAt": "2020-12-04T23:58:24Z", "path": "processing/src/main/java/org/apache/druid/query/aggregation/GroupingAggregatorFactory.java", "diffHunk": "@@ -41,6 +41,40 @@\n import java.util.Objects;\n import java.util.Set;\n \n+/**\n+ * This class implements {@code grouping_id} function to determine the grouping that a row is part of. Different rows\n+ * in same result could have different grouping columns when subtotals are used.\n+ *\n+ * It takes following arguments\n+ *  - {@code name} - Name of aggregators\n+ *  - {code groupings} - List of dimensions that user is interested in tracking", "originalCommit": "6dd363203dd13d21657ebf38af0a837df96218e4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ1NzI3NA==", "url": "https://github.com/apache/druid/pull/10518#discussion_r536457274", "bodyText": "nit: javadoc comment format on inline comment", "author": "clintropolis", "createdAt": "2020-12-05T00:18:38Z", "path": "processing/src/main/java/org/apache/druid/query/groupby/epinephelinae/RowBasedGrouperHelper.java", "diffHunk": "@@ -534,21 +536,45 @@ private static ValueExtractFunction makeValueExtractFunction(\n   public static CloseableGrouperIterator<RowBasedKey, ResultRow> makeGrouperIterator(\n       final Grouper<RowBasedKey> grouper,\n       final GroupByQuery query,\n-      @Nullable final List<String> dimsToInclude,\n+      @Nullable final List<DimensionSpec> dimsToInclude,\n       final Closeable closeable\n   )\n   {\n     final boolean includeTimestamp = query.getResultRowHasTimestamp();\n     final BitSet dimsToIncludeBitSet = new BitSet(query.getDimensions().size());\n     final int resultRowDimensionStart = query.getResultRowDimensionStart();\n+    final BitSet groupingAggregatorsBitSet = new BitSet(query.getAggregatorSpecs().size());\n+    final Object[] groupingAggregatorValues = new Long[query.getAggregatorSpecs().size()];\n \n     if (dimsToInclude != null) {\n-      for (String dimension : dimsToInclude) {\n-        final int dimIndex = query.getResultRowSignature().indexOf(dimension);\n+      for (DimensionSpec dimensionSpec : dimsToInclude) {\n+        String outputName = dimensionSpec.getOutputName();\n+        final int dimIndex = query.getResultRowSignature().indexOf(outputName);\n         if (dimIndex >= 0) {\n           dimsToIncludeBitSet.set(dimIndex - resultRowDimensionStart);\n         }\n       }\n+\n+      /**", "originalCommit": "6dd363203dd13d21657ebf38af0a837df96218e4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "5fc9a1b5f093baf75eecb4c46d5d24dc5b657bf6", "url": "https://github.com/apache/druid/commit/5fc9a1b5f093baf75eecb4c46d5d24dc5b657bf6", "message": "Fix typos", "committedDate": "2020-12-06T10:09:41Z", "type": "commit"}, {"oid": "8678c78d770bce2dda47a4dc15589ead42243bc4", "url": "https://github.com/apache/druid/commit/8678c78d770bce2dda47a4dc15589ead42243bc4", "message": "typo fix", "committedDate": "2020-12-07T10:48:47Z", "type": "commit"}]}