{"pr_number": 9122, "pr_title": "Add SQL GROUPING SETS support.", "pr_createdAt": "2020-01-03T19:03:47Z", "pr_url": "https://github.com/apache/druid/pull/9122", "timeline": [{"oid": "81ad3801c482d00260998cd7d5a92e406124809b", "url": "https://github.com/apache/druid/commit/81ad3801c482d00260998cd7d5a92e406124809b", "message": "Add SQL GROUPING SETS support.\n\nBuilt on top of the subtotalsSpec feature in the groupBy query. This also involves\ntwo changes to subtotalsSpec:\n\n- Alter behavior so limitSpec is applied after subtotalsSpec, rather than applied to\n  each grouping set. This is more in line with SQL standard behavior. I think it is okay\n  to make this change, since the old behavior was not documented, so users should\n  hopefully not be depending on it.\n- Fix a bug where virtual columns were included in the subtotal queries, but they\n  should not have been.\n\nAlso fixes two bugs in query equality checking:\n\n- BaseQuery: Use getDuration() instead of \"duration\" in equals and hashCode, since the\n  latter is lazily initialized and might be null in one query but not the other.\n- GroupByQuery: Include subtotalsSpec in equals and hashCode.", "committedDate": "2020-01-03T19:03:15Z", "type": "commit"}, {"oid": "3c7cef8e5e54520fa6532f8ba2772e78da07618c", "url": "https://github.com/apache/druid/commit/3c7cef8e5e54520fa6532f8ba2772e78da07618c", "message": "Fix bugs.", "committedDate": "2020-01-03T20:17:54Z", "type": "commit"}, {"oid": "d68dd92c20d5b9f7ef2685ce381f145b9fb71c1f", "url": "https://github.com/apache/druid/commit/d68dd92c20d5b9f7ef2685ce381f145b9fb71c1f", "message": "Merge branch 'master' into grouping-sets", "committedDate": "2020-02-21T19:13:34Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQyODA4Nw==", "url": "https://github.com/apache/druid/pull/9122#discussion_r383428087", "bodyText": "EqualsVerifier Test for this please", "author": "suneet-s", "createdAt": "2020-02-24T18:11:05Z", "path": "processing/src/main/java/org/apache/druid/query/groupby/GroupByQuery.java", "diffHunk": "@@ -1236,7 +1243,8 @@ public int hashCode()\n         dimFilter,\n         dimensions,\n         aggregatorSpecs,\n-        postAggregatorSpecs\n+        postAggregatorSpecs,\n+        subtotalsSpec", "originalCommit": "d68dd92c20d5b9f7ef2685ce381f145b9fb71c1f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDA4ODAyNg==", "url": "https://github.com/apache/druid/pull/9122#discussion_r384088026", "bodyText": "OK, I added it.", "author": "gianm", "createdAt": "2020-02-25T19:48:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQyODA4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ0MTU4Ng==", "url": "https://github.com/apache/druid/pull/9122#discussion_r383441586", "bodyText": "not really part of this change - maybe worth filing an issue for. The with... interface returns a query object, so chaining doesn't really make sense here. Maybe we should consider making that return the Builder so callers can call .build() when they're done setting all the fields. In this example it looks like it creates 4 intermediate GroupByQyery objects and a Builder for each object", "author": "suneet-s", "createdAt": "2020-02-24T18:38:17Z", "path": "processing/src/main/java/org/apache/druid/query/groupby/strategy/GroupByStrategyV2.java", "diffHunk": "@@ -369,13 +374,13 @@ public boolean doMergeResults(final GroupByQuery query)\n                    .map(AggregatorFactory::getCombiningFactory)\n                    .collect(Collectors.toList())\n           )\n-          .withSubtotalsSpec(null)\n-          .withDimFilter(null);\n-\n+          .withVirtualColumns(VirtualColumns.EMPTY)\n+          .withDimFilter(null)\n+          .withSubtotalsSpec(null);", "originalCommit": "d68dd92c20d5b9f7ef2685ce381f145b9fb71c1f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDA4NjIxMw==", "url": "https://github.com/apache/druid/pull/9122#discussion_r384086213", "bodyText": "What do you mean by 'make sense'? It makes sense to me in that you have an immutable object (the GroupByQuery) and you are using chaining to create a derived copy.", "author": "gianm", "createdAt": "2020-02-25T19:45:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ0MTU4Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDEyOTMwNQ==", "url": "https://github.com/apache/druid/pull/9122#discussion_r384129305", "bodyText": "Sorry, I should have phrased that better.\nI meant that there seems to be a lot of overlap between the .with... functions and the GroupByQuery.Builder functions. When I saw that pattern, I was wondering how do you choose between the 2. And since both exist, I may not pick the correct one.\nNothing to change here - just my stream of thought while reading the code.", "author": "suneet-s", "createdAt": "2020-02-25T21:13:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ0MTU4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ1MzUwOQ==", "url": "https://github.com/apache/druid/pull/9122#discussion_r383453509", "bodyText": "nit: it's cheaper to check if havingFilter != null before checking hasEffect", "author": "suneet-s", "createdAt": "2020-02-24T19:01:18Z", "path": "sql/src/main/java/org/apache/druid/sql/calcite/rel/DruidQuery.java", "diffHunk": "@@ -706,7 +722,9 @@ private Query computeQuery()\n   @Nullable\n   public TimeseriesQuery toTimeseriesQuery()\n   {\n-    if (grouping == null || grouping.getHavingFilter() != null) {\n+    if (grouping == null\n+        || grouping.getSubtotals().hasEffect(grouping.getDimensionSpecs())\n+        || grouping.getHavingFilter() != null) {", "originalCommit": "d68dd92c20d5b9f7ef2685ce381f145b9fb71c1f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDA4Njc3OQ==", "url": "https://github.com/apache/druid/pull/9122#discussion_r384086779", "bodyText": "It's probably going to be an exceedingly small effect, I'd like to leave it this way if you don't mind.", "author": "gianm", "createdAt": "2020-02-25T19:46:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ1MzUwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDEyNjg0NA==", "url": "https://github.com/apache/druid/pull/9122#discussion_r384126844", "bodyText": "\ud83d\udc4d", "author": "suneet-s", "createdAt": "2020-02-25T21:08:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ1MzUwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ1Nzg2Ng==", "url": "https://github.com/apache/druid/pull/9122#discussion_r383457866", "bodyText": "equals and hashCode for List<List> can be expensive. Is this concerning? Should we create a memoized string that represents the lists  so that the check can be faster? Or is that overkill?", "author": "suneet-s", "createdAt": "2020-02-24T19:10:03Z", "path": "sql/src/main/java/org/apache/druid/sql/calcite/rel/Subtotals.java", "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.sql.calcite.rel;\n+\n+\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Represents the Druid groupBy query concept of subtotals, which is similar to GROUPING SETS.\n+ */\n+public class Subtotals\n+{\n+  /**\n+   * List of subtotals: each one is a list of dimension indexes. (i.e. [0, 1] means use the first and second\n+   * dimensions).\n+   */\n+  private final List<IntList> subtotals;\n+\n+  Subtotals(List<IntList> subtotals)\n+  {\n+    this.subtotals = subtotals;\n+  }\n+\n+  public List<IntList> getSubtotals()\n+  {\n+    return subtotals;\n+  }\n+\n+  @Nullable\n+  public List<List<String>> toSubtotalsSpec(final List<DimensionSpec> dimensions)\n+  {\n+    if (hasEffect(dimensions)) {\n+      return subtotals.stream()\n+                      .map(\n+                          subtotalInts -> {\n+                            final List<String> subtotalDimensionNames = new ArrayList<>();\n+                            for (int dimIndex : subtotalInts) {\n+                              subtotalDimensionNames.add(dimensions.get(dimIndex).getOutputName());\n+                            }\n+                            return subtotalDimensionNames;\n+                          }\n+                      )\n+                      .collect(Collectors.toList());\n+    } else {\n+      return null;\n+    }\n+  }\n+\n+  /**\n+   * Returns whether this subtotals spec has an effect, and cannot be ignored.\n+   */\n+  public boolean hasEffect(final List<DimensionSpec> dimensionSpecs)\n+  {\n+    if (subtotals.isEmpty() || (subtotals.size() == 1 && subtotals.get(0).size() == dimensionSpecs.size())) {\n+      return false;\n+    } else {\n+      return true;\n+    }\n+  }\n+\n+  @Override\n+  public boolean equals(Object o)\n+  {\n+    if (this == o) {\n+      return true;\n+    }\n+    if (o == null || getClass() != o.getClass()) {\n+      return false;\n+    }\n+    Subtotals subtotals1 = (Subtotals) o;\n+    return subtotals.equals(subtotals1.subtotals);\n+  }\n+\n+  @Override\n+  public int hashCode()\n+  {\n+    return Objects.hash(subtotals);\n+  }", "originalCommit": "d68dd92c20d5b9f7ef2685ce381f145b9fb71c1f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDA4NzEzMg==", "url": "https://github.com/apache/druid/pull/9122#discussion_r384087132", "bodyText": "I don't expect them to be called very often, and usually in that case, I don't bother memoizing (extra code to get right).", "author": "gianm", "createdAt": "2020-02-25T19:46:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ1Nzg2Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDEyNjcyNA==", "url": "https://github.com/apache/druid/pull/9122#discussion_r384126724", "bodyText": "\ud83d\udc4d", "author": "suneet-s", "createdAt": "2020-02-25T21:08:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ1Nzg2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ2MTg4NQ==", "url": "https://github.com/apache/druid/pull/9122#discussion_r383461885", "bodyText": "\ud83d\udc4d nice tests!\nIs GROUPING SETS ( (dummy) ) === GROUPING SETS ( () ) or should it fail?", "author": "suneet-s", "createdAt": "2020-02-24T19:18:12Z", "path": "sql/src/test/java/org/apache/druid/sql/calcite/CalciteQueryTest.java", "diffHunk": "@@ -9579,6 +9600,538 @@ public void testGroupByTimeAndOtherDimension() throws Exception\n     );\n   }\n \n+  @Test\n+  public void testGroupingSets() throws Exception\n+  {\n+    // Cannot vectorize due to virtual columns.\n+    cannotVectorize();\n+\n+    testQuery(\n+        \"SELECT dim2, gran, SUM(cnt)\\n\"\n+        + \"FROM (SELECT FLOOR(__time TO MONTH) AS gran, COALESCE(dim2, '') dim2, cnt FROM druid.foo) AS x\\n\"\n+        + \"GROUP BY GROUPING SETS ( (dim2, gran), (dim2), (gran), () )\",\n+        ImmutableList.of(\n+            GroupByQuery.builder()\n+                        .setDataSource(CalciteTests.DATASOURCE1)\n+                        .setInterval(querySegmentSpec(Filtration.eternity()))\n+                        .setGranularity(Granularities.ALL)\n+                        .setVirtualColumns(\n+                            expressionVirtualColumn(\n+                                \"v0\",\n+                                \"case_searched(notnull(\\\"dim2\\\"),\\\"dim2\\\",'')\",\n+                                ValueType.STRING\n+                            ),\n+                            expressionVirtualColumn(\n+                                \"v1\",\n+                                \"timestamp_floor(\\\"__time\\\",'P1M',null,'UTC')\",\n+                                ValueType.LONG\n+                            )\n+                        )\n+                        .setDimensions(\n+                            dimensions(\n+                                new DefaultDimensionSpec(\"v0\", \"v0\"),\n+                                new DefaultDimensionSpec(\"v1\", \"v1\", ValueType.LONG)\n+                            )\n+                        )\n+                        .setAggregatorSpecs(aggregators(new LongSumAggregatorFactory(\"a0\", \"cnt\")))\n+                        .setSubtotalsSpec(\n+                            ImmutableList.of(\n+                                ImmutableList.of(\"v0\", \"v1\"),\n+                                ImmutableList.of(\"v0\"),\n+                                ImmutableList.of(\"v1\"),\n+                                ImmutableList.of()\n+                            )\n+                        )\n+                        .setContext(QUERY_CONTEXT_DEFAULT)\n+                        .build()\n+        ),\n+        ImmutableList.of(\n+            new Object[]{\"\", timestamp(\"2000-01-01\"), 2L},\n+            new Object[]{\"\", timestamp(\"2001-01-01\"), 1L},\n+            new Object[]{\"a\", timestamp(\"2000-01-01\"), 1L},\n+            new Object[]{\"a\", timestamp(\"2001-01-01\"), 1L},\n+            new Object[]{\"abc\", timestamp(\"2001-01-01\"), 1L},\n+            new Object[]{\"\", null, 3L},\n+            new Object[]{\"a\", null, 2L},\n+            new Object[]{\"abc\", null, 1L},\n+            new Object[]{NULL_VALUE, timestamp(\"2000-01-01\"), 3L},\n+            new Object[]{NULL_VALUE, timestamp(\"2001-01-01\"), 3L},\n+            new Object[]{NULL_VALUE, null, 6L}\n+        )\n+    );\n+  }\n+\n+  @Test\n+  public void testGroupingSetsWithNumericDimension() throws Exception\n+  {\n+    testQuery(\n+        \"SELECT cnt, COUNT(*)\\n\"\n+        + \"FROM foo\\n\"\n+        + \"GROUP BY GROUPING SETS ( (cnt), () )\",\n+        ImmutableList.of(\n+            GroupByQuery.builder()\n+                        .setDataSource(CalciteTests.DATASOURCE1)\n+                        .setInterval(querySegmentSpec(Filtration.eternity()))\n+                        .setGranularity(Granularities.ALL)\n+                        .setDimensions(dimensions(new DefaultDimensionSpec(\"cnt\", \"d0\", ValueType.LONG)))\n+                        .setAggregatorSpecs(aggregators(new CountAggregatorFactory(\"a0\")))\n+                        .setSubtotalsSpec(\n+                            ImmutableList.of(\n+                                ImmutableList.of(\"d0\"),\n+                                ImmutableList.of()\n+                            )\n+                        )\n+                        .setContext(QUERY_CONTEXT_DEFAULT)\n+                        .build()\n+        ),\n+        ImmutableList.of(\n+            new Object[]{1L, 6L},\n+            new Object[]{null, 6L}\n+        )\n+    );\n+  }\n+\n+  @Test\n+  public void testGroupByRollup() throws Exception\n+  {\n+    // Cannot vectorize due to virtual columns.\n+    cannotVectorize();\n+\n+    testQuery(\n+        \"SELECT dim2, gran, SUM(cnt)\\n\"\n+        + \"FROM (SELECT FLOOR(__time TO MONTH) AS gran, COALESCE(dim2, '') dim2, cnt FROM druid.foo) AS x\\n\"\n+        + \"GROUP BY ROLLUP (dim2, gran)\",\n+        ImmutableList.of(\n+            GroupByQuery.builder()\n+                        .setDataSource(CalciteTests.DATASOURCE1)\n+                        .setInterval(querySegmentSpec(Filtration.eternity()))\n+                        .setGranularity(Granularities.ALL)\n+                        .setVirtualColumns(\n+                            expressionVirtualColumn(\n+                                \"v0\",\n+                                \"case_searched(notnull(\\\"dim2\\\"),\\\"dim2\\\",'')\",\n+                                ValueType.STRING\n+                            ),\n+                            expressionVirtualColumn(\n+                                \"v1\",\n+                                \"timestamp_floor(\\\"__time\\\",'P1M',null,'UTC')\",\n+                                ValueType.LONG\n+                            )\n+                        )\n+                        .setDimensions(\n+                            dimensions(\n+                                new DefaultDimensionSpec(\"v0\", \"v0\"),\n+                                new DefaultDimensionSpec(\"v1\", \"v1\", ValueType.LONG)\n+                            )\n+                        )\n+                        .setAggregatorSpecs(aggregators(new LongSumAggregatorFactory(\"a0\", \"cnt\")))\n+                        .setSubtotalsSpec(\n+                            ImmutableList.of(\n+                                ImmutableList.of(\"v0\", \"v1\"),\n+                                ImmutableList.of(\"v0\"),\n+                                ImmutableList.of()\n+                            )\n+                        )\n+                        .setContext(QUERY_CONTEXT_DEFAULT)\n+                        .build()\n+        ),\n+        ImmutableList.of(\n+            new Object[]{\"\", timestamp(\"2000-01-01\"), 2L},\n+            new Object[]{\"\", timestamp(\"2001-01-01\"), 1L},\n+            new Object[]{\"a\", timestamp(\"2000-01-01\"), 1L},\n+            new Object[]{\"a\", timestamp(\"2001-01-01\"), 1L},\n+            new Object[]{\"abc\", timestamp(\"2001-01-01\"), 1L},\n+            new Object[]{\"\", null, 3L},\n+            new Object[]{\"a\", null, 2L},\n+            new Object[]{\"abc\", null, 1L},\n+            new Object[]{NULL_VALUE, null, 6L}\n+        )\n+    );\n+  }\n+\n+  @Test\n+  public void testGroupByCube() throws Exception\n+  {\n+    // Cannot vectorize due to virtual columns.\n+    cannotVectorize();\n+\n+    testQuery(\n+        \"SELECT dim2, gran, SUM(cnt)\\n\"\n+        + \"FROM (SELECT FLOOR(__time TO MONTH) AS gran, COALESCE(dim2, '') dim2, cnt FROM druid.foo) AS x\\n\"\n+        + \"GROUP BY CUBE (dim2, gran)\",\n+        ImmutableList.of(\n+            GroupByQuery.builder()\n+                        .setDataSource(CalciteTests.DATASOURCE1)\n+                        .setInterval(querySegmentSpec(Filtration.eternity()))\n+                        .setGranularity(Granularities.ALL)\n+                        .setVirtualColumns(\n+                            expressionVirtualColumn(\n+                                \"v0\",\n+                                \"case_searched(notnull(\\\"dim2\\\"),\\\"dim2\\\",'')\",\n+                                ValueType.STRING\n+                            ),\n+                            expressionVirtualColumn(\n+                                \"v1\",\n+                                \"timestamp_floor(\\\"__time\\\",'P1M',null,'UTC')\",\n+                                ValueType.LONG\n+                            )\n+                        )\n+                        .setDimensions(\n+                            dimensions(\n+                                new DefaultDimensionSpec(\"v0\", \"v0\"),\n+                                new DefaultDimensionSpec(\"v1\", \"v1\", ValueType.LONG)\n+                            )\n+                        )\n+                        .setAggregatorSpecs(aggregators(new LongSumAggregatorFactory(\"a0\", \"cnt\")))\n+                        .setSubtotalsSpec(\n+                            ImmutableList.of(\n+                                ImmutableList.of(\"v0\", \"v1\"),\n+                                ImmutableList.of(\"v0\"),\n+                                ImmutableList.of(\"v1\"),\n+                                ImmutableList.of()\n+                            )\n+                        )\n+                        .setContext(QUERY_CONTEXT_DEFAULT)\n+                        .build()\n+        ),\n+        ImmutableList.of(\n+            new Object[]{\"\", timestamp(\"2000-01-01\"), 2L},\n+            new Object[]{\"\", timestamp(\"2001-01-01\"), 1L},\n+            new Object[]{\"a\", timestamp(\"2000-01-01\"), 1L},\n+            new Object[]{\"a\", timestamp(\"2001-01-01\"), 1L},\n+            new Object[]{\"abc\", timestamp(\"2001-01-01\"), 1L},\n+            new Object[]{\"\", null, 3L},\n+            new Object[]{\"a\", null, 2L},\n+            new Object[]{\"abc\", null, 1L},\n+            new Object[]{NULL_VALUE, timestamp(\"2000-01-01\"), 3L},\n+            new Object[]{NULL_VALUE, timestamp(\"2001-01-01\"), 3L},\n+            new Object[]{NULL_VALUE, null, 6L}\n+        )\n+    );\n+  }\n+\n+  @Test\n+  public void testGroupingSetsWithDummyDimension() throws Exception\n+  {\n+    // Cannot vectorize due to virtual columns.\n+    cannotVectorize();\n+\n+    testQuery(\n+        \"SELECT dim2, gran, SUM(cnt)\\n\"\n+        + \"FROM (SELECT FLOOR(__time TO MONTH) AS gran, COALESCE(dim2, '') dim2, cnt FROM druid.foo) AS x\\n\"\n+        + \"GROUP BY GROUPING SETS ( (dim2, 'dummy', gran), (dim2), (gran), ('dummy') )\",\n+        ImmutableList.of(\n+            GroupByQuery.builder()\n+                        .setDataSource(CalciteTests.DATASOURCE1)\n+                        .setInterval(querySegmentSpec(Filtration.eternity()))\n+                        .setGranularity(Granularities.ALL)\n+                        .setVirtualColumns(\n+                            expressionVirtualColumn(\n+                                \"v0\",\n+                                \"case_searched(notnull(\\\"dim2\\\"),\\\"dim2\\\",'')\",\n+                                ValueType.STRING\n+                            ),\n+                            expressionVirtualColumn(\n+                                \"v2\",\n+                                \"timestamp_floor(\\\"__time\\\",'P1M',null,'UTC')\",\n+                                ValueType.LONG\n+                            )\n+                        )\n+                        .setDimensions(\n+                            dimensions(\n+                                new DefaultDimensionSpec(\"v0\", \"v0\"),\n+                                new DefaultDimensionSpec(\"v2\", \"v2\", ValueType.LONG)\n+                            )\n+                        )\n+                        .setAggregatorSpecs(aggregators(new LongSumAggregatorFactory(\"a0\", \"cnt\")))\n+                        .setSubtotalsSpec(\n+                            ImmutableList.of(\n+                                ImmutableList.of(\"v0\", \"v2\"),\n+                                ImmutableList.of(\"v0\"),\n+                                ImmutableList.of(),\n+                                ImmutableList.of(\"v2\")\n+                            )\n+                        )\n+                        .setContext(QUERY_CONTEXT_DEFAULT)\n+                        .build()\n+        ),\n+        ImmutableList.of(\n+            new Object[]{\"\", timestamp(\"2000-01-01\"), 2L},\n+            new Object[]{\"\", timestamp(\"2001-01-01\"), 1L},\n+            new Object[]{\"a\", timestamp(\"2000-01-01\"), 1L},\n+            new Object[]{\"a\", timestamp(\"2001-01-01\"), 1L},\n+            new Object[]{\"abc\", timestamp(\"2001-01-01\"), 1L},\n+            new Object[]{\"\", null, 3L},\n+            new Object[]{\"a\", null, 2L},\n+            new Object[]{\"abc\", null, 1L},\n+            new Object[]{NULL_VALUE, null, 6L},\n+            new Object[]{NULL_VALUE, timestamp(\"2000-01-01\"), 3L},\n+            new Object[]{NULL_VALUE, timestamp(\"2001-01-01\"), 3L}\n+        )\n+    );\n+  }\n+\n+  @Test\n+  public void testGroupingSetsNoSuperset() throws Exception\n+  {\n+    // Cannot vectorize due to virtual columns.\n+    cannotVectorize();\n+\n+    // Note: the grouping sets are reordered in the output of this query, but this is allowed.\n+    testQuery(\n+        \"SELECT dim2, gran, SUM(cnt)\\n\"\n+        + \"FROM (SELECT FLOOR(__time TO MONTH) AS gran, COALESCE(dim2, '') dim2, cnt FROM druid.foo) AS x\\n\"\n+        + \"GROUP BY GROUPING SETS ( (), (dim2), (gran) )\",\n+        ImmutableList.of(\n+            GroupByQuery.builder()\n+                        .setDataSource(CalciteTests.DATASOURCE1)\n+                        .setInterval(querySegmentSpec(Filtration.eternity()))\n+                        .setGranularity(Granularities.ALL)\n+                        .setVirtualColumns(\n+                            expressionVirtualColumn(\n+                                \"v0\",\n+                                \"case_searched(notnull(\\\"dim2\\\"),\\\"dim2\\\",'')\",\n+                                ValueType.STRING\n+                            ),\n+                            expressionVirtualColumn(\n+                                \"v1\",\n+                                \"timestamp_floor(\\\"__time\\\",'P1M',null,'UTC')\",\n+                                ValueType.LONG\n+                            )\n+                        )\n+                        .setDimensions(\n+                            dimensions(\n+                                new DefaultDimensionSpec(\"v0\", \"v0\"),\n+                                new DefaultDimensionSpec(\"v1\", \"v1\", ValueType.LONG)\n+                            )\n+                        )\n+                        .setAggregatorSpecs(aggregators(new LongSumAggregatorFactory(\"a0\", \"cnt\")))\n+                        .setSubtotalsSpec(\n+                            ImmutableList.of(\n+                                ImmutableList.of(\"v0\"),\n+                                ImmutableList.of(\"v1\"),\n+                                ImmutableList.of()\n+                            )\n+                        )\n+                        .setContext(QUERY_CONTEXT_DEFAULT)\n+                        .build()\n+        ),\n+        ImmutableList.of(\n+            new Object[]{\"\", null, 3L},\n+            new Object[]{\"a\", null, 2L},\n+            new Object[]{\"abc\", null, 1L},\n+            new Object[]{NULL_VALUE, timestamp(\"2000-01-01\"), 3L},\n+            new Object[]{NULL_VALUE, timestamp(\"2001-01-01\"), 3L},\n+            new Object[]{NULL_VALUE, null, 6L}\n+        )\n+    );\n+  }\n+\n+  @Test\n+  public void testGroupingSetsWithOrderByDimension() throws Exception\n+  {\n+    // Cannot vectorize due to virtual columns.\n+    cannotVectorize();\n+\n+    testQuery(\n+        \"SELECT dim2, gran, SUM(cnt)\\n\"\n+        + \"FROM (SELECT FLOOR(__time TO MONTH) AS gran, COALESCE(dim2, '') dim2, cnt FROM druid.foo) AS x\\n\"\n+        + \"GROUP BY GROUPING SETS ( (), (dim2), (gran) )\\n\"\n+        + \"ORDER BY gran, dim2 DESC\",\n+        ImmutableList.of(\n+            GroupByQuery.builder()\n+                        .setDataSource(CalciteTests.DATASOURCE1)\n+                        .setInterval(querySegmentSpec(Filtration.eternity()))\n+                        .setGranularity(Granularities.ALL)\n+                        .setVirtualColumns(\n+                            expressionVirtualColumn(\n+                                \"v0\",\n+                                \"case_searched(notnull(\\\"dim2\\\"),\\\"dim2\\\",'')\",\n+                                ValueType.STRING\n+                            ),\n+                            expressionVirtualColumn(\n+                                \"v1\",\n+                                \"timestamp_floor(\\\"__time\\\",'P1M',null,'UTC')\",\n+                                ValueType.LONG\n+                            )\n+                        )\n+                        .setDimensions(\n+                            dimensions(\n+                                new DefaultDimensionSpec(\"v0\", \"v0\"),\n+                                new DefaultDimensionSpec(\"v1\", \"v1\", ValueType.LONG)\n+                            )\n+                        )\n+                        .setAggregatorSpecs(aggregators(new LongSumAggregatorFactory(\"a0\", \"cnt\")))\n+                        .setSubtotalsSpec(\n+                            ImmutableList.of(\n+                                ImmutableList.of(\"v0\"),\n+                                ImmutableList.of(\"v1\"),\n+                                ImmutableList.of()\n+                            )\n+                        )\n+                        .setLimitSpec(\n+                            new DefaultLimitSpec(\n+                                ImmutableList.of(\n+                                    new OrderByColumnSpec(\n+                                        \"v1\",\n+                                        Direction.ASCENDING,\n+                                        StringComparators.NUMERIC\n+                                    ),\n+                                    new OrderByColumnSpec(\n+                                        \"v0\",\n+                                        Direction.DESCENDING,\n+                                        StringComparators.LEXICOGRAPHIC\n+                                    )\n+                                ),\n+                                Integer.MAX_VALUE\n+                            )\n+                        )\n+                        .setContext(QUERY_CONTEXT_DEFAULT)\n+                        .build()\n+        ),\n+        ImmutableList.of(\n+            new Object[]{\"abc\", null, 1L},\n+            new Object[]{\"a\", null, 2L},\n+            new Object[]{\"\", null, 3L},\n+            new Object[]{NULL_VALUE, null, 6L},\n+            new Object[]{NULL_VALUE, timestamp(\"2000-01-01\"), 3L},\n+            new Object[]{NULL_VALUE, timestamp(\"2001-01-01\"), 3L}\n+        )\n+    );\n+  }\n+\n+  @Test\n+  public void testGroupingSetsWithOrderByAggregator() throws Exception\n+  {\n+    // Cannot vectorize due to virtual columns.\n+    cannotVectorize();\n+\n+    testQuery(\n+        \"SELECT dim2, gran, SUM(cnt)\\n\"\n+        + \"FROM (SELECT FLOOR(__time TO MONTH) AS gran, COALESCE(dim2, '') dim2, cnt FROM druid.foo) AS x\\n\"\n+        + \"GROUP BY GROUPING SETS ( (), (dim2), (gran) )\\n\"\n+        + \"ORDER BY SUM(cnt)\\n\",\n+        ImmutableList.of(\n+            GroupByQuery.builder()\n+                        .setDataSource(CalciteTests.DATASOURCE1)\n+                        .setInterval(querySegmentSpec(Filtration.eternity()))\n+                        .setGranularity(Granularities.ALL)\n+                        .setVirtualColumns(\n+                            expressionVirtualColumn(\n+                                \"v0\",\n+                                \"case_searched(notnull(\\\"dim2\\\"),\\\"dim2\\\",'')\",\n+                                ValueType.STRING\n+                            ),\n+                            expressionVirtualColumn(\n+                                \"v1\",\n+                                \"timestamp_floor(\\\"__time\\\",'P1M',null,'UTC')\",\n+                                ValueType.LONG\n+                            )\n+                        )\n+                        .setDimensions(\n+                            dimensions(\n+                                new DefaultDimensionSpec(\"v0\", \"v0\"),\n+                                new DefaultDimensionSpec(\"v1\", \"v1\", ValueType.LONG)\n+                            )\n+                        )\n+                        .setAggregatorSpecs(aggregators(new LongSumAggregatorFactory(\"a0\", \"cnt\")))\n+                        .setSubtotalsSpec(\n+                            ImmutableList.of(\n+                                ImmutableList.of(\"v0\"),\n+                                ImmutableList.of(\"v1\"),\n+                                ImmutableList.of()\n+                            )\n+                        )\n+                        .setLimitSpec(\n+                            new DefaultLimitSpec(\n+                                ImmutableList.of(\n+                                    new OrderByColumnSpec(\n+                                        \"a0\",\n+                                        Direction.ASCENDING,\n+                                        StringComparators.NUMERIC\n+                                    )\n+                                ),\n+                                Integer.MAX_VALUE\n+                            )\n+                        )\n+                        .setContext(QUERY_CONTEXT_DEFAULT)\n+                        .build()\n+        ),\n+        ImmutableList.of(\n+            new Object[]{\"abc\", null, 1L},\n+            new Object[]{\"a\", null, 2L},\n+            new Object[]{\"\", null, 3L},\n+            new Object[]{NULL_VALUE, timestamp(\"2000-01-01\"), 3L},\n+            new Object[]{NULL_VALUE, timestamp(\"2001-01-01\"), 3L},\n+            new Object[]{NULL_VALUE, null, 6L}\n+        )\n+    );\n+  }\n+\n+  @Test\n+  public void testGroupingSetsWithOrderByAggregatorWithLimit() throws Exception\n+  {\n+    // Cannot vectorize due to virtual columns.\n+    cannotVectorize();\n+\n+    testQuery(\n+        \"SELECT dim2, gran, SUM(cnt)\\n\"\n+        + \"FROM (SELECT FLOOR(__time TO MONTH) AS gran, COALESCE(dim2, '') dim2, cnt FROM druid.foo) AS x\\n\"\n+        + \"GROUP BY GROUPING SETS ( (), (dim2), (gran) )\\n\"\n+        + \"ORDER BY SUM(cnt)\\n\"\n+        + \"LIMIT 1\",\n+        ImmutableList.of(\n+            GroupByQuery.builder()\n+                        .setDataSource(CalciteTests.DATASOURCE1)\n+                        .setInterval(querySegmentSpec(Filtration.eternity()))\n+                        .setGranularity(Granularities.ALL)\n+                        .setVirtualColumns(\n+                            expressionVirtualColumn(\n+                                \"v0\",\n+                                \"case_searched(notnull(\\\"dim2\\\"),\\\"dim2\\\",'')\",\n+                                ValueType.STRING\n+                            ),\n+                            expressionVirtualColumn(\n+                                \"v1\",\n+                                \"timestamp_floor(\\\"__time\\\",'P1M',null,'UTC')\",\n+                                ValueType.LONG\n+                            )\n+                        )\n+                        .setDimensions(\n+                            dimensions(\n+                                new DefaultDimensionSpec(\"v0\", \"v0\"),\n+                                new DefaultDimensionSpec(\"v1\", \"v1\", ValueType.LONG)\n+                            )\n+                        )\n+                        .setAggregatorSpecs(aggregators(new LongSumAggregatorFactory(\"a0\", \"cnt\")))\n+                        .setSubtotalsSpec(\n+                            ImmutableList.of(\n+                                ImmutableList.of(\"v0\"),\n+                                ImmutableList.of(\"v1\"),\n+                                ImmutableList.of()\n+                            )\n+                        )\n+                        .setLimitSpec(\n+                            new DefaultLimitSpec(\n+                                ImmutableList.of(\n+                                    new OrderByColumnSpec(\n+                                        \"a0\",\n+                                        Direction.ASCENDING,\n+                                        StringComparators.NUMERIC\n+                                    )\n+                                ),\n+                                1\n+                            )\n+                        )\n+                        .setContext(QUERY_CONTEXT_DEFAULT)\n+                        .build()\n+        ),\n+        ImmutableList.of(\n+            new Object[]{\"abc\", null, 1L}\n+        )\n+    );\n+  }\n+", "originalCommit": "d68dd92c20d5b9f7ef2685ce381f145b9fb71c1f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDA4NzQwMQ==", "url": "https://github.com/apache/druid/pull/9122#discussion_r384087401", "bodyText": "Are you referring to a specific test case?", "author": "gianm", "createdAt": "2020-02-25T19:47:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ2MTg4NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDEyNjYwNQ==", "url": "https://github.com/apache/druid/pull/9122#discussion_r384126605", "bodyText": "I don't think I read a test that did this explicitly. testGroupingSetsWithDummyDimension appears to do this where the dummy column isn't included in the subTotalsSpec. I guess I was just asking - is there anything special about calling GROUPING SETS only on a non-existent column? Should it just behave like you called GROUPING SETS on nothing?", "author": "suneet-s", "createdAt": "2020-02-25T21:08:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ2MTg4NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ2Mjk1MA==", "url": "https://github.com/apache/druid/pull/9122#discussion_r383462950", "bodyText": "Maybe add a test for ROLLUP (gran, dim2) ie reverse order of the select columns. Not sure if we need the same thing for CUBE since it generates the same grouping sets with the reverse order.", "author": "suneet-s", "createdAt": "2020-02-24T19:20:15Z", "path": "sql/src/test/java/org/apache/druid/sql/calcite/CalciteQueryTest.java", "diffHunk": "@@ -9579,6 +9600,538 @@ public void testGroupByTimeAndOtherDimension() throws Exception\n     );\n   }\n \n+  @Test\n+  public void testGroupingSets() throws Exception\n+  {\n+    // Cannot vectorize due to virtual columns.\n+    cannotVectorize();\n+\n+    testQuery(\n+        \"SELECT dim2, gran, SUM(cnt)\\n\"\n+        + \"FROM (SELECT FLOOR(__time TO MONTH) AS gran, COALESCE(dim2, '') dim2, cnt FROM druid.foo) AS x\\n\"\n+        + \"GROUP BY GROUPING SETS ( (dim2, gran), (dim2), (gran), () )\",\n+        ImmutableList.of(\n+            GroupByQuery.builder()\n+                        .setDataSource(CalciteTests.DATASOURCE1)\n+                        .setInterval(querySegmentSpec(Filtration.eternity()))\n+                        .setGranularity(Granularities.ALL)\n+                        .setVirtualColumns(\n+                            expressionVirtualColumn(\n+                                \"v0\",\n+                                \"case_searched(notnull(\\\"dim2\\\"),\\\"dim2\\\",'')\",\n+                                ValueType.STRING\n+                            ),\n+                            expressionVirtualColumn(\n+                                \"v1\",\n+                                \"timestamp_floor(\\\"__time\\\",'P1M',null,'UTC')\",\n+                                ValueType.LONG\n+                            )\n+                        )\n+                        .setDimensions(\n+                            dimensions(\n+                                new DefaultDimensionSpec(\"v0\", \"v0\"),\n+                                new DefaultDimensionSpec(\"v1\", \"v1\", ValueType.LONG)\n+                            )\n+                        )\n+                        .setAggregatorSpecs(aggregators(new LongSumAggregatorFactory(\"a0\", \"cnt\")))\n+                        .setSubtotalsSpec(\n+                            ImmutableList.of(\n+                                ImmutableList.of(\"v0\", \"v1\"),\n+                                ImmutableList.of(\"v0\"),\n+                                ImmutableList.of(\"v1\"),\n+                                ImmutableList.of()\n+                            )\n+                        )\n+                        .setContext(QUERY_CONTEXT_DEFAULT)\n+                        .build()\n+        ),\n+        ImmutableList.of(\n+            new Object[]{\"\", timestamp(\"2000-01-01\"), 2L},\n+            new Object[]{\"\", timestamp(\"2001-01-01\"), 1L},\n+            new Object[]{\"a\", timestamp(\"2000-01-01\"), 1L},\n+            new Object[]{\"a\", timestamp(\"2001-01-01\"), 1L},\n+            new Object[]{\"abc\", timestamp(\"2001-01-01\"), 1L},\n+            new Object[]{\"\", null, 3L},\n+            new Object[]{\"a\", null, 2L},\n+            new Object[]{\"abc\", null, 1L},\n+            new Object[]{NULL_VALUE, timestamp(\"2000-01-01\"), 3L},\n+            new Object[]{NULL_VALUE, timestamp(\"2001-01-01\"), 3L},\n+            new Object[]{NULL_VALUE, null, 6L}\n+        )\n+    );\n+  }\n+\n+  @Test\n+  public void testGroupingSetsWithNumericDimension() throws Exception\n+  {\n+    testQuery(\n+        \"SELECT cnt, COUNT(*)\\n\"\n+        + \"FROM foo\\n\"\n+        + \"GROUP BY GROUPING SETS ( (cnt), () )\",\n+        ImmutableList.of(\n+            GroupByQuery.builder()\n+                        .setDataSource(CalciteTests.DATASOURCE1)\n+                        .setInterval(querySegmentSpec(Filtration.eternity()))\n+                        .setGranularity(Granularities.ALL)\n+                        .setDimensions(dimensions(new DefaultDimensionSpec(\"cnt\", \"d0\", ValueType.LONG)))\n+                        .setAggregatorSpecs(aggregators(new CountAggregatorFactory(\"a0\")))\n+                        .setSubtotalsSpec(\n+                            ImmutableList.of(\n+                                ImmutableList.of(\"d0\"),\n+                                ImmutableList.of()\n+                            )\n+                        )\n+                        .setContext(QUERY_CONTEXT_DEFAULT)\n+                        .build()\n+        ),\n+        ImmutableList.of(\n+            new Object[]{1L, 6L},\n+            new Object[]{null, 6L}\n+        )\n+    );\n+  }\n+\n+  @Test\n+  public void testGroupByRollup() throws Exception\n+  {\n+    // Cannot vectorize due to virtual columns.\n+    cannotVectorize();\n+\n+    testQuery(\n+        \"SELECT dim2, gran, SUM(cnt)\\n\"\n+        + \"FROM (SELECT FLOOR(__time TO MONTH) AS gran, COALESCE(dim2, '') dim2, cnt FROM druid.foo) AS x\\n\"\n+        + \"GROUP BY ROLLUP (dim2, gran)\",", "originalCommit": "d68dd92c20d5b9f7ef2685ce381f145b9fb71c1f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDA5MjM5MA==", "url": "https://github.com/apache/druid/pull/9122#discussion_r384092390", "bodyText": "OK, I'll add it.", "author": "gianm", "createdAt": "2020-02-25T19:56:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ2Mjk1MA=="}], "type": "inlineReview"}, {"oid": "a3b0a415b9e79bc880ee9d1b6191a471efe23935", "url": "https://github.com/apache/druid/commit/a3b0a415b9e79bc880ee9d1b6191a471efe23935", "message": "Merge branch 'master' into grouping-sets", "committedDate": "2020-02-25T02:08:59Z", "type": "commit"}, {"oid": "a9ede1a829a486872daa7744949e822d28e288d7", "url": "https://github.com/apache/druid/commit/a9ede1a829a486872daa7744949e822d28e288d7", "message": "Fix tests.", "committedDate": "2020-02-25T02:17:35Z", "type": "commit"}, {"oid": "922263425044d473f919565b5e5dae2b6313d43f", "url": "https://github.com/apache/druid/commit/922263425044d473f919565b5e5dae2b6313d43f", "message": "PR updates.", "committedDate": "2020-02-25T19:57:38Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDE5MDUyMQ==", "url": "https://github.com/apache/druid/pull/9122#discussion_r384190521", "bodyText": "Should havingFilter be annotated with @Nullable for this method as well?", "author": "ccaominh", "createdAt": "2020-02-25T23:30:37Z", "path": "sql/src/main/java/org/apache/druid/sql/calcite/rel/Grouping.java", "diffHunk": "@@ -92,19 +104,25 @@ private Grouping(\n \n   public static Grouping create(\n       final List<DimensionExpression> dimensions,\n+      final Subtotals subtotals,\n       final List<Aggregation> aggregations,\n       final DimFilter havingFilter,\n       final RowSignature outputRowSignature\n   )\n   {\n-    return new Grouping(dimensions, aggregations, havingFilter, outputRowSignature);\n+    return new Grouping(dimensions, subtotals, aggregations, havingFilter, outputRowSignature);", "originalCommit": "922263425044d473f919565b5e5dae2b6313d43f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDIxMzU2MQ==", "url": "https://github.com/apache/druid/pull/9122#discussion_r384213561", "bodyText": "Yes, it should, I'll add it.", "author": "gianm", "createdAt": "2020-02-26T00:40:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDE5MDUyMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDE5MjM3Mw==", "url": "https://github.com/apache/druid/pull/9122#discussion_r384192373", "bodyText": "Is there a test for this?", "author": "ccaominh", "createdAt": "2020-02-25T23:35:08Z", "path": "sql/src/main/java/org/apache/druid/sql/calcite/rel/Grouping.java", "diffHunk": "@@ -141,36 +159,95 @@ public RowSignature getOutputRowSignature()\n     return outputRowSignature;\n   }\n \n+  /**\n+   * Applies a post-grouping projection.\n+   *\n+   * @see DruidQuery#computeGrouping which uses this\n+   */\n+  public Grouping applyProject(final PlannerContext plannerContext, final Project project)\n+  {\n+    final List<DimensionExpression> newDimensions = new ArrayList<>();\n+    final List<Aggregation> newAggregations = new ArrayList<>(aggregations);\n+    final Subtotals newSubtotals;\n+\n+    final Projection postAggregationProjection = Projection.postAggregation(\n+        project,\n+        plannerContext,\n+        outputRowSignature,\n+        \"p\"\n+    );\n+\n+    postAggregationProjection.getPostAggregators().forEach(\n+        postAggregator -> newAggregations.add(Aggregation.create(postAggregator))\n+    );\n+\n+    // Remove literal dimensions that did not appear in the projection. This is useful for queries\n+    // like \"SELECT COUNT(*) FROM tbl GROUP BY 'dummy'\" which some tools can generate, and for which we don't\n+    // actually want to include a dimension 'dummy'.\n+    final ImmutableBitSet aggregateProjectBits = RelOptUtil.InputFinder.bits(project.getChildExps(), null);\n+    final int[] newDimIndexes = new int[dimensions.size()];\n+\n+    for (int i = 0; i < dimensions.size(); i++) {\n+      final DimensionExpression dimension = dimensions.get(i);\n+      if (Parser.parse(dimension.getDruidExpression().getExpression(), plannerContext.getExprMacroTable())\n+                .isLiteral() && !aggregateProjectBits.get(i)) {\n+        newDimIndexes[i] = -1;\n+      } else {\n+        newDimIndexes[i] = newDimensions.size();\n+        newDimensions.add(dimension);\n+      }\n+    }\n+\n+    // Renumber subtotals, if needed, to account for removed dummy dimensions.\n+    if (newDimensions.size() != dimensions.size()) {\n+      final List<IntList> newSubtotalsList = new ArrayList<>();\n+\n+      for (IntList subtotal : subtotals.getSubtotals()) {\n+        final IntList newSubtotal = new IntArrayList();\n+        for (int dimIndex : subtotal) {\n+          final int newDimIndex = newDimIndexes[dimIndex];\n+          if (newDimIndex >= 0) {\n+            newSubtotal.add(newDimIndex);\n+          }\n+        }\n+\n+        newSubtotalsList.add(newSubtotal);\n+      }\n+\n+      newSubtotals = new Subtotals(newSubtotalsList);\n+    } else {\n+      newSubtotals = subtotals;\n+    }\n+\n+    return Grouping.create(\n+        newDimensions,\n+        newSubtotals,\n+        newAggregations,\n+        havingFilter,\n+        postAggregationProjection.getOutputRowSignature()\n+    );\n+  }\n+\n   @Override\n-  public boolean equals(final Object o)\n+  public boolean equals(Object o)", "originalCommit": "922263425044d473f919565b5e5dae2b6313d43f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDIxMzU3Mg==", "url": "https://github.com/apache/druid/pull/9122#discussion_r384213572", "bodyText": "I'll add one.", "author": "gianm", "createdAt": "2020-02-26T00:40:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDE5MjM3Mw=="}], "type": "inlineReview"}, {"oid": "3074be820663cdd6be239baea6303eb37a692334", "url": "https://github.com/apache/druid/commit/3074be820663cdd6be239baea6303eb37a692334", "message": "Grouping class hygiene.", "committedDate": "2020-02-26T00:40:11Z", "type": "commit"}]}