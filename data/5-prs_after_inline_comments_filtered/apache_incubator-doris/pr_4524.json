{"pr_number": 4524, "pr_title": "[SparkDpp] Support complete types", "pr_createdAt": "2020-09-02T13:24:04Z", "pr_url": "https://github.com/apache/incubator-doris/pull/4524", "timeline": [{"oid": "07942ac364d185906fb5d2a6e748a2b01f37f4d2", "url": "https://github.com/apache/incubator-doris/commit/07942ac364d185906fb5d2a6e748a2b01f37f4d2", "message": "support complete types", "committedDate": "2020-09-02T13:16:36Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzkzMDYyMA==", "url": "https://github.com/apache/incubator-doris/pull/4524#discussion_r483930620", "bodyText": "If the column definition is k1 decimal(4,3), than the value range of k1 should be\n[-9.999, 9.999]\nAnd your code will give: [-9999.999, 9999.999], which is not right.", "author": "morningman", "createdAt": "2020-09-05T09:09:13Z", "path": "fe/spark-dpp/src/main/java/org/apache/doris/load/loadv2/dpp/ColumnParser.java", "diffHunk": "@@ -186,4 +192,61 @@ public boolean parse(String value) {\n             throw new RuntimeException(\"string check failed \", e);\n         }\n     }\n+}\n+\n+class DecimalParser extends ColumnParser {\n+\n+    public static int PRECISION = 27;\n+    public static int SCALE = 9;\n+\n+    private BigDecimal maxValue;\n+    private BigDecimal minValue;\n+\n+    public DecimalParser(EtlJobConfig.EtlColumn etlColumn) {\n+        StringBuilder precisionStr = new StringBuilder();\n+        for (int i = 0; i < etlColumn.precision; i++) {", "originalCommit": "07942ac364d185906fb5d2a6e748a2b01f37f4d2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzkzNDU3Mg==", "url": "https://github.com/apache/incubator-doris/pull/4524#discussion_r483934572", "bodyText": "Better to refer to the logic in DecimalLiteral class.\ncheckPrecisionAndScale(int precision, int scale)", "author": "wyb", "createdAt": "2020-09-05T09:56:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzkzMDYyMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDE1ODI3NA==", "url": "https://github.com/apache/incubator-doris/pull/4524#discussion_r484158274", "bodyText": "\ud83d\udc4c", "author": "wangbo", "createdAt": "2020-09-07T02:51:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzkzMDYyMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzkzMTM0Nw==", "url": "https://github.com/apache/incubator-doris/pull/4524#discussion_r483931347", "bodyText": "missing DEFAULT?", "author": "morningman", "createdAt": "2020-09-05T09:18:18Z", "path": "fe/spark-dpp/src/main/java/org/apache/doris/load/loadv2/dpp/SparkDpp.java", "diffHunk": "@@ -358,12 +362,44 @@ private void processRollupTree(RollupTreeNode rootNode,\n         return Pair.of(keyMap.toArray(new Integer[keyMap.size()]), valueMap.toArray(new Integer[valueMap.size()]));\n     }\n \n-    // repartition dataframe by partitionid_bucketid\n-    // so data in the same bucket will be consecutive.\n-    private JavaPairRDD<List<Object>, Object[]> fillTupleWithPartitionColumn(SparkSession spark, Dataset<Row> dataframe,\n+    /**\n+     *   check decimal,char/varchar\n+     */\n+    private boolean validateData(Object srcValue, EtlJobConfig.EtlColumn etlColumn, ColumnParser columnParser,Row row) {\n+\n+        switch (etlColumn.columnType.toUpperCase()) {\n+            case \"DECIMALV2\":\n+                // TODO(wb):  support decimal round; see be DecimalV2Value::round\n+                DecimalParser decimalParser = (DecimalParser) columnParser;\n+                BigDecimal srcBigDecimal = (BigDecimal) srcValue;\n+                if (srcValue != null && (decimalParser.getMaxValue().compareTo(srcBigDecimal) < 0 || decimalParser.getMinValue().compareTo(srcBigDecimal) > 0)) {\n+                    LOG.warn(String.format(\"decimal value is not valid for defination, column=%s, value=%s,precision=%s,scale=%s\",\n+                            etlColumn.columnName, srcValue.toString(), srcBigDecimal.precision(), srcBigDecimal.scale()));\n+                    abnormalRowAcc.add(1);\n+                    return false;\n+                }\n+                break;\n+            case \"CHAR\":\n+            case \"VARCHAR\":\n+                // TODO(wb) padding char type\n+                if (srcValue != null && srcValue.toString().length() > etlColumn.stringLength) {\n+                    LOG.warn(String.format(\"the length of input is too long than schema. column_name:%s,input_str[%s],schema length:%s,actual length:%s\",\n+                            etlColumn.columnName, row.toString(), etlColumn.stringLength, srcValue.toString().length()));\n+                    return false;\n+                }\n+                break;", "originalCommit": "07942ac364d185906fb5d2a6e748a2b01f37f4d2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDE1ODYzOA==", "url": "https://github.com/apache/incubator-doris/pull/4524#discussion_r484158638", "bodyText": "we just validate char/varchar and decimal here,so it't not necessary", "author": "wangbo", "createdAt": "2020-09-07T02:53:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzkzMTM0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzkzNjEwMg==", "url": "https://github.com/apache/incubator-doris/pull/4524#discussion_r483936102", "bodyText": "Check largeint type range", "author": "wyb", "createdAt": "2020-09-05T10:16:30Z", "path": "fe/spark-dpp/src/main/java/org/apache/doris/load/loadv2/dpp/ColumnParser.java", "diffHunk": "@@ -186,4 +192,61 @@ public boolean parse(String value) {\n             throw new RuntimeException(\"string check failed \", e);\n         }\n     }\n+}\n+\n+class DecimalParser extends ColumnParser {\n+\n+    public static int PRECISION = 27;\n+    public static int SCALE = 9;\n+\n+    private BigDecimal maxValue;\n+    private BigDecimal minValue;\n+\n+    public DecimalParser(EtlJobConfig.EtlColumn etlColumn) {\n+        StringBuilder precisionStr = new StringBuilder();\n+        for (int i = 0; i < etlColumn.precision; i++) {\n+            precisionStr.append(\"9\");\n+        }\n+        StringBuilder scaleStr = new StringBuilder();\n+        for (int i = 0; i < etlColumn.scale; i++) {\n+            scaleStr.append(\"9\");\n+        }\n+        maxValue = new BigDecimal(precisionStr.toString() + \".\" + scaleStr.toString());\n+        minValue = new BigDecimal(\"-\" + precisionStr.toString() + \".\" + scaleStr.toString());\n+    }\n+\n+    @Override\n+    public boolean parse(String value) {\n+        try {\n+            BigDecimal bigDecimal = new BigDecimal(value);\n+            return bigDecimal.precision() - bigDecimal.scale() <= PRECISION - SCALE && bigDecimal.scale() <= SCALE;\n+        } catch (NumberFormatException e) {\n+            return false;\n+        } catch (Exception e) {\n+            throw new RuntimeException(\"decimal parse failed \", e);\n+        }\n+    }\n+\n+    public BigDecimal getMaxValue() {\n+        return maxValue;\n+    }\n+\n+    public BigDecimal getMinValue() {\n+        return minValue;\n+    }\n+}\n+\n+class LargeIntParser extends ColumnParser {\n+\n+    @Override\n+    public boolean parse(String value) {\n+        try {\n+            BigInteger bigInteger = new BigInteger(value);", "originalCommit": "07942ac364d185906fb5d2a6e748a2b01f37f4d2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDE1OTg3Ng==", "url": "https://github.com/apache/incubator-doris/pull/4524#discussion_r484159876", "bodyText": "BigInteger constructors and operations throw {@code ArithmeticException} when\nthe result is out of the supported range of\n-2 Integer.MAX_VALUE}(exclusive) to\n+2Integer.MAX_VALUE}(exclusive)\n\nSo I think add a ArithmeticException here is enough", "author": "wangbo", "createdAt": "2020-09-07T02:59:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzkzNjEwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDA2MzgzNg==", "url": "https://github.com/apache/incubator-doris/pull/4524#discussion_r484063836", "bodyText": "byte length", "author": "wyb", "createdAt": "2020-09-06T12:27:05Z", "path": "fe/spark-dpp/src/main/java/org/apache/doris/load/loadv2/dpp/SparkDpp.java", "diffHunk": "@@ -358,12 +362,44 @@ private void processRollupTree(RollupTreeNode rootNode,\n         return Pair.of(keyMap.toArray(new Integer[keyMap.size()]), valueMap.toArray(new Integer[valueMap.size()]));\n     }\n \n-    // repartition dataframe by partitionid_bucketid\n-    // so data in the same bucket will be consecutive.\n-    private JavaPairRDD<List<Object>, Object[]> fillTupleWithPartitionColumn(SparkSession spark, Dataset<Row> dataframe,\n+    /**\n+     *   check decimal,char/varchar\n+     */\n+    private boolean validateData(Object srcValue, EtlJobConfig.EtlColumn etlColumn, ColumnParser columnParser,Row row) {\n+\n+        switch (etlColumn.columnType.toUpperCase()) {\n+            case \"DECIMALV2\":\n+                // TODO(wb):  support decimal round; see be DecimalV2Value::round\n+                DecimalParser decimalParser = (DecimalParser) columnParser;\n+                BigDecimal srcBigDecimal = (BigDecimal) srcValue;\n+                if (srcValue != null && (decimalParser.getMaxValue().compareTo(srcBigDecimal) < 0 || decimalParser.getMinValue().compareTo(srcBigDecimal) > 0)) {\n+                    LOG.warn(String.format(\"decimal value is not valid for defination, column=%s, value=%s,precision=%s,scale=%s\",\n+                            etlColumn.columnName, srcValue.toString(), srcBigDecimal.precision(), srcBigDecimal.scale()));\n+                    abnormalRowAcc.add(1);\n+                    return false;\n+                }\n+                break;\n+            case \"CHAR\":\n+            case \"VARCHAR\":\n+                // TODO(wb) padding char type\n+                if (srcValue != null && srcValue.toString().length() > etlColumn.stringLength) {", "originalCommit": "07942ac364d185906fb5d2a6e748a2b01f37f4d2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDE1OTg4NQ==", "url": "https://github.com/apache/incubator-doris/pull/4524#discussion_r484159885", "bodyText": "\ud83d\udc4c", "author": "wangbo", "createdAt": "2020-09-07T02:59:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDA2MzgzNg=="}], "type": "inlineReview"}, {"oid": "3fa0b36bc80afd1f6b0266ec20862844ec0147f9", "url": "https://github.com/apache/incubator-doris/commit/3fa0b36bc80afd1f6b0266ec20862844ec0147f9", "message": "1 add ut\n2 some fix", "committedDate": "2020-09-08T06:03:29Z", "type": "commit"}, {"oid": "155d3df799e8d339089d39f85f6299040e12f389", "url": "https://github.com/apache/incubator-doris/commit/155d3df799e8d339089d39f85f6299040e12f389", "message": "remove useless import", "committedDate": "2020-09-09T02:54:26Z", "type": "commit"}]}