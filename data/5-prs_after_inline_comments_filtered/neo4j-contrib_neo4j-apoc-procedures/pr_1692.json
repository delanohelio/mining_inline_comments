{"pr_number": 1692, "pr_title": "Fixes #1689: Adds support for S3 as an export destination", "pr_createdAt": "2020-10-14T02:00:44Z", "pr_url": "https://github.com/neo4j-contrib/neo4j-apoc-procedures/pull/1692", "timeline": [{"oid": "f82fa86eaa2932dadcafbccfe15b82349712b85d", "url": "https://github.com/neo4j-contrib/neo4j-apoc-procedures/commit/f82fa86eaa2932dadcafbccfe15b82349712b85d", "message": "Fixes #1689: Adds support for S3 as an export destination\n\nAdds support for S3 as an export destination\n\nAdds the ability to use an S3 location as an export destination for csv, graphml, json, and cypher script.\n\nIncludes test coverage.\n\nhttps://github.com/neo4j-contrib/neo4j-apoc-procedures/issues/1689", "committedDate": "2020-10-14T00:05:10Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjM0NzIwNQ==", "url": "https://github.com/neo4j-contrib/neo4j-apoc-procedures/pull/1692#discussion_r506347205", "bodyText": "Instead of this ignore we can leverage LocalStack in combination with Testcontainers:\nhttps://www.testcontainers.org/modules/localstack/\ncan you please create a base class with it and extend each one that you created?", "author": "conker84", "createdAt": "2020-10-16T12:06:26Z", "path": "src/test/java/apoc/export/ExportS3PerformanceTest.java", "diffHunk": "@@ -0,0 +1,116 @@\n+package apoc.export;\n+\n+import apoc.export.csv.ExportCSV;\n+import apoc.graph.Graphs;\n+import apoc.util.TestUtil;\n+import apoc.util.s3.S3Aws;\n+import apoc.util.s3.S3Params;\n+import apoc.util.s3.S3ParamsExtractor;\n+import com.amazonaws.services.s3.AmazonS3;\n+import com.amazonaws.services.s3.model.ObjectListing;\n+import com.amazonaws.services.s3.model.S3ObjectSummary;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.Ignore;\n+import org.junit.Test;\n+import org.neo4j.graphdb.GraphDatabaseService;\n+import org.neo4j.graphdb.factory.GraphDatabaseSettings;\n+import org.neo4j.test.TestGraphDatabaseFactory;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.net.URL;\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.Optional;\n+\n+import static apoc.util.MapUtil.map;\n+import static junit.framework.TestCase.assertTrue;\n+\n+@Ignore(\"To use this test, you need to set the S3 bucket and region to a valid endpoint \" +", "originalCommit": "f82fa86eaa2932dadcafbccfe15b82349712b85d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjM0Nzk4NQ==", "url": "https://github.com/neo4j-contrib/neo4j-apoc-procedures/pull/1692#discussion_r506347985", "bodyText": "I think that we can make public the ones inside ExportCsvTest and reuse them", "author": "conker84", "createdAt": "2020-10-16T12:07:21Z", "path": "src/test/java/apoc/export/csv/ExportCsvS3Test.java", "diffHunk": "@@ -0,0 +1,265 @@\n+package apoc.export.csv;\n+\n+import apoc.graph.Graphs;\n+import apoc.util.TestUtil;\n+import apoc.util.s3.S3TestUtil;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.Ignore;\n+import org.junit.Test;\n+import org.neo4j.graphdb.GraphDatabaseService;\n+import org.neo4j.graphdb.factory.GraphDatabaseSettings;\n+import org.neo4j.test.TestGraphDatabaseFactory;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.Map;\n+import java.util.Optional;\n+\n+import static apoc.util.MapUtil.map;\n+import static junit.framework.TestCase.assertTrue;\n+import static org.junit.Assert.assertEquals;\n+\n+@Ignore(\"To use this test, you need to set the S3 bucket and region to a valid endpoint \" +\n+        \"and have your access key and secret key setup in your environment.\")\n+public class ExportCsvS3Test {\n+    private static String S3_BUCKET_NAME = null;\n+\n+    private static final String EXPECTED_QUERY_NODES = String.format(\"\\\"u\\\"%n\" +\n+            \"\\\"{\\\"\\\"id\\\"\\\":0,\\\"\\\"labels\\\"\\\":[\\\"\\\"User\\\"\\\",\\\"\\\"User1\\\"\\\"],\\\"\\\"properties\\\"\\\":{\\\"\\\"name\\\"\\\":\\\"\\\"foo\\\"\\\",\\\"\\\"age\\\"\\\":42,\\\"\\\"male\\\"\\\":true,\\\"\\\"kids\\\"\\\":[\\\"\\\"a\\\"\\\",\\\"\\\"b\\\"\\\",\\\"\\\"c\\\"\\\"]}}\\\"%n\" +\n+            \"\\\"{\\\"\\\"id\\\"\\\":1,\\\"\\\"labels\\\"\\\":[\\\"\\\"User\\\"\\\"],\\\"\\\"properties\\\"\\\":{\\\"\\\"name\\\"\\\":\\\"\\\"bar\\\"\\\",\\\"\\\"age\\\"\\\":42}}\\\"%n\" +\n+            \"\\\"{\\\"\\\"id\\\"\\\":2,\\\"\\\"labels\\\"\\\":[\\\"\\\"User\\\"\\\"],\\\"\\\"properties\\\"\\\":{\\\"\\\"age\\\"\\\":12}}\\\"%n\");\n+    private static final String EXPECTED_QUERY = String.format(\"\\\"u.age\\\",\\\"u.name\\\",\\\"u.male\\\",\\\"u.kids\\\",\\\"labels(u)\\\"%n\" +\n+            \"\\\"42\\\",\\\"foo\\\",\\\"true\\\",\\\"[\\\"\\\"a\\\"\\\",\\\"\\\"b\\\"\\\",\\\"\\\"c\\\"\\\"]\\\",\\\"[\\\"\\\"User1\\\"\\\",\\\"\\\"User\\\"\\\"]\\\"%n\" +\n+            \"\\\"42\\\",\\\"bar\\\",\\\"\\\",\\\"\\\",\\\"[\\\"\\\"User\\\"\\\"]\\\"%n\" +\n+            \"\\\"12\\\",\\\"\\\",\\\"\\\",\\\"\\\",\\\"[\\\"\\\"User\\\"\\\"]\\\"%n\");\n+    private static final String EXPECTED_QUERY_WITHOUT_QUOTES = String.format(\"u.age,u.name,u.male,u.kids,labels(u)%n\" +\n+            \"42,foo,true,[\\\"a\\\",\\\"b\\\",\\\"c\\\"],[\\\"User1\\\",\\\"User\\\"]%n\" +\n+            \"42,bar,,,[\\\"User\\\"]%n\" +\n+            \"12,,,,[\\\"User\\\"]%n\");\n+    private static final String EXPECTED_QUERY_QUOTES_NONE = String.format(\"a.name,a.city,a.street,labels(a)%n\" +\n+            \"Andrea,Milano,Via Garibaldi, 7,[\\\"Address1\\\",\\\"Address\\\"]%n\" +\n+            \"Bar Sport,,,[\\\"Address\\\"]%n\" +\n+            \",,via Benni,[\\\"Address\\\"]%n\");\n+    private static final String EXPECTED_QUERY_QUOTES_ALWAYS = String.format(\"\\\"a.name\\\",\\\"a.city\\\",\\\"a.street\\\",\\\"labels(a)\\\"%n\" +\n+            \"\\\"Andrea\\\",\\\"Milano\\\",\\\"Via Garibaldi, 7\\\",\\\"[\\\"\\\"Address1\\\"\\\",\\\"\\\"Address\\\"\\\"]\\\"%n\" +\n+            \"\\\"Bar Sport\\\",\\\"\\\",\\\"\\\",\\\"[\\\"\\\"Address\\\"\\\"]\\\"%n\" +\n+            \"\\\"\\\",\\\"\\\",\\\"via Benni\\\",\\\"[\\\"\\\"Address\\\"\\\"]\\\"%n\");\n+    private static final String EXPECTED_QUERY_QUOTES_NEEDED = String.format(\"a.name,a.city,a.street,labels(a)%n\" +\n+            \"Andrea,Milano,\\\"Via Garibaldi, 7\\\",\\\"[\\\"Address1\\\",\\\"Address\\\"]\\\"%n\" +\n+            \"Bar Sport,,,\\\"[\\\"Address\\\"]\\\"%n\" +\n+            \",,via Benni,\\\"[\\\"Address\\\"]\\\"%n\");\n+    private static final String EXPECTED = String.format(\"\\\"_id\\\",\\\"_labels\\\",\\\"age\\\",\\\"city\\\",\\\"kids\\\",\\\"male\\\",\\\"name\\\",\\\"street\\\",\\\"_start\\\",\\\"_end\\\",\\\"_type\\\"%n\" +\n+            \"\\\"0\\\",\\\":User:User1\\\",\\\"42\\\",\\\"\\\",\\\"[\\\"\\\"a\\\"\\\",\\\"\\\"b\\\"\\\",\\\"\\\"c\\\"\\\"]\\\",\\\"true\\\",\\\"foo\\\",\\\"\\\",,,%n\" +\n+            \"\\\"1\\\",\\\":User\\\",\\\"42\\\",\\\"\\\",\\\"\\\",\\\"\\\",\\\"bar\\\",\\\"\\\",,,%n\" +\n+            \"\\\"2\\\",\\\":User\\\",\\\"12\\\",\\\"\\\",\\\"\\\",\\\"\\\",\\\"\\\",\\\"\\\",,,%n\" +\n+            \"\\\"20\\\",\\\":Address:Address1\\\",\\\"\\\",\\\"Milano\\\",\\\"\\\",\\\"\\\",\\\"Andrea\\\",\\\"Via Garibaldi, 7\\\",,,%n\" +\n+            \"\\\"21\\\",\\\":Address\\\",\\\"\\\",\\\"\\\",\\\"\\\",\\\"\\\",\\\"Bar Sport\\\",\\\"\\\",,,%n\" +\n+            \"\\\"22\\\",\\\":Address\\\",\\\"\\\",\\\"\\\",\\\"\\\",\\\"\\\",\\\"\\\",\\\"via Benni\\\",,,%n\" +\n+            \",,,,,,,,\\\"0\\\",\\\"1\\\",\\\"KNOWS\\\"%n\" +\n+            \",,,,,,,,\\\"20\\\",\\\"21\\\",\\\"NEXT_DELIVERY\\\"%n\");\n+\n+    private static final String EXPECTED_NONE_QUOTES = String.format(\"_id,_labels,age,city,kids,male,name,street,_start,_end,_type%n\" +\n+            \"0,:User:User1,42,,[\\\"a\\\",\\\"b\\\",\\\"c\\\"],true,foo,,,,%n\" +\n+            \"1,:User,42,,,,bar,,,,%n\" +\n+            \"2,:User,12,,,,,,,,%n\" +\n+            \"20,:Address:Address1,,Milano,,,Andrea,Via Garibaldi, 7,,,%n\" +\n+            \"21,:Address,,,,,Bar Sport,,,,%n\" +\n+            \"22,:Address,,,,,,via Benni,,,%n\" +\n+            \",,,,,,,,0,1,KNOWS%n\" +\n+            \",,,,,,,,20,21,NEXT_DELIVERY%n\");\n+    private static final String EXPECTED_NEEDED_QUOTES = String.format(\"_id,_labels,age,city,kids,male,name,street,_start,_end,_type%n\" +\n+            \"0,:User:User1,42,,\\\"[\\\"a\\\",\\\"b\\\",\\\"c\\\"]\\\",true,foo,,,,%n\" +\n+            \"1,:User,42,,,,bar,,,,%n\" +\n+            \"2,:User,12,,,,,,,,%n\" +\n+            \"20,:Address:Address1,,Milano,,,Andrea,\\\"Via Garibaldi, 7\\\",,,%n\" +\n+            \"21,:Address,,,,,Bar Sport,,,,%n\" +\n+            \"22,:Address,,,,,,via Benni,,,%n\" +\n+            \",,,,,,,,0,1,KNOWS%n\" +\n+            \",,,,,,,,20,21,NEXT_DELIVERY%n\");", "originalCommit": "f82fa86eaa2932dadcafbccfe15b82349712b85d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjM0OTE2NQ==", "url": "https://github.com/neo4j-contrib/neo4j-apoc-procedures/pull/1692#discussion_r506349165", "bodyText": "I think that we can make public the inner class inside ExportCypherTest and reuse it", "author": "conker84", "createdAt": "2020-10-16T12:08:45Z", "path": "src/test/java/apoc/export/cypher/ExportCypherS3Test.java", "diffHunk": "@@ -0,0 +1,1060 @@\n+package apoc.export.cypher;\n+\n+import apoc.graph.Graphs;\n+import apoc.util.TestUtil;\n+import apoc.util.s3.S3TestUtil;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Ignore;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TestName;\n+import org.neo4j.graphdb.GraphDatabaseService;\n+import org.neo4j.graphdb.factory.GraphDatabaseSettings;\n+import org.neo4j.test.TestGraphDatabaseFactory;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.Map;\n+import java.util.Optional;\n+\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_CLEAN_UP;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_CLEAN_UP_EMPTY;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_CYPHER_DATE;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_CYPHER_DURATION;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_CYPHER_LABELS_ASCENDEND;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_CYPHER_POINT;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_CYPHER_SHELL;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_CYPHER_SHELL_OPTIMIZED;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_CYPHER_SHELL_OPTIMIZED_BATCH_SIZE;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_CYPHER_TIME;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_INDEXES_AWAIT;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_NEO4J_MERGE;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_NEO4J_OPTIMIZED;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_NEO4J_OPTIMIZED_BATCH_SIZE;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_NEO4J_SHELL;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_NODES;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_NODES_EMPTY;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_NODES_MERGE_ON_CREATE_SET;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_NODES_OPTIMIZED;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_ONLY_SCHEMA_CYPHER_SHELL;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_ONLY_SCHEMA_NEO4J_SHELL;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_PLAIN;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_PLAIN_ADD_STRUCTURE_UNWIND;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_PLAIN_OPTIMIZED_BATCH_SIZE;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_PLAIN_UPDATE_STRUCTURE_UNWIND;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_QUERY_CYPHER_SHELL_OPTIMIZED_ODD;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_QUERY_CYPHER_SHELL_OPTIMIZED_UNWIND;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_QUERY_CYPHER_SHELL_PARAMS_OPTIMIZED_ODD;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_RELATIONSHIPS;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_RELATIONSHIPS_MERGE_ON_CREATE_SET;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_RELATIONSHIPS_OPTIMIZED;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_RELATIONSHIPS_PARAMS_ODD;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_SCHEMA;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_SCHEMA_EMPTY;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_SCHEMA_OPTIMIZED;\n+import static apoc.export.cypher.ExportCypherTest.ExportCypherResults.EXPECTED_UPDATE_ALL_UNWIND;\n+import static apoc.export.util.ExportFormat.CYPHER_SHELL;\n+import static apoc.export.util.ExportFormat.NEO4J_SHELL;\n+import static apoc.export.util.ExportFormat.PLAIN_FORMAT;\n+import static apoc.util.Util.map;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+@Ignore(\"To use this test, you need to set the S3 bucket and region to a valid endpoint \" +\n+        \"and have your access key and secret key setup in your environment.\")\n+public class ExportCypherS3Test {\n+    private static String S3_BUCKET_NAME = null;\n+\n+    private static final Map<String, Object> exportConfig = map(\"useOptimizations\", map(\"type\", \"none\"), \"separateFiles\", true, \"format\", \"neo4j-admin\");\n+    private static GraphDatabaseService db;\n+    private static File directory = new File(\"target/import\");\n+\n+    static { //noinspection ResultOfMethodCallIgnored\n+        directory.mkdirs();\n+    }\n+\n+    @Rule\n+    public TestName testName = new TestName();\n+\n+    private static final String OPTIMIZED = \"Optimized\";\n+    private static final String ODD = \"OddDataset\";\n+\n+    private static String getS3Url(String key) {\n+        return String.format(\"s3://:@/%s/%s\", S3_BUCKET_NAME, key);\n+    }\n+\n+    private void verifyUpload(String fileName, String expected) throws IOException {\n+        String s3Url = getS3Url(fileName);\n+        S3TestUtil.readFile(s3Url, Paths.get(directory.toString(), fileName).toString());\n+        assertEquals(expected, readFile(fileName));\n+    }\n+\n+    private static String readFile(String fileName) {\n+        return TestUtil.readFileToString(new File(directory, fileName));\n+    }\n+\n+    private static String getEnvVar(String envVarKey) throws Exception {\n+        return Optional.ofNullable(System.getenv(envVarKey)).orElseThrow(\n+                () -> new Exception(String.format(\"%s is not set in the environment\", envVarKey))\n+        );\n+    }\n+\n+    @Before\n+    public void setUp() throws Exception {\n+        if (S3_BUCKET_NAME == null) {\n+            S3_BUCKET_NAME = getEnvVar(\"S3_BUCKET_NAME\");\n+        }\n+        db = new TestGraphDatabaseFactory().newImpermanentDatabaseBuilder()\n+                .setConfig(GraphDatabaseSettings.load_csv_file_url_root, directory.getAbsolutePath())\n+                .setConfig(\"apoc.export.file.enabled\", \"true\")\n+                .newGraphDatabase();\n+        TestUtil.registerProcedure(db, ExportCypher.class, Graphs.class);\n+        db.execute(\"CREATE INDEX ON :Bar(first_name, last_name)\").close();\n+        db.execute(\"CREATE INDEX ON :Foo(name)\").close();\n+        db.execute(\"CREATE CONSTRAINT ON (b:Bar) ASSERT b.name IS UNIQUE\").close();\n+        if (testName.getMethodName().endsWith(OPTIMIZED)) {\n+            db.execute(\"CREATE (f:Foo {name:'foo', born:date('2018-10-31')})-[:KNOWS {since:2016}]->(b:Bar {name:'bar',age:42}),(c:Bar:Person {age:12}),(d:Bar {age:12}),\" +\n+                    \" (t:Foo {name:'foo2', born:date('2017-09-29')})-[:KNOWS {since:2015}]->(e:Bar {name:'bar2',age:44}),({age:99})\").close();\n+        } else if(testName.getMethodName().endsWith(ODD)) {\n+            db.execute(\"CREATE (f:Foo {name:'foo', born:date('2018-10-31')}),\" +\n+                    \"(t:Foo {name:'foo2', born:date('2017-09-29')}),\" +\n+                    \"(g:Foo {name:'foo3', born:date('2016-03-12')}),\" +\n+                    \"(b:Bar {name:'bar',age:42}),\" +\n+                    \"(c:Bar {age:12}),\" +\n+                    \"(d:Bar {age:4}),\" +\n+                    \"(e:Bar {name:'bar2',age:44}),\" +\n+                    \"(f)-[:KNOWS {since:2016}]->(b)\").close();\n+        } else {\n+            db.execute(\"CREATE (f:Foo {name:'foo', born:date('2018-10-31')})-[:KNOWS {since:2016}]->(b:Bar {name:'bar',age:42}),(c:Bar {age:12})\").close();\n+        }\n+    }\n+\n+    @After\n+    public void tearDown() {\n+        db.shutdown();\n+    }\n+\n+    // -- Whole file test -- //\n+    @Test\n+    public void testExportAllCypherDefault() throws Exception {\n+        String fileName = \"all.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        TestUtil.testCall(db, \"CALL apoc.export.cypher.all($s3,{useOptimizations: { type: 'none'}, format: 'neo4j-shell'})\",\n+                map(\"s3\", s3Url),\n+                (r) -> assertResults(s3Url, r, \"database\"));\n+        verifyUpload(fileName, EXPECTED_NEO4J_SHELL);\n+    }\n+\n+    @Test\n+    public void testExportAllCypherForCypherShell() throws Exception {\n+        String fileName = \"all.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        TestUtil.testCall(db, \"CALL apoc.export.cypher.all($s3,$config)\",\n+                map(\"s3\", s3Url, \"config\", map(\"useOptimizations\", map(\"type\", \"none\"), \"format\", \"cypher-shell\")),\n+                (r) -> assertResults(s3Url, r, \"database\"));\n+        verifyUpload(fileName, EXPECTED_CYPHER_SHELL);\n+    }\n+\n+    @Test\n+    public void testExportQueryCypherForNeo4j() throws Exception {\n+        String fileName = \"all.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        String query = \"MATCH (n) OPTIONAL MATCH p = (n)-[r]-(m) RETURN n,r,m\";\n+        TestUtil.testCall(db, \"CALL apoc.export.cypher.query($query,$s3,$config)\",\n+                map(\"s3\", s3Url, \"query\", query, \"config\", map(\"useOptimizations\", map(\"type\", \"none\"), \"format\", \"neo4j-shell\")), (r) -> {\n+                });\n+        verifyUpload(fileName, EXPECTED_NEO4J_SHELL);\n+    }\n+\n+    @Test\n+    public void testExportGraphCypher() throws Exception {\n+        String fileName = \"graph.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        TestUtil.testCall(db, \"CALL apoc.graph.fromDB('test',{}) yield graph \" +\n+                        \"CALL apoc.export.cypher.graph(graph, $s3,$exportConfig) \" +\n+                        \"YIELD nodes, relationships, properties, file, source,format, time \" +\n+                        \"RETURN *\",\n+                map(\"s3\", s3Url, \"exportConfig\", map(\"useOptimizations\", map(\"type\", \"none\"), \"format\", \"neo4j-shell\")),\n+                (r) -> assertResults(s3Url, r, \"graph\"));\n+        verifyUpload(fileName, EXPECTED_NEO4J_SHELL);\n+    }\n+\n+    // -- Separate files tests -- //\n+    @Test\n+    public void testExportAllCypherNodes() throws Exception {\n+        String fileName = \"all.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        TestUtil.testCall(db, \"CALL apoc.export.cypher.all($s3,$exportConfig)\",\n+                map(\"s3\", s3Url, \"exportConfig\", exportConfig),\n+                (r) -> assertResults(s3Url, r, \"database\"));\n+        verifyUpload(\"all.nodes.cypher\", EXPECTED_NODES);\n+    }\n+\n+    @Test\n+    public void testExportAllCypherRelationships() throws Exception {\n+        String fileName = \"all.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        TestUtil.testCall(db, \"CALL apoc.export.cypher.all($s3,$exportConfig)\",\n+                map(\"s3\", s3Url, \"exportConfig\", exportConfig),\n+                (r) -> assertResults(s3Url, r, \"database\"));\n+        verifyUpload(\"all.relationships.cypher\", EXPECTED_RELATIONSHIPS);\n+    }\n+\n+    @Test\n+    public void testExportAllCypherSchema() throws Exception {\n+        String fileName = \"all.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        TestUtil.testCall(db, \"CALL apoc.export.cypher.all($s3,$exportConfig)\",\n+                map(\"s3\", s3Url, \"exportConfig\", exportConfig),\n+                (r) -> assertResults(s3Url, r, \"database\"));\n+        verifyUpload(\"all.schema.cypher\", EXPECTED_SCHEMA);\n+    }\n+\n+    @Test\n+    public void testExportAllCypherCleanUp() throws Exception {\n+        String fileName = \"all.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        TestUtil.testCall(db, \"CALL apoc.export.cypher.all($s3,$exportConfig)\",\n+                map(\"s3\", s3Url, \"exportConfig\", exportConfig),\n+                (r) -> assertResults(s3Url, r, \"database\"));\n+        verifyUpload(\"all.cleanup.cypher\", EXPECTED_CLEAN_UP);\n+    }\n+\n+    @Test\n+    public void testExportGraphCypherNodes() throws Exception {\n+        String fileName = \"graph.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        TestUtil.testCall(db, \"CALL apoc.graph.fromDB('test',{}) yield graph \" +\n+                \"CALL apoc.export.cypher.graph(graph, $s3,$exportConfig) \" +\n+                \"YIELD nodes, relationships, properties, file, source,format, time \" +\n+                \"RETURN *\",\n+                map(\"s3\", s3Url, \"exportConfig\", exportConfig),\n+                (r) -> assertResults(s3Url, r, \"graph\"));\n+        verifyUpload(\"graph.nodes.cypher\", EXPECTED_NODES);\n+    }\n+\n+    @Test\n+    public void testExportGraphCypherRelationships() throws Exception {\n+        String fileName = \"graph.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        TestUtil.testCall(db, \"CALL apoc.graph.fromDB('test',{}) yield graph \" +\n+                        \"CALL apoc.export.cypher.graph(graph, $s3,$exportConfig) \" +\n+                        \"YIELD nodes, relationships, properties, file, source, format, time \" +\n+                        \"RETURN *\",\n+                map(\"s3\", s3Url, \"exportConfig\", exportConfig),\n+                (r) -> assertResults(s3Url, r, \"graph\"));\n+        verifyUpload(\"graph.relationships.cypher\", EXPECTED_RELATIONSHIPS);\n+    }\n+\n+    @Test\n+    public void testExportGraphCypherSchema() throws Exception {\n+        String fileName = \"graph.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        TestUtil.testCall(db, \"CALL apoc.graph.fromDB('test',{}) yield graph \" +\n+                        \"CALL apoc.export.cypher.graph(graph, $s3,$exportConfig) \" +\n+                        \"YIELD nodes, relationships, properties, file, source,format, time \" +\n+                        \"RETURN *\",\n+                map(\"s3\", s3Url, \"exportConfig\", exportConfig),\n+                (r) -> assertResults(s3Url, r, \"graph\"));\n+        verifyUpload(\"graph.schema.cypher\", EXPECTED_SCHEMA);\n+    }\n+\n+    @Test\n+    public void testExportGraphCypherCleanUp() throws Exception {\n+        String fileName = \"graph.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        TestUtil.testCall(db, \"CALL apoc.graph.fromDB('test',{}) yield graph \" +\n+                        \"CALL apoc.export.cypher.graph(graph, $s3,$exportConfig) \" +\n+                        \"YIELD nodes, relationships, properties, file, source,format, time \" +\n+                        \"RETURN *\",\n+                map(\"s3\", s3Url, \"exportConfig\", exportConfig),\n+                (r) -> assertResults(s3Url, r, \"graph\"));\n+        verifyUpload(\"graph.cleanup.cypher\", EXPECTED_CLEAN_UP);\n+    }\n+\n+    private void assertResults(String fileName, Map<String, Object> r, final String source) {\n+        assertEquals(3L, r.get(\"nodes\"));\n+        assertEquals(1L, r.get(\"relationships\"));\n+        assertEquals(6L, r.get(\"properties\"));\n+        assertEquals(fileName, r.get(\"file\"));\n+        assertEquals(source + \": nodes(3), rels(1)\", r.get(\"source\"));\n+        assertEquals(\"cypher\", r.get(\"format\"));\n+        assertTrue(\"Should get time greater than 0\",((long) r.get(\"time\")) >= 0);\n+    }\n+\n+    @Test\n+    public void testExportQueryCypherPlainFormat() throws Exception {\n+        String fileName = \"all.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        String query = \"MATCH (n) OPTIONAL MATCH p = (n)-[r]-(m) RETURN n,r,m\";\n+        TestUtil.testCall(db, \"CALL apoc.export.cypher.query($query,$s3,$config)\",\n+                map(\"s3\", s3Url, \"query\", query, \"config\", map(\"useOptimizations\", map(\"type\", \"none\"), \"format\", \"plain\")), (r) -> {\n+                });\n+        verifyUpload(fileName, EXPECTED_PLAIN);\n+    }\n+\n+    @Test\n+    public void testExportQueryCypherFormatUpdateAll() throws Exception {\n+        String fileName = \"all.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        String query = \"MATCH (n) OPTIONAL MATCH p = (n)-[r]-(m) RETURN n,r,m\";\n+        TestUtil.testCall(db, \"CALL apoc.export.cypher.query($query,$s3,$config)\",\n+                map(\"s3\", s3Url, \"query\", query, \"config\", map(\"useOptimizations\", map(\"type\", \"none\"), \"format\", \"neo4j-shell\", \"cypherFormat\", \"updateAll\")), (r) -> {\n+                });\n+        verifyUpload(fileName, EXPECTED_NEO4J_MERGE);\n+    }\n+\n+    @Test\n+    public void testExportQueryCypherFormatAddStructure() throws Exception {\n+        String fileName = \"all.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        String query = \"MATCH (n) OPTIONAL MATCH p = (n)-[r]-(m) RETURN n,r,m\";\n+        TestUtil.testCall(db, \"CALL apoc.export.cypher.query($query,$s3,$config)\",\n+                map(\"s3\", s3Url, \"query\", query, \"config\", map(\"useOptimizations\", map(\"type\", \"none\"), \"format\", \"neo4j-shell\", \"cypherFormat\", \"addStructure\")), (r) -> {\n+                });\n+        verifyUpload(fileName, EXPECTED_NODES_MERGE_ON_CREATE_SET + EXPECTED_SCHEMA_EMPTY + EXPECTED_RELATIONSHIPS + EXPECTED_CLEAN_UP_EMPTY);\n+    }\n+\n+    @Test\n+    public void testExportQueryCypherFormatUpdateStructure() throws Exception {\n+        String fileName = \"all.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        String query = \"MATCH (n) OPTIONAL MATCH p = (n)-[r]-(m) RETURN n,r,m\";\n+        TestUtil.testCall(db, \"CALL apoc.export.cypher.query($query,$s3,$config)\",\n+                map(\"s3\", s3Url, \"query\", query, \"config\", map(\"useOptimizations\", map(\"type\", \"none\"), \"format\", \"neo4j-shell\", \"cypherFormat\", \"updateStructure\")), (r) -> {\n+                });\n+        verifyUpload(fileName, EXPECTED_NODES_EMPTY + EXPECTED_SCHEMA_EMPTY + EXPECTED_RELATIONSHIPS_MERGE_ON_CREATE_SET + EXPECTED_CLEAN_UP_EMPTY);\n+    }\n+\n+    @Test\n+    public void testExportSchemaCypher() throws Exception {\n+        String fileName = \"onlySchema.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        TestUtil.testCall(db, \"CALL apoc.export.cypher.schema($s3,$exportConfig)\", map(\"s3\", s3Url, \"exportConfig\", exportConfig), (r) -> {\n+        });\n+        verifyUpload(fileName, EXPECTED_ONLY_SCHEMA_NEO4J_SHELL);\n+    }\n+\n+    @Test\n+    public void testExportSchemaCypherShell() throws Exception {\n+        String fileName = \"onlySchema.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        TestUtil.testCall(db, \"CALL apoc.export.cypher.schema($s3,$exportConfig)\",\n+                map(\"s3\", s3Url, \"exportConfig\", map(\"useOptimizations\", map(\"type\", \"none\"), \"format\", \"cypher-shell\")),\n+                (r) -> {});\n+        verifyUpload(fileName, EXPECTED_ONLY_SCHEMA_CYPHER_SHELL);\n+    }\n+\n+    @Test\n+    public void testExportCypherNodePoint() throws IOException {\n+        db.execute(\"CREATE (f:Test {name:'foo',\" +\n+                \"place2d:point({ x: 2.3, y: 4.5 }),\" +\n+                \"place3d1:point({ x: 2.3, y: 4.5 , z: 1.2})})\" +\n+                \"-[:FRIEND_OF {place2d:point({ longitude: 56.7, latitude: 12.78 })}]->\" +\n+                \"(:Bar {place3d:point({ longitude: 12.78, latitude: 56.7, height: 100 })})\");\n+        String fileName = \"temporalPoint.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        String query = \"MATCH (n:Test)-[r]-(m) RETURN n,r,m\";\n+        TestUtil.testCall(db, \"CALL apoc.export.cypher.query($query,$s3,$config)\",\n+                map(\"s3\", s3Url, \"query\", query, \"config\", map(\"useOptimizations\", map(\"type\", \"none\"),\"format\", \"neo4j-shell\")),\n+                (r) -> {});\n+        verifyUpload(fileName, EXPECTED_CYPHER_POINT);\n+    }\n+\n+    @Test\n+    public void testExportCypherNodeDate() throws IOException {\n+        db.execute(\"CREATE (f:Test {name:'foo', \" +\n+                \"date:date('2018-10-30'), \" +\n+                \"datetime:datetime('2018-10-30T12:50:35.556+0100'), \" +\n+                \"localTime:localdatetime('20181030T19:32:24')})\" +\n+                \"-[:FRIEND_OF {date:date('2018-10-30')}]->\" +\n+                \"(:Bar {datetime:datetime('2018-10-30T12:50:35.556')})\");\n+        String fileName = \"temporalDate.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        String query = \"MATCH (n:Test)-[r]-(m) RETURN n,r,m\";\n+        TestUtil.testCall(db, \"CALL apoc.export.cypher.query($query,$s3,$config)\",\n+                map(\"s3\", s3Url, \"query\", query, \"config\", map(\"useOptimizations\", map(\"type\", \"none\"),\"format\", \"neo4j-shell\")),\n+                (r) -> {});\n+        verifyUpload(fileName, EXPECTED_CYPHER_DATE);\n+    }\n+\n+    @Test\n+    public void testExportCypherNodeTime() throws IOException {\n+        db.execute(\"CREATE (f:Test {name:'foo', \" +\n+                \"local:localtime('12:50:35.556'),\" +\n+                \"t:time('125035.556+0100')})\" +\n+                \"-[:FRIEND_OF {t:time('125035.556+0100')}]->\" +\n+                \"(:Bar {datetime:datetime('2018-10-30T12:50:35.556+0100')})\");\n+        String fileName = \"temporalTime.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        String query = \"MATCH (n:Test)-[r]-(m) RETURN n,r,m\";\n+        TestUtil.testCall(db, \"CALL apoc.export.cypher.query($query,$s3,$config)\",\n+                map(\"s3\", s3Url, \"query\", query, \"config\", map(\"useOptimizations\", map(\"type\", \"none\"),\"format\", \"neo4j-shell\")),\n+                (r) -> {});\n+        verifyUpload(fileName, EXPECTED_CYPHER_TIME);\n+    }\n+\n+    @Test\n+    public void testExportCypherNodeDuration() throws IOException {\n+        db.execute(\"CREATE (f:Test {name:'foo', \" +\n+                \"duration:duration('P5M1.5D')})\" +\n+                \"-[:FRIEND_OF {duration:duration('P5M1.5D')}]->\" +\n+                \"(:Bar {duration:duration('P5M1.5D')})\");\n+        String fileName = \"temporalDuration.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        String query = \"MATCH (n:Test)-[r]-(m) RETURN n,r,m\";\n+        TestUtil.testCall(db, \"CALL apoc.export.cypher.query($query,$s3,$config)\",\n+                map(\"s3\", s3Url, \"query\", query, \"config\", map(\"useOptimizations\", map(\"type\", \"none\"),\"format\", \"neo4j-shell\")),\n+                (r) -> {});\n+        verifyUpload(fileName, EXPECTED_CYPHER_DURATION);\n+    }\n+\n+    @Test\n+    public void testExportWithAscendingLabels() throws IOException {\n+        db.execute(\"CREATE (f:User:User1:User0:User12 {name:'Alan'})\");\n+        String fileName = \"ascendingLabels.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        String query = \"MATCH (f:User) WHERE f.name='Alan' RETURN f\";\n+        TestUtil.testCall(db, \"CALL apoc.export.cypher.query($query,$s3,$config)\",\n+                map(\"s3\", s3Url, \"query\", query, \"config\", map(\"useOptimizations\", map(\"type\", \"none\"),\"format\", \"neo4j-shell\")),\n+                (r) -> {});\n+        verifyUpload(fileName, EXPECTED_CYPHER_LABELS_ASCENDEND);\n+    }\n+\n+    @Test\n+    public void testExportAllCypherDefaultWithUnwindBatchSizeOptimized() throws Exception {\n+        String fileName = \"allDefaultOptimized.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        TestUtil.testCall(db, \"CALL apoc.export.cypher.all($s3,{useOptimizations: { type: 'unwind_batch', unwindBatchSize: 2}, format: 'neo4j-shell'})\", map(\"s3\", s3Url),\n+                (r) -> assertResultsOptimized(s3Url, r));\n+        verifyUpload(fileName, EXPECTED_NEO4J_OPTIMIZED_BATCH_SIZE);\n+    }\n+\n+    @Test\n+    public void testExportAllCypherDefaultOptimized() throws Exception {\n+        String fileName = \"allDefaultOptimized.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        TestUtil.testCall(db, \"CALL apoc.export.cypher.all($s3, $exportConfig)\", map(\"s3\", s3Url, \"exportConfig\", map(\"format\", \"neo4j-shell\")),\n+                (r) -> assertResultsOptimized(s3Url, r));\n+        verifyUpload(fileName, EXPECTED_NEO4J_OPTIMIZED);\n+    }\n+\n+    @Test\n+    public void testExportAllCypherDefaultSeparatedFilesOptimized() throws Exception {\n+        String fileName = \"allDefaultOptimized.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        TestUtil.testCall(db, \"CALL apoc.export.cypher.all($s3, $exportConfig)\",\n+                map(\"s3\", s3Url, \"exportConfig\", map(\"separateFiles\", true, \"format\", \"neo4j-shell\")),\n+                (r) -> assertResultsOptimized(s3Url, r));\n+        verifyUpload(\"allDefaultOptimized.nodes.cypher\", EXPECTED_NODES_OPTIMIZED);\n+        verifyUpload(\"allDefaultOptimized.relationships.cypher\", EXPECTED_RELATIONSHIPS_OPTIMIZED);\n+        verifyUpload(\"allDefaultOptimized.schema.cypher\", EXPECTED_SCHEMA_OPTIMIZED);\n+        verifyUpload(\"allDefaultOptimized.cleanup.cypher\", EXPECTED_CLEAN_UP);\n+    }\n+\n+    @Test\n+    public void testExportAllCypherCypherShellWithUnwindBatchSizeOptimized() throws Exception {\n+        String fileName = \"allCypherShellOptimized.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        TestUtil.testCall(db, \"CALL apoc.export.cypher.all($s3,{format:'cypher-shell', useOptimizations: {type: 'unwind_batch'}})\",\n+                map(\"s3\", s3Url),\n+                (r) -> assertResultsOptimized(s3Url, r));\n+        verifyUpload(fileName, EXPECTED_CYPHER_SHELL_OPTIMIZED_BATCH_SIZE);\n+    }\n+\n+    @Test\n+    public void testExportAllCypherCypherShellOptimized() throws Exception {\n+        String fileName = \"allCypherShellOptimized.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        TestUtil.testCall(db, \"CALL apoc.export.cypher.all($s3,{format:'cypher-shell'})\",\n+                map(\"s3\", s3Url),\n+                (r) -> assertResultsOptimized(s3Url, r));\n+        verifyUpload(fileName, EXPECTED_CYPHER_SHELL_OPTIMIZED);\n+    }\n+\n+    @Test\n+    public void testExportAllCypherPlainWithUnwindBatchSizeOptimized() throws Exception {\n+        String fileName = \"allPlainOptimized.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        TestUtil.testCall(db, \"CALL apoc.export.cypher.all($s3,{format:'plain', useOptimizations: { type: 'unwind_batch', unwindBatchSize: 2}})\",\n+                map(\"s3\", s3Url),\n+                (r) -> assertResultsOptimized(s3Url, r));\n+        verifyUpload(fileName, EXPECTED_PLAIN_OPTIMIZED_BATCH_SIZE);\n+    }\n+\n+    @Test\n+    public void testExportAllCypherPlainAddStructureWithUnwindBatchSizeOptimized() throws Exception {\n+        String fileName = \"allPlainAddStructureOptimized.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        TestUtil.testCall(db, \"CALL apoc.export.cypher.all($s3,{format:'plain', cypherFormat: 'addStructure', useOptimizations: { type: 'unwind_batch', unwindBatchSize: 2}})\",\n+                map(\"s3\", s3Url), (r) -> assertResultsOptimized(s3Url, r));\n+        verifyUpload(fileName, EXPECTED_PLAIN_ADD_STRUCTURE_UNWIND);\n+    }\n+\n+    @Test\n+    public void testExportAllCypherPlainUpdateStructureWithUnwindBatchSizeOptimized() throws Exception {\n+        String fileName = \"allPlainUpdateStructureOptimized.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        TestUtil.testCall(db, \"CALL apoc.export.cypher.all($s3,{format:'plain', cypherFormat: 'updateStructure', useOptimizations: { type: 'unwind_batch', unwindBatchSize: 2}})\",\n+                map(\"s3\", s3Url), (r) -> {\n+                    assertEquals(0L, r.get(\"nodes\"));\n+                    assertEquals(2L, r.get(\"relationships\"));\n+                    assertEquals(2L, r.get(\"properties\"));\n+                    assertEquals(s3Url, r.get(\"file\"));\n+                    assertEquals(\"cypher\", r.get(\"format\"));\n+                    assertTrue(\"Should get time greater than 0\",((long) r.get(\"time\")) >= 0);\n+                });\n+        verifyUpload(fileName, EXPECTED_PLAIN_UPDATE_STRUCTURE_UNWIND);\n+    }\n+\n+    @Test\n+    public void testExportAllCypherPlainUpdateAllWithUnwindBatchSizeOptimized() throws Exception {\n+        String fileName = \"allPlainUpdateAllOptimized.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        TestUtil.testCall(db, \"CALL apoc.export.cypher.all($s3,{format:'plain', cypherFormat: 'updateAll', useOptimizations: { type: 'unwind_batch', unwindBatchSize: 2}})\",\n+                map(\"s3\", s3Url), (r) -> assertResultsOptimized(s3Url, r));\n+        verifyUpload(fileName, EXPECTED_UPDATE_ALL_UNWIND);\n+    }\n+\n+    @Test\n+    public void testExportQueryCypherShellWithUnwindBatchSizeWithBatchSizeOptimized() throws Exception {\n+        String fileName = \"allPlainOptimized.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        TestUtil.testCall(db, \"CALL apoc.export.cypher.all($s3,{format:'cypher-shell', useOptimizations: { type: 'unwind_batch', unwindBatchSize: 2}, batchSize: 2})\",\n+                map(\"s3\", s3Url),\n+                (r) -> assertResultsOptimized(s3Url, r));\n+        verifyUpload(fileName, EXPECTED_QUERY_CYPHER_SHELL_OPTIMIZED_UNWIND);\n+    }\n+\n+    @Test\n+    public void testExportQueryCypherShellWithUnwindBatchSizeWithBatchSizeOddDataset() throws Exception {\n+        String fileName = \"allPlainOdd.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        TestUtil.testCall(db, \"CALL apoc.export.cypher.all($s3,{format:'cypher-shell', useOptimizations: { type: 'unwind_batch', unwindBatchSize: 2}, batchSize: 2})\",\n+                map(\"s3\", s3Url), (r) -> assertResultsOdd(s3Url, r));\n+        verifyUpload(fileName, EXPECTED_QUERY_CYPHER_SHELL_OPTIMIZED_ODD);\n+    }\n+\n+    @Test\n+    public void testExportQueryCypherShellUnwindBatchParamsWithOddDataset() throws Exception {\n+        String fileName = \"allPlainOdd.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        TestUtil.testCall(db, \"CALL apoc.export.cypher.all($s3,{format:'cypher-shell', useOptimizations: { type: 'unwind_batch_params', unwindBatchSize: 2}, batchSize:2})\",\n+                map(\"s3\", s3Url),\n+                (r) -> assertResultsOdd(s3Url, r));\n+        verifyUpload(fileName, EXPECTED_QUERY_CYPHER_SHELL_PARAMS_OPTIMIZED_ODD);\n+    }\n+\n+    @Test\n+    public void testExportQueryCypherShellUnwindBatchParamsWithOddBatchSizeOddDataset() throws Exception {\n+        db.execute(\"CREATE (:Bar {name:'bar3',age:35}), (:Bar {name:'bar4',age:36})\");\n+        String fileName = \"allPlainOddNew.cypher\";\n+        String s3Url = getS3Url(fileName);\n+        TestUtil.testCall(db, \"CALL apoc.export.cypher.all($s3,{format:'cypher-shell', useOptimizations: { type: 'unwind_batch_params', unwindBatchSize: 2}, batchSize:3})\",\n+                map(\"s3\", s3Url),\n+                (r) -> {});\n+        db.execute(\"MATCH (n:Bar {name:'bar3',age:35}), (n1:Bar {name:'bar4',age:36}) DELETE n, n1\");\n+        String expectedNodes = String.format(\":begin%n\" +\n+                \":param rows => [{_id:4, properties:{age:12}}, {_id:5, properties:{age:4}}]%n\" +\n+                \"UNWIND $rows AS row%n\" +\n+                \"CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Bar;%n\" +\n+                \":param rows => [{_id:0, properties:{born:date('2018-10-31'), name:\\\"foo\\\"}}]%n\" +\n+                \"UNWIND $rows AS row%n\" +\n+                \"CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Foo;%n\" +\n+                \":commit%n\" +\n+                \":begin%n\" +\n+                \":param rows => [{_id:1, properties:{born:date('2017-09-29'), name:\\\"foo2\\\"}}, {_id:2, properties:{born:date('2016-03-12'), name:\\\"foo3\\\"}}]%n\" +\n+                \"UNWIND $rows AS row%n\" +\n+                \"CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Foo;%n\" +\n+                \":param rows => [{name:\\\"bar\\\", properties:{age:42}}]%n\" +\n+                \"UNWIND $rows AS row%n\" +\n+                \"CREATE (n:Bar{name: row.name}) SET n += row.properties;%n\" +\n+                \":commit%n\" +\n+                \":begin%n\" +\n+                \":param rows => [{name:\\\"bar2\\\", properties:{age:44}}, {name:\\\"bar3\\\", properties:{age:35}}]%n\" +\n+                \"UNWIND $rows AS row%n\" +\n+                \"CREATE (n:Bar{name: row.name}) SET n += row.properties;%n\" +\n+                \":param rows => [{name:\\\"bar4\\\", properties:{age:36}}]%n\" +\n+                \"UNWIND $rows AS row%n\" +\n+                \"CREATE (n:Bar{name: row.name}) SET n += row.properties;%n\" +\n+                \":commit%n\");\n+        int expectedDropNum = 3;\n+        String expectedDrop = String.format(\":begin%n\" +\n+                \"MATCH (n:`UNIQUE IMPORT LABEL`)  WITH n LIMIT %d REMOVE n:`UNIQUE IMPORT LABEL` REMOVE n.`UNIQUE IMPORT ID`;%n\" +\n+                \":commit%n\" +\n+                \":begin%n\" +\n+                \"MATCH (n:`UNIQUE IMPORT LABEL`)  WITH n LIMIT %d REMOVE n:`UNIQUE IMPORT LABEL` REMOVE n.`UNIQUE IMPORT ID`;%n\" +\n+                \":commit%n\" +\n+                \":begin%n\" +\n+                \"DROP CONSTRAINT ON (node:`UNIQUE IMPORT LABEL`) ASSERT (node.`UNIQUE IMPORT ID`) IS UNIQUE;%n\" +\n+                \":commit%n\", expectedDropNum, expectedDropNum);\n+        String expected = (EXPECTED_SCHEMA_OPTIMIZED + expectedNodes + EXPECTED_RELATIONSHIPS_PARAMS_ODD + expectedDrop)\n+                .replace(NEO4J_SHELL.begin(), CYPHER_SHELL.begin())\n+                .replace(NEO4J_SHELL.commit(), CYPHER_SHELL.commit())\n+                .replace(NEO4J_SHELL.schemaAwait(), EXPECTED_INDEXES_AWAIT)\n+                .replace(NEO4J_SHELL.schemaAwait(), CYPHER_SHELL.schemaAwait());\n+        verifyUpload(fileName, expected);\n+    }\n+\n+    private void assertResultsOptimized(String fileName, Map<String, Object> r) {\n+        assertEquals(7L, r.get(\"nodes\"));\n+        assertEquals(2L, r.get(\"relationships\"));\n+        assertEquals(13L, r.get(\"properties\"));\n+        assertEquals(fileName, r.get(\"file\"));\n+        assertEquals(\"database\" + \": nodes(7), rels(2)\", r.get(\"source\"));\n+        assertEquals(\"cypher\", r.get(\"format\"));\n+        assertTrue(\"Should get time greater than 0\",((long) r.get(\"time\")) >= 0);\n+    }\n+\n+    private void assertResultsOdd(String fileName, Map<String, Object> r) {\n+        assertEquals(7L, r.get(\"nodes\"));\n+        assertEquals(1L, r.get(\"relationships\"));\n+        assertEquals(13L, r.get(\"properties\"));\n+        assertEquals(fileName, r.get(\"file\"));\n+        assertEquals(\"database\" + \": nodes(7), rels(1)\", r.get(\"source\"));\n+        assertEquals(\"cypher\", r.get(\"format\"));\n+        assertTrue(\"Should get time greater than 0\",((long) r.get(\"time\")) >= 0);\n+    }\n+\n+    static class ExportCypherResults {\n+\n+        static final String EXPECTED_NODES = String.format(\"BEGIN%n\" +\n+                \"CREATE (:Foo:`UNIQUE IMPORT LABEL` {born:date('2018-10-31'), name:\\\"foo\\\", `UNIQUE IMPORT ID`:0});%n\" +\n+                \"CREATE (:Bar {age:42, name:\\\"bar\\\"});%n\" +\n+                \"CREATE (:Bar:`UNIQUE IMPORT LABEL` {age:12, `UNIQUE IMPORT ID`:2});%n\" +\n+                \"COMMIT%n\");\n+\n+        private static final String EXPECTED_NODES_MERGE = String.format(\"BEGIN%n\" +\n+                \"MERGE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`:0}) SET n.name=\\\"foo\\\", n.born=date('2018-10-31'), n:Foo;%n\" +\n+                \"MERGE (n:Bar{name:\\\"bar\\\"}) SET n.age=42;%n\" +\n+                \"MERGE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`:2}) SET n.age=12, n:Bar;%n\" +\n+                \"COMMIT%n\");\n+\n+        static final String EXPECTED_NODES_MERGE_ON_CREATE_SET =\n+                EXPECTED_NODES_MERGE.replaceAll(\" SET \", \" ON CREATE SET \");\n+\n+        static final String EXPECTED_NODES_EMPTY = String.format(\"BEGIN%n\" +\n+                \"COMMIT%n\");\n+\n+        static final String EXPECTED_SCHEMA = String.format(\"BEGIN%n\" +\n+                \"CREATE INDEX ON :Bar(first_name,last_name);%n\" +\n+                \"CREATE INDEX ON :Foo(name);%n\" +\n+                \"CREATE CONSTRAINT ON (node:Bar) ASSERT (node.name) IS UNIQUE;%n\" +\n+                \"CREATE CONSTRAINT ON (node:`UNIQUE IMPORT LABEL`) ASSERT (node.`UNIQUE IMPORT ID`) IS UNIQUE;%n\" +\n+                \"COMMIT%n\" +\n+                \"SCHEMA AWAIT%n\");\n+\n+        static final String EXPECTED_SCHEMA_EMPTY = String.format(\"BEGIN%n\" +\n+                \"COMMIT%n\" +\n+                \"SCHEMA AWAIT%n\");\n+\n+        public static final String EXPECTED_INDEXES_AWAIT = String.format(\"CALL db.awaitIndexes(300);%n\");\n+\n+        private static final String EXPECTED_INDEXES_AWAIT_QUERY = String.format(\"CALL db.awaitIndex(300);%n\");\n+\n+        static final String EXPECTED_RELATIONSHIPS = String.format(\"BEGIN%n\" +\n+                \"MATCH (n1:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`:0}), (n2:Bar{name:\\\"bar\\\"}) CREATE (n1)-[r:KNOWS {since:2016}]->(n2);%n\" +\n+                \"COMMIT%n\");\n+\n+        private static final String EXPECTED_RELATIONSHIPS_MERGE = String.format(\"BEGIN%n\" +\n+                \"MATCH (n1:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`:0}), (n2:Bar{name:\\\"bar\\\"}) MERGE (n1)-[r:KNOWS]->(n2) SET r.since=2016;%n\" +\n+                \"COMMIT%n\");\n+\n+        static final String EXPECTED_RELATIONSHIPS_MERGE_ON_CREATE_SET =\n+                EXPECTED_RELATIONSHIPS_MERGE.replaceAll(\" SET \", \" ON CREATE SET \");\n+\n+        static final String EXPECTED_CLEAN_UP = String.format(\"BEGIN%n\" +\n+                \"MATCH (n:`UNIQUE IMPORT LABEL`)  WITH n LIMIT 20000 REMOVE n:`UNIQUE IMPORT LABEL` REMOVE n.`UNIQUE IMPORT ID`;%n\" +\n+                \"COMMIT%n\" +\n+                \"BEGIN%n\" +\n+                \"DROP CONSTRAINT ON (node:`UNIQUE IMPORT LABEL`) ASSERT (node.`UNIQUE IMPORT ID`) IS UNIQUE;%n\" +\n+                \"COMMIT%n\");\n+\n+        static final String EXPECTED_CLEAN_UP_EMPTY = String.format(\"BEGIN%n\" +\n+                \"COMMIT%n\" +\n+                \"BEGIN%n\" +\n+                \"COMMIT%n\");\n+\n+        static final String EXPECTED_ONLY_SCHEMA_NEO4J_SHELL = String.format(\"BEGIN%n\" +\n+                \"CREATE INDEX ON :Bar(first_name,last_name);%n\" +\n+                \"CREATE INDEX ON :Foo(name);%n\" +\n+                \"CREATE CONSTRAINT ON (node:Bar) ASSERT (node.name) IS UNIQUE;%n\" +\n+                \"COMMIT%n\" +\n+                \"SCHEMA AWAIT%n\");\n+\n+        static final String EXPECTED_CYPHER_POINT = String.format(\"BEGIN%n\" +\n+                \"CREATE (:Test:`UNIQUE IMPORT LABEL` {name:\\\"foo\\\", place2d:point({x: 2.3, y: 4.5, crs: 'cartesian'}), place3d1:point({x: 2.3, y: 4.5, z: 1.2, crs: 'cartesian-3d'}), `UNIQUE IMPORT ID`:3});%n\" +\n+                \"CREATE (:Bar:`UNIQUE IMPORT LABEL` {place3d:point({x: 12.78, y: 56.7, z: 100.0, crs: 'wgs-84-3d'}), `UNIQUE IMPORT ID`:4});%n\" +\n+                \"COMMIT%n\" +\n+                \"BEGIN%n\" +\n+                \"CREATE INDEX ON :Bar(first_name,last_name);%n\" +\n+                \"CREATE CONSTRAINT ON (node:Bar) ASSERT (node.name) IS UNIQUE;%n\" +\n+                \"CREATE CONSTRAINT ON (node:`UNIQUE IMPORT LABEL`) ASSERT (node.`UNIQUE IMPORT ID`) IS UNIQUE;%n\" +\n+                \"COMMIT%n\" +\n+                \"SCHEMA AWAIT%n\" +\n+                \"BEGIN%n\" +\n+                \"MATCH (n1:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`:3}), (n2:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`:4}) CREATE (n1)-[r:FRIEND_OF {place2d:point({x: 56.7, y: 12.78, crs: 'wgs-84'})}]->(n2);%n\" +\n+                \"COMMIT%n\" +\n+                \"BEGIN%n\" +\n+                \"MATCH (n:`UNIQUE IMPORT LABEL`)  WITH n LIMIT 20000 REMOVE n:`UNIQUE IMPORT LABEL` REMOVE n.`UNIQUE IMPORT ID`;%n\" +\n+                \"COMMIT%n\" +\n+                \"BEGIN%n\" +\n+                \"DROP CONSTRAINT ON (node:`UNIQUE IMPORT LABEL`) ASSERT (node.`UNIQUE IMPORT ID`) IS UNIQUE;%n\" +\n+                \"COMMIT%n\");\n+\n+        static final String EXPECTED_CYPHER_DATE = String.format(\"BEGIN%n\" +\n+                \"CREATE (:Test:`UNIQUE IMPORT LABEL` {date:date('2018-10-30'), datetime:datetime('2018-10-30T12:50:35.556+01:00'), localTime:localdatetime('2018-10-30T19:32:24'), name:\\\"foo\\\", `UNIQUE IMPORT ID`:3});%n\" +\n+                \"CREATE (:Bar:`UNIQUE IMPORT LABEL` {datetime:datetime('2018-10-30T12:50:35.556Z'), `UNIQUE IMPORT ID`:4});%n\" +\n+                \"COMMIT%n\" +\n+                \"BEGIN%n\" +\n+                \"CREATE INDEX ON :Bar(first_name,last_name);%n\" +\n+                \"CREATE CONSTRAINT ON (node:Bar) ASSERT (node.name) IS UNIQUE;%n\" +\n+                \"CREATE CONSTRAINT ON (node:`UNIQUE IMPORT LABEL`) ASSERT (node.`UNIQUE IMPORT ID`) IS UNIQUE;%n\" +\n+                \"COMMIT%n\" +\n+                \"SCHEMA AWAIT%n\" +\n+                \"BEGIN%n\" +\n+                \"MATCH (n1:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`:3}), (n2:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`:4}) CREATE (n1)-[r:FRIEND_OF {date:date('2018-10-30')}]->(n2);%n\" +\n+                \"COMMIT%n\" +\n+                \"BEGIN%n\" +\n+                \"MATCH (n:`UNIQUE IMPORT LABEL`)  WITH n LIMIT 20000 REMOVE n:`UNIQUE IMPORT LABEL` REMOVE n.`UNIQUE IMPORT ID`;%n\" +\n+                \"COMMIT%n\" +\n+                \"BEGIN%n\" +\n+                \"DROP CONSTRAINT ON (node:`UNIQUE IMPORT LABEL`) ASSERT (node.`UNIQUE IMPORT ID`) IS UNIQUE;%n\" +\n+                \"COMMIT%n\");\n+\n+        static final String EXPECTED_CYPHER_TIME = String.format(\"BEGIN%n\" +\n+                \"CREATE (:Test:`UNIQUE IMPORT LABEL` {local:localtime('12:50:35.556'), name:\\\"foo\\\", t:time('12:50:35.556+01:00'), `UNIQUE IMPORT ID`:3});%n\" +\n+                \"CREATE (:Bar:`UNIQUE IMPORT LABEL` {datetime:datetime('2018-10-30T12:50:35.556+01:00'), `UNIQUE IMPORT ID`:4});%n\" +\n+                \"COMMIT%n\" +\n+                \"BEGIN%n\" +\n+                \"CREATE INDEX ON :Bar(first_name,last_name);%n\" +\n+                \"CREATE CONSTRAINT ON (node:Bar) ASSERT (node.name) IS UNIQUE;%n\" +\n+                \"CREATE CONSTRAINT ON (node:`UNIQUE IMPORT LABEL`) ASSERT (node.`UNIQUE IMPORT ID`) IS UNIQUE;%n\" +\n+                \"COMMIT%n\" +\n+                \"SCHEMA AWAIT%n\" +\n+                \"BEGIN%n\" +\n+                \"MATCH (n1:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`:3}), (n2:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`:4}) CREATE (n1)-[r:FRIEND_OF {t:time('12:50:35.556+01:00')}]->(n2);%n\" +\n+                \"COMMIT%n\" +\n+                \"BEGIN%n\" +\n+                \"MATCH (n:`UNIQUE IMPORT LABEL`)  WITH n LIMIT 20000 REMOVE n:`UNIQUE IMPORT LABEL` REMOVE n.`UNIQUE IMPORT ID`;%n\" +\n+                \"COMMIT%n\" +\n+                \"BEGIN%n\" +\n+                \"DROP CONSTRAINT ON (node:`UNIQUE IMPORT LABEL`) ASSERT (node.`UNIQUE IMPORT ID`) IS UNIQUE;%n\" +\n+                \"COMMIT%n\");\n+\n+        static final String EXPECTED_CYPHER_DURATION = String.format(\"BEGIN%n\" +\n+                \"CREATE (:Test:`UNIQUE IMPORT LABEL` {duration:duration('P5M1DT12H'), name:\\\"foo\\\", `UNIQUE IMPORT ID`:3});%n\" +\n+                \"CREATE (:Bar:`UNIQUE IMPORT LABEL` {duration:duration('P5M1DT12H'), `UNIQUE IMPORT ID`:4});%n\" +\n+                \"COMMIT%n\" +\n+                \"BEGIN%n\" +\n+                \"CREATE INDEX ON :Bar(first_name,last_name);%n\" +\n+                \"CREATE CONSTRAINT ON (node:Bar) ASSERT (node.name) IS UNIQUE;%n\" +\n+                \"CREATE CONSTRAINT ON (node:`UNIQUE IMPORT LABEL`) ASSERT (node.`UNIQUE IMPORT ID`) IS UNIQUE;%n\" +\n+                \"COMMIT%n\" +\n+                \"SCHEMA AWAIT%n\" +\n+                \"BEGIN%n\" +\n+                \"MATCH (n1:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`:3}), (n2:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`:4}) CREATE (n1)-[r:FRIEND_OF {duration:duration('P5M1DT12H')}]->(n2);%n\" +\n+                \"COMMIT%n\" +\n+                \"BEGIN%n\" +\n+                \"MATCH (n:`UNIQUE IMPORT LABEL`)  WITH n LIMIT 20000 REMOVE n:`UNIQUE IMPORT LABEL` REMOVE n.`UNIQUE IMPORT ID`;%n\" +\n+                \"COMMIT%n\" +\n+                \"BEGIN%n\" +\n+                \"DROP CONSTRAINT ON (node:`UNIQUE IMPORT LABEL`) ASSERT (node.`UNIQUE IMPORT ID`) IS UNIQUE;%n\" +\n+                \"COMMIT%n\");\n+\n+        static final String EXPECTED_CYPHER_LABELS_ASCENDEND = String.format(\"BEGIN%n\" +\n+                \"CREATE (:User:User0:User1:User12:`UNIQUE IMPORT LABEL` {name:\\\"Alan\\\", `UNIQUE IMPORT ID`:3});%n\" +\n+                \"COMMIT%n\" +\n+                \"BEGIN%n\" +\n+                \"CREATE CONSTRAINT ON (node:`UNIQUE IMPORT LABEL`) ASSERT (node.`UNIQUE IMPORT ID`) IS UNIQUE;%n\" +\n+                \"COMMIT%n\" +\n+                \"SCHEMA AWAIT%n\" +\n+                \"BEGIN%n\" +\n+                \"MATCH (n:`UNIQUE IMPORT LABEL`)  WITH n LIMIT 20000 REMOVE n:`UNIQUE IMPORT LABEL` REMOVE n.`UNIQUE IMPORT ID`;%n\" +\n+                \"COMMIT%n\" +\n+                \"BEGIN%n\" +\n+                \"DROP CONSTRAINT ON (node:`UNIQUE IMPORT LABEL`) ASSERT (node.`UNIQUE IMPORT ID`) IS UNIQUE;%n\" +\n+                \"COMMIT%n\");\n+\n+        static final String EXPECTED_SCHEMA_OPTIMIZED = String.format(\"BEGIN%n\" +\n+                \"CREATE INDEX ON :Bar(first_name,last_name);%n\" +\n+                \"CREATE INDEX ON :Foo(name);%n\" +\n+                \"CREATE CONSTRAINT ON (node:Bar) ASSERT (node.name) IS UNIQUE;%n\" +\n+                \"CREATE CONSTRAINT ON (node:`UNIQUE IMPORT LABEL`) ASSERT (node.`UNIQUE IMPORT ID`) IS UNIQUE;%n\" +\n+                \"COMMIT%n\" +\n+                \"SCHEMA AWAIT%n\");\n+\n+        static final String EXPECTED_NODES_OPTIMIZED_BATCH_SIZE = String.format(\"BEGIN%n\" +\n+                \"UNWIND [{_id:3, properties:{age:12}}] AS row%n\" +\n+                \"CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Bar;%n\" +\n+                \"UNWIND [{_id:2, properties:{age:12}}] AS row%n\" +\n+                \"CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Bar:Person;%n\" +\n+                \"UNWIND [{_id:0, properties:{born:date('2018-10-31'), name:\\\"foo\\\"}}, {_id:4, properties:{born:date('2017-09-29'), name:\\\"foo2\\\"}}] AS row%n\" +\n+                \"CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Foo;%n\" +\n+                \"UNWIND [{name:\\\"bar\\\", properties:{age:42}}, {name:\\\"bar2\\\", properties:{age:44}}] AS row%n\" +\n+                \"CREATE (n:Bar{name: row.name}) SET n += row.properties;%n\" +\n+                \"UNWIND [{_id:6, properties:{age:99}}] AS row%n\" +\n+                \"CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties;%n\" +\n+                \"COMMIT%n\");\n+\n+        static final String EXPECTED_NODES_OPTIMIZED = String.format(\"BEGIN%n\" +\n+                \"UNWIND [{_id:3, properties:{age:12}}] AS row%n\" +\n+                \"CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Bar;%n\" +\n+                \"UNWIND [{_id:2, properties:{age:12}}] AS row%n\" +\n+                \"CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Bar:Person;%n\" +\n+                \"UNWIND [{_id:0, properties:{born:date('2018-10-31'), name:\\\"foo\\\"}}, {_id:4, properties:{born:date('2017-09-29'), name:\\\"foo2\\\"}}] AS row%n\" +\n+                \"CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Foo;%n\" +\n+                \"UNWIND [{name:\\\"bar\\\", properties:{age:42}}, {name:\\\"bar2\\\", properties:{age:44}}] AS row%n\" +\n+                \"CREATE (n:Bar{name: row.name}) SET n += row.properties;%n\" +\n+                \"UNWIND [{_id:6, properties:{age:99}}] AS row%n\" +\n+                \"CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties;%n\" +\n+                \"COMMIT%n\");\n+\n+        static final String EXPECTED_QUERY_NODES_OPTIMIZED = String.format(\"BEGIN%n\" +\n+                \"UNWIND [{_id:0, properties:{born:date('2018-10-31'), name:\\\"foo\\\"}}, {_id:4, properties:{born:date('2017-09-29'), name:\\\"foo2\\\"}}] AS row%n\" +\n+                \"CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Foo;%n\" +\n+                \"UNWIND [{name:\\\"bar\\\", properties:{age:42}}, {name:\\\"bar2\\\", properties:{age:44}}] AS row%n\" +\n+                \"CREATE (n:Bar{name: row.name}) SET n += row.properties;%n\" +\n+                \"COMMIT%n\");\n+\n+        static final String EXPECTED_QUERY_NODES_OPTIMIZED2 = String.format(\"BEGIN%n\" +\n+                \"UNWIND [{_id:4, properties:{born:date('2017-09-29'), name:\\\"foo2\\\"}}, {_id:0, properties:{born:date('2018-10-31'), name:\\\"foo\\\"}}] AS row%n\" +\n+                \"CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Foo;%n\" +\n+                \"UNWIND [{name:\\\"bar\\\", properties:{age:42}}, {name:\\\"bar2\\\", properties:{age:44}}] AS row%n\" +\n+                \"CREATE (n:Bar{name: row.name}) SET n += row.properties;%n\" +\n+                \"COMMIT%n\");\n+\n+        static final String EXPECTED_RELATIONSHIPS_OPTIMIZED = String.format(\"BEGIN%n\" +\n+                \"UNWIND [{start: {_id:0}, end: {name:\\\"bar\\\"}, properties:{since:2016}}, {start: {_id:4}, end: {name:\\\"bar2\\\"}, properties:{since:2015}}] AS row%n\" +\n+                \"MATCH (start:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.start._id})%n\" +\n+                \"MATCH (end:Bar{name: row.end.name})%n\" +\n+                \"CREATE (start)-[r:KNOWS]->(end) SET r += row.properties;%n\" +\n+                \"COMMIT%n\");\n+\n+        static final String EXPECTED_RELATIONSHIPS_ODD = String.format(\"BEGIN%n\" +\n+                \"UNWIND [{start: {_id:0}, end: {name:\\\"bar\\\"}, properties:{since:2016}}] AS row%n\" +\n+                \"MATCH (start:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.start._id})%n\" +\n+                \"MATCH (end:Bar{name: row.end.name})%n\" +\n+                \"CREATE (start)-[r:KNOWS]->(end) SET r += row.properties;%n\" +\n+                \"COMMIT%n\");\n+\n+        static final String EXPECTED_RELATIONSHIPS_PARAMS_ODD = String.format(\n+                \"BEGIN%n\" +\n+                        \":param rows => [{start: {_id:0}, end: {name:\\\"bar\\\"}, properties:{since:2016}}]%n\" +\n+                        \"UNWIND $rows AS row%n\" +\n+                        \"MATCH (start:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.start._id})%n\" +\n+                        \"MATCH (end:Bar{name: row.end.name})%n\" +\n+                        \"CREATE (start)-[r:KNOWS]->(end) SET r += row.properties;%n\" +\n+                        \"COMMIT%n\");\n+\n+        static final String DROP_UNIQUE_OPTIMIZED = String.format(\"BEGIN%n\" +\n+                \"MATCH (n:`UNIQUE IMPORT LABEL`)  WITH n LIMIT 20000 REMOVE n:`UNIQUE IMPORT LABEL` REMOVE n.`UNIQUE IMPORT ID`;%n\" +\n+                \"COMMIT%n\" +\n+                \"BEGIN%n\" +\n+                \"DROP CONSTRAINT ON (node:`UNIQUE IMPORT LABEL`) ASSERT (node.`UNIQUE IMPORT ID`) IS UNIQUE;%n\" +\n+                \"COMMIT%n\");\n+\n+        static final String DROP_UNIQUE_OPTIMIZED_BATCH = String.format(\"BEGIN%n\" +\n+                \"MATCH (n:`UNIQUE IMPORT LABEL`)  WITH n LIMIT 2 REMOVE n:`UNIQUE IMPORT LABEL` REMOVE n.`UNIQUE IMPORT ID`;%n\" +\n+                \"COMMIT%n\" +\n+                \"BEGIN%n\" +\n+                \"MATCH (n:`UNIQUE IMPORT LABEL`)  WITH n LIMIT 2 REMOVE n:`UNIQUE IMPORT LABEL` REMOVE n.`UNIQUE IMPORT ID`;%n\" +\n+                \"COMMIT%n\" +\n+                \"BEGIN%n\" +\n+                \"MATCH (n:`UNIQUE IMPORT LABEL`)  WITH n LIMIT 2 REMOVE n:`UNIQUE IMPORT LABEL` REMOVE n.`UNIQUE IMPORT ID`;%n\" +\n+                \"COMMIT%n\" +\n+                \"BEGIN%n\" +\n+                \"DROP CONSTRAINT ON (node:`UNIQUE IMPORT LABEL`) ASSERT (node.`UNIQUE IMPORT ID`) IS UNIQUE;%n\" +\n+                \"COMMIT%n\");\n+\n+        static final String EXPECTED_NODES_OPTIMIZED_BATCH_SIZE_UNWIND = String.format(\"BEGIN%n\" +\n+                \"UNWIND [{_id:3, properties:{age:12}}] AS row%n\" +\n+                \"CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Bar;%n\" +\n+                \"UNWIND [{_id:2, properties:{age:12}}] AS row%n\" +\n+                \"CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Bar:Person;%n\" +\n+                \"COMMIT%n\" +\n+                \"BEGIN%n\" +\n+                \"UNWIND [{_id:0, properties:{born:date('2018-10-31'), name:\\\"foo\\\"}}, {_id:4, properties:{born:date('2017-09-29'), name:\\\"foo2\\\"}}] AS row%n\" +\n+                \"CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Foo;%n\" +\n+                \"COMMIT%n\" +\n+                \"BEGIN%n\" +\n+                \"UNWIND [{name:\\\"bar\\\", properties:{age:42}}, {name:\\\"bar2\\\", properties:{age:44}}] AS row%n\" +\n+                \"CREATE (n:Bar{name: row.name}) SET n += row.properties;%n\" +\n+                \"COMMIT%n\" +\n+                \"BEGIN%n\" +\n+                \"UNWIND [{_id:6, properties:{age:99}}] AS row%n\" +\n+                \"CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties;%n\" +\n+                \"COMMIT%n\");\n+\n+        static final String EXPECTED_NODES_OPTIMIZED_BATCH_SIZE_ODD = String.format(\"BEGIN%n\" +\n+                \"UNWIND [{_id:4, properties:{age:12}}, {_id:5, properties:{age:4}}] AS row%n\" +\n+                \"CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Bar;%n\" +\n+                \"COMMIT%n\" +\n+                \"BEGIN%n\" +\n+                \"UNWIND [{_id:0, properties:{born:date('2018-10-31'), name:\\\"foo\\\"}}, {_id:1, properties:{born:date('2017-09-29'), name:\\\"foo2\\\"}}] AS row%n\" +\n+                \"CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Foo;%n\" +\n+                \"COMMIT%n\" +\n+                \"BEGIN%n\" +\n+                \"UNWIND [{_id:2, properties:{born:date('2016-03-12'), name:\\\"foo3\\\"}}] AS row%n\" +\n+                \"CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Foo;%n\" +\n+                \"UNWIND [{name:\\\"bar\\\", properties:{age:42}}] AS row%n\" +\n+                \"CREATE (n:Bar{name: row.name}) SET n += row.properties;%n\" +\n+                \"COMMIT%n\" +\n+                \"BEGIN%n\" +\n+                \"UNWIND [{name:\\\"bar2\\\", properties:{age:44}}] AS row%n\" +\n+                \"CREATE (n:Bar{name: row.name}) SET n += row.properties;%n\" +\n+                \"COMMIT%n\");\n+\n+        static final String EXPECTED_NODES_OPTIMIZED_PARAMS_BATCH_SIZE_ODD = String.format(\n+                \":begin%n\" +\n+                        \":param rows => [{_id:4, properties:{age:12}}, {_id:5, properties:{age:4}}]%n\" +\n+                        \"UNWIND $rows AS row%n\" +\n+                        \"CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Bar;%n\" +\n+                        \":commit%n\" +\n+                        \":begin%n\" +\n+                        \":param rows => [{_id:0, properties:{born:date('2018-10-31'), name:\\\"foo\\\"}}, {_id:1, properties:{born:date('2017-09-29'), name:\\\"foo2\\\"}}]%n\" +\n+                        \"UNWIND $rows AS row%n\" +\n+                        \"CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Foo;%n\" +\n+                        \":commit%n\" +\n+                        \":begin%n\" +\n+                        \":param rows => [{_id:2, properties:{born:date('2016-03-12'), name:\\\"foo3\\\"}}]%n\" +\n+                        \"UNWIND $rows AS row%n\" +\n+                        \"CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Foo;%n\" +\n+                        \":param rows => [{name:\\\"bar\\\", properties:{age:42}}]%n\" +\n+                        \"UNWIND $rows AS row%n\" +\n+                        \"CREATE (n:Bar{name: row.name}) SET n += row.properties;%n\" +\n+                        \":commit%n\" +\n+                        \":begin%n\" +\n+                        \":param rows => [{name:\\\"bar2\\\", properties:{age:44}}]%n\" +\n+                        \"UNWIND $rows AS row%n\" +\n+                        \"CREATE (n:Bar{name: row.name}) SET n += row.properties;%n\" +\n+                        \":commit%n\");\n+\n+        static final String EXPECTED_PLAIN_ADD_STRUCTURE_UNWIND = String.format(\"UNWIND [{_id:3, properties:{age:12}}] AS row%n\" +\n+                \"MERGE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) ON CREATE SET n += row.properties SET n:Bar;%n\" +\n+                \"UNWIND [{_id:2, properties:{age:12}}] AS row%n\" +\n+                \"MERGE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) ON CREATE SET n += row.properties SET n:Bar:Person;%n\" +\n+                \"UNWIND [{_id:0, properties:{born:date('2018-10-31'), name:\\\"foo\\\"}}, {_id:4, properties:{born:date('2017-09-29'), name:\\\"foo2\\\"}}] AS row%n\" +\n+                \"MERGE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) ON CREATE SET n += row.properties SET n:Foo;%n\" +\n+                \"UNWIND [{name:\\\"bar\\\", properties:{age:42}}, {name:\\\"bar2\\\", properties:{age:44}}] AS row%n\" +\n+                \"MERGE (n:Bar{name: row.name}) ON CREATE SET n += row.properties;%n\" +\n+                \"UNWIND [{_id:6, properties:{age:99}}] AS row%n\" +\n+                \"MERGE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) ON CREATE SET n += row.properties;%n\" +\n+                \"UNWIND [{start: {_id:0}, end: {name:\\\"bar\\\"}, properties:{since:2016}}, {start: {_id:4}, end: {name:\\\"bar2\\\"}, properties:{since:2015}}] AS row%n\" +\n+                \"MATCH (start:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.start._id})%n\" +\n+                \"MATCH (end:Bar{name: row.end.name})%n\" +\n+                \"CREATE (start)-[r:KNOWS]->(end)  SET r += row.properties;%n\");\n+\n+        static final String EXPECTED_UPDATE_ALL_UNWIND = String.format(\"CREATE INDEX ON :Bar(first_name,last_name);%n\" +\n+                \"CREATE INDEX ON :Foo(name);%n\" +\n+                \"CREATE CONSTRAINT ON (node:Bar) ASSERT (node.name) IS UNIQUE;%n\" +\n+                \"CREATE CONSTRAINT ON (node:`UNIQUE IMPORT LABEL`) ASSERT (node.`UNIQUE IMPORT ID`) IS UNIQUE;%n\" +\n+                \"UNWIND [{_id:3, properties:{age:12}}] AS row%n\" +\n+                \"MERGE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Bar;%n\" +\n+                \"UNWIND [{_id:2, properties:{age:12}}] AS row%n\" +\n+                \"MERGE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Bar:Person;%n\" +\n+                \"UNWIND [{_id:0, properties:{born:date('2018-10-31'), name:\\\"foo\\\"}}, {_id:4, properties:{born:date('2017-09-29'), name:\\\"foo2\\\"}}] AS row%n\" +\n+                \"MERGE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Foo;%n\" +\n+                \"UNWIND [{name:\\\"bar\\\", properties:{age:42}}, {name:\\\"bar2\\\", properties:{age:44}}] AS row%n\" +\n+                \"MERGE (n:Bar{name: row.name}) SET n += row.properties;%n\" +\n+                \"UNWIND [{_id:6, properties:{age:99}}] AS row%n\" +\n+                \"MERGE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties;%n\" +\n+                \"UNWIND [{start: {_id:0}, end: {name:\\\"bar\\\"}, properties:{since:2016}}, {start: {_id:4}, end: {name:\\\"bar2\\\"}, properties:{since:2015}}] AS row%n\" +\n+                \"MATCH (start:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.start._id})%n\" +\n+                \"MATCH (end:Bar{name: row.end.name})%n\" +\n+                \"MERGE (start)-[r:KNOWS]->(end) SET r += row.properties;%n\" +\n+                \"MATCH (n:`UNIQUE IMPORT LABEL`)  WITH n LIMIT 20000 REMOVE n:`UNIQUE IMPORT LABEL` REMOVE n.`UNIQUE IMPORT ID`;%n\" +\n+                \"DROP CONSTRAINT ON (node:`UNIQUE IMPORT LABEL`) ASSERT (node.`UNIQUE IMPORT ID`) IS UNIQUE;%n\");\n+\n+        static final String EXPECTED_PLAIN_UPDATE_STRUCTURE_UNWIND = String.format(\"UNWIND [{start: {_id:0}, end: {name:\\\"bar\\\"}, properties:{since:2016}}, {start: {_id:4}, end: {name:\\\"bar2\\\"}, properties:{since:2015}}] AS row%n\" +\n+                \"MATCH (start:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.start._id})%n\" +\n+                \"MATCH (end:Bar{name: row.end.name})%n\" +\n+                \"MERGE (start)-[r:KNOWS]->(end) SET r += row.properties;%n\");\n+\n+        static final String EXPECTED_NEO4J_OPTIMIZED = EXPECTED_SCHEMA_OPTIMIZED + EXPECTED_NODES_OPTIMIZED + EXPECTED_RELATIONSHIPS_OPTIMIZED + DROP_UNIQUE_OPTIMIZED;\n+\n+        static final String EXPECTED_NEO4J_OPTIMIZED_BATCH_SIZE = EXPECTED_SCHEMA_OPTIMIZED + EXPECTED_NODES_OPTIMIZED_BATCH_SIZE + EXPECTED_RELATIONSHIPS_OPTIMIZED + DROP_UNIQUE_OPTIMIZED;\n+\n+        static final String EXPECTED_NEO4J_SHELL_OPTIMIZED = EXPECTED_SCHEMA_OPTIMIZED + EXPECTED_NODES_OPTIMIZED + EXPECTED_RELATIONSHIPS_OPTIMIZED + DROP_UNIQUE_OPTIMIZED;\n+\n+        static final String EXPECTED_NEO4J_SHELL_OPTIMIZED_BATCH_SIZE = EXPECTED_SCHEMA_OPTIMIZED + EXPECTED_NODES_OPTIMIZED_BATCH_SIZE + EXPECTED_RELATIONSHIPS_OPTIMIZED + DROP_UNIQUE_OPTIMIZED;\n+\n+        static final String EXPECTED_QUERY_NODES =  EXPECTED_SCHEMA_OPTIMIZED + EXPECTED_QUERY_NODES_OPTIMIZED + EXPECTED_RELATIONSHIPS_OPTIMIZED + DROP_UNIQUE_OPTIMIZED;\n+        static final String EXPECTED_QUERY_NODES2 =  EXPECTED_SCHEMA_OPTIMIZED + EXPECTED_QUERY_NODES_OPTIMIZED2 + EXPECTED_RELATIONSHIPS_OPTIMIZED + DROP_UNIQUE_OPTIMIZED;\n+\n+        static final String EXPECTED_CYPHER_OPTIMIZED_BATCH_SIZE_UNWIND = EXPECTED_SCHEMA_OPTIMIZED + EXPECTED_NODES_OPTIMIZED_BATCH_SIZE_UNWIND + EXPECTED_RELATIONSHIPS_OPTIMIZED + DROP_UNIQUE_OPTIMIZED_BATCH;\n+\n+        static final String EXPECTED_CYPHER_OPTIMIZED_BATCH_SIZE_ODD = EXPECTED_SCHEMA_OPTIMIZED + EXPECTED_NODES_OPTIMIZED_BATCH_SIZE_ODD + EXPECTED_RELATIONSHIPS_ODD + DROP_UNIQUE_OPTIMIZED_BATCH;\n+\n+        static final String EXPECTED_CYPHER_SHELL_PARAMS_OPTIMIZED_ODD = EXPECTED_SCHEMA_OPTIMIZED + EXPECTED_NODES_OPTIMIZED_PARAMS_BATCH_SIZE_ODD + EXPECTED_RELATIONSHIPS_PARAMS_ODD + DROP_UNIQUE_OPTIMIZED_BATCH;\n+\n+\n+        static final String EXPECTED_QUERY_CYPHER_SHELL_OPTIMIZED_UNWIND = EXPECTED_CYPHER_OPTIMIZED_BATCH_SIZE_UNWIND\n+                .replace(NEO4J_SHELL.begin(), CYPHER_SHELL.begin())\n+                .replace(NEO4J_SHELL.commit(), CYPHER_SHELL.commit())\n+                .replace(NEO4J_SHELL.schemaAwait(), EXPECTED_INDEXES_AWAIT)\n+                .replace(NEO4J_SHELL.schemaAwait(), CYPHER_SHELL.schemaAwait());\n+\n+\n+        static final String EXPECTED_QUERY_CYPHER_SHELL_OPTIMIZED_ODD = EXPECTED_CYPHER_OPTIMIZED_BATCH_SIZE_ODD\n+                .replace(NEO4J_SHELL.begin(), CYPHER_SHELL.begin())\n+                .replace(NEO4J_SHELL.commit(), CYPHER_SHELL.commit())\n+                .replace(NEO4J_SHELL.schemaAwait(), EXPECTED_INDEXES_AWAIT)\n+                .replace(NEO4J_SHELL.schemaAwait(), CYPHER_SHELL.schemaAwait());\n+\n+        static final String EXPECTED_QUERY_CYPHER_SHELL_PARAMS_OPTIMIZED_ODD = EXPECTED_CYPHER_SHELL_PARAMS_OPTIMIZED_ODD\n+                .replace(NEO4J_SHELL.begin(), CYPHER_SHELL.begin())\n+                .replace(NEO4J_SHELL.commit(), CYPHER_SHELL.commit())\n+                .replace(NEO4J_SHELL.schemaAwait(), EXPECTED_INDEXES_AWAIT)\n+                .replace(NEO4J_SHELL.schemaAwait(), CYPHER_SHELL.schemaAwait());\n+\n+        static final String EXPECTED_QUERY_CYPHER_SHELL_OPTIMIZED = EXPECTED_QUERY_NODES\n+                .replace(NEO4J_SHELL.begin(), CYPHER_SHELL.begin())\n+                .replace(NEO4J_SHELL.commit(), CYPHER_SHELL.commit())\n+                .replace(NEO4J_SHELL.schemaAwait(), EXPECTED_INDEXES_AWAIT_QUERY)\n+                .replace(NEO4J_SHELL.schemaAwait(), CYPHER_SHELL.schemaAwait());\n+\n+        static final String EXPECTED_QUERY_CYPHER_SHELL_OPTIMIZED2 = EXPECTED_QUERY_NODES2\n+                .replace(NEO4J_SHELL.begin(), CYPHER_SHELL.begin())\n+                .replace(NEO4J_SHELL.commit(), CYPHER_SHELL.commit())\n+                .replace(NEO4J_SHELL.schemaAwait(), EXPECTED_INDEXES_AWAIT_QUERY)\n+                .replace(NEO4J_SHELL.schemaAwait(), CYPHER_SHELL.schemaAwait());\n+\n+        static final String EXPECTED_CYPHER_SHELL_OPTIMIZED = EXPECTED_NEO4J_SHELL_OPTIMIZED\n+                .replace(NEO4J_SHELL.begin(), CYPHER_SHELL.begin())\n+                .replace(NEO4J_SHELL.commit(), CYPHER_SHELL.commit())\n+                .replace(NEO4J_SHELL.schemaAwait(), EXPECTED_INDEXES_AWAIT)\n+                .replace(NEO4J_SHELL.schemaAwait(), CYPHER_SHELL.schemaAwait());\n+\n+        static final String EXPECTED_CYPHER_SHELL_OPTIMIZED_BATCH_SIZE = EXPECTED_NEO4J_SHELL_OPTIMIZED_BATCH_SIZE\n+                .replace(NEO4J_SHELL.begin(), CYPHER_SHELL.begin())\n+                .replace(NEO4J_SHELL.commit(), CYPHER_SHELL.commit())\n+                .replace(NEO4J_SHELL.schemaAwait(), EXPECTED_INDEXES_AWAIT)\n+                .replace(NEO4J_SHELL.schemaAwait(), CYPHER_SHELL.schemaAwait());\n+\n+        static final String EXPECTED_PLAIN_OPTIMIZED_BATCH_SIZE = EXPECTED_NEO4J_SHELL_OPTIMIZED_BATCH_SIZE\n+                .replace(NEO4J_SHELL.begin(), PLAIN_FORMAT.begin())\n+                .replace(NEO4J_SHELL.commit(), PLAIN_FORMAT.commit())\n+                .replace(NEO4J_SHELL.schemaAwait(), PLAIN_FORMAT.schemaAwait());\n+\n+        static final String EXPECTED_NEO4J_SHELL = EXPECTED_NODES + EXPECTED_SCHEMA + EXPECTED_RELATIONSHIPS + EXPECTED_CLEAN_UP;\n+\n+        static final String EXPECTED_CYPHER_SHELL = EXPECTED_NEO4J_SHELL\n+                .replace(NEO4J_SHELL.begin(), CYPHER_SHELL.begin())\n+                .replace(NEO4J_SHELL.commit(), CYPHER_SHELL.commit())\n+                .replace(NEO4J_SHELL.schemaAwait(), EXPECTED_INDEXES_AWAIT)\n+                .replace(NEO4J_SHELL.schemaAwait(), CYPHER_SHELL.schemaAwait());\n+\n+        static final String EXPECTED_PLAIN = EXPECTED_NEO4J_SHELL\n+                .replace(NEO4J_SHELL.begin(), PLAIN_FORMAT.begin()).replace(NEO4J_SHELL.commit(), PLAIN_FORMAT.commit())\n+                .replace(NEO4J_SHELL.schemaAwait(), PLAIN_FORMAT.schemaAwait());\n+\n+        static final String EXPECTED_NEO4J_MERGE = EXPECTED_NODES_MERGE + EXPECTED_SCHEMA + EXPECTED_RELATIONSHIPS_MERGE + EXPECTED_CLEAN_UP;\n+\n+        static final String EXPECTED_ONLY_SCHEMA_CYPHER_SHELL = EXPECTED_ONLY_SCHEMA_NEO4J_SHELL.replace(NEO4J_SHELL.begin(), CYPHER_SHELL.begin())\n+                .replace(NEO4J_SHELL.commit(), CYPHER_SHELL.commit()).replace(NEO4J_SHELL.schemaAwait(), CYPHER_SHELL.schemaAwait()) + EXPECTED_INDEXES_AWAIT;\n+    }", "originalCommit": "f82fa86eaa2932dadcafbccfe15b82349712b85d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjM0OTYxNw==", "url": "https://github.com/neo4j-contrib/neo4j-apoc-procedures/pull/1692#discussion_r506349617", "bodyText": "reuse the original", "author": "conker84", "createdAt": "2020-10-16T12:09:23Z", "path": "src/test/java/apoc/export/graphml/ExportGraphMLS3Test.java", "diffHunk": "@@ -0,0 +1,335 @@\n+package apoc.export.graphml;\n+\n+import apoc.graph.Graphs;\n+import apoc.util.TestUtil;\n+import apoc.util.s3.S3TestUtil;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Ignore;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TestName;\n+import org.neo4j.graphdb.GraphDatabaseService;\n+import org.neo4j.graphdb.factory.GraphDatabaseBuilder;\n+import org.neo4j.graphdb.factory.GraphDatabaseSettings;\n+import org.neo4j.test.TestGraphDatabaseFactory;\n+import org.xmlunit.builder.DiffBuilder;\n+import org.xmlunit.diff.DefaultNodeMatcher;\n+import org.xmlunit.diff.Diff;\n+import org.xmlunit.diff.ElementSelector;\n+import org.xmlunit.util.Nodes;\n+\n+import javax.xml.namespace.QName;\n+import java.io.File;\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+\n+import static apoc.util.MapUtil.map;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+import static org.xmlunit.diff.ElementSelectors.byName;\n+\n+@Ignore(\"To use this test, you need to set the S3 bucket and region to a valid endpoint \" +\n+        \"and have your access key and secret key setup in your environment.\")\n+public class ExportGraphMLS3Test {\n+    private static String S3_BUCKET_NAME = null;\n+\n+    public static final List<String> ATTRIBUTES_CONTAINING_NODE_IDS = Arrays.asList(\"id\", \"source\", \"target\");\n+\n+    public static final String GRAPH = \"<graph id=\\\"G\\\" edgedefault=\\\"directed\\\">%n\";\n+    public static final String HEADER = \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>%n\" +\n+            \"<graphml xmlns=\\\"http://graphml.graphdrawing.org/xmlns\\\" xmlns:xsi=\\\"http://www.w3.org/2001/XMLSchema-instance\\\" xsi:schemaLocation=\\\"http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd\\\">%n\";\n+    public static final String KEY_TYPES_FALSE = \"<key id=\\\"born\\\" for=\\\"node\\\" attr.name=\\\"born\\\"/>%n\" +\n+            \"<key id=\\\"values\\\" for=\\\"node\\\" attr.name=\\\"values\\\"/>%n\" +\n+            \"<key id=\\\"name\\\" for=\\\"node\\\" attr.name=\\\"name\\\"/>%n\" +\n+            \"<key id=\\\"label\\\" for=\\\"node\\\" attr.name=\\\"label\\\"/>%n\"+\n+            \"<key id=\\\"place\\\" for=\\\"node\\\" attr.name=\\\"place\\\"/>%n\" +\n+            \"<key id=\\\"age\\\" for=\\\"node\\\" attr.name=\\\"age\\\"/>%n\" +\n+            \"<key id=\\\"label\\\" for=\\\"edge\\\" attr.name=\\\"label\\\"/>%n\";\n+    public static final String KEY_TYPES = \"<key id=\\\"born\\\" for=\\\"node\\\" attr.name=\\\"born\\\" attr.type=\\\"string\\\"/>%n\" +\n+            \"<key id=\\\"values\\\" for=\\\"node\\\" attr.name=\\\"values\\\" attr.type=\\\"string\\\" attr.list=\\\"long\\\"/>%n\" +\n+            \"<key id=\\\"name\\\" for=\\\"node\\\" attr.name=\\\"name\\\" attr.type=\\\"string\\\"/>%n\" +\n+            \"<key id=\\\"label\\\" for=\\\"node\\\" attr.name=\\\"label\\\" attr.type=\\\"string\\\"/>%n\"+\n+            \"<key id=\\\"place\\\" for=\\\"node\\\" attr.name=\\\"place\\\" attr.type=\\\"string\\\"/>%n\" +\n+            \"<key id=\\\"age\\\" for=\\\"node\\\" attr.name=\\\"age\\\" attr.type=\\\"long\\\"/>%n\" +\n+            \"<key id=\\\"label\\\" for=\\\"edge\\\" attr.name=\\\"label\\\" attr.type=\\\"string\\\"/>%n\";\n+    public static final String KEY_TYPES_PATH = \"<key id=\\\"born\\\" for=\\\"node\\\" attr.name=\\\"born\\\" attr.type=\\\"string\\\"/>%n\" +\n+            \"<key id=\\\"name\\\" for=\\\"node\\\" attr.name=\\\"name\\\" attr.type=\\\"string\\\"/>%n\" +\n+            \"<key id=\\\"label\\\" for=\\\"node\\\" attr.name=\\\"label\\\" attr.type=\\\"string\\\"/>%n\"+\n+            \"<key id=\\\"place\\\" for=\\\"node\\\" attr.name=\\\"place\\\" attr.type=\\\"string\\\"/>%n\" +\n+            \"<key id=\\\"TYPE\\\" for=\\\"node\\\" attr.name=\\\"TYPE\\\" attr.type=\\\"string\\\"/>%n\" +\n+            \"<key id=\\\"age\\\" for=\\\"node\\\" attr.name=\\\"age\\\" attr.type=\\\"long\\\"/>%n\" +\n+            \"<key id=\\\"label\\\" for=\\\"edge\\\" attr.name=\\\"label\\\" attr.type=\\\"string\\\"/>%n\" +\n+            \"<key id=\\\"TYPE\\\" for=\\\"edge\\\" attr.name=\\\"TYPE\\\" attr.type=\\\"string\\\"/>%n\";\n+    public static final String KEY_TYPES_CAMEL_CASE = \"<key id=\\\"firstName\\\" for=\\\"node\\\" attr.name=\\\"firstName\\\" attr.type=\\\"string\\\"/>%n\" +\n+            \"<key id=\\\"ageNow\\\" for=\\\"node\\\" attr.name=\\\"ageNow\\\" attr.type=\\\"long\\\"/>%n\" +\n+            \"<key id=\\\"name\\\" for=\\\"node\\\" attr.name=\\\"name\\\" attr.type=\\\"string\\\"/>%n\" +\n+            \"<key id=\\\"label\\\" for=\\\"node\\\" attr.name=\\\"label\\\" attr.type=\\\"string\\\"/>%n\" +\n+            \"<key id=\\\"TYPE\\\" for=\\\"node\\\" attr.name=\\\"TYPE\\\" attr.type=\\\"string\\\"/>%n\" +\n+            \"<key id=\\\"label\\\" for=\\\"edge\\\" attr.name=\\\"label\\\" attr.type=\\\"string\\\"/>%n\" +\n+            \"<key id=\\\"TYPE\\\" for=\\\"edge\\\" attr.name=\\\"TYPE\\\" attr.type=\\\"string\\\"/>%n\";\n+    public static final String DATA = \"<node id=\\\"n0\\\" labels=\\\":Foo:Foo0:Foo2\\\"><data key=\\\"labels\\\">:Foo:Foo0:Foo2</data><data key=\\\"place\\\">{\\\"crs\\\":\\\"wgs-84-3d\\\",\\\"latitude\\\":56.7,\\\"longitude\\\":12.78,\\\"height\\\":100.0}</data><data key=\\\"name\\\">foo</data><data key=\\\"born\\\">2018-10-10</data></node>%n\" +\n+            \"<node id=\\\"n1\\\" labels=\\\":Bar\\\"><data key=\\\"labels\\\">:Bar</data><data key=\\\"age\\\">42</data><data key=\\\"name\\\">bar</data><data key=\\\"place\\\">{\\\"crs\\\":\\\"wgs-84\\\",\\\"latitude\\\":56.7,\\\"longitude\\\":12.78,\\\"height\\\":null}</data></node>%n\" +\n+            \"<node id=\\\"n2\\\" labels=\\\":Bar\\\"><data key=\\\"labels\\\">:Bar</data><data key=\\\"age\\\">12</data><data key=\\\"values\\\">[1,2,3]</data></node>%n\" +\n+            \"<edge id=\\\"e0\\\" source=\\\"n0\\\" target=\\\"n1\\\" label=\\\"KNOWS\\\"><data key=\\\"label\\\">KNOWS</data></edge>%n\";\n+    public static final String DATA_CAMEL_CASE =\n+            \"<node id=\\\"n0\\\" labels=\\\":Foo:Foo0:Foo2\\\"><data key=\\\"TYPE\\\">:Foo:Foo0:Foo2</data><data key=\\\"label\\\">foo</data><data key=\\\"firstName\\\">foo</data></node>%n\" +\n+                    \"<node id=\\\"n1\\\" labels=\\\":Bar\\\"><data key=\\\"TYPE\\\">:Bar</data><data key=\\\"label\\\">bar</data><data key=\\\"name\\\">bar</data><data key=\\\"ageNow\\\">42</data></node>%n\" +\n+                    \"<edge id=\\\"e0\\\" source=\\\"n0\\\" target=\\\"n1\\\" label=\\\"KNOWS\\\"><data key=\\\"label\\\">KNOWS</data><data key=\\\"TYPE\\\">KNOWS</data></edge>%n\";\n+\n+    public static final String FOOTER = \"</graph>%n\" +\n+            \"</graphml>\";\n+\n+    public static final String DATA_PATH = \"<node id=\\\"n0\\\" labels=\\\":Foo:Foo0:Foo2\\\"><data key=\\\"TYPE\\\">:Foo:Foo0:Foo2</data><data key=\\\"label\\\">foo</data><data key=\\\"place\\\">{\\\"crs\\\":\\\"wgs-84-3d\\\",\\\"latitude\\\":56.7,\\\"longitude\\\":12.78,\\\"height\\\":100.0}</data><data key=\\\"name\\\">foo</data><data key=\\\"born\\\">2018-10-10</data></node>%n\" +\n+            \"<node id=\\\"n1\\\" labels=\\\":Bar\\\"><data key=\\\"TYPE\\\">:Bar</data><data key=\\\"label\\\">bar</data><data key=\\\"age\\\">42</data><data key=\\\"name\\\">bar</data><data key=\\\"place\\\">{\\\"crs\\\":\\\"wgs-84\\\",\\\"latitude\\\":56.7,\\\"longitude\\\":12.78,\\\"height\\\":null}</data></node>%n\" +\n+            \"<edge id=\\\"e0\\\" source=\\\"n0\\\" target=\\\"n1\\\" label=\\\"KNOWS\\\"><data key=\\\"label\\\">KNOWS</data><data key=\\\"TYPE\\\">KNOWS</data></edge>%n\";\n+\n+    public static final String DATA_PATH_CAPTION = \"<node id=\\\"n0\\\" labels=\\\":Foo:Foo0:Foo2\\\"><data key=\\\"TYPE\\\">:Foo:Foo0:Foo2</data><data key=\\\"label\\\">foo</data><data key=\\\"place\\\">{\\\"crs\\\":\\\"wgs-84-3d\\\",\\\"latitude\\\":56.7,\\\"longitude\\\":12.78,\\\"height\\\":100.0}</data><data key=\\\"name\\\">foo</data><data key=\\\"born\\\">2018-10-10</data></node>%n\" +\n+            \"<node id=\\\"n1\\\" labels=\\\":Bar\\\"><data key=\\\"TYPE\\\">:Bar</data><data key=\\\"label\\\">bar</data><data key=\\\"age\\\">42</data><data key=\\\"name\\\">bar</data><data key=\\\"place\\\">{\\\"crs\\\":\\\"wgs-84\\\",\\\"latitude\\\":56.7,\\\"longitude\\\":12.78,\\\"height\\\":null}</data></node>%n\" +\n+            \"<edge id=\\\"e0\\\" source=\\\"n0\\\" target=\\\"n1\\\" label=\\\"KNOWS\\\"><data key=\\\"label\\\">KNOWS</data><data key=\\\"TYPE\\\">KNOWS</data></edge>%n\";\n+\n+    public static final String DATA_PATH_CAPTION_DEFAULT = \"<node id=\\\"n0\\\" labels=\\\":Foo:Foo0:Foo2\\\"><data key=\\\"TYPE\\\">:Foo:Foo0:Foo2</data><data key=\\\"label\\\">point({x: 56.7, y: 12.78, z: 100.0, crs: 'wgs-84-3d'})</data><data key=\\\"place\\\">{\\\"crs\\\":\\\"wgs-84-3d\\\",\\\"latitude\\\":56.7,\\\"longitude\\\":12.78,\\\"height\\\":100.0}</data><data key=\\\"name\\\">foo</data><data key=\\\"born\\\">2018-10-10</data></node>%n\" +\n+            \"<node id=\\\"n1\\\" labels=\\\":Bar\\\"><data key=\\\"TYPE\\\">:Bar</data><data key=\\\"label\\\">42</data><data key=\\\"age\\\">42</data><data key=\\\"name\\\">bar</data><data key=\\\"place\\\">{\\\"crs\\\":\\\"wgs-84\\\",\\\"latitude\\\":56.7,\\\"longitude\\\":12.78,\\\"height\\\":null}</data></node>%n\" +\n+            \"<edge id=\\\"e0\\\" source=\\\"n0\\\" target=\\\"n1\\\" label=\\\"KNOWS\\\"><data key=\\\"label\\\">KNOWS</data><data key=\\\"TYPE\\\">KNOWS</data></edge>%n\";\n+\n+    private static final String EXPECTED_TYPES_PATH = String.format(HEADER + KEY_TYPES_PATH + GRAPH + DATA_PATH + FOOTER);\n+    private static final String EXPECTED_TYPES_PATH_CAPTION = String.format(HEADER + KEY_TYPES_PATH + GRAPH + DATA_PATH_CAPTION + FOOTER);\n+    private static final String EXPECTED_TYPES_PATH_WRONG_CAPTION = String.format(HEADER + KEY_TYPES_PATH + GRAPH + DATA_PATH_CAPTION_DEFAULT + FOOTER);\n+    private static final String EXPECTED_TYPES = String.format(HEADER + KEY_TYPES + GRAPH + DATA + FOOTER);\n+    private static final String EXPECTED_FALSE = String.format(HEADER + KEY_TYPES_FALSE + GRAPH + DATA + FOOTER);\n+    private static final String EXPECTED_TYPES_PATH_CAMEL_CASE = String.format(HEADER + KEY_TYPES_CAMEL_CASE + GRAPH + DATA_CAMEL_CASE + FOOTER);", "originalCommit": "f82fa86eaa2932dadcafbccfe15b82349712b85d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjM1MjY3Nw==", "url": "https://github.com/neo4j-contrib/neo4j-apoc-procedures/pull/1692#discussion_r506352677", "bodyText": "what is meant for? I cannot find any info in the documentation can you please add it?", "author": "conker84", "createdAt": "2020-10-16T12:13:52Z", "path": "src/main/java/apoc/export/cypher/ExportFileManager.java", "diffHunk": "@@ -12,4 +12,6 @@\n     String drain(String type);\n \n     String getFileName();\n+\n+    Boolean separatedFiles();", "originalCommit": "f82fa86eaa2932dadcafbccfe15b82349712b85d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjM1NTUyNA==", "url": "https://github.com/neo4j-contrib/neo4j-apoc-procedures/pull/1692#discussion_r506355524", "bodyText": "maybe we can use it in a try-with-resource instead of closing it explicitly?", "author": "conker84", "createdAt": "2020-10-16T12:18:00Z", "path": "src/main/java/apoc/export/cypher/MultiStatementCypherSubGraphExporter.java", "diffHunk": "@@ -93,26 +93,38 @@ public void export(ExportConfig config, Reporter reporter, ExportFileManager cyp\n         int batchSize = config.getBatchSize();\n         ExportConfig.OptimizationType useOptimizations = config.getOptimizationType();\n \n+        PrintWriter schemaWriter = cypherFileManager.getPrintWriter(\"schema\");\n+        PrintWriter nodesWriter = cypherFileManager.getPrintWriter(\"nodes\");\n+        PrintWriter relationshipsWriter = cypherFileManager.getPrintWriter(\"relationships\");\n+        PrintWriter cleanupWriter = cypherFileManager.getPrintWriter(\"cleanup\");", "originalCommit": "f82fa86eaa2932dadcafbccfe15b82349712b85d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjM1NjI0OQ==", "url": "https://github.com/neo4j-contrib/neo4j-apoc-procedures/pull/1692#discussion_r506356249", "bodyText": "the resources will be never closed if the value is false?", "author": "conker84", "createdAt": "2020-10-16T12:18:57Z", "path": "src/main/java/apoc/export/cypher/MultiStatementCypherSubGraphExporter.java", "diffHunk": "@@ -93,26 +93,38 @@ public void export(ExportConfig config, Reporter reporter, ExportFileManager cyp\n         int batchSize = config.getBatchSize();\n         ExportConfig.OptimizationType useOptimizations = config.getOptimizationType();\n \n+        PrintWriter schemaWriter = cypherFileManager.getPrintWriter(\"schema\");\n+        PrintWriter nodesWriter = cypherFileManager.getPrintWriter(\"nodes\");\n+        PrintWriter relationshipsWriter = cypherFileManager.getPrintWriter(\"relationships\");\n+        PrintWriter cleanupWriter = cypherFileManager.getPrintWriter(\"cleanup\");\n+\n         switch (useOptimizations) {\n             case NONE:\n-                exportNodes(cypherFileManager.getPrintWriter(\"nodes\"), reporter, batchSize);\n-                exportSchema(cypherFileManager.getPrintWriter(\"schema\"));\n-                exportRelationships(cypherFileManager.getPrintWriter(\"relationships\"), reporter, batchSize);\n+                exportNodes(nodesWriter, reporter, batchSize);\n+                exportSchema(schemaWriter);\n+                exportRelationships(relationshipsWriter, reporter, batchSize);\n                 break;\n             default:\n                 artificialUniques += countArtificialUniques(graph.getNodes());\n-                exportSchema(cypherFileManager.getPrintWriter(\"schema\"));\n-                PrintWriter nodeWrite = cypherFileManager.getPrintWriter(\"nodes\");\n-                exportNodesUnwindBatch(nodeWrite, reporter);\n-                PrintWriter relWrite = cypherFileManager.getPrintWriter(\"relationships\");\n-                exportRelationshipsUnwindBatch(relWrite, reporter);\n+                exportSchema(schemaWriter);\n+                exportNodesUnwindBatch(nodesWriter, reporter);\n+                exportRelationshipsUnwindBatch(relationshipsWriter, reporter);\n+                break;\n+        }\n+        if (cypherFileManager.separatedFiles()) {", "originalCommit": "f82fa86eaa2932dadcafbccfe15b82349712b85d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjM1NzE2MQ==", "url": "https://github.com/neo4j-contrib/neo4j-apoc-procedures/pull/1692#discussion_r506357161", "bodyText": "try-with-resource?", "author": "conker84", "createdAt": "2020-10-16T12:20:09Z", "path": "src/main/java/apoc/export/cypher/MultiStatementCypherSubGraphExporter.java", "diffHunk": "@@ -93,26 +93,38 @@ public void export(ExportConfig config, Reporter reporter, ExportFileManager cyp\n         int batchSize = config.getBatchSize();\n         ExportConfig.OptimizationType useOptimizations = config.getOptimizationType();\n \n+        PrintWriter schemaWriter = cypherFileManager.getPrintWriter(\"schema\");\n+        PrintWriter nodesWriter = cypherFileManager.getPrintWriter(\"nodes\");\n+        PrintWriter relationshipsWriter = cypherFileManager.getPrintWriter(\"relationships\");\n+        PrintWriter cleanupWriter = cypherFileManager.getPrintWriter(\"cleanup\");\n+\n         switch (useOptimizations) {\n             case NONE:\n-                exportNodes(cypherFileManager.getPrintWriter(\"nodes\"), reporter, batchSize);\n-                exportSchema(cypherFileManager.getPrintWriter(\"schema\"));\n-                exportRelationships(cypherFileManager.getPrintWriter(\"relationships\"), reporter, batchSize);\n+                exportNodes(nodesWriter, reporter, batchSize);\n+                exportSchema(schemaWriter);\n+                exportRelationships(relationshipsWriter, reporter, batchSize);\n                 break;\n             default:\n                 artificialUniques += countArtificialUniques(graph.getNodes());\n-                exportSchema(cypherFileManager.getPrintWriter(\"schema\"));\n-                PrintWriter nodeWrite = cypherFileManager.getPrintWriter(\"nodes\");\n-                exportNodesUnwindBatch(nodeWrite, reporter);\n-                PrintWriter relWrite = cypherFileManager.getPrintWriter(\"relationships\");\n-                exportRelationshipsUnwindBatch(relWrite, reporter);\n+                exportSchema(schemaWriter);\n+                exportNodesUnwindBatch(nodesWriter, reporter);\n+                exportRelationshipsUnwindBatch(relationshipsWriter, reporter);\n+                break;\n+        }\n+        if (cypherFileManager.separatedFiles()) {\n+            nodesWriter.close();\n+            schemaWriter.close();\n+            relationshipsWriter.close();\n         }\n-        exportCleanUp(cypherFileManager.getPrintWriter(\"cleanup\"), batchSize);\n+        exportCleanUp(cleanupWriter, batchSize);\n+        cleanupWriter.close();\n         reporter.done();\n     }\n \n     public void exportOnlySchema(ExportFileManager cypherFileManager) throws IOException {\n-        exportSchema(cypherFileManager.getPrintWriter(\"schema\"));\n+        PrintWriter schemaWriter = cypherFileManager.getPrintWriter(\"schema\");\n+        exportSchema(schemaWriter);\n+        schemaWriter.close();", "originalCommit": "f82fa86eaa2932dadcafbccfe15b82349712b85d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjM1ODQwMw==", "url": "https://github.com/neo4j-contrib/neo4j-apoc-procedures/pull/1692#discussion_r506358403", "bodyText": "do you think makes sense have some kind of factory pattern here and use it instead the if/else/if?", "author": "conker84", "createdAt": "2020-10-16T12:21:43Z", "path": "src/main/java/apoc/util/FileUtils.java", "diffHunk": "@@ -31,6 +32,7 @@\n     public static final String HDFS_PROTOCOL = \"hdfs\";\n     public static final boolean HDFS_ENABLED = Util.classExists(\"org.apache.hadoop.fs.FileSystem\");\n     public static final Pattern HDFS_PATTERN = Pattern.compile(\"^(hdfs:\\\\/\\\\/)(?:[^@\\\\/\\\\n]+@)?([^\\\\/\\\\n]+)\");\n+    public static final Pattern S3_PATTERN = Pattern.compile(\"^(s3:\\\\/\\\\/)(?:[^@\\\\/\\\\n]+@)?([^\\\\/\\\\n]+)\");", "originalCommit": "f82fa86eaa2932dadcafbccfe15b82349712b85d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjM1OTM0Mw==", "url": "https://github.com/neo4j-contrib/neo4j-apoc-procedures/pull/1692#discussion_r506359343", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    if (Objects.nonNull(accessKey) && !accessKey.isEmpty()\n          \n          \n            \n                    if (StringUtils.isNotBlank(accessKey)\n          \n      \n    \n    \n  \n\nand the same as for others?", "author": "conker84", "createdAt": "2020-10-16T12:23:06Z", "path": "src/main/java/apoc/util/s3/S3Aws.java", "diffHunk": "@@ -46,4 +67,20 @@ public long getLength() {\n             }\n         };\n     }\n+\n+    private static AWSCredentialsProvider getCredentialsProvider(\n+            final String accessKey, final String secretKey, final String sessionToken) {\n+\n+        if (Objects.nonNull(accessKey) && !accessKey.isEmpty()", "originalCommit": "f82fa86eaa2932dadcafbccfe15b82349712b85d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjM2MzY0Ng==", "url": "https://github.com/neo4j-contrib/neo4j-apoc-procedures/pull/1692#discussion_r506363646", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    if (Objects.nonNull(endpoint) &&  endpoint.isEmpty()) {\n          \n          \n            \n                    if (StringUtils.isBlank(endpoint)) {", "author": "conker84", "createdAt": "2020-10-16T12:28:43Z", "path": "src/main/java/apoc/util/s3/S3ParamsExtractor.java", "diffHunk": "@@ -53,22 +64,37 @@ public static S3Params extract(URL url) throws  IllegalArgumentException {\n \n         String region = null;\n \n-        //look for endpoint contains region.\n-        for (Regions r: Regions.values()){\n-            if(endpoint.toLowerCase().contains(r.getName().toLowerCase())){\n-                region = r.getName().toLowerCase();\n+        if (Objects.nonNull(endpoint)) {\n+\n+            // Look for endpoint contains region\n+            for (Regions r: Regions.values()){\n+                if(endpoint.toLowerCase().contains(r.getName().toLowerCase())){\n+                    region = r.getName().toLowerCase();\n+                    break;\n+                }\n             }\n-        }\n \n-        //has specific endpoints for regions otherwise remove region from endpoint\n-        if(Objects.nonNull(region) && !endpoint.contains(\"amazonaws.com\")) {\n-            endpoint = endpoint.substring(endpoint.indexOf(\".\") + 1);\n+            if(Objects.nonNull(region)) {\n+                //has specific endpoints for regions, otherwise remove region from endpoint\n+                if(!endpoint.contains(\"amazonaws.com\")) {\n+                    endpoint = endpoint.substring(endpoint.indexOf(\".\") + 1);\n+                }\n+\n+                // If it contains region only, it is an invalid endpoint.\n+                if (region.toLowerCase().equals(endpoint.toLowerCase())) {\n+                    endpoint = \"\";\n+                }\n+            }\n         }\n \n         if (url.getPort() != 80 && url.getPort() != 443 && url.getPort() > 0) {\n             endpoint += \":\" + url.getPort();\n         }\n \n-        return new S3Params(accessKey, secretKey, endpoint, bucket, key, region);\n+        if (Objects.nonNull(endpoint) &&  endpoint.isEmpty()) {", "originalCommit": "f82fa86eaa2932dadcafbccfe15b82349712b85d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "70f71f7b083dd69aa63293e4f0386833194b53a0", "url": "https://github.com/neo4j-contrib/neo4j-apoc-procedures/commit/70f71f7b083dd69aa63293e4f0386833194b53a0", "message": "Fixes #1689: Adds support for S3 as an export destination\n\nCR feedback\n\nhttps://github.com/neo4j-contrib/neo4j-apoc-procedures/issues/1689", "committedDate": "2020-11-10T06:30:41Z", "type": "commit"}, {"oid": "ba918d75b5c0de3ac44e62fdca8c36312f9cb842", "url": "https://github.com/neo4j-contrib/neo4j-apoc-procedures/commit/ba918d75b5c0de3ac44e62fdca8c36312f9cb842", "message": "Fixes #1689: Adds support for S3 as an export destination\n\n    CR feedback to address failing test case\n\n    https://github.com/neo4j-contrib/neo4j-apoc-procedures/issues/1689", "committedDate": "2020-11-17T19:00:06Z", "type": "commit"}]}