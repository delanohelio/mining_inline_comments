{"pr_number": 1870, "pr_title": "[HUDI-808] Support cleaning bootstrap source data", "pr_createdAt": "2020-07-24T05:23:10Z", "pr_url": "https://github.com/apache/hudi/pull/1870", "timeline": [{"oid": "946b08eeab23a8fe78d5916b96e502714fa9bee7", "url": "https://github.com/apache/hudi/commit/946b08eeab23a8fe78d5916b96e502714fa9bee7", "message": "[HUDI-808] Support cleaning bootstrap source data", "committedDate": "2020-07-28T18:12:15Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzI5MTg1Nw==", "url": "https://github.com/apache/hudi/pull/1870#discussion_r463291857", "bodyText": "I see some private functions in this class to test cleaning based on commits and file versions, that are re-used by other tests. Is it possible to re-use some of these already created ones. May be introduce another boolean flag for bootstrap which can do additional creation of source files and later check if they are cleaned up.", "author": "umehrot2", "createdAt": "2020-07-30T21:51:09Z", "path": "hudi-client/src/test/java/org/apache/hudi/table/TestCleaner.java", "diffHunk": "@@ -885,6 +888,109 @@ private void testKeepLatestCommits(boolean simulateFailureRetry, boolean enableI\n         file2P0C1));\n   }\n \n+  @Test\n+  public void testBootstrapSourceFileCleanWithKeepLatestFileVersions() throws IOException {\n+    testBootstrapSourceFileClean(HoodieCleaningPolicy.KEEP_LATEST_FILE_VERSIONS);\n+  }\n+\n+  @Test\n+  public void testBootstrapSourceFileCleanWithKeepLatestCommits() throws IOException {\n+    testBootstrapSourceFileClean(HoodieCleaningPolicy.KEEP_LATEST_COMMITS);\n+  }\n+\n+  /**\n+   * Test HoodieTable.clean() with Bootstrap source file clean enable.\n+   */\n+  @Test\n+  private void testBootstrapSourceFileClean(HoodieCleaningPolicy cleaningPolicy) throws IOException {\n+    HoodieWriteConfig config = HoodieWriteConfig.newBuilder().withPath(basePath).withAssumeDatePartitioning(true)\n+        .withCompactionConfig(HoodieCompactionConfig.newBuilder()\n+            .withCleanBootstrapSourceFileEnabled(true)\n+            .withCleanerPolicy(cleaningPolicy).retainCommits(1).retainFileVersions(2).build())\n+        .build();", "originalCommit": "946b08eeab23a8fe78d5916b96e502714fa9bee7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzM3MzQ3Nw==", "url": "https://github.com/apache/hudi/pull/1870#discussion_r467373477", "bodyText": "Rewrote the test part to make use of the original test code.", "author": "zhedoubushishi", "createdAt": "2020-08-08T07:19:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzI5MTg1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjI0MzA1Ng==", "url": "https://github.com/apache/hudi/pull/1870#discussion_r466243056", "bodyText": "can we move these to the test class itself? these are very specific to bootstrap.", "author": "vinothchandar", "createdAt": "2020-08-06T08:43:21Z", "path": "hudi-common/src/test/java/org/apache/hudi/common/testutils/HoodieTestUtils.java", "diffHunk": "@@ -513,4 +522,41 @@ public static void writeRecordsToLogFiles(FileSystem fs, String basePath, Schema\n     }\n     return writeStatList;\n   }\n+\n+  public static Map<String, List<BootstrapSourceFileMapping>> generateBootstrapIndex(HoodieTableMetaClient metaClient,", "originalCommit": "946b08eeab23a8fe78d5916b96e502714fa9bee7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njc0MjQwOQ==", "url": "https://github.com/apache/hudi/pull/1870#discussion_r466742409", "bodyText": "Sure. Done.", "author": "zhedoubushishi", "createdAt": "2020-08-06T23:40:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjI0MzA1Ng=="}], "type": "inlineReview"}, {"oid": "98cb7ccc736005fc9e907f19608e6be5d8596aaf", "url": "https://github.com/apache/hudi/commit/98cb7ccc736005fc9e907f19608e6be5d8596aaf", "message": "[HUDI-808] Support cleaning bootstrap source data", "committedDate": "2020-08-08T07:08:55Z", "type": "forcePushed"}, {"oid": "e25ea60f77252ca81b212e1147ecef36f25d63d2", "url": "https://github.com/apache/hudi/commit/e25ea60f77252ca81b212e1147ecef36f25d63d2", "message": "[HUDI-808] Support cleaning bootstrap source data", "committedDate": "2020-08-08T07:18:26Z", "type": "forcePushed"}, {"oid": "82edf2206f83574f1577175cfa2606039683ffea", "url": "https://github.com/apache/hudi/commit/82edf2206f83574f1577175cfa2606039683ffea", "message": "[HUDI-808] Support cleaning bootstrap source data", "committedDate": "2020-08-08T08:34:59Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQwMTg3Mg==", "url": "https://github.com/apache/hudi/pull/1870#discussion_r467401872", "bodyText": "@zhedoubushishi : I think this is an unnecessary call we will be making per file deletion. With embedded timeline service, this request will be routed to driver. Instead, I think we can handle it using versioning in clean plan.  Thoughts ?", "author": "bvaradar", "createdAt": "2020-08-08T08:50:11Z", "path": "hudi-client/src/main/java/org/apache/hudi/table/action/clean/CleanActionExecutor.java", "diffHunk": "@@ -116,6 +119,19 @@ HoodieCleanerPlan requestClean(JavaSparkContext jsc) {\n         PartitionCleanStat partitionCleanStat = partitionCleanStatMap.get(partitionPath);\n         partitionCleanStat.addDeleteFilePatterns(deletePath.getName());\n         partitionCleanStat.addDeletedFileResult(deletePath.getName(), deletedFileResult);\n+\n+        // If CleanBootstrapSourceFileEnabled and it is a metadata bootstrap commit, also delete the corresponding source file\n+        if (cleanBootstrapSourceFileEnabled && !FSUtils.isLogFile(deletePath)\n+            && FSUtils.getCommitTime(delFileName).equals(HoodieTimeline.METADATA_BOOTSTRAP_INSTANT_TS)) {\n+          Option<HoodieBaseFile> baseFile = fileSystemView.getBaseFileOn(partitionPath,", "originalCommit": "82edf2206f83574f1577175cfa2606039683ffea", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ5Njk0NQ==", "url": "https://github.com/apache/hudi/pull/1870#discussion_r467496945", "bodyText": "I see what you mean. Yea we should avoid making unnecessary calls. So regarding to versioning, do you mean create a class like TimelineLayoutVersion or just simply handle this logic in the CleanActionExecutor. For example, if the parameter is a full file path then delete it. Else if the parameter is a file name, generate the file path and then delete it.", "author": "zhedoubushishi", "createdAt": "2020-08-08T19:34:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQwMTg3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzUyNDUwOQ==", "url": "https://github.com/apache/hudi/pull/1870#discussion_r467524509", "bodyText": "@zhedoubushishi : Tried reaching you on slack :) to discuss an approach. I went ahead and implemented it in the interest of time.\nThe basic idea is to ensure that Cleaner plan stores necessary information related to files to be deleted including bootstrap base files. The cleaner executor will simply read the cleaner plan and be able to distinguish normal vs bootstrap base files. It goes ahead and deletes those files. For bootstrap base files, it records the complete path of the file it deleted in a separate (new) avro field. This is very important in order to ensure incremental timeline syncing (which reads these metadata) to work properly.\nPlease take a look at this code changes if possible.\n( @vinothchandar  @umehrot2  : FYI )", "author": "bvaradar", "createdAt": "2020-08-09T01:56:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQwMTg3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzUyNDY0NQ==", "url": "https://github.com/apache/hudi/pull/1870#discussion_r467524645", "bodyText": "@zhedoubushishi : Please also note that for ensuring backwards compatibility, I add a migrator class (CleanPlanMigrator.java) to handle pre and post 0.6  .clean.requested files.", "author": "bvaradar", "createdAt": "2020-08-09T01:59:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQwMTg3Mg=="}], "type": "inlineReview"}, {"oid": "60c5bfb67ef09972a5ccaa5c45085aac41d84932", "url": "https://github.com/apache/hudi/commit/60c5bfb67ef09972a5ccaa5c45085aac41d84932", "message": "[HUDI-808] Support cleaning bootstrap source data", "committedDate": "2020-08-09T01:45:12Z", "type": "forcePushed"}, {"oid": "8344982d6c125e70faa3ea83ac0dcd612d14694f", "url": "https://github.com/apache/hudi/commit/8344982d6c125e70faa3ea83ac0dcd612d14694f", "message": "[HUDI-808] Support cleaning bootstrap source data", "committedDate": "2020-08-09T02:09:39Z", "type": "forcePushed"}, {"oid": "6174d890b8d6fa91e3a8d1b960443222350446bd", "url": "https://github.com/apache/hudi/commit/6174d890b8d6fa91e3a8d1b960443222350446bd", "message": "[HUDI-808] Support cleaning bootstrap source data", "committedDate": "2020-08-09T02:26:45Z", "type": "forcePushed"}, {"oid": "c0bd452d0367eee8b8c37502f6b56c2ee645ef24", "url": "https://github.com/apache/hudi/commit/c0bd452d0367eee8b8c37502f6b56c2ee645ef24", "message": "[HUDI-808] Support cleaning bootstrap source data", "committedDate": "2020-08-09T05:35:05Z", "type": "forcePushed"}, {"oid": "896828d0340183369b8faf0c96721f446c30135f", "url": "https://github.com/apache/hudi/commit/896828d0340183369b8faf0c96721f446c30135f", "message": "[HUDI-808] Support cleaning bootstrap source data", "committedDate": "2020-08-09T16:07:57Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzYyODY0OQ==", "url": "https://github.com/apache/hudi/pull/1870#discussion_r467628649", "bodyText": "rename : hoodie.cleaner.delete.bootstrap.base.file ?", "author": "vinothchandar", "createdAt": "2020-08-09T21:04:09Z", "path": "hudi-client/src/main/java/org/apache/hudi/config/HoodieCompactionConfig.java", "diffHunk": "@@ -52,6 +52,8 @@\n   public static final String MAX_COMMITS_TO_KEEP_PROP = \"hoodie.keep.max.commits\";\n   public static final String MIN_COMMITS_TO_KEEP_PROP = \"hoodie.keep.min.commits\";\n   public static final String COMMITS_ARCHIVAL_BATCH_SIZE_PROP = \"hoodie.commits.archival.batch\";\n+  // Set true to clean bootstrap source files when necessary\n+  public static final String CLEANER_BOOTSTRAP_BASE_FILE_ENABLED = \"hoodie.cleaner.bootstrap.base.file\";", "originalCommit": "896828d0340183369b8faf0c96721f446c30135f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODM4MzQzMQ==", "url": "https://github.com/apache/hudi/pull/1870#discussion_r468383431", "bodyText": "Done", "author": "bvaradar", "createdAt": "2020-08-11T07:34:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzYyODY0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Nzk0NDE5Ng==", "url": "https://github.com/apache/hudi/pull/1870#discussion_r467944196", "bodyText": "stylistic: in general, a stream within stream is a bit hard to read. flatMap() first? but guess this is a map. probably using a named lambda function may help", "author": "vinothchandar", "createdAt": "2020-08-10T14:29:58Z", "path": "hudi-client/src/main/java/org/apache/hudi/table/action/clean/CleanActionExecutor.java", "diffHunk": "@@ -82,40 +83,45 @@ HoodieCleanerPlan requestClean(JavaSparkContext jsc) {\n       LOG.info(\"Using cleanerParallelism: \" + cleanerParallelism);\n \n       jsc.setJobGroup(this.getClass().getSimpleName(), \"Generates list of file slices to be cleaned\");\n-      Map<String, List<String>> cleanOps = jsc\n+      Map<String, List<HoodieCleanFileInfo>> cleanOps = jsc\n           .parallelize(partitionsToClean, cleanerParallelism)\n           .map(partitionPathToClean -> Pair.of(partitionPathToClean, planner.getDeletePaths(partitionPathToClean)))\n           .collect().stream()\n-          .collect(Collectors.toMap(Pair::getKey, Pair::getValue));\n+          .collect(Collectors.toMap(Pair::getKey,", "originalCommit": "896828d0340183369b8faf0c96721f446c30135f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODM4Mjg0Mg==", "url": "https://github.com/apache/hudi/pull/1870#discussion_r468382842", "bodyText": "Done", "author": "bvaradar", "createdAt": "2020-08-11T07:33:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Nzk0NDE5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Nzk0NzA5OA==", "url": "https://github.com/apache/hudi/pull/1870#discussion_r467947098", "bodyText": "this is same as\npartitionCleanStat.addDeleteFilePatterns(deletePath.toString(), isBootstrapBasePathFile);\npartitionCleanStat.addDeletedFileResult(deletePath.toString(), deletedFileResult, isBootstrapBasePathFile);\n\nright", "author": "vinothchandar", "createdAt": "2020-08-10T14:34:10Z", "path": "hudi-client/src/main/java/org/apache/hudi/table/action/clean/CleanActionExecutor.java", "diffHunk": "@@ -82,40 +83,45 @@ HoodieCleanerPlan requestClean(JavaSparkContext jsc) {\n       LOG.info(\"Using cleanerParallelism: \" + cleanerParallelism);\n \n       jsc.setJobGroup(this.getClass().getSimpleName(), \"Generates list of file slices to be cleaned\");\n-      Map<String, List<String>> cleanOps = jsc\n+      Map<String, List<HoodieCleanFileInfo>> cleanOps = jsc\n           .parallelize(partitionsToClean, cleanerParallelism)\n           .map(partitionPathToClean -> Pair.of(partitionPathToClean, planner.getDeletePaths(partitionPathToClean)))\n           .collect().stream()\n-          .collect(Collectors.toMap(Pair::getKey, Pair::getValue));\n+          .collect(Collectors.toMap(Pair::getKey,\n+            (y) -> y.getValue().stream().map(CleanFileInfo::toHoodieFileCleanInfo).collect(Collectors.toList())));\n \n       return new HoodieCleanerPlan(earliestInstant\n           .map(x -> new HoodieActionInstant(x.getTimestamp(), x.getAction(), x.getState().name())).orElse(null),\n-          config.getCleanerPolicy().name(), cleanOps, 1);\n+          config.getCleanerPolicy().name(), null, CleanPlanner.LATEST_CLEAN_PLAN_VERSION, cleanOps);\n     } catch (IOException e) {\n       throw new HoodieIOException(\"Failed to schedule clean operation\", e);\n     }\n   }\n \n-  private static PairFlatMapFunction<Iterator<Tuple2<String, String>>, String, PartitionCleanStat> deleteFilesFunc(\n-      HoodieTable table) {\n-    return (PairFlatMapFunction<Iterator<Tuple2<String, String>>, String, PartitionCleanStat>) iter -> {\n+  private static PairFlatMapFunction<Iterator<Tuple2<String, CleanFileInfo>>, String, PartitionCleanStat>\n+        deleteFilesFunc(HoodieTable table) {\n+    return (PairFlatMapFunction<Iterator<Tuple2<String, CleanFileInfo>>, String, PartitionCleanStat>) iter -> {\n       Map<String, PartitionCleanStat> partitionCleanStatMap = new HashMap<>();\n-\n       FileSystem fs = table.getMetaClient().getFs();\n-      Path basePath = new Path(table.getMetaClient().getBasePath());\n       while (iter.hasNext()) {\n-        Tuple2<String, String> partitionDelFileTuple = iter.next();\n+        Tuple2<String, CleanFileInfo> partitionDelFileTuple = iter.next();\n         String partitionPath = partitionDelFileTuple._1();\n-        String delFileName = partitionDelFileTuple._2();\n-        Path deletePath = FSUtils.getPartitionPath(FSUtils.getPartitionPath(basePath, partitionPath), delFileName);\n+        Path deletePath = new Path(partitionDelFileTuple._2().getFilePath());\n         String deletePathStr = deletePath.toString();\n         Boolean deletedFileResult = deleteFileAndGetResult(fs, deletePathStr);\n         if (!partitionCleanStatMap.containsKey(partitionPath)) {\n           partitionCleanStatMap.put(partitionPath, new PartitionCleanStat(partitionPath));\n         }\n+        boolean isBootstrapBasePathFile = partitionDelFileTuple._2().isBootstrapBaseFile();\n         PartitionCleanStat partitionCleanStat = partitionCleanStatMap.get(partitionPath);\n-        partitionCleanStat.addDeleteFilePatterns(deletePath.getName());\n-        partitionCleanStat.addDeletedFileResult(deletePath.getName(), deletedFileResult);\n+        if (isBootstrapBasePathFile) {", "originalCommit": "896828d0340183369b8faf0c96721f446c30135f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODM3NTEzNg==", "url": "https://github.com/apache/hudi/pull/1870#discussion_r468375136", "bodyText": "deletePath.toString() returns a full path whereas deletePath.getName() returns only the file name.  That was the reason why it was in if-else block.", "author": "bvaradar", "createdAt": "2020-08-11T07:18:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Nzk0NzA5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Nzk1Mzk5OQ==", "url": "https://github.com/apache/hudi/pull/1870#discussion_r467953999", "bodyText": "CollectionUtils.emptyList or something?", "author": "vinothchandar", "createdAt": "2020-08-10T14:44:08Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/HoodieCleanStat.java", "diffHunk": "@@ -39,17 +40,34 @@\n   private final List<String> successDeleteFiles;\n   // Files that could not be deleted\n   private final List<String> failedDeleteFiles;\n+  // Boostrap Base Path patterns that were generated for the delete operation\n+  private final List<String> deleteBootstrapBasePathPatterns;\n+  private final List<String> successDeleteBootstrapBaseFiles;\n+  // Files that could not be deleted\n+  private final List<String> failedDeleteBootstrapBaseFiles;\n   // Earliest commit that was retained in this clean\n   private final String earliestCommitToRetain;\n \n   public HoodieCleanStat(HoodieCleaningPolicy policy, String partitionPath, List<String> deletePathPatterns,\n       List<String> successDeleteFiles, List<String> failedDeleteFiles, String earliestCommitToRetain) {\n+    this(policy, partitionPath, deletePathPatterns, successDeleteFiles, failedDeleteFiles, earliestCommitToRetain,\n+        new ArrayList<>(), new ArrayList<>(), new ArrayList<>());", "originalCommit": "896828d0340183369b8faf0c96721f446c30135f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODA2OTY5OQ==", "url": "https://github.com/apache/hudi/pull/1870#discussion_r468069699", "bodyText": "[typo] boostrap -> bootstrap", "author": "zhedoubushishi", "createdAt": "2020-08-10T17:39:33Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/HoodieCleanStat.java", "diffHunk": "@@ -39,17 +40,34 @@\n   private final List<String> successDeleteFiles;\n   // Files that could not be deleted\n   private final List<String> failedDeleteFiles;\n+  // Boostrap Base Path patterns that were generated for the delete operation", "originalCommit": "896828d0340183369b8faf0c96721f446c30135f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODA3MDQ3OA==", "url": "https://github.com/apache/hudi/pull/1870#discussion_r468070478", "bodyText": "[nit] wrong line", "author": "zhedoubushishi", "createdAt": "2020-08-10T17:40:59Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/HoodieCleanStat.java", "diffHunk": "@@ -18,6 +18,7 @@\n \n package org.apache.hudi.common;\n \n+import java.util.ArrayList;", "originalCommit": "896828d0340183369b8faf0c96721f446c30135f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODA3NjE0Mg==", "url": "https://github.com/apache/hudi/pull/1870#discussion_r468076142", "bodyText": "[nit] wrong line", "author": "zhedoubushishi", "createdAt": "2020-08-10T17:50:50Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/table/timeline/versioning/clean/CleanPlanV2MigrationHandler.java", "diffHunk": "@@ -0,0 +1,63 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.table.timeline.versioning.clean;\n+\n+import java.util.HashMap;", "originalCommit": "896828d0340183369b8faf0c96721f446c30135f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODA3OTEzMw==", "url": "https://github.com/apache/hudi/pull/1870#discussion_r468079133", "bodyText": "[nit] wrong line", "author": "zhedoubushishi", "createdAt": "2020-08-10T17:56:00Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/util/CleanerUtils.java", "diffHunk": "@@ -26,39 +26,49 @@\n import org.apache.hudi.common.table.timeline.HoodieInstant;\n import org.apache.hudi.common.table.timeline.TimelineMetadataUtils;\n import org.apache.hudi.common.table.timeline.versioning.clean.CleanMetadataMigrator;\n-import org.apache.hudi.common.table.timeline.versioning.clean.CleanV1MigrationHandler;\n-import org.apache.hudi.common.table.timeline.versioning.clean.CleanV2MigrationHandler;\n+import org.apache.hudi.common.table.timeline.versioning.clean.CleanMetadataV1MigrationHandler;\n+import org.apache.hudi.common.table.timeline.versioning.clean.CleanMetadataV2MigrationHandler;\n \n import java.io.IOException;\n import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n+import org.apache.hudi.common.table.timeline.versioning.clean.CleanPlanMigrator;", "originalCommit": "896828d0340183369b8faf0c96721f446c30135f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "dcad7aa9afca86e204dba67f678c2330bdc3fa41", "url": "https://github.com/apache/hudi/commit/dcad7aa9afca86e204dba67f678c2330bdc3fa41", "message": "[HUDI-808] Support cleaning bootstrap source data", "committedDate": "2020-08-11T05:19:53Z", "type": "commit"}, {"oid": "ee0e71b0416b4cd58c4e971f1d4a6807b08a34aa", "url": "https://github.com/apache/hudi/commit/ee0e71b0416b4cd58c4e971f1d4a6807b08a34aa", "message": "Address review comments", "committedDate": "2020-08-11T07:45:23Z", "type": "commit"}, {"oid": "ee0e71b0416b4cd58c4e971f1d4a6807b08a34aa", "url": "https://github.com/apache/hudi/commit/ee0e71b0416b4cd58c4e971f1d4a6807b08a34aa", "message": "Address review comments", "committedDate": "2020-08-11T07:45:23Z", "type": "forcePushed"}]}