{"pr_number": 1200, "pr_title": "[HUDI-514] A schema provider to get metadata through Jdbc", "pr_createdAt": "2020-01-09T08:11:49Z", "pr_url": "https://github.com/apache/hudi/pull/1200", "timeline": [{"oid": "9fa9644c724588aba68d490b74178bdff5b7278c", "url": "https://github.com/apache/hudi/commit/9fa9644c724588aba68d490b74178bdff5b7278c", "message": "A schema provider to get metadata through Jdbc", "committedDate": "2020-01-09T08:06:50Z", "type": "commit"}, {"oid": "1926c4490f42ee6cf48cb523e7bd9be9a6cf4d73", "url": "https://github.com/apache/hudi/commit/1926c4490f42ee6cf48cb523e7bd9be9a6cf4d73", "message": "addition maven compile dependency", "committedDate": "2020-01-09T09:58:28Z", "type": "commit"}, {"oid": "b821f630b3f61eab3ac1902c1eed8843291f3de2", "url": "https://github.com/apache/hudi/commit/b821f630b3f61eab3ac1902c1eed8843291f3de2", "message": "Optimize code and provide test cases", "committedDate": "2020-01-13T07:56:47Z", "type": "commit"}, {"oid": "f78a11b335cfe74cb7dc27cb7cd80179c731931d", "url": "https://github.com/apache/hudi/commit/f78a11b335cfe74cb7dc27cb7cd80179c731931d", "message": "Merge branch 'master' into jdbc-provider", "committedDate": "2020-01-13T08:24:06Z", "type": "commit"}, {"oid": "368fa3c7eabedbe910f23bacc9a03c76734c3a18", "url": "https://github.com/apache/hudi/commit/368fa3c7eabedbe910f23bacc9a03c76734c3a18", "message": "Merge branch 'github-master' into jdbc-provider\n\n# Conflicts:\n#\thudi-utilities/src/test/java/org/apache/hudi/utilities/TestHoodieDeltaStreamer.java", "committedDate": "2020-01-14T02:16:38Z", "type": "commit"}, {"oid": "fa755374671875743e1ed3709ed37c5203e22273", "url": "https://github.com/apache/hudi/commit/fa755374671875743e1ed3709ed37c5203e22273", "message": "Merge remote-tracking branch 'origin/jdbc-provider' into jdbc-provider\n\n# Conflicts:\n#\thudi-utilities/src/test/java/org/apache/hudi/utilities/TestHoodieDeltaStreamer.java", "committedDate": "2020-01-14T02:16:59Z", "type": "commit"}, {"oid": "bf6bbd9e7d2750706db510a432863853d10f53a9", "url": "https://github.com/apache/hudi/commit/bf6bbd9e7d2750706db510a432863853d10f53a9", "message": "update code to fit spark 2.4.4 version", "committedDate": "2020-01-14T03:09:16Z", "type": "commit"}, {"oid": "2a69e3a259e5b164a40dcf8ad5a6742073a4339f", "url": "https://github.com/apache/hudi/commit/2a69e3a259e5b164a40dcf8ad5a6742073a4339f", "message": "Merge branch 'github-master' into jdbc-provider", "committedDate": "2020-01-14T05:36:52Z", "type": "commit"}, {"oid": "0a4cffeb68b4bae34f9984447d38a58a25074c0c", "url": "https://github.com/apache/hudi/commit/0a4cffeb68b4bae34f9984447d38a58a25074c0c", "message": "fix bug", "committedDate": "2020-01-14T06:26:16Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE4MjEzNQ==", "url": "https://github.com/apache/hudi/pull/1200#discussion_r366182135", "bodyText": "rename to getJDBCSchema?", "author": "vinothchandar", "createdAt": "2020-01-14T07:20:51Z", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/UtilHelpers.java", "diffHunk": "@@ -236,4 +250,57 @@ public static TypedProperties readConfig(InputStream in) throws IOException {\n     defaults.load(in);\n     return defaults;\n   }\n+\n+  /***\n+   * call spark function get the schema through jdbc.\n+   * @param options\n+   * @return\n+   * @throws Exception\n+   */\n+  public static Schema getSchema(Map<String, String> options) throws Exception {", "originalCommit": "0a4cffeb68b4bae34f9984447d38a58a25074c0c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE4MzA0MQ==", "url": "https://github.com/apache/hudi/pull/1200#discussion_r366183041", "bodyText": "change to table does not exist!?", "author": "vinothchandar", "createdAt": "2020-01-14T07:24:17Z", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/UtilHelpers.java", "diffHunk": "@@ -236,4 +250,57 @@ public static TypedProperties readConfig(InputStream in) throws IOException {\n     defaults.load(in);\n     return defaults;\n   }\n+\n+  /***\n+   * call spark function get the schema through jdbc.\n+   * @param options\n+   * @return\n+   * @throws Exception\n+   */\n+  public static Schema getSchema(Map<String, String> options) throws Exception {\n+    scala.collection.immutable.Map<String, String> ioptions = toScalaImmutableMap(options);\n+    JDBCOptions jdbcOptions = new JDBCOptions(ioptions);\n+    Connection conn = JdbcUtils.createConnectionFactory(jdbcOptions).apply();\n+    String url = jdbcOptions.url();\n+    String table = jdbcOptions.tableOrQuery();\n+    JdbcOptionsInWrite jdbcOptionsInWrite = new JdbcOptionsInWrite(ioptions);\n+    boolean tableExists = JdbcUtils.tableExists(conn, jdbcOptionsInWrite);\n+    if (tableExists) {\n+      JdbcDialect dialect = JdbcDialects.get(url);\n+      try {\n+        PreparedStatement statement = conn.prepareStatement(dialect.getSchemaQuery(table));\n+        try {\n+          statement.setQueryTimeout(Integer.parseInt(options.get(\"timeout\")));\n+          ResultSet rs = statement.executeQuery();\n+          try {\n+            StructType structType;\n+            if (Boolean.parseBoolean(ioptions.get(\"nullable\").get())) {\n+              structType = JdbcUtils.getSchema(rs, dialect, true);\n+            } else {\n+              structType = JdbcUtils.getSchema(rs, dialect, false);\n+            }\n+            return AvroConversionUtils.convertStructTypeToAvroSchema(structType, table, \"hoodie.\" + table);\n+          } finally {\n+            rs.close();\n+          }\n+        } finally {\n+          statement.close();\n+        }\n+      } finally {\n+        conn.close();\n+      }\n+    } else {\n+      throw new HoodieException(String.format(\"%s table not exists!\", table));", "originalCommit": "0a4cffeb68b4bae34f9984447d38a58a25074c0c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE4MzMyNg==", "url": "https://github.com/apache/hudi/pull/1200#discussion_r366183326", "bodyText": "import the java collection classes?Map, List, ArrayList ?", "author": "vinothchandar", "createdAt": "2020-01-14T07:25:29Z", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/UtilHelpers.java", "diffHunk": "@@ -236,4 +250,57 @@ public static TypedProperties readConfig(InputStream in) throws IOException {\n     defaults.load(in);\n     return defaults;\n   }\n+\n+  /***\n+   * call spark function get the schema through jdbc.\n+   * @param options\n+   * @return\n+   * @throws Exception\n+   */\n+  public static Schema getSchema(Map<String, String> options) throws Exception {\n+    scala.collection.immutable.Map<String, String> ioptions = toScalaImmutableMap(options);\n+    JDBCOptions jdbcOptions = new JDBCOptions(ioptions);\n+    Connection conn = JdbcUtils.createConnectionFactory(jdbcOptions).apply();\n+    String url = jdbcOptions.url();\n+    String table = jdbcOptions.tableOrQuery();\n+    JdbcOptionsInWrite jdbcOptionsInWrite = new JdbcOptionsInWrite(ioptions);\n+    boolean tableExists = JdbcUtils.tableExists(conn, jdbcOptionsInWrite);\n+    if (tableExists) {\n+      JdbcDialect dialect = JdbcDialects.get(url);\n+      try {\n+        PreparedStatement statement = conn.prepareStatement(dialect.getSchemaQuery(table));\n+        try {\n+          statement.setQueryTimeout(Integer.parseInt(options.get(\"timeout\")));\n+          ResultSet rs = statement.executeQuery();\n+          try {\n+            StructType structType;\n+            if (Boolean.parseBoolean(ioptions.get(\"nullable\").get())) {\n+              structType = JdbcUtils.getSchema(rs, dialect, true);\n+            } else {\n+              structType = JdbcUtils.getSchema(rs, dialect, false);\n+            }\n+            return AvroConversionUtils.convertStructTypeToAvroSchema(structType, table, \"hoodie.\" + table);\n+          } finally {\n+            rs.close();\n+          }\n+        } finally {\n+          statement.close();\n+        }\n+      } finally {\n+        conn.close();\n+      }\n+    } else {\n+      throw new HoodieException(String.format(\"%s table not exists!\", table));\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unchecked\")\n+  private static <K, V> scala.collection.immutable.Map<K, V> toScalaImmutableMap(java.util.Map<K, V> javaMap) {", "originalCommit": "0a4cffeb68b4bae34f9984447d38a58a25074c0c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjMwOTkxMw==", "url": "https://github.com/apache/hudi/pull/1200#discussion_r366309913", "bodyText": "Because the underlying spark function only accepts parameters of type scala.collection.immutable.Map, I provide a private conversion function from java map to scala immutable Map.", "author": "OpenOpened", "createdAt": "2020-01-14T12:27:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE4MzMyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Njc4NDU5Mg==", "url": "https://github.com/apache/hudi/pull/1200#discussion_r376784592", "bodyText": "also is the method(toScalaImmutableMap) copied from other projects or implemented on our own?", "author": "leesf", "createdAt": "2020-02-09T13:37:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE4MzMyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjE4MzU1NA==", "url": "https://github.com/apache/hudi/pull/1200#discussion_r366183554", "bodyText": "can we create a separate test class for this? given you are only testing the schema provider?", "author": "vinothchandar", "createdAt": "2020-01-14T07:26:30Z", "path": "hudi-utilities/src/test/java/org/apache/hudi/utilities/TestHoodieDeltaStreamer.java", "diffHunk": "@@ -511,6 +524,22 @@ public void testNullSchemaProvider() throws Exception {\n     }\n   }\n \n+  @Test\n+  public void testJdbcbasedSchemaProvider() throws Exception {", "originalCommit": "0a4cffeb68b4bae34f9984447d38a58a25074c0c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "95d404a1bbc97d087354927b176639bb797048e9", "url": "https://github.com/apache/hudi/commit/95d404a1bbc97d087354927b176639bb797048e9", "message": "Optimize code", "committedDate": "2020-01-14T08:49:31Z", "type": "commit"}, {"oid": "83c671d81e5852240d321a4aba3a009be0aa54a7", "url": "https://github.com/apache/hudi/commit/83c671d81e5852240d321a4aba3a009be0aa54a7", "message": "Merge branch 'github-master' into jdbc-provider", "committedDate": "2020-01-14T09:21:19Z", "type": "commit"}, {"oid": "de0566a92663ec85d0e0aa61622a528331e14482", "url": "https://github.com/apache/hudi/commit/de0566a92663ec85d0e0aa61622a528331e14482", "message": "auto close jsc object", "committedDate": "2020-01-14T10:34:36Z", "type": "commit"}, {"oid": "ad18cae7d5bd69c2166caf2c26010cd4ffabee59", "url": "https://github.com/apache/hudi/commit/ad18cae7d5bd69c2166caf2c26010cd4ffabee59", "message": "Adding license to TestJdbcbasedSchemaProvider class", "committedDate": "2020-01-26T18:59:52Z", "type": "commit"}, {"oid": "f53e725d2354bc6eeb54d2819ddb1611b1625c60", "url": "https://github.com/apache/hudi/commit/f53e725d2354bc6eeb54d2819ddb1611b1625c60", "message": "Merge branch 'github-master' into jdbc-provider\n\n# Conflicts:\n#\thudi-utilities/src/main/java/org/apache/hudi/utilities/UtilHelpers.java", "committedDate": "2020-02-08T11:28:25Z", "type": "commit"}, {"oid": "13e80e2068bfec0df08573e260d896f966cf86b8", "url": "https://github.com/apache/hudi/commit/13e80e2068bfec0df08573e260d896f966cf86b8", "message": "Merge remote-tracking branch 'origin/jdbc-provider' into jdbc-provider", "committedDate": "2020-02-08T11:28:30Z", "type": "commit"}, {"oid": "d18385136e454b56d4aa0cd4470c7c426aa0965a", "url": "https://github.com/apache/hudi/commit/d18385136e454b56d4aa0cd4470c7c426aa0965a", "message": "fix bug and resolve conflict", "committedDate": "2020-02-08T11:44:26Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjcwNTY5MA==", "url": "https://github.com/apache/hudi/pull/1200#discussion_r376705690", "bodyText": "Would be changed to try-with-resources? since try-catch-finnaly has been optimized to try-with-resources in the project now.", "author": "leesf", "createdAt": "2020-02-08T11:51:30Z", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/UtilHelpers.java", "diffHunk": "@@ -235,4 +248,57 @@ public static TypedProperties readConfig(InputStream in) throws IOException {\n     defaults.load(in);\n     return defaults;\n   }\n+\n+  /***\n+   * call spark function get the schema through jdbc.\n+   * @param options\n+   * @return\n+   * @throws Exception\n+   */\n+  public static Schema getJDBCSchema(Map<String, String> options) throws Exception {\n+    scala.collection.immutable.Map<String, String> ioptions = toScalaImmutableMap(options);\n+    JDBCOptions jdbcOptions = new JDBCOptions(ioptions);\n+    Connection conn = JdbcUtils.createConnectionFactory(jdbcOptions).apply();\n+    String url = jdbcOptions.url();\n+    String table = jdbcOptions.tableOrQuery();\n+    JdbcOptionsInWrite jdbcOptionsInWrite = new JdbcOptionsInWrite(ioptions);\n+    boolean tableExists = JdbcUtils.tableExists(conn, jdbcOptionsInWrite);\n+    if (tableExists) {\n+      JdbcDialect dialect = JdbcDialects.get(url);\n+      try {\n+        PreparedStatement statement = conn.prepareStatement(dialect.getSchemaQuery(table));\n+        try {\n+          statement.setQueryTimeout(Integer.parseInt(options.get(\"timeout\")));\n+          ResultSet rs = statement.executeQuery();\n+          try {\n+            StructType structType;\n+            if (Boolean.parseBoolean(ioptions.get(\"nullable\").get())) {\n+              structType = JdbcUtils.getSchema(rs, dialect, true);\n+            } else {\n+              structType = JdbcUtils.getSchema(rs, dialect, false);\n+            }\n+            return AvroConversionUtils.convertStructTypeToAvroSchema(structType, table, \"hoodie.\" + table);\n+          } finally {\n+            rs.close();\n+          }\n+        } finally {\n+          statement.close();\n+        }\n+      } finally {\n+        conn.close();\n+      }", "originalCommit": "d18385136e454b56d4aa0cd4470c7c426aa0965a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjcwODEwOA==", "url": "https://github.com/apache/hudi/pull/1200#discussion_r376708108", "bodyText": "thank you for your advice. i wll do it.", "author": "OpenOpened", "createdAt": "2020-02-08T12:45:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjcwNTY5MA=="}], "type": "inlineReview"}, {"oid": "57061ed4cc570c1c89739ddb020b000d534c7e5d", "url": "https://github.com/apache/hudi/commit/57061ed4cc570c1c89739ddb020b000d534c7e5d", "message": "try-with-resources code optimize", "committedDate": "2020-02-08T13:05:49Z", "type": "commit"}, {"oid": "013babffb8e5f221d34812c0b19950e8b7dfb60e", "url": "https://github.com/apache/hudi/commit/013babffb8e5f221d34812c0b19950e8b7dfb60e", "message": "fix code style problem", "committedDate": "2020-02-08T14:00:04Z", "type": "commit"}, {"oid": "450dde982f8c4550c088a15048fe9a10d3c70729", "url": "https://github.com/apache/hudi/commit/450dde982f8c4550c088a15048fe9a10d3c70729", "message": "fix variable name", "committedDate": "2020-02-08T14:57:09Z", "type": "commit"}, {"oid": "f7914c163e895ad103278c22bd11eb4e07fd368a", "url": "https://github.com/apache/hudi/commit/f7914c163e895ad103278c22bd11eb4e07fd368a", "message": "addition a little comments", "committedDate": "2020-02-10T03:39:57Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzA0ODY3OA==", "url": "https://github.com/apache/hudi/pull/1200#discussion_r377048678", "bodyText": "I think we could remove this line, If we copy from other projects, we may need add copyright to LICENSE. but if copied from stackoverflow, it would be removed.", "author": "leesf", "createdAt": "2020-02-10T13:03:04Z", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/UtilHelpers.java", "diffHunk": "@@ -235,4 +248,57 @@ public static TypedProperties readConfig(InputStream in) throws IOException {\n     defaults.load(in);\n     return defaults;\n   }\n+\n+  /***\n+   * call spark function get the schema through jdbc.\n+   * The code logic implementation refers to spark 2.4.x and spark 3.x.\n+   * @param options\n+   * @return\n+   * @throws Exception\n+   */\n+  public static Schema getJDBCSchema(Map<String, String> options) throws Exception {\n+    scala.collection.immutable.Map<String, String> ioptions = toScalaImmutableMap(options);\n+    JDBCOptions jdbcOptions = new JDBCOptions(ioptions);\n+    Connection conn = JdbcUtils.createConnectionFactory(jdbcOptions).apply();\n+    String url = jdbcOptions.url();\n+    String table = jdbcOptions.tableOrQuery();\n+    JdbcOptionsInWrite jdbcOptionsInWrite = new JdbcOptionsInWrite(ioptions);\n+    boolean tableExists = JdbcUtils.tableExists(conn, jdbcOptionsInWrite);\n+\n+    if (tableExists) {\n+      JdbcDialect dialect = JdbcDialects.get(url);\n+      try (PreparedStatement statement = conn.prepareStatement(dialect.getSchemaQuery(table))) {\n+        statement.setQueryTimeout(Integer.parseInt(options.get(\"timeout\")));\n+        try (ResultSet rs = statement.executeQuery()) {\n+          StructType structType;\n+          if (Boolean.parseBoolean(ioptions.get(\"nullable\").get())) {\n+            structType = JdbcUtils.getSchema(rs, dialect, true);\n+          } else {\n+            structType = JdbcUtils.getSchema(rs, dialect, false);\n+          }\n+          return AvroConversionUtils.convertStructTypeToAvroSchema(structType, table, \"hoodie.\" + table);\n+        }\n+      }\n+    } else {\n+      throw new HoodieException(String.format(\"%s table does not exists!\", table));\n+    }\n+  }\n+\n+  /**\n+   * Replace java map with scala immutable map.\n+   * refers: https://stackoverflow.com/questions/11903167/convert-java-util-hashmap-to-scala-collection-immutable-map-in-java/11903737#11903737", "originalCommit": "f7914c163e895ad103278c22bd11eb4e07fd368a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzA3ODUxMA==", "url": "https://github.com/apache/hudi/pull/1200#discussion_r377078510", "bodyText": "ok, i will remove it.", "author": "OpenOpened", "createdAt": "2020-02-10T14:00:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzA0ODY3OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODAzNTE2Ng==", "url": "https://github.com/apache/hudi/pull/1200#discussion_r378035166", "bodyText": "Sorry to be a pain. but this piece of code would be problematic since its exactly https://stackoverflow.com/a/45992769 ? Please re-implement this", "author": "vinothchandar", "createdAt": "2020-02-12T04:26:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzA0ODY3OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODA1NTI4OA==", "url": "https://github.com/apache/hudi/pull/1200#discussion_r378055288", "bodyText": "Do you guys have a better way? I checked the relevant information. If you want to achieve conversion elegantly, there are only two methods. First, using scala code to do the conversion, you need to implement a scala conversion class. Second, rewrite the related spark method with java. The disadvantage is that it may cause compatibility problems in the future.", "author": "OpenOpened", "createdAt": "2020-02-12T06:06:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzA0ODY3OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODEzNDU3Mg==", "url": "https://github.com/apache/hudi/pull/1200#discussion_r378134572", "bodyText": "@vinothchandar @leesf I reimplemented the relevant logic using the second approach.", "author": "OpenOpened", "createdAt": "2020-02-12T09:37:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzA0ODY3OA=="}], "type": "inlineReview"}, {"oid": "a44a52a4e60532beaeb75fa136571542328d0308", "url": "https://github.com/apache/hudi/commit/a44a52a4e60532beaeb75fa136571542328d0308", "message": "remove extra comments", "committedDate": "2020-02-10T14:01:51Z", "type": "commit"}, {"oid": "ca14ac95db69fc7701e0453df01119d42204f509", "url": "https://github.com/apache/hudi/commit/ca14ac95db69fc7701e0453df01119d42204f509", "message": "reimplement code using java", "committedDate": "2020-02-12T08:19:31Z", "type": "commit"}]}