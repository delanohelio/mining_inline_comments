{"pr_number": 1848, "pr_title": "[HUDI-69] Support Spark Datasource for MOR table - RDD approach", "pr_createdAt": "2020-07-20T01:06:48Z", "pr_url": "https://github.com/apache/hudi/pull/1848", "timeline": [{"oid": "45015db2ab95da640d9ba7ddfdfb5799970cf19d", "url": "https://github.com/apache/hudi/commit/45015db2ab95da640d9ba7ddfdfb5799970cf19d", "message": "[HUDI-69] Support Spark Datasource for MOR table", "committedDate": "2020-07-21T05:14:51Z", "type": "forcePushed"}, {"oid": "bdda1d6650365c616d233503e3ca8994cd0922cc", "url": "https://github.com/apache/hudi/commit/bdda1d6650365c616d233503e3ca8994cd0922cc", "message": "[HUDI-69] Support Spark Datasource for MOR table", "committedDate": "2020-07-21T05:22:59Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzg2MzgxOA==", "url": "https://github.com/apache/hudi/pull/1848#discussion_r457863818", "bodyText": "hows this different from the class we already have in hudi-common : SerializableConfiguration ?", "author": "vinothchandar", "createdAt": "2020-07-21T06:24:41Z", "path": "hudi-hadoop-mr/src/main/java/org/apache/hudi/hadoop/config/HadoopSerializableConfiguration.java", "diffHunk": "@@ -0,0 +1,43 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.hadoop.config;\n+\n+import org.apache.hadoop.conf.Configuration;\n+\n+import java.io.IOException;\n+import java.io.ObjectInputStream;\n+import java.io.ObjectOutputStream;\n+import java.io.Serializable;\n+\n+public class HadoopSerializableConfiguration implements Serializable {", "originalCommit": "bdda1d6650365c616d233503e3ca8994cd0922cc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODIxMzgzMQ==", "url": "https://github.com/apache/hudi/pull/1848#discussion_r458213831", "bodyText": "Didn't know this. Will switch over.", "author": "garyli1019", "createdAt": "2020-07-21T16:04:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzg2MzgxOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODU0MzQ2Nw==", "url": "https://github.com/apache/hudi/pull/1848#discussion_r458543467", "bodyText": "done", "author": "garyli1019", "createdAt": "2020-07-22T05:30:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzg2MzgxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzg2Mzk5NA==", "url": "https://github.com/apache/hudi/pull/1848#discussion_r457863994", "bodyText": "why remove this?", "author": "vinothchandar", "createdAt": "2020-07-21T06:25:06Z", "path": "hudi-hadoop-mr/src/main/java/org/apache/hudi/hadoop/realtime/AbstractRealtimeRecordReader.java", "diffHunk": "@@ -147,12 +146,4 @@ public Schema getWriterSchema() {\n   public Schema getHiveSchema() {\n     return hiveSchema;\n   }\n-\n-  public long getMaxCompactionMemoryInBytes() {", "originalCommit": "bdda1d6650365c616d233503e3ca8994cd0922cc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODIxNTA5Mw==", "url": "https://github.com/apache/hudi/pull/1848#discussion_r458215093", "bodyText": "Moved to a utils class. Need to call this method from HoodieMergeOnReadRDD", "author": "garyli1019", "createdAt": "2020-07-21T16:06:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzg2Mzk5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzg2NDQzNQ==", "url": "https://github.com/apache/hudi/pull/1848#discussion_r457864435", "bodyText": "seems good to avoid the static import here and have the reader realize the class its coming from ?", "author": "vinothchandar", "createdAt": "2020-07-21T06:26:12Z", "path": "hudi-hadoop-mr/src/main/java/org/apache/hudi/hadoop/realtime/RealtimeCompactedRecordReader.java", "diffHunk": "@@ -40,6 +40,8 @@\n import java.io.IOException;\n import java.util.Map;\n \n+import static org.apache.hudi.hadoop.utils.HoodieRealtimeRecordReaderUtils.getMaxCompactionMemoryInBytes;", "originalCommit": "bdda1d6650365c616d233503e3ca8994cd0922cc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODU0NDUzOA==", "url": "https://github.com/apache/hudi/pull/1848#discussion_r458544538", "bodyText": "done", "author": "garyli1019", "createdAt": "2020-07-22T05:33:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzg2NDQzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzg2NDc3MA==", "url": "https://github.com/apache/hudi/pull/1848#discussion_r457864770", "bodyText": "ah ok. its just relocated", "author": "vinothchandar", "createdAt": "2020-07-21T06:26:54Z", "path": "hudi-hadoop-mr/src/main/java/org/apache/hudi/hadoop/utils/HoodieRealtimeRecordReaderUtils.java", "diffHunk": "@@ -69,6 +71,17 @@ public static Schema readSchema(Configuration conf, Path filePath) {\n     }\n   }\n \n+  /**\n+   * get the max compaction memory in bytes from JobConf.\n+   */\n+  public static long getMaxCompactionMemoryInBytes(JobConf jobConf) {", "originalCommit": "bdda1d6650365c616d233503e3ca8994cd0922cc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "a4c7069abaafc7faa0476d6a190a6cf55fbd2bbe", "url": "https://github.com/apache/hudi/commit/a4c7069abaafc7faa0476d6a190a6cf55fbd2bbe", "message": "[HUDI-69] Support Spark Datasource for MOR table", "committedDate": "2020-07-22T05:59:19Z", "type": "forcePushed"}, {"oid": "41d1d05d1baa05b89f7bdbdc4458d3e8926f8982", "url": "https://github.com/apache/hudi/commit/41d1d05d1baa05b89f7bdbdc4458d3e8926f8982", "message": "[HUDI-69] Support Spark Datasource for MOR table", "committedDate": "2020-07-22T06:02:19Z", "type": "forcePushed"}, {"oid": "f38c76c784b9ba462bfefbf7700a762f70ca2087", "url": "https://github.com/apache/hudi/commit/f38c76c784b9ba462bfefbf7700a762f70ca2087", "message": "[HUDI-69] Support Spark Datasource for MOR table", "committedDate": "2020-07-22T17:35:30Z", "type": "forcePushed"}, {"oid": "5b051e575463e11aa9b30ee62c01ef5546151114", "url": "https://github.com/apache/hudi/commit/5b051e575463e11aa9b30ee62c01ef5546151114", "message": "[HUDI-69] Support Spark Datasource for MOR table", "committedDate": "2020-07-22T17:42:53Z", "type": "forcePushed"}, {"oid": "eefad4beb4f15864b1ea9925b0d4f54deba776fc", "url": "https://github.com/apache/hudi/commit/eefad4beb4f15864b1ea9925b0d4f54deba776fc", "message": "[HUDI-69] Support PruneFilteredScan", "committedDate": "2020-07-26T23:22:32Z", "type": "forcePushed"}, {"oid": "d8ef9d3dd2eed57983ccb43f235806be848f11e3", "url": "https://github.com/apache/hudi/commit/d8ef9d3dd2eed57983ccb43f235806be848f11e3", "message": "[HUDI-69] Support PruneFilteredScan", "committedDate": "2020-07-27T03:24:55Z", "type": "forcePushed"}, {"oid": "4b05f0f7b12e083b66084b11a80a207f33bd7dcc", "url": "https://github.com/apache/hudi/commit/4b05f0f7b12e083b66084b11a80a207f33bd7dcc", "message": "[HUDI-69] Support PruneFilteredScan", "committedDate": "2020-07-27T20:39:19Z", "type": "forcePushed"}, {"oid": "e6c77567658e73a3db26681ed25e54c8214ca1cd", "url": "https://github.com/apache/hudi/commit/e6c77567658e73a3db26681ed25e54c8214ca1cd", "message": "[HUDI-69] Support PruneFilteredScan", "committedDate": "2020-07-29T04:43:38Z", "type": "forcePushed"}, {"oid": "8f6c63b91d8af0430a35df843c3e6e722d1d6dc5", "url": "https://github.com/apache/hudi/commit/8f6c63b91d8af0430a35df843c3e6e722d1d6dc5", "message": "[HUDI-69] Remove unnecessary payload config", "committedDate": "2020-08-04T05:48:47Z", "type": "forcePushed"}, {"oid": "73a10478e2d6aed717b9701a4cf6745ea6d27aaa", "url": "https://github.com/apache/hudi/commit/73a10478e2d6aed717b9701a4cf6745ea6d27aaa", "message": "[HUDI-69] SUPPORT Spark Datasource for MOR table", "committedDate": "2020-08-04T06:01:51Z", "type": "forcePushed"}, {"oid": "a2b1467e7961a88ca91a3657807039351b64d834", "url": "https://github.com/apache/hudi/commit/a2b1467e7961a88ca91a3657807039351b64d834", "message": "[HUDI-69] SUPPORT Spark Datasource for MOR table\n\n- This PR implements Spark Datasource for MOR table in the RDD approach.\n- Implemented SnapshotRelation\n- Implemented HudiMergeOnReadRDD\n- Implemented separate Iterator to handle merge and unmerge record reader.\n- Added TestMORDataSource to verify this feature.", "committedDate": "2020-08-04T06:52:55Z", "type": "forcePushed"}, {"oid": "496daba54f981b082b6da8cfd642c5ec748b9b58", "url": "https://github.com/apache/hudi/commit/496daba54f981b082b6da8cfd642c5ec748b9b58", "message": "[HUDI-69] SUPPORT Spark Datasource for MOR table\n\n- This PR implements Spark Datasource for MOR table in the RDD approach.\n- Implemented SnapshotRelation\n- Implemented HudiMergeOnReadRDD\n- Implemented separate Iterator to handle merge and unmerge record reader.\n- Added TestMORDataSource to verify this feature.", "committedDate": "2020-08-04T17:21:48Z", "type": "forcePushed"}, {"oid": "52066a3d867682a010a41c1c11b638615edef674", "url": "https://github.com/apache/hudi/commit/52066a3d867682a010a41c1c11b638615edef674", "message": "[HUDI-69] SUPPORT Spark Datasource for MOR table\n\n- This PR implements Spark Datasource for MOR table in the RDD approach.\n- Implemented SnapshotRelation\n- Implemented HudiMergeOnReadRDD\n- Implemented separate Iterator to handle merge and unmerge record reader.\n- Added TestMORDataSource to verify this feature.", "committedDate": "2020-08-04T20:31:04Z", "type": "forcePushed"}, {"oid": "9e50d46c03a50e4fbd372f1dffdf6e0e84585c79", "url": "https://github.com/apache/hudi/commit/9e50d46c03a50e4fbd372f1dffdf6e0e84585c79", "message": "fix flaky test", "committedDate": "2020-08-04T22:44:15Z", "type": "forcePushed"}, {"oid": "1bbb23d04a483802407f85d98c89668f19be881b", "url": "https://github.com/apache/hudi/commit/1bbb23d04a483802407f85d98c89668f19be881b", "message": "Adding debug statements for test failure", "committedDate": "2020-08-05T13:50:43Z", "type": "forcePushed"}, {"oid": "a053967b65240ee394e2a33c228fe617c203d8f6", "url": "https://github.com/apache/hudi/commit/a053967b65240ee394e2a33c228fe617c203d8f6", "message": "Adding debug statements for test failure", "committedDate": "2020-08-05T16:20:46Z", "type": "forcePushed"}, {"oid": "fc5425ddeb2ac075f230793c5ff7906786fc66f3", "url": "https://github.com/apache/hudi/commit/fc5425ddeb2ac075f230793c5ff7906786fc66f3", "message": "Adding debug statements for test failure", "committedDate": "2020-08-06T05:35:01Z", "type": "forcePushed"}, {"oid": "dcd26632c4c17f72fb6d96b1c65e8fed5a83e437", "url": "https://github.com/apache/hudi/commit/dcd26632c4c17f72fb6d96b1c65e8fed5a83e437", "message": "Adding debug statements for test failure", "committedDate": "2020-08-06T06:02:04Z", "type": "forcePushed"}, {"oid": "15f95a2c560fa5bc03b97db0591d518635257e3a", "url": "https://github.com/apache/hudi/commit/15f95a2c560fa5bc03b97db0591d518635257e3a", "message": "Adding debug statements for test failure", "committedDate": "2020-08-06T06:36:05Z", "type": "forcePushed"}, {"oid": "a9533a099cacd86e79b65c483d41397ad62ff76f", "url": "https://github.com/apache/hudi/commit/a9533a099cacd86e79b65c483d41397ad62ff76f", "message": "Adding debug statements for test failure", "committedDate": "2020-08-06T07:32:54Z", "type": "forcePushed"}, {"oid": "f70258dacf59e80888f5c95c93dfbc7e5ab90164", "url": "https://github.com/apache/hudi/commit/f70258dacf59e80888f5c95c93dfbc7e5ab90164", "message": "Adding debug statements for test failure", "committedDate": "2020-08-06T07:48:32Z", "type": "forcePushed"}, {"oid": "52a4532e75ae50cffbc4c3daaddbb6827c251975", "url": "https://github.com/apache/hudi/commit/52a4532e75ae50cffbc4c3daaddbb6827c251975", "message": "Adding debug statements for test failure", "committedDate": "2020-08-06T08:30:50Z", "type": "forcePushed"}, {"oid": "4731d25e1223ca025df6a146ae8760f2f81d99d8", "url": "https://github.com/apache/hudi/commit/4731d25e1223ca025df6a146ae8760f2f81d99d8", "message": "[HUDI-69] Support Spark Datasource for MOR table\n- This PR implements Spark Datasource for MOR table in the RDD approach.\n- Implemented SnapshotRelation\n- Implemented HudiMergeOnReadRDD\n- Implemented separate Iterator to handle merge and unmerge record reader.\n- Added TestMORDataSource to verify this feature.", "committedDate": "2020-08-06T21:08:50Z", "type": "commit"}, {"oid": "d8beca97ef56b1fd1aac2ea9241d82d41103776f", "url": "https://github.com/apache/hudi/commit/d8beca97ef56b1fd1aac2ea9241d82d41103776f", "message": "[MINOR] fix some tests to pass CI", "committedDate": "2020-08-06T21:12:09Z", "type": "commit"}, {"oid": "d8beca97ef56b1fd1aac2ea9241d82d41103776f", "url": "https://github.com/apache/hudi/commit/d8beca97ef56b1fd1aac2ea9241d82d41103776f", "message": "[MINOR] fix some tests to pass CI", "committedDate": "2020-08-06T21:12:09Z", "type": "forcePushed"}, {"oid": "60cec20ba14076e94f365269d2e68cf41fabc508", "url": "https://github.com/apache/hudi/commit/60cec20ba14076e94f365269d2e68cf41fabc508", "message": "Clean up test file name, add tests for mixed query type tests\n\n - We can now revert the change made in DefaultSource", "committedDate": "2020-08-07T06:35:08Z", "type": "commit"}]}