{"pr_number": 1964, "pr_title": "[HUDI-1191] Add incremental meta client API to query partitions changed", "pr_createdAt": "2020-08-14T00:18:39Z", "pr_url": "https://github.com/apache/hudi/pull/1964", "timeline": [{"oid": "aa3d03eabc61572dc85e5f8d5b9f8979455fc792", "url": "https://github.com/apache/hudi/commit/aa3d03eabc61572dc85e5f8d5b9f8979455fc792", "message": "[HUDI-1191] Add incremental meta client API to query partitions modified in a time window", "committedDate": "2020-08-14T00:37:33Z", "type": "forcePushed"}, {"oid": "f0cd600d209d9ca370ea4ba0ff1536867fc706d0", "url": "https://github.com/apache/hudi/commit/f0cd600d209d9ca370ea4ba0ff1536867fc706d0", "message": "[HUDI-1191] Add incremental meta client API to query partitions modified in a time window", "committedDate": "2020-08-24T20:24:42Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTg5MjY4OA==", "url": "https://github.com/apache/hudi/pull/1964#discussion_r475892688", "bodyText": "I don't think this makes sense in the timeline as of now. If you take a look at the timeline API's,  they only talk about the metadata that has changed. getPartitionsMutated conceptually is providing what has changed in the underlying data as opposed to what has changed in the timeline per se. Generally, all of this information should come from the timeline but that requires a full redesign on the timeline. Should we add this API here -> https://github.com/apache/hudi/blob/master/hudi-client/src/main/java/org/apache/hudi/client/HoodieReadClient.java#L195 ? And you can wrap this functionality in a TimelineUtils ?\nWhen we have clearer design on timeline, we can merge back the TimelineUtils to the real timeline...", "author": "n3nash", "createdAt": "2020-08-24T21:03:16Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/table/timeline/HoodieTimeline.java", "diffHunk": "@@ -232,6 +233,12 @@\n    */\n   Option<byte[]> getInstantDetails(HoodieInstant instant);\n \n+  /**\n+   * Returns partitions that have been modified in the timeline. This includes internal operations such as clean.\n+   * Note that this only returns data for completed instants.\n+   */\n+  List<String> getPartitionsMutated();", "originalCommit": "f0cd600d209d9ca370ea4ba0ff1536867fc706d0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTg5NTYxNw==", "url": "https://github.com/apache/hudi/pull/1964#discussion_r475895617", "bodyText": "+1 on abstraction point. I think having a separate helper class would be better.", "author": "bvaradar", "createdAt": "2020-08-24T21:09:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTg5MjY4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTkwMTUzNA==", "url": "https://github.com/apache/hudi/pull/1964#discussion_r475901534", "bodyText": "@n3nash I want this to be in hudi-common, so this can be reused in hadoop-mr and hive-sync.  Do you want me to create TimelineUtils in common?", "author": "satishkotha", "createdAt": "2020-08-24T21:21:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTg5MjY4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTkxOTI1NA==", "url": "https://github.com/apache/hudi/pull/1964#discussion_r475919254", "bodyText": "created TimelineUtils", "author": "satishkotha", "createdAt": "2020-08-24T22:01:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTg5MjY4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTg5NTM2OQ==", "url": "https://github.com/apache/hudi/pull/1964#discussion_r475895369", "bodyText": "Timeline APIs are only about instants  in general. I think adding partitions here is breaking that abstraction. Can you move this to some helper class", "author": "bvaradar", "createdAt": "2020-08-24T21:08:39Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/table/timeline/HoodieDefaultTimeline.java", "diffHunk": "@@ -296,6 +300,42 @@ public boolean isBeforeTimelineStarts(String instant) {\n     return details.apply(instant);\n   }\n \n+  /**", "originalCommit": "f0cd600d209d9ca370ea4ba0ff1536867fc706d0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTkxOTQ0NQ==", "url": "https://github.com/apache/hudi/pull/1964#discussion_r475919445", "bodyText": "Thank you. Moved it", "author": "satishkotha", "createdAt": "2020-08-24T22:02:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTg5NTM2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTkwMzc2Mw==", "url": "https://github.com/apache/hudi/pull/1964#discussion_r475903763", "bodyText": "We dont need to look at clean and (event compaction) for figuring out changed partitions for the case of hive syncing.", "author": "bvaradar", "createdAt": "2020-08-24T21:25:55Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/table/timeline/HoodieDefaultTimeline.java", "diffHunk": "@@ -296,6 +300,42 @@ public boolean isBeforeTimelineStarts(String instant) {\n     return details.apply(instant);\n   }\n \n+  /**\n+   * Returns partitions that have been modified in the timeline. This includes internal operations such as clean.\n+   * Note that this only returns data for completed instants.\n+   */\n+  public List<String> getPartitionsMutated() {\n+    return filterCompletedInstants().getInstants().flatMap(s -> {\n+      switch (s.getAction()) {\n+        case HoodieTimeline.COMMIT_ACTION:\n+        case HoodieTimeline.DELTA_COMMIT_ACTION:\n+          try {\n+            HoodieCommitMetadata commitMetadata = HoodieCommitMetadata.fromBytes(getInstantDetails(s).get(), HoodieCommitMetadata.class);\n+            return commitMetadata.getPartitionToWriteStats().keySet().stream();\n+          } catch (IOException e) {\n+            throw new HoodieIOException(\"Failed to get partitions written between \" + firstInstant() + \" \" + lastInstant(), e);\n+          }\n+        case HoodieTimeline.CLEAN_ACTION:", "originalCommit": "f0cd600d209d9ca370ea4ba0ff1536867fc706d0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTkyMDI3OQ==", "url": "https://github.com/apache/hudi/pull/1964#discussion_r475920279", "bodyText": "The method takes in a timeline. So hive sync only passes \"commit\" timeline to this method and gets only partitions modified by commit instants.  I added another method just for clarity that only looks at commits. Let me know if you have any suggestions.", "author": "satishkotha", "createdAt": "2020-08-24T22:04:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTkwMzc2Mw=="}], "type": "inlineReview"}, {"oid": "7cd6d9d420d36071991eeb16277e210e33324f77", "url": "https://github.com/apache/hudi/commit/7cd6d9d420d36071991eeb16277e210e33324f77", "message": "[HUDI-1191] Add incremental meta client API to query partitions modified in a time window", "committedDate": "2020-08-24T22:00:20Z", "type": "forcePushed"}, {"oid": "a7c7c0b44982ec4a4ac64dfabd15a45ebbc48279", "url": "https://github.com/apache/hudi/commit/a7c7c0b44982ec4a4ac64dfabd15a45ebbc48279", "message": "[HUDI-1191] Add incremental meta client API to query partitions modified in a time window", "committedDate": "2020-08-24T22:06:20Z", "type": "forcePushed"}, {"oid": "383b5b4b1b3544a06ae2ae59b46e0a5323b03a68", "url": "https://github.com/apache/hudi/commit/383b5b4b1b3544a06ae2ae59b46e0a5323b03a68", "message": "[HUDI-1191] Add incremental meta client API to query partitions modified in a time window", "committedDate": "2020-08-24T22:09:29Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTkyNTExNQ==", "url": "https://github.com/apache/hudi/pull/1964#discussion_r475925115", "bodyText": "Let's keep the same name as before getCommitMetadata & getCleanMetadata unless there is a specific need for keeping the names short..", "author": "n3nash", "createdAt": "2020-08-24T22:16:34Z", "path": "hudi-common/src/test/java/org/apache/hudi/common/table/TestTimelineUtils.java", "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.table;\n+\n+import org.apache.hudi.avro.model.HoodieCleanMetadata;\n+import org.apache.hudi.avro.model.HoodieCleanPartitionMetadata;\n+import org.apache.hudi.common.model.HoodieCleaningPolicy;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.HoodieWriteStat;\n+import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.common.table.timeline.TimelineMetadataUtils;\n+import org.apache.hudi.common.table.timeline.TimelineUtils;\n+import org.apache.hudi.common.testutils.HoodieCommonTestHarness;\n+import org.apache.hudi.common.util.Option;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+public class TestTimelineUtils extends HoodieCommonTestHarness {\n+\n+  @BeforeEach\n+  public void setUp() throws Exception {\n+    initMetaClient();\n+  }\n+\n+  @Test\n+  public void testGetPartitions() throws IOException {\n+    HoodieActiveTimeline activeTimeline = metaClient.getActiveTimeline();\n+    HoodieTimeline activeCommitTimeline = activeTimeline.getCommitTimeline();\n+    assertTrue(activeCommitTimeline.empty());\n+\n+    String olderPartition = \"0\"; // older partitions that is modified by all cleans\n+    for (int i = 1; i <= 5; i++) {\n+      String ts = i + \"\";\n+      HoodieInstant instant = new HoodieInstant(true, HoodieTimeline.COMMIT_ACTION, ts);\n+      activeTimeline.createNewInstant(instant);\n+      activeTimeline.saveAsComplete(instant, Option.of(getCommitMeta(basePath, ts, ts, 2)));\n+\n+      HoodieInstant cleanInstant = new HoodieInstant(true, HoodieTimeline.CLEAN_ACTION, ts);\n+      activeTimeline.createNewInstant(cleanInstant);\n+      activeTimeline.saveAsComplete(cleanInstant, getCleanMeta(olderPartition, ts));\n+    }\n+\n+    metaClient.reloadActiveTimeline();\n+\n+    // verify modified partitions included cleaned data\n+    List<String> partitions = TimelineUtils.getPartitionsMutated(metaClient.getActiveTimeline().findInstantsAfter(\"1\", 10));\n+    assertEquals(5, partitions.size());\n+    assertEquals(partitions, Arrays.asList(new String[]{\"0\", \"2\", \"3\", \"4\", \"5\"}));\n+\n+    partitions = TimelineUtils.getPartitionsMutated(metaClient.getActiveTimeline().findInstantsInRange(\"1\", \"4\"));\n+    assertEquals(4, partitions.size());\n+    assertEquals(partitions, Arrays.asList(new String[]{\"0\", \"2\", \"3\", \"4\"}));\n+\n+    // verify only commit actions\n+    partitions = TimelineUtils.getPartitionsWritten(metaClient.getActiveTimeline().findInstantsAfter(\"1\", 10));\n+    assertEquals(4, partitions.size());\n+    assertEquals(partitions, Arrays.asList(new String[]{\"2\", \"3\", \"4\", \"5\"}));\n+\n+    partitions = TimelineUtils.getPartitionsWritten(metaClient.getActiveTimeline().findInstantsInRange(\"1\", \"4\"));\n+    assertEquals(3, partitions.size());\n+    assertEquals(partitions, Arrays.asList(new String[]{\"2\", \"3\", \"4\"}));\n+  }\n+\n+  @Test\n+  public void testGetPartitionsUnpartitioned() throws IOException {\n+    HoodieActiveTimeline activeTimeline = metaClient.getActiveTimeline();\n+    HoodieTimeline activeCommitTimeline = activeTimeline.getCommitTimeline();\n+    assertTrue(activeCommitTimeline.empty());\n+\n+    String partitionPath = \"\";\n+    for (int i = 1; i <= 5; i++) {\n+      String ts = i + \"\";\n+      HoodieInstant instant = new HoodieInstant(true, HoodieTimeline.COMMIT_ACTION, ts);\n+      activeTimeline.createNewInstant(instant);\n+      activeTimeline.saveAsComplete(instant, Option.of(getCommitMeta(basePath, partitionPath, ts, 2)));\n+\n+      HoodieInstant cleanInstant = new HoodieInstant(true, HoodieTimeline.CLEAN_ACTION, ts);\n+      activeTimeline.createNewInstant(cleanInstant);\n+      activeTimeline.saveAsComplete(cleanInstant, getCleanMeta(partitionPath, ts));\n+    }\n+\n+    metaClient.reloadActiveTimeline();\n+\n+    // verify modified partitions included cleaned data\n+    List<String> partitions = TimelineUtils.getPartitionsMutated(metaClient.getActiveTimeline().findInstantsAfter(\"1\", 10));\n+    assertTrue(partitions.isEmpty());\n+\n+    partitions = TimelineUtils.getPartitionsMutated(metaClient.getActiveTimeline().findInstantsInRange(\"1\", \"4\"));\n+    assertTrue(partitions.isEmpty());\n+  }\n+\n+  private byte[] getCommitMeta(String basePath, String partition, String commitTs, int count)", "originalCommit": "383b5b4b1b3544a06ae2ae59b46e0a5323b03a68", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTkyNTMxNA==", "url": "https://github.com/apache/hudi/pull/1964#discussion_r475925314", "bodyText": "Do you want to throw an exception here for now so it's not treated incorrectly ?", "author": "n3nash", "createdAt": "2020-08-24T22:17:06Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/table/timeline/TimelineUtils.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.table.timeline;\n+\n+import org.apache.hudi.avro.model.HoodieCleanMetadata;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.exception.HoodieIOException;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * TimelineUtils provides a common way to query incremental meta-data changes for a hoodie table.\n+ *\n+ * This is useful in multiple places including:\n+ * 1) HiveSync - this can be used to query partitions that changed since previous sync.\n+ * 2) Incremental reads - InputFormats can use this API to queryxw\n+ */\n+public class TimelineUtils {\n+\n+  /**\n+   * Returns partitions that have new data strictly after commitTime.\n+   * Does not include internal operations such as clean in the timeline.\n+   */\n+  public static List<String> getPartitionsWritten(HoodieTimeline timeline) {\n+    HoodieTimeline timelineToSync = timeline.getCommitsAndCompactionTimeline();\n+    return getPartitionsMutated(timelineToSync);\n+  }\n+\n+  /**\n+   * Returns partitions that have been modified including internal operations such as clean in the passed timeline.\n+   */\n+  public static List<String> getPartitionsMutated(HoodieTimeline timeline) {\n+    return timeline.filterCompletedInstants().getInstants().flatMap(s -> {\n+      switch (s.getAction()) {\n+        case HoodieTimeline.COMMIT_ACTION:\n+        case HoodieTimeline.DELTA_COMMIT_ACTION:\n+          try {\n+            HoodieCommitMetadata commitMetadata = HoodieCommitMetadata.fromBytes(timeline.getInstantDetails(s).get(), HoodieCommitMetadata.class);\n+            return commitMetadata.getPartitionToWriteStats().keySet().stream();\n+          } catch (IOException e) {\n+            throw new HoodieIOException(\"Failed to get partitions written between \" + timeline.firstInstant() + \" \" + timeline.lastInstant(), e);\n+          }\n+        case HoodieTimeline.CLEAN_ACTION:\n+          try {\n+            HoodieCleanMetadata cleanMetadata = TimelineMetadataUtils.deserializeHoodieCleanMetadata(timeline.getInstantDetails(s).get());\n+            return cleanMetadata.getPartitionMetadata().keySet().stream();\n+          } catch (IOException e) {\n+            throw new HoodieIOException(\"Failed to get partitions cleaned between \" + timeline.firstInstant() + \" \" + timeline.lastInstant(), e);\n+          }\n+        case HoodieTimeline.COMPACTION_ACTION:\n+          // compaction is not a completed instant.  So no need to consider this action.\n+        case HoodieTimeline.SAVEPOINT_ACTION:\n+        case HoodieTimeline.ROLLBACK_ACTION:\n+        case HoodieTimeline.RESTORE_ACTION:\n+          return Stream.empty();", "originalCommit": "383b5b4b1b3544a06ae2ae59b46e0a5323b03a68", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTk2MjU1OQ==", "url": "https://github.com/apache/hudi/pull/1964#discussion_r475962559", "bodyText": "compaction is not treated as completed instants. So this can be ignored. I implemented all other actions and added tests", "author": "satishkotha", "createdAt": "2020-08-24T23:34:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTkyNTMxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTkzMTE0Nw==", "url": "https://github.com/apache/hudi/pull/1964#discussion_r475931147", "bodyText": "typo : queryxw -> query", "author": "bvaradar", "createdAt": "2020-08-24T22:33:09Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/table/timeline/TimelineUtils.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.table.timeline;\n+\n+import org.apache.hudi.avro.model.HoodieCleanMetadata;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.exception.HoodieIOException;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * TimelineUtils provides a common way to query incremental meta-data changes for a hoodie table.\n+ *\n+ * This is useful in multiple places including:\n+ * 1) HiveSync - this can be used to query partitions that changed since previous sync.\n+ * 2) Incremental reads - InputFormats can use this API to queryxw", "originalCommit": "383b5b4b1b3544a06ae2ae59b46e0a5323b03a68", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTk2MTI5Mw==", "url": "https://github.com/apache/hudi/pull/1964#discussion_r475961293", "bodyText": "thank you! fixed.", "author": "satishkotha", "createdAt": "2020-08-24T23:32:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTkzMTE0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTkzMTM0Mg==", "url": "https://github.com/apache/hudi/pull/1964#discussion_r475931342", "bodyText": "getPartitionsMutated -> getAffectedPartitions ?", "author": "bvaradar", "createdAt": "2020-08-24T22:33:42Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/table/timeline/TimelineUtils.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.table.timeline;\n+\n+import org.apache.hudi.avro.model.HoodieCleanMetadata;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.exception.HoodieIOException;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+/**\n+ * TimelineUtils provides a common way to query incremental meta-data changes for a hoodie table.\n+ *\n+ * This is useful in multiple places including:\n+ * 1) HiveSync - this can be used to query partitions that changed since previous sync.\n+ * 2) Incremental reads - InputFormats can use this API to queryxw\n+ */\n+public class TimelineUtils {\n+\n+  /**\n+   * Returns partitions that have new data strictly after commitTime.\n+   * Does not include internal operations such as clean in the timeline.\n+   */\n+  public static List<String> getPartitionsWritten(HoodieTimeline timeline) {\n+    HoodieTimeline timelineToSync = timeline.getCommitsAndCompactionTimeline();\n+    return getPartitionsMutated(timelineToSync);\n+  }\n+\n+  /**\n+   * Returns partitions that have been modified including internal operations such as clean in the passed timeline.\n+   */\n+  public static List<String> getPartitionsMutated(HoodieTimeline timeline) {", "originalCommit": "383b5b4b1b3544a06ae2ae59b46e0a5323b03a68", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTkzMzQ5Ng==", "url": "https://github.com/apache/hudi/pull/1964#discussion_r475933496", "bodyText": "I am assuming you are planning to use this API internally. Right ?", "author": "bvaradar", "createdAt": "2020-08-24T22:40:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTkzMTM0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTk2MTIwNA==", "url": "https://github.com/apache/hudi/pull/1964#discussion_r475961204", "bodyText": "Yes, this is for internal use. I have no strong opinion on name. I think it was initially getAffectedPartitions, changed to getPartitionsMutated because of @n3nash suggestion. i'm fine with going back if he agrees", "author": "satishkotha", "createdAt": "2020-08-24T23:32:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTkzMTM0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjAyNjg0Ng==", "url": "https://github.com/apache/hudi/pull/1964#discussion_r476026846", "bodyText": "Sure, getAffectedPartitions is fine @satishkotha, I think initially it was getWrittenPartitions or something..", "author": "n3nash", "createdAt": "2020-08-25T01:10:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTkzMTM0Mg=="}], "type": "inlineReview"}, {"oid": "d97f63242642a493a1560322407109788e62d517", "url": "https://github.com/apache/hudi/commit/d97f63242642a493a1560322407109788e62d517", "message": "[HUDI-1191] Add incremental meta client API to query partitions modified in a time window", "committedDate": "2020-08-24T23:20:59Z", "type": "forcePushed"}, {"oid": "0ce5b94d4cc4dcacf512bf03061f9ad87495c6c9", "url": "https://github.com/apache/hudi/commit/0ce5b94d4cc4dcacf512bf03061f9ad87495c6c9", "message": "[HUDI-1191] Add incremental meta client API to query partitions modified in a time window", "committedDate": "2020-08-24T23:26:20Z", "type": "forcePushed"}, {"oid": "d84ca7a751d10ff33223e4fe59b01330a9666f39", "url": "https://github.com/apache/hudi/commit/d84ca7a751d10ff33223e4fe59b01330a9666f39", "message": "[HUDI-1191] Add incremental meta client API to query partitions modified in a time window", "committedDate": "2020-08-25T16:55:39Z", "type": "commit"}, {"oid": "d84ca7a751d10ff33223e4fe59b01330a9666f39", "url": "https://github.com/apache/hudi/commit/d84ca7a751d10ff33223e4fe59b01330a9666f39", "message": "[HUDI-1191] Add incremental meta client API to query partitions modified in a time window", "committedDate": "2020-08-25T16:55:39Z", "type": "forcePushed"}]}