{"pr_number": 2301, "pr_title": "[HUDI-1435] Fix bug in Marker File Reconciliation for Non-Partitioned datasets", "pr_createdAt": "2020-12-07T08:05:33Z", "pr_url": "https://github.com/apache/hudi/pull/2301", "timeline": [{"oid": "0f21decb5d8588ae8f08e5af46964748816f5535", "url": "https://github.com/apache/hudi/commit/0f21decb5d8588ae8f08e5af46964748816f5535", "message": "[HUDI-1435] Fix bug in Marker File Reconciliation for Non-Partitioned datasets", "committedDate": "2020-12-07T08:04:54Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzkyNjY4NA==", "url": "https://github.com/apache/hudi/pull/2301#discussion_r537926684", "bodyText": "@bvaradar can we add a test for this ?", "author": "n3nash", "createdAt": "2020-12-07T23:58:27Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/HoodieTable.java", "diffHunk": "@@ -460,7 +460,7 @@ protected void reconcileAgainstMarkers(HoodieEngineContext context,\n       if (!invalidDataPaths.isEmpty()) {\n         LOG.info(\"Removing duplicate data files created due to spark retries before committing. Paths=\" + invalidDataPaths);\n         Map<String, List<Pair<String, String>>> invalidPathsByPartition = invalidDataPaths.stream()\n-            .map(dp -> Pair.of(new Path(dp).getParent().toString(), new Path(basePath, dp).toString()))\n+            .map(dp -> Pair.of(new Path(basePath, dp).getParent().toString(), new Path(basePath, dp).toString()))", "originalCommit": "0f21decb5d8588ae8f08e5af46964748816f5535", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}