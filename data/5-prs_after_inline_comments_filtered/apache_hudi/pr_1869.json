{"pr_number": 1869, "pr_title": "[HUDI-427] Implement CLI support for performing bootstrap", "pr_createdAt": "2020-07-24T05:10:11Z", "pr_url": "https://github.com/apache/hudi/pull/1869", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjY3NzY2Mg==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r462677662", "bodyText": "It seems like to run bootstrap command, it will be mandatory for the user to himself create the target Hudi location and connect to it before being able to perform bootstrap. I remember discussing once about this, but can you help me understand again what is the challenge in supporting this end to end without requiring to connect to a table ?\nI see HDFSParquetImportCommand being able to do this end to end, creating the target table itself without requiring the user to do it.", "author": "umehrot2", "createdAt": "2020-07-30T01:17:35Z", "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/BootstrapCommand.java", "diffHunk": "@@ -0,0 +1,189 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.commands;\n+\n+import org.apache.hudi.avro.model.BootstrapIndexInfo;\n+import org.apache.hudi.cli.HoodieCLI;\n+import org.apache.hudi.cli.HoodiePrintHelper;\n+import org.apache.hudi.cli.TableHeader;\n+import org.apache.hudi.cli.commands.SparkMain.SparkCommand;\n+import org.apache.hudi.cli.utils.InputStreamConsumer;\n+import org.apache.hudi.cli.utils.SparkUtil;\n+import org.apache.hudi.common.model.BootstrapSourceFileMapping;\n+import org.apache.hudi.common.model.HoodieFileGroupId;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.utilities.UtilHelpers;\n+\n+import org.apache.spark.launcher.SparkLauncher;\n+import org.apache.spark.util.Utils;\n+import org.springframework.shell.core.CommandMarker;\n+import org.springframework.shell.core.annotation.CliCommand;\n+import org.springframework.shell.core.annotation.CliOption;\n+import org.springframework.stereotype.Component;\n+\n+import java.io.IOException;\n+import java.net.URISyntaxException;\n+import java.util.Arrays;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import scala.collection.JavaConverters;\n+\n+/**\n+ * CLI command to perform bootstrap action & display bootstrap index.\n+ */\n+@Component\n+public class BootstrapCommand implements CommandMarker {\n+\n+  @CliCommand(value = \"bootstrap run\", help = \"Run a bootstrap action for current Hudi table\")\n+  public String bootstrap(", "originalCommit": "7d810fdb82dede006472d1bf08ec37788e42dc4a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTQ1Nzc3OQ==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r465457779", "bodyText": "I reconsidered about this issue. I agreed that we can run bootstrap as what HDFSParquetImportCommand does. So we only need to connect to the table when we want to get index info.", "author": "zhedoubushishi", "createdAt": "2020-08-05T03:59:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjY3NzY2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjY3ODAyNw==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r462678027", "bodyText": "Please check HDFSParquetImportCommand and keep the field names similar to what is already used there.", "author": "umehrot2", "createdAt": "2020-07-30T01:18:53Z", "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/BootstrapCommand.java", "diffHunk": "@@ -0,0 +1,189 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.commands;\n+\n+import org.apache.hudi.avro.model.BootstrapIndexInfo;\n+import org.apache.hudi.cli.HoodieCLI;\n+import org.apache.hudi.cli.HoodiePrintHelper;\n+import org.apache.hudi.cli.TableHeader;\n+import org.apache.hudi.cli.commands.SparkMain.SparkCommand;\n+import org.apache.hudi.cli.utils.InputStreamConsumer;\n+import org.apache.hudi.cli.utils.SparkUtil;\n+import org.apache.hudi.common.model.BootstrapSourceFileMapping;\n+import org.apache.hudi.common.model.HoodieFileGroupId;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.utilities.UtilHelpers;\n+\n+import org.apache.spark.launcher.SparkLauncher;\n+import org.apache.spark.util.Utils;\n+import org.springframework.shell.core.CommandMarker;\n+import org.springframework.shell.core.annotation.CliCommand;\n+import org.springframework.shell.core.annotation.CliOption;\n+import org.springframework.stereotype.Component;\n+\n+import java.io.IOException;\n+import java.net.URISyntaxException;\n+import java.util.Arrays;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import scala.collection.JavaConverters;\n+\n+/**\n+ * CLI command to perform bootstrap action & display bootstrap index.\n+ */\n+@Component\n+public class BootstrapCommand implements CommandMarker {\n+\n+  @CliCommand(value = \"bootstrap run\", help = \"Run a bootstrap action for current Hudi table\")\n+  public String bootstrap(\n+      @CliOption(key = {\"sourcePath\"}, mandatory = true, help = \"Source data path of the table\") final String sourcePath,\n+      @CliOption(key = {\"recordKeyColumns\"}, mandatory = true, help = \"Record key columns for bootstrap data\") final String recordKeyCols,\n+      @CliOption(key = {\"partitionFields\"}, unspecifiedDefaultValue = \"\", help = \"Partition fields for bootstrap data\") final String partitionsFields,", "originalCommit": "7d810fdb82dede006472d1bf08ec37788e42dc4a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDYwNDUxMQ==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r464604511", "bodyText": "Done.", "author": "zhedoubushishi", "createdAt": "2020-08-03T19:00:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjY3ODAyNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjY3ODcyNg==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r462678726", "bodyText": "Like in HDFSParquetImportCommand we need something similar where it accepts properties file or array of hoodie configurations so that the user can pass any addition hoodie configurations they want.  These probably do not need to be mentioned separately here and a user wanting to override them should specify it in the additional configurations they pass.", "author": "umehrot2", "createdAt": "2020-07-30T01:21:28Z", "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/BootstrapCommand.java", "diffHunk": "@@ -0,0 +1,189 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.commands;\n+\n+import org.apache.hudi.avro.model.BootstrapIndexInfo;\n+import org.apache.hudi.cli.HoodieCLI;\n+import org.apache.hudi.cli.HoodiePrintHelper;\n+import org.apache.hudi.cli.TableHeader;\n+import org.apache.hudi.cli.commands.SparkMain.SparkCommand;\n+import org.apache.hudi.cli.utils.InputStreamConsumer;\n+import org.apache.hudi.cli.utils.SparkUtil;\n+import org.apache.hudi.common.model.BootstrapSourceFileMapping;\n+import org.apache.hudi.common.model.HoodieFileGroupId;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.utilities.UtilHelpers;\n+\n+import org.apache.spark.launcher.SparkLauncher;\n+import org.apache.spark.util.Utils;\n+import org.springframework.shell.core.CommandMarker;\n+import org.springframework.shell.core.annotation.CliCommand;\n+import org.springframework.shell.core.annotation.CliOption;\n+import org.springframework.stereotype.Component;\n+\n+import java.io.IOException;\n+import java.net.URISyntaxException;\n+import java.util.Arrays;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import scala.collection.JavaConverters;\n+\n+/**\n+ * CLI command to perform bootstrap action & display bootstrap index.\n+ */\n+@Component\n+public class BootstrapCommand implements CommandMarker {\n+\n+  @CliCommand(value = \"bootstrap run\", help = \"Run a bootstrap action for current Hudi table\")\n+  public String bootstrap(\n+      @CliOption(key = {\"sourcePath\"}, mandatory = true, help = \"Source data path of the table\") final String sourcePath,\n+      @CliOption(key = {\"recordKeyColumns\"}, mandatory = true, help = \"Record key columns for bootstrap data\") final String recordKeyCols,\n+      @CliOption(key = {\"partitionFields\"}, unspecifiedDefaultValue = \"\", help = \"Partition fields for bootstrap data\") final String partitionsFields,\n+      @CliOption(key = {\"parallelism\"}, unspecifiedDefaultValue = \"1500\", help = \"Bootstrap writer parallelism\") final int parallelism,\n+      @CliOption(key = {\"schema\"}, unspecifiedDefaultValue = \"\", help = \"Schema of the source data file\") final String schema,\n+      @CliOption(key = {\"selectorClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.client.bootstrap.selector.MetadataOnlyBootstrapModeSelector\",\n+          help = \"Selector class for bootstrap\") final String selectorClass,\n+      @CliOption(key = {\"keyGeneratorClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.keygen.SimpleKeyGenerator\",\n+          help = \"Key generator class for bootstrap\") final String keyGeneratorClass,\n+      @CliOption(key = {\"fullBootstrapInputProvider\"}, unspecifiedDefaultValue = \"org.apache.hudi.bootstrap.SparkDataSourceBasedFullBootstrapInputProvider\",\n+          help = \"Class for Full bootstrap input provider\") final String fullBootstrapInputProvider,", "originalCommit": "7d810fdb82dede006472d1bf08ec37788e42dc4a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDYwNDU1Mw==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r464604553", "bodyText": "Good point. Will add.", "author": "zhedoubushishi", "createdAt": "2020-08-03T19:00:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjY3ODcyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjY4MDA0Nw==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r462680047", "bodyText": "Where is 4G coming from ? Atleast in CompactionCommand I see 2G as the default being used.", "author": "umehrot2", "createdAt": "2020-07-30T01:26:35Z", "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/BootstrapCommand.java", "diffHunk": "@@ -0,0 +1,189 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.commands;\n+\n+import org.apache.hudi.avro.model.BootstrapIndexInfo;\n+import org.apache.hudi.cli.HoodieCLI;\n+import org.apache.hudi.cli.HoodiePrintHelper;\n+import org.apache.hudi.cli.TableHeader;\n+import org.apache.hudi.cli.commands.SparkMain.SparkCommand;\n+import org.apache.hudi.cli.utils.InputStreamConsumer;\n+import org.apache.hudi.cli.utils.SparkUtil;\n+import org.apache.hudi.common.model.BootstrapSourceFileMapping;\n+import org.apache.hudi.common.model.HoodieFileGroupId;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.utilities.UtilHelpers;\n+\n+import org.apache.spark.launcher.SparkLauncher;\n+import org.apache.spark.util.Utils;\n+import org.springframework.shell.core.CommandMarker;\n+import org.springframework.shell.core.annotation.CliCommand;\n+import org.springframework.shell.core.annotation.CliOption;\n+import org.springframework.stereotype.Component;\n+\n+import java.io.IOException;\n+import java.net.URISyntaxException;\n+import java.util.Arrays;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import scala.collection.JavaConverters;\n+\n+/**\n+ * CLI command to perform bootstrap action & display bootstrap index.\n+ */\n+@Component\n+public class BootstrapCommand implements CommandMarker {\n+\n+  @CliCommand(value = \"bootstrap run\", help = \"Run a bootstrap action for current Hudi table\")\n+  public String bootstrap(\n+      @CliOption(key = {\"sourcePath\"}, mandatory = true, help = \"Source data path of the table\") final String sourcePath,\n+      @CliOption(key = {\"recordKeyColumns\"}, mandatory = true, help = \"Record key columns for bootstrap data\") final String recordKeyCols,\n+      @CliOption(key = {\"partitionFields\"}, unspecifiedDefaultValue = \"\", help = \"Partition fields for bootstrap data\") final String partitionsFields,\n+      @CliOption(key = {\"parallelism\"}, unspecifiedDefaultValue = \"1500\", help = \"Bootstrap writer parallelism\") final int parallelism,\n+      @CliOption(key = {\"schema\"}, unspecifiedDefaultValue = \"\", help = \"Schema of the source data file\") final String schema,\n+      @CliOption(key = {\"selectorClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.client.bootstrap.selector.MetadataOnlyBootstrapModeSelector\",\n+          help = \"Selector class for bootstrap\") final String selectorClass,\n+      @CliOption(key = {\"keyGeneratorClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.keygen.SimpleKeyGenerator\",\n+          help = \"Key generator class for bootstrap\") final String keyGeneratorClass,\n+      @CliOption(key = {\"fullBootstrapInputProvider\"}, unspecifiedDefaultValue = \"org.apache.hudi.bootstrap.SparkDataSourceBasedFullBootstrapInputProvider\",\n+          help = \"Class for Full bootstrap input provider\") final String fullBootstrapInputProvider,\n+      @CliOption(key = \"sparkMaster\", unspecifiedDefaultValue = \"\", help = \"Spark Master\") String master,\n+      @CliOption(key = \"sparkMemory\", unspecifiedDefaultValue = \"4G\", help = \"Spark executor memory\") final String sparkMemory)", "originalCommit": "7d810fdb82dede006472d1bf08ec37788e42dc4a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDYwNDU4Mg==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r464604582", "bodyText": "For compaction run, it uses 4G: https://github.com/apache/hudi/blob/master/hudi-cli/src/main/java/org/apache/hudi/cli/commands/CompactionCommand.java#L225. Also, clean run also uses 4G: https://github.com/apache/hudi/blob/master/hudi-cli/src/main/java/org/apache/hudi/cli/commands/CleansCommand.java#L125\nI think run bootstrap is also a complex spark job, maybe 4G is better?", "author": "zhedoubushishi", "createdAt": "2020-08-03T19:00:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjY4MDA0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjY4MjcwOA==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r462682708", "bodyText": "The message is slightly misleading. May be When passing fileIds, partitionPath is mandatory more clearly tells whats going on ?", "author": "umehrot2", "createdAt": "2020-07-30T01:34:07Z", "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/BootstrapCommand.java", "diffHunk": "@@ -0,0 +1,189 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.commands;\n+\n+import org.apache.hudi.avro.model.BootstrapIndexInfo;\n+import org.apache.hudi.cli.HoodieCLI;\n+import org.apache.hudi.cli.HoodiePrintHelper;\n+import org.apache.hudi.cli.TableHeader;\n+import org.apache.hudi.cli.commands.SparkMain.SparkCommand;\n+import org.apache.hudi.cli.utils.InputStreamConsumer;\n+import org.apache.hudi.cli.utils.SparkUtil;\n+import org.apache.hudi.common.model.BootstrapSourceFileMapping;\n+import org.apache.hudi.common.model.HoodieFileGroupId;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.utilities.UtilHelpers;\n+\n+import org.apache.spark.launcher.SparkLauncher;\n+import org.apache.spark.util.Utils;\n+import org.springframework.shell.core.CommandMarker;\n+import org.springframework.shell.core.annotation.CliCommand;\n+import org.springframework.shell.core.annotation.CliOption;\n+import org.springframework.stereotype.Component;\n+\n+import java.io.IOException;\n+import java.net.URISyntaxException;\n+import java.util.Arrays;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import scala.collection.JavaConverters;\n+\n+/**\n+ * CLI command to perform bootstrap action & display bootstrap index.\n+ */\n+@Component\n+public class BootstrapCommand implements CommandMarker {\n+\n+  @CliCommand(value = \"bootstrap run\", help = \"Run a bootstrap action for current Hudi table\")\n+  public String bootstrap(\n+      @CliOption(key = {\"sourcePath\"}, mandatory = true, help = \"Source data path of the table\") final String sourcePath,\n+      @CliOption(key = {\"recordKeyColumns\"}, mandatory = true, help = \"Record key columns for bootstrap data\") final String recordKeyCols,\n+      @CliOption(key = {\"partitionFields\"}, unspecifiedDefaultValue = \"\", help = \"Partition fields for bootstrap data\") final String partitionsFields,\n+      @CliOption(key = {\"parallelism\"}, unspecifiedDefaultValue = \"1500\", help = \"Bootstrap writer parallelism\") final int parallelism,\n+      @CliOption(key = {\"schema\"}, unspecifiedDefaultValue = \"\", help = \"Schema of the source data file\") final String schema,\n+      @CliOption(key = {\"selectorClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.client.bootstrap.selector.MetadataOnlyBootstrapModeSelector\",\n+          help = \"Selector class for bootstrap\") final String selectorClass,\n+      @CliOption(key = {\"keyGeneratorClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.keygen.SimpleKeyGenerator\",\n+          help = \"Key generator class for bootstrap\") final String keyGeneratorClass,\n+      @CliOption(key = {\"fullBootstrapInputProvider\"}, unspecifiedDefaultValue = \"org.apache.hudi.bootstrap.SparkDataSourceBasedFullBootstrapInputProvider\",\n+          help = \"Class for Full bootstrap input provider\") final String fullBootstrapInputProvider,\n+      @CliOption(key = \"sparkMaster\", unspecifiedDefaultValue = \"\", help = \"Spark Master\") String master,\n+      @CliOption(key = \"sparkMemory\", unspecifiedDefaultValue = \"4G\", help = \"Spark executor memory\") final String sparkMemory)\n+      throws IOException, InterruptedException, URISyntaxException {\n+\n+    boolean initialized = HoodieCLI.initConf();\n+    HoodieCLI.initFS(initialized);\n+    HoodieTableMetaClient metaClient = HoodieCLI.getTableMetaClient();\n+\n+    String sparkPropertiesPath =\n+        Utils.getDefaultPropertiesFile(JavaConverters.mapAsScalaMapConverter(System.getenv()).asScala());\n+\n+    SparkLauncher sparkLauncher = SparkUtil.initLauncher(sparkPropertiesPath);\n+\n+    String cmd = SparkCommand.BOOTSTRAP.toString();\n+\n+    sparkLauncher.addAppArgs(cmd, master, sparkMemory, metaClient.getTableConfig().getTableName(), metaClient.getBasePath(), sourcePath, schema, recordKeyCols,\n+        partitionsFields, String.valueOf(parallelism), selectorClass, keyGeneratorClass, fullBootstrapInputProvider);\n+    UtilHelpers.validateAndAddProperties(new String[] {}, sparkLauncher);\n+    Process process = sparkLauncher.launch();\n+    InputStreamConsumer.captureOutput(process);\n+    int exitCode = process.waitFor();\n+    if (exitCode != 0) {\n+      return \"Failed to bootstrap source data to Hudi dataset\";\n+    }\n+    return \"Bootstrapped source data to Hudi dataset\";\n+  }\n+\n+  @CliCommand(value = \"bootstrap show index mapping\", help = \"Show bootstrap index mapping\")\n+  public String showBootstrapIndexMapping(\n+      @CliOption(key = {\"partitionPath\"}, unspecifiedDefaultValue = \"\", help = \"A valid paritition path\") String partition,\n+      @CliOption(key = {\"fileIds\"}, unspecifiedDefaultValue = \"\", help = \"Valid fileIds split by comma\") String fileIds,\n+      @CliOption(key = {\"limit\"}, unspecifiedDefaultValue = \"-1\", help = \"Limit rows to be displayed\") Integer limit,\n+      @CliOption(key = {\"sortBy\"}, unspecifiedDefaultValue = \"\", help = \"Sorting Field\") final String sortByField,\n+      @CliOption(key = {\"desc\"}, unspecifiedDefaultValue = \"false\", help = \"Ordering\") final boolean descending,\n+      @CliOption(key = {\"headeronly\"}, unspecifiedDefaultValue = \"false\", help = \"Print Header Only\")\n+      final boolean headerOnly) {\n+\n+    if (partition.isEmpty() && !fileIds.isEmpty()) {\n+      throw new IllegalStateException(\"Both paritionPath and fileIds are required\");", "originalCommit": "7d810fdb82dede006472d1bf08ec37788e42dc4a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDYwNTEwNA==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r464605104", "bodyText": "Done.", "author": "zhedoubushishi", "createdAt": "2020-08-03T19:01:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjY4MjcwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjY4Mjg4OQ==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r462682889", "bodyText": "What is the issue here ? Is this something that we should fix in bootstrap index code ?", "author": "umehrot2", "createdAt": "2020-07-30T01:34:46Z", "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/BootstrapCommand.java", "diffHunk": "@@ -0,0 +1,189 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.commands;\n+\n+import org.apache.hudi.avro.model.BootstrapIndexInfo;\n+import org.apache.hudi.cli.HoodieCLI;\n+import org.apache.hudi.cli.HoodiePrintHelper;\n+import org.apache.hudi.cli.TableHeader;\n+import org.apache.hudi.cli.commands.SparkMain.SparkCommand;\n+import org.apache.hudi.cli.utils.InputStreamConsumer;\n+import org.apache.hudi.cli.utils.SparkUtil;\n+import org.apache.hudi.common.model.BootstrapSourceFileMapping;\n+import org.apache.hudi.common.model.HoodieFileGroupId;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.utilities.UtilHelpers;\n+\n+import org.apache.spark.launcher.SparkLauncher;\n+import org.apache.spark.util.Utils;\n+import org.springframework.shell.core.CommandMarker;\n+import org.springframework.shell.core.annotation.CliCommand;\n+import org.springframework.shell.core.annotation.CliOption;\n+import org.springframework.stereotype.Component;\n+\n+import java.io.IOException;\n+import java.net.URISyntaxException;\n+import java.util.Arrays;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import scala.collection.JavaConverters;\n+\n+/**\n+ * CLI command to perform bootstrap action & display bootstrap index.\n+ */\n+@Component\n+public class BootstrapCommand implements CommandMarker {\n+\n+  @CliCommand(value = \"bootstrap run\", help = \"Run a bootstrap action for current Hudi table\")\n+  public String bootstrap(\n+      @CliOption(key = {\"sourcePath\"}, mandatory = true, help = \"Source data path of the table\") final String sourcePath,\n+      @CliOption(key = {\"recordKeyColumns\"}, mandatory = true, help = \"Record key columns for bootstrap data\") final String recordKeyCols,\n+      @CliOption(key = {\"partitionFields\"}, unspecifiedDefaultValue = \"\", help = \"Partition fields for bootstrap data\") final String partitionsFields,\n+      @CliOption(key = {\"parallelism\"}, unspecifiedDefaultValue = \"1500\", help = \"Bootstrap writer parallelism\") final int parallelism,\n+      @CliOption(key = {\"schema\"}, unspecifiedDefaultValue = \"\", help = \"Schema of the source data file\") final String schema,\n+      @CliOption(key = {\"selectorClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.client.bootstrap.selector.MetadataOnlyBootstrapModeSelector\",\n+          help = \"Selector class for bootstrap\") final String selectorClass,\n+      @CliOption(key = {\"keyGeneratorClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.keygen.SimpleKeyGenerator\",\n+          help = \"Key generator class for bootstrap\") final String keyGeneratorClass,\n+      @CliOption(key = {\"fullBootstrapInputProvider\"}, unspecifiedDefaultValue = \"org.apache.hudi.bootstrap.SparkDataSourceBasedFullBootstrapInputProvider\",\n+          help = \"Class for Full bootstrap input provider\") final String fullBootstrapInputProvider,\n+      @CliOption(key = \"sparkMaster\", unspecifiedDefaultValue = \"\", help = \"Spark Master\") String master,\n+      @CliOption(key = \"sparkMemory\", unspecifiedDefaultValue = \"4G\", help = \"Spark executor memory\") final String sparkMemory)\n+      throws IOException, InterruptedException, URISyntaxException {\n+\n+    boolean initialized = HoodieCLI.initConf();\n+    HoodieCLI.initFS(initialized);\n+    HoodieTableMetaClient metaClient = HoodieCLI.getTableMetaClient();\n+\n+    String sparkPropertiesPath =\n+        Utils.getDefaultPropertiesFile(JavaConverters.mapAsScalaMapConverter(System.getenv()).asScala());\n+\n+    SparkLauncher sparkLauncher = SparkUtil.initLauncher(sparkPropertiesPath);\n+\n+    String cmd = SparkCommand.BOOTSTRAP.toString();\n+\n+    sparkLauncher.addAppArgs(cmd, master, sparkMemory, metaClient.getTableConfig().getTableName(), metaClient.getBasePath(), sourcePath, schema, recordKeyCols,\n+        partitionsFields, String.valueOf(parallelism), selectorClass, keyGeneratorClass, fullBootstrapInputProvider);\n+    UtilHelpers.validateAndAddProperties(new String[] {}, sparkLauncher);\n+    Process process = sparkLauncher.launch();\n+    InputStreamConsumer.captureOutput(process);\n+    int exitCode = process.waitFor();\n+    if (exitCode != 0) {\n+      return \"Failed to bootstrap source data to Hudi dataset\";\n+    }\n+    return \"Bootstrapped source data to Hudi dataset\";\n+  }\n+\n+  @CliCommand(value = \"bootstrap show index mapping\", help = \"Show bootstrap index mapping\")\n+  public String showBootstrapIndexMapping(\n+      @CliOption(key = {\"partitionPath\"}, unspecifiedDefaultValue = \"\", help = \"A valid paritition path\") String partition,\n+      @CliOption(key = {\"fileIds\"}, unspecifiedDefaultValue = \"\", help = \"Valid fileIds split by comma\") String fileIds,\n+      @CliOption(key = {\"limit\"}, unspecifiedDefaultValue = \"-1\", help = \"Limit rows to be displayed\") Integer limit,\n+      @CliOption(key = {\"sortBy\"}, unspecifiedDefaultValue = \"\", help = \"Sorting Field\") final String sortByField,\n+      @CliOption(key = {\"desc\"}, unspecifiedDefaultValue = \"false\", help = \"Ordering\") final boolean descending,\n+      @CliOption(key = {\"headeronly\"}, unspecifiedDefaultValue = \"false\", help = \"Print Header Only\")\n+      final boolean headerOnly) {\n+\n+    if (partition.isEmpty() && !fileIds.isEmpty()) {\n+      throw new IllegalStateException(\"Both paritionPath and fileIds are required\");\n+    }\n+    BootstrapIndex.IndexReader indexReader = createBootstrapIndexReader();\n+\n+    // TODO tmp solution because the result of BootstrapIndex.IndexReader.getIndexedPartitions() is not clean\n+    List<String> indexedPartitions = indexReader.getIndexedPartitions().stream()\n+        .map(p -> p.split(\"//\")[0].substring(5)).collect(Collectors.toList());", "originalCommit": "7d810fdb82dede006472d1bf08ec37788e42dc4a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTg3MjQwMw==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r465872403", "bodyText": "Added similar logic in the HFileBootstrapIndex.", "author": "zhedoubushishi", "createdAt": "2020-08-05T17:00:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjY4Mjg4OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjY4NDk3OA==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r462684978", "bodyText": "I think the following commands may be better:\nbootstrap index show => This shows basic index information\nbootstrap index showMapping => Shows mappings\nbootstrap index showPartitions => Shows indexed partitions", "author": "umehrot2", "createdAt": "2020-07-30T01:42:46Z", "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/BootstrapCommand.java", "diffHunk": "@@ -0,0 +1,189 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.commands;\n+\n+import org.apache.hudi.avro.model.BootstrapIndexInfo;\n+import org.apache.hudi.cli.HoodieCLI;\n+import org.apache.hudi.cli.HoodiePrintHelper;\n+import org.apache.hudi.cli.TableHeader;\n+import org.apache.hudi.cli.commands.SparkMain.SparkCommand;\n+import org.apache.hudi.cli.utils.InputStreamConsumer;\n+import org.apache.hudi.cli.utils.SparkUtil;\n+import org.apache.hudi.common.model.BootstrapSourceFileMapping;\n+import org.apache.hudi.common.model.HoodieFileGroupId;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.utilities.UtilHelpers;\n+\n+import org.apache.spark.launcher.SparkLauncher;\n+import org.apache.spark.util.Utils;\n+import org.springframework.shell.core.CommandMarker;\n+import org.springframework.shell.core.annotation.CliCommand;\n+import org.springframework.shell.core.annotation.CliOption;\n+import org.springframework.stereotype.Component;\n+\n+import java.io.IOException;\n+import java.net.URISyntaxException;\n+import java.util.Arrays;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import scala.collection.JavaConverters;\n+\n+/**\n+ * CLI command to perform bootstrap action & display bootstrap index.\n+ */\n+@Component\n+public class BootstrapCommand implements CommandMarker {\n+\n+  @CliCommand(value = \"bootstrap run\", help = \"Run a bootstrap action for current Hudi table\")\n+  public String bootstrap(\n+      @CliOption(key = {\"sourcePath\"}, mandatory = true, help = \"Source data path of the table\") final String sourcePath,\n+      @CliOption(key = {\"recordKeyColumns\"}, mandatory = true, help = \"Record key columns for bootstrap data\") final String recordKeyCols,\n+      @CliOption(key = {\"partitionFields\"}, unspecifiedDefaultValue = \"\", help = \"Partition fields for bootstrap data\") final String partitionsFields,\n+      @CliOption(key = {\"parallelism\"}, unspecifiedDefaultValue = \"1500\", help = \"Bootstrap writer parallelism\") final int parallelism,\n+      @CliOption(key = {\"schema\"}, unspecifiedDefaultValue = \"\", help = \"Schema of the source data file\") final String schema,\n+      @CliOption(key = {\"selectorClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.client.bootstrap.selector.MetadataOnlyBootstrapModeSelector\",\n+          help = \"Selector class for bootstrap\") final String selectorClass,\n+      @CliOption(key = {\"keyGeneratorClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.keygen.SimpleKeyGenerator\",\n+          help = \"Key generator class for bootstrap\") final String keyGeneratorClass,\n+      @CliOption(key = {\"fullBootstrapInputProvider\"}, unspecifiedDefaultValue = \"org.apache.hudi.bootstrap.SparkDataSourceBasedFullBootstrapInputProvider\",\n+          help = \"Class for Full bootstrap input provider\") final String fullBootstrapInputProvider,\n+      @CliOption(key = \"sparkMaster\", unspecifiedDefaultValue = \"\", help = \"Spark Master\") String master,\n+      @CliOption(key = \"sparkMemory\", unspecifiedDefaultValue = \"4G\", help = \"Spark executor memory\") final String sparkMemory)\n+      throws IOException, InterruptedException, URISyntaxException {\n+\n+    boolean initialized = HoodieCLI.initConf();\n+    HoodieCLI.initFS(initialized);\n+    HoodieTableMetaClient metaClient = HoodieCLI.getTableMetaClient();\n+\n+    String sparkPropertiesPath =\n+        Utils.getDefaultPropertiesFile(JavaConverters.mapAsScalaMapConverter(System.getenv()).asScala());\n+\n+    SparkLauncher sparkLauncher = SparkUtil.initLauncher(sparkPropertiesPath);\n+\n+    String cmd = SparkCommand.BOOTSTRAP.toString();\n+\n+    sparkLauncher.addAppArgs(cmd, master, sparkMemory, metaClient.getTableConfig().getTableName(), metaClient.getBasePath(), sourcePath, schema, recordKeyCols,\n+        partitionsFields, String.valueOf(parallelism), selectorClass, keyGeneratorClass, fullBootstrapInputProvider);\n+    UtilHelpers.validateAndAddProperties(new String[] {}, sparkLauncher);\n+    Process process = sparkLauncher.launch();\n+    InputStreamConsumer.captureOutput(process);\n+    int exitCode = process.waitFor();\n+    if (exitCode != 0) {\n+      return \"Failed to bootstrap source data to Hudi dataset\";\n+    }\n+    return \"Bootstrapped source data to Hudi dataset\";\n+  }\n+\n+  @CliCommand(value = \"bootstrap show index mapping\", help = \"Show bootstrap index mapping\")", "originalCommit": "7d810fdb82dede006472d1bf08ec37788e42dc4a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjY4NTIxOA==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r462685218", "bodyText": "We should test all the Commands/APIs. It current tests only two of them.", "author": "umehrot2", "createdAt": "2020-07-30T01:43:36Z", "path": "hudi-cli/src/test/java/org/apache/hudi/cli/integ/ITTestBootstrapCommand.java", "diffHunk": "@@ -0,0 +1,108 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.integ;\n+\n+import org.apache.hudi.cli.HoodieCLI;\n+import org.apache.hudi.cli.HoodiePrintHelper;\n+import org.apache.hudi.cli.commands.TableCommand;\n+import org.apache.hudi.cli.testutils.AbstractShellIntegrationTest;\n+import org.apache.hudi.common.model.HoodieTableType;\n+import org.apache.hudi.common.table.timeline.versioning.TimelineLayoutVersion;\n+import org.apache.hudi.testutils.HoodieTestDataGenerator;\n+\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.SaveMode;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.springframework.shell.core.CommandResult;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+/**\n+ * Test class of {@link org.apache.hudi.cli.commands.BootstrapCommand}.\n+ */\n+public class ITTestBootstrapCommand extends AbstractShellIntegrationTest {\n+\n+  private static final int TOTAL_RECORDS = 100;\n+  private static final String PARTITION_FIELD = \"datestr\";\n+  private static final String RECORD_KEY_FIELD = \"_row_key\";\n+\n+  private String sourcePath;\n+  private String tablePath;\n+  private List<String> partitions;\n+\n+  @BeforeEach\n+  public void init() throws IOException {\n+    String srcName = \"source\";\n+    String tableName = \"test-table\";\n+    sourcePath = basePath + File.separator + srcName;\n+    tablePath = basePath + File.separator + tableName;\n+\n+    partitions = Arrays.asList(\"2018\", \"2019\", \"2020\");\n+    double timestamp = new Double(Instant.now().toEpochMilli()).longValue();\n+    Dataset<Row> df = HoodieTestDataGenerator.generateTestRawTripDataset(timestamp,\n+        TOTAL_RECORDS, partitions, jsc, sqlContext);\n+    df.write().partitionBy(\"datestr\").format(\"parquet\").mode(SaveMode.Overwrite).save(sourcePath);\n+\n+    // Create table and connect\n+    new TableCommand().createTable(\n+        tablePath, tableName, HoodieTableType.COPY_ON_WRITE.name(),\n+        \"\", TimelineLayoutVersion.VERSION_1, \"org.apache.hudi.common.model.HoodieAvroPayload\",\n+        \"org.apache.hudi.common.bootstrap.index.HFileBasedBootstrapIndex\");\n+  }\n+\n+  /**\n+   * Test case for command 'bootstrap'.\n+   */\n+  @Test\n+  public void testBootstrapRunCommand() throws IOException {\n+    // test bootstrap run command\n+    String cmdStr = String.format(\"bootstrap run --sourcePath %s --recordKeyColumns %s --partitionFields %s --sparkMaster %s\",\n+        sourcePath, RECORD_KEY_FIELD, PARTITION_FIELD, \"local\");\n+    CommandResult cr = getShell().executeCommand(cmdStr);\n+    assertTrue(cr.isSuccess());\n+\n+    // Check hudi table exist\n+    new TableCommand().connect(tablePath, TimelineLayoutVersion.VERSION_1, false, 2000, 300000, 7);\n+    metaClient = HoodieCLI.getTableMetaClient();\n+    assertEquals(1, metaClient.getActiveTimeline().getCommitsTimeline().countInstants(), \"Should have 1 commit.\");\n+\n+    // test bootstrap show indexed partitions", "originalCommit": "7d810fdb82dede006472d1bf08ec37788e42dc4a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTQ1NzQzNA==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r465457434", "bodyText": "Added another two test cases for bootstrap index showMapping.", "author": "zhedoubushishi", "createdAt": "2020-08-05T03:58:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjY4NTIxOA=="}], "type": "inlineReview"}, {"oid": "6d0545078fedda5ec13cb6161486e620b92ae5b3", "url": "https://github.com/apache/hudi/commit/6d0545078fedda5ec13cb6161486e620b92ae5b3", "message": "[HUDI-427] Implement CLI support for performing bootstrap", "committedDate": "2020-08-05T03:47:32Z", "type": "forcePushed"}, {"oid": "42512b780a4a52a3b9eda947d93aa22d99e53031", "url": "https://github.com/apache/hudi/commit/42512b780a4a52a3b9eda947d93aa22d99e53031", "message": "[HUDI-427] Implement CLI support for performing bootstrap", "committedDate": "2020-08-05T03:57:50Z", "type": "forcePushed"}, {"oid": "294ca475a90749d6700d6920921b601603bf4a50", "url": "https://github.com/apache/hudi/commit/294ca475a90749d6700d6920921b601603bf4a50", "message": "[HUDI-427] Implement CLI support for performing bootstrap", "committedDate": "2020-08-05T16:58:46Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjI0MDEwMA==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r466240100", "bodyText": "were the values currently returning something incorrect?  if so, how were the tests happy?", "author": "vinothchandar", "createdAt": "2020-08-06T08:38:13Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/bootstrap/index/HFileBootstrapIndex.java", "diffHunk": "@@ -240,13 +240,21 @@ private HoodieBootstrapIndexInfo fetchBootstrapIndexInfo() throws IOException {\n     @Override\n     public List<String> getIndexedPartitionPaths() {\n       HFileScanner scanner = partitionIndexReader().getScanner(true, true);\n-      return getAllKeys(scanner);\n+      List<String> cellKeys = getAllKeys(scanner);\n+      // cellKey is in this format:\n+      // part=datestr=2452537//LATEST_TIMESTAMP/Put/vlen=2405/seqid=0\n+      return cellKeys.stream().map(key -> key.split(\"//\")[0].substring(5))\n+          .distinct().collect(Collectors.toList());\n     }\n \n     @Override\n     public List<String> getIndexedFileIds() {\n       HFileScanner scanner = fileIdIndexReader().getScanner(true, true);\n-      return getAllKeys(scanner);\n+      List<String> cellKeys = getAllKeys(scanner);\n+      // cellKey is in this format:\n+      // part=datestr=2452537;fileid=baab9c50-c35e-49d1-b928-695aa7e37833//LATEST_TIMESTAMP/Put/vlen=2312/seqid=0\n+      return cellKeys.stream().map(key -> key.split(\"//\")[0].split(\";\")[1].split(\"=\")[1])", "originalCommit": "294ca475a90749d6700d6920921b601603bf4a50", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjI0ODYzMA==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r466248630", "bodyText": "I have this question too, but IIUC this code path was probably not being used till now. @zhedoubushishi can confirm.", "author": "umehrot2", "createdAt": "2020-08-06T08:52:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjI0MDEwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjU4OTQ3NA==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r466589474", "bodyText": "These two methods are only called in TestBootstrapIndex. And what it does in the test code is to check the size of the result, so that's why we fail to catch this error before. Let me create a separate commit/pr to include this fix and also add some test cases to cover these two methods.", "author": "zhedoubushishi", "createdAt": "2020-08-06T17:58:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjI0MDEwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjY5NjM2Ng==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r466696366", "bodyText": "This is a known issue: https://issues.apache.org/jira/browse/HUDI-971", "author": "zhedoubushishi", "createdAt": "2020-08-06T21:28:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjI0MDEwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEzMzg5MA==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r467133890", "bodyText": "@zhedoubushishi :  Can you instead copy the code from the PR #1933. This is essentially the same thing I fixed. I did not realize you have tried to address the issue here. IMO, PR 1933 is more cleaner", "author": "bvaradar", "createdAt": "2020-08-07T16:08:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjI0MDEwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEzNTU1OQ==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r467135559", "bodyText": "@zhedoubushishi : I will assign the original ticket to you", "author": "bvaradar", "createdAt": "2020-08-07T16:11:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjI0MDEwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzI3MjMyNg==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r467272326", "bodyText": "@bvaradar thanks! PR #1933 looks good to me. Migrated it into current PR.", "author": "zhedoubushishi", "createdAt": "2020-08-07T21:16:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjI0MDEwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjExNTE4MA==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r466115180", "bodyText": "OverwriteWithLatestAvroPayload is the default payload class that is used everywhere.", "author": "umehrot2", "createdAt": "2020-08-06T02:53:34Z", "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/BootstrapCommand.java", "diffHunk": "@@ -0,0 +1,184 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.commands;\n+\n+import org.apache.hudi.cli.HoodieCLI;\n+import org.apache.hudi.cli.HoodiePrintHelper;\n+import org.apache.hudi.cli.TableHeader;\n+import org.apache.hudi.cli.commands.SparkMain.SparkCommand;\n+import org.apache.hudi.cli.utils.InputStreamConsumer;\n+import org.apache.hudi.cli.utils.SparkUtil;\n+import org.apache.hudi.common.bootstrap.index.BootstrapIndex;\n+import org.apache.hudi.common.model.BootstrapFileMapping;\n+import org.apache.hudi.common.model.HoodieFileGroupId;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.utilities.UtilHelpers;\n+\n+import org.apache.spark.launcher.SparkLauncher;\n+import org.apache.spark.util.Utils;\n+import org.springframework.shell.core.CommandMarker;\n+import org.springframework.shell.core.annotation.CliCommand;\n+import org.springframework.shell.core.annotation.CliOption;\n+import org.springframework.stereotype.Component;\n+\n+import java.io.IOException;\n+import java.net.URISyntaxException;\n+import java.util.Arrays;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import scala.collection.JavaConverters;\n+\n+/**\n+ * CLI command to perform bootstrap action & display bootstrap index.\n+ */\n+@Component\n+public class BootstrapCommand implements CommandMarker {\n+\n+  @CliCommand(value = \"bootstrap run\", help = \"Run a bootstrap action for current Hudi table\")\n+  public String bootstrap(\n+      @CliOption(key = {\"srcPath\"}, mandatory = true, help = \"Bootstrap source data path of the table\") final String srcPath,\n+      @CliOption(key = {\"targetPath\"}, mandatory = true,\n+          help = \"Base path for the target hoodie table\") final String targetPath,\n+      @CliOption(key = {\"tableName\"}, mandatory = true, help = \"Hoodie table name\") final String tableName,\n+      @CliOption(key = {\"tableType\"}, mandatory = true, help = \"Hoodie table type\") final String tableType,\n+      @CliOption(key = {\"rowKeyField\"}, mandatory = true, help = \"Record key columns for bootstrap data\") final String rowKeyField,\n+      @CliOption(key = {\"partitionPathField\"}, unspecifiedDefaultValue = \"\",\n+          help = \"Partition fields for bootstrap source data\") final String partitionPathField,\n+      @CliOption(key = {\"bootstrapIndexClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.common.bootstrap.index.HFileBootstrapIndex\",\n+          help = \"Bootstrap Index Class\") final String bootstrapIndexClass,\n+      @CliOption(key = {\"selectorClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.client.bootstrap.selector.MetadataOnlyBootstrapModeSelector\",\n+          help = \"Selector class for bootstrap\") final String selectorClass,\n+      @CliOption(key = {\"keyGeneratorClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.keygen.SimpleKeyGenerator\",\n+          help = \"Key generator class for bootstrap\") final String keyGeneratorClass,\n+      @CliOption(key = {\"fullBootstrapInputProvider\"}, unspecifiedDefaultValue = \"org.apache.hudi.bootstrap.SparkParquetBootstrapDataProvider\",\n+          help = \"Class for Full bootstrap input provider\") final String fullBootstrapInputProvider,\n+      @CliOption(key = {\"schemaProviderClass\"}, unspecifiedDefaultValue = \"\",\n+          help = \"SchemaProvider to attach schemas to bootstrap source data\") final String schemaProviderClass,\n+      @CliOption(key = {\"payloadClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.common.model.HoodieAvroPayload\",", "originalCommit": "294ca475a90749d6700d6920921b601603bf4a50", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjU3MjA5OA==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r466572098", "bodyText": "I see. I saw create table command uses HoodieAvroPayload: https://github.com/apache/hudi/blob/master/hudi-cli/src/main/java/org/apache/hudi/cli/commands/TableCommand.java#L90.\nBut since deltastreamer and spark datasource both use OverwriteWithLatestAvroPayload, I think we should also change the default value of create table command to make it consistent.", "author": "zhedoubushishi", "createdAt": "2020-08-06T17:27:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjExNTE4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4MzU4Mw==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r467483583", "bodyText": "@n3nash : FYI", "author": "bvaradar", "createdAt": "2020-08-08T16:55:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjExNTE4MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjExNzY5NQ==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r466117695", "bodyText": "paritionPathField does not seem to be the right name for this field. In this case we are accepting the actual partition path, so partitionPath makes more sense.", "author": "umehrot2", "createdAt": "2020-08-06T03:03:58Z", "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/BootstrapCommand.java", "diffHunk": "@@ -0,0 +1,184 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.commands;\n+\n+import org.apache.hudi.cli.HoodieCLI;\n+import org.apache.hudi.cli.HoodiePrintHelper;\n+import org.apache.hudi.cli.TableHeader;\n+import org.apache.hudi.cli.commands.SparkMain.SparkCommand;\n+import org.apache.hudi.cli.utils.InputStreamConsumer;\n+import org.apache.hudi.cli.utils.SparkUtil;\n+import org.apache.hudi.common.bootstrap.index.BootstrapIndex;\n+import org.apache.hudi.common.model.BootstrapFileMapping;\n+import org.apache.hudi.common.model.HoodieFileGroupId;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.utilities.UtilHelpers;\n+\n+import org.apache.spark.launcher.SparkLauncher;\n+import org.apache.spark.util.Utils;\n+import org.springframework.shell.core.CommandMarker;\n+import org.springframework.shell.core.annotation.CliCommand;\n+import org.springframework.shell.core.annotation.CliOption;\n+import org.springframework.stereotype.Component;\n+\n+import java.io.IOException;\n+import java.net.URISyntaxException;\n+import java.util.Arrays;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import scala.collection.JavaConverters;\n+\n+/**\n+ * CLI command to perform bootstrap action & display bootstrap index.\n+ */\n+@Component\n+public class BootstrapCommand implements CommandMarker {\n+\n+  @CliCommand(value = \"bootstrap run\", help = \"Run a bootstrap action for current Hudi table\")\n+  public String bootstrap(\n+      @CliOption(key = {\"srcPath\"}, mandatory = true, help = \"Bootstrap source data path of the table\") final String srcPath,\n+      @CliOption(key = {\"targetPath\"}, mandatory = true,\n+          help = \"Base path for the target hoodie table\") final String targetPath,\n+      @CliOption(key = {\"tableName\"}, mandatory = true, help = \"Hoodie table name\") final String tableName,\n+      @CliOption(key = {\"tableType\"}, mandatory = true, help = \"Hoodie table type\") final String tableType,\n+      @CliOption(key = {\"rowKeyField\"}, mandatory = true, help = \"Record key columns for bootstrap data\") final String rowKeyField,\n+      @CliOption(key = {\"partitionPathField\"}, unspecifiedDefaultValue = \"\",\n+          help = \"Partition fields for bootstrap source data\") final String partitionPathField,\n+      @CliOption(key = {\"bootstrapIndexClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.common.bootstrap.index.HFileBootstrapIndex\",\n+          help = \"Bootstrap Index Class\") final String bootstrapIndexClass,\n+      @CliOption(key = {\"selectorClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.client.bootstrap.selector.MetadataOnlyBootstrapModeSelector\",\n+          help = \"Selector class for bootstrap\") final String selectorClass,\n+      @CliOption(key = {\"keyGeneratorClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.keygen.SimpleKeyGenerator\",\n+          help = \"Key generator class for bootstrap\") final String keyGeneratorClass,\n+      @CliOption(key = {\"fullBootstrapInputProvider\"}, unspecifiedDefaultValue = \"org.apache.hudi.bootstrap.SparkParquetBootstrapDataProvider\",\n+          help = \"Class for Full bootstrap input provider\") final String fullBootstrapInputProvider,\n+      @CliOption(key = {\"schemaProviderClass\"}, unspecifiedDefaultValue = \"\",\n+          help = \"SchemaProvider to attach schemas to bootstrap source data\") final String schemaProviderClass,\n+      @CliOption(key = {\"payloadClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.common.model.HoodieAvroPayload\",\n+          help = \"Payload Class\") final String payloadClass,\n+      @CliOption(key = {\"parallelism\"}, unspecifiedDefaultValue = \"1500\", help = \"Bootstrap writer parallelism\") final int parallelism,\n+      @CliOption(key = {\"sparkMaster\"}, unspecifiedDefaultValue = \"\", help = \"Spark Master\") String master,\n+      @CliOption(key = {\"sparkMemory\"}, unspecifiedDefaultValue = \"4G\", help = \"Spark executor memory\") final String sparkMemory,\n+      @CliOption(key = {\"enableHiveSync\"}, unspecifiedDefaultValue = \"false\", help = \"Enable Hive sync\") final Boolean enableHiveSync,\n+      @CliOption(key = {\"propsFilePath\"}, help = \"path to properties file on localfs or dfs with configurations for hoodie client for importing\",\n+          unspecifiedDefaultValue = \"\") final String propsFilePath,\n+      @CliOption(key = {\"hoodieConfigs\"}, help = \"Any configuration that can be set in the properties file can be passed here in the form of an array\",\n+          unspecifiedDefaultValue = \"\") final String[] configs)\n+      throws IOException, InterruptedException, URISyntaxException {\n+\n+    String sparkPropertiesPath =\n+        Utils.getDefaultPropertiesFile(JavaConverters.mapAsScalaMapConverter(System.getenv()).asScala());\n+\n+    SparkLauncher sparkLauncher = SparkUtil.initLauncher(sparkPropertiesPath);\n+\n+    String cmd = SparkCommand.BOOTSTRAP.toString();\n+\n+    sparkLauncher.addAppArgs(cmd, master, sparkMemory, tableName, tableType, targetPath, srcPath, rowKeyField,\n+        partitionPathField, String.valueOf(parallelism), schemaProviderClass, bootstrapIndexClass, selectorClass,\n+        keyGeneratorClass, fullBootstrapInputProvider, payloadClass, String.valueOf(enableHiveSync), propsFilePath);\n+    UtilHelpers.validateAndAddProperties(configs, sparkLauncher);\n+    Process process = sparkLauncher.launch();\n+    InputStreamConsumer.captureOutput(process);\n+    int exitCode = process.waitFor();\n+    if (exitCode != 0) {\n+      return \"Failed to bootstrap source data to Hudi dataset\";\n+    }\n+    return \"Bootstrapped source data as Hudi dataset\";\n+  }\n+\n+  @CliCommand(value = \"bootstrap index showMapping\", help = \"Show bootstrap index mapping\")\n+  public String showBootstrapIndexMapping(\n+      @CliOption(key = {\"partitionPathField\"}, unspecifiedDefaultValue = \"\", help = \"A valid paritition path\") String partitionPathField,", "originalCommit": "294ca475a90749d6700d6920921b601603bf4a50", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjU4OTc0Nw==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r466589747", "bodyText": "Good catch. Changed.", "author": "zhedoubushishi", "createdAt": "2020-08-06T17:58:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjExNzY5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjExOTM3MA==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r466119370", "bodyText": "HoodieException would be better here.", "author": "umehrot2", "createdAt": "2020-08-06T03:10:45Z", "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/BootstrapCommand.java", "diffHunk": "@@ -0,0 +1,184 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.commands;\n+\n+import org.apache.hudi.cli.HoodieCLI;\n+import org.apache.hudi.cli.HoodiePrintHelper;\n+import org.apache.hudi.cli.TableHeader;\n+import org.apache.hudi.cli.commands.SparkMain.SparkCommand;\n+import org.apache.hudi.cli.utils.InputStreamConsumer;\n+import org.apache.hudi.cli.utils.SparkUtil;\n+import org.apache.hudi.common.bootstrap.index.BootstrapIndex;\n+import org.apache.hudi.common.model.BootstrapFileMapping;\n+import org.apache.hudi.common.model.HoodieFileGroupId;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.utilities.UtilHelpers;\n+\n+import org.apache.spark.launcher.SparkLauncher;\n+import org.apache.spark.util.Utils;\n+import org.springframework.shell.core.CommandMarker;\n+import org.springframework.shell.core.annotation.CliCommand;\n+import org.springframework.shell.core.annotation.CliOption;\n+import org.springframework.stereotype.Component;\n+\n+import java.io.IOException;\n+import java.net.URISyntaxException;\n+import java.util.Arrays;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import scala.collection.JavaConverters;\n+\n+/**\n+ * CLI command to perform bootstrap action & display bootstrap index.\n+ */\n+@Component\n+public class BootstrapCommand implements CommandMarker {\n+\n+  @CliCommand(value = \"bootstrap run\", help = \"Run a bootstrap action for current Hudi table\")\n+  public String bootstrap(\n+      @CliOption(key = {\"srcPath\"}, mandatory = true, help = \"Bootstrap source data path of the table\") final String srcPath,\n+      @CliOption(key = {\"targetPath\"}, mandatory = true,\n+          help = \"Base path for the target hoodie table\") final String targetPath,\n+      @CliOption(key = {\"tableName\"}, mandatory = true, help = \"Hoodie table name\") final String tableName,\n+      @CliOption(key = {\"tableType\"}, mandatory = true, help = \"Hoodie table type\") final String tableType,\n+      @CliOption(key = {\"rowKeyField\"}, mandatory = true, help = \"Record key columns for bootstrap data\") final String rowKeyField,\n+      @CliOption(key = {\"partitionPathField\"}, unspecifiedDefaultValue = \"\",\n+          help = \"Partition fields for bootstrap source data\") final String partitionPathField,\n+      @CliOption(key = {\"bootstrapIndexClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.common.bootstrap.index.HFileBootstrapIndex\",\n+          help = \"Bootstrap Index Class\") final String bootstrapIndexClass,\n+      @CliOption(key = {\"selectorClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.client.bootstrap.selector.MetadataOnlyBootstrapModeSelector\",\n+          help = \"Selector class for bootstrap\") final String selectorClass,\n+      @CliOption(key = {\"keyGeneratorClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.keygen.SimpleKeyGenerator\",\n+          help = \"Key generator class for bootstrap\") final String keyGeneratorClass,\n+      @CliOption(key = {\"fullBootstrapInputProvider\"}, unspecifiedDefaultValue = \"org.apache.hudi.bootstrap.SparkParquetBootstrapDataProvider\",\n+          help = \"Class for Full bootstrap input provider\") final String fullBootstrapInputProvider,\n+      @CliOption(key = {\"schemaProviderClass\"}, unspecifiedDefaultValue = \"\",\n+          help = \"SchemaProvider to attach schemas to bootstrap source data\") final String schemaProviderClass,\n+      @CliOption(key = {\"payloadClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.common.model.HoodieAvroPayload\",\n+          help = \"Payload Class\") final String payloadClass,\n+      @CliOption(key = {\"parallelism\"}, unspecifiedDefaultValue = \"1500\", help = \"Bootstrap writer parallelism\") final int parallelism,\n+      @CliOption(key = {\"sparkMaster\"}, unspecifiedDefaultValue = \"\", help = \"Spark Master\") String master,\n+      @CliOption(key = {\"sparkMemory\"}, unspecifiedDefaultValue = \"4G\", help = \"Spark executor memory\") final String sparkMemory,\n+      @CliOption(key = {\"enableHiveSync\"}, unspecifiedDefaultValue = \"false\", help = \"Enable Hive sync\") final Boolean enableHiveSync,\n+      @CliOption(key = {\"propsFilePath\"}, help = \"path to properties file on localfs or dfs with configurations for hoodie client for importing\",\n+          unspecifiedDefaultValue = \"\") final String propsFilePath,\n+      @CliOption(key = {\"hoodieConfigs\"}, help = \"Any configuration that can be set in the properties file can be passed here in the form of an array\",\n+          unspecifiedDefaultValue = \"\") final String[] configs)\n+      throws IOException, InterruptedException, URISyntaxException {\n+\n+    String sparkPropertiesPath =\n+        Utils.getDefaultPropertiesFile(JavaConverters.mapAsScalaMapConverter(System.getenv()).asScala());\n+\n+    SparkLauncher sparkLauncher = SparkUtil.initLauncher(sparkPropertiesPath);\n+\n+    String cmd = SparkCommand.BOOTSTRAP.toString();\n+\n+    sparkLauncher.addAppArgs(cmd, master, sparkMemory, tableName, tableType, targetPath, srcPath, rowKeyField,\n+        partitionPathField, String.valueOf(parallelism), schemaProviderClass, bootstrapIndexClass, selectorClass,\n+        keyGeneratorClass, fullBootstrapInputProvider, payloadClass, String.valueOf(enableHiveSync), propsFilePath);\n+    UtilHelpers.validateAndAddProperties(configs, sparkLauncher);\n+    Process process = sparkLauncher.launch();\n+    InputStreamConsumer.captureOutput(process);\n+    int exitCode = process.waitFor();\n+    if (exitCode != 0) {\n+      return \"Failed to bootstrap source data to Hudi dataset\";\n+    }\n+    return \"Bootstrapped source data as Hudi dataset\";\n+  }\n+\n+  @CliCommand(value = \"bootstrap index showMapping\", help = \"Show bootstrap index mapping\")\n+  public String showBootstrapIndexMapping(\n+      @CliOption(key = {\"partitionPathField\"}, unspecifiedDefaultValue = \"\", help = \"A valid paritition path\") String partitionPathField,\n+      @CliOption(key = {\"fileIds\"}, unspecifiedDefaultValue = \"\", help = \"Valid fileIds split by comma\") String fileIds,\n+      @CliOption(key = {\"limit\"}, unspecifiedDefaultValue = \"-1\", help = \"Limit rows to be displayed\") Integer limit,\n+      @CliOption(key = {\"sortBy\"}, unspecifiedDefaultValue = \"\", help = \"Sorting Field\") final String sortByField,\n+      @CliOption(key = {\"desc\"}, unspecifiedDefaultValue = \"false\", help = \"Ordering\") final boolean descending,\n+      @CliOption(key = {\"headeronly\"}, unspecifiedDefaultValue = \"false\", help = \"Print Header Only\")\n+      final boolean headerOnly) {\n+\n+    if (partitionPathField.isEmpty() && !fileIds.isEmpty()) {\n+      throw new IllegalStateException(\"When passing fileIds, partitionPath is mandatory\");\n+    }\n+    BootstrapIndex.IndexReader indexReader = createBootstrapIndexReader();\n+    List<String> indexedPartitions = indexReader.getIndexedPartitionPaths();\n+\n+    if (!partitionPathField.isEmpty() && !indexedPartitions.contains(partitionPathField)) {\n+      return partitionPathField + \" is not an valid indexed partition\";\n+    }\n+\n+    List<BootstrapFileMapping> mappingList = new ArrayList<>();\n+    if (!fileIds.isEmpty()) {\n+      List<HoodieFileGroupId> fileGroupIds = Arrays.stream(fileIds.split(\",\"))\n+          .map(fileId -> new HoodieFileGroupId(partitionPathField, fileId)).collect(Collectors.toList());\n+      mappingList.addAll(indexReader.getSourceFileMappingForFileIds(fileGroupIds).values());\n+    } else if (!partitionPathField.isEmpty()) {\n+      mappingList.addAll(indexReader.getSourceFileMappingForPartition(partitionPathField));\n+    } else {\n+      for (String part : indexedPartitions) {\n+        mappingList.addAll(indexReader.getSourceFileMappingForPartition(part));\n+      }\n+    }\n+\n+    final List<Comparable[]> rows = convertBootstrapSourceFileMapping(mappingList);\n+    final TableHeader header = new TableHeader()\n+        .addTableHeaderField(\"Hudi Partition\")\n+        .addTableHeaderField(\"FileId\")\n+        .addTableHeaderField(\"Source File Base Path\")\n+        .addTableHeaderField(\"Source File Parition\")\n+        .addTableHeaderField(\"Source File Path\");\n+\n+    return HoodiePrintHelper.print(header, new HashMap<>(), sortByField, descending,\n+        limit, headerOnly, rows);\n+  }\n+\n+  @CliCommand(value = \"bootstrap index showPartitions\", help = \"Show bootstrap indexed partitions\")\n+  public String showBootstrapIndexPartitions() {\n+\n+    BootstrapIndex.IndexReader indexReader = createBootstrapIndexReader();\n+    List<String> indexedPartitions = indexReader.getIndexedPartitionPaths();\n+\n+    String[] header = new String[] {\"Indexed partitions\"};\n+    String[][] rows = new String[indexedPartitions.size()][1];\n+    for (int i = 0; i < indexedPartitions.size(); i++) {\n+      rows[i][0] = indexedPartitions.get(i);\n+    }\n+    return HoodiePrintHelper.print(header, rows);\n+  }\n+\n+  private BootstrapIndex.IndexReader createBootstrapIndexReader() {\n+    HoodieTableMetaClient metaClient = HoodieCLI.getTableMetaClient();\n+    BootstrapIndex index = BootstrapIndex.getBootstrapIndex(metaClient);\n+    if (!index.isPresent()) {\n+      throw new IllegalStateException(\"This is not a bootstraped Hudi table. Don't have any index info\");", "originalCommit": "294ca475a90749d6700d6920921b601603bf4a50", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEyMzMyNA==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r466123324", "bodyText": "How does enableHiveSync work by itself without other hive related parameters like database, table etc.", "author": "umehrot2", "createdAt": "2020-08-06T03:26:52Z", "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/BootstrapCommand.java", "diffHunk": "@@ -0,0 +1,184 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.commands;\n+\n+import org.apache.hudi.cli.HoodieCLI;\n+import org.apache.hudi.cli.HoodiePrintHelper;\n+import org.apache.hudi.cli.TableHeader;\n+import org.apache.hudi.cli.commands.SparkMain.SparkCommand;\n+import org.apache.hudi.cli.utils.InputStreamConsumer;\n+import org.apache.hudi.cli.utils.SparkUtil;\n+import org.apache.hudi.common.bootstrap.index.BootstrapIndex;\n+import org.apache.hudi.common.model.BootstrapFileMapping;\n+import org.apache.hudi.common.model.HoodieFileGroupId;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.utilities.UtilHelpers;\n+\n+import org.apache.spark.launcher.SparkLauncher;\n+import org.apache.spark.util.Utils;\n+import org.springframework.shell.core.CommandMarker;\n+import org.springframework.shell.core.annotation.CliCommand;\n+import org.springframework.shell.core.annotation.CliOption;\n+import org.springframework.stereotype.Component;\n+\n+import java.io.IOException;\n+import java.net.URISyntaxException;\n+import java.util.Arrays;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import scala.collection.JavaConverters;\n+\n+/**\n+ * CLI command to perform bootstrap action & display bootstrap index.\n+ */\n+@Component\n+public class BootstrapCommand implements CommandMarker {\n+\n+  @CliCommand(value = \"bootstrap run\", help = \"Run a bootstrap action for current Hudi table\")\n+  public String bootstrap(\n+      @CliOption(key = {\"srcPath\"}, mandatory = true, help = \"Bootstrap source data path of the table\") final String srcPath,\n+      @CliOption(key = {\"targetPath\"}, mandatory = true,\n+          help = \"Base path for the target hoodie table\") final String targetPath,\n+      @CliOption(key = {\"tableName\"}, mandatory = true, help = \"Hoodie table name\") final String tableName,\n+      @CliOption(key = {\"tableType\"}, mandatory = true, help = \"Hoodie table type\") final String tableType,\n+      @CliOption(key = {\"rowKeyField\"}, mandatory = true, help = \"Record key columns for bootstrap data\") final String rowKeyField,\n+      @CliOption(key = {\"partitionPathField\"}, unspecifiedDefaultValue = \"\",\n+          help = \"Partition fields for bootstrap source data\") final String partitionPathField,\n+      @CliOption(key = {\"bootstrapIndexClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.common.bootstrap.index.HFileBootstrapIndex\",\n+          help = \"Bootstrap Index Class\") final String bootstrapIndexClass,\n+      @CliOption(key = {\"selectorClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.client.bootstrap.selector.MetadataOnlyBootstrapModeSelector\",\n+          help = \"Selector class for bootstrap\") final String selectorClass,\n+      @CliOption(key = {\"keyGeneratorClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.keygen.SimpleKeyGenerator\",\n+          help = \"Key generator class for bootstrap\") final String keyGeneratorClass,\n+      @CliOption(key = {\"fullBootstrapInputProvider\"}, unspecifiedDefaultValue = \"org.apache.hudi.bootstrap.SparkParquetBootstrapDataProvider\",\n+          help = \"Class for Full bootstrap input provider\") final String fullBootstrapInputProvider,\n+      @CliOption(key = {\"schemaProviderClass\"}, unspecifiedDefaultValue = \"\",\n+          help = \"SchemaProvider to attach schemas to bootstrap source data\") final String schemaProviderClass,\n+      @CliOption(key = {\"payloadClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.common.model.HoodieAvroPayload\",\n+          help = \"Payload Class\") final String payloadClass,\n+      @CliOption(key = {\"parallelism\"}, unspecifiedDefaultValue = \"1500\", help = \"Bootstrap writer parallelism\") final int parallelism,\n+      @CliOption(key = {\"sparkMaster\"}, unspecifiedDefaultValue = \"\", help = \"Spark Master\") String master,\n+      @CliOption(key = {\"sparkMemory\"}, unspecifiedDefaultValue = \"4G\", help = \"Spark executor memory\") final String sparkMemory,\n+      @CliOption(key = {\"enableHiveSync\"}, unspecifiedDefaultValue = \"false\", help = \"Enable Hive sync\") final Boolean enableHiveSync,", "originalCommit": "294ca475a90749d6700d6920921b601603bf4a50", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjU2MjA4Mw==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r466562083", "bodyText": "Here the usage is similar to DeltaStreamer: https://github.com/apache/hudi/blob/master/hudi-utilities/src/main/java/org/apache/hudi/utilities/deltastreamer/HoodieDeltaStreamer.java#L273. You need to add other options in --hoodie-conf or properties file.\nMaybe we should better document help to make it more clear.", "author": "zhedoubushishi", "createdAt": "2020-08-06T17:14:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEyMzMyNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzM2ODU4OA==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r467368588", "bodyText": "hoodieConfigs is a parameter that is already added  for this. Resolving this comment.", "author": "bvaradar", "createdAt": "2020-08-08T06:15:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEyMzMyNA=="}], "type": "inlineReview"}, {"oid": "6fcd70b697e3085efb08e0de4c349a923f7f739d", "url": "https://github.com/apache/hudi/commit/6fcd70b697e3085efb08e0de4c349a923f7f739d", "message": "[HUDI-427] Implement CLI support for performing bootstrap", "committedDate": "2020-08-06T20:38:54Z", "type": "forcePushed"}, {"oid": "765b87770dc7d270b8cb69d8dc32108057a283f2", "url": "https://github.com/apache/hudi/commit/765b87770dc7d270b8cb69d8dc32108057a283f2", "message": "[HUDI-427] Implement CLI support for performing bootstrap", "committedDate": "2020-08-06T20:45:15Z", "type": "forcePushed"}, {"oid": "f5ee921d9d43594b04e46da9de49d0055396f8ad", "url": "https://github.com/apache/hudi/commit/f5ee921d9d43594b04e46da9de49d0055396f8ad", "message": "[HUDI-427] Implement CLI support for performing bootstrap", "committedDate": "2020-08-06T21:26:03Z", "type": "forcePushed"}, {"oid": "3a8b113ad295802d163533f50f9b2bf7ef46289f", "url": "https://github.com/apache/hudi/commit/3a8b113ad295802d163533f50f9b2bf7ef46289f", "message": "[HUDI-971] Clean partitions & fileIds returned by HFileBootstrapIndex", "committedDate": "2020-08-07T21:13:18Z", "type": "commit"}, {"oid": "5bf14eb44a026095d2cfee0c757192b221943ec7", "url": "https://github.com/apache/hudi/commit/5bf14eb44a026095d2cfee0c757192b221943ec7", "message": "[HUDI-427] Implement CLI support for performing bootstrap", "committedDate": "2020-08-07T21:13:18Z", "type": "commit"}, {"oid": "5bf14eb44a026095d2cfee0c757192b221943ec7", "url": "https://github.com/apache/hudi/commit/5bf14eb44a026095d2cfee0c757192b221943ec7", "message": "[HUDI-427] Implement CLI support for performing bootstrap", "committedDate": "2020-08-07T21:13:18Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzM2OTM4Mg==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r467369382", "bodyText": "I reverted this method to be protected. This should not be used directly by  clients.", "author": "bvaradar", "createdAt": "2020-08-08T06:25:51Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/bootstrap/index/BootstrapIndex.java", "diffHunk": "@@ -73,12 +73,12 @@ public final boolean useIndex() {\n   /**\n    * Check if bootstrap Index is present and ensures readable.\n    */\n-  protected abstract boolean isPresent();\n+  public abstract boolean isPresent();", "originalCommit": "5bf14eb44a026095d2cfee0c757192b221943ec7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzM2OTQ2MA==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r467369460", "bodyText": "TO preserve uniformity with other CLIs, I renamed the CLI to be \"bootstrap index showpartitions\"", "author": "bvaradar", "createdAt": "2020-08-08T06:26:45Z", "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/BootstrapCommand.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.commands;\n+\n+import org.apache.hudi.cli.HoodieCLI;\n+import org.apache.hudi.cli.HoodiePrintHelper;\n+import org.apache.hudi.cli.TableHeader;\n+import org.apache.hudi.cli.commands.SparkMain.SparkCommand;\n+import org.apache.hudi.cli.utils.InputStreamConsumer;\n+import org.apache.hudi.cli.utils.SparkUtil;\n+import org.apache.hudi.common.bootstrap.index.BootstrapIndex;\n+import org.apache.hudi.common.model.BootstrapFileMapping;\n+import org.apache.hudi.common.model.HoodieFileGroupId;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.exception.HoodieException;\n+import org.apache.hudi.utilities.UtilHelpers;\n+\n+import org.apache.spark.launcher.SparkLauncher;\n+import org.apache.spark.util.Utils;\n+import org.springframework.shell.core.CommandMarker;\n+import org.springframework.shell.core.annotation.CliCommand;\n+import org.springframework.shell.core.annotation.CliOption;\n+import org.springframework.stereotype.Component;\n+\n+import java.io.IOException;\n+import java.net.URISyntaxException;\n+import java.util.Arrays;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import scala.collection.JavaConverters;\n+\n+/**\n+ * CLI command to perform bootstrap action & display bootstrap index.\n+ */\n+@Component\n+public class BootstrapCommand implements CommandMarker {\n+\n+  @CliCommand(value = \"bootstrap run\", help = \"Run a bootstrap action for current Hudi table\")\n+  public String bootstrap(\n+      @CliOption(key = {\"srcPath\"}, mandatory = true, help = \"Bootstrap source data path of the table\") final String srcPath,\n+      @CliOption(key = {\"targetPath\"}, mandatory = true,\n+          help = \"Base path for the target hoodie table\") final String targetPath,\n+      @CliOption(key = {\"tableName\"}, mandatory = true, help = \"Hoodie table name\") final String tableName,\n+      @CliOption(key = {\"tableType\"}, mandatory = true, help = \"Hoodie table type\") final String tableType,\n+      @CliOption(key = {\"rowKeyField\"}, mandatory = true, help = \"Record key columns for bootstrap data\") final String rowKeyField,\n+      @CliOption(key = {\"partitionPathField\"}, unspecifiedDefaultValue = \"\",\n+          help = \"Partition fields for bootstrap source data\") final String partitionPathField,\n+      @CliOption(key = {\"bootstrapIndexClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.common.bootstrap.index.HFileBootstrapIndex\",\n+          help = \"Bootstrap Index Class\") final String bootstrapIndexClass,\n+      @CliOption(key = {\"selectorClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.client.bootstrap.selector.MetadataOnlyBootstrapModeSelector\",\n+          help = \"Selector class for bootstrap\") final String selectorClass,\n+      @CliOption(key = {\"keyGeneratorClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.keygen.SimpleKeyGenerator\",\n+          help = \"Key generator class for bootstrap\") final String keyGeneratorClass,\n+      @CliOption(key = {\"fullBootstrapInputProvider\"}, unspecifiedDefaultValue = \"org.apache.hudi.bootstrap.SparkParquetBootstrapDataProvider\",\n+          help = \"Class for Full bootstrap input provider\") final String fullBootstrapInputProvider,\n+      @CliOption(key = {\"schemaProviderClass\"}, unspecifiedDefaultValue = \"\",\n+          help = \"SchemaProvider to attach schemas to bootstrap source data\") final String schemaProviderClass,\n+      @CliOption(key = {\"payloadClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.common.model.OverwriteWithLatestAvroPayload\",\n+          help = \"Payload Class\") final String payloadClass,\n+      @CliOption(key = {\"parallelism\"}, unspecifiedDefaultValue = \"1500\", help = \"Bootstrap writer parallelism\") final int parallelism,\n+      @CliOption(key = {\"sparkMaster\"}, unspecifiedDefaultValue = \"\", help = \"Spark Master\") String master,\n+      @CliOption(key = {\"sparkMemory\"}, unspecifiedDefaultValue = \"4G\", help = \"Spark executor memory\") final String sparkMemory,\n+      @CliOption(key = {\"enableHiveSync\"}, unspecifiedDefaultValue = \"false\", help = \"Enable Hive sync\") final Boolean enableHiveSync,\n+      @CliOption(key = {\"propsFilePath\"}, help = \"path to properties file on localfs or dfs with configurations for hoodie client for importing\",\n+          unspecifiedDefaultValue = \"\") final String propsFilePath,\n+      @CliOption(key = {\"hoodieConfigs\"}, help = \"Any configuration that can be set in the properties file can be passed here in the form of an array\",\n+          unspecifiedDefaultValue = \"\") final String[] configs)\n+      throws IOException, InterruptedException, URISyntaxException {\n+\n+    String sparkPropertiesPath =\n+        Utils.getDefaultPropertiesFile(JavaConverters.mapAsScalaMapConverter(System.getenv()).asScala());\n+\n+    SparkLauncher sparkLauncher = SparkUtil.initLauncher(sparkPropertiesPath);\n+\n+    String cmd = SparkCommand.BOOTSTRAP.toString();\n+\n+    sparkLauncher.addAppArgs(cmd, master, sparkMemory, tableName, tableType, targetPath, srcPath, rowKeyField,\n+        partitionPathField, String.valueOf(parallelism), schemaProviderClass, bootstrapIndexClass, selectorClass,\n+        keyGeneratorClass, fullBootstrapInputProvider, payloadClass, String.valueOf(enableHiveSync), propsFilePath);\n+    UtilHelpers.validateAndAddProperties(configs, sparkLauncher);\n+    Process process = sparkLauncher.launch();\n+    InputStreamConsumer.captureOutput(process);\n+    int exitCode = process.waitFor();\n+    if (exitCode != 0) {\n+      return \"Failed to bootstrap source data to Hudi dataset\";\n+    }\n+    return \"Bootstrapped source data as Hudi dataset\";\n+  }\n+\n+  @CliCommand(value = \"bootstrap index showMapping\", help = \"Show bootstrap index mapping\")\n+  public String showBootstrapIndexMapping(\n+      @CliOption(key = {\"partitionPath\"}, unspecifiedDefaultValue = \"\", help = \"A valid paritition path\") String partitionPath,\n+      @CliOption(key = {\"fileIds\"}, unspecifiedDefaultValue = \"\", help = \"Valid fileIds split by comma\") String fileIds,\n+      @CliOption(key = {\"limit\"}, unspecifiedDefaultValue = \"-1\", help = \"Limit rows to be displayed\") Integer limit,\n+      @CliOption(key = {\"sortBy\"}, unspecifiedDefaultValue = \"\", help = \"Sorting Field\") final String sortByField,\n+      @CliOption(key = {\"desc\"}, unspecifiedDefaultValue = \"false\", help = \"Ordering\") final boolean descending,\n+      @CliOption(key = {\"headeronly\"}, unspecifiedDefaultValue = \"false\", help = \"Print Header Only\")\n+      final boolean headerOnly) {\n+\n+    if (partitionPath.isEmpty() && !fileIds.isEmpty()) {\n+      throw new IllegalStateException(\"When passing fileIds, partitionPath is mandatory\");\n+    }\n+    BootstrapIndex.IndexReader indexReader = createBootstrapIndexReader();\n+    List<String> indexedPartitions = indexReader.getIndexedPartitionPaths();\n+\n+    if (!partitionPath.isEmpty() && !indexedPartitions.contains(partitionPath)) {\n+      return partitionPath + \" is not an valid indexed partition\";\n+    }\n+\n+    List<BootstrapFileMapping> mappingList = new ArrayList<>();\n+    if (!fileIds.isEmpty()) {\n+      List<HoodieFileGroupId> fileGroupIds = Arrays.stream(fileIds.split(\",\"))\n+          .map(fileId -> new HoodieFileGroupId(partitionPath, fileId)).collect(Collectors.toList());\n+      mappingList.addAll(indexReader.getSourceFileMappingForFileIds(fileGroupIds).values());\n+    } else if (!partitionPath.isEmpty()) {\n+      mappingList.addAll(indexReader.getSourceFileMappingForPartition(partitionPath));\n+    } else {\n+      for (String part : indexedPartitions) {\n+        mappingList.addAll(indexReader.getSourceFileMappingForPartition(part));\n+      }\n+    }\n+\n+    final List<Comparable[]> rows = convertBootstrapSourceFileMapping(mappingList);\n+    final TableHeader header = new TableHeader()\n+        .addTableHeaderField(\"Hudi Partition\")\n+        .addTableHeaderField(\"FileId\")\n+        .addTableHeaderField(\"Source File Base Path\")\n+        .addTableHeaderField(\"Source File Parition\")\n+        .addTableHeaderField(\"Source File Path\");\n+\n+    return HoodiePrintHelper.print(header, new HashMap<>(), sortByField, descending,\n+        limit, headerOnly, rows);\n+  }\n+\n+  @CliCommand(value = \"bootstrap index showPartitions\", help = \"Show bootstrap indexed partitions\")", "originalCommit": "5bf14eb44a026095d2cfee0c757192b221943ec7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzM2OTQ4Ng==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r467369486", "bodyText": "TO preserve uniformity with other CLIs, I renamed the CLI to be \"bootstrap index showmapping\"", "author": "bvaradar", "createdAt": "2020-08-08T06:26:59Z", "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/BootstrapCommand.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.commands;\n+\n+import org.apache.hudi.cli.HoodieCLI;\n+import org.apache.hudi.cli.HoodiePrintHelper;\n+import org.apache.hudi.cli.TableHeader;\n+import org.apache.hudi.cli.commands.SparkMain.SparkCommand;\n+import org.apache.hudi.cli.utils.InputStreamConsumer;\n+import org.apache.hudi.cli.utils.SparkUtil;\n+import org.apache.hudi.common.bootstrap.index.BootstrapIndex;\n+import org.apache.hudi.common.model.BootstrapFileMapping;\n+import org.apache.hudi.common.model.HoodieFileGroupId;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.exception.HoodieException;\n+import org.apache.hudi.utilities.UtilHelpers;\n+\n+import org.apache.spark.launcher.SparkLauncher;\n+import org.apache.spark.util.Utils;\n+import org.springframework.shell.core.CommandMarker;\n+import org.springframework.shell.core.annotation.CliCommand;\n+import org.springframework.shell.core.annotation.CliOption;\n+import org.springframework.stereotype.Component;\n+\n+import java.io.IOException;\n+import java.net.URISyntaxException;\n+import java.util.Arrays;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import scala.collection.JavaConverters;\n+\n+/**\n+ * CLI command to perform bootstrap action & display bootstrap index.\n+ */\n+@Component\n+public class BootstrapCommand implements CommandMarker {\n+\n+  @CliCommand(value = \"bootstrap run\", help = \"Run a bootstrap action for current Hudi table\")\n+  public String bootstrap(\n+      @CliOption(key = {\"srcPath\"}, mandatory = true, help = \"Bootstrap source data path of the table\") final String srcPath,\n+      @CliOption(key = {\"targetPath\"}, mandatory = true,\n+          help = \"Base path for the target hoodie table\") final String targetPath,\n+      @CliOption(key = {\"tableName\"}, mandatory = true, help = \"Hoodie table name\") final String tableName,\n+      @CliOption(key = {\"tableType\"}, mandatory = true, help = \"Hoodie table type\") final String tableType,\n+      @CliOption(key = {\"rowKeyField\"}, mandatory = true, help = \"Record key columns for bootstrap data\") final String rowKeyField,\n+      @CliOption(key = {\"partitionPathField\"}, unspecifiedDefaultValue = \"\",\n+          help = \"Partition fields for bootstrap source data\") final String partitionPathField,\n+      @CliOption(key = {\"bootstrapIndexClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.common.bootstrap.index.HFileBootstrapIndex\",\n+          help = \"Bootstrap Index Class\") final String bootstrapIndexClass,\n+      @CliOption(key = {\"selectorClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.client.bootstrap.selector.MetadataOnlyBootstrapModeSelector\",\n+          help = \"Selector class for bootstrap\") final String selectorClass,\n+      @CliOption(key = {\"keyGeneratorClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.keygen.SimpleKeyGenerator\",\n+          help = \"Key generator class for bootstrap\") final String keyGeneratorClass,\n+      @CliOption(key = {\"fullBootstrapInputProvider\"}, unspecifiedDefaultValue = \"org.apache.hudi.bootstrap.SparkParquetBootstrapDataProvider\",\n+          help = \"Class for Full bootstrap input provider\") final String fullBootstrapInputProvider,\n+      @CliOption(key = {\"schemaProviderClass\"}, unspecifiedDefaultValue = \"\",\n+          help = \"SchemaProvider to attach schemas to bootstrap source data\") final String schemaProviderClass,\n+      @CliOption(key = {\"payloadClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.common.model.OverwriteWithLatestAvroPayload\",\n+          help = \"Payload Class\") final String payloadClass,\n+      @CliOption(key = {\"parallelism\"}, unspecifiedDefaultValue = \"1500\", help = \"Bootstrap writer parallelism\") final int parallelism,\n+      @CliOption(key = {\"sparkMaster\"}, unspecifiedDefaultValue = \"\", help = \"Spark Master\") String master,\n+      @CliOption(key = {\"sparkMemory\"}, unspecifiedDefaultValue = \"4G\", help = \"Spark executor memory\") final String sparkMemory,\n+      @CliOption(key = {\"enableHiveSync\"}, unspecifiedDefaultValue = \"false\", help = \"Enable Hive sync\") final Boolean enableHiveSync,\n+      @CliOption(key = {\"propsFilePath\"}, help = \"path to properties file on localfs or dfs with configurations for hoodie client for importing\",\n+          unspecifiedDefaultValue = \"\") final String propsFilePath,\n+      @CliOption(key = {\"hoodieConfigs\"}, help = \"Any configuration that can be set in the properties file can be passed here in the form of an array\",\n+          unspecifiedDefaultValue = \"\") final String[] configs)\n+      throws IOException, InterruptedException, URISyntaxException {\n+\n+    String sparkPropertiesPath =\n+        Utils.getDefaultPropertiesFile(JavaConverters.mapAsScalaMapConverter(System.getenv()).asScala());\n+\n+    SparkLauncher sparkLauncher = SparkUtil.initLauncher(sparkPropertiesPath);\n+\n+    String cmd = SparkCommand.BOOTSTRAP.toString();\n+\n+    sparkLauncher.addAppArgs(cmd, master, sparkMemory, tableName, tableType, targetPath, srcPath, rowKeyField,\n+        partitionPathField, String.valueOf(parallelism), schemaProviderClass, bootstrapIndexClass, selectorClass,\n+        keyGeneratorClass, fullBootstrapInputProvider, payloadClass, String.valueOf(enableHiveSync), propsFilePath);\n+    UtilHelpers.validateAndAddProperties(configs, sparkLauncher);\n+    Process process = sparkLauncher.launch();\n+    InputStreamConsumer.captureOutput(process);\n+    int exitCode = process.waitFor();\n+    if (exitCode != 0) {\n+      return \"Failed to bootstrap source data to Hudi dataset\";\n+    }\n+    return \"Bootstrapped source data as Hudi dataset\";\n+  }\n+\n+  @CliCommand(value = \"bootstrap index showMapping\", help = \"Show bootstrap index mapping\")", "originalCommit": "5bf14eb44a026095d2cfee0c757192b221943ec7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzM3MDM0Ng==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r467370346", "bodyText": "Nit: typos, Will fix them", "author": "bvaradar", "createdAt": "2020-08-08T06:38:14Z", "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/BootstrapCommand.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.commands;\n+\n+import org.apache.hudi.cli.HoodieCLI;\n+import org.apache.hudi.cli.HoodiePrintHelper;\n+import org.apache.hudi.cli.TableHeader;\n+import org.apache.hudi.cli.commands.SparkMain.SparkCommand;\n+import org.apache.hudi.cli.utils.InputStreamConsumer;\n+import org.apache.hudi.cli.utils.SparkUtil;\n+import org.apache.hudi.common.bootstrap.index.BootstrapIndex;\n+import org.apache.hudi.common.model.BootstrapFileMapping;\n+import org.apache.hudi.common.model.HoodieFileGroupId;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.exception.HoodieException;\n+import org.apache.hudi.utilities.UtilHelpers;\n+\n+import org.apache.spark.launcher.SparkLauncher;\n+import org.apache.spark.util.Utils;\n+import org.springframework.shell.core.CommandMarker;\n+import org.springframework.shell.core.annotation.CliCommand;\n+import org.springframework.shell.core.annotation.CliOption;\n+import org.springframework.stereotype.Component;\n+\n+import java.io.IOException;\n+import java.net.URISyntaxException;\n+import java.util.Arrays;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import scala.collection.JavaConverters;\n+\n+/**\n+ * CLI command to perform bootstrap action & display bootstrap index.\n+ */\n+@Component\n+public class BootstrapCommand implements CommandMarker {\n+\n+  @CliCommand(value = \"bootstrap run\", help = \"Run a bootstrap action for current Hudi table\")\n+  public String bootstrap(\n+      @CliOption(key = {\"srcPath\"}, mandatory = true, help = \"Bootstrap source data path of the table\") final String srcPath,\n+      @CliOption(key = {\"targetPath\"}, mandatory = true,\n+          help = \"Base path for the target hoodie table\") final String targetPath,\n+      @CliOption(key = {\"tableName\"}, mandatory = true, help = \"Hoodie table name\") final String tableName,\n+      @CliOption(key = {\"tableType\"}, mandatory = true, help = \"Hoodie table type\") final String tableType,\n+      @CliOption(key = {\"rowKeyField\"}, mandatory = true, help = \"Record key columns for bootstrap data\") final String rowKeyField,\n+      @CliOption(key = {\"partitionPathField\"}, unspecifiedDefaultValue = \"\",\n+          help = \"Partition fields for bootstrap source data\") final String partitionPathField,\n+      @CliOption(key = {\"bootstrapIndexClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.common.bootstrap.index.HFileBootstrapIndex\",\n+          help = \"Bootstrap Index Class\") final String bootstrapIndexClass,\n+      @CliOption(key = {\"selectorClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.client.bootstrap.selector.MetadataOnlyBootstrapModeSelector\",\n+          help = \"Selector class for bootstrap\") final String selectorClass,\n+      @CliOption(key = {\"keyGeneratorClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.keygen.SimpleKeyGenerator\",\n+          help = \"Key generator class for bootstrap\") final String keyGeneratorClass,\n+      @CliOption(key = {\"fullBootstrapInputProvider\"}, unspecifiedDefaultValue = \"org.apache.hudi.bootstrap.SparkParquetBootstrapDataProvider\",\n+          help = \"Class for Full bootstrap input provider\") final String fullBootstrapInputProvider,\n+      @CliOption(key = {\"schemaProviderClass\"}, unspecifiedDefaultValue = \"\",\n+          help = \"SchemaProvider to attach schemas to bootstrap source data\") final String schemaProviderClass,\n+      @CliOption(key = {\"payloadClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.common.model.OverwriteWithLatestAvroPayload\",\n+          help = \"Payload Class\") final String payloadClass,\n+      @CliOption(key = {\"parallelism\"}, unspecifiedDefaultValue = \"1500\", help = \"Bootstrap writer parallelism\") final int parallelism,\n+      @CliOption(key = {\"sparkMaster\"}, unspecifiedDefaultValue = \"\", help = \"Spark Master\") String master,\n+      @CliOption(key = {\"sparkMemory\"}, unspecifiedDefaultValue = \"4G\", help = \"Spark executor memory\") final String sparkMemory,\n+      @CliOption(key = {\"enableHiveSync\"}, unspecifiedDefaultValue = \"false\", help = \"Enable Hive sync\") final Boolean enableHiveSync,\n+      @CliOption(key = {\"propsFilePath\"}, help = \"path to properties file on localfs or dfs with configurations for hoodie client for importing\",\n+          unspecifiedDefaultValue = \"\") final String propsFilePath,\n+      @CliOption(key = {\"hoodieConfigs\"}, help = \"Any configuration that can be set in the properties file can be passed here in the form of an array\",\n+          unspecifiedDefaultValue = \"\") final String[] configs)\n+      throws IOException, InterruptedException, URISyntaxException {\n+\n+    String sparkPropertiesPath =\n+        Utils.getDefaultPropertiesFile(JavaConverters.mapAsScalaMapConverter(System.getenv()).asScala());\n+\n+    SparkLauncher sparkLauncher = SparkUtil.initLauncher(sparkPropertiesPath);\n+\n+    String cmd = SparkCommand.BOOTSTRAP.toString();\n+\n+    sparkLauncher.addAppArgs(cmd, master, sparkMemory, tableName, tableType, targetPath, srcPath, rowKeyField,\n+        partitionPathField, String.valueOf(parallelism), schemaProviderClass, bootstrapIndexClass, selectorClass,\n+        keyGeneratorClass, fullBootstrapInputProvider, payloadClass, String.valueOf(enableHiveSync), propsFilePath);\n+    UtilHelpers.validateAndAddProperties(configs, sparkLauncher);\n+    Process process = sparkLauncher.launch();\n+    InputStreamConsumer.captureOutput(process);\n+    int exitCode = process.waitFor();\n+    if (exitCode != 0) {\n+      return \"Failed to bootstrap source data to Hudi dataset\";\n+    }\n+    return \"Bootstrapped source data as Hudi dataset\";\n+  }\n+\n+  @CliCommand(value = \"bootstrap index showMapping\", help = \"Show bootstrap index mapping\")\n+  public String showBootstrapIndexMapping(\n+      @CliOption(key = {\"partitionPath\"}, unspecifiedDefaultValue = \"\", help = \"A valid paritition path\") String partitionPath,", "originalCommit": "5bf14eb44a026095d2cfee0c757192b221943ec7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "99e5d7a7a7073a03d8408e40561032813821f7ed", "url": "https://github.com/apache/hudi/commit/99e5d7a7a7073a03d8408e40561032813821f7ed", "message": "[HUDI-427] Address review comments", "committedDate": "2020-08-08T06:41:09Z", "type": "commit"}, {"oid": "22009287af4244992fd5a0136c8ba28df64cd2cb", "url": "https://github.com/apache/hudi/commit/22009287af4244992fd5a0136c8ba28df64cd2cb", "message": "Add error message for a failing test", "committedDate": "2020-08-08T07:35:47Z", "type": "commit"}, {"oid": "5546c15334974a066962facd356d4fd25bd56542", "url": "https://github.com/apache/hudi/commit/5546c15334974a066962facd356d4fd25bd56542", "message": "Add error message for a failing test", "committedDate": "2020-08-08T08:08:33Z", "type": "commit"}, {"oid": "f9dd21b257ee6266e797e42d5ad7dcb6657bc2a4", "url": "https://github.com/apache/hudi/commit/f9dd21b257ee6266e797e42d5ad7dcb6657bc2a4", "message": "Reverting default payload class", "committedDate": "2020-08-08T17:48:02Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4ODMxNg==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r467488316", "bodyText": "Let's retain the old payload class for now. We can rethink about this as part of upgrade-downgrade (https://issues.apache.org/jira/browse/HUDI-1172)", "author": "bvaradar", "createdAt": "2020-08-08T17:51:24Z", "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/TableCommand.java", "diffHunk": "@@ -87,7 +87,7 @@ public String createTable(\n           help = \"Hoodie Table Type. Must be one of : COPY_ON_WRITE or MERGE_ON_READ\") final String tableTypeStr,\n       @CliOption(key = {\"archiveLogFolder\"}, help = \"Folder Name for storing archived timeline\") String archiveFolder,\n       @CliOption(key = {\"layoutVersion\"}, help = \"Specific Layout Version to use\") Integer layoutVersion,\n-      @CliOption(key = {\"payloadClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.common.model.HoodieAvroPayload\",\n+      @CliOption(key = {\"payloadClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.common.model.OverwriteWithLatestAvroPayload\",", "originalCommit": "5546c15334974a066962facd356d4fd25bd56542", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}