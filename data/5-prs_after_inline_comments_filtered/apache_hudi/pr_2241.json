{"pr_number": 2241, "pr_title": "[HUDI-1384] Decoupling hive jdbc dependency when HIVE_USE_JDBC_OPT_KE\u2026", "pr_createdAt": "2020-11-10T12:50:32Z", "pr_url": "https://github.com/apache/hudi/pull/2241", "timeline": [{"oid": "519f16e8350197aab729ef10724e25e42b3e7036", "url": "https://github.com/apache/hudi/commit/519f16e8350197aab729ef10724e25e42b3e7036", "message": "[HUDI-1384] Decoupling hive jdbc dependency when HIVE_USE_JDBC_OPT_KEY set false", "committedDate": "2020-11-10T12:48:15Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjAyMDI1OA==", "url": "https://github.com/apache/hudi/pull/2241#discussion_r522020258", "bodyText": "Hi @pengzhiwei2018, thanks for your contribution.\nIIUC,  when you are using this feature, no matter you set HIVE_USE_JDBC_OPT_KEY to true or false, the hive-jdbc jar has already been included in hudi binary jar. so this pr is unnecessary.\nWDYT?", "author": "wangxianghu", "createdAt": "2020-11-12T11:01:43Z", "path": "hudi-sync/hudi-hive-sync/src/main/java/org/apache/hudi/hive/HoodieHiveClient.java", "diffHunk": "@@ -426,7 +415,7 @@ public CommandProcessorResponse updateHiveSQLUsingHiveDriver(String sql) {\n   private void createHiveConnection() {\n     if (connection == null) {\n       try {\n-        Class.forName(HiveDriver.class.getCanonicalName());\n+        Class.forName(\"org.apache.hive.jdbc.HiveDriver\");\n       } catch (ClassNotFoundException e) {", "originalCommit": "519f16e8350197aab729ef10724e25e42b3e7036", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzMwNTYxNQ==", "url": "https://github.com/apache/hudi/pull/2241#discussion_r523305615", "bodyText": "Thanks for you response  @wangxianghu . When we debug code with the HIVE_USE_JDBC_OPT_KEY=false  in IDE, we just include the hudi-spark dependency,the hive-jdbc is no need for us. More dependencies include may lead to more conflicts. And also IMO it is better to follow the minimization principle.If we do not use the hive jdbc, we should not include the dependency in the code.Even though the jdbc has packaged in the hudi-spark-bundle.", "author": "pengzhiwei2018", "createdAt": "2020-11-14T00:58:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjAyMDI1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjYwNzMxOA==", "url": "https://github.com/apache/hudi/pull/2241#discussion_r526607318", "bodyText": "Sounds reasonable.", "author": "yanghua", "createdAt": "2020-11-19T05:42:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjAyMDI1OA=="}], "type": "inlineReview"}]}