{"pr_number": 1239, "pr_title": "[HUDI-551] Abstract a test case class for DFS Source to make it extensible", "pr_createdAt": "2020-01-17T07:06:51Z", "pr_url": "https://github.com/apache/hudi/pull/1239", "timeline": [{"oid": "1875b16b569eca1df0cb33818110d0b91763f183", "url": "https://github.com/apache/hudi/commit/1875b16b569eca1df0cb33818110d0b91763f183", "message": "[MINOR] Abstract a test case class for DFS Source to make it extensible", "committedDate": "2020-01-18T07:45:17Z", "type": "commit"}, {"oid": "4e2b8ead8d1a1fc024040cc75fcd842c9ef268e6", "url": "https://github.com/apache/hudi/commit/4e2b8ead8d1a1fc024040cc75fcd842c9ef268e6", "message": "Rearrange the test classes of DFS Source.", "committedDate": "2020-01-18T07:45:21Z", "type": "commit"}, {"oid": "54032670a865e1498fa266648e3397f8f6908694", "url": "https://github.com/apache/hudi/commit/54032670a865e1498fa266648e3397f8f6908694", "message": "Fix import ordering.", "committedDate": "2020-01-18T07:45:21Z", "type": "commit"}, {"oid": "54032670a865e1498fa266648e3397f8f6908694", "url": "https://github.com/apache/hudi/commit/54032670a865e1498fa266648e3397f8f6908694", "message": "Fix import ordering.", "committedDate": "2020-01-18T07:45:21Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI2NDgxOA==", "url": "https://github.com/apache/hudi/pull/1239#discussion_r368264818", "bodyText": "Would not get the point of this method, a bit of tricky.", "author": "leesf", "createdAt": "2020-01-19T04:25:57Z", "path": "hudi-utilities/src/test/java/org/apache/hudi/utilities/sources/AbstractDFSSourceTestBase.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.utilities.sources;\n+\n+import org.apache.hudi.AvroConversionUtils;\n+import org.apache.hudi.common.HoodieTestDataGenerator;\n+import org.apache.hudi.common.model.HoodieRecord;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.utilities.UtilitiesTestBase;\n+import org.apache.hudi.utilities.deltastreamer.SourceFormatAdapter;\n+import org.apache.hudi.utilities.schema.FilebasedSchemaProvider;\n+\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.LocatedFileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.SparkSession;\n+import org.junit.After;\n+import org.junit.AfterClass;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.List;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * An abstract test base for {@link Source} using DFS as the file system.\n+ */\n+public abstract class AbstractDFSSourceTestBase extends UtilitiesTestBase {\n+\n+  FilebasedSchemaProvider schemaProvider;\n+  String dfsRoot;\n+  String fileSuffix;\n+  int fileCount = 1;\n+  HoodieTestDataGenerator dataGenerator = new HoodieTestDataGenerator();\n+\n+  @BeforeClass\n+  public static void initClass() throws Exception {\n+    UtilitiesTestBase.initClass();\n+  }\n+\n+  @AfterClass\n+  public static void cleanupClass() throws Exception {\n+    UtilitiesTestBase.cleanupClass();\n+  }\n+\n+  @Before\n+  public void setup() throws Exception {\n+    super.setup();\n+    schemaProvider = new FilebasedSchemaProvider(Helpers.setupSchemaOnDFS(), jsc);\n+  }\n+\n+  @After\n+  public void teardown() throws Exception {\n+    super.teardown();\n+  }\n+\n+  /**\n+   * Prepares the specific {@link Source} to test, by passing in necessary configurations.\n+   *\n+   * @return A {@link Source} using DFS as the file system.\n+   */\n+  abstract Source prepareDFSSource();\n+\n+  /**\n+   * Writes test data, i.e., a {@link List} of {@link HoodieRecord}, to a file on DFS.\n+   *\n+   * @param records Test data.\n+   * @param path    The path in {@link Path} of the file to write.\n+   * @throws IOException\n+   */\n+  abstract void writeNewDataToFile(List<HoodieRecord> records, Path path) throws IOException;\n+\n+  /**\n+   * Generates a batch of test data and writes the data to a file.  This can be called multiple times to generate multiple files.\n+   *\n+   * @return The {@link Path} of the file.\n+   * @throws IOException\n+   */\n+  Path generateOneFile() throws IOException {\n+    Path path = new Path(dfsRoot, fileCount + fileSuffix);\n+    switch (fileCount) {\n+      case 1:\n+        writeNewDataToFile(dataGenerator.generateInserts(\"000\", 100), path);\n+        fileCount++;\n+        return path;\n+      case 2:\n+        writeNewDataToFile(dataGenerator.generateInserts(\"001\", 10000), path);\n+        fileCount++;\n+        return path;\n+      default:\n+        return null;\n+    }\n+  }", "originalCommit": "54032670a865e1498fa266648e3397f8f6908694", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI2NjUyNA==", "url": "https://github.com/apache/hudi/pull/1239#discussion_r368266524", "bodyText": "Each time it's called, the method generates a new file for a batch of data.  Only two batches are considered.  Any suggestions to make it better?", "author": "yihua", "createdAt": "2020-01-19T05:15:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI2NDgxOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI2ODEwMw==", "url": "https://github.com/apache/hudi/pull/1239#discussion_r368268103", "bodyText": "In my latest commit, as we discussed, I parameterized this method to take the file name, commit time String and the number of records to generate, to make it easier to understand and use.", "author": "yihua", "createdAt": "2020-01-19T05:56:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI2NDgxOA=="}], "type": "inlineReview"}, {"oid": "4a589e984a37b49406b8372a31e08f80b8c981cc", "url": "https://github.com/apache/hudi/commit/4a589e984a37b49406b8372a31e08f80b8c981cc", "message": "Simplify the generateOneFile() method.", "committedDate": "2020-01-19T05:52:36Z", "type": "commit"}, {"oid": "33a19a68c014682884e06f0348348747db790ed4", "url": "https://github.com/apache/hudi/commit/33a19a68c014682884e06f0348348747db790ed4", "message": "Remove redundant comments.", "committedDate": "2020-01-19T05:58:04Z", "type": "commit"}]}