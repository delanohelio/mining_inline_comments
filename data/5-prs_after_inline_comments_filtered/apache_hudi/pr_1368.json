{"pr_number": 1368, "pr_title": "[HUDI-650] Modify handleUpdate path to validate partitionPath", "pr_createdAt": "2020-03-03T04:55:24Z", "pr_url": "https://github.com/apache/hudi/pull/1368", "timeline": [{"oid": "0d1b680316220e2828eb93479e9c214d66f5e737", "url": "https://github.com/apache/hudi/commit/0d1b680316220e2828eb93479e9c214d66f5e737", "message": "Fix handleUpdate to include partitionPath", "committedDate": "2020-03-03T20:15:28Z", "type": "commit"}, {"oid": "0d1b680316220e2828eb93479e9c214d66f5e737", "url": "https://github.com/apache/hudi/commit/0d1b680316220e2828eb93479e9c214d66f5e737", "message": "Fix handleUpdate to include partitionPath", "committedDate": "2020-03-03T20:15:28Z", "type": "forcePushed"}, {"oid": "90cd096fe13610a232c0c350b92c41df47a59153", "url": "https://github.com/apache/hudi/commit/90cd096fe13610a232c0c350b92c41df47a59153", "message": "remove unused import", "committedDate": "2020-03-03T20:28:17Z", "type": "commit"}, {"oid": "c45e281fe88416405a6e8e8defef0c89641557b6", "url": "https://github.com/apache/hudi/commit/c45e281fe88416405a6e8e8defef0c89641557b6", "message": "trigger Travis rebuild", "committedDate": "2020-03-03T21:47:26Z", "type": "commit"}, {"oid": "39a68d29b4d7a247fee3b54c5841fafebb8a2251", "url": "https://github.com/apache/hudi/commit/39a68d29b4d7a247fee3b54c5841fafebb8a2251", "message": "add partitionpath for AppendHandle", "committedDate": "2020-03-04T18:43:26Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTgwNjc3Mg==", "url": "https://github.com/apache/hudi/pull/1368#discussion_r389806772", "bodyText": "Can you add descriptive comments at the function level on what this tests and the steps involved ?", "author": "bvaradar", "createdAt": "2020-03-09T16:27:47Z", "path": "hudi-client/src/test/java/org/apache/hudi/table/TestMergeOnReadTable.java", "diffHunk": "@@ -1208,6 +1207,83 @@ public void testRollingStatsWithSmallFileHandling() throws Exception {\n     }\n   }\n \n+  @Test\n+  public void testHandleUpdateWithMultiplePartitions() throws Exception {", "originalCommit": "39a68d29b4d7a247fee3b54c5841fafebb8a2251", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI3NTU1Mw==", "url": "https://github.com/apache/hudi/pull/1368#discussion_r393275553", "bodyText": "done", "author": "satishkotha", "createdAt": "2020-03-16T19:53:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTgwNjc3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTgwNzEyMQ==", "url": "https://github.com/apache/hudi/pull/1368#discussion_r389807121", "bodyText": "Can you add comment on why you are expecting errors here ?", "author": "bvaradar", "createdAt": "2020-03-09T16:28:21Z", "path": "hudi-client/src/test/java/org/apache/hudi/table/TestMergeOnReadTable.java", "diffHunk": "@@ -1208,6 +1207,83 @@ public void testRollingStatsWithSmallFileHandling() throws Exception {\n     }\n   }\n \n+  @Test\n+  public void testHandleUpdateWithMultiplePartitions() throws Exception {\n+    HoodieWriteConfig cfg = getConfig(true);\n+    try (HoodieWriteClient client = getWriteClient(cfg);) {\n+\n+      /**\n+       * Write 1 (only inserts, written as parquet file)\n+       */\n+      String newCommitTime = \"001\";\n+      client.startCommitWithTime(newCommitTime);\n+\n+      List<HoodieRecord> records = dataGen.generateInserts(newCommitTime, 20);\n+      JavaRDD<HoodieRecord> writeRecords = jsc.parallelize(records, 1);\n+\n+      List<WriteStatus> statuses = client.upsert(writeRecords, newCommitTime).collect();\n+      assertNoWriteErrors(statuses);\n+\n+      HoodieTableMetaClient metaClient = new HoodieTableMetaClient(jsc.hadoopConfiguration(), cfg.getBasePath());\n+      HoodieMergeOnReadTable hoodieTable = (HoodieMergeOnReadTable) HoodieTable.getHoodieTable(metaClient, cfg, jsc);\n+\n+      Option<HoodieInstant> deltaCommit = metaClient.getActiveTimeline().getDeltaCommitTimeline().firstInstant();\n+      assertTrue(deltaCommit.isPresent());\n+      assertEquals(\"Delta commit should be 001\", \"001\", deltaCommit.get().getTimestamp());\n+\n+      Option<HoodieInstant> commit = metaClient.getActiveTimeline().getCommitTimeline().firstInstant();\n+      assertFalse(commit.isPresent());\n+\n+      FileStatus[] allFiles = HoodieTestUtils.listAllDataFilesInPath(metaClient.getFs(), cfg.getBasePath());\n+      BaseFileOnlyView roView =\n+              new HoodieTableFileSystemView(metaClient, metaClient.getCommitTimeline().filterCompletedInstants(), allFiles);\n+      Stream<HoodieBaseFile> dataFilesToRead = roView.getLatestBaseFiles();\n+      assertFalse(dataFilesToRead.findAny().isPresent());\n+\n+      roView = new HoodieTableFileSystemView(metaClient, hoodieTable.getCompletedCommitsTimeline(), allFiles);\n+      dataFilesToRead = roView.getLatestBaseFiles();\n+      assertTrue(\"should list the parquet files we wrote in the delta commit\",\n+              dataFilesToRead.findAny().isPresent());\n+\n+      /**\n+       * Write 2 (only updates, written to .log file)\n+       */\n+      newCommitTime = \"002\";\n+      client.startCommitWithTime(newCommitTime);\n+\n+      records = dataGen.generateUpdates(newCommitTime, records);\n+      writeRecords = jsc.parallelize(records, 1);\n+      statuses = client.upsert(writeRecords, newCommitTime).collect();\n+      assertNoWriteErrors(statuses);\n+\n+      /**\n+       * Write 3 (only deletes, written to .log file)\n+       */\n+      final String newDeleteTime = \"004\";\n+      final String partitionPath = records.get(0).getPartitionPath();\n+      final String fileId = statuses.get(0).getFileId();\n+      client.startCommitWithTime(newDeleteTime);\n+\n+      List<HoodieRecord> fewRecordsForDelete = dataGen.generateDeletesFromExistingRecords(records);\n+      JavaRDD<HoodieRecord> deleteRDD = jsc.parallelize(fewRecordsForDelete, 1);\n+\n+      // initialize partitioner\n+      hoodieTable.getUpsertPartitioner(new WorkloadProfile(deleteRDD));\n+      final List<List<WriteStatus>> deleteStatus = jsc.parallelize(Arrays.asList(1)).map(x -> {\n+        return hoodieTable.handleUpdate(newDeleteTime, partitionPath, fileId, fewRecordsForDelete.iterator());\n+      }).map(x -> (List<WriteStatus>) HoodieClientTestUtils.collectStatuses(x)).collect();\n+\n+      // Verify there are  errors\n+      WriteStatus status = deleteStatus.get(0).get(0);\n+      assertTrue(status.hasErrors());", "originalCommit": "39a68d29b4d7a247fee3b54c5841fafebb8a2251", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI3NTUxNQ==", "url": "https://github.com/apache/hudi/pull/1368#discussion_r393275515", "bodyText": "done", "author": "satishkotha", "createdAt": "2020-03-16T19:53:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTgwNzEyMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTgwNzg5Ng==", "url": "https://github.com/apache/hudi/pull/1368#discussion_r389807896", "bodyText": "Now that all handles have partitionPath, can this be moved to base class (HoodieWriteHandle ?)", "author": "bvaradar", "createdAt": "2020-03-09T16:29:35Z", "path": "hudi-client/src/main/java/org/apache/hudi/io/HoodieMergeHandle.java", "diffHunk": "@@ -61,6 +61,7 @@\n   private Map<String, HoodieRecord<T>> keyToNewRecords;\n   private Set<String> writtenRecordKeys;\n   private HoodieStorageWriter<IndexedRecord> storageWriter;\n+  private String partitionPath;", "originalCommit": "39a68d29b4d7a247fee3b54c5841fafebb8a2251", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI3NTQ1Mw==", "url": "https://github.com/apache/hudi/pull/1368#discussion_r393275453", "bodyText": "Fixed. I tried to see if there is a way to have this partition validation check in one place, but couldn't find a common entry point. Please let me know if you have suggestions here. happy to refactor more if needed", "author": "satishkotha", "createdAt": "2020-03-16T19:53:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTgwNzg5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjczMjI5MA==", "url": "https://github.com/apache/hudi/pull/1368#discussion_r392732290", "bodyText": "nitpick: delete 4 spaces in front.", "author": "smarthi", "createdAt": "2020-03-16T00:32:32Z", "path": "hudi-client/src/test/java/org/apache/hudi/table/TestCopyOnWriteTable.java", "diffHunk": "@@ -209,8 +207,8 @@ public void testUpdateRecords() throws Exception {\n     metaClient = HoodieTableMetaClient.reload(metaClient);\n     final HoodieCopyOnWriteTable newTable = new HoodieCopyOnWriteTable(config, jsc);\n     List<WriteStatus> statuses = jsc.parallelize(Arrays.asList(1)).map(x -> {\n-      return newTable.handleUpdate(newCommitTime, updatedRecord1.getCurrentLocation().getFileId(),\n-          updatedRecords.iterator());\n+      return newTable.handleUpdate(newCommitTime, updatedRecord1.getPartitionPath(),\n+              updatedRecord1.getCurrentLocation().getFileId(), updatedRecords.iterator());", "originalCommit": "39a68d29b4d7a247fee3b54c5841fafebb8a2251", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "fd97065907d24dca0ba03d1bd0b205eac48e1ef6", "url": "https://github.com/apache/hudi/commit/fd97065907d24dca0ba03d1bd0b205eac48e1ef6", "message": "Review comments", "committedDate": "2020-03-16T19:47:37Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTIyODgzNw==", "url": "https://github.com/apache/hudi/pull/1368#discussion_r395228837", "bodyText": "Can you add what the expected and actual partition path was in the exception message ?", "author": "bvaradar", "createdAt": "2020-03-19T18:17:47Z", "path": "hudi-client/src/main/java/org/apache/hudi/io/HoodieAppendHandle.java", "diffHunk": "@@ -295,6 +294,13 @@ private Writer createLogWriter(Option<FileSlice> fileSlice, String baseCommitTim\n   }\n \n   private void writeToBuffer(HoodieRecord<T> record) {\n+    if (!partitionPath.equals(record.getPartitionPath())) {\n+      writeStatus.markFailure(record, new HoodieUpsertException(\"mismatched partition path\"),", "originalCommit": "fd97065907d24dca0ba03d1bd0b205eac48e1ef6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM4OTAxMg==", "url": "https://github.com/apache/hudi/pull/1368#discussion_r395389012", "bodyText": "added", "author": "satishkotha", "createdAt": "2020-03-20T00:22:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTIyODgzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTIyOTc2OQ==", "url": "https://github.com/apache/hudi/pull/1368#discussion_r395229769", "bodyText": "Same here.", "author": "bvaradar", "createdAt": "2020-03-19T18:19:23Z", "path": "hudi-client/src/main/java/org/apache/hudi/io/HoodieMergeHandle.java", "diffHunk": "@@ -236,6 +233,10 @@ private boolean writeUpdateRecord(HoodieRecord<T> hoodieRecord, Option<IndexedRe\n \n   private boolean writeRecord(HoodieRecord<T> hoodieRecord, Option<IndexedRecord> indexedRecord) {\n     Option recordMetadata = hoodieRecord.getData().getMetadata();\n+    if (!partitionPath.equals(hoodieRecord.getPartitionPath())) {\n+      writeStatus.markFailure(hoodieRecord, new HoodieUpsertException(\"mismatched partition path\"), recordMetadata);", "originalCommit": "fd97065907d24dca0ba03d1bd0b205eac48e1ef6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM4OTA0Mg==", "url": "https://github.com/apache/hudi/pull/1368#discussion_r395389042", "bodyText": "done", "author": "satishkotha", "createdAt": "2020-03-20T00:22:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTIyOTc2OQ=="}], "type": "inlineReview"}, {"oid": "b9291773cb9328258961caa73a77c05b81e0174c", "url": "https://github.com/apache/hudi/commit/b9291773cb9328258961caa73a77c05b81e0174c", "message": "more detailed exception message", "committedDate": "2020-03-20T00:20:35Z", "type": "commit"}]}