{"pr_number": 878, "pr_title": "PHOENIX-6118: Multi Tenant Workloads using PHERF", "pr_createdAt": "2020-09-11T16:46:20Z", "pr_url": "https://github.com/apache/phoenix/pull/878", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzI4OTY3MA==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r487289670", "bodyText": "please add apache license", "author": "yanxinyi", "createdAt": "2020-09-11T21:03:46Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/configuration/Noop.java", "diffHunk": "@@ -0,0 +1,29 @@\n+package org.apache.phoenix.pherf.configuration;", "originalCommit": "05782529a415932a35fd0867e1f6e5a364f610e3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzI4OTk1Mw==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r487289953", "bodyText": "nit: please add apache license", "author": "yanxinyi", "createdAt": "2020-09-11T21:04:28Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/configuration/OperationGroup.java", "diffHunk": "@@ -0,0 +1,26 @@\n+package org.apache.phoenix.pherf.configuration;", "originalCommit": "05782529a415932a35fd0867e1f6e5a364f610e3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzI5MDgzMg==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r487290832", "bodyText": "why we are setting this to a negative number? Should be at lease 1?", "author": "yanxinyi", "createdAt": "2020-09-11T21:06:41Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/configuration/LoadProfile.java", "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ *   or more contributor license agreements.  See the NOTICE file\n+ *   distributed with this work for additional information\n+ *   regarding copyright ownership.  The ASF licenses this file\n+ *   to you under the Apache License, Version 2.0 (the\n+ *   \"License\"); you may not use this file except in compliance\n+ *   with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *   Unless required by applicable law or agreed to in writing, software\n+ *   distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *   See the License for the specific language governing permissions and\n+ *   limitations under the License.\n+ */\n+\n+package org.apache.phoenix.pherf.configuration;\n+\n+import javax.xml.bind.annotation.XmlAttribute;\n+import javax.xml.bind.annotation.XmlType;\n+import java.util.List;\n+\n+@XmlType\n+public class LoadProfile {\n+\n+    private int batchSize;\n+    private int numOperations;\n+    List<TenantGroup> tenantDistribution;\n+    List<OperationGroup> opDistribution;\n+\n+    public LoadProfile() {\n+        this.batchSize = Integer.MIN_VALUE;", "originalCommit": "05782529a415932a35fd0867e1f6e5a364f610e3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzI5MTM5OQ==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r487291399", "bodyText": "I didn't see anywhere calling this set method. Where is the place that we are setting this batch size value?", "author": "yanxinyi", "createdAt": "2020-09-11T21:08:07Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/configuration/LoadProfile.java", "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ *   or more contributor license agreements.  See the NOTICE file\n+ *   distributed with this work for additional information\n+ *   regarding copyright ownership.  The ASF licenses this file\n+ *   to you under the Apache License, Version 2.0 (the\n+ *   \"License\"); you may not use this file except in compliance\n+ *   with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *   Unless required by applicable law or agreed to in writing, software\n+ *   distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *   See the License for the specific language governing permissions and\n+ *   limitations under the License.\n+ */\n+\n+package org.apache.phoenix.pherf.configuration;\n+\n+import javax.xml.bind.annotation.XmlAttribute;\n+import javax.xml.bind.annotation.XmlType;\n+import java.util.List;\n+\n+@XmlType\n+public class LoadProfile {\n+\n+    private int batchSize;\n+    private int numOperations;\n+    List<TenantGroup> tenantDistribution;\n+    List<OperationGroup> opDistribution;\n+\n+    public LoadProfile() {\n+        this.batchSize = Integer.MIN_VALUE;\n+    }\n+\n+    public int getBatchSize() {\n+        return batchSize;\n+    }\n+\n+    public void setBatchSize(int batchSize) {", "originalCommit": "05782529a415932a35fd0867e1f6e5a364f610e3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzU2MzY1NA==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r487563654", "bodyText": "XML serialization/deserialization methods use getters and setter to marshal/unmarshal XML files into Objects.", "author": "jpisaac", "createdAt": "2020-09-13T18:51:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzI5MTM5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODExOTk5Nw==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r488119997", "bodyText": "not: can this be private?", "author": "ChinmaySKulkarni", "createdAt": "2020-09-14T17:57:47Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/configuration/LoadProfile.java", "diffHunk": "@@ -0,0 +1,69 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ *   or more contributor license agreements.  See the NOTICE file\n+ *   distributed with this work for additional information\n+ *   regarding copyright ownership.  The ASF licenses this file\n+ *   to you under the Apache License, Version 2.0 (the\n+ *   \"License\"); you may not use this file except in compliance\n+ *   with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *   Unless required by applicable law or agreed to in writing, software\n+ *   distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *   See the License for the specific language governing permissions and\n+ *   limitations under the License.\n+ */\n+\n+package org.apache.phoenix.pherf.configuration;\n+\n+import javax.xml.bind.annotation.XmlType;\n+import java.util.List;\n+\n+@XmlType\n+public class LoadProfile {\n+    public static int MIN_BATCH_SIZE = 1;", "originalCommit": "ff277bf70eb2e10a9ed79bcdef895a7d6683675e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODEyMDYyMw==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r488120623", "bodyText": "Why do we need this NoOp class for?", "author": "ChinmaySKulkarni", "createdAt": "2020-09-14T17:58:52Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/configuration/Noop.java", "diffHunk": "@@ -0,0 +1,47 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.phoenix.pherf.configuration;\n+\n+import javax.xml.bind.annotation.XmlAttribute;\n+import javax.xml.bind.annotation.XmlType;\n+\n+@XmlType\n+public class Noop {", "originalCommit": "ff277bf70eb2e10a9ed79bcdef895a7d6683675e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODEzMzg0NA==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r488133844", "bodyText": "I think this is for no operation that simulates the idle time.", "author": "yanxinyi", "createdAt": "2020-09-14T18:22:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODEyMDYyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDQxMjE3Mw==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r490412173", "bodyText": "@ChinmaySKulkarni This holds the idle time to be used for waiting. Modeled it as an operation, thus follows the same pattern as other operations.", "author": "jpisaac", "createdAt": "2020-09-17T16:50:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODEyMDYyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTczNTc2NQ==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r539735765", "bodyText": "Can we rename it so it reflects an operation aimed at injecting \"idle/wait time\"?", "author": "ChinmaySKulkarni", "createdAt": "2020-12-09T23:50:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODEyMDYyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3NjE1Nw==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545476157", "bodyText": "Ping @jpisaac I think we should still consider renaming the class so it is clear that it is introduced for the sole purpose of adding wait time. Maybe call it IdleOp", "author": "ChinmaySKulkarni", "createdAt": "2020-12-17T23:37:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODEyMDYyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODEyMDg0NA==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r488120844", "bodyText": "Can you add header comments for all newly introduced classes?", "author": "ChinmaySKulkarni", "createdAt": "2020-09-14T17:59:17Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/configuration/LoadProfile.java", "diffHunk": "@@ -0,0 +1,69 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ *   or more contributor license agreements.  See the NOTICE file\n+ *   distributed with this work for additional information\n+ *   regarding copyright ownership.  The ASF licenses this file\n+ *   to you under the Apache License, Version 2.0 (the\n+ *   \"License\"); you may not use this file except in compliance\n+ *   with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *   Unless required by applicable law or agreed to in writing, software\n+ *   distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *   See the License for the specific language governing permissions and\n+ *   limitations under the License.\n+ */\n+\n+package org.apache.phoenix.pherf.configuration;\n+\n+import javax.xml.bind.annotation.XmlType;\n+import java.util.List;\n+\n+@XmlType\n+public class LoadProfile {", "originalCommit": "ff277bf70eb2e10a9ed79bcdef895a7d6683675e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDQxNjY1MA==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r490416650", "bodyText": "@ChinmaySKulkarni added the headers, since you commented let me know if I missed anything.", "author": "jpisaac", "createdAt": "2020-09-17T16:57:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODEyMDg0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3NTUwMA==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545475500", "bodyText": "I meant class-level comments for all the new classes", "author": "ChinmaySKulkarni", "createdAt": "2020-12-17T23:36:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODEyMDg0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODE2NjEzMQ==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r488166131", "bodyText": "nit: weird indent", "author": "yanxinyi", "createdAt": "2020-09-14T19:21:02Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/configuration/Upsert.java", "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ *   or more contributor license agreements.  See the NOTICE file\n+ *   distributed with this work for additional information\n+ *   regarding copyright ownership.  The ASF licenses this file\n+ *   to you under the Apache License, Version 2.0 (the\n+ *   \"License\"); you may not use this file except in compliance\n+ *   with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *   Unless required by applicable law or agreed to in writing, software\n+ *   distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *   See the License for the specific language governing permissions and\n+ *   limitations under the License.\n+ */\n+\n+package org.apache.phoenix.pherf.configuration;\n+\n+import org.apache.phoenix.pherf.rules.RulesApplier;\n+\n+import javax.xml.bind.annotation.XmlAttribute;\n+import javax.xml.bind.annotation.XmlType;\n+import java.util.List;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+public class Upsert {\n+\n+    private String id;\n+    private String upsertGroup;\n+    private String statement;\n+    private List<Column> columns;\n+    private Pattern pattern;\n+    private long timeoutDuration = Long.MAX_VALUE;\n+\n+    public Upsert() {\n+    \tpattern = Pattern.compile(\"\\\\[.*?\\\\]\");\n+    }\n+    \n+\n+    public String getDynamicStatement(RulesApplier ruleApplier, Scenario scenario) throws Exception {\n+    \tString ret = this.statement;\n+    \tString needQuotes = \"\";\n+    \tMatcher m = pattern.matcher(ret);\n+        while(m.find()) {\n+        \tString dynamicField = m.group(0).replace(\"[\", \"\").replace(\"]\", \"\");\n+        \tColumn dynamicColumn = ruleApplier.getRule(dynamicField, scenario);\n+\t\t\tneedQuotes = (dynamicColumn.getType() == DataTypeMapping.CHAR || dynamicColumn\n+\t\t\t\t\t.getType() == DataTypeMapping.VARCHAR) ? \"'\" : \"\";\n+\t\t\tret = ret.replace(\"[\" + dynamicField + \"]\",\n+\t\t\t\t\tneedQuotes + ruleApplier.getDataValue(dynamicColumn).getValue() + needQuotes);\n+     }", "originalCommit": "ff277bf70eb2e10a9ed79bcdef895a7d6683675e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDQxNTYwNg==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r490415606", "bodyText": "Will try and fix that!!", "author": "jpisaac", "createdAt": "2020-09-17T16:56:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODE2NjEzMQ=="}], "type": "inlineReview"}, {"oid": "1086c208503063d8bdd8033bd925922af297b20a", "url": "https://github.com/apache/phoenix/commit/1086c208503063d8bdd8033bd925922af297b20a", "message": "Added implementation classes and tests", "committedDate": "2020-12-03T01:12:53Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzk0ODQzMQ==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r537948431", "bodyText": "why we ignore this test?", "author": "yanxinyi", "createdAt": "2020-12-08T00:53:17Z", "path": "phoenix-pherf/src/it/java/org/apache/phoenix/pherf/PherfMainIT.java", "diffHunk": "@@ -50,7 +51,7 @@\n     @Rule\n     public final ExpectedSystemExit exit = ExpectedSystemExit.none();\n \n-    @Test\n+    @Ignore", "originalCommit": "1086c208503063d8bdd8033bd925922af297b20a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3MTMwNw==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545471307", "bodyText": "Same question", "author": "ChinmaySKulkarni", "createdAt": "2020-12-17T23:25:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzk0ODQzMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzk0OTYyOA==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r537949628", "bodyText": "nit:  apache header", "author": "yanxinyi", "createdAt": "2020-12-08T00:56:27Z", "path": "phoenix-pherf/src/it/java/org/apache/phoenix/pherf/workload/mt/tenantoperation/MultiTenantOperationBaseIT.java", "diffHunk": "@@ -0,0 +1,68 @@\n+package org.apache.phoenix.pherf.workload.mt.tenantoperation;", "originalCommit": "1086c208503063d8bdd8033bd925922af297b20a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzk1Mzg0Ng==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r537953846", "bodyText": "nit:apache header", "author": "yanxinyi", "createdAt": "2020-12-08T01:07:11Z", "path": "phoenix-pherf/src/it/java/org/apache/phoenix/pherf/workload/mt/tenantoperation/TenantOperationIT.java", "diffHunk": "@@ -0,0 +1,113 @@\n+package org.apache.phoenix.pherf.workload.mt.tenantoperation;", "originalCommit": "1086c208503063d8bdd8033bd925922af297b20a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODAwMjIwMw==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r538002203", "bodyText": "nit: remove unused statement", "author": "yanxinyi", "createdAt": "2020-12-08T03:15:57Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/rules/RulesApplier.java", "diffHunk": "@@ -138,9 +161,10 @@ public DataValue getDataForRule(Scenario scenario, Column phxMetaColumn) throws\n             // Assume the first rule map\n             Map<DataTypeMapping, List> ruleMap = modelList.get(0);\n             List<Column> ruleList = ruleMap.get(phxMetaColumn.getType());\n+            //LOGGER.info(String.format(\"Did not found a correct override column rule, %s, %s\", phxMetaColumn.getName(), phxMetaColumn.getType()));", "originalCommit": "1086c208503063d8bdd8033bd925922af297b20a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODAwMjQ0OQ==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r538002449", "bodyText": "nit: style issue", "author": "yanxinyi", "createdAt": "2020-12-08T03:16:45Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/util/PhoenixUtil.java", "diffHunk": "@@ -455,4 +473,156 @@ public String getExplainPlan(Query query, Scenario scenario, RulesApplier ruleAp\n         }\n         return buf.toString();\n     }\n+\n+    public PreparedStatement buildStatement(RulesApplier rulesApplier, Scenario scenario, List<Column> columns,\n+            PreparedStatement statement, SimpleDateFormat simpleDateFormat) throws Exception {\n+\n+        int count = 1;\n+        for (Column column : columns) {\n+            DataValue dataValue = rulesApplier.getDataForRule(scenario, column);\n+            switch (column.getType()) {\n+            case VARCHAR:\n+                if (dataValue.getValue().equals(\"\")) {\n+                    statement.setNull(count, Types.VARCHAR);\n+                } else {\n+                    statement.setString(count, dataValue.getValue());\n+                }\n+                break;\n+            case CHAR:\n+                if (dataValue.getValue().equals(\"\")) {\n+                    statement.setNull(count, Types.CHAR);\n+                } else {\n+                    statement.setString(count, dataValue.getValue());\n+                }\n+                break;\n+            case DECIMAL:\n+                if (dataValue.getValue().equals(\"\")) {\n+                    statement.setNull(count, Types.DECIMAL);\n+                } else {\n+                    statement.setBigDecimal(count, new BigDecimal(dataValue.getValue()));\n+                }\n+                break;\n+            case INTEGER:\n+                if (dataValue.getValue().equals(\"\")) {\n+                    statement.setNull(count, Types.INTEGER);\n+                } else {\n+                    statement.setInt(count, Integer.parseInt(dataValue.getValue()));\n+                }\n+                break;\n+            case UNSIGNED_LONG:\n+                if (dataValue.getValue().equals(\"\")) {\n+                    statement.setNull(count, Types.OTHER);\n+                } else {\n+                    statement.setLong(count, Long.parseLong(dataValue.getValue()));\n+                }\n+                break;\n+            case BIGINT:\n+                if (dataValue.getValue().equals(\"\")) {\n+                    statement.setNull(count, Types.BIGINT);\n+                } else {\n+                    statement.setLong(count, Long.parseLong(dataValue.getValue()));\n+                }\n+                break;\n+            case TINYINT:\n+                if (dataValue.getValue().equals(\"\")) {\n+                    statement.setNull(count, Types.TINYINT);\n+                } else {\n+                    statement.setLong(count, Integer.parseInt(dataValue.getValue()));\n+                }\n+                break;\n+            case DATE:\n+                if (dataValue.getValue().equals(\"\")) {\n+                    statement.setNull(count, Types.DATE);\n+                } else {\n+                    Date\n+                            date =", "originalCommit": "1086c208503063d8bdd8033bd925922af297b20a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMTkxNzQxMg==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r601917412", "bodyText": "can you address this in the next PR", "author": "yanxinyi", "createdAt": "2021-03-26T00:11:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODAwMjQ0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODc2MDIzMw==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r538760233", "bodyText": "same here", "author": "yanxinyi", "createdAt": "2020-12-08T19:50:49Z", "path": "phoenix-pherf/src/it/java/org/apache/phoenix/pherf/workload/mt/tenantoperation/TenantOperationWorkloadIT.java", "diffHunk": "@@ -0,0 +1,141 @@\n+package org.apache.phoenix.pherf.workload.mt.tenantoperation;", "originalCommit": "1086c208503063d8bdd8033bd925922af297b20a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODc2MDk5NA==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r538760994", "bodyText": "please remember using phoenix third party at the master branch", "author": "yanxinyi", "createdAt": "2020-12-08T19:52:01Z", "path": "phoenix-pherf/src/it/java/org/apache/phoenix/pherf/workload/mt/tenantoperation/TenantOperationWorkloadIT.java", "diffHunk": "@@ -0,0 +1,141 @@\n+package org.apache.phoenix.pherf.workload.mt.tenantoperation;\n+\n+import com.clearspring.analytics.util.Lists;\n+import com.google.common.collect.Maps;", "originalCommit": "1086c208503063d8bdd8033bd925922af297b20a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "ede0f62202e57bbbcd900cc09faa6db95d551393", "url": "https://github.com/apache/phoenix/commit/ede0f62202e57bbbcd900cc09faa6db95d551393", "message": "Added implementation classes and tests", "committedDate": "2020-12-10T23:54:45Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjc4MDg5Mw==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r542780893", "bodyText": "nit: do you wanna remove logging here since we are not testing logging?", "author": "yanxinyi", "createdAt": "2020-12-14T21:01:10Z", "path": "phoenix-pherf/src/it/java/org/apache/phoenix/pherf/workload/mt/tenantoperation/TenantOperationIT.java", "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+\n+package org.apache.phoenix.pherf.workload.mt.tenantoperation;\n+\n+import com.lmax.disruptor.LifecycleAware;\n+import com.lmax.disruptor.WorkHandler;\n+import org.apache.phoenix.end2end.BaseHBaseManagedTimeIT;\n+import org.apache.phoenix.end2end.ParallelStatsDisabledIT;\n+import org.apache.phoenix.pherf.PherfConstants;\n+import org.apache.phoenix.pherf.XMLConfigParserTest;\n+import org.apache.phoenix.pherf.configuration.DataModel;\n+import org.apache.phoenix.pherf.configuration.LoadProfile;\n+import org.apache.phoenix.pherf.configuration.Scenario;\n+import org.apache.phoenix.pherf.configuration.XMLConfigParser;\n+import org.apache.phoenix.pherf.schema.SchemaReader;\n+import org.apache.phoenix.pherf.util.PhoenixUtil;\n+import org.apache.phoenix.pherf.workload.mt.Operation;\n+import org.apache.phoenix.pherf.workload.mt.OperationStats;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationEventGenerator;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationFactory.NoopTenantOperationImpl;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationFactory.PreScenarioTenantOperationImpl;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationFactory.QueryTenantOperationImpl;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationFactory.UpsertTenantOperationImpl;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationFactory.UserDefinedOperationImpl;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationFactoryTest;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationInfo;\n+import org.junit.Assert;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.xml.bind.UnmarshalException;\n+import java.net.URL;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertTrue;\n+\n+public class TenantOperationIT extends MultiTenantOperationBaseIT {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(TenantOperationIT.class);", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3MjAxMA==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545472010", "bodyText": "nit: Use assertEquals() instead", "author": "ChinmaySKulkarni", "createdAt": "2020-12-17T23:27:27Z", "path": "phoenix-pherf/src/it/java/org/apache/phoenix/pherf/workload/mt/tenantoperation/TenantOperationIT.java", "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+\n+package org.apache.phoenix.pherf.workload.mt.tenantoperation;\n+\n+import com.lmax.disruptor.LifecycleAware;\n+import com.lmax.disruptor.WorkHandler;\n+import org.apache.phoenix.end2end.BaseHBaseManagedTimeIT;\n+import org.apache.phoenix.end2end.ParallelStatsDisabledIT;\n+import org.apache.phoenix.pherf.PherfConstants;\n+import org.apache.phoenix.pherf.XMLConfigParserTest;\n+import org.apache.phoenix.pherf.configuration.DataModel;\n+import org.apache.phoenix.pherf.configuration.LoadProfile;\n+import org.apache.phoenix.pherf.configuration.Scenario;\n+import org.apache.phoenix.pherf.configuration.XMLConfigParser;\n+import org.apache.phoenix.pherf.schema.SchemaReader;\n+import org.apache.phoenix.pherf.util.PhoenixUtil;\n+import org.apache.phoenix.pherf.workload.mt.Operation;\n+import org.apache.phoenix.pherf.workload.mt.OperationStats;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationEventGenerator;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationFactory.NoopTenantOperationImpl;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationFactory.PreScenarioTenantOperationImpl;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationFactory.QueryTenantOperationImpl;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationFactory.UpsertTenantOperationImpl;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationFactory.UserDefinedOperationImpl;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationFactoryTest;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationInfo;\n+import org.junit.Assert;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.xml.bind.UnmarshalException;\n+import java.net.URL;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertTrue;\n+\n+public class TenantOperationIT extends MultiTenantOperationBaseIT {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(TenantOperationIT.class);\n+\n+    @Test\n+    public void testVariousOperations() throws Exception {\n+        int numTenantGroups = 3;\n+        int numOpGroups = 5;\n+        int numRuns = 10;\n+        int numOperations = 10;\n+\n+        PhoenixUtil pUtil = PhoenixUtil.create();\n+        DataModel model = readTestDataModel(\"/scenario/test_mt_workload.xml\");\n+        for (Scenario scenario : model.getScenarios()) {\n+            LOGGER.debug(String.format(\"Testing %s\", scenario.getName()));\n+            LoadProfile loadProfile = scenario.getLoadProfile();\n+            assertTrue(\"tenant group size is not as expected: \",", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3MjEzMQ==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545472131", "bodyText": "Same for other such instances", "author": "ChinmaySKulkarni", "createdAt": "2020-12-17T23:27:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3MjAxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3Mjc3OA==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545472778", "bodyText": "can't we just use the enum value instead of referring to its ordinal here?", "author": "ChinmaySKulkarni", "createdAt": "2020-12-17T23:29:13Z", "path": "phoenix-pherf/src/it/java/org/apache/phoenix/pherf/workload/mt/tenantoperation/TenantOperationIT.java", "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+\n+package org.apache.phoenix.pherf.workload.mt.tenantoperation;\n+\n+import com.lmax.disruptor.LifecycleAware;\n+import com.lmax.disruptor.WorkHandler;\n+import org.apache.phoenix.end2end.BaseHBaseManagedTimeIT;\n+import org.apache.phoenix.end2end.ParallelStatsDisabledIT;\n+import org.apache.phoenix.pherf.PherfConstants;\n+import org.apache.phoenix.pherf.XMLConfigParserTest;\n+import org.apache.phoenix.pherf.configuration.DataModel;\n+import org.apache.phoenix.pherf.configuration.LoadProfile;\n+import org.apache.phoenix.pherf.configuration.Scenario;\n+import org.apache.phoenix.pherf.configuration.XMLConfigParser;\n+import org.apache.phoenix.pherf.schema.SchemaReader;\n+import org.apache.phoenix.pherf.util.PhoenixUtil;\n+import org.apache.phoenix.pherf.workload.mt.Operation;\n+import org.apache.phoenix.pherf.workload.mt.OperationStats;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationEventGenerator;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationFactory.NoopTenantOperationImpl;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationFactory.PreScenarioTenantOperationImpl;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationFactory.QueryTenantOperationImpl;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationFactory.UpsertTenantOperationImpl;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationFactory.UserDefinedOperationImpl;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationFactoryTest;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationInfo;\n+import org.junit.Assert;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.xml.bind.UnmarshalException;\n+import java.net.URL;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertTrue;\n+\n+public class TenantOperationIT extends MultiTenantOperationBaseIT {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(TenantOperationIT.class);\n+\n+    @Test\n+    public void testVariousOperations() throws Exception {\n+        int numTenantGroups = 3;\n+        int numOpGroups = 5;\n+        int numRuns = 10;\n+        int numOperations = 10;\n+\n+        PhoenixUtil pUtil = PhoenixUtil.create();\n+        DataModel model = readTestDataModel(\"/scenario/test_mt_workload.xml\");\n+        for (Scenario scenario : model.getScenarios()) {\n+            LOGGER.debug(String.format(\"Testing %s\", scenario.getName()));\n+            LoadProfile loadProfile = scenario.getLoadProfile();\n+            assertTrue(\"tenant group size is not as expected: \",\n+                    loadProfile.getTenantDistribution().size() == numTenantGroups);\n+            assertTrue(\"operation group size is not as expected: \",\n+                    loadProfile.getOpDistribution().size() == numOpGroups);\n+\n+            TenantOperationFactory opFactory = new TenantOperationFactory(pUtil, model, scenario);\n+            TenantOperationEventGenerator evtGen = new TenantOperationEventGenerator(\n+                    opFactory.getOperationsForScenario(), model, scenario);\n+\n+            assertTrue(\"operation group size from the factory is not as expected: \",\n+                    opFactory.getOperationsForScenario().size() == numOpGroups);\n+\n+            int numRowsInserted = 0;\n+            for (int i = 0; i < numRuns; i++) {\n+                int ops = numOperations;\n+                loadProfile.setNumOperations(ops);\n+                while (ops-- > 0) {\n+                    TenantOperationInfo info = evtGen.next();\n+                    TenantOperationImpl op = opFactory.getOperation(info);\n+                    int row = TestOperationGroup.valueOf(info.getOperationGroupId()).ordinal();", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3MzY2Ng==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545473666", "bodyText": "There seems to be some inherent assumption what each operation group does i.e. upsert vs NoOp, etc. as per my understanding. Can you rename the enum values and/or add some comments to clarify this?", "author": "ChinmaySKulkarni", "createdAt": "2020-12-17T23:31:18Z", "path": "phoenix-pherf/src/it/java/org/apache/phoenix/pherf/workload/mt/tenantoperation/MultiTenantOperationBaseIT.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+\n+\n+package org.apache.phoenix.pherf.workload.mt.tenantoperation;\n+\n+import com.lmax.disruptor.LifecycleAware;\n+import com.lmax.disruptor.WorkHandler;\n+import org.apache.phoenix.end2end.ParallelStatsDisabledIT;\n+import org.apache.phoenix.pherf.PherfConstants;\n+import org.apache.phoenix.pherf.XMLConfigParserTest;\n+import org.apache.phoenix.pherf.configuration.DataModel;\n+import org.apache.phoenix.pherf.configuration.Scenario;\n+import org.apache.phoenix.pherf.configuration.XMLConfigParser;\n+import org.apache.phoenix.pherf.schema.SchemaReader;\n+import org.apache.phoenix.pherf.util.PhoenixUtil;\n+import org.apache.phoenix.pherf.workload.Workload;\n+import org.junit.BeforeClass;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.xml.bind.UnmarshalException;\n+import java.net.URL;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertTrue;\n+\n+public class MultiTenantOperationBaseIT extends ParallelStatsDisabledIT {\n+    static enum TestOperationGroup {\n+        op1, op2, op3, op4, op5", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3Mzg3Mw==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545473873", "bodyText": "Why not use switch on the enum values themselves rather than the ordinal?", "author": "ChinmaySKulkarni", "createdAt": "2020-12-17T23:31:49Z", "path": "phoenix-pherf/src/it/java/org/apache/phoenix/pherf/workload/mt/tenantoperation/TenantOperationIT.java", "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+\n+package org.apache.phoenix.pherf.workload.mt.tenantoperation;\n+\n+import com.lmax.disruptor.LifecycleAware;\n+import com.lmax.disruptor.WorkHandler;\n+import org.apache.phoenix.end2end.BaseHBaseManagedTimeIT;\n+import org.apache.phoenix.end2end.ParallelStatsDisabledIT;\n+import org.apache.phoenix.pherf.PherfConstants;\n+import org.apache.phoenix.pherf.XMLConfigParserTest;\n+import org.apache.phoenix.pherf.configuration.DataModel;\n+import org.apache.phoenix.pherf.configuration.LoadProfile;\n+import org.apache.phoenix.pherf.configuration.Scenario;\n+import org.apache.phoenix.pherf.configuration.XMLConfigParser;\n+import org.apache.phoenix.pherf.schema.SchemaReader;\n+import org.apache.phoenix.pherf.util.PhoenixUtil;\n+import org.apache.phoenix.pherf.workload.mt.Operation;\n+import org.apache.phoenix.pherf.workload.mt.OperationStats;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationEventGenerator;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationFactory.NoopTenantOperationImpl;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationFactory.PreScenarioTenantOperationImpl;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationFactory.QueryTenantOperationImpl;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationFactory.UpsertTenantOperationImpl;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationFactory.UserDefinedOperationImpl;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationFactoryTest;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationInfo;\n+import org.junit.Assert;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.xml.bind.UnmarshalException;\n+import java.net.URL;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertTrue;\n+\n+public class TenantOperationIT extends MultiTenantOperationBaseIT {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(TenantOperationIT.class);\n+\n+    @Test\n+    public void testVariousOperations() throws Exception {\n+        int numTenantGroups = 3;\n+        int numOpGroups = 5;\n+        int numRuns = 10;\n+        int numOperations = 10;\n+\n+        PhoenixUtil pUtil = PhoenixUtil.create();\n+        DataModel model = readTestDataModel(\"/scenario/test_mt_workload.xml\");\n+        for (Scenario scenario : model.getScenarios()) {\n+            LOGGER.debug(String.format(\"Testing %s\", scenario.getName()));\n+            LoadProfile loadProfile = scenario.getLoadProfile();\n+            assertTrue(\"tenant group size is not as expected: \",\n+                    loadProfile.getTenantDistribution().size() == numTenantGroups);\n+            assertTrue(\"operation group size is not as expected: \",\n+                    loadProfile.getOpDistribution().size() == numOpGroups);\n+\n+            TenantOperationFactory opFactory = new TenantOperationFactory(pUtil, model, scenario);\n+            TenantOperationEventGenerator evtGen = new TenantOperationEventGenerator(\n+                    opFactory.getOperationsForScenario(), model, scenario);\n+\n+            assertTrue(\"operation group size from the factory is not as expected: \",\n+                    opFactory.getOperationsForScenario().size() == numOpGroups);\n+\n+            int numRowsInserted = 0;\n+            for (int i = 0; i < numRuns; i++) {\n+                int ops = numOperations;\n+                loadProfile.setNumOperations(ops);\n+                while (ops-- > 0) {\n+                    TenantOperationInfo info = evtGen.next();\n+                    TenantOperationImpl op = opFactory.getOperation(info);\n+                    int row = TestOperationGroup.valueOf(info.getOperationGroupId()).ordinal();\n+                    OperationStats stats = op.getMethod().apply(info);\n+                    LOGGER.info(pUtil.getGSON().toJson(stats));\n+                    if (info.getOperation().getType() == Operation.OperationType.PRE_RUN) continue;\n+                    switch (row) {\n+                    case 0:", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3NDU2OA==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545474568", "bodyText": "Use assertEquals instead", "author": "ChinmaySKulkarni", "createdAt": "2020-12-17T23:33:40Z", "path": "phoenix-pherf/src/it/java/org/apache/phoenix/pherf/workload/mt/tenantoperation/TenantOperationWorkloadIT.java", "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+\n+package org.apache.phoenix.pherf.workload.mt.tenantoperation;\n+\n+import com.clearspring.analytics.util.Lists;\n+import com.google.common.collect.Maps;\n+import com.lmax.disruptor.LifecycleAware;\n+import com.lmax.disruptor.WorkHandler;\n+import org.apache.phoenix.pherf.configuration.DataModel;\n+import org.apache.phoenix.pherf.configuration.Scenario;\n+import org.apache.phoenix.pherf.util.PhoenixUtil;\n+import org.apache.phoenix.pherf.workload.Workload;\n+import org.apache.phoenix.pherf.workload.mt.OperationStats;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationWorkload.TenantOperationEvent;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.net.InetAddress;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.junit.Assert.assertTrue;\n+\n+public class TenantOperationWorkloadIT extends MultiTenantOperationBaseIT {\n+\n+    private static class EventCountingWorkHandler implements\n+            WorkHandler<TenantOperationEvent>, LifecycleAware {\n+        private final String handlerId;\n+        private final TenantOperationFactory tenantOperationFactory;\n+        private static final Logger LOGGER = LoggerFactory.getLogger(EventCountingWorkHandler.class);\n+        private final Map<String, CountDownLatch> latches;\n+        public EventCountingWorkHandler(TenantOperationFactory tenantOperationFactory,\n+                String handlerId, Map<String, CountDownLatch> latches) {\n+            this.handlerId = handlerId;\n+            this.tenantOperationFactory = tenantOperationFactory;\n+            this.latches = latches;\n+        }\n+\n+        @Override public void onStart() {}\n+\n+        @Override public void onShutdown() {}\n+\n+        @Override public void onEvent(TenantOperationEvent event)\n+                throws Exception {\n+            TenantOperationInfo input = event.getTenantOperationInfo();\n+            TenantOperationImpl op = tenantOperationFactory.getOperation(input);\n+            OperationStats stats = op.getMethod().apply(input);\n+            LOGGER.info(tenantOperationFactory.getPhoenixUtil().getGSON().toJson(stats));\n+            assertTrue(stats.getStatus() == 0);", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3NDY3NQ==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545474675", "bodyText": "ditto", "author": "ChinmaySKulkarni", "createdAt": "2020-12-17T23:33:58Z", "path": "phoenix-pherf/src/it/java/org/apache/phoenix/pherf/workload/mt/tenantoperation/TenantOperationWorkloadIT.java", "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+\n+package org.apache.phoenix.pherf.workload.mt.tenantoperation;\n+\n+import com.clearspring.analytics.util.Lists;\n+import com.google.common.collect.Maps;\n+import com.lmax.disruptor.LifecycleAware;\n+import com.lmax.disruptor.WorkHandler;\n+import org.apache.phoenix.pherf.configuration.DataModel;\n+import org.apache.phoenix.pherf.configuration.Scenario;\n+import org.apache.phoenix.pherf.util.PhoenixUtil;\n+import org.apache.phoenix.pherf.workload.Workload;\n+import org.apache.phoenix.pherf.workload.mt.OperationStats;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationWorkload.TenantOperationEvent;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.net.InetAddress;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.junit.Assert.assertTrue;\n+\n+public class TenantOperationWorkloadIT extends MultiTenantOperationBaseIT {\n+\n+    private static class EventCountingWorkHandler implements\n+            WorkHandler<TenantOperationEvent>, LifecycleAware {\n+        private final String handlerId;\n+        private final TenantOperationFactory tenantOperationFactory;\n+        private static final Logger LOGGER = LoggerFactory.getLogger(EventCountingWorkHandler.class);\n+        private final Map<String, CountDownLatch> latches;\n+        public EventCountingWorkHandler(TenantOperationFactory tenantOperationFactory,\n+                String handlerId, Map<String, CountDownLatch> latches) {\n+            this.handlerId = handlerId;\n+            this.tenantOperationFactory = tenantOperationFactory;\n+            this.latches = latches;\n+        }\n+\n+        @Override public void onStart() {}\n+\n+        @Override public void onShutdown() {}\n+\n+        @Override public void onEvent(TenantOperationEvent event)\n+                throws Exception {\n+            TenantOperationInfo input = event.getTenantOperationInfo();\n+            TenantOperationImpl op = tenantOperationFactory.getOperation(input);\n+            OperationStats stats = op.getMethod().apply(input);\n+            LOGGER.info(tenantOperationFactory.getPhoenixUtil().getGSON().toJson(stats));\n+            assertTrue(stats.getStatus() == 0);\n+            latches.get(handlerId).countDown();\n+        }\n+    }\n+\n+    @Test\n+    public void testWorkloadWithOneHandler() throws Exception {\n+        int numOpGroups = 5;\n+        int numHandlers = 1;\n+        int totalOperations = 50;\n+        int perHandlerCount = 50;\n+\n+        ExecutorService executor = null;\n+        try {\n+            executor = Executors.newFixedThreadPool(numHandlers);\n+            PhoenixUtil pUtil = PhoenixUtil.create();\n+            DataModel model = readTestDataModel(\"/scenario/test_mt_workload.xml\");\n+            for (Scenario scenario : model.getScenarios()) {\n+                // Set the total number of operations for this load profile\n+                scenario.getLoadProfile().setNumOperations(totalOperations);\n+                TenantOperationFactory opFactory = new TenantOperationFactory(pUtil, model, scenario);\n+                assertTrue(\"operation group size from the factory is not as expected: \",", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3NTAwNg==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545475006", "bodyText": "Please add class-level comments for all of these new classes", "author": "ChinmaySKulkarni", "createdAt": "2020-12-17T23:34:47Z", "path": "phoenix-pherf/src/it/java/org/apache/phoenix/pherf/workload/mt/tenantoperation/TenantOperationWorkloadIT.java", "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+\n+package org.apache.phoenix.pherf.workload.mt.tenantoperation;\n+\n+import com.clearspring.analytics.util.Lists;\n+import com.google.common.collect.Maps;\n+import com.lmax.disruptor.LifecycleAware;\n+import com.lmax.disruptor.WorkHandler;\n+import org.apache.phoenix.pherf.configuration.DataModel;\n+import org.apache.phoenix.pherf.configuration.Scenario;\n+import org.apache.phoenix.pherf.util.PhoenixUtil;\n+import org.apache.phoenix.pherf.workload.Workload;\n+import org.apache.phoenix.pherf.workload.mt.OperationStats;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationWorkload.TenantOperationEvent;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.net.InetAddress;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.junit.Assert.assertTrue;\n+\n+public class TenantOperationWorkloadIT extends MultiTenantOperationBaseIT {", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3NTA4NQ==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545475085", "bodyText": "ditto", "author": "ChinmaySKulkarni", "createdAt": "2020-12-17T23:35:04Z", "path": "phoenix-pherf/src/it/java/org/apache/phoenix/pherf/workload/mt/tenantoperation/TenantOperationWorkloadIT.java", "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+\n+package org.apache.phoenix.pherf.workload.mt.tenantoperation;\n+\n+import com.clearspring.analytics.util.Lists;\n+import com.google.common.collect.Maps;\n+import com.lmax.disruptor.LifecycleAware;\n+import com.lmax.disruptor.WorkHandler;\n+import org.apache.phoenix.pherf.configuration.DataModel;\n+import org.apache.phoenix.pherf.configuration.Scenario;\n+import org.apache.phoenix.pherf.util.PhoenixUtil;\n+import org.apache.phoenix.pherf.workload.Workload;\n+import org.apache.phoenix.pherf.workload.mt.OperationStats;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationWorkload.TenantOperationEvent;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.net.InetAddress;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.junit.Assert.assertTrue;\n+\n+public class TenantOperationWorkloadIT extends MultiTenantOperationBaseIT {\n+\n+    private static class EventCountingWorkHandler implements\n+            WorkHandler<TenantOperationEvent>, LifecycleAware {\n+        private final String handlerId;\n+        private final TenantOperationFactory tenantOperationFactory;\n+        private static final Logger LOGGER = LoggerFactory.getLogger(EventCountingWorkHandler.class);\n+        private final Map<String, CountDownLatch> latches;\n+        public EventCountingWorkHandler(TenantOperationFactory tenantOperationFactory,\n+                String handlerId, Map<String, CountDownLatch> latches) {\n+            this.handlerId = handlerId;\n+            this.tenantOperationFactory = tenantOperationFactory;\n+            this.latches = latches;\n+        }\n+\n+        @Override public void onStart() {}\n+\n+        @Override public void onShutdown() {}\n+\n+        @Override public void onEvent(TenantOperationEvent event)\n+                throws Exception {\n+            TenantOperationInfo input = event.getTenantOperationInfo();\n+            TenantOperationImpl op = tenantOperationFactory.getOperation(input);\n+            OperationStats stats = op.getMethod().apply(input);\n+            LOGGER.info(tenantOperationFactory.getPhoenixUtil().getGSON().toJson(stats));\n+            assertTrue(stats.getStatus() == 0);\n+            latches.get(handlerId).countDown();\n+        }\n+    }\n+\n+    @Test\n+    public void testWorkloadWithOneHandler() throws Exception {\n+        int numOpGroups = 5;\n+        int numHandlers = 1;\n+        int totalOperations = 50;\n+        int perHandlerCount = 50;\n+\n+        ExecutorService executor = null;\n+        try {\n+            executor = Executors.newFixedThreadPool(numHandlers);\n+            PhoenixUtil pUtil = PhoenixUtil.create();\n+            DataModel model = readTestDataModel(\"/scenario/test_mt_workload.xml\");\n+            for (Scenario scenario : model.getScenarios()) {\n+                // Set the total number of operations for this load profile\n+                scenario.getLoadProfile().setNumOperations(totalOperations);\n+                TenantOperationFactory opFactory = new TenantOperationFactory(pUtil, model, scenario);\n+                assertTrue(\"operation group size from the factory is not as expected: \",\n+                        opFactory.getOperationsForScenario().size() == numOpGroups);\n+\n+                // populate the handlers and countdown latches.\n+                String handlerId = String.format(\"%s.%d\", InetAddress.getLocalHost().getHostName(), numHandlers);\n+                List<WorkHandler> workers = Lists.newArrayList();\n+                Map<String, CountDownLatch> latches = Maps.newConcurrentMap();\n+                workers.add(new EventCountingWorkHandler(opFactory, handlerId, latches));\n+                latches.put(handlerId, new CountDownLatch(perHandlerCount));\n+                // submit the workload\n+                Workload workload = new TenantOperationWorkload(pUtil, model, scenario, workers, properties);\n+                Future status = executor.submit(workload.execute());\n+                // Just make sure there are no exceptions\n+                status.get();\n+\n+                // Wait for the handlers to count down\n+                for (Map.Entry<String, CountDownLatch> latch : latches.entrySet()) {\n+                    assertTrue(latch.getValue().await(60, TimeUnit.SECONDS));\n+                }\n+            }\n+        } finally {\n+            if (executor != null) {\n+                executor.shutdown();\n+            }\n+        }\n+    }\n+\n+    @Test\n+    public void testWorkloadWithManyHandlers() throws Exception {\n+        int numOpGroups = 5;\n+        int numHandlers = 5;\n+        int totalOperations = 500;\n+        int perHandlerCount = 50;\n+\n+        ExecutorService executor = Executors.newFixedThreadPool(numHandlers);\n+        PhoenixUtil pUtil = PhoenixUtil.create();\n+        DataModel model = readTestDataModel(\"/scenario/test_mt_workload.xml\");\n+        for (Scenario scenario : model.getScenarios()) {\n+            // Set the total number of operations for this load profile\n+            scenario.getLoadProfile().setNumOperations(totalOperations);\n+            TenantOperationFactory opFactory = new TenantOperationFactory(pUtil, model, scenario);\n+            assertTrue(\"operation group size from the factory is not as expected: \",", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3NTc1MA==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545475750", "bodyText": "Change these lists to private?", "author": "ChinmaySKulkarni", "createdAt": "2020-12-17T23:36:48Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/configuration/LoadProfile.java", "diffHunk": "@@ -0,0 +1,113 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ *   or more contributor license agreements.  See the NOTICE file\n+ *   distributed with this work for additional information\n+ *   regarding copyright ownership.  The ASF licenses this file\n+ *   to you under the Apache License, Version 2.0 (the\n+ *   \"License\"); you may not use this file except in compliance\n+ *   with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *   Unless required by applicable law or agreed to in writing, software\n+ *   distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *   See the License for the specific language governing permissions and\n+ *   limitations under the License.\n+ */\n+\n+package org.apache.phoenix.pherf.configuration;\n+\n+import javax.xml.bind.annotation.XmlType;\n+import java.util.List;\n+\n+@XmlType\n+public class LoadProfile {\n+    private static final int MIN_BATCH_SIZE = 1;\n+    private static final String DEFAULT_TENANT_ID_FMT = \"00D%s%07d\";\n+    private static final int DEFAULT_GROUP_ID_LEN = 5;\n+    private static final int DEFAULT_TENANT_ID_LEN = 15;\n+\n+    // Holds the batch size to be used in upserts.\n+    private int batchSize;\n+    // Holds the number of operations to be generated.\n+    private long numOperations;\n+    /**\n+     * Holds the format to be used when generating tenantIds.\n+     * TenantId format should typically have 2 parts -\n+     * 1. string fmt - that hold the tenant group id.\n+     * 2. int fmt - that holds a random number between 1 and max tenants\n+     * for e.g DEFAULT_TENANT_ID_FMT = \"00D%s%07d\";\n+     */\n+    private String tenantIdFormat;\n+    private int groupIdLength;\n+    private int tenantIdLength;\n+    // Holds the desired tenant distribution for this load.\n+    List<TenantGroup> tenantDistribution;\n+    // Holds the desired operation distribution for this load.\n+    List<OperationGroup> opDistribution;", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3NjQxOA==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545476418", "bodyText": "Is this method to generate queries on the fly or something else? Can you add a comment?", "author": "ChinmaySKulkarni", "createdAt": "2020-12-17T23:38:31Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/configuration/Query.java", "diffHunk": "@@ -51,20 +51,24 @@ public Query() {\n     public String getStatement() {\n         return statement;\n     }\n-    \n-    public String getDynamicStatement(RulesApplier ruleApplier, Scenario scenario) throws Exception {\n-    \tString ret = this.statement;\n-    \tString needQuotes = \"\";\n-    \tMatcher m = pattern.matcher(ret);\n-        while(m.find()) {\n-        \tString dynamicField = m.group(0).replace(\"[\", \"\").replace(\"]\", \"\");\n-        \tColumn dynamicColumn = ruleApplier.getRule(dynamicField, scenario);\n-\t\t\tneedQuotes = (dynamicColumn.getType() == DataTypeMapping.CHAR || dynamicColumn\n-\t\t\t\t\t.getType() == DataTypeMapping.VARCHAR) ? \"'\" : \"\";\n-\t\t\tret = ret.replace(\"[\" + dynamicField + \"]\",\n-\t\t\t\t\tneedQuotes + ruleApplier.getDataValue(dynamicColumn).getValue() + needQuotes);\n-     }\n-      \treturn ret;    \t\n+\n+    public String getDynamicStatement(RulesApplier ruleApplier, Scenario scenario)", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3OTkxMg==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545479912", "bodyText": "Can Query and Upsert and other such classes be derived from some common base class/ implement a common interface? Seems like a lot of the behavior is common (at the methods if not implementations)", "author": "ChinmaySKulkarni", "createdAt": "2020-12-17T23:47:49Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/configuration/Upsert.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ *   or more contributor license agreements.  See the NOTICE file\n+ *   distributed with this work for additional information\n+ *   regarding copyright ownership.  The ASF licenses this file\n+ *   to you under the Apache License, Version 2.0 (the\n+ *   \"License\"); you may not use this file except in compliance\n+ *   with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *   Unless required by applicable law or agreed to in writing, software\n+ *   distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *   See the License for the specific language governing permissions and\n+ *   limitations under the License.\n+ */\n+\n+package org.apache.phoenix.pherf.configuration;\n+\n+import org.apache.phoenix.pherf.rules.RulesApplier;\n+\n+import javax.xml.bind.annotation.XmlAttribute;\n+import java.util.List;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+public class Upsert {\n+\n+    private String id;\n+    private String upsertGroup;\n+    private String statement;\n+    private List<Column> columns;\n+    private boolean useGlobalConnection;\n+    private Pattern pattern;\n+    private long timeoutDuration = Long.MAX_VALUE;\n+\n+    public Upsert() {\n+    \tpattern = Pattern.compile(\"\\\\[.*?\\\\]\");\n+    }\n+\n+    public String getDynamicStatement(RulesApplier ruleApplier, Scenario scenario)", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4MDIwMg==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545480202", "bodyText": "I didn't understand these comments. Can you please clarify?", "author": "ChinmaySKulkarni", "createdAt": "2020-12-17T23:48:37Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/rules/RulesApplier.java", "diffHunk": "@@ -59,13 +61,34 @@\n \n     private Map<Column,RuleBasedDataGenerator> columnRuleBasedDataGeneratorMap = new HashMap<>();\n \n+    // Support for multiple models, but rules are only relevant each model\n+    // TODO : This is a step towards getting the above comment fixed.", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4MDI5Mg==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545480292", "bodyText": "same here. Didn't understand which comment we are fixing?", "author": "ChinmaySKulkarni", "createdAt": "2020-12-17T23:48:59Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/rules/RulesApplier.java", "diffHunk": "@@ -422,9 +446,15 @@ private void populateModelList() {\n         if (!modelList.isEmpty()) {\n             return;\n         }\n-        \n+\n         // Support for multiple models, but rules are only relevant each model\n-        for (DataModel model : parser.getDataModels()) {\n+        // TODO : This is a step towards getting the above comment fixed.", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4MDQzNQ==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545480435", "bodyText": "nit: Make class final and add a private constructor if it doesn't exist since this is a Util.", "author": "ChinmaySKulkarni", "createdAt": "2020-12-17T23:49:26Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/util/PhoenixUtil.java", "diffHunk": "@@ -45,14 +57,15 @@\n import static org.apache.phoenix.jdbc.PhoenixDatabaseMetaData.TABLE_SCHEM;\n \n public class PhoenixUtil {", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4MDU3Mw==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545480573", "bodyText": "is this change necessary?", "author": "ChinmaySKulkarni", "createdAt": "2020-12-17T23:49:43Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/util/PhoenixUtil.java", "diffHunk": "@@ -335,7 +353,7 @@ public void executeScenarioDdl(List<Ddl> ddls, String tenantId, DataLoadTimeSumm\n      * @param tableName\n      * @throws InterruptedException\n      */\n-    private void waitForAsyncIndexToFinish(String tableName) throws InterruptedException {\n+    public void waitForAsyncIndexToFinish(String tableName) throws InterruptedException {", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4MDg0OA==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545480848", "bodyText": "Do we want to remove this comment and also the one above it?", "author": "ChinmaySKulkarni", "createdAt": "2020-12-17T23:50:25Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/util/ResourceList.java", "diffHunk": "@@ -74,9 +76,11 @@ public ResourceList(String rootResourceDir) {\n     private Collection<Path> getResourcesPaths(\n             final Pattern pattern) throws Exception {\n \n-        final String classPath = System.getProperty(\"java.class.path\", \".\");\n+        //final String classPath = System.getProperty(\"java.class.path\", \".\");\n+        // TODO remove", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4MTQxNg==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545481416", "bodyText": "handlerId can't be private?", "author": "ChinmaySKulkarni", "createdAt": "2020-12-17T23:51:54Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/workload/mt/OperationStats.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.phoenix.pherf.workload.mt;\n+\n+import org.apache.phoenix.pherf.result.ResultValue;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationInfo;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * Holds metrics + contextual info on the operation run.\n+ */\n+public class OperationStats {\n+    private final String modelName;\n+    private final String scenarioName;\n+    private final String tableName;\n+    private final String tenantId;\n+    private final String tenantGroup;\n+    private final String operationGroup;\n+    private final Operation.OperationType opType;\n+    private String handlerId;", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4MjQ4MA==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545482480", "bodyText": "nit: Extract some of these steps into their own methods? This will make unit testing easier too.", "author": "ChinmaySKulkarni", "createdAt": "2020-12-17T23:54:43Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/workload/mt/tenantoperation/TenantOperationEventGenerator.java", "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.phoenix.pherf.workload.mt.tenantoperation;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.base.Strings;\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import com.sun.org.apache.xpath.internal.operations.Mod;\n+import org.apache.commons.math3.distribution.EnumeratedDistribution;\n+import org.apache.commons.math3.util.Pair;\n+import org.apache.phoenix.pherf.PherfConstants;\n+import org.apache.phoenix.pherf.configuration.DataModel;\n+import org.apache.phoenix.pherf.configuration.LoadProfile;\n+import org.apache.phoenix.pherf.configuration.OperationGroup;\n+import org.apache.phoenix.pherf.configuration.Scenario;\n+import org.apache.phoenix.pherf.configuration.TenantGroup;\n+import org.apache.phoenix.pherf.util.PhoenixUtil;\n+import org.apache.phoenix.pherf.workload.mt.Operation;\n+import org.apache.phoenix.pherf.workload.mt.EventGenerator;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Random;\n+\n+/**\n+ * A perf load event generator based on the supplied load profile.\n+ */\n+\n+public class TenantOperationEventGenerator\n+        implements EventGenerator<TenantOperationInfo> {\n+\n+    private static class WeightedRandomSampler {\n+        private final Random RANDOM = new Random();\n+        private final LoadProfile loadProfile;\n+        private final String modelName;\n+        private final String scenarioName;\n+        private final String tableName;\n+        private final EnumeratedDistribution<String> distribution;\n+\n+        private final Map<String, TenantGroup> tenantGroupMap = Maps.newHashMap();\n+        private final Map<String, Operation> operationMap = Maps.newHashMap();\n+        private final Map<String, OperationGroup> operationGroupMap = Maps.newHashMap();\n+\n+        public WeightedRandomSampler(List<Operation> operationList, DataModel model, Scenario scenario) {\n+            this.modelName = model.getName();\n+            this.scenarioName = scenario.getName();\n+            this.tableName = scenario.getTableName();\n+            this.loadProfile = scenario.getLoadProfile();\n+\n+            for (Operation op : operationList) {\n+                for (OperationGroup og : loadProfile.getOpDistribution()) {\n+                    if (op.getId().compareTo(og.getId()) == 0) {\n+                        operationMap.put(op.getId(), op);\n+                        operationGroupMap.put(op.getId(), og);\n+                    }\n+                }\n+            }\n+            Preconditions.checkArgument(!operationMap.isEmpty(),\n+                    \"Operation list and load profile operation do not match\");\n+\n+            double totalTenantGroupWeight = 0.0f;", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4OTc0Mw==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545489743", "bodyText": "Can we break this method up too instead of putting it all in the constructor itself?", "author": "ChinmaySKulkarni", "createdAt": "2020-12-18T00:15:14Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/workload/mt/tenantoperation/TenantOperationFactory.java", "diffHunk": "@@ -0,0 +1,501 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.phoenix.pherf.workload.mt.tenantoperation;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Charsets;\n+import com.google.common.base.Function;\n+import com.google.common.collect.Lists;\n+import com.google.common.hash.BloomFilter;\n+import com.google.common.hash.Funnel;\n+import com.google.common.hash.PrimitiveSink;\n+import org.apache.phoenix.pherf.configuration.Column;\n+import org.apache.phoenix.pherf.configuration.DataModel;\n+import org.apache.phoenix.pherf.configuration.Ddl;\n+import org.apache.phoenix.pherf.configuration.LoadProfile;\n+import org.apache.phoenix.pherf.configuration.Noop;\n+import org.apache.phoenix.pherf.configuration.Query;\n+import org.apache.phoenix.pherf.configuration.QuerySet;\n+import org.apache.phoenix.pherf.configuration.Scenario;\n+import org.apache.phoenix.pherf.configuration.TenantGroup;\n+import org.apache.phoenix.pherf.configuration.Upsert;\n+import org.apache.phoenix.pherf.configuration.UserDefined;\n+import org.apache.phoenix.pherf.configuration.XMLConfigParser;\n+import org.apache.phoenix.pherf.rules.DataValue;\n+import org.apache.phoenix.pherf.rules.RulesApplier;\n+import org.apache.phoenix.pherf.util.PhoenixUtil;\n+import org.apache.phoenix.pherf.workload.mt.EventGenerator;\n+import org.apache.phoenix.pherf.workload.mt.NoopOperation;\n+import org.apache.phoenix.pherf.workload.mt.Operation;\n+import org.apache.phoenix.pherf.workload.mt.OperationStats;\n+import org.apache.phoenix.pherf.workload.mt.PreScenarioOperation;\n+import org.apache.phoenix.pherf.workload.mt.QueryOperation;\n+import org.apache.phoenix.pherf.workload.mt.UpsertOperation;\n+import org.apache.phoenix.pherf.workload.mt.UserDefinedOperation;\n+import org.apache.phoenix.util.EnvironmentEdgeManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.math.BigDecimal;\n+import java.sql.Array;\n+import java.sql.Connection;\n+import java.sql.Date;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.text.SimpleDateFormat;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * Factory class for operations.\n+ * The class is responsible for creating new instances of various operation types.\n+ * Operations typically implement @see {@link TenantOperationImpl}\n+ * Operations that need to be executed are generated\n+ * by @see {@link EventGenerator}\n+ */\n+public class TenantOperationFactory {\n+\n+    private static class TenantView {\n+        private final String tenantId;\n+        private final String viewName;\n+\n+        public TenantView(String tenantId, String viewName) {\n+            this.tenantId = tenantId;\n+            this.viewName = viewName;\n+        }\n+\n+        public String getTenantId() {\n+            return tenantId;\n+        }\n+\n+        public String getViewName() {\n+            return viewName;\n+        }\n+    }\n+    private static final Logger LOGGER = LoggerFactory.getLogger(TenantOperationFactory.class);\n+    private final PhoenixUtil phoenixUtil;\n+    private final DataModel model;\n+    private final Scenario scenario;\n+    private final XMLConfigParser parser;\n+\n+    private final RulesApplier rulesApplier;\n+    private final LoadProfile loadProfile;\n+    private final List<Operation> operationList = Lists.newArrayList();\n+\n+    private final BloomFilter<TenantView> tenantsLoaded;\n+\n+    public TenantOperationFactory(PhoenixUtil phoenixUtil, DataModel model, Scenario scenario) {\n+        this.phoenixUtil = phoenixUtil;\n+        this.model = model;\n+        this.scenario = scenario;\n+        this.parser = null;\n+        this.rulesApplier = new RulesApplier(model);\n+        this.loadProfile = this.scenario.getLoadProfile();\n+        Funnel<TenantView> tenantViewFunnel = new Funnel<TenantView>() {", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4OTkwOA==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545489908", "bodyText": "nit: Might be worth refactoring all these anonymous classes", "author": "ChinmaySKulkarni", "createdAt": "2020-12-18T00:15:43Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/workload/mt/tenantoperation/TenantOperationFactory.java", "diffHunk": "@@ -0,0 +1,501 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.phoenix.pherf.workload.mt.tenantoperation;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Charsets;\n+import com.google.common.base.Function;\n+import com.google.common.collect.Lists;\n+import com.google.common.hash.BloomFilter;\n+import com.google.common.hash.Funnel;\n+import com.google.common.hash.PrimitiveSink;\n+import org.apache.phoenix.pherf.configuration.Column;\n+import org.apache.phoenix.pherf.configuration.DataModel;\n+import org.apache.phoenix.pherf.configuration.Ddl;\n+import org.apache.phoenix.pherf.configuration.LoadProfile;\n+import org.apache.phoenix.pherf.configuration.Noop;\n+import org.apache.phoenix.pherf.configuration.Query;\n+import org.apache.phoenix.pherf.configuration.QuerySet;\n+import org.apache.phoenix.pherf.configuration.Scenario;\n+import org.apache.phoenix.pherf.configuration.TenantGroup;\n+import org.apache.phoenix.pherf.configuration.Upsert;\n+import org.apache.phoenix.pherf.configuration.UserDefined;\n+import org.apache.phoenix.pherf.configuration.XMLConfigParser;\n+import org.apache.phoenix.pherf.rules.DataValue;\n+import org.apache.phoenix.pherf.rules.RulesApplier;\n+import org.apache.phoenix.pherf.util.PhoenixUtil;\n+import org.apache.phoenix.pherf.workload.mt.EventGenerator;\n+import org.apache.phoenix.pherf.workload.mt.NoopOperation;\n+import org.apache.phoenix.pherf.workload.mt.Operation;\n+import org.apache.phoenix.pherf.workload.mt.OperationStats;\n+import org.apache.phoenix.pherf.workload.mt.PreScenarioOperation;\n+import org.apache.phoenix.pherf.workload.mt.QueryOperation;\n+import org.apache.phoenix.pherf.workload.mt.UpsertOperation;\n+import org.apache.phoenix.pherf.workload.mt.UserDefinedOperation;\n+import org.apache.phoenix.util.EnvironmentEdgeManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.math.BigDecimal;\n+import java.sql.Array;\n+import java.sql.Connection;\n+import java.sql.Date;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.text.SimpleDateFormat;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * Factory class for operations.\n+ * The class is responsible for creating new instances of various operation types.\n+ * Operations typically implement @see {@link TenantOperationImpl}\n+ * Operations that need to be executed are generated\n+ * by @see {@link EventGenerator}\n+ */\n+public class TenantOperationFactory {\n+\n+    private static class TenantView {\n+        private final String tenantId;\n+        private final String viewName;\n+\n+        public TenantView(String tenantId, String viewName) {\n+            this.tenantId = tenantId;\n+            this.viewName = viewName;\n+        }\n+\n+        public String getTenantId() {\n+            return tenantId;\n+        }\n+\n+        public String getViewName() {\n+            return viewName;\n+        }\n+    }\n+    private static final Logger LOGGER = LoggerFactory.getLogger(TenantOperationFactory.class);\n+    private final PhoenixUtil phoenixUtil;\n+    private final DataModel model;\n+    private final Scenario scenario;\n+    private final XMLConfigParser parser;\n+\n+    private final RulesApplier rulesApplier;\n+    private final LoadProfile loadProfile;\n+    private final List<Operation> operationList = Lists.newArrayList();\n+\n+    private final BloomFilter<TenantView> tenantsLoaded;\n+\n+    public TenantOperationFactory(PhoenixUtil phoenixUtil, DataModel model, Scenario scenario) {\n+        this.phoenixUtil = phoenixUtil;\n+        this.model = model;\n+        this.scenario = scenario;\n+        this.parser = null;\n+        this.rulesApplier = new RulesApplier(model);\n+        this.loadProfile = this.scenario.getLoadProfile();\n+        Funnel<TenantView> tenantViewFunnel = new Funnel<TenantView>() {\n+            @Override\n+            public void funnel(TenantView tenantView, PrimitiveSink into) {\n+                into.putString(tenantView.getTenantId(), Charsets.UTF_8)\n+                        .putString(tenantView.getViewName(), Charsets.UTF_8);\n+            }\n+        };\n+\n+        int numTenants = 0;\n+        for (TenantGroup tg : loadProfile.getTenantDistribution()) {\n+            numTenants += tg.getNumTenants();\n+        }\n+\n+        // This holds the info whether the tenant view was created (initialized) or not.\n+        tenantsLoaded = BloomFilter.create(tenantViewFunnel, numTenants, 0.01);\n+\n+        // Read the scenario definition and load the various operations.\n+        for (final Noop noOp : scenario.getNoop()) {", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5MDMzOQ==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545490339", "bodyText": "Are we doing this TODO?", "author": "ChinmaySKulkarni", "createdAt": "2020-12-18T00:16:55Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/workload/mt/tenantoperation/TenantOperationFactory.java", "diffHunk": "@@ -0,0 +1,501 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.phoenix.pherf.workload.mt.tenantoperation;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Charsets;\n+import com.google.common.base.Function;\n+import com.google.common.collect.Lists;\n+import com.google.common.hash.BloomFilter;\n+import com.google.common.hash.Funnel;\n+import com.google.common.hash.PrimitiveSink;\n+import org.apache.phoenix.pherf.configuration.Column;\n+import org.apache.phoenix.pherf.configuration.DataModel;\n+import org.apache.phoenix.pherf.configuration.Ddl;\n+import org.apache.phoenix.pherf.configuration.LoadProfile;\n+import org.apache.phoenix.pherf.configuration.Noop;\n+import org.apache.phoenix.pherf.configuration.Query;\n+import org.apache.phoenix.pherf.configuration.QuerySet;\n+import org.apache.phoenix.pherf.configuration.Scenario;\n+import org.apache.phoenix.pherf.configuration.TenantGroup;\n+import org.apache.phoenix.pherf.configuration.Upsert;\n+import org.apache.phoenix.pherf.configuration.UserDefined;\n+import org.apache.phoenix.pherf.configuration.XMLConfigParser;\n+import org.apache.phoenix.pherf.rules.DataValue;\n+import org.apache.phoenix.pherf.rules.RulesApplier;\n+import org.apache.phoenix.pherf.util.PhoenixUtil;\n+import org.apache.phoenix.pherf.workload.mt.EventGenerator;\n+import org.apache.phoenix.pherf.workload.mt.NoopOperation;\n+import org.apache.phoenix.pherf.workload.mt.Operation;\n+import org.apache.phoenix.pherf.workload.mt.OperationStats;\n+import org.apache.phoenix.pherf.workload.mt.PreScenarioOperation;\n+import org.apache.phoenix.pherf.workload.mt.QueryOperation;\n+import org.apache.phoenix.pherf.workload.mt.UpsertOperation;\n+import org.apache.phoenix.pherf.workload.mt.UserDefinedOperation;\n+import org.apache.phoenix.util.EnvironmentEdgeManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.math.BigDecimal;\n+import java.sql.Array;\n+import java.sql.Connection;\n+import java.sql.Date;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.text.SimpleDateFormat;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * Factory class for operations.\n+ * The class is responsible for creating new instances of various operation types.\n+ * Operations typically implement @see {@link TenantOperationImpl}\n+ * Operations that need to be executed are generated\n+ * by @see {@link EventGenerator}\n+ */\n+public class TenantOperationFactory {\n+\n+    private static class TenantView {\n+        private final String tenantId;\n+        private final String viewName;\n+\n+        public TenantView(String tenantId, String viewName) {\n+            this.tenantId = tenantId;\n+            this.viewName = viewName;\n+        }\n+\n+        public String getTenantId() {\n+            return tenantId;\n+        }\n+\n+        public String getViewName() {\n+            return viewName;\n+        }\n+    }\n+    private static final Logger LOGGER = LoggerFactory.getLogger(TenantOperationFactory.class);\n+    private final PhoenixUtil phoenixUtil;\n+    private final DataModel model;\n+    private final Scenario scenario;\n+    private final XMLConfigParser parser;\n+\n+    private final RulesApplier rulesApplier;\n+    private final LoadProfile loadProfile;\n+    private final List<Operation> operationList = Lists.newArrayList();\n+\n+    private final BloomFilter<TenantView> tenantsLoaded;\n+\n+    public TenantOperationFactory(PhoenixUtil phoenixUtil, DataModel model, Scenario scenario) {\n+        this.phoenixUtil = phoenixUtil;\n+        this.model = model;\n+        this.scenario = scenario;\n+        this.parser = null;\n+        this.rulesApplier = new RulesApplier(model);\n+        this.loadProfile = this.scenario.getLoadProfile();\n+        Funnel<TenantView> tenantViewFunnel = new Funnel<TenantView>() {\n+            @Override\n+            public void funnel(TenantView tenantView, PrimitiveSink into) {\n+                into.putString(tenantView.getTenantId(), Charsets.UTF_8)\n+                        .putString(tenantView.getViewName(), Charsets.UTF_8);\n+            }\n+        };\n+\n+        int numTenants = 0;\n+        for (TenantGroup tg : loadProfile.getTenantDistribution()) {\n+            numTenants += tg.getNumTenants();\n+        }\n+\n+        // This holds the info whether the tenant view was created (initialized) or not.\n+        tenantsLoaded = BloomFilter.create(tenantViewFunnel, numTenants, 0.01);\n+\n+        // Read the scenario definition and load the various operations.\n+        for (final Noop noOp : scenario.getNoop()) {\n+            Operation noopOperation = new NoopOperation() {\n+                @Override public Noop getNoop() {\n+                    return noOp;\n+                }\n+                @Override public String getId() {\n+                    return noOp.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.NO_OP;\n+                }\n+            };\n+            operationList.add(noopOperation);\n+        }\n+\n+        for (final Upsert upsert : scenario.getUpsert()) {\n+            Operation upsertOp = new UpsertOperation() {\n+                @Override public Upsert getUpsert() {\n+                    return upsert;\n+                }\n+\n+                @Override public String getId() {\n+                    return upsert.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.UPSERT;\n+                }\n+            };\n+            operationList.add(upsertOp);\n+        }\n+        for (final QuerySet querySet : scenario.getQuerySet()) {\n+            for (final Query query : querySet.getQuery()) {\n+                Operation queryOp = new QueryOperation() {\n+                    @Override public Query getQuery() {\n+                        return query;\n+                    }\n+\n+                    @Override public String getId() {\n+                        return query.getId();\n+                    }\n+\n+                    @Override public OperationType getType() {\n+                        return OperationType.SELECT;\n+                    }\n+                };\n+                operationList.add(queryOp);\n+            }\n+        }\n+\n+        for (final UserDefined udf : scenario.getUdf()) {\n+            Operation udfOperation = new UserDefinedOperation() {\n+                @Override public UserDefined getUserFunction() {\n+                    return udf;\n+                }\n+\n+                @Override public String getId() {\n+                    return udf.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.USER_DEFINED;\n+                }\n+            };\n+            operationList.add(udfOperation);\n+        }\n+    }\n+\n+    public PhoenixUtil getPhoenixUtil() {\n+        return phoenixUtil;\n+    }\n+\n+    public DataModel getModel() {\n+        return model;\n+    }\n+\n+    public Scenario getScenario() {\n+        return scenario;\n+    }\n+\n+    public List<Operation> getOperationsForScenario() {\n+        return operationList;\n+    }\n+\n+    public TenantOperationImpl getOperation(final TenantOperationInfo input) {\n+        TenantView tenantView = new TenantView(input.getTenantId(), scenario.getTableName());\n+\n+        // Check if pre run ddls are needed.\n+        if (!tenantsLoaded.mightContain(tenantView)) {\n+            // Initialize the tenant using the pre scenario ddls.\n+            final PreScenarioOperation operation = new PreScenarioOperation() {\n+                @Override public List<Ddl> getPreScenarioDdls() {\n+                    List<Ddl> ddls = scenario.getPreScenarioDdls();\n+                    return ddls == null ? Lists.<Ddl>newArrayList() : ddls;\n+                }\n+\n+                @Override public String getId() {\n+                    return OperationType.PRE_RUN.name();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.PRE_RUN;\n+                }\n+            };\n+            // Initialize with the pre run operation.\n+            TenantOperationInfo preRunSample = new TenantOperationInfo(\n+                    input.getModelName(),\n+                    input.getScenarioName(),\n+                    input.getTableName(),\n+                    input.getTenantGroupId(),\n+                    Operation.OperationType.PRE_RUN.name(),\n+                    input.getTenantId(), operation);\n+\n+            TenantOperationImpl impl = new PreScenarioTenantOperationImpl();\n+            try {\n+                // Run the initialization operation.\n+                OperationStats stats = impl.getMethod().apply(preRunSample);\n+                LOGGER.info(phoenixUtil.getGSON().toJson(stats));\n+            } catch (Exception e) {\n+                LOGGER.error(\n+                        String.format(\"Failed to initialize tenant. [%s, %s] \",\n+                                tenantView.tenantId,\n+                                tenantView.viewName\n+                        ), e.fillInStackTrace());\n+            }\n+            tenantsLoaded.put(tenantView);\n+        }\n+\n+        switch (input.getOperation().getType()) {\n+        case NO_OP:\n+            return new NoopTenantOperationImpl();\n+        case SELECT:\n+            return new QueryTenantOperationImpl();\n+        case UPSERT:\n+            return new UpsertTenantOperationImpl();\n+        case USER_DEFINED:\n+            return new UserDefinedOperationImpl();\n+        default:\n+            throw new IllegalArgumentException(\"Unknown operation type\");\n+        }\n+    }\n+\n+    class QueryTenantOperationImpl implements TenantOperationImpl {\n+\n+        @Override public Function<TenantOperationInfo, OperationStats> getMethod() {\n+            return new Function<TenantOperationInfo, OperationStats>() {\n+\n+                @Nullable @Override public OperationStats apply(@Nullable TenantOperationInfo input) {\n+                    final QueryOperation operation = (QueryOperation) input.getOperation();\n+                    final String tenantGroup = input.getTenantGroupId();\n+                    final String opGroup = input.getOperationGroupId();\n+                    final String tenantId = input.getTenantId();\n+                    final String scenarioName = input.getScenarioName();\n+                    final String tableName = input.getTableName();\n+                    final Query query = operation.getQuery();\n+                    final long opCounter = 1;\n+\n+                    String opName = String.format(\"%s:%s:%s:%s:%s\", scenarioName, tableName,\n+                            opGroup, tenantGroup, tenantId);\n+                    LOGGER.info(\"\\nExecuting query \" + query.getStatement());\n+                    // TODO add explain plan output to the stats.", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5MDQxNg==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545490416", "bodyText": "Use try-with-resources instead", "author": "ChinmaySKulkarni", "createdAt": "2020-12-18T00:17:07Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/workload/mt/tenantoperation/TenantOperationFactory.java", "diffHunk": "@@ -0,0 +1,501 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.phoenix.pherf.workload.mt.tenantoperation;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Charsets;\n+import com.google.common.base.Function;\n+import com.google.common.collect.Lists;\n+import com.google.common.hash.BloomFilter;\n+import com.google.common.hash.Funnel;\n+import com.google.common.hash.PrimitiveSink;\n+import org.apache.phoenix.pherf.configuration.Column;\n+import org.apache.phoenix.pherf.configuration.DataModel;\n+import org.apache.phoenix.pherf.configuration.Ddl;\n+import org.apache.phoenix.pherf.configuration.LoadProfile;\n+import org.apache.phoenix.pherf.configuration.Noop;\n+import org.apache.phoenix.pherf.configuration.Query;\n+import org.apache.phoenix.pherf.configuration.QuerySet;\n+import org.apache.phoenix.pherf.configuration.Scenario;\n+import org.apache.phoenix.pherf.configuration.TenantGroup;\n+import org.apache.phoenix.pherf.configuration.Upsert;\n+import org.apache.phoenix.pherf.configuration.UserDefined;\n+import org.apache.phoenix.pherf.configuration.XMLConfigParser;\n+import org.apache.phoenix.pherf.rules.DataValue;\n+import org.apache.phoenix.pherf.rules.RulesApplier;\n+import org.apache.phoenix.pherf.util.PhoenixUtil;\n+import org.apache.phoenix.pherf.workload.mt.EventGenerator;\n+import org.apache.phoenix.pherf.workload.mt.NoopOperation;\n+import org.apache.phoenix.pherf.workload.mt.Operation;\n+import org.apache.phoenix.pherf.workload.mt.OperationStats;\n+import org.apache.phoenix.pherf.workload.mt.PreScenarioOperation;\n+import org.apache.phoenix.pherf.workload.mt.QueryOperation;\n+import org.apache.phoenix.pherf.workload.mt.UpsertOperation;\n+import org.apache.phoenix.pherf.workload.mt.UserDefinedOperation;\n+import org.apache.phoenix.util.EnvironmentEdgeManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.math.BigDecimal;\n+import java.sql.Array;\n+import java.sql.Connection;\n+import java.sql.Date;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.text.SimpleDateFormat;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * Factory class for operations.\n+ * The class is responsible for creating new instances of various operation types.\n+ * Operations typically implement @see {@link TenantOperationImpl}\n+ * Operations that need to be executed are generated\n+ * by @see {@link EventGenerator}\n+ */\n+public class TenantOperationFactory {\n+\n+    private static class TenantView {\n+        private final String tenantId;\n+        private final String viewName;\n+\n+        public TenantView(String tenantId, String viewName) {\n+            this.tenantId = tenantId;\n+            this.viewName = viewName;\n+        }\n+\n+        public String getTenantId() {\n+            return tenantId;\n+        }\n+\n+        public String getViewName() {\n+            return viewName;\n+        }\n+    }\n+    private static final Logger LOGGER = LoggerFactory.getLogger(TenantOperationFactory.class);\n+    private final PhoenixUtil phoenixUtil;\n+    private final DataModel model;\n+    private final Scenario scenario;\n+    private final XMLConfigParser parser;\n+\n+    private final RulesApplier rulesApplier;\n+    private final LoadProfile loadProfile;\n+    private final List<Operation> operationList = Lists.newArrayList();\n+\n+    private final BloomFilter<TenantView> tenantsLoaded;\n+\n+    public TenantOperationFactory(PhoenixUtil phoenixUtil, DataModel model, Scenario scenario) {\n+        this.phoenixUtil = phoenixUtil;\n+        this.model = model;\n+        this.scenario = scenario;\n+        this.parser = null;\n+        this.rulesApplier = new RulesApplier(model);\n+        this.loadProfile = this.scenario.getLoadProfile();\n+        Funnel<TenantView> tenantViewFunnel = new Funnel<TenantView>() {\n+            @Override\n+            public void funnel(TenantView tenantView, PrimitiveSink into) {\n+                into.putString(tenantView.getTenantId(), Charsets.UTF_8)\n+                        .putString(tenantView.getViewName(), Charsets.UTF_8);\n+            }\n+        };\n+\n+        int numTenants = 0;\n+        for (TenantGroup tg : loadProfile.getTenantDistribution()) {\n+            numTenants += tg.getNumTenants();\n+        }\n+\n+        // This holds the info whether the tenant view was created (initialized) or not.\n+        tenantsLoaded = BloomFilter.create(tenantViewFunnel, numTenants, 0.01);\n+\n+        // Read the scenario definition and load the various operations.\n+        for (final Noop noOp : scenario.getNoop()) {\n+            Operation noopOperation = new NoopOperation() {\n+                @Override public Noop getNoop() {\n+                    return noOp;\n+                }\n+                @Override public String getId() {\n+                    return noOp.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.NO_OP;\n+                }\n+            };\n+            operationList.add(noopOperation);\n+        }\n+\n+        for (final Upsert upsert : scenario.getUpsert()) {\n+            Operation upsertOp = new UpsertOperation() {\n+                @Override public Upsert getUpsert() {\n+                    return upsert;\n+                }\n+\n+                @Override public String getId() {\n+                    return upsert.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.UPSERT;\n+                }\n+            };\n+            operationList.add(upsertOp);\n+        }\n+        for (final QuerySet querySet : scenario.getQuerySet()) {\n+            for (final Query query : querySet.getQuery()) {\n+                Operation queryOp = new QueryOperation() {\n+                    @Override public Query getQuery() {\n+                        return query;\n+                    }\n+\n+                    @Override public String getId() {\n+                        return query.getId();\n+                    }\n+\n+                    @Override public OperationType getType() {\n+                        return OperationType.SELECT;\n+                    }\n+                };\n+                operationList.add(queryOp);\n+            }\n+        }\n+\n+        for (final UserDefined udf : scenario.getUdf()) {\n+            Operation udfOperation = new UserDefinedOperation() {\n+                @Override public UserDefined getUserFunction() {\n+                    return udf;\n+                }\n+\n+                @Override public String getId() {\n+                    return udf.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.USER_DEFINED;\n+                }\n+            };\n+            operationList.add(udfOperation);\n+        }\n+    }\n+\n+    public PhoenixUtil getPhoenixUtil() {\n+        return phoenixUtil;\n+    }\n+\n+    public DataModel getModel() {\n+        return model;\n+    }\n+\n+    public Scenario getScenario() {\n+        return scenario;\n+    }\n+\n+    public List<Operation> getOperationsForScenario() {\n+        return operationList;\n+    }\n+\n+    public TenantOperationImpl getOperation(final TenantOperationInfo input) {\n+        TenantView tenantView = new TenantView(input.getTenantId(), scenario.getTableName());\n+\n+        // Check if pre run ddls are needed.\n+        if (!tenantsLoaded.mightContain(tenantView)) {\n+            // Initialize the tenant using the pre scenario ddls.\n+            final PreScenarioOperation operation = new PreScenarioOperation() {\n+                @Override public List<Ddl> getPreScenarioDdls() {\n+                    List<Ddl> ddls = scenario.getPreScenarioDdls();\n+                    return ddls == null ? Lists.<Ddl>newArrayList() : ddls;\n+                }\n+\n+                @Override public String getId() {\n+                    return OperationType.PRE_RUN.name();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.PRE_RUN;\n+                }\n+            };\n+            // Initialize with the pre run operation.\n+            TenantOperationInfo preRunSample = new TenantOperationInfo(\n+                    input.getModelName(),\n+                    input.getScenarioName(),\n+                    input.getTableName(),\n+                    input.getTenantGroupId(),\n+                    Operation.OperationType.PRE_RUN.name(),\n+                    input.getTenantId(), operation);\n+\n+            TenantOperationImpl impl = new PreScenarioTenantOperationImpl();\n+            try {\n+                // Run the initialization operation.\n+                OperationStats stats = impl.getMethod().apply(preRunSample);\n+                LOGGER.info(phoenixUtil.getGSON().toJson(stats));\n+            } catch (Exception e) {\n+                LOGGER.error(\n+                        String.format(\"Failed to initialize tenant. [%s, %s] \",\n+                                tenantView.tenantId,\n+                                tenantView.viewName\n+                        ), e.fillInStackTrace());\n+            }\n+            tenantsLoaded.put(tenantView);\n+        }\n+\n+        switch (input.getOperation().getType()) {\n+        case NO_OP:\n+            return new NoopTenantOperationImpl();\n+        case SELECT:\n+            return new QueryTenantOperationImpl();\n+        case UPSERT:\n+            return new UpsertTenantOperationImpl();\n+        case USER_DEFINED:\n+            return new UserDefinedOperationImpl();\n+        default:\n+            throw new IllegalArgumentException(\"Unknown operation type\");\n+        }\n+    }\n+\n+    class QueryTenantOperationImpl implements TenantOperationImpl {\n+\n+        @Override public Function<TenantOperationInfo, OperationStats> getMethod() {\n+            return new Function<TenantOperationInfo, OperationStats>() {\n+\n+                @Nullable @Override public OperationStats apply(@Nullable TenantOperationInfo input) {\n+                    final QueryOperation operation = (QueryOperation) input.getOperation();\n+                    final String tenantGroup = input.getTenantGroupId();\n+                    final String opGroup = input.getOperationGroupId();\n+                    final String tenantId = input.getTenantId();\n+                    final String scenarioName = input.getScenarioName();\n+                    final String tableName = input.getTableName();\n+                    final Query query = operation.getQuery();\n+                    final long opCounter = 1;\n+\n+                    String opName = String.format(\"%s:%s:%s:%s:%s\", scenarioName, tableName,\n+                            opGroup, tenantGroup, tenantId);\n+                    LOGGER.info(\"\\nExecuting query \" + query.getStatement());\n+                    // TODO add explain plan output to the stats.\n+\n+                    Connection conn = null;\n+                    PreparedStatement statement = null;\n+                    ResultSet rs = null;\n+                    Long startTime = EnvironmentEdgeManager.currentTimeMillis();\n+                    Long resultRowCount = 0L;\n+                    Long queryElapsedTime = 0L;\n+                    String queryIteration = opName + \":\" + opCounter;\n+                    try {", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5MDY2Nw==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545490667", "bodyText": "Can you explain what you mean by 'dynamic statements' and do we want to uncomment/remove this?", "author": "ChinmaySKulkarni", "createdAt": "2020-12-18T00:17:51Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/workload/mt/tenantoperation/TenantOperationFactory.java", "diffHunk": "@@ -0,0 +1,501 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.phoenix.pherf.workload.mt.tenantoperation;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Charsets;\n+import com.google.common.base.Function;\n+import com.google.common.collect.Lists;\n+import com.google.common.hash.BloomFilter;\n+import com.google.common.hash.Funnel;\n+import com.google.common.hash.PrimitiveSink;\n+import org.apache.phoenix.pherf.configuration.Column;\n+import org.apache.phoenix.pherf.configuration.DataModel;\n+import org.apache.phoenix.pherf.configuration.Ddl;\n+import org.apache.phoenix.pherf.configuration.LoadProfile;\n+import org.apache.phoenix.pherf.configuration.Noop;\n+import org.apache.phoenix.pherf.configuration.Query;\n+import org.apache.phoenix.pherf.configuration.QuerySet;\n+import org.apache.phoenix.pherf.configuration.Scenario;\n+import org.apache.phoenix.pherf.configuration.TenantGroup;\n+import org.apache.phoenix.pherf.configuration.Upsert;\n+import org.apache.phoenix.pherf.configuration.UserDefined;\n+import org.apache.phoenix.pherf.configuration.XMLConfigParser;\n+import org.apache.phoenix.pherf.rules.DataValue;\n+import org.apache.phoenix.pherf.rules.RulesApplier;\n+import org.apache.phoenix.pherf.util.PhoenixUtil;\n+import org.apache.phoenix.pherf.workload.mt.EventGenerator;\n+import org.apache.phoenix.pherf.workload.mt.NoopOperation;\n+import org.apache.phoenix.pherf.workload.mt.Operation;\n+import org.apache.phoenix.pherf.workload.mt.OperationStats;\n+import org.apache.phoenix.pherf.workload.mt.PreScenarioOperation;\n+import org.apache.phoenix.pherf.workload.mt.QueryOperation;\n+import org.apache.phoenix.pherf.workload.mt.UpsertOperation;\n+import org.apache.phoenix.pherf.workload.mt.UserDefinedOperation;\n+import org.apache.phoenix.util.EnvironmentEdgeManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.math.BigDecimal;\n+import java.sql.Array;\n+import java.sql.Connection;\n+import java.sql.Date;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.text.SimpleDateFormat;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * Factory class for operations.\n+ * The class is responsible for creating new instances of various operation types.\n+ * Operations typically implement @see {@link TenantOperationImpl}\n+ * Operations that need to be executed are generated\n+ * by @see {@link EventGenerator}\n+ */\n+public class TenantOperationFactory {\n+\n+    private static class TenantView {\n+        private final String tenantId;\n+        private final String viewName;\n+\n+        public TenantView(String tenantId, String viewName) {\n+            this.tenantId = tenantId;\n+            this.viewName = viewName;\n+        }\n+\n+        public String getTenantId() {\n+            return tenantId;\n+        }\n+\n+        public String getViewName() {\n+            return viewName;\n+        }\n+    }\n+    private static final Logger LOGGER = LoggerFactory.getLogger(TenantOperationFactory.class);\n+    private final PhoenixUtil phoenixUtil;\n+    private final DataModel model;\n+    private final Scenario scenario;\n+    private final XMLConfigParser parser;\n+\n+    private final RulesApplier rulesApplier;\n+    private final LoadProfile loadProfile;\n+    private final List<Operation> operationList = Lists.newArrayList();\n+\n+    private final BloomFilter<TenantView> tenantsLoaded;\n+\n+    public TenantOperationFactory(PhoenixUtil phoenixUtil, DataModel model, Scenario scenario) {\n+        this.phoenixUtil = phoenixUtil;\n+        this.model = model;\n+        this.scenario = scenario;\n+        this.parser = null;\n+        this.rulesApplier = new RulesApplier(model);\n+        this.loadProfile = this.scenario.getLoadProfile();\n+        Funnel<TenantView> tenantViewFunnel = new Funnel<TenantView>() {\n+            @Override\n+            public void funnel(TenantView tenantView, PrimitiveSink into) {\n+                into.putString(tenantView.getTenantId(), Charsets.UTF_8)\n+                        .putString(tenantView.getViewName(), Charsets.UTF_8);\n+            }\n+        };\n+\n+        int numTenants = 0;\n+        for (TenantGroup tg : loadProfile.getTenantDistribution()) {\n+            numTenants += tg.getNumTenants();\n+        }\n+\n+        // This holds the info whether the tenant view was created (initialized) or not.\n+        tenantsLoaded = BloomFilter.create(tenantViewFunnel, numTenants, 0.01);\n+\n+        // Read the scenario definition and load the various operations.\n+        for (final Noop noOp : scenario.getNoop()) {\n+            Operation noopOperation = new NoopOperation() {\n+                @Override public Noop getNoop() {\n+                    return noOp;\n+                }\n+                @Override public String getId() {\n+                    return noOp.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.NO_OP;\n+                }\n+            };\n+            operationList.add(noopOperation);\n+        }\n+\n+        for (final Upsert upsert : scenario.getUpsert()) {\n+            Operation upsertOp = new UpsertOperation() {\n+                @Override public Upsert getUpsert() {\n+                    return upsert;\n+                }\n+\n+                @Override public String getId() {\n+                    return upsert.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.UPSERT;\n+                }\n+            };\n+            operationList.add(upsertOp);\n+        }\n+        for (final QuerySet querySet : scenario.getQuerySet()) {\n+            for (final Query query : querySet.getQuery()) {\n+                Operation queryOp = new QueryOperation() {\n+                    @Override public Query getQuery() {\n+                        return query;\n+                    }\n+\n+                    @Override public String getId() {\n+                        return query.getId();\n+                    }\n+\n+                    @Override public OperationType getType() {\n+                        return OperationType.SELECT;\n+                    }\n+                };\n+                operationList.add(queryOp);\n+            }\n+        }\n+\n+        for (final UserDefined udf : scenario.getUdf()) {\n+            Operation udfOperation = new UserDefinedOperation() {\n+                @Override public UserDefined getUserFunction() {\n+                    return udf;\n+                }\n+\n+                @Override public String getId() {\n+                    return udf.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.USER_DEFINED;\n+                }\n+            };\n+            operationList.add(udfOperation);\n+        }\n+    }\n+\n+    public PhoenixUtil getPhoenixUtil() {\n+        return phoenixUtil;\n+    }\n+\n+    public DataModel getModel() {\n+        return model;\n+    }\n+\n+    public Scenario getScenario() {\n+        return scenario;\n+    }\n+\n+    public List<Operation> getOperationsForScenario() {\n+        return operationList;\n+    }\n+\n+    public TenantOperationImpl getOperation(final TenantOperationInfo input) {\n+        TenantView tenantView = new TenantView(input.getTenantId(), scenario.getTableName());\n+\n+        // Check if pre run ddls are needed.\n+        if (!tenantsLoaded.mightContain(tenantView)) {\n+            // Initialize the tenant using the pre scenario ddls.\n+            final PreScenarioOperation operation = new PreScenarioOperation() {\n+                @Override public List<Ddl> getPreScenarioDdls() {\n+                    List<Ddl> ddls = scenario.getPreScenarioDdls();\n+                    return ddls == null ? Lists.<Ddl>newArrayList() : ddls;\n+                }\n+\n+                @Override public String getId() {\n+                    return OperationType.PRE_RUN.name();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.PRE_RUN;\n+                }\n+            };\n+            // Initialize with the pre run operation.\n+            TenantOperationInfo preRunSample = new TenantOperationInfo(\n+                    input.getModelName(),\n+                    input.getScenarioName(),\n+                    input.getTableName(),\n+                    input.getTenantGroupId(),\n+                    Operation.OperationType.PRE_RUN.name(),\n+                    input.getTenantId(), operation);\n+\n+            TenantOperationImpl impl = new PreScenarioTenantOperationImpl();\n+            try {\n+                // Run the initialization operation.\n+                OperationStats stats = impl.getMethod().apply(preRunSample);\n+                LOGGER.info(phoenixUtil.getGSON().toJson(stats));\n+            } catch (Exception e) {\n+                LOGGER.error(\n+                        String.format(\"Failed to initialize tenant. [%s, %s] \",\n+                                tenantView.tenantId,\n+                                tenantView.viewName\n+                        ), e.fillInStackTrace());\n+            }\n+            tenantsLoaded.put(tenantView);\n+        }\n+\n+        switch (input.getOperation().getType()) {\n+        case NO_OP:\n+            return new NoopTenantOperationImpl();\n+        case SELECT:\n+            return new QueryTenantOperationImpl();\n+        case UPSERT:\n+            return new UpsertTenantOperationImpl();\n+        case USER_DEFINED:\n+            return new UserDefinedOperationImpl();\n+        default:\n+            throw new IllegalArgumentException(\"Unknown operation type\");\n+        }\n+    }\n+\n+    class QueryTenantOperationImpl implements TenantOperationImpl {\n+\n+        @Override public Function<TenantOperationInfo, OperationStats> getMethod() {\n+            return new Function<TenantOperationInfo, OperationStats>() {\n+\n+                @Nullable @Override public OperationStats apply(@Nullable TenantOperationInfo input) {\n+                    final QueryOperation operation = (QueryOperation) input.getOperation();\n+                    final String tenantGroup = input.getTenantGroupId();\n+                    final String opGroup = input.getOperationGroupId();\n+                    final String tenantId = input.getTenantId();\n+                    final String scenarioName = input.getScenarioName();\n+                    final String tableName = input.getTableName();\n+                    final Query query = operation.getQuery();\n+                    final long opCounter = 1;\n+\n+                    String opName = String.format(\"%s:%s:%s:%s:%s\", scenarioName, tableName,\n+                            opGroup, tenantGroup, tenantId);\n+                    LOGGER.info(\"\\nExecuting query \" + query.getStatement());\n+                    // TODO add explain plan output to the stats.\n+\n+                    Connection conn = null;\n+                    PreparedStatement statement = null;\n+                    ResultSet rs = null;\n+                    Long startTime = EnvironmentEdgeManager.currentTimeMillis();\n+                    Long resultRowCount = 0L;\n+                    Long queryElapsedTime = 0L;\n+                    String queryIteration = opName + \":\" + opCounter;\n+                    try {\n+                        conn = phoenixUtil.getConnection(tenantId);\n+                        conn.setAutoCommit(true);\n+                        // TODO dynamic statements\n+                        //final String statementString = query.getDynamicStatement(rulesApplier, scenario);", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5MDc5NQ==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545490795", "bodyText": "nit: Logger.error(String, e) should be sufficient", "author": "ChinmaySKulkarni", "createdAt": "2020-12-18T00:18:13Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/workload/mt/tenantoperation/TenantOperationFactory.java", "diffHunk": "@@ -0,0 +1,501 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.phoenix.pherf.workload.mt.tenantoperation;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Charsets;\n+import com.google.common.base.Function;\n+import com.google.common.collect.Lists;\n+import com.google.common.hash.BloomFilter;\n+import com.google.common.hash.Funnel;\n+import com.google.common.hash.PrimitiveSink;\n+import org.apache.phoenix.pherf.configuration.Column;\n+import org.apache.phoenix.pherf.configuration.DataModel;\n+import org.apache.phoenix.pherf.configuration.Ddl;\n+import org.apache.phoenix.pherf.configuration.LoadProfile;\n+import org.apache.phoenix.pherf.configuration.Noop;\n+import org.apache.phoenix.pherf.configuration.Query;\n+import org.apache.phoenix.pherf.configuration.QuerySet;\n+import org.apache.phoenix.pherf.configuration.Scenario;\n+import org.apache.phoenix.pherf.configuration.TenantGroup;\n+import org.apache.phoenix.pherf.configuration.Upsert;\n+import org.apache.phoenix.pherf.configuration.UserDefined;\n+import org.apache.phoenix.pherf.configuration.XMLConfigParser;\n+import org.apache.phoenix.pherf.rules.DataValue;\n+import org.apache.phoenix.pherf.rules.RulesApplier;\n+import org.apache.phoenix.pherf.util.PhoenixUtil;\n+import org.apache.phoenix.pherf.workload.mt.EventGenerator;\n+import org.apache.phoenix.pherf.workload.mt.NoopOperation;\n+import org.apache.phoenix.pherf.workload.mt.Operation;\n+import org.apache.phoenix.pherf.workload.mt.OperationStats;\n+import org.apache.phoenix.pherf.workload.mt.PreScenarioOperation;\n+import org.apache.phoenix.pherf.workload.mt.QueryOperation;\n+import org.apache.phoenix.pherf.workload.mt.UpsertOperation;\n+import org.apache.phoenix.pherf.workload.mt.UserDefinedOperation;\n+import org.apache.phoenix.util.EnvironmentEdgeManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.math.BigDecimal;\n+import java.sql.Array;\n+import java.sql.Connection;\n+import java.sql.Date;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.text.SimpleDateFormat;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * Factory class for operations.\n+ * The class is responsible for creating new instances of various operation types.\n+ * Operations typically implement @see {@link TenantOperationImpl}\n+ * Operations that need to be executed are generated\n+ * by @see {@link EventGenerator}\n+ */\n+public class TenantOperationFactory {\n+\n+    private static class TenantView {\n+        private final String tenantId;\n+        private final String viewName;\n+\n+        public TenantView(String tenantId, String viewName) {\n+            this.tenantId = tenantId;\n+            this.viewName = viewName;\n+        }\n+\n+        public String getTenantId() {\n+            return tenantId;\n+        }\n+\n+        public String getViewName() {\n+            return viewName;\n+        }\n+    }\n+    private static final Logger LOGGER = LoggerFactory.getLogger(TenantOperationFactory.class);\n+    private final PhoenixUtil phoenixUtil;\n+    private final DataModel model;\n+    private final Scenario scenario;\n+    private final XMLConfigParser parser;\n+\n+    private final RulesApplier rulesApplier;\n+    private final LoadProfile loadProfile;\n+    private final List<Operation> operationList = Lists.newArrayList();\n+\n+    private final BloomFilter<TenantView> tenantsLoaded;\n+\n+    public TenantOperationFactory(PhoenixUtil phoenixUtil, DataModel model, Scenario scenario) {\n+        this.phoenixUtil = phoenixUtil;\n+        this.model = model;\n+        this.scenario = scenario;\n+        this.parser = null;\n+        this.rulesApplier = new RulesApplier(model);\n+        this.loadProfile = this.scenario.getLoadProfile();\n+        Funnel<TenantView> tenantViewFunnel = new Funnel<TenantView>() {\n+            @Override\n+            public void funnel(TenantView tenantView, PrimitiveSink into) {\n+                into.putString(tenantView.getTenantId(), Charsets.UTF_8)\n+                        .putString(tenantView.getViewName(), Charsets.UTF_8);\n+            }\n+        };\n+\n+        int numTenants = 0;\n+        for (TenantGroup tg : loadProfile.getTenantDistribution()) {\n+            numTenants += tg.getNumTenants();\n+        }\n+\n+        // This holds the info whether the tenant view was created (initialized) or not.\n+        tenantsLoaded = BloomFilter.create(tenantViewFunnel, numTenants, 0.01);\n+\n+        // Read the scenario definition and load the various operations.\n+        for (final Noop noOp : scenario.getNoop()) {\n+            Operation noopOperation = new NoopOperation() {\n+                @Override public Noop getNoop() {\n+                    return noOp;\n+                }\n+                @Override public String getId() {\n+                    return noOp.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.NO_OP;\n+                }\n+            };\n+            operationList.add(noopOperation);\n+        }\n+\n+        for (final Upsert upsert : scenario.getUpsert()) {\n+            Operation upsertOp = new UpsertOperation() {\n+                @Override public Upsert getUpsert() {\n+                    return upsert;\n+                }\n+\n+                @Override public String getId() {\n+                    return upsert.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.UPSERT;\n+                }\n+            };\n+            operationList.add(upsertOp);\n+        }\n+        for (final QuerySet querySet : scenario.getQuerySet()) {\n+            for (final Query query : querySet.getQuery()) {\n+                Operation queryOp = new QueryOperation() {\n+                    @Override public Query getQuery() {\n+                        return query;\n+                    }\n+\n+                    @Override public String getId() {\n+                        return query.getId();\n+                    }\n+\n+                    @Override public OperationType getType() {\n+                        return OperationType.SELECT;\n+                    }\n+                };\n+                operationList.add(queryOp);\n+            }\n+        }\n+\n+        for (final UserDefined udf : scenario.getUdf()) {\n+            Operation udfOperation = new UserDefinedOperation() {\n+                @Override public UserDefined getUserFunction() {\n+                    return udf;\n+                }\n+\n+                @Override public String getId() {\n+                    return udf.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.USER_DEFINED;\n+                }\n+            };\n+            operationList.add(udfOperation);\n+        }\n+    }\n+\n+    public PhoenixUtil getPhoenixUtil() {\n+        return phoenixUtil;\n+    }\n+\n+    public DataModel getModel() {\n+        return model;\n+    }\n+\n+    public Scenario getScenario() {\n+        return scenario;\n+    }\n+\n+    public List<Operation> getOperationsForScenario() {\n+        return operationList;\n+    }\n+\n+    public TenantOperationImpl getOperation(final TenantOperationInfo input) {\n+        TenantView tenantView = new TenantView(input.getTenantId(), scenario.getTableName());\n+\n+        // Check if pre run ddls are needed.\n+        if (!tenantsLoaded.mightContain(tenantView)) {\n+            // Initialize the tenant using the pre scenario ddls.\n+            final PreScenarioOperation operation = new PreScenarioOperation() {\n+                @Override public List<Ddl> getPreScenarioDdls() {\n+                    List<Ddl> ddls = scenario.getPreScenarioDdls();\n+                    return ddls == null ? Lists.<Ddl>newArrayList() : ddls;\n+                }\n+\n+                @Override public String getId() {\n+                    return OperationType.PRE_RUN.name();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.PRE_RUN;\n+                }\n+            };\n+            // Initialize with the pre run operation.\n+            TenantOperationInfo preRunSample = new TenantOperationInfo(\n+                    input.getModelName(),\n+                    input.getScenarioName(),\n+                    input.getTableName(),\n+                    input.getTenantGroupId(),\n+                    Operation.OperationType.PRE_RUN.name(),\n+                    input.getTenantId(), operation);\n+\n+            TenantOperationImpl impl = new PreScenarioTenantOperationImpl();\n+            try {\n+                // Run the initialization operation.\n+                OperationStats stats = impl.getMethod().apply(preRunSample);\n+                LOGGER.info(phoenixUtil.getGSON().toJson(stats));\n+            } catch (Exception e) {\n+                LOGGER.error(\n+                        String.format(\"Failed to initialize tenant. [%s, %s] \",\n+                                tenantView.tenantId,\n+                                tenantView.viewName\n+                        ), e.fillInStackTrace());", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5MTEyOQ==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545491129", "bodyText": "nit: You can use Closables.closeQuietly() for these", "author": "ChinmaySKulkarni", "createdAt": "2020-12-18T00:19:09Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/workload/mt/tenantoperation/TenantOperationFactory.java", "diffHunk": "@@ -0,0 +1,501 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.phoenix.pherf.workload.mt.tenantoperation;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Charsets;\n+import com.google.common.base.Function;\n+import com.google.common.collect.Lists;\n+import com.google.common.hash.BloomFilter;\n+import com.google.common.hash.Funnel;\n+import com.google.common.hash.PrimitiveSink;\n+import org.apache.phoenix.pherf.configuration.Column;\n+import org.apache.phoenix.pherf.configuration.DataModel;\n+import org.apache.phoenix.pherf.configuration.Ddl;\n+import org.apache.phoenix.pherf.configuration.LoadProfile;\n+import org.apache.phoenix.pherf.configuration.Noop;\n+import org.apache.phoenix.pherf.configuration.Query;\n+import org.apache.phoenix.pherf.configuration.QuerySet;\n+import org.apache.phoenix.pherf.configuration.Scenario;\n+import org.apache.phoenix.pherf.configuration.TenantGroup;\n+import org.apache.phoenix.pherf.configuration.Upsert;\n+import org.apache.phoenix.pherf.configuration.UserDefined;\n+import org.apache.phoenix.pherf.configuration.XMLConfigParser;\n+import org.apache.phoenix.pherf.rules.DataValue;\n+import org.apache.phoenix.pherf.rules.RulesApplier;\n+import org.apache.phoenix.pherf.util.PhoenixUtil;\n+import org.apache.phoenix.pherf.workload.mt.EventGenerator;\n+import org.apache.phoenix.pherf.workload.mt.NoopOperation;\n+import org.apache.phoenix.pherf.workload.mt.Operation;\n+import org.apache.phoenix.pherf.workload.mt.OperationStats;\n+import org.apache.phoenix.pherf.workload.mt.PreScenarioOperation;\n+import org.apache.phoenix.pherf.workload.mt.QueryOperation;\n+import org.apache.phoenix.pherf.workload.mt.UpsertOperation;\n+import org.apache.phoenix.pherf.workload.mt.UserDefinedOperation;\n+import org.apache.phoenix.util.EnvironmentEdgeManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.math.BigDecimal;\n+import java.sql.Array;\n+import java.sql.Connection;\n+import java.sql.Date;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.text.SimpleDateFormat;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * Factory class for operations.\n+ * The class is responsible for creating new instances of various operation types.\n+ * Operations typically implement @see {@link TenantOperationImpl}\n+ * Operations that need to be executed are generated\n+ * by @see {@link EventGenerator}\n+ */\n+public class TenantOperationFactory {\n+\n+    private static class TenantView {\n+        private final String tenantId;\n+        private final String viewName;\n+\n+        public TenantView(String tenantId, String viewName) {\n+            this.tenantId = tenantId;\n+            this.viewName = viewName;\n+        }\n+\n+        public String getTenantId() {\n+            return tenantId;\n+        }\n+\n+        public String getViewName() {\n+            return viewName;\n+        }\n+    }\n+    private static final Logger LOGGER = LoggerFactory.getLogger(TenantOperationFactory.class);\n+    private final PhoenixUtil phoenixUtil;\n+    private final DataModel model;\n+    private final Scenario scenario;\n+    private final XMLConfigParser parser;\n+\n+    private final RulesApplier rulesApplier;\n+    private final LoadProfile loadProfile;\n+    private final List<Operation> operationList = Lists.newArrayList();\n+\n+    private final BloomFilter<TenantView> tenantsLoaded;\n+\n+    public TenantOperationFactory(PhoenixUtil phoenixUtil, DataModel model, Scenario scenario) {\n+        this.phoenixUtil = phoenixUtil;\n+        this.model = model;\n+        this.scenario = scenario;\n+        this.parser = null;\n+        this.rulesApplier = new RulesApplier(model);\n+        this.loadProfile = this.scenario.getLoadProfile();\n+        Funnel<TenantView> tenantViewFunnel = new Funnel<TenantView>() {\n+            @Override\n+            public void funnel(TenantView tenantView, PrimitiveSink into) {\n+                into.putString(tenantView.getTenantId(), Charsets.UTF_8)\n+                        .putString(tenantView.getViewName(), Charsets.UTF_8);\n+            }\n+        };\n+\n+        int numTenants = 0;\n+        for (TenantGroup tg : loadProfile.getTenantDistribution()) {\n+            numTenants += tg.getNumTenants();\n+        }\n+\n+        // This holds the info whether the tenant view was created (initialized) or not.\n+        tenantsLoaded = BloomFilter.create(tenantViewFunnel, numTenants, 0.01);\n+\n+        // Read the scenario definition and load the various operations.\n+        for (final Noop noOp : scenario.getNoop()) {\n+            Operation noopOperation = new NoopOperation() {\n+                @Override public Noop getNoop() {\n+                    return noOp;\n+                }\n+                @Override public String getId() {\n+                    return noOp.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.NO_OP;\n+                }\n+            };\n+            operationList.add(noopOperation);\n+        }\n+\n+        for (final Upsert upsert : scenario.getUpsert()) {\n+            Operation upsertOp = new UpsertOperation() {\n+                @Override public Upsert getUpsert() {\n+                    return upsert;\n+                }\n+\n+                @Override public String getId() {\n+                    return upsert.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.UPSERT;\n+                }\n+            };\n+            operationList.add(upsertOp);\n+        }\n+        for (final QuerySet querySet : scenario.getQuerySet()) {\n+            for (final Query query : querySet.getQuery()) {\n+                Operation queryOp = new QueryOperation() {\n+                    @Override public Query getQuery() {\n+                        return query;\n+                    }\n+\n+                    @Override public String getId() {\n+                        return query.getId();\n+                    }\n+\n+                    @Override public OperationType getType() {\n+                        return OperationType.SELECT;\n+                    }\n+                };\n+                operationList.add(queryOp);\n+            }\n+        }\n+\n+        for (final UserDefined udf : scenario.getUdf()) {\n+            Operation udfOperation = new UserDefinedOperation() {\n+                @Override public UserDefined getUserFunction() {\n+                    return udf;\n+                }\n+\n+                @Override public String getId() {\n+                    return udf.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.USER_DEFINED;\n+                }\n+            };\n+            operationList.add(udfOperation);\n+        }\n+    }\n+\n+    public PhoenixUtil getPhoenixUtil() {\n+        return phoenixUtil;\n+    }\n+\n+    public DataModel getModel() {\n+        return model;\n+    }\n+\n+    public Scenario getScenario() {\n+        return scenario;\n+    }\n+\n+    public List<Operation> getOperationsForScenario() {\n+        return operationList;\n+    }\n+\n+    public TenantOperationImpl getOperation(final TenantOperationInfo input) {\n+        TenantView tenantView = new TenantView(input.getTenantId(), scenario.getTableName());\n+\n+        // Check if pre run ddls are needed.\n+        if (!tenantsLoaded.mightContain(tenantView)) {\n+            // Initialize the tenant using the pre scenario ddls.\n+            final PreScenarioOperation operation = new PreScenarioOperation() {\n+                @Override public List<Ddl> getPreScenarioDdls() {\n+                    List<Ddl> ddls = scenario.getPreScenarioDdls();\n+                    return ddls == null ? Lists.<Ddl>newArrayList() : ddls;\n+                }\n+\n+                @Override public String getId() {\n+                    return OperationType.PRE_RUN.name();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.PRE_RUN;\n+                }\n+            };\n+            // Initialize with the pre run operation.\n+            TenantOperationInfo preRunSample = new TenantOperationInfo(\n+                    input.getModelName(),\n+                    input.getScenarioName(),\n+                    input.getTableName(),\n+                    input.getTenantGroupId(),\n+                    Operation.OperationType.PRE_RUN.name(),\n+                    input.getTenantId(), operation);\n+\n+            TenantOperationImpl impl = new PreScenarioTenantOperationImpl();\n+            try {\n+                // Run the initialization operation.\n+                OperationStats stats = impl.getMethod().apply(preRunSample);\n+                LOGGER.info(phoenixUtil.getGSON().toJson(stats));\n+            } catch (Exception e) {\n+                LOGGER.error(\n+                        String.format(\"Failed to initialize tenant. [%s, %s] \",\n+                                tenantView.tenantId,\n+                                tenantView.viewName\n+                        ), e.fillInStackTrace());\n+            }\n+            tenantsLoaded.put(tenantView);\n+        }\n+\n+        switch (input.getOperation().getType()) {\n+        case NO_OP:\n+            return new NoopTenantOperationImpl();\n+        case SELECT:\n+            return new QueryTenantOperationImpl();\n+        case UPSERT:\n+            return new UpsertTenantOperationImpl();\n+        case USER_DEFINED:\n+            return new UserDefinedOperationImpl();\n+        default:\n+            throw new IllegalArgumentException(\"Unknown operation type\");\n+        }\n+    }\n+\n+    class QueryTenantOperationImpl implements TenantOperationImpl {\n+\n+        @Override public Function<TenantOperationInfo, OperationStats> getMethod() {\n+            return new Function<TenantOperationInfo, OperationStats>() {\n+\n+                @Nullable @Override public OperationStats apply(@Nullable TenantOperationInfo input) {\n+                    final QueryOperation operation = (QueryOperation) input.getOperation();\n+                    final String tenantGroup = input.getTenantGroupId();\n+                    final String opGroup = input.getOperationGroupId();\n+                    final String tenantId = input.getTenantId();\n+                    final String scenarioName = input.getScenarioName();\n+                    final String tableName = input.getTableName();\n+                    final Query query = operation.getQuery();\n+                    final long opCounter = 1;\n+\n+                    String opName = String.format(\"%s:%s:%s:%s:%s\", scenarioName, tableName,\n+                            opGroup, tenantGroup, tenantId);\n+                    LOGGER.info(\"\\nExecuting query \" + query.getStatement());\n+                    // TODO add explain plan output to the stats.\n+\n+                    Connection conn = null;\n+                    PreparedStatement statement = null;\n+                    ResultSet rs = null;\n+                    Long startTime = EnvironmentEdgeManager.currentTimeMillis();\n+                    Long resultRowCount = 0L;\n+                    Long queryElapsedTime = 0L;\n+                    String queryIteration = opName + \":\" + opCounter;\n+                    try {\n+                        conn = phoenixUtil.getConnection(tenantId);\n+                        conn.setAutoCommit(true);\n+                        // TODO dynamic statements\n+                        //final String statementString = query.getDynamicStatement(rulesApplier, scenario);\n+                        statement = conn.prepareStatement(query.getStatement());\n+                        boolean isQuery = statement.execute();\n+                        if (isQuery) {\n+                            rs = statement.getResultSet();\n+                            boolean isSelectCountStatement = query.getStatement().toUpperCase().trim().contains(\"COUNT(\") ? true : false;\n+                            org.apache.hadoop.hbase.util.Pair<Long, Long>\n+                                    r = phoenixUtil.getResults(query, rs, queryIteration, isSelectCountStatement, startTime);\n+                            resultRowCount = r.getFirst();\n+                            queryElapsedTime = r.getSecond();\n+                        } else {\n+                            conn.commit();\n+                        }\n+                    } catch (Exception e) {\n+                        LOGGER.error(\"Exception while executing query iteration \" + queryIteration, e);\n+                    } finally {\n+                        try {\n+                            if (rs != null) rs.close();\n+                            if (statement != null) statement.close();\n+                            if (conn != null) conn.close();\n+\n+                        } catch (Throwable t) {\n+                            // swallow;", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5MTUwMg==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545491502", "bodyText": "We call commit() later anyways. Is setting this necessary? In case we run UPSERT SELECTS or DELETES with auto-commit, that will change the execution (client side vs server side) and this might be undesirable.", "author": "ChinmaySKulkarni", "createdAt": "2020-12-18T00:20:20Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/workload/mt/tenantoperation/TenantOperationFactory.java", "diffHunk": "@@ -0,0 +1,501 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.phoenix.pherf.workload.mt.tenantoperation;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Charsets;\n+import com.google.common.base.Function;\n+import com.google.common.collect.Lists;\n+import com.google.common.hash.BloomFilter;\n+import com.google.common.hash.Funnel;\n+import com.google.common.hash.PrimitiveSink;\n+import org.apache.phoenix.pherf.configuration.Column;\n+import org.apache.phoenix.pherf.configuration.DataModel;\n+import org.apache.phoenix.pherf.configuration.Ddl;\n+import org.apache.phoenix.pherf.configuration.LoadProfile;\n+import org.apache.phoenix.pherf.configuration.Noop;\n+import org.apache.phoenix.pherf.configuration.Query;\n+import org.apache.phoenix.pherf.configuration.QuerySet;\n+import org.apache.phoenix.pherf.configuration.Scenario;\n+import org.apache.phoenix.pherf.configuration.TenantGroup;\n+import org.apache.phoenix.pherf.configuration.Upsert;\n+import org.apache.phoenix.pherf.configuration.UserDefined;\n+import org.apache.phoenix.pherf.configuration.XMLConfigParser;\n+import org.apache.phoenix.pherf.rules.DataValue;\n+import org.apache.phoenix.pherf.rules.RulesApplier;\n+import org.apache.phoenix.pherf.util.PhoenixUtil;\n+import org.apache.phoenix.pherf.workload.mt.EventGenerator;\n+import org.apache.phoenix.pherf.workload.mt.NoopOperation;\n+import org.apache.phoenix.pherf.workload.mt.Operation;\n+import org.apache.phoenix.pherf.workload.mt.OperationStats;\n+import org.apache.phoenix.pherf.workload.mt.PreScenarioOperation;\n+import org.apache.phoenix.pherf.workload.mt.QueryOperation;\n+import org.apache.phoenix.pherf.workload.mt.UpsertOperation;\n+import org.apache.phoenix.pherf.workload.mt.UserDefinedOperation;\n+import org.apache.phoenix.util.EnvironmentEdgeManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.math.BigDecimal;\n+import java.sql.Array;\n+import java.sql.Connection;\n+import java.sql.Date;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.text.SimpleDateFormat;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * Factory class for operations.\n+ * The class is responsible for creating new instances of various operation types.\n+ * Operations typically implement @see {@link TenantOperationImpl}\n+ * Operations that need to be executed are generated\n+ * by @see {@link EventGenerator}\n+ */\n+public class TenantOperationFactory {\n+\n+    private static class TenantView {\n+        private final String tenantId;\n+        private final String viewName;\n+\n+        public TenantView(String tenantId, String viewName) {\n+            this.tenantId = tenantId;\n+            this.viewName = viewName;\n+        }\n+\n+        public String getTenantId() {\n+            return tenantId;\n+        }\n+\n+        public String getViewName() {\n+            return viewName;\n+        }\n+    }\n+    private static final Logger LOGGER = LoggerFactory.getLogger(TenantOperationFactory.class);\n+    private final PhoenixUtil phoenixUtil;\n+    private final DataModel model;\n+    private final Scenario scenario;\n+    private final XMLConfigParser parser;\n+\n+    private final RulesApplier rulesApplier;\n+    private final LoadProfile loadProfile;\n+    private final List<Operation> operationList = Lists.newArrayList();\n+\n+    private final BloomFilter<TenantView> tenantsLoaded;\n+\n+    public TenantOperationFactory(PhoenixUtil phoenixUtil, DataModel model, Scenario scenario) {\n+        this.phoenixUtil = phoenixUtil;\n+        this.model = model;\n+        this.scenario = scenario;\n+        this.parser = null;\n+        this.rulesApplier = new RulesApplier(model);\n+        this.loadProfile = this.scenario.getLoadProfile();\n+        Funnel<TenantView> tenantViewFunnel = new Funnel<TenantView>() {\n+            @Override\n+            public void funnel(TenantView tenantView, PrimitiveSink into) {\n+                into.putString(tenantView.getTenantId(), Charsets.UTF_8)\n+                        .putString(tenantView.getViewName(), Charsets.UTF_8);\n+            }\n+        };\n+\n+        int numTenants = 0;\n+        for (TenantGroup tg : loadProfile.getTenantDistribution()) {\n+            numTenants += tg.getNumTenants();\n+        }\n+\n+        // This holds the info whether the tenant view was created (initialized) or not.\n+        tenantsLoaded = BloomFilter.create(tenantViewFunnel, numTenants, 0.01);\n+\n+        // Read the scenario definition and load the various operations.\n+        for (final Noop noOp : scenario.getNoop()) {\n+            Operation noopOperation = new NoopOperation() {\n+                @Override public Noop getNoop() {\n+                    return noOp;\n+                }\n+                @Override public String getId() {\n+                    return noOp.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.NO_OP;\n+                }\n+            };\n+            operationList.add(noopOperation);\n+        }\n+\n+        for (final Upsert upsert : scenario.getUpsert()) {\n+            Operation upsertOp = new UpsertOperation() {\n+                @Override public Upsert getUpsert() {\n+                    return upsert;\n+                }\n+\n+                @Override public String getId() {\n+                    return upsert.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.UPSERT;\n+                }\n+            };\n+            operationList.add(upsertOp);\n+        }\n+        for (final QuerySet querySet : scenario.getQuerySet()) {\n+            for (final Query query : querySet.getQuery()) {\n+                Operation queryOp = new QueryOperation() {\n+                    @Override public Query getQuery() {\n+                        return query;\n+                    }\n+\n+                    @Override public String getId() {\n+                        return query.getId();\n+                    }\n+\n+                    @Override public OperationType getType() {\n+                        return OperationType.SELECT;\n+                    }\n+                };\n+                operationList.add(queryOp);\n+            }\n+        }\n+\n+        for (final UserDefined udf : scenario.getUdf()) {\n+            Operation udfOperation = new UserDefinedOperation() {\n+                @Override public UserDefined getUserFunction() {\n+                    return udf;\n+                }\n+\n+                @Override public String getId() {\n+                    return udf.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.USER_DEFINED;\n+                }\n+            };\n+            operationList.add(udfOperation);\n+        }\n+    }\n+\n+    public PhoenixUtil getPhoenixUtil() {\n+        return phoenixUtil;\n+    }\n+\n+    public DataModel getModel() {\n+        return model;\n+    }\n+\n+    public Scenario getScenario() {\n+        return scenario;\n+    }\n+\n+    public List<Operation> getOperationsForScenario() {\n+        return operationList;\n+    }\n+\n+    public TenantOperationImpl getOperation(final TenantOperationInfo input) {\n+        TenantView tenantView = new TenantView(input.getTenantId(), scenario.getTableName());\n+\n+        // Check if pre run ddls are needed.\n+        if (!tenantsLoaded.mightContain(tenantView)) {\n+            // Initialize the tenant using the pre scenario ddls.\n+            final PreScenarioOperation operation = new PreScenarioOperation() {\n+                @Override public List<Ddl> getPreScenarioDdls() {\n+                    List<Ddl> ddls = scenario.getPreScenarioDdls();\n+                    return ddls == null ? Lists.<Ddl>newArrayList() : ddls;\n+                }\n+\n+                @Override public String getId() {\n+                    return OperationType.PRE_RUN.name();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.PRE_RUN;\n+                }\n+            };\n+            // Initialize with the pre run operation.\n+            TenantOperationInfo preRunSample = new TenantOperationInfo(\n+                    input.getModelName(),\n+                    input.getScenarioName(),\n+                    input.getTableName(),\n+                    input.getTenantGroupId(),\n+                    Operation.OperationType.PRE_RUN.name(),\n+                    input.getTenantId(), operation);\n+\n+            TenantOperationImpl impl = new PreScenarioTenantOperationImpl();\n+            try {\n+                // Run the initialization operation.\n+                OperationStats stats = impl.getMethod().apply(preRunSample);\n+                LOGGER.info(phoenixUtil.getGSON().toJson(stats));\n+            } catch (Exception e) {\n+                LOGGER.error(\n+                        String.format(\"Failed to initialize tenant. [%s, %s] \",\n+                                tenantView.tenantId,\n+                                tenantView.viewName\n+                        ), e.fillInStackTrace());\n+            }\n+            tenantsLoaded.put(tenantView);\n+        }\n+\n+        switch (input.getOperation().getType()) {\n+        case NO_OP:\n+            return new NoopTenantOperationImpl();\n+        case SELECT:\n+            return new QueryTenantOperationImpl();\n+        case UPSERT:\n+            return new UpsertTenantOperationImpl();\n+        case USER_DEFINED:\n+            return new UserDefinedOperationImpl();\n+        default:\n+            throw new IllegalArgumentException(\"Unknown operation type\");\n+        }\n+    }\n+\n+    class QueryTenantOperationImpl implements TenantOperationImpl {\n+\n+        @Override public Function<TenantOperationInfo, OperationStats> getMethod() {\n+            return new Function<TenantOperationInfo, OperationStats>() {\n+\n+                @Nullable @Override public OperationStats apply(@Nullable TenantOperationInfo input) {\n+                    final QueryOperation operation = (QueryOperation) input.getOperation();\n+                    final String tenantGroup = input.getTenantGroupId();\n+                    final String opGroup = input.getOperationGroupId();\n+                    final String tenantId = input.getTenantId();\n+                    final String scenarioName = input.getScenarioName();\n+                    final String tableName = input.getTableName();\n+                    final Query query = operation.getQuery();\n+                    final long opCounter = 1;\n+\n+                    String opName = String.format(\"%s:%s:%s:%s:%s\", scenarioName, tableName,\n+                            opGroup, tenantGroup, tenantId);\n+                    LOGGER.info(\"\\nExecuting query \" + query.getStatement());\n+                    // TODO add explain plan output to the stats.\n+\n+                    Connection conn = null;\n+                    PreparedStatement statement = null;\n+                    ResultSet rs = null;\n+                    Long startTime = EnvironmentEdgeManager.currentTimeMillis();\n+                    Long resultRowCount = 0L;\n+                    Long queryElapsedTime = 0L;\n+                    String queryIteration = opName + \":\" + opCounter;\n+                    try {\n+                        conn = phoenixUtil.getConnection(tenantId);\n+                        conn.setAutoCommit(true);\n+                        // TODO dynamic statements\n+                        //final String statementString = query.getDynamicStatement(rulesApplier, scenario);\n+                        statement = conn.prepareStatement(query.getStatement());\n+                        boolean isQuery = statement.execute();\n+                        if (isQuery) {\n+                            rs = statement.getResultSet();\n+                            boolean isSelectCountStatement = query.getStatement().toUpperCase().trim().contains(\"COUNT(\") ? true : false;\n+                            org.apache.hadoop.hbase.util.Pair<Long, Long>\n+                                    r = phoenixUtil.getResults(query, rs, queryIteration, isSelectCountStatement, startTime);\n+                            resultRowCount = r.getFirst();\n+                            queryElapsedTime = r.getSecond();\n+                        } else {\n+                            conn.commit();\n+                        }\n+                    } catch (Exception e) {\n+                        LOGGER.error(\"Exception while executing query iteration \" + queryIteration, e);\n+                    } finally {\n+                        try {\n+                            if (rs != null) rs.close();\n+                            if (statement != null) statement.close();\n+                            if (conn != null) conn.close();\n+\n+                        } catch (Throwable t) {\n+                            // swallow;\n+                        }\n+                    }\n+                    return new OperationStats(input, startTime, 0, resultRowCount, queryElapsedTime);\n+                }\n+            };\n+        }\n+    }\n+\n+    class UpsertTenantOperationImpl implements TenantOperationImpl {\n+\n+        @Override public Function<TenantOperationInfo, OperationStats> getMethod() {\n+            return new Function<TenantOperationInfo, OperationStats>() {\n+\n+                @Nullable @Override public OperationStats apply(@Nullable TenantOperationInfo input) {\n+\n+                    final int batchSize = loadProfile.getBatchSize();\n+                    final boolean useBatchApi = batchSize != 0;\n+                    final int rowCount = useBatchApi ? batchSize : 1;\n+\n+                    final UpsertOperation operation = (UpsertOperation) input.getOperation();\n+                    final String tenantGroup = input.getTenantGroupId();\n+                    final String opGroup = input.getOperationGroupId();\n+                    final String tenantId = input.getTenantId();\n+                    final Upsert upsert = operation.getUpsert();\n+                    final String tableName = input.getTableName();\n+                    final String scenarioName = input.getScenarioName();\n+                    final List<Column> columns = upsert.getColumn();\n+\n+                    final String opName = String.format(\"%s:%s:%s:%s:%s\",\n+                            scenarioName, tableName, opGroup, tenantGroup, tenantId);\n+\n+                    long rowsCreated = 0;\n+                    long startTime = 0, duration, totalDuration;\n+                    SimpleDateFormat simpleDateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");\n+                    try (Connection connection = phoenixUtil.getConnection(tenantId)) {\n+                        connection.setAutoCommit(true);", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5MTY2Ng==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545491666", "bodyText": "Log instead", "author": "ChinmaySKulkarni", "createdAt": "2020-12-18T00:20:52Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/workload/mt/tenantoperation/TenantOperationFactory.java", "diffHunk": "@@ -0,0 +1,501 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.phoenix.pherf.workload.mt.tenantoperation;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Charsets;\n+import com.google.common.base.Function;\n+import com.google.common.collect.Lists;\n+import com.google.common.hash.BloomFilter;\n+import com.google.common.hash.Funnel;\n+import com.google.common.hash.PrimitiveSink;\n+import org.apache.phoenix.pherf.configuration.Column;\n+import org.apache.phoenix.pherf.configuration.DataModel;\n+import org.apache.phoenix.pherf.configuration.Ddl;\n+import org.apache.phoenix.pherf.configuration.LoadProfile;\n+import org.apache.phoenix.pherf.configuration.Noop;\n+import org.apache.phoenix.pherf.configuration.Query;\n+import org.apache.phoenix.pherf.configuration.QuerySet;\n+import org.apache.phoenix.pherf.configuration.Scenario;\n+import org.apache.phoenix.pherf.configuration.TenantGroup;\n+import org.apache.phoenix.pherf.configuration.Upsert;\n+import org.apache.phoenix.pherf.configuration.UserDefined;\n+import org.apache.phoenix.pherf.configuration.XMLConfigParser;\n+import org.apache.phoenix.pherf.rules.DataValue;\n+import org.apache.phoenix.pherf.rules.RulesApplier;\n+import org.apache.phoenix.pherf.util.PhoenixUtil;\n+import org.apache.phoenix.pherf.workload.mt.EventGenerator;\n+import org.apache.phoenix.pherf.workload.mt.NoopOperation;\n+import org.apache.phoenix.pherf.workload.mt.Operation;\n+import org.apache.phoenix.pherf.workload.mt.OperationStats;\n+import org.apache.phoenix.pherf.workload.mt.PreScenarioOperation;\n+import org.apache.phoenix.pherf.workload.mt.QueryOperation;\n+import org.apache.phoenix.pherf.workload.mt.UpsertOperation;\n+import org.apache.phoenix.pherf.workload.mt.UserDefinedOperation;\n+import org.apache.phoenix.util.EnvironmentEdgeManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.math.BigDecimal;\n+import java.sql.Array;\n+import java.sql.Connection;\n+import java.sql.Date;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.text.SimpleDateFormat;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * Factory class for operations.\n+ * The class is responsible for creating new instances of various operation types.\n+ * Operations typically implement @see {@link TenantOperationImpl}\n+ * Operations that need to be executed are generated\n+ * by @see {@link EventGenerator}\n+ */\n+public class TenantOperationFactory {\n+\n+    private static class TenantView {\n+        private final String tenantId;\n+        private final String viewName;\n+\n+        public TenantView(String tenantId, String viewName) {\n+            this.tenantId = tenantId;\n+            this.viewName = viewName;\n+        }\n+\n+        public String getTenantId() {\n+            return tenantId;\n+        }\n+\n+        public String getViewName() {\n+            return viewName;\n+        }\n+    }\n+    private static final Logger LOGGER = LoggerFactory.getLogger(TenantOperationFactory.class);\n+    private final PhoenixUtil phoenixUtil;\n+    private final DataModel model;\n+    private final Scenario scenario;\n+    private final XMLConfigParser parser;\n+\n+    private final RulesApplier rulesApplier;\n+    private final LoadProfile loadProfile;\n+    private final List<Operation> operationList = Lists.newArrayList();\n+\n+    private final BloomFilter<TenantView> tenantsLoaded;\n+\n+    public TenantOperationFactory(PhoenixUtil phoenixUtil, DataModel model, Scenario scenario) {\n+        this.phoenixUtil = phoenixUtil;\n+        this.model = model;\n+        this.scenario = scenario;\n+        this.parser = null;\n+        this.rulesApplier = new RulesApplier(model);\n+        this.loadProfile = this.scenario.getLoadProfile();\n+        Funnel<TenantView> tenantViewFunnel = new Funnel<TenantView>() {\n+            @Override\n+            public void funnel(TenantView tenantView, PrimitiveSink into) {\n+                into.putString(tenantView.getTenantId(), Charsets.UTF_8)\n+                        .putString(tenantView.getViewName(), Charsets.UTF_8);\n+            }\n+        };\n+\n+        int numTenants = 0;\n+        for (TenantGroup tg : loadProfile.getTenantDistribution()) {\n+            numTenants += tg.getNumTenants();\n+        }\n+\n+        // This holds the info whether the tenant view was created (initialized) or not.\n+        tenantsLoaded = BloomFilter.create(tenantViewFunnel, numTenants, 0.01);\n+\n+        // Read the scenario definition and load the various operations.\n+        for (final Noop noOp : scenario.getNoop()) {\n+            Operation noopOperation = new NoopOperation() {\n+                @Override public Noop getNoop() {\n+                    return noOp;\n+                }\n+                @Override public String getId() {\n+                    return noOp.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.NO_OP;\n+                }\n+            };\n+            operationList.add(noopOperation);\n+        }\n+\n+        for (final Upsert upsert : scenario.getUpsert()) {\n+            Operation upsertOp = new UpsertOperation() {\n+                @Override public Upsert getUpsert() {\n+                    return upsert;\n+                }\n+\n+                @Override public String getId() {\n+                    return upsert.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.UPSERT;\n+                }\n+            };\n+            operationList.add(upsertOp);\n+        }\n+        for (final QuerySet querySet : scenario.getQuerySet()) {\n+            for (final Query query : querySet.getQuery()) {\n+                Operation queryOp = new QueryOperation() {\n+                    @Override public Query getQuery() {\n+                        return query;\n+                    }\n+\n+                    @Override public String getId() {\n+                        return query.getId();\n+                    }\n+\n+                    @Override public OperationType getType() {\n+                        return OperationType.SELECT;\n+                    }\n+                };\n+                operationList.add(queryOp);\n+            }\n+        }\n+\n+        for (final UserDefined udf : scenario.getUdf()) {\n+            Operation udfOperation = new UserDefinedOperation() {\n+                @Override public UserDefined getUserFunction() {\n+                    return udf;\n+                }\n+\n+                @Override public String getId() {\n+                    return udf.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.USER_DEFINED;\n+                }\n+            };\n+            operationList.add(udfOperation);\n+        }\n+    }\n+\n+    public PhoenixUtil getPhoenixUtil() {\n+        return phoenixUtil;\n+    }\n+\n+    public DataModel getModel() {\n+        return model;\n+    }\n+\n+    public Scenario getScenario() {\n+        return scenario;\n+    }\n+\n+    public List<Operation> getOperationsForScenario() {\n+        return operationList;\n+    }\n+\n+    public TenantOperationImpl getOperation(final TenantOperationInfo input) {\n+        TenantView tenantView = new TenantView(input.getTenantId(), scenario.getTableName());\n+\n+        // Check if pre run ddls are needed.\n+        if (!tenantsLoaded.mightContain(tenantView)) {\n+            // Initialize the tenant using the pre scenario ddls.\n+            final PreScenarioOperation operation = new PreScenarioOperation() {\n+                @Override public List<Ddl> getPreScenarioDdls() {\n+                    List<Ddl> ddls = scenario.getPreScenarioDdls();\n+                    return ddls == null ? Lists.<Ddl>newArrayList() : ddls;\n+                }\n+\n+                @Override public String getId() {\n+                    return OperationType.PRE_RUN.name();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.PRE_RUN;\n+                }\n+            };\n+            // Initialize with the pre run operation.\n+            TenantOperationInfo preRunSample = new TenantOperationInfo(\n+                    input.getModelName(),\n+                    input.getScenarioName(),\n+                    input.getTableName(),\n+                    input.getTenantGroupId(),\n+                    Operation.OperationType.PRE_RUN.name(),\n+                    input.getTenantId(), operation);\n+\n+            TenantOperationImpl impl = new PreScenarioTenantOperationImpl();\n+            try {\n+                // Run the initialization operation.\n+                OperationStats stats = impl.getMethod().apply(preRunSample);\n+                LOGGER.info(phoenixUtil.getGSON().toJson(stats));\n+            } catch (Exception e) {\n+                LOGGER.error(\n+                        String.format(\"Failed to initialize tenant. [%s, %s] \",\n+                                tenantView.tenantId,\n+                                tenantView.viewName\n+                        ), e.fillInStackTrace());\n+            }\n+            tenantsLoaded.put(tenantView);\n+        }\n+\n+        switch (input.getOperation().getType()) {\n+        case NO_OP:\n+            return new NoopTenantOperationImpl();\n+        case SELECT:\n+            return new QueryTenantOperationImpl();\n+        case UPSERT:\n+            return new UpsertTenantOperationImpl();\n+        case USER_DEFINED:\n+            return new UserDefinedOperationImpl();\n+        default:\n+            throw new IllegalArgumentException(\"Unknown operation type\");\n+        }\n+    }\n+\n+    class QueryTenantOperationImpl implements TenantOperationImpl {\n+\n+        @Override public Function<TenantOperationInfo, OperationStats> getMethod() {\n+            return new Function<TenantOperationInfo, OperationStats>() {\n+\n+                @Nullable @Override public OperationStats apply(@Nullable TenantOperationInfo input) {\n+                    final QueryOperation operation = (QueryOperation) input.getOperation();\n+                    final String tenantGroup = input.getTenantGroupId();\n+                    final String opGroup = input.getOperationGroupId();\n+                    final String tenantId = input.getTenantId();\n+                    final String scenarioName = input.getScenarioName();\n+                    final String tableName = input.getTableName();\n+                    final Query query = operation.getQuery();\n+                    final long opCounter = 1;\n+\n+                    String opName = String.format(\"%s:%s:%s:%s:%s\", scenarioName, tableName,\n+                            opGroup, tenantGroup, tenantId);\n+                    LOGGER.info(\"\\nExecuting query \" + query.getStatement());\n+                    // TODO add explain plan output to the stats.\n+\n+                    Connection conn = null;\n+                    PreparedStatement statement = null;\n+                    ResultSet rs = null;\n+                    Long startTime = EnvironmentEdgeManager.currentTimeMillis();\n+                    Long resultRowCount = 0L;\n+                    Long queryElapsedTime = 0L;\n+                    String queryIteration = opName + \":\" + opCounter;\n+                    try {\n+                        conn = phoenixUtil.getConnection(tenantId);\n+                        conn.setAutoCommit(true);\n+                        // TODO dynamic statements\n+                        //final String statementString = query.getDynamicStatement(rulesApplier, scenario);\n+                        statement = conn.prepareStatement(query.getStatement());\n+                        boolean isQuery = statement.execute();\n+                        if (isQuery) {\n+                            rs = statement.getResultSet();\n+                            boolean isSelectCountStatement = query.getStatement().toUpperCase().trim().contains(\"COUNT(\") ? true : false;\n+                            org.apache.hadoop.hbase.util.Pair<Long, Long>\n+                                    r = phoenixUtil.getResults(query, rs, queryIteration, isSelectCountStatement, startTime);\n+                            resultRowCount = r.getFirst();\n+                            queryElapsedTime = r.getSecond();\n+                        } else {\n+                            conn.commit();\n+                        }\n+                    } catch (Exception e) {\n+                        LOGGER.error(\"Exception while executing query iteration \" + queryIteration, e);\n+                    } finally {\n+                        try {\n+                            if (rs != null) rs.close();\n+                            if (statement != null) statement.close();\n+                            if (conn != null) conn.close();\n+\n+                        } catch (Throwable t) {\n+                            // swallow;\n+                        }\n+                    }\n+                    return new OperationStats(input, startTime, 0, resultRowCount, queryElapsedTime);\n+                }\n+            };\n+        }\n+    }\n+\n+    class UpsertTenantOperationImpl implements TenantOperationImpl {\n+\n+        @Override public Function<TenantOperationInfo, OperationStats> getMethod() {\n+            return new Function<TenantOperationInfo, OperationStats>() {\n+\n+                @Nullable @Override public OperationStats apply(@Nullable TenantOperationInfo input) {\n+\n+                    final int batchSize = loadProfile.getBatchSize();\n+                    final boolean useBatchApi = batchSize != 0;\n+                    final int rowCount = useBatchApi ? batchSize : 1;\n+\n+                    final UpsertOperation operation = (UpsertOperation) input.getOperation();\n+                    final String tenantGroup = input.getTenantGroupId();\n+                    final String opGroup = input.getOperationGroupId();\n+                    final String tenantId = input.getTenantId();\n+                    final Upsert upsert = operation.getUpsert();\n+                    final String tableName = input.getTableName();\n+                    final String scenarioName = input.getScenarioName();\n+                    final List<Column> columns = upsert.getColumn();\n+\n+                    final String opName = String.format(\"%s:%s:%s:%s:%s\",\n+                            scenarioName, tableName, opGroup, tenantGroup, tenantId);\n+\n+                    long rowsCreated = 0;\n+                    long startTime = 0, duration, totalDuration;\n+                    SimpleDateFormat simpleDateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");\n+                    try (Connection connection = phoenixUtil.getConnection(tenantId)) {\n+                        connection.setAutoCommit(true);\n+                        startTime = EnvironmentEdgeManager.currentTimeMillis();\n+                        String sql = phoenixUtil.buildSql(columns, tableName);\n+                        PreparedStatement stmt = null;\n+                        try {\n+                            stmt = connection.prepareStatement(sql);\n+                            for (long i = rowCount; i > 0; i--) {\n+                                LOGGER.debug(\"Operation \" + opName + \" executing \");\n+                                stmt = phoenixUtil.buildStatement(rulesApplier, scenario, columns, stmt, simpleDateFormat);\n+                                if (useBatchApi) {\n+                                    stmt.addBatch();\n+                                } else {\n+                                    rowsCreated += stmt.executeUpdate();\n+                                }\n+                            }\n+                        } catch (SQLException e) {\n+                            LOGGER.error(\"Operation \" + opName + \" failed with exception \", e);\n+                            throw e;\n+                        } finally {\n+                            // Need to keep the statement open to send the remaining batch of updates\n+                            if (!useBatchApi && stmt != null) {\n+                                stmt.close();\n+                            }\n+                            if (connection != null) {\n+                                if (useBatchApi && stmt != null) {\n+                                    int[] results = stmt.executeBatch();\n+                                    for (int x = 0; x < results.length; x++) {\n+                                        int result = results[x];\n+                                        if (result < 1) {\n+                                            final String msg =\n+                                                    \"Failed to write update in batch (update count=\"\n+                                                            + result + \")\";\n+                                            throw new RuntimeException(msg);\n+                                        }\n+                                        rowsCreated += result;\n+                                    }\n+                                    // Close the statement after our last batch execution.\n+                                    stmt.close();\n+                                }\n+\n+                                try {\n+                                    connection.commit();\n+                                    duration = EnvironmentEdgeManager.currentTimeMillis() - startTime;\n+                                    LOGGER.info(\"Writer ( \" + Thread.currentThread().getName()\n+                                            + \") committed Final Batch. Duration (\" + duration + \") Ms\");\n+                                    connection.close();\n+                                } catch (SQLException e) {\n+                                    // Swallow since we are closing anyway\n+                                    e.printStackTrace();", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5MTczMQ==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545491731", "bodyText": "Use try-with-resources.", "author": "ChinmaySKulkarni", "createdAt": "2020-12-18T00:21:04Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/workload/mt/tenantoperation/TenantOperationFactory.java", "diffHunk": "@@ -0,0 +1,501 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.phoenix.pherf.workload.mt.tenantoperation;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Charsets;\n+import com.google.common.base.Function;\n+import com.google.common.collect.Lists;\n+import com.google.common.hash.BloomFilter;\n+import com.google.common.hash.Funnel;\n+import com.google.common.hash.PrimitiveSink;\n+import org.apache.phoenix.pherf.configuration.Column;\n+import org.apache.phoenix.pherf.configuration.DataModel;\n+import org.apache.phoenix.pherf.configuration.Ddl;\n+import org.apache.phoenix.pherf.configuration.LoadProfile;\n+import org.apache.phoenix.pherf.configuration.Noop;\n+import org.apache.phoenix.pherf.configuration.Query;\n+import org.apache.phoenix.pherf.configuration.QuerySet;\n+import org.apache.phoenix.pherf.configuration.Scenario;\n+import org.apache.phoenix.pherf.configuration.TenantGroup;\n+import org.apache.phoenix.pherf.configuration.Upsert;\n+import org.apache.phoenix.pherf.configuration.UserDefined;\n+import org.apache.phoenix.pherf.configuration.XMLConfigParser;\n+import org.apache.phoenix.pherf.rules.DataValue;\n+import org.apache.phoenix.pherf.rules.RulesApplier;\n+import org.apache.phoenix.pherf.util.PhoenixUtil;\n+import org.apache.phoenix.pherf.workload.mt.EventGenerator;\n+import org.apache.phoenix.pherf.workload.mt.NoopOperation;\n+import org.apache.phoenix.pherf.workload.mt.Operation;\n+import org.apache.phoenix.pherf.workload.mt.OperationStats;\n+import org.apache.phoenix.pherf.workload.mt.PreScenarioOperation;\n+import org.apache.phoenix.pherf.workload.mt.QueryOperation;\n+import org.apache.phoenix.pherf.workload.mt.UpsertOperation;\n+import org.apache.phoenix.pherf.workload.mt.UserDefinedOperation;\n+import org.apache.phoenix.util.EnvironmentEdgeManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.math.BigDecimal;\n+import java.sql.Array;\n+import java.sql.Connection;\n+import java.sql.Date;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.text.SimpleDateFormat;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * Factory class for operations.\n+ * The class is responsible for creating new instances of various operation types.\n+ * Operations typically implement @see {@link TenantOperationImpl}\n+ * Operations that need to be executed are generated\n+ * by @see {@link EventGenerator}\n+ */\n+public class TenantOperationFactory {\n+\n+    private static class TenantView {\n+        private final String tenantId;\n+        private final String viewName;\n+\n+        public TenantView(String tenantId, String viewName) {\n+            this.tenantId = tenantId;\n+            this.viewName = viewName;\n+        }\n+\n+        public String getTenantId() {\n+            return tenantId;\n+        }\n+\n+        public String getViewName() {\n+            return viewName;\n+        }\n+    }\n+    private static final Logger LOGGER = LoggerFactory.getLogger(TenantOperationFactory.class);\n+    private final PhoenixUtil phoenixUtil;\n+    private final DataModel model;\n+    private final Scenario scenario;\n+    private final XMLConfigParser parser;\n+\n+    private final RulesApplier rulesApplier;\n+    private final LoadProfile loadProfile;\n+    private final List<Operation> operationList = Lists.newArrayList();\n+\n+    private final BloomFilter<TenantView> tenantsLoaded;\n+\n+    public TenantOperationFactory(PhoenixUtil phoenixUtil, DataModel model, Scenario scenario) {\n+        this.phoenixUtil = phoenixUtil;\n+        this.model = model;\n+        this.scenario = scenario;\n+        this.parser = null;\n+        this.rulesApplier = new RulesApplier(model);\n+        this.loadProfile = this.scenario.getLoadProfile();\n+        Funnel<TenantView> tenantViewFunnel = new Funnel<TenantView>() {\n+            @Override\n+            public void funnel(TenantView tenantView, PrimitiveSink into) {\n+                into.putString(tenantView.getTenantId(), Charsets.UTF_8)\n+                        .putString(tenantView.getViewName(), Charsets.UTF_8);\n+            }\n+        };\n+\n+        int numTenants = 0;\n+        for (TenantGroup tg : loadProfile.getTenantDistribution()) {\n+            numTenants += tg.getNumTenants();\n+        }\n+\n+        // This holds the info whether the tenant view was created (initialized) or not.\n+        tenantsLoaded = BloomFilter.create(tenantViewFunnel, numTenants, 0.01);\n+\n+        // Read the scenario definition and load the various operations.\n+        for (final Noop noOp : scenario.getNoop()) {\n+            Operation noopOperation = new NoopOperation() {\n+                @Override public Noop getNoop() {\n+                    return noOp;\n+                }\n+                @Override public String getId() {\n+                    return noOp.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.NO_OP;\n+                }\n+            };\n+            operationList.add(noopOperation);\n+        }\n+\n+        for (final Upsert upsert : scenario.getUpsert()) {\n+            Operation upsertOp = new UpsertOperation() {\n+                @Override public Upsert getUpsert() {\n+                    return upsert;\n+                }\n+\n+                @Override public String getId() {\n+                    return upsert.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.UPSERT;\n+                }\n+            };\n+            operationList.add(upsertOp);\n+        }\n+        for (final QuerySet querySet : scenario.getQuerySet()) {\n+            for (final Query query : querySet.getQuery()) {\n+                Operation queryOp = new QueryOperation() {\n+                    @Override public Query getQuery() {\n+                        return query;\n+                    }\n+\n+                    @Override public String getId() {\n+                        return query.getId();\n+                    }\n+\n+                    @Override public OperationType getType() {\n+                        return OperationType.SELECT;\n+                    }\n+                };\n+                operationList.add(queryOp);\n+            }\n+        }\n+\n+        for (final UserDefined udf : scenario.getUdf()) {\n+            Operation udfOperation = new UserDefinedOperation() {\n+                @Override public UserDefined getUserFunction() {\n+                    return udf;\n+                }\n+\n+                @Override public String getId() {\n+                    return udf.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.USER_DEFINED;\n+                }\n+            };\n+            operationList.add(udfOperation);\n+        }\n+    }\n+\n+    public PhoenixUtil getPhoenixUtil() {\n+        return phoenixUtil;\n+    }\n+\n+    public DataModel getModel() {\n+        return model;\n+    }\n+\n+    public Scenario getScenario() {\n+        return scenario;\n+    }\n+\n+    public List<Operation> getOperationsForScenario() {\n+        return operationList;\n+    }\n+\n+    public TenantOperationImpl getOperation(final TenantOperationInfo input) {\n+        TenantView tenantView = new TenantView(input.getTenantId(), scenario.getTableName());\n+\n+        // Check if pre run ddls are needed.\n+        if (!tenantsLoaded.mightContain(tenantView)) {\n+            // Initialize the tenant using the pre scenario ddls.\n+            final PreScenarioOperation operation = new PreScenarioOperation() {\n+                @Override public List<Ddl> getPreScenarioDdls() {\n+                    List<Ddl> ddls = scenario.getPreScenarioDdls();\n+                    return ddls == null ? Lists.<Ddl>newArrayList() : ddls;\n+                }\n+\n+                @Override public String getId() {\n+                    return OperationType.PRE_RUN.name();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.PRE_RUN;\n+                }\n+            };\n+            // Initialize with the pre run operation.\n+            TenantOperationInfo preRunSample = new TenantOperationInfo(\n+                    input.getModelName(),\n+                    input.getScenarioName(),\n+                    input.getTableName(),\n+                    input.getTenantGroupId(),\n+                    Operation.OperationType.PRE_RUN.name(),\n+                    input.getTenantId(), operation);\n+\n+            TenantOperationImpl impl = new PreScenarioTenantOperationImpl();\n+            try {\n+                // Run the initialization operation.\n+                OperationStats stats = impl.getMethod().apply(preRunSample);\n+                LOGGER.info(phoenixUtil.getGSON().toJson(stats));\n+            } catch (Exception e) {\n+                LOGGER.error(\n+                        String.format(\"Failed to initialize tenant. [%s, %s] \",\n+                                tenantView.tenantId,\n+                                tenantView.viewName\n+                        ), e.fillInStackTrace());\n+            }\n+            tenantsLoaded.put(tenantView);\n+        }\n+\n+        switch (input.getOperation().getType()) {\n+        case NO_OP:\n+            return new NoopTenantOperationImpl();\n+        case SELECT:\n+            return new QueryTenantOperationImpl();\n+        case UPSERT:\n+            return new UpsertTenantOperationImpl();\n+        case USER_DEFINED:\n+            return new UserDefinedOperationImpl();\n+        default:\n+            throw new IllegalArgumentException(\"Unknown operation type\");\n+        }\n+    }\n+\n+    class QueryTenantOperationImpl implements TenantOperationImpl {\n+\n+        @Override public Function<TenantOperationInfo, OperationStats> getMethod() {\n+            return new Function<TenantOperationInfo, OperationStats>() {\n+\n+                @Nullable @Override public OperationStats apply(@Nullable TenantOperationInfo input) {\n+                    final QueryOperation operation = (QueryOperation) input.getOperation();\n+                    final String tenantGroup = input.getTenantGroupId();\n+                    final String opGroup = input.getOperationGroupId();\n+                    final String tenantId = input.getTenantId();\n+                    final String scenarioName = input.getScenarioName();\n+                    final String tableName = input.getTableName();\n+                    final Query query = operation.getQuery();\n+                    final long opCounter = 1;\n+\n+                    String opName = String.format(\"%s:%s:%s:%s:%s\", scenarioName, tableName,\n+                            opGroup, tenantGroup, tenantId);\n+                    LOGGER.info(\"\\nExecuting query \" + query.getStatement());\n+                    // TODO add explain plan output to the stats.\n+\n+                    Connection conn = null;\n+                    PreparedStatement statement = null;\n+                    ResultSet rs = null;\n+                    Long startTime = EnvironmentEdgeManager.currentTimeMillis();\n+                    Long resultRowCount = 0L;\n+                    Long queryElapsedTime = 0L;\n+                    String queryIteration = opName + \":\" + opCounter;\n+                    try {\n+                        conn = phoenixUtil.getConnection(tenantId);\n+                        conn.setAutoCommit(true);\n+                        // TODO dynamic statements\n+                        //final String statementString = query.getDynamicStatement(rulesApplier, scenario);\n+                        statement = conn.prepareStatement(query.getStatement());\n+                        boolean isQuery = statement.execute();\n+                        if (isQuery) {\n+                            rs = statement.getResultSet();\n+                            boolean isSelectCountStatement = query.getStatement().toUpperCase().trim().contains(\"COUNT(\") ? true : false;\n+                            org.apache.hadoop.hbase.util.Pair<Long, Long>\n+                                    r = phoenixUtil.getResults(query, rs, queryIteration, isSelectCountStatement, startTime);\n+                            resultRowCount = r.getFirst();\n+                            queryElapsedTime = r.getSecond();\n+                        } else {\n+                            conn.commit();\n+                        }\n+                    } catch (Exception e) {\n+                        LOGGER.error(\"Exception while executing query iteration \" + queryIteration, e);\n+                    } finally {\n+                        try {\n+                            if (rs != null) rs.close();\n+                            if (statement != null) statement.close();\n+                            if (conn != null) conn.close();\n+\n+                        } catch (Throwable t) {\n+                            // swallow;\n+                        }\n+                    }\n+                    return new OperationStats(input, startTime, 0, resultRowCount, queryElapsedTime);\n+                }\n+            };\n+        }\n+    }\n+\n+    class UpsertTenantOperationImpl implements TenantOperationImpl {\n+\n+        @Override public Function<TenantOperationInfo, OperationStats> getMethod() {\n+            return new Function<TenantOperationInfo, OperationStats>() {\n+\n+                @Nullable @Override public OperationStats apply(@Nullable TenantOperationInfo input) {\n+\n+                    final int batchSize = loadProfile.getBatchSize();\n+                    final boolean useBatchApi = batchSize != 0;\n+                    final int rowCount = useBatchApi ? batchSize : 1;\n+\n+                    final UpsertOperation operation = (UpsertOperation) input.getOperation();\n+                    final String tenantGroup = input.getTenantGroupId();\n+                    final String opGroup = input.getOperationGroupId();\n+                    final String tenantId = input.getTenantId();\n+                    final Upsert upsert = operation.getUpsert();\n+                    final String tableName = input.getTableName();\n+                    final String scenarioName = input.getScenarioName();\n+                    final List<Column> columns = upsert.getColumn();\n+\n+                    final String opName = String.format(\"%s:%s:%s:%s:%s\",\n+                            scenarioName, tableName, opGroup, tenantGroup, tenantId);\n+\n+                    long rowsCreated = 0;\n+                    long startTime = 0, duration, totalDuration;\n+                    SimpleDateFormat simpleDateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");\n+                    try (Connection connection = phoenixUtil.getConnection(tenantId)) {\n+                        connection.setAutoCommit(true);\n+                        startTime = EnvironmentEdgeManager.currentTimeMillis();\n+                        String sql = phoenixUtil.buildSql(columns, tableName);\n+                        PreparedStatement stmt = null;\n+                        try {", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5MTk4OA==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545491988", "bodyText": "Might be better to just let the outer catch block catch the exception since you're rethrowing it anyways. And then we can log there.", "author": "ChinmaySKulkarni", "createdAt": "2020-12-18T00:21:49Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/workload/mt/tenantoperation/TenantOperationFactory.java", "diffHunk": "@@ -0,0 +1,501 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.phoenix.pherf.workload.mt.tenantoperation;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Charsets;\n+import com.google.common.base.Function;\n+import com.google.common.collect.Lists;\n+import com.google.common.hash.BloomFilter;\n+import com.google.common.hash.Funnel;\n+import com.google.common.hash.PrimitiveSink;\n+import org.apache.phoenix.pherf.configuration.Column;\n+import org.apache.phoenix.pherf.configuration.DataModel;\n+import org.apache.phoenix.pherf.configuration.Ddl;\n+import org.apache.phoenix.pherf.configuration.LoadProfile;\n+import org.apache.phoenix.pherf.configuration.Noop;\n+import org.apache.phoenix.pherf.configuration.Query;\n+import org.apache.phoenix.pherf.configuration.QuerySet;\n+import org.apache.phoenix.pherf.configuration.Scenario;\n+import org.apache.phoenix.pherf.configuration.TenantGroup;\n+import org.apache.phoenix.pherf.configuration.Upsert;\n+import org.apache.phoenix.pherf.configuration.UserDefined;\n+import org.apache.phoenix.pherf.configuration.XMLConfigParser;\n+import org.apache.phoenix.pherf.rules.DataValue;\n+import org.apache.phoenix.pherf.rules.RulesApplier;\n+import org.apache.phoenix.pherf.util.PhoenixUtil;\n+import org.apache.phoenix.pherf.workload.mt.EventGenerator;\n+import org.apache.phoenix.pherf.workload.mt.NoopOperation;\n+import org.apache.phoenix.pherf.workload.mt.Operation;\n+import org.apache.phoenix.pherf.workload.mt.OperationStats;\n+import org.apache.phoenix.pherf.workload.mt.PreScenarioOperation;\n+import org.apache.phoenix.pherf.workload.mt.QueryOperation;\n+import org.apache.phoenix.pherf.workload.mt.UpsertOperation;\n+import org.apache.phoenix.pherf.workload.mt.UserDefinedOperation;\n+import org.apache.phoenix.util.EnvironmentEdgeManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.math.BigDecimal;\n+import java.sql.Array;\n+import java.sql.Connection;\n+import java.sql.Date;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.text.SimpleDateFormat;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * Factory class for operations.\n+ * The class is responsible for creating new instances of various operation types.\n+ * Operations typically implement @see {@link TenantOperationImpl}\n+ * Operations that need to be executed are generated\n+ * by @see {@link EventGenerator}\n+ */\n+public class TenantOperationFactory {\n+\n+    private static class TenantView {\n+        private final String tenantId;\n+        private final String viewName;\n+\n+        public TenantView(String tenantId, String viewName) {\n+            this.tenantId = tenantId;\n+            this.viewName = viewName;\n+        }\n+\n+        public String getTenantId() {\n+            return tenantId;\n+        }\n+\n+        public String getViewName() {\n+            return viewName;\n+        }\n+    }\n+    private static final Logger LOGGER = LoggerFactory.getLogger(TenantOperationFactory.class);\n+    private final PhoenixUtil phoenixUtil;\n+    private final DataModel model;\n+    private final Scenario scenario;\n+    private final XMLConfigParser parser;\n+\n+    private final RulesApplier rulesApplier;\n+    private final LoadProfile loadProfile;\n+    private final List<Operation> operationList = Lists.newArrayList();\n+\n+    private final BloomFilter<TenantView> tenantsLoaded;\n+\n+    public TenantOperationFactory(PhoenixUtil phoenixUtil, DataModel model, Scenario scenario) {\n+        this.phoenixUtil = phoenixUtil;\n+        this.model = model;\n+        this.scenario = scenario;\n+        this.parser = null;\n+        this.rulesApplier = new RulesApplier(model);\n+        this.loadProfile = this.scenario.getLoadProfile();\n+        Funnel<TenantView> tenantViewFunnel = new Funnel<TenantView>() {\n+            @Override\n+            public void funnel(TenantView tenantView, PrimitiveSink into) {\n+                into.putString(tenantView.getTenantId(), Charsets.UTF_8)\n+                        .putString(tenantView.getViewName(), Charsets.UTF_8);\n+            }\n+        };\n+\n+        int numTenants = 0;\n+        for (TenantGroup tg : loadProfile.getTenantDistribution()) {\n+            numTenants += tg.getNumTenants();\n+        }\n+\n+        // This holds the info whether the tenant view was created (initialized) or not.\n+        tenantsLoaded = BloomFilter.create(tenantViewFunnel, numTenants, 0.01);\n+\n+        // Read the scenario definition and load the various operations.\n+        for (final Noop noOp : scenario.getNoop()) {\n+            Operation noopOperation = new NoopOperation() {\n+                @Override public Noop getNoop() {\n+                    return noOp;\n+                }\n+                @Override public String getId() {\n+                    return noOp.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.NO_OP;\n+                }\n+            };\n+            operationList.add(noopOperation);\n+        }\n+\n+        for (final Upsert upsert : scenario.getUpsert()) {\n+            Operation upsertOp = new UpsertOperation() {\n+                @Override public Upsert getUpsert() {\n+                    return upsert;\n+                }\n+\n+                @Override public String getId() {\n+                    return upsert.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.UPSERT;\n+                }\n+            };\n+            operationList.add(upsertOp);\n+        }\n+        for (final QuerySet querySet : scenario.getQuerySet()) {\n+            for (final Query query : querySet.getQuery()) {\n+                Operation queryOp = new QueryOperation() {\n+                    @Override public Query getQuery() {\n+                        return query;\n+                    }\n+\n+                    @Override public String getId() {\n+                        return query.getId();\n+                    }\n+\n+                    @Override public OperationType getType() {\n+                        return OperationType.SELECT;\n+                    }\n+                };\n+                operationList.add(queryOp);\n+            }\n+        }\n+\n+        for (final UserDefined udf : scenario.getUdf()) {\n+            Operation udfOperation = new UserDefinedOperation() {\n+                @Override public UserDefined getUserFunction() {\n+                    return udf;\n+                }\n+\n+                @Override public String getId() {\n+                    return udf.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.USER_DEFINED;\n+                }\n+            };\n+            operationList.add(udfOperation);\n+        }\n+    }\n+\n+    public PhoenixUtil getPhoenixUtil() {\n+        return phoenixUtil;\n+    }\n+\n+    public DataModel getModel() {\n+        return model;\n+    }\n+\n+    public Scenario getScenario() {\n+        return scenario;\n+    }\n+\n+    public List<Operation> getOperationsForScenario() {\n+        return operationList;\n+    }\n+\n+    public TenantOperationImpl getOperation(final TenantOperationInfo input) {\n+        TenantView tenantView = new TenantView(input.getTenantId(), scenario.getTableName());\n+\n+        // Check if pre run ddls are needed.\n+        if (!tenantsLoaded.mightContain(tenantView)) {\n+            // Initialize the tenant using the pre scenario ddls.\n+            final PreScenarioOperation operation = new PreScenarioOperation() {\n+                @Override public List<Ddl> getPreScenarioDdls() {\n+                    List<Ddl> ddls = scenario.getPreScenarioDdls();\n+                    return ddls == null ? Lists.<Ddl>newArrayList() : ddls;\n+                }\n+\n+                @Override public String getId() {\n+                    return OperationType.PRE_RUN.name();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.PRE_RUN;\n+                }\n+            };\n+            // Initialize with the pre run operation.\n+            TenantOperationInfo preRunSample = new TenantOperationInfo(\n+                    input.getModelName(),\n+                    input.getScenarioName(),\n+                    input.getTableName(),\n+                    input.getTenantGroupId(),\n+                    Operation.OperationType.PRE_RUN.name(),\n+                    input.getTenantId(), operation);\n+\n+            TenantOperationImpl impl = new PreScenarioTenantOperationImpl();\n+            try {\n+                // Run the initialization operation.\n+                OperationStats stats = impl.getMethod().apply(preRunSample);\n+                LOGGER.info(phoenixUtil.getGSON().toJson(stats));\n+            } catch (Exception e) {\n+                LOGGER.error(\n+                        String.format(\"Failed to initialize tenant. [%s, %s] \",\n+                                tenantView.tenantId,\n+                                tenantView.viewName\n+                        ), e.fillInStackTrace());\n+            }\n+            tenantsLoaded.put(tenantView);\n+        }\n+\n+        switch (input.getOperation().getType()) {\n+        case NO_OP:\n+            return new NoopTenantOperationImpl();\n+        case SELECT:\n+            return new QueryTenantOperationImpl();\n+        case UPSERT:\n+            return new UpsertTenantOperationImpl();\n+        case USER_DEFINED:\n+            return new UserDefinedOperationImpl();\n+        default:\n+            throw new IllegalArgumentException(\"Unknown operation type\");\n+        }\n+    }\n+\n+    class QueryTenantOperationImpl implements TenantOperationImpl {\n+\n+        @Override public Function<TenantOperationInfo, OperationStats> getMethod() {\n+            return new Function<TenantOperationInfo, OperationStats>() {\n+\n+                @Nullable @Override public OperationStats apply(@Nullable TenantOperationInfo input) {\n+                    final QueryOperation operation = (QueryOperation) input.getOperation();\n+                    final String tenantGroup = input.getTenantGroupId();\n+                    final String opGroup = input.getOperationGroupId();\n+                    final String tenantId = input.getTenantId();\n+                    final String scenarioName = input.getScenarioName();\n+                    final String tableName = input.getTableName();\n+                    final Query query = operation.getQuery();\n+                    final long opCounter = 1;\n+\n+                    String opName = String.format(\"%s:%s:%s:%s:%s\", scenarioName, tableName,\n+                            opGroup, tenantGroup, tenantId);\n+                    LOGGER.info(\"\\nExecuting query \" + query.getStatement());\n+                    // TODO add explain plan output to the stats.\n+\n+                    Connection conn = null;\n+                    PreparedStatement statement = null;\n+                    ResultSet rs = null;\n+                    Long startTime = EnvironmentEdgeManager.currentTimeMillis();\n+                    Long resultRowCount = 0L;\n+                    Long queryElapsedTime = 0L;\n+                    String queryIteration = opName + \":\" + opCounter;\n+                    try {\n+                        conn = phoenixUtil.getConnection(tenantId);\n+                        conn.setAutoCommit(true);\n+                        // TODO dynamic statements\n+                        //final String statementString = query.getDynamicStatement(rulesApplier, scenario);\n+                        statement = conn.prepareStatement(query.getStatement());\n+                        boolean isQuery = statement.execute();\n+                        if (isQuery) {\n+                            rs = statement.getResultSet();\n+                            boolean isSelectCountStatement = query.getStatement().toUpperCase().trim().contains(\"COUNT(\") ? true : false;\n+                            org.apache.hadoop.hbase.util.Pair<Long, Long>\n+                                    r = phoenixUtil.getResults(query, rs, queryIteration, isSelectCountStatement, startTime);\n+                            resultRowCount = r.getFirst();\n+                            queryElapsedTime = r.getSecond();\n+                        } else {\n+                            conn.commit();\n+                        }\n+                    } catch (Exception e) {\n+                        LOGGER.error(\"Exception while executing query iteration \" + queryIteration, e);\n+                    } finally {\n+                        try {\n+                            if (rs != null) rs.close();\n+                            if (statement != null) statement.close();\n+                            if (conn != null) conn.close();\n+\n+                        } catch (Throwable t) {\n+                            // swallow;\n+                        }\n+                    }\n+                    return new OperationStats(input, startTime, 0, resultRowCount, queryElapsedTime);\n+                }\n+            };\n+        }\n+    }\n+\n+    class UpsertTenantOperationImpl implements TenantOperationImpl {\n+\n+        @Override public Function<TenantOperationInfo, OperationStats> getMethod() {\n+            return new Function<TenantOperationInfo, OperationStats>() {\n+\n+                @Nullable @Override public OperationStats apply(@Nullable TenantOperationInfo input) {\n+\n+                    final int batchSize = loadProfile.getBatchSize();\n+                    final boolean useBatchApi = batchSize != 0;\n+                    final int rowCount = useBatchApi ? batchSize : 1;\n+\n+                    final UpsertOperation operation = (UpsertOperation) input.getOperation();\n+                    final String tenantGroup = input.getTenantGroupId();\n+                    final String opGroup = input.getOperationGroupId();\n+                    final String tenantId = input.getTenantId();\n+                    final Upsert upsert = operation.getUpsert();\n+                    final String tableName = input.getTableName();\n+                    final String scenarioName = input.getScenarioName();\n+                    final List<Column> columns = upsert.getColumn();\n+\n+                    final String opName = String.format(\"%s:%s:%s:%s:%s\",\n+                            scenarioName, tableName, opGroup, tenantGroup, tenantId);\n+\n+                    long rowsCreated = 0;\n+                    long startTime = 0, duration, totalDuration;\n+                    SimpleDateFormat simpleDateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");\n+                    try (Connection connection = phoenixUtil.getConnection(tenantId)) {\n+                        connection.setAutoCommit(true);\n+                        startTime = EnvironmentEdgeManager.currentTimeMillis();\n+                        String sql = phoenixUtil.buildSql(columns, tableName);\n+                        PreparedStatement stmt = null;\n+                        try {\n+                            stmt = connection.prepareStatement(sql);\n+                            for (long i = rowCount; i > 0; i--) {\n+                                LOGGER.debug(\"Operation \" + opName + \" executing \");\n+                                stmt = phoenixUtil.buildStatement(rulesApplier, scenario, columns, stmt, simpleDateFormat);\n+                                if (useBatchApi) {\n+                                    stmt.addBatch();\n+                                } else {\n+                                    rowsCreated += stmt.executeUpdate();\n+                                }\n+                            }\n+                        } catch (SQLException e) {\n+                            LOGGER.error(\"Operation \" + opName + \" failed with exception \", e);", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5MjI2NQ==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545492265", "bodyText": "Can you create a Jira for this and link that in the TODO so we keep track of it?", "author": "ChinmaySKulkarni", "createdAt": "2020-12-18T00:22:42Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/workload/mt/tenantoperation/TenantOperationFactory.java", "diffHunk": "@@ -0,0 +1,501 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.phoenix.pherf.workload.mt.tenantoperation;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Charsets;\n+import com.google.common.base.Function;\n+import com.google.common.collect.Lists;\n+import com.google.common.hash.BloomFilter;\n+import com.google.common.hash.Funnel;\n+import com.google.common.hash.PrimitiveSink;\n+import org.apache.phoenix.pherf.configuration.Column;\n+import org.apache.phoenix.pherf.configuration.DataModel;\n+import org.apache.phoenix.pherf.configuration.Ddl;\n+import org.apache.phoenix.pherf.configuration.LoadProfile;\n+import org.apache.phoenix.pherf.configuration.Noop;\n+import org.apache.phoenix.pherf.configuration.Query;\n+import org.apache.phoenix.pherf.configuration.QuerySet;\n+import org.apache.phoenix.pherf.configuration.Scenario;\n+import org.apache.phoenix.pherf.configuration.TenantGroup;\n+import org.apache.phoenix.pherf.configuration.Upsert;\n+import org.apache.phoenix.pherf.configuration.UserDefined;\n+import org.apache.phoenix.pherf.configuration.XMLConfigParser;\n+import org.apache.phoenix.pherf.rules.DataValue;\n+import org.apache.phoenix.pherf.rules.RulesApplier;\n+import org.apache.phoenix.pherf.util.PhoenixUtil;\n+import org.apache.phoenix.pherf.workload.mt.EventGenerator;\n+import org.apache.phoenix.pherf.workload.mt.NoopOperation;\n+import org.apache.phoenix.pherf.workload.mt.Operation;\n+import org.apache.phoenix.pherf.workload.mt.OperationStats;\n+import org.apache.phoenix.pherf.workload.mt.PreScenarioOperation;\n+import org.apache.phoenix.pherf.workload.mt.QueryOperation;\n+import org.apache.phoenix.pherf.workload.mt.UpsertOperation;\n+import org.apache.phoenix.pherf.workload.mt.UserDefinedOperation;\n+import org.apache.phoenix.util.EnvironmentEdgeManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.math.BigDecimal;\n+import java.sql.Array;\n+import java.sql.Connection;\n+import java.sql.Date;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.text.SimpleDateFormat;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * Factory class for operations.\n+ * The class is responsible for creating new instances of various operation types.\n+ * Operations typically implement @see {@link TenantOperationImpl}\n+ * Operations that need to be executed are generated\n+ * by @see {@link EventGenerator}\n+ */\n+public class TenantOperationFactory {\n+\n+    private static class TenantView {\n+        private final String tenantId;\n+        private final String viewName;\n+\n+        public TenantView(String tenantId, String viewName) {\n+            this.tenantId = tenantId;\n+            this.viewName = viewName;\n+        }\n+\n+        public String getTenantId() {\n+            return tenantId;\n+        }\n+\n+        public String getViewName() {\n+            return viewName;\n+        }\n+    }\n+    private static final Logger LOGGER = LoggerFactory.getLogger(TenantOperationFactory.class);\n+    private final PhoenixUtil phoenixUtil;\n+    private final DataModel model;\n+    private final Scenario scenario;\n+    private final XMLConfigParser parser;\n+\n+    private final RulesApplier rulesApplier;\n+    private final LoadProfile loadProfile;\n+    private final List<Operation> operationList = Lists.newArrayList();\n+\n+    private final BloomFilter<TenantView> tenantsLoaded;\n+\n+    public TenantOperationFactory(PhoenixUtil phoenixUtil, DataModel model, Scenario scenario) {\n+        this.phoenixUtil = phoenixUtil;\n+        this.model = model;\n+        this.scenario = scenario;\n+        this.parser = null;\n+        this.rulesApplier = new RulesApplier(model);\n+        this.loadProfile = this.scenario.getLoadProfile();\n+        Funnel<TenantView> tenantViewFunnel = new Funnel<TenantView>() {\n+            @Override\n+            public void funnel(TenantView tenantView, PrimitiveSink into) {\n+                into.putString(tenantView.getTenantId(), Charsets.UTF_8)\n+                        .putString(tenantView.getViewName(), Charsets.UTF_8);\n+            }\n+        };\n+\n+        int numTenants = 0;\n+        for (TenantGroup tg : loadProfile.getTenantDistribution()) {\n+            numTenants += tg.getNumTenants();\n+        }\n+\n+        // This holds the info whether the tenant view was created (initialized) or not.\n+        tenantsLoaded = BloomFilter.create(tenantViewFunnel, numTenants, 0.01);\n+\n+        // Read the scenario definition and load the various operations.\n+        for (final Noop noOp : scenario.getNoop()) {\n+            Operation noopOperation = new NoopOperation() {\n+                @Override public Noop getNoop() {\n+                    return noOp;\n+                }\n+                @Override public String getId() {\n+                    return noOp.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.NO_OP;\n+                }\n+            };\n+            operationList.add(noopOperation);\n+        }\n+\n+        for (final Upsert upsert : scenario.getUpsert()) {\n+            Operation upsertOp = new UpsertOperation() {\n+                @Override public Upsert getUpsert() {\n+                    return upsert;\n+                }\n+\n+                @Override public String getId() {\n+                    return upsert.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.UPSERT;\n+                }\n+            };\n+            operationList.add(upsertOp);\n+        }\n+        for (final QuerySet querySet : scenario.getQuerySet()) {\n+            for (final Query query : querySet.getQuery()) {\n+                Operation queryOp = new QueryOperation() {\n+                    @Override public Query getQuery() {\n+                        return query;\n+                    }\n+\n+                    @Override public String getId() {\n+                        return query.getId();\n+                    }\n+\n+                    @Override public OperationType getType() {\n+                        return OperationType.SELECT;\n+                    }\n+                };\n+                operationList.add(queryOp);\n+            }\n+        }\n+\n+        for (final UserDefined udf : scenario.getUdf()) {\n+            Operation udfOperation = new UserDefinedOperation() {\n+                @Override public UserDefined getUserFunction() {\n+                    return udf;\n+                }\n+\n+                @Override public String getId() {\n+                    return udf.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.USER_DEFINED;\n+                }\n+            };\n+            operationList.add(udfOperation);\n+        }\n+    }\n+\n+    public PhoenixUtil getPhoenixUtil() {\n+        return phoenixUtil;\n+    }\n+\n+    public DataModel getModel() {\n+        return model;\n+    }\n+\n+    public Scenario getScenario() {\n+        return scenario;\n+    }\n+\n+    public List<Operation> getOperationsForScenario() {\n+        return operationList;\n+    }\n+\n+    public TenantOperationImpl getOperation(final TenantOperationInfo input) {\n+        TenantView tenantView = new TenantView(input.getTenantId(), scenario.getTableName());\n+\n+        // Check if pre run ddls are needed.\n+        if (!tenantsLoaded.mightContain(tenantView)) {\n+            // Initialize the tenant using the pre scenario ddls.\n+            final PreScenarioOperation operation = new PreScenarioOperation() {\n+                @Override public List<Ddl> getPreScenarioDdls() {\n+                    List<Ddl> ddls = scenario.getPreScenarioDdls();\n+                    return ddls == null ? Lists.<Ddl>newArrayList() : ddls;\n+                }\n+\n+                @Override public String getId() {\n+                    return OperationType.PRE_RUN.name();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.PRE_RUN;\n+                }\n+            };\n+            // Initialize with the pre run operation.\n+            TenantOperationInfo preRunSample = new TenantOperationInfo(\n+                    input.getModelName(),\n+                    input.getScenarioName(),\n+                    input.getTableName(),\n+                    input.getTenantGroupId(),\n+                    Operation.OperationType.PRE_RUN.name(),\n+                    input.getTenantId(), operation);\n+\n+            TenantOperationImpl impl = new PreScenarioTenantOperationImpl();\n+            try {\n+                // Run the initialization operation.\n+                OperationStats stats = impl.getMethod().apply(preRunSample);\n+                LOGGER.info(phoenixUtil.getGSON().toJson(stats));\n+            } catch (Exception e) {\n+                LOGGER.error(\n+                        String.format(\"Failed to initialize tenant. [%s, %s] \",\n+                                tenantView.tenantId,\n+                                tenantView.viewName\n+                        ), e.fillInStackTrace());\n+            }\n+            tenantsLoaded.put(tenantView);\n+        }\n+\n+        switch (input.getOperation().getType()) {\n+        case NO_OP:\n+            return new NoopTenantOperationImpl();\n+        case SELECT:\n+            return new QueryTenantOperationImpl();\n+        case UPSERT:\n+            return new UpsertTenantOperationImpl();\n+        case USER_DEFINED:\n+            return new UserDefinedOperationImpl();\n+        default:\n+            throw new IllegalArgumentException(\"Unknown operation type\");\n+        }\n+    }\n+\n+    class QueryTenantOperationImpl implements TenantOperationImpl {\n+\n+        @Override public Function<TenantOperationInfo, OperationStats> getMethod() {\n+            return new Function<TenantOperationInfo, OperationStats>() {\n+\n+                @Nullable @Override public OperationStats apply(@Nullable TenantOperationInfo input) {\n+                    final QueryOperation operation = (QueryOperation) input.getOperation();\n+                    final String tenantGroup = input.getTenantGroupId();\n+                    final String opGroup = input.getOperationGroupId();\n+                    final String tenantId = input.getTenantId();\n+                    final String scenarioName = input.getScenarioName();\n+                    final String tableName = input.getTableName();\n+                    final Query query = operation.getQuery();\n+                    final long opCounter = 1;\n+\n+                    String opName = String.format(\"%s:%s:%s:%s:%s\", scenarioName, tableName,\n+                            opGroup, tenantGroup, tenantId);\n+                    LOGGER.info(\"\\nExecuting query \" + query.getStatement());\n+                    // TODO add explain plan output to the stats.\n+\n+                    Connection conn = null;\n+                    PreparedStatement statement = null;\n+                    ResultSet rs = null;\n+                    Long startTime = EnvironmentEdgeManager.currentTimeMillis();\n+                    Long resultRowCount = 0L;\n+                    Long queryElapsedTime = 0L;\n+                    String queryIteration = opName + \":\" + opCounter;\n+                    try {\n+                        conn = phoenixUtil.getConnection(tenantId);\n+                        conn.setAutoCommit(true);\n+                        // TODO dynamic statements\n+                        //final String statementString = query.getDynamicStatement(rulesApplier, scenario);\n+                        statement = conn.prepareStatement(query.getStatement());\n+                        boolean isQuery = statement.execute();\n+                        if (isQuery) {\n+                            rs = statement.getResultSet();\n+                            boolean isSelectCountStatement = query.getStatement().toUpperCase().trim().contains(\"COUNT(\") ? true : false;\n+                            org.apache.hadoop.hbase.util.Pair<Long, Long>\n+                                    r = phoenixUtil.getResults(query, rs, queryIteration, isSelectCountStatement, startTime);\n+                            resultRowCount = r.getFirst();\n+                            queryElapsedTime = r.getSecond();\n+                        } else {\n+                            conn.commit();\n+                        }\n+                    } catch (Exception e) {\n+                        LOGGER.error(\"Exception while executing query iteration \" + queryIteration, e);\n+                    } finally {\n+                        try {\n+                            if (rs != null) rs.close();\n+                            if (statement != null) statement.close();\n+                            if (conn != null) conn.close();\n+\n+                        } catch (Throwable t) {\n+                            // swallow;\n+                        }\n+                    }\n+                    return new OperationStats(input, startTime, 0, resultRowCount, queryElapsedTime);\n+                }\n+            };\n+        }\n+    }\n+\n+    class UpsertTenantOperationImpl implements TenantOperationImpl {\n+\n+        @Override public Function<TenantOperationInfo, OperationStats> getMethod() {\n+            return new Function<TenantOperationInfo, OperationStats>() {\n+\n+                @Nullable @Override public OperationStats apply(@Nullable TenantOperationInfo input) {\n+\n+                    final int batchSize = loadProfile.getBatchSize();\n+                    final boolean useBatchApi = batchSize != 0;\n+                    final int rowCount = useBatchApi ? batchSize : 1;\n+\n+                    final UpsertOperation operation = (UpsertOperation) input.getOperation();\n+                    final String tenantGroup = input.getTenantGroupId();\n+                    final String opGroup = input.getOperationGroupId();\n+                    final String tenantId = input.getTenantId();\n+                    final Upsert upsert = operation.getUpsert();\n+                    final String tableName = input.getTableName();\n+                    final String scenarioName = input.getScenarioName();\n+                    final List<Column> columns = upsert.getColumn();\n+\n+                    final String opName = String.format(\"%s:%s:%s:%s:%s\",\n+                            scenarioName, tableName, opGroup, tenantGroup, tenantId);\n+\n+                    long rowsCreated = 0;\n+                    long startTime = 0, duration, totalDuration;\n+                    SimpleDateFormat simpleDateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");\n+                    try (Connection connection = phoenixUtil.getConnection(tenantId)) {\n+                        connection.setAutoCommit(true);\n+                        startTime = EnvironmentEdgeManager.currentTimeMillis();\n+                        String sql = phoenixUtil.buildSql(columns, tableName);\n+                        PreparedStatement stmt = null;\n+                        try {\n+                            stmt = connection.prepareStatement(sql);\n+                            for (long i = rowCount; i > 0; i--) {\n+                                LOGGER.debug(\"Operation \" + opName + \" executing \");\n+                                stmt = phoenixUtil.buildStatement(rulesApplier, scenario, columns, stmt, simpleDateFormat);\n+                                if (useBatchApi) {\n+                                    stmt.addBatch();\n+                                } else {\n+                                    rowsCreated += stmt.executeUpdate();\n+                                }\n+                            }\n+                        } catch (SQLException e) {\n+                            LOGGER.error(\"Operation \" + opName + \" failed with exception \", e);\n+                            throw e;\n+                        } finally {\n+                            // Need to keep the statement open to send the remaining batch of updates\n+                            if (!useBatchApi && stmt != null) {\n+                                stmt.close();\n+                            }\n+                            if (connection != null) {\n+                                if (useBatchApi && stmt != null) {\n+                                    int[] results = stmt.executeBatch();\n+                                    for (int x = 0; x < results.length; x++) {\n+                                        int result = results[x];\n+                                        if (result < 1) {\n+                                            final String msg =\n+                                                    \"Failed to write update in batch (update count=\"\n+                                                            + result + \")\";\n+                                            throw new RuntimeException(msg);\n+                                        }\n+                                        rowsCreated += result;\n+                                    }\n+                                    // Close the statement after our last batch execution.\n+                                    stmt.close();\n+                                }\n+\n+                                try {\n+                                    connection.commit();\n+                                    duration = EnvironmentEdgeManager.currentTimeMillis() - startTime;\n+                                    LOGGER.info(\"Writer ( \" + Thread.currentThread().getName()\n+                                            + \") committed Final Batch. Duration (\" + duration + \") Ms\");\n+                                    connection.close();\n+                                } catch (SQLException e) {\n+                                    // Swallow since we are closing anyway\n+                                    e.printStackTrace();\n+                                }\n+                            }\n+                        }\n+                    } catch (SQLException throwables) {\n+                        throw new RuntimeException(throwables);\n+                    } catch (Exception e) {\n+                        throw new RuntimeException(e);\n+                    }\n+\n+                    totalDuration = EnvironmentEdgeManager.currentTimeMillis() - startTime;\n+                    return new OperationStats(input, startTime, 0, rowsCreated, totalDuration);\n+                }\n+            };\n+        }\n+    }\n+\n+    class PreScenarioTenantOperationImpl implements TenantOperationImpl {\n+\n+        @Override public Function<TenantOperationInfo, OperationStats> getMethod() {\n+            return new Function<TenantOperationInfo, OperationStats>() {\n+                @Override public OperationStats apply(final TenantOperationInfo input) {\n+                    final PreScenarioOperation operation = (PreScenarioOperation) input.getOperation();\n+                    final String tenantId = input.getTenantId();\n+                    final String tableName = scenario.getTableName();\n+\n+                    long startTime = EnvironmentEdgeManager.currentTimeMillis();\n+                    if (!operation.getPreScenarioDdls().isEmpty()) {\n+                        try (Connection conn = phoenixUtil.getConnection(tenantId)) {\n+                            for (Ddl ddl : scenario.getPreScenarioDdls()) {\n+                                LOGGER.info(\"\\nExecuting DDL:\" + ddl + \" on tenantId:\" + tenantId);\n+                                phoenixUtil.executeStatement(ddl.toString(), conn);\n+                                if (ddl.getStatement().toUpperCase().contains(phoenixUtil.ASYNC_KEYWORD)) {\n+                                    phoenixUtil.waitForAsyncIndexToFinish(ddl.getTableName());\n+                                }\n+                            }\n+                        } catch (SQLException throwables) {\n+                            throw new RuntimeException(throwables);\n+                        } catch (Exception e) {\n+                            throw new RuntimeException(e);\n+                        }\n+                    }\n+                    long totalDuration = EnvironmentEdgeManager.currentTimeMillis() - startTime;\n+                    return new OperationStats(input, startTime,0, operation.getPreScenarioDdls().size(), totalDuration);\n+\n+                }\n+            };\n+        }\n+    }\n+\n+    @VisibleForTesting\n+    class NoopTenantOperationImpl implements TenantOperationImpl {\n+\n+        @Override public Function<TenantOperationInfo, OperationStats> getMethod() {\n+            return new Function<TenantOperationInfo, OperationStats>() {\n+                @Override public OperationStats apply(final TenantOperationInfo input) {\n+\n+                    final NoopOperation operation = (NoopOperation) input.getOperation();\n+                    final Noop noop = operation.getNoop();\n+\n+                    long startTime = EnvironmentEdgeManager.currentTimeMillis();\n+                    // Sleep for the specified time to simulate idle time.\n+                    try {\n+                        TimeUnit.MILLISECONDS.sleep(noop.getIdleTime());\n+                        long duration = EnvironmentEdgeManager.currentTimeMillis() - startTime;\n+                        return new OperationStats(input, startTime, 0, 0, duration);\n+                    } catch (InterruptedException e) {\n+                        e.printStackTrace();\n+                        long duration = EnvironmentEdgeManager.currentTimeMillis() - startTime;\n+                        return new OperationStats(input, startTime,-1, 0, duration);\n+                    }\n+                }\n+            };\n+        }\n+    }\n+\n+    class UserDefinedOperationImpl implements TenantOperationImpl {\n+\n+        @Override public Function<TenantOperationInfo, OperationStats> getMethod() {\n+            return new Function<TenantOperationInfo, OperationStats>() {\n+                @Override public OperationStats apply(final TenantOperationInfo input) {\n+                    // TODO : implement user defined operation invocation.", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5MjYwMg==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545492602", "bodyText": "nit: Interface name probably shouldn't end with Impl", "author": "ChinmaySKulkarni", "createdAt": "2020-12-18T00:23:45Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/workload/mt/tenantoperation/TenantOperationImpl.java", "diffHunk": "@@ -0,0 +1,33 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.phoenix.pherf.workload.mt.tenantoperation;\n+\n+import com.google.common.base.Function;\n+import org.apache.phoenix.pherf.workload.mt.OperationStats;\n+\n+/**\n+ * An interface that implementers can use to provide a function that takes\n+ * @see {@link TenantOperationInfo} as an input and gives @see {@link OperationStats} as output.\n+ * This @see {@link Function} will invoked by the\n+ * @see {@link TenantOperationWorkHandler#onEvent(TenantOperationWorkload.TenantOperationEvent)}\n+ * when handling the events.\n+ */\n+public interface TenantOperationImpl {", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5Mjc4OQ==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545492789", "bodyText": "TODO", "author": "ChinmaySKulkarni", "createdAt": "2020-12-18T00:24:18Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/workload/mt/tenantoperation/TenantOperationWorkHandler.java", "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.phoenix.pherf.workload.mt.tenantoperation;\n+\n+import com.lmax.disruptor.LifecycleAware;\n+import com.lmax.disruptor.WorkHandler;\n+import org.apache.phoenix.pherf.configuration.Scenario;\n+import org.apache.phoenix.pherf.workload.mt.OperationStats;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationWorkload.TenantOperationEvent;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * TODO Documentation", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5MzQ3NQ==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545493475", "bodyText": "Shouldn't operationStats really be different per Operation? Operation is an interface whereas this is a concrete class. Each operation type might have their own stats, no? Maybe make this an abstract class instead and have each operation type implement their own stats which extend this?", "author": "ChinmaySKulkarni", "createdAt": "2020-12-18T00:26:16Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/workload/mt/OperationStats.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.phoenix.pherf.workload.mt;\n+\n+import org.apache.phoenix.pherf.result.ResultValue;\n+import org.apache.phoenix.pherf.workload.mt.tenantoperation.TenantOperationInfo;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * Holds metrics + contextual info on the operation run.\n+ */\n+public class OperationStats {", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5NjkxOQ==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545496919", "bodyText": "log instead", "author": "ChinmaySKulkarni", "createdAt": "2020-12-18T00:36:44Z", "path": "phoenix-pherf/src/main/java/org/apache/phoenix/pherf/workload/mt/tenantoperation/TenantOperationFactory.java", "diffHunk": "@@ -0,0 +1,501 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.phoenix.pherf.workload.mt.tenantoperation;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Charsets;\n+import com.google.common.base.Function;\n+import com.google.common.collect.Lists;\n+import com.google.common.hash.BloomFilter;\n+import com.google.common.hash.Funnel;\n+import com.google.common.hash.PrimitiveSink;\n+import org.apache.phoenix.pherf.configuration.Column;\n+import org.apache.phoenix.pherf.configuration.DataModel;\n+import org.apache.phoenix.pherf.configuration.Ddl;\n+import org.apache.phoenix.pherf.configuration.LoadProfile;\n+import org.apache.phoenix.pherf.configuration.Noop;\n+import org.apache.phoenix.pherf.configuration.Query;\n+import org.apache.phoenix.pherf.configuration.QuerySet;\n+import org.apache.phoenix.pherf.configuration.Scenario;\n+import org.apache.phoenix.pherf.configuration.TenantGroup;\n+import org.apache.phoenix.pherf.configuration.Upsert;\n+import org.apache.phoenix.pherf.configuration.UserDefined;\n+import org.apache.phoenix.pherf.configuration.XMLConfigParser;\n+import org.apache.phoenix.pherf.rules.DataValue;\n+import org.apache.phoenix.pherf.rules.RulesApplier;\n+import org.apache.phoenix.pherf.util.PhoenixUtil;\n+import org.apache.phoenix.pherf.workload.mt.EventGenerator;\n+import org.apache.phoenix.pherf.workload.mt.NoopOperation;\n+import org.apache.phoenix.pherf.workload.mt.Operation;\n+import org.apache.phoenix.pherf.workload.mt.OperationStats;\n+import org.apache.phoenix.pherf.workload.mt.PreScenarioOperation;\n+import org.apache.phoenix.pherf.workload.mt.QueryOperation;\n+import org.apache.phoenix.pherf.workload.mt.UpsertOperation;\n+import org.apache.phoenix.pherf.workload.mt.UserDefinedOperation;\n+import org.apache.phoenix.util.EnvironmentEdgeManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.math.BigDecimal;\n+import java.sql.Array;\n+import java.sql.Connection;\n+import java.sql.Date;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Types;\n+import java.text.SimpleDateFormat;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * Factory class for operations.\n+ * The class is responsible for creating new instances of various operation types.\n+ * Operations typically implement @see {@link TenantOperationImpl}\n+ * Operations that need to be executed are generated\n+ * by @see {@link EventGenerator}\n+ */\n+public class TenantOperationFactory {\n+\n+    private static class TenantView {\n+        private final String tenantId;\n+        private final String viewName;\n+\n+        public TenantView(String tenantId, String viewName) {\n+            this.tenantId = tenantId;\n+            this.viewName = viewName;\n+        }\n+\n+        public String getTenantId() {\n+            return tenantId;\n+        }\n+\n+        public String getViewName() {\n+            return viewName;\n+        }\n+    }\n+    private static final Logger LOGGER = LoggerFactory.getLogger(TenantOperationFactory.class);\n+    private final PhoenixUtil phoenixUtil;\n+    private final DataModel model;\n+    private final Scenario scenario;\n+    private final XMLConfigParser parser;\n+\n+    private final RulesApplier rulesApplier;\n+    private final LoadProfile loadProfile;\n+    private final List<Operation> operationList = Lists.newArrayList();\n+\n+    private final BloomFilter<TenantView> tenantsLoaded;\n+\n+    public TenantOperationFactory(PhoenixUtil phoenixUtil, DataModel model, Scenario scenario) {\n+        this.phoenixUtil = phoenixUtil;\n+        this.model = model;\n+        this.scenario = scenario;\n+        this.parser = null;\n+        this.rulesApplier = new RulesApplier(model);\n+        this.loadProfile = this.scenario.getLoadProfile();\n+        Funnel<TenantView> tenantViewFunnel = new Funnel<TenantView>() {\n+            @Override\n+            public void funnel(TenantView tenantView, PrimitiveSink into) {\n+                into.putString(tenantView.getTenantId(), Charsets.UTF_8)\n+                        .putString(tenantView.getViewName(), Charsets.UTF_8);\n+            }\n+        };\n+\n+        int numTenants = 0;\n+        for (TenantGroup tg : loadProfile.getTenantDistribution()) {\n+            numTenants += tg.getNumTenants();\n+        }\n+\n+        // This holds the info whether the tenant view was created (initialized) or not.\n+        tenantsLoaded = BloomFilter.create(tenantViewFunnel, numTenants, 0.01);\n+\n+        // Read the scenario definition and load the various operations.\n+        for (final Noop noOp : scenario.getNoop()) {\n+            Operation noopOperation = new NoopOperation() {\n+                @Override public Noop getNoop() {\n+                    return noOp;\n+                }\n+                @Override public String getId() {\n+                    return noOp.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.NO_OP;\n+                }\n+            };\n+            operationList.add(noopOperation);\n+        }\n+\n+        for (final Upsert upsert : scenario.getUpsert()) {\n+            Operation upsertOp = new UpsertOperation() {\n+                @Override public Upsert getUpsert() {\n+                    return upsert;\n+                }\n+\n+                @Override public String getId() {\n+                    return upsert.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.UPSERT;\n+                }\n+            };\n+            operationList.add(upsertOp);\n+        }\n+        for (final QuerySet querySet : scenario.getQuerySet()) {\n+            for (final Query query : querySet.getQuery()) {\n+                Operation queryOp = new QueryOperation() {\n+                    @Override public Query getQuery() {\n+                        return query;\n+                    }\n+\n+                    @Override public String getId() {\n+                        return query.getId();\n+                    }\n+\n+                    @Override public OperationType getType() {\n+                        return OperationType.SELECT;\n+                    }\n+                };\n+                operationList.add(queryOp);\n+            }\n+        }\n+\n+        for (final UserDefined udf : scenario.getUdf()) {\n+            Operation udfOperation = new UserDefinedOperation() {\n+                @Override public UserDefined getUserFunction() {\n+                    return udf;\n+                }\n+\n+                @Override public String getId() {\n+                    return udf.getId();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.USER_DEFINED;\n+                }\n+            };\n+            operationList.add(udfOperation);\n+        }\n+    }\n+\n+    public PhoenixUtil getPhoenixUtil() {\n+        return phoenixUtil;\n+    }\n+\n+    public DataModel getModel() {\n+        return model;\n+    }\n+\n+    public Scenario getScenario() {\n+        return scenario;\n+    }\n+\n+    public List<Operation> getOperationsForScenario() {\n+        return operationList;\n+    }\n+\n+    public TenantOperationImpl getOperation(final TenantOperationInfo input) {\n+        TenantView tenantView = new TenantView(input.getTenantId(), scenario.getTableName());\n+\n+        // Check if pre run ddls are needed.\n+        if (!tenantsLoaded.mightContain(tenantView)) {\n+            // Initialize the tenant using the pre scenario ddls.\n+            final PreScenarioOperation operation = new PreScenarioOperation() {\n+                @Override public List<Ddl> getPreScenarioDdls() {\n+                    List<Ddl> ddls = scenario.getPreScenarioDdls();\n+                    return ddls == null ? Lists.<Ddl>newArrayList() : ddls;\n+                }\n+\n+                @Override public String getId() {\n+                    return OperationType.PRE_RUN.name();\n+                }\n+\n+                @Override public OperationType getType() {\n+                    return OperationType.PRE_RUN;\n+                }\n+            };\n+            // Initialize with the pre run operation.\n+            TenantOperationInfo preRunSample = new TenantOperationInfo(\n+                    input.getModelName(),\n+                    input.getScenarioName(),\n+                    input.getTableName(),\n+                    input.getTenantGroupId(),\n+                    Operation.OperationType.PRE_RUN.name(),\n+                    input.getTenantId(), operation);\n+\n+            TenantOperationImpl impl = new PreScenarioTenantOperationImpl();\n+            try {\n+                // Run the initialization operation.\n+                OperationStats stats = impl.getMethod().apply(preRunSample);\n+                LOGGER.info(phoenixUtil.getGSON().toJson(stats));\n+            } catch (Exception e) {\n+                LOGGER.error(\n+                        String.format(\"Failed to initialize tenant. [%s, %s] \",\n+                                tenantView.tenantId,\n+                                tenantView.viewName\n+                        ), e.fillInStackTrace());\n+            }\n+            tenantsLoaded.put(tenantView);\n+        }\n+\n+        switch (input.getOperation().getType()) {\n+        case NO_OP:\n+            return new NoopTenantOperationImpl();\n+        case SELECT:\n+            return new QueryTenantOperationImpl();\n+        case UPSERT:\n+            return new UpsertTenantOperationImpl();\n+        case USER_DEFINED:\n+            return new UserDefinedOperationImpl();\n+        default:\n+            throw new IllegalArgumentException(\"Unknown operation type\");\n+        }\n+    }\n+\n+    class QueryTenantOperationImpl implements TenantOperationImpl {\n+\n+        @Override public Function<TenantOperationInfo, OperationStats> getMethod() {\n+            return new Function<TenantOperationInfo, OperationStats>() {\n+\n+                @Nullable @Override public OperationStats apply(@Nullable TenantOperationInfo input) {\n+                    final QueryOperation operation = (QueryOperation) input.getOperation();\n+                    final String tenantGroup = input.getTenantGroupId();\n+                    final String opGroup = input.getOperationGroupId();\n+                    final String tenantId = input.getTenantId();\n+                    final String scenarioName = input.getScenarioName();\n+                    final String tableName = input.getTableName();\n+                    final Query query = operation.getQuery();\n+                    final long opCounter = 1;\n+\n+                    String opName = String.format(\"%s:%s:%s:%s:%s\", scenarioName, tableName,\n+                            opGroup, tenantGroup, tenantId);\n+                    LOGGER.info(\"\\nExecuting query \" + query.getStatement());\n+                    // TODO add explain plan output to the stats.\n+\n+                    Connection conn = null;\n+                    PreparedStatement statement = null;\n+                    ResultSet rs = null;\n+                    Long startTime = EnvironmentEdgeManager.currentTimeMillis();\n+                    Long resultRowCount = 0L;\n+                    Long queryElapsedTime = 0L;\n+                    String queryIteration = opName + \":\" + opCounter;\n+                    try {\n+                        conn = phoenixUtil.getConnection(tenantId);\n+                        conn.setAutoCommit(true);\n+                        // TODO dynamic statements\n+                        //final String statementString = query.getDynamicStatement(rulesApplier, scenario);\n+                        statement = conn.prepareStatement(query.getStatement());\n+                        boolean isQuery = statement.execute();\n+                        if (isQuery) {\n+                            rs = statement.getResultSet();\n+                            boolean isSelectCountStatement = query.getStatement().toUpperCase().trim().contains(\"COUNT(\") ? true : false;\n+                            org.apache.hadoop.hbase.util.Pair<Long, Long>\n+                                    r = phoenixUtil.getResults(query, rs, queryIteration, isSelectCountStatement, startTime);\n+                            resultRowCount = r.getFirst();\n+                            queryElapsedTime = r.getSecond();\n+                        } else {\n+                            conn.commit();\n+                        }\n+                    } catch (Exception e) {\n+                        LOGGER.error(\"Exception while executing query iteration \" + queryIteration, e);\n+                    } finally {\n+                        try {\n+                            if (rs != null) rs.close();\n+                            if (statement != null) statement.close();\n+                            if (conn != null) conn.close();\n+\n+                        } catch (Throwable t) {\n+                            // swallow;\n+                        }\n+                    }\n+                    return new OperationStats(input, startTime, 0, resultRowCount, queryElapsedTime);\n+                }\n+            };\n+        }\n+    }\n+\n+    class UpsertTenantOperationImpl implements TenantOperationImpl {\n+\n+        @Override public Function<TenantOperationInfo, OperationStats> getMethod() {\n+            return new Function<TenantOperationInfo, OperationStats>() {\n+\n+                @Nullable @Override public OperationStats apply(@Nullable TenantOperationInfo input) {\n+\n+                    final int batchSize = loadProfile.getBatchSize();\n+                    final boolean useBatchApi = batchSize != 0;\n+                    final int rowCount = useBatchApi ? batchSize : 1;\n+\n+                    final UpsertOperation operation = (UpsertOperation) input.getOperation();\n+                    final String tenantGroup = input.getTenantGroupId();\n+                    final String opGroup = input.getOperationGroupId();\n+                    final String tenantId = input.getTenantId();\n+                    final Upsert upsert = operation.getUpsert();\n+                    final String tableName = input.getTableName();\n+                    final String scenarioName = input.getScenarioName();\n+                    final List<Column> columns = upsert.getColumn();\n+\n+                    final String opName = String.format(\"%s:%s:%s:%s:%s\",\n+                            scenarioName, tableName, opGroup, tenantGroup, tenantId);\n+\n+                    long rowsCreated = 0;\n+                    long startTime = 0, duration, totalDuration;\n+                    SimpleDateFormat simpleDateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");\n+                    try (Connection connection = phoenixUtil.getConnection(tenantId)) {\n+                        connection.setAutoCommit(true);\n+                        startTime = EnvironmentEdgeManager.currentTimeMillis();\n+                        String sql = phoenixUtil.buildSql(columns, tableName);\n+                        PreparedStatement stmt = null;\n+                        try {\n+                            stmt = connection.prepareStatement(sql);\n+                            for (long i = rowCount; i > 0; i--) {\n+                                LOGGER.debug(\"Operation \" + opName + \" executing \");\n+                                stmt = phoenixUtil.buildStatement(rulesApplier, scenario, columns, stmt, simpleDateFormat);\n+                                if (useBatchApi) {\n+                                    stmt.addBatch();\n+                                } else {\n+                                    rowsCreated += stmt.executeUpdate();\n+                                }\n+                            }\n+                        } catch (SQLException e) {\n+                            LOGGER.error(\"Operation \" + opName + \" failed with exception \", e);\n+                            throw e;\n+                        } finally {\n+                            // Need to keep the statement open to send the remaining batch of updates\n+                            if (!useBatchApi && stmt != null) {\n+                                stmt.close();\n+                            }\n+                            if (connection != null) {\n+                                if (useBatchApi && stmt != null) {\n+                                    int[] results = stmt.executeBatch();\n+                                    for (int x = 0; x < results.length; x++) {\n+                                        int result = results[x];\n+                                        if (result < 1) {\n+                                            final String msg =\n+                                                    \"Failed to write update in batch (update count=\"\n+                                                            + result + \")\";\n+                                            throw new RuntimeException(msg);\n+                                        }\n+                                        rowsCreated += result;\n+                                    }\n+                                    // Close the statement after our last batch execution.\n+                                    stmt.close();\n+                                }\n+\n+                                try {\n+                                    connection.commit();\n+                                    duration = EnvironmentEdgeManager.currentTimeMillis() - startTime;\n+                                    LOGGER.info(\"Writer ( \" + Thread.currentThread().getName()\n+                                            + \") committed Final Batch. Duration (\" + duration + \") Ms\");\n+                                    connection.close();\n+                                } catch (SQLException e) {\n+                                    // Swallow since we are closing anyway\n+                                    e.printStackTrace();\n+                                }\n+                            }\n+                        }\n+                    } catch (SQLException throwables) {\n+                        throw new RuntimeException(throwables);\n+                    } catch (Exception e) {\n+                        throw new RuntimeException(e);\n+                    }\n+\n+                    totalDuration = EnvironmentEdgeManager.currentTimeMillis() - startTime;\n+                    return new OperationStats(input, startTime, 0, rowsCreated, totalDuration);\n+                }\n+            };\n+        }\n+    }\n+\n+    class PreScenarioTenantOperationImpl implements TenantOperationImpl {\n+\n+        @Override public Function<TenantOperationInfo, OperationStats> getMethod() {\n+            return new Function<TenantOperationInfo, OperationStats>() {\n+                @Override public OperationStats apply(final TenantOperationInfo input) {\n+                    final PreScenarioOperation operation = (PreScenarioOperation) input.getOperation();\n+                    final String tenantId = input.getTenantId();\n+                    final String tableName = scenario.getTableName();\n+\n+                    long startTime = EnvironmentEdgeManager.currentTimeMillis();\n+                    if (!operation.getPreScenarioDdls().isEmpty()) {\n+                        try (Connection conn = phoenixUtil.getConnection(tenantId)) {\n+                            for (Ddl ddl : scenario.getPreScenarioDdls()) {\n+                                LOGGER.info(\"\\nExecuting DDL:\" + ddl + \" on tenantId:\" + tenantId);\n+                                phoenixUtil.executeStatement(ddl.toString(), conn);\n+                                if (ddl.getStatement().toUpperCase().contains(phoenixUtil.ASYNC_KEYWORD)) {\n+                                    phoenixUtil.waitForAsyncIndexToFinish(ddl.getTableName());\n+                                }\n+                            }\n+                        } catch (SQLException throwables) {\n+                            throw new RuntimeException(throwables);\n+                        } catch (Exception e) {\n+                            throw new RuntimeException(e);\n+                        }\n+                    }\n+                    long totalDuration = EnvironmentEdgeManager.currentTimeMillis() - startTime;\n+                    return new OperationStats(input, startTime,0, operation.getPreScenarioDdls().size(), totalDuration);\n+\n+                }\n+            };\n+        }\n+    }\n+\n+    @VisibleForTesting\n+    class NoopTenantOperationImpl implements TenantOperationImpl {\n+\n+        @Override public Function<TenantOperationInfo, OperationStats> getMethod() {\n+            return new Function<TenantOperationInfo, OperationStats>() {\n+                @Override public OperationStats apply(final TenantOperationInfo input) {\n+\n+                    final NoopOperation operation = (NoopOperation) input.getOperation();\n+                    final Noop noop = operation.getNoop();\n+\n+                    long startTime = EnvironmentEdgeManager.currentTimeMillis();\n+                    // Sleep for the specified time to simulate idle time.\n+                    try {\n+                        TimeUnit.MILLISECONDS.sleep(noop.getIdleTime());\n+                        long duration = EnvironmentEdgeManager.currentTimeMillis() - startTime;\n+                        return new OperationStats(input, startTime, 0, 0, duration);\n+                    } catch (InterruptedException e) {\n+                        e.printStackTrace();", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5NzUwMw==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545497503", "bodyText": "Nit: Use assertEquals() everywhere", "author": "ChinmaySKulkarni", "createdAt": "2020-12-18T00:38:25Z", "path": "phoenix-pherf/src/test/java/org/apache/phoenix/pherf/ConfigurationParserTest.java", "diffHunk": "@@ -122,22 +125,61 @@ public void testConfigReader() {\n         }\n     }\n \n-    private URL getResourceUrl() {\n-        URL resourceUrl = getClass().getResource(\"/scenario/test_scenario.xml\");\n+    @Test\n+    public void testWorkloadWithLoadProfile() throws Exception {\n+        String testResourceName = \"/scenario/test_scenario_with_load_profile.xml\";\n+        Set<String> scenarioNames = Sets.newHashSet(\"scenario_11\", \"scenario_12\");\n+        List<Scenario> scenarioList = getScenarios(testResourceName);\n+        Scenario target = null;\n+        for (Scenario scenario : scenarioList) {\n+            if (scenarioNames.contains(scenario.getName())) {\n+                target = scenario;\n+            }\n+            assertNotNull(\"Could not find scenario: \" + scenario.getName(), target);\n+        }\n+\n+        Scenario testScenarioWithLoadProfile = scenarioList.get(0);\n+        LoadProfile loadProfile = testScenarioWithLoadProfile.getLoadProfile();\n+        assertTrue(\"batch size not as expected: \",", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5ODEyNw==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545498127", "bodyText": "Are we handling this null value in the caller?", "author": "ChinmaySKulkarni", "createdAt": "2020-12-18T00:40:21Z", "path": "phoenix-pherf/src/test/java/org/apache/phoenix/pherf/workload/mt/tenantoperation/TenantOperationEventGeneratorTest.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+\n+package org.apache.phoenix.pherf.workload.mt.tenantoperation;\n+\n+import org.apache.phoenix.pherf.XMLConfigParserTest;\n+import org.apache.phoenix.pherf.configuration.DataModel;\n+import org.apache.phoenix.pherf.configuration.LoadProfile;\n+import org.apache.phoenix.pherf.configuration.Scenario;\n+import org.apache.phoenix.pherf.configuration.XMLConfigParser;\n+import org.apache.phoenix.pherf.util.PhoenixUtil;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.xml.bind.UnmarshalException;\n+import java.net.URL;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.fail;\n+\n+public class TenantOperationEventGeneratorTest {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(TenantOperationEventGeneratorTest.class);\n+    private enum TestOperationGroup {\n+        op1, op2, op3, op4, op5\n+    }\n+\n+    private enum TestTenantGroup {\n+        tg1, tg2, tg3\n+    }\n+\n+    public DataModel readTestDataModel(String resourceName) throws Exception {\n+        URL scenarioUrl = XMLConfigParserTest.class.getResource(resourceName);\n+        assertNotNull(scenarioUrl);\n+        Path p = Paths.get(scenarioUrl.toURI());\n+        try {\n+            return XMLConfigParser.readDataModel(p);\n+        } catch (UnmarshalException e) {\n+            // If we don't parse the DTD, the variable 'name' won't be defined in the XML\n+            LOGGER.warn(\"Caught expected exception\", e);\n+        }\n+        return null;", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5ODIyOQ==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r545498229", "bodyText": "nit: assertEquals throughout", "author": "ChinmaySKulkarni", "createdAt": "2020-12-18T00:40:45Z", "path": "phoenix-pherf/src/test/java/org/apache/phoenix/pherf/workload/mt/tenantoperation/TenantOperationEventGeneratorTest.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+\n+package org.apache.phoenix.pherf.workload.mt.tenantoperation;\n+\n+import org.apache.phoenix.pherf.XMLConfigParserTest;\n+import org.apache.phoenix.pherf.configuration.DataModel;\n+import org.apache.phoenix.pherf.configuration.LoadProfile;\n+import org.apache.phoenix.pherf.configuration.Scenario;\n+import org.apache.phoenix.pherf.configuration.XMLConfigParser;\n+import org.apache.phoenix.pherf.util.PhoenixUtil;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.xml.bind.UnmarshalException;\n+import java.net.URL;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.fail;\n+\n+public class TenantOperationEventGeneratorTest {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(TenantOperationEventGeneratorTest.class);\n+    private enum TestOperationGroup {\n+        op1, op2, op3, op4, op5\n+    }\n+\n+    private enum TestTenantGroup {\n+        tg1, tg2, tg3\n+    }\n+\n+    public DataModel readTestDataModel(String resourceName) throws Exception {\n+        URL scenarioUrl = XMLConfigParserTest.class.getResource(resourceName);\n+        assertNotNull(scenarioUrl);\n+        Path p = Paths.get(scenarioUrl.toURI());\n+        try {\n+            return XMLConfigParser.readDataModel(p);\n+        } catch (UnmarshalException e) {\n+            // If we don't parse the DTD, the variable 'name' won't be defined in the XML\n+            LOGGER.warn(\"Caught expected exception\", e);\n+        }\n+        return null;\n+    }\n+\n+    /**\n+     * Case 1 : where some operations have zero weight\n+     * Case 2 : where some tenant groups have zero weight\n+     * Case 3 : where no operations and tenant groups have zero weight\n+     * Case 4 : where some combinations of operation and tenant groups have zero weight\n+     *\n+     * @throws Exception\n+     */\n+    @Test\n+    public void testVariousEventGeneration() throws Exception {\n+        int numRuns = 10;\n+        int numOperations = 100000;\n+        int allowedVariance = 1000;\n+        int normalizedOperations = (numOperations * numRuns) / 10000;\n+        int numTenantGroups = 3;\n+        int numOpGroups = 5;\n+\n+        PhoenixUtil pUtil = PhoenixUtil.create();\n+        DataModel model = readTestDataModel(\"/scenario/test_evt_gen1.xml\");\n+        for (Scenario scenario : model.getScenarios()) {\n+            LOGGER.debug(String.format(\"Testing %s\", scenario.getName()));\n+            LoadProfile loadProfile = scenario.getLoadProfile();\n+            assertTrue(\"tenant group size is not as expected: \",", "originalCommit": "ede0f62202e57bbbcd900cc09faa6db95d551393", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "5b4be3885968fe4f7b17217ac095bdaf21cb6fb6", "url": "https://github.com/apache/phoenix/commit/5b4be3885968fe4f7b17217ac095bdaf21cb6fb6", "message": "Fixed rebase errors", "committedDate": "2021-02-26T21:59:04Z", "type": "forcePushed"}, {"oid": "4274eb146ba0f64fea9beea04c41a08d0d3710b3", "url": "https://github.com/apache/phoenix/commit/4274eb146ba0f64fea9beea04c41a08d0d3710b3", "message": "Fixed rebase related changes", "committedDate": "2021-03-23T21:32:59Z", "type": "forcePushed"}, {"oid": "ee296b9b6245f923e278681b478442378575ec64", "url": "https://github.com/apache/phoenix/commit/ee296b9b6245f923e278681b478442378575ec64", "message": "Added configuration classes and interfaces for multi tenant workloads", "committedDate": "2021-03-23T23:39:17Z", "type": "commit"}, {"oid": "3c5a17144f58d34de53a512ca6917718e339ae16", "url": "https://github.com/apache/phoenix/commit/3c5a17144f58d34de53a512ca6917718e339ae16", "message": "Addressed review comments", "committedDate": "2021-03-23T23:39:17Z", "type": "commit"}, {"oid": "9cc1996a6439a9f278e2a0aef3705a008bb2680b", "url": "https://github.com/apache/phoenix/commit/9cc1996a6439a9f278e2a0aef3705a008bb2680b", "message": "Added some more defaults and configs", "committedDate": "2021-03-23T23:39:17Z", "type": "commit"}, {"oid": "34ffb53029d6a8635ba57394eb2c4c040d9cb441", "url": "https://github.com/apache/phoenix/commit/34ffb53029d6a8635ba57394eb2c4c040d9cb441", "message": "Added implementation classes and tests", "committedDate": "2021-03-23T23:39:17Z", "type": "commit"}, {"oid": "0fe7cace5176ccb67cb076bf9ecaa889b36681bf", "url": "https://github.com/apache/phoenix/commit/0fe7cace5176ccb67cb076bf9ecaa889b36681bf", "message": "Addressed review comments and code refactorings", "committedDate": "2021-03-23T23:39:17Z", "type": "commit"}, {"oid": "6003d7b72fc47d0aa12d721460f9ccbfa1d54cd4", "url": "https://github.com/apache/phoenix/commit/6003d7b72fc47d0aa12d721460f9ccbfa1d54cd4", "message": "Finishing up review comments", "committedDate": "2021-03-23T23:39:17Z", "type": "commit"}, {"oid": "d73dfdd262192c4c91e31a62b8a621c251a7e9f7", "url": "https://github.com/apache/phoenix/commit/d73dfdd262192c4c91e31a62b8a621c251a7e9f7", "message": "Fixed rebase related changes", "committedDate": "2021-03-23T23:39:17Z", "type": "forcePushed"}, {"oid": "9bdcacd4320a18f4d1b83c4378d238c5dfe7a6fd", "url": "https://github.com/apache/phoenix/commit/9bdcacd4320a18f4d1b83c4378d238c5dfe7a6fd", "message": "Fixed rebase related changes", "committedDate": "2021-03-24T03:37:44Z", "type": "commit"}, {"oid": "9bdcacd4320a18f4d1b83c4378d238c5dfe7a6fd", "url": "https://github.com/apache/phoenix/commit/9bdcacd4320a18f4d1b83c4378d238c5dfe7a6fd", "message": "Fixed rebase related changes", "committedDate": "2021-03-24T03:37:44Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMTkwOTI3MA==", "url": "https://github.com/apache/phoenix/pull/878#discussion_r601909270", "bodyText": "nit: can you remove this unused import from the next PR. Don't need to fix it now", "author": "yanxinyi", "createdAt": "2021-03-25T23:48:04Z", "path": "phoenix-pherf/src/it/java/org/apache/phoenix/pherf/PherfMainIT.java", "diffHunk": "@@ -23,6 +23,7 @@\n import org.apache.phoenix.pherf.result.ResultValue;\n import org.apache.phoenix.pherf.result.file.ResultFileDetails;\n import org.apache.phoenix.pherf.result.impl.CSVFileResultHandler;\n+import org.junit.Ignore;", "originalCommit": "9bdcacd4320a18f4d1b83c4378d238c5dfe7a6fd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}