{"pr_number": 737, "pr_title": "PHOENIX-5773 Index tool output tables should support multiple simulta\u2026", "pr_createdAt": "2020-03-18T22:08:51Z", "pr_url": "https://github.com/apache/phoenix/pull/737", "timeline": [{"oid": "40fd290f18b36a2cbbbe0b059890393625c7709d", "url": "https://github.com/apache/phoenix/commit/40fd290f18b36a2cbbbe0b059890393625c7709d", "message": "PHOENIX-5773 Index tool output tables should support multiple simultaneous rebuilds", "committedDate": "2020-03-18T22:01:29Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTMxODUyNg==", "url": "https://github.com/apache/phoenix/pull/737#discussion_r395318526", "bodyText": "Would be good to extract row key building into its own function", "author": "gjacoby126", "createdAt": "2020-03-19T21:04:03Z", "path": "phoenix-core/src/main/java/org/apache/phoenix/coprocessor/IndexRebuildRegionScanner.java", "diffHunk": "@@ -257,16 +258,29 @@ private void logToIndexToolResultTable() throws IOException {\n         long scanMaxTs = scan.getTimeRange().getMax();\n         byte[] keyPrefix = Bytes.toBytes(Long.toString(scanMaxTs));\n         byte[] regionName = Bytes.toBytes(region.getRegionInfo().getRegionNameAsString());\n-        // The row key for the result table is the max timestamp of the scan + the table region name + scan start row\n-        // + scan stop row\n-        byte[] rowKey = new byte[keyPrefix.length + regionName.length + scan.getStartRow().length +\n-                scan.getStopRow().length];\n-        Bytes.putBytes(rowKey, 0, keyPrefix, 0, keyPrefix.length);\n-        Bytes.putBytes(rowKey, keyPrefix.length, regionName, 0, regionName.length);\n-        Bytes.putBytes(rowKey, keyPrefix.length + regionName.length, scan.getStartRow(), 0,\n-                scan.getStartRow().length);\n-        Bytes.putBytes(rowKey, keyPrefix.length + regionName.length + scan.getStartRow().length,\n-                scan.getStopRow(), 0, scan.getStopRow().length);\n+        int targetOffset = 0;\n+        // The row key for the result table : timestamp | index table name | datable table region name |\n+        //                                    scan start row | scan stop row\n+        byte[] rowKey = new byte[keyPrefix.length + ROW_KEY_SEPARATOR_BYTE.length + indexHTable.getName().toBytes().length +", "originalCommit": "40fd290f18b36a2cbbbe0b059890393625c7709d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM4ODUzNQ==", "url": "https://github.com/apache/phoenix/pull/737#discussion_r395388535", "bodyText": "I will extract the code out to a separate method.", "author": "kadirozde", "createdAt": "2020-03-20T00:20:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTMxODUyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTMxOTM1Ng==", "url": "https://github.com/apache/phoenix/pull/737#discussion_r395319356", "bodyText": "What happens if the Scan start row contains the bytes for \"|\"? Does this need to be length encoded instead of using separators? Or perhaps escaped somehow?", "author": "gjacoby126", "createdAt": "2020-03-19T21:05:57Z", "path": "phoenix-core/src/main/java/org/apache/phoenix/coprocessor/IndexRebuildRegionScanner.java", "diffHunk": "@@ -257,16 +258,29 @@ private void logToIndexToolResultTable() throws IOException {\n         long scanMaxTs = scan.getTimeRange().getMax();\n         byte[] keyPrefix = Bytes.toBytes(Long.toString(scanMaxTs));\n         byte[] regionName = Bytes.toBytes(region.getRegionInfo().getRegionNameAsString());\n-        // The row key for the result table is the max timestamp of the scan + the table region name + scan start row\n-        // + scan stop row\n-        byte[] rowKey = new byte[keyPrefix.length + regionName.length + scan.getStartRow().length +\n-                scan.getStopRow().length];\n-        Bytes.putBytes(rowKey, 0, keyPrefix, 0, keyPrefix.length);\n-        Bytes.putBytes(rowKey, keyPrefix.length, regionName, 0, regionName.length);\n-        Bytes.putBytes(rowKey, keyPrefix.length + regionName.length, scan.getStartRow(), 0,\n-                scan.getStartRow().length);\n-        Bytes.putBytes(rowKey, keyPrefix.length + regionName.length + scan.getStartRow().length,\n-                scan.getStopRow(), 0, scan.getStopRow().length);\n+        int targetOffset = 0;\n+        // The row key for the result table : timestamp | index table name | datable table region name |\n+        //                                    scan start row | scan stop row\n+        byte[] rowKey = new byte[keyPrefix.length + ROW_KEY_SEPARATOR_BYTE.length + indexHTable.getName().toBytes().length +\n+                ROW_KEY_SEPARATOR_BYTE.length + regionName.length + ROW_KEY_SEPARATOR_BYTE.length +\n+                scan.getStartRow().length + ROW_KEY_SEPARATOR_BYTE.length + scan.getStopRow().length];\n+        Bytes.putBytes(rowKey, targetOffset, keyPrefix, 0, keyPrefix.length);\n+        targetOffset += keyPrefix.length;\n+        Bytes.putBytes(rowKey, targetOffset, ROW_KEY_SEPARATOR_BYTE, 0, ROW_KEY_SEPARATOR_BYTE.length);\n+        targetOffset += ROW_KEY_SEPARATOR_BYTE.length;\n+        Bytes.putBytes(rowKey, targetOffset, indexHTable.getName().toBytes(), 0, indexHTable.getName().toBytes().length);\n+        targetOffset += indexHTable.getName().toBytes().length;\n+        Bytes.putBytes(rowKey, targetOffset, ROW_KEY_SEPARATOR_BYTE, 0, ROW_KEY_SEPARATOR_BYTE.length);\n+        targetOffset += ROW_KEY_SEPARATOR_BYTE.length;\n+        Bytes.putBytes(rowKey, targetOffset, regionName, 0, regionName.length);\n+        targetOffset += regionName.length;\n+        Bytes.putBytes(rowKey, targetOffset, ROW_KEY_SEPARATOR_BYTE, 0, ROW_KEY_SEPARATOR_BYTE.length);\n+        targetOffset += ROW_KEY_SEPARATOR_BYTE.length;\n+        Bytes.putBytes(rowKey, targetOffset, scan.getStartRow(), 0, scan.getStartRow().length);\n+        targetOffset += scan.getStartRow().length;", "originalCommit": "40fd290f18b36a2cbbbe0b059890393625c7709d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM4NjQxMA==", "url": "https://github.com/apache/phoenix/pull/737#discussion_r395386410", "bodyText": "Nothing. The separator is just for helping the human debugger copy subfields within a row key. @priyankporwal suggested this separator.", "author": "kadirozde", "createdAt": "2020-03-20T00:11:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTMxOTM1Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM4NzcwMA==", "url": "https://github.com/apache/phoenix/pull/737#discussion_r395387700", "bodyText": "Assume that a non-human has to parse this key into fields, and that this is not just for use manually in HBase shell. What happens if the Scan start row contains the bytes for \"|\"?", "author": "gjacoby126", "createdAt": "2020-03-20T00:16:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTMxOTM1Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQ0OTYwNQ==", "url": "https://github.com/apache/phoenix/pull/737#discussion_r395449605", "bodyText": "@gjacoby126, I am not sure what you are really asking. I did not say these separators are for programs. I said they were just there to help humans. The previous version did not have any separators. There were no requirement in this jira to add such separators. I added them based on Priyank's suggestion as he claimed it would improve debugging. If there is a requirement to parse the row key to obtain subfields then we need to have a separate jira to implement that. Please also note that the row key is constructed in a way to help debugging. For example, the timestamp values are written as variable strings instead of fixed-size long values. We need to redesign the row key and maybe to have two versions of it, one for human and the other for programs.  That deserves a separate jira.", "author": "kadirozde", "createdAt": "2020-03-20T05:56:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTMxOTM1Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTg1MDI0Mw==", "url": "https://github.com/apache/phoenix/pull/737#discussion_r395850243", "bodyText": "Valid points valid on both sides. I suggested a separator and pipe character as an aid for humans reading these keys. Although not perfect, it will work for programmatic access as well, assuming timestamp and index-names cannot have '|' character - by looking at first 2 occurrences only. The key may have '|' but that's a problem for another day.", "author": "priyankporwal", "createdAt": "2020-03-20T19:32:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTMxOTM1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTMxOTU3NA==", "url": "https://github.com/apache/phoenix/pull/737#discussion_r395319574", "bodyText": "likewise, extracting to a method to build the output table row key would be good.", "author": "gjacoby126", "createdAt": "2020-03-19T21:06:26Z", "path": "phoenix-core/src/main/java/org/apache/phoenix/coprocessor/IndexRebuildRegionScanner.java", "diffHunk": "@@ -412,30 +426,31 @@ public void logToIndexToolOutputTable(byte[] dataRowKey, byte[] indexRowKey, lon\n         long scanMaxTs = scan.getTimeRange().getMax();\n         byte[] keyPrefix = Bytes.toBytes(Long.toString(scanMaxTs));\n         byte[] rowKey;\n-        // The row key for the output table is the max timestamp of the scan + data row key\n-        if (dataRowKey != null) {\n-            rowKey = new byte[keyPrefix.length + dataRowKey.length];\n-            Bytes.putBytes(rowKey, 0, keyPrefix, 0, keyPrefix.length);\n-            Bytes.putBytes(rowKey, keyPrefix.length, dataRowKey, 0, dataRowKey.length);\n-        } else {\n-            rowKey = new byte[keyPrefix.length];\n-            Bytes.putBytes(rowKey, 0, keyPrefix, 0, keyPrefix.length);\n-        }\n+        int targetOffset = 0;\n+        // The row key for the output table : timestamp | index table name | data row key\n+        rowKey = new byte[keyPrefix.length + ROW_KEY_SEPARATOR_BYTE.length + indexHTable.getName().toBytes().length +\n+                ROW_KEY_SEPARATOR_BYTE.length + dataRowKey.length];\n+        Bytes.putBytes(rowKey, targetOffset, keyPrefix, 0, keyPrefix.length);\n+        targetOffset += keyPrefix.length;", "originalCommit": "40fd290f18b36a2cbbbe0b059890393625c7709d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM4ODU4NA==", "url": "https://github.com/apache/phoenix/pull/737#discussion_r395388584", "bodyText": "Will do that", "author": "kadirozde", "createdAt": "2020-03-20T00:20:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTMxOTU3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTMyMjMyOQ==", "url": "https://github.com/apache/phoenix/pull/737#discussion_r395322329", "bodyText": "Extracting the index tool result and index tool output writing code into separate classes (with read methods!) would facilitate testing -- I agree with @swaroopak that this needs some tests, I'd say probably for both insert and read. Adding read methods would also make life easier for utilities, whether in Phoenix or outside, to be able to programmatically parse the result and output tables. Otherwise a whole lot of boilerplate byte parsing has to be rewritten each time.", "author": "gjacoby126", "createdAt": "2020-03-19T21:12:16Z", "path": "phoenix-core/src/main/java/org/apache/phoenix/coprocessor/IndexRebuildRegionScanner.java", "diffHunk": "@@ -257,16 +258,29 @@ private void logToIndexToolResultTable() throws IOException {\n         long scanMaxTs = scan.getTimeRange().getMax();\n         byte[] keyPrefix = Bytes.toBytes(Long.toString(scanMaxTs));\n         byte[] regionName = Bytes.toBytes(region.getRegionInfo().getRegionNameAsString());\n-        // The row key for the result table is the max timestamp of the scan + the table region name + scan start row\n-        // + scan stop row\n-        byte[] rowKey = new byte[keyPrefix.length + regionName.length + scan.getStartRow().length +\n-                scan.getStopRow().length];\n-        Bytes.putBytes(rowKey, 0, keyPrefix, 0, keyPrefix.length);\n-        Bytes.putBytes(rowKey, keyPrefix.length, regionName, 0, regionName.length);\n-        Bytes.putBytes(rowKey, keyPrefix.length + regionName.length, scan.getStartRow(), 0,\n-                scan.getStartRow().length);\n-        Bytes.putBytes(rowKey, keyPrefix.length + regionName.length + scan.getStartRow().length,\n-                scan.getStopRow(), 0, scan.getStopRow().length);\n+        int targetOffset = 0;", "originalCommit": "40fd290f18b36a2cbbbe0b059890393625c7709d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTMyMzM5OA==", "url": "https://github.com/apache/phoenix/pull/737#discussion_r395323398", "bodyText": "If you don't have the bandwidth for the read part, I'm happy to help out with it, either in this JIRA or another. If it doesn't get put into Phoenix here it's code I have to write anyway. :-)", "author": "gjacoby126", "createdAt": "2020-03-19T21:14:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTMyMjMyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQ0NjU3Mg==", "url": "https://github.com/apache/phoenix/pull/737#discussion_r395446572", "bodyText": "Please feel free to open a JIRA to extract  index tool output writing code into separate classes and  write a unit test for them.", "author": "kadirozde", "createdAt": "2020-03-20T05:38:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTMyMjMyOQ=="}], "type": "inlineReview"}, {"oid": "e2494c201e260f057ba4046f300e14680a88c61b", "url": "https://github.com/apache/phoenix/commit/e2494c201e260f057ba4046f300e14680a88c61b", "message": "PHOENIX-5773 Extract out the code generating row key", "committedDate": "2020-03-20T19:52:08Z", "type": "commit"}, {"oid": "64e8645b351e042feaa397275099ffe1ab6de261", "url": "https://github.com/apache/phoenix/commit/64e8645b351e042feaa397275099ffe1ab6de261", "message": "PHOENIX-5773 Added testing for index tool table row keys", "committedDate": "2020-03-23T20:25:37Z", "type": "commit"}]}