{"pr_number": 1367, "pr_title": "SAMZA-2530: Split out processing logic from TaskSideInputStorageManager", "pr_createdAt": "2020-05-23T08:01:27Z", "pr_url": "https://github.com/apache/samza/pull/1367", "timeline": [{"oid": "9e6bde0c8c288615330ab88151b3742cc4bb251c", "url": "https://github.com/apache/samza/commit/9e6bde0c8c288615330ab88151b3742cc4bb251c", "message": "Splitting processing logic out from TaskSideInputStorageManager", "committedDate": "2020-05-23T08:00:51Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUyNTM1Nw==", "url": "https://github.com/apache/samza/pull/1367#discussion_r429525357", "bodyText": "copied from TaskSideInputStorageManager", "author": "bkonold", "createdAt": "2020-05-23T08:03:01Z", "path": "samza-core/src/main/java/org/apache/samza/storage/TaskSideInputHandler.java", "diffHunk": "@@ -0,0 +1,233 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.samza.storage;\n+\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import java.io.File;\n+import java.util.AbstractMap;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+import org.apache.samza.Partition;\n+import org.apache.samza.SamzaException;\n+import org.apache.samza.container.TaskName;\n+import org.apache.samza.job.model.TaskMode;\n+import org.apache.samza.storage.kv.Entry;\n+import org.apache.samza.storage.kv.KeyValueStore;\n+import org.apache.samza.system.IncomingMessageEnvelope;\n+import org.apache.samza.system.StreamMetadataCache;\n+import org.apache.samza.system.SystemAdmins;\n+import org.apache.samza.system.SystemStream;\n+import org.apache.samza.system.SystemStreamMetadata;\n+import org.apache.samza.system.SystemStreamPartition;\n+import org.apache.samza.util.Clock;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import scala.collection.JavaConverters;\n+\n+\n+/**\n+ * This class encapsulates all processing logic / state for all side input SSPs within a task.\n+ */\n+public class TaskSideInputHandler {\n+  private static final Logger LOG = LoggerFactory.getLogger(TaskSideInputHandler.class);\n+\n+  private final StorageManagerUtil storageManagerUtil = new StorageManagerUtil();\n+\n+  private final TaskName taskName;\n+  private final TaskSideInputStorageManager taskSideInputStorageManager;\n+  private final Map<SystemStreamPartition, Set<String>> sspToStores;\n+  private final Map<String, SideInputsProcessor> storeToProcessor;\n+  private final SystemAdmins systemAdmins;\n+  private final StreamMetadataCache streamMetadataCache;\n+  private final Map<SystemStreamPartition, String> lastProcessedOffsets = new ConcurrentHashMap<>();\n+\n+  private Map<SystemStreamPartition, String> startingOffsets;\n+\n+  public TaskSideInputHandler(\n+      TaskName taskName,\n+      TaskMode taskMode,\n+      File storeBaseDir,\n+      Map<String, StorageEngine> storeToStorageEngines,\n+      Map<String, Set<SystemStreamPartition>> storeToSSPs,\n+      Map<String, SideInputsProcessor> storeToProcessor,\n+      SystemAdmins systemAdmins,\n+      StreamMetadataCache streamMetadataCache,\n+      Clock clock) {\n+    this.taskName = taskName;\n+    this.systemAdmins = systemAdmins;\n+    this.streamMetadataCache = streamMetadataCache;\n+    this.storeToProcessor = storeToProcessor;\n+\n+    this.sspToStores = storeToSSPs.entrySet().stream()\n+        .flatMap(storeAndSSPs -> storeAndSSPs.getValue().stream()\n+            .map(ssp -> new AbstractMap.SimpleImmutableEntry<>(ssp, storeAndSSPs.getKey())))\n+        .collect(Collectors.groupingBy(\n+            Map.Entry::getKey,\n+            Collectors.mapping(Map.Entry::getValue, Collectors.toSet())));\n+\n+    this.taskSideInputStorageManager = new TaskSideInputStorageManager(taskName,\n+        taskMode,\n+        storeBaseDir,\n+        storeToStorageEngines,\n+        storeToSSPs,\n+        clock);\n+\n+    validateProcessorConfiguration();\n+  }\n+\n+  public TaskName getTaskName() {\n+    return this.taskName;\n+  }\n+\n+  public void init() {\n+    this.taskSideInputStorageManager.init();\n+\n+    Map<SystemStreamPartition, String> fileOffsets = taskSideInputStorageManager.getFileOffsets();\n+    this.lastProcessedOffsets.putAll(fileOffsets);\n+    this.startingOffsets = getStartingOffsets(fileOffsets, getOldestOffsets());\n+  }\n+\n+  public void process(IncomingMessageEnvelope envelope) {\n+    SystemStreamPartition envelopeSSP = envelope.getSystemStreamPartition();\n+    String envelopeOffset = envelope.getOffset();\n+\n+    for (String store: this.sspToStores.get(envelopeSSP)) {\n+      SideInputsProcessor storeProcessor = this.storeToProcessor.get(store);\n+      KeyValueStore keyValueStore = (KeyValueStore) this.taskSideInputStorageManager.getStore(store);\n+      Collection<Entry<?, ?>> entriesToBeWritten = storeProcessor.process(envelope, keyValueStore);\n+\n+      // TODO: SAMZA-2255: optimize writes to side input stores\n+      for (Entry entry : entriesToBeWritten) {\n+        // If the key is null we ignore, if the value is null, we issue a delete, else we issue a put\n+        if (entry.getKey() != null) {\n+          if (entry.getValue() != null) {\n+            keyValueStore.put(entry.getKey(), entry.getValue());\n+          } else {\n+            keyValueStore.delete(entry.getKey());\n+          }\n+        }\n+      }\n+    }\n+\n+    this.lastProcessedOffsets.put(envelopeSSP, envelopeOffset);\n+  }", "originalCommit": "9e6bde0c8c288615330ab88151b3742cc4bb251c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUyNTM2Ng==", "url": "https://github.com/apache/samza/pull/1367#discussion_r429525366", "bodyText": "copied from TaskSideInputStorageManager", "author": "bkonold", "createdAt": "2020-05-23T08:03:15Z", "path": "samza-core/src/main/java/org/apache/samza/storage/TaskSideInputHandler.java", "diffHunk": "@@ -0,0 +1,233 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.samza.storage;\n+\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import java.io.File;\n+import java.util.AbstractMap;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+import org.apache.samza.Partition;\n+import org.apache.samza.SamzaException;\n+import org.apache.samza.container.TaskName;\n+import org.apache.samza.job.model.TaskMode;\n+import org.apache.samza.storage.kv.Entry;\n+import org.apache.samza.storage.kv.KeyValueStore;\n+import org.apache.samza.system.IncomingMessageEnvelope;\n+import org.apache.samza.system.StreamMetadataCache;\n+import org.apache.samza.system.SystemAdmins;\n+import org.apache.samza.system.SystemStream;\n+import org.apache.samza.system.SystemStreamMetadata;\n+import org.apache.samza.system.SystemStreamPartition;\n+import org.apache.samza.util.Clock;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import scala.collection.JavaConverters;\n+\n+\n+/**\n+ * This class encapsulates all processing logic / state for all side input SSPs within a task.\n+ */\n+public class TaskSideInputHandler {\n+  private static final Logger LOG = LoggerFactory.getLogger(TaskSideInputHandler.class);\n+\n+  private final StorageManagerUtil storageManagerUtil = new StorageManagerUtil();\n+\n+  private final TaskName taskName;\n+  private final TaskSideInputStorageManager taskSideInputStorageManager;\n+  private final Map<SystemStreamPartition, Set<String>> sspToStores;\n+  private final Map<String, SideInputsProcessor> storeToProcessor;\n+  private final SystemAdmins systemAdmins;\n+  private final StreamMetadataCache streamMetadataCache;\n+  private final Map<SystemStreamPartition, String> lastProcessedOffsets = new ConcurrentHashMap<>();\n+\n+  private Map<SystemStreamPartition, String> startingOffsets;\n+\n+  public TaskSideInputHandler(\n+      TaskName taskName,\n+      TaskMode taskMode,\n+      File storeBaseDir,\n+      Map<String, StorageEngine> storeToStorageEngines,\n+      Map<String, Set<SystemStreamPartition>> storeToSSPs,\n+      Map<String, SideInputsProcessor> storeToProcessor,\n+      SystemAdmins systemAdmins,\n+      StreamMetadataCache streamMetadataCache,\n+      Clock clock) {\n+    this.taskName = taskName;\n+    this.systemAdmins = systemAdmins;\n+    this.streamMetadataCache = streamMetadataCache;\n+    this.storeToProcessor = storeToProcessor;\n+\n+    this.sspToStores = storeToSSPs.entrySet().stream()\n+        .flatMap(storeAndSSPs -> storeAndSSPs.getValue().stream()\n+            .map(ssp -> new AbstractMap.SimpleImmutableEntry<>(ssp, storeAndSSPs.getKey())))\n+        .collect(Collectors.groupingBy(\n+            Map.Entry::getKey,\n+            Collectors.mapping(Map.Entry::getValue, Collectors.toSet())));\n+\n+    this.taskSideInputStorageManager = new TaskSideInputStorageManager(taskName,\n+        taskMode,\n+        storeBaseDir,\n+        storeToStorageEngines,\n+        storeToSSPs,\n+        clock);\n+\n+    validateProcessorConfiguration();\n+  }\n+\n+  public TaskName getTaskName() {\n+    return this.taskName;\n+  }\n+\n+  public void init() {\n+    this.taskSideInputStorageManager.init();\n+\n+    Map<SystemStreamPartition, String> fileOffsets = taskSideInputStorageManager.getFileOffsets();\n+    this.lastProcessedOffsets.putAll(fileOffsets);\n+    this.startingOffsets = getStartingOffsets(fileOffsets, getOldestOffsets());\n+  }\n+\n+  public void process(IncomingMessageEnvelope envelope) {\n+    SystemStreamPartition envelopeSSP = envelope.getSystemStreamPartition();\n+    String envelopeOffset = envelope.getOffset();\n+\n+    for (String store: this.sspToStores.get(envelopeSSP)) {\n+      SideInputsProcessor storeProcessor = this.storeToProcessor.get(store);\n+      KeyValueStore keyValueStore = (KeyValueStore) this.taskSideInputStorageManager.getStore(store);\n+      Collection<Entry<?, ?>> entriesToBeWritten = storeProcessor.process(envelope, keyValueStore);\n+\n+      // TODO: SAMZA-2255: optimize writes to side input stores\n+      for (Entry entry : entriesToBeWritten) {\n+        // If the key is null we ignore, if the value is null, we issue a delete, else we issue a put\n+        if (entry.getKey() != null) {\n+          if (entry.getValue() != null) {\n+            keyValueStore.put(entry.getKey(), entry.getValue());\n+          } else {\n+            keyValueStore.delete(entry.getKey());\n+          }\n+        }\n+      }\n+    }\n+\n+    this.lastProcessedOffsets.put(envelopeSSP, envelopeOffset);\n+  }\n+\n+  public void flush() {\n+    this.taskSideInputStorageManager.flush(this.lastProcessedOffsets);\n+  }\n+\n+  public String getStartingOffset(SystemStreamPartition ssp) {\n+    return this.startingOffsets.get(ssp);\n+  }\n+\n+  public String getLastProcessedOffset(SystemStreamPartition ssp) {\n+    return this.lastProcessedOffsets.get(ssp);\n+  }\n+\n+  public void stop() {\n+    this.taskSideInputStorageManager.stop(this.lastProcessedOffsets);\n+  }\n+\n+  /**\n+   * Gets the starting offsets for the {@link SystemStreamPartition}s belonging to all the side input stores.\n+   * If the local file offset is available and is greater than the oldest available offset from source, uses it,\n+   * else falls back to oldest offset in the source.\n+   *\n+   * @param fileOffsets offsets from the local offset file\n+   * @param oldestOffsets oldest offsets from the source\n+   * @return a {@link Map} of {@link SystemStreamPartition} to offset\n+   */\n+  @VisibleForTesting\n+  Map<SystemStreamPartition, String> getStartingOffsets(\n+      Map<SystemStreamPartition, String> fileOffsets, Map<SystemStreamPartition, String> oldestOffsets) {\n+    Map<SystemStreamPartition, String> startingOffsets = new HashMap<>();\n+\n+    this.sspToStores.keySet().forEach(ssp -> {\n+        String fileOffset = fileOffsets.get(ssp);\n+        String oldestOffset = oldestOffsets.get(ssp);\n+\n+        startingOffsets.put(ssp,\n+            this.storageManagerUtil.getStartingOffset(\n+                ssp, this.systemAdmins.getSystemAdmin(ssp.getSystem()), fileOffset, oldestOffset));\n+      });\n+\n+    return startingOffsets;\n+  }\n+\n+  /**\n+   * Gets the oldest offset for the {@link SystemStreamPartition}s associated with all the store side inputs.\n+   *   1. Groups the list of the SSPs based on system stream\n+   *   2. Fetches the {@link SystemStreamMetadata} from {@link StreamMetadataCache}\n+   *   3. Fetches the partition metadata for each system stream and fetch the corresponding partition metadata\n+   *      and populates the oldest offset for SSPs belonging to the system stream.\n+   *\n+   * @return a {@link Map} of {@link SystemStreamPartition} to their oldest offset. If partitionMetadata could not be\n+   * obtained for any {@link SystemStreamPartition} the offset for it is populated as null.\n+   */\n+  @VisibleForTesting\n+  Map<SystemStreamPartition, String> getOldestOffsets() {\n+    Map<SystemStreamPartition, String> oldestOffsets = new HashMap<>();\n+\n+    // Step 1\n+    Map<SystemStream, List<SystemStreamPartition>> systemStreamToSsp = this.sspToStores.keySet().stream()\n+        .collect(Collectors.groupingBy(SystemStreamPartition::getSystemStream));\n+\n+    // Step 2\n+    Map<SystemStream, SystemStreamMetadata> metadata = JavaConverters.mapAsJavaMapConverter(\n+        streamMetadataCache.getStreamMetadata(\n+            JavaConverters.asScalaSetConverter(systemStreamToSsp.keySet()).asScala().toSet(), false)).asJava();\n+\n+    // Step 3\n+    metadata.forEach((systemStream, systemStreamMetadata) -> {\n+\n+        // get the partition metadata for each system stream\n+        Map<Partition, SystemStreamMetadata.SystemStreamPartitionMetadata> partitionMetadata =\n+            systemStreamMetadata.getSystemStreamPartitionMetadata();\n+\n+        // For SSPs belonging to the system stream, use the partition metadata to get the oldest offset\n+        // if partitionMetadata was not obtained for any SSP, populate oldest-offset as null\n+        // Because of https://bugs.openjdk.java.net/browse/JDK-8148463 using lambda will NPE when getOldestOffset() is null\n+        for (SystemStreamPartition ssp : systemStreamToSsp.get(systemStream)) {\n+          oldestOffsets.put(ssp, partitionMetadata.get(ssp.getPartition()).getOldestOffset());\n+        }\n+      });\n+\n+    return oldestOffsets;\n+  }\n+\n+  private void validateProcessorConfiguration() {\n+    Set<String> stores = this.sspToStores.values().stream()\n+        .flatMap(Collection::stream)\n+        .collect(Collectors.toSet());\n+\n+    stores.forEach(storeName -> {\n+        if (!storeToProcessor.containsKey(storeName)) {\n+          throw new SamzaException(\n+              String.format(\"Side inputs processor missing for store: %s.\", storeName));\n+        }\n+      });\n+  }\n+}", "originalCommit": "9e6bde0c8c288615330ab88151b3742cc4bb251c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUyNTQyMg==", "url": "https://github.com/apache/samza/pull/1367#discussion_r429525422", "bodyText": "adapted from TaskSideInputStorageManager", "author": "bkonold", "createdAt": "2020-05-23T08:04:13Z", "path": "samza-core/src/test/java/org/apache/samza/storage/TestTaskSideInputHandler.java", "diffHunk": "@@ -0,0 +1,197 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.samza.storage;\n+\n+import java.io.File;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+import org.apache.samza.Partition;\n+import org.apache.samza.container.TaskName;\n+import org.apache.samza.job.model.TaskMode;\n+import org.apache.samza.system.StreamMetadataCache;\n+import org.apache.samza.system.SystemAdmin;\n+import org.apache.samza.system.SystemAdmins;\n+import org.apache.samza.system.SystemStream;\n+import org.apache.samza.system.SystemStreamMetadata;\n+import org.apache.samza.system.SystemStreamPartition;\n+import org.apache.samza.util.Clock;\n+import org.apache.samza.util.ScalaJavaUtil;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import static org.junit.Assert.*;\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Mockito.*;\n+\n+\n+public class TestTaskSideInputHandler {\n+  private static final String TEST_TASK_NAME = \"test-task\";\n+  private static final String TEST_SYSTEM = \"test-system\";\n+  private static final String TEST_STORE = \"test-store\";\n+  private static final String TEST_STREAM = \"test-stream\";\n+\n+    /**\n+   * This test is for cases, when calls to systemAdmin (e.g., KafkaSystemAdmin's) get-stream-metadata method return null.\n+   */\n+  @Test\n+  public void testGetStartingOffsetsWhenStreamMetadataIsNull() {\n+    final String taskName = \"test-get-starting-offset-task\";\n+\n+    Set<SystemStreamPartition> ssps = IntStream.range(1, 2)\n+        .mapToObj(idx -> new SystemStreamPartition(TEST_SYSTEM, TEST_STREAM, new Partition(idx)))\n+        .collect(Collectors.toSet());\n+    Map<Partition, SystemStreamMetadata.SystemStreamPartitionMetadata> partitionMetadata = ssps.stream()\n+        .collect(Collectors.toMap(SystemStreamPartition::getPartition,\n+            x -> new SystemStreamMetadata.SystemStreamPartitionMetadata(null, \"1\", \"2\")));\n+\n+\n+    TaskSideInputHandler handler = new MockTaskSideInputHandlerBuilder(taskName, TaskMode.Active)\n+        .addStreamMetadata(Collections.singletonMap(new SystemStream(TEST_SYSTEM, TEST_STREAM),\n+            new SystemStreamMetadata(TEST_STREAM, partitionMetadata)))\n+        .addStore(TEST_STORE, ssps)\n+        .build();\n+\n+    handler.init();\n+\n+    ssps.forEach(ssp -> {\n+        String startingOffset = handler.getStartingOffset(\n+            new SystemStreamPartition(TEST_SYSTEM, TEST_STREAM, ssp.getPartition()));\n+        Assert.assertNull(\"Starting offset should be null\", startingOffset);\n+      });\n+  }\n+\n+  @Test\n+  public void testGetStartingOffsets() {\n+    final String storeName = \"test-get-starting-offset-store\";\n+    final String taskName = \"test-get-starting-offset-task\";\n+\n+    Set<SystemStreamPartition> ssps = IntStream.range(1, 6)\n+        .mapToObj(idx -> new SystemStreamPartition(TEST_SYSTEM, TEST_STREAM, new Partition(idx)))\n+        .collect(Collectors.toSet());\n+\n+\n+    TaskSideInputHandler handler = new MockTaskSideInputHandlerBuilder(taskName, TaskMode.Active)\n+        .addStore(storeName, ssps)\n+        .build();\n+\n+    // set up file and oldest offsets. for even partitions, fileOffsets will be larger; for odd partitions oldestOffsets will be larger\n+    Map<SystemStreamPartition, String> fileOffsets = ssps.stream()\n+        .collect(Collectors.toMap(Function.identity(), ssp -> {\n+            int partitionId = ssp.getPartition().getPartitionId();\n+            int offset = partitionId % 2 == 0 ? partitionId + 10 : partitionId;\n+            return String.valueOf(offset);\n+          }));\n+    Map<SystemStreamPartition, String> oldestOffsets = ssps.stream()\n+        .collect(Collectors.toMap(Function.identity(), ssp -> {\n+            int partitionId = ssp.getPartition().getPartitionId();\n+            int offset = partitionId % 2 == 0 ? partitionId : partitionId + 10;\n+\n+            return String.valueOf(offset);\n+          }));\n+\n+    doCallRealMethod().when(handler).getStartingOffsets(fileOffsets, oldestOffsets);\n+\n+    Map<SystemStreamPartition, String> startingOffsets = handler.getStartingOffsets(fileOffsets, oldestOffsets);\n+\n+    assertTrue(\"Failed to get starting offsets for all ssps\", startingOffsets.size() == 5);", "originalCommit": "9e6bde0c8c288615330ab88151b3742cc4bb251c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUyNTQ0MA==", "url": "https://github.com/apache/samza/pull/1367#discussion_r429525440", "bodyText": "New - added for stricter behavior check on getStartingOffsets", "author": "bkonold", "createdAt": "2020-05-23T08:04:35Z", "path": "samza-core/src/test/java/org/apache/samza/storage/TestTaskSideInputHandler.java", "diffHunk": "@@ -0,0 +1,197 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.samza.storage;\n+\n+import java.io.File;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+import org.apache.samza.Partition;\n+import org.apache.samza.container.TaskName;\n+import org.apache.samza.job.model.TaskMode;\n+import org.apache.samza.system.StreamMetadataCache;\n+import org.apache.samza.system.SystemAdmin;\n+import org.apache.samza.system.SystemAdmins;\n+import org.apache.samza.system.SystemStream;\n+import org.apache.samza.system.SystemStreamMetadata;\n+import org.apache.samza.system.SystemStreamPartition;\n+import org.apache.samza.util.Clock;\n+import org.apache.samza.util.ScalaJavaUtil;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import static org.junit.Assert.*;\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Mockito.*;\n+\n+\n+public class TestTaskSideInputHandler {\n+  private static final String TEST_TASK_NAME = \"test-task\";\n+  private static final String TEST_SYSTEM = \"test-system\";\n+  private static final String TEST_STORE = \"test-store\";\n+  private static final String TEST_STREAM = \"test-stream\";\n+\n+    /**\n+   * This test is for cases, when calls to systemAdmin (e.g., KafkaSystemAdmin's) get-stream-metadata method return null.\n+   */\n+  @Test\n+  public void testGetStartingOffsetsWhenStreamMetadataIsNull() {\n+    final String taskName = \"test-get-starting-offset-task\";\n+\n+    Set<SystemStreamPartition> ssps = IntStream.range(1, 2)\n+        .mapToObj(idx -> new SystemStreamPartition(TEST_SYSTEM, TEST_STREAM, new Partition(idx)))\n+        .collect(Collectors.toSet());\n+    Map<Partition, SystemStreamMetadata.SystemStreamPartitionMetadata> partitionMetadata = ssps.stream()\n+        .collect(Collectors.toMap(SystemStreamPartition::getPartition,\n+            x -> new SystemStreamMetadata.SystemStreamPartitionMetadata(null, \"1\", \"2\")));\n+\n+\n+    TaskSideInputHandler handler = new MockTaskSideInputHandlerBuilder(taskName, TaskMode.Active)\n+        .addStreamMetadata(Collections.singletonMap(new SystemStream(TEST_SYSTEM, TEST_STREAM),\n+            new SystemStreamMetadata(TEST_STREAM, partitionMetadata)))\n+        .addStore(TEST_STORE, ssps)\n+        .build();\n+\n+    handler.init();\n+\n+    ssps.forEach(ssp -> {\n+        String startingOffset = handler.getStartingOffset(\n+            new SystemStreamPartition(TEST_SYSTEM, TEST_STREAM, ssp.getPartition()));\n+        Assert.assertNull(\"Starting offset should be null\", startingOffset);\n+      });\n+  }\n+\n+  @Test\n+  public void testGetStartingOffsets() {\n+    final String storeName = \"test-get-starting-offset-store\";\n+    final String taskName = \"test-get-starting-offset-task\";\n+\n+    Set<SystemStreamPartition> ssps = IntStream.range(1, 6)\n+        .mapToObj(idx -> new SystemStreamPartition(TEST_SYSTEM, TEST_STREAM, new Partition(idx)))\n+        .collect(Collectors.toSet());\n+\n+\n+    TaskSideInputHandler handler = new MockTaskSideInputHandlerBuilder(taskName, TaskMode.Active)\n+        .addStore(storeName, ssps)\n+        .build();\n+\n+    // set up file and oldest offsets. for even partitions, fileOffsets will be larger; for odd partitions oldestOffsets will be larger\n+    Map<SystemStreamPartition, String> fileOffsets = ssps.stream()\n+        .collect(Collectors.toMap(Function.identity(), ssp -> {\n+            int partitionId = ssp.getPartition().getPartitionId();\n+            int offset = partitionId % 2 == 0 ? partitionId + 10 : partitionId;\n+            return String.valueOf(offset);\n+          }));\n+    Map<SystemStreamPartition, String> oldestOffsets = ssps.stream()\n+        .collect(Collectors.toMap(Function.identity(), ssp -> {\n+            int partitionId = ssp.getPartition().getPartitionId();\n+            int offset = partitionId % 2 == 0 ? partitionId : partitionId + 10;\n+\n+            return String.valueOf(offset);\n+          }));\n+\n+    doCallRealMethod().when(handler).getStartingOffsets(fileOffsets, oldestOffsets);\n+\n+    Map<SystemStreamPartition, String> startingOffsets = handler.getStartingOffsets(fileOffsets, oldestOffsets);\n+\n+    assertTrue(\"Failed to get starting offsets for all ssps\", startingOffsets.size() == 5);\n+    startingOffsets.forEach((ssp, offset) -> {\n+        int partitionId = ssp.getPartition().getPartitionId();\n+        String expectedOffset = partitionId % 2 == 0\n+            // 1 + fileOffset\n+            ? getOffsetAfter(String.valueOf(ssp.getPartition().getPartitionId() + 10))\n+            // oldestOffset\n+            : String.valueOf(ssp.getPartition().getPartitionId() + 10);\n+        assertEquals(\"Larger of fileOffsets and oldestOffsets should always be chosen\", expectedOffset, offset);\n+      });", "originalCommit": "9e6bde0c8c288615330ab88151b3742cc4bb251c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg2MTM5Mw==", "url": "https://github.com/apache/samza/pull/1367#discussion_r430861393", "bodyText": "This is a new validation added?", "author": "lakshmi-manasa-g", "createdAt": "2020-05-27T05:15:12Z", "path": "samza-core/src/main/java/org/apache/samza/storage/TaskSideInputHandler.java", "diffHunk": "@@ -0,0 +1,233 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.samza.storage;\n+\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import java.io.File;\n+import java.util.AbstractMap;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+import org.apache.samza.Partition;\n+import org.apache.samza.SamzaException;\n+import org.apache.samza.container.TaskName;\n+import org.apache.samza.job.model.TaskMode;\n+import org.apache.samza.storage.kv.Entry;\n+import org.apache.samza.storage.kv.KeyValueStore;\n+import org.apache.samza.system.IncomingMessageEnvelope;\n+import org.apache.samza.system.StreamMetadataCache;\n+import org.apache.samza.system.SystemAdmins;\n+import org.apache.samza.system.SystemStream;\n+import org.apache.samza.system.SystemStreamMetadata;\n+import org.apache.samza.system.SystemStreamPartition;\n+import org.apache.samza.util.Clock;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import scala.collection.JavaConverters;\n+\n+\n+/**\n+ * This class encapsulates all processing logic / state for all side input SSPs within a task.\n+ */\n+public class TaskSideInputHandler {\n+  private static final Logger LOG = LoggerFactory.getLogger(TaskSideInputHandler.class);\n+\n+  private final StorageManagerUtil storageManagerUtil = new StorageManagerUtil();\n+\n+  private final TaskName taskName;\n+  private final TaskSideInputStorageManager taskSideInputStorageManager;\n+  private final Map<SystemStreamPartition, Set<String>> sspToStores;\n+  private final Map<String, SideInputsProcessor> storeToProcessor;\n+  private final SystemAdmins systemAdmins;\n+  private final StreamMetadataCache streamMetadataCache;\n+  private final Map<SystemStreamPartition, String> lastProcessedOffsets = new ConcurrentHashMap<>();\n+\n+  private Map<SystemStreamPartition, String> startingOffsets;\n+\n+  public TaskSideInputHandler(\n+      TaskName taskName,\n+      TaskMode taskMode,\n+      File storeBaseDir,\n+      Map<String, StorageEngine> storeToStorageEngines,\n+      Map<String, Set<SystemStreamPartition>> storeToSSPs,\n+      Map<String, SideInputsProcessor> storeToProcessor,\n+      SystemAdmins systemAdmins,\n+      StreamMetadataCache streamMetadataCache,\n+      Clock clock) {\n+    this.taskName = taskName;\n+    this.systemAdmins = systemAdmins;\n+    this.streamMetadataCache = streamMetadataCache;\n+    this.storeToProcessor = storeToProcessor;\n+\n+    this.sspToStores = storeToSSPs.entrySet().stream()\n+        .flatMap(storeAndSSPs -> storeAndSSPs.getValue().stream()\n+            .map(ssp -> new AbstractMap.SimpleImmutableEntry<>(ssp, storeAndSSPs.getKey())))\n+        .collect(Collectors.groupingBy(\n+            Map.Entry::getKey,\n+            Collectors.mapping(Map.Entry::getValue, Collectors.toSet())));\n+\n+    this.taskSideInputStorageManager = new TaskSideInputStorageManager(taskName,\n+        taskMode,\n+        storeBaseDir,\n+        storeToStorageEngines,\n+        storeToSSPs,\n+        clock);\n+\n+    validateProcessorConfiguration();", "originalCommit": "9e6bde0c8c288615330ab88151b3742cc4bb251c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg3ODM0Nw==", "url": "https://github.com/apache/samza/pull/1367#discussion_r430878347", "bodyText": "This is not actually new - I just moved the bit validating the processor mapping out from the storage manager into the handler.", "author": "bkonold", "createdAt": "2020-05-27T06:11:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg2MTM5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg2MTc1Mw==", "url": "https://github.com/apache/samza/pull/1367#discussion_r430861753", "bodyText": "There were info logs for these in the original code. Any reason to remove them?", "author": "lakshmi-manasa-g", "createdAt": "2020-05-27T05:16:45Z", "path": "samza-core/src/main/java/org/apache/samza/storage/TaskSideInputHandler.java", "diffHunk": "@@ -0,0 +1,233 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.samza.storage;\n+\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import java.io.File;\n+import java.util.AbstractMap;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+import org.apache.samza.Partition;\n+import org.apache.samza.SamzaException;\n+import org.apache.samza.container.TaskName;\n+import org.apache.samza.job.model.TaskMode;\n+import org.apache.samza.storage.kv.Entry;\n+import org.apache.samza.storage.kv.KeyValueStore;\n+import org.apache.samza.system.IncomingMessageEnvelope;\n+import org.apache.samza.system.StreamMetadataCache;\n+import org.apache.samza.system.SystemAdmins;\n+import org.apache.samza.system.SystemStream;\n+import org.apache.samza.system.SystemStreamMetadata;\n+import org.apache.samza.system.SystemStreamPartition;\n+import org.apache.samza.util.Clock;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import scala.collection.JavaConverters;\n+\n+\n+/**\n+ * This class encapsulates all processing logic / state for all side input SSPs within a task.\n+ */\n+public class TaskSideInputHandler {\n+  private static final Logger LOG = LoggerFactory.getLogger(TaskSideInputHandler.class);\n+\n+  private final StorageManagerUtil storageManagerUtil = new StorageManagerUtil();\n+\n+  private final TaskName taskName;\n+  private final TaskSideInputStorageManager taskSideInputStorageManager;\n+  private final Map<SystemStreamPartition, Set<String>> sspToStores;\n+  private final Map<String, SideInputsProcessor> storeToProcessor;\n+  private final SystemAdmins systemAdmins;\n+  private final StreamMetadataCache streamMetadataCache;\n+  private final Map<SystemStreamPartition, String> lastProcessedOffsets = new ConcurrentHashMap<>();\n+\n+  private Map<SystemStreamPartition, String> startingOffsets;\n+\n+  public TaskSideInputHandler(\n+      TaskName taskName,\n+      TaskMode taskMode,\n+      File storeBaseDir,\n+      Map<String, StorageEngine> storeToStorageEngines,\n+      Map<String, Set<SystemStreamPartition>> storeToSSPs,\n+      Map<String, SideInputsProcessor> storeToProcessor,\n+      SystemAdmins systemAdmins,\n+      StreamMetadataCache streamMetadataCache,\n+      Clock clock) {\n+    this.taskName = taskName;\n+    this.systemAdmins = systemAdmins;\n+    this.streamMetadataCache = streamMetadataCache;\n+    this.storeToProcessor = storeToProcessor;\n+\n+    this.sspToStores = storeToSSPs.entrySet().stream()\n+        .flatMap(storeAndSSPs -> storeAndSSPs.getValue().stream()\n+            .map(ssp -> new AbstractMap.SimpleImmutableEntry<>(ssp, storeAndSSPs.getKey())))\n+        .collect(Collectors.groupingBy(\n+            Map.Entry::getKey,\n+            Collectors.mapping(Map.Entry::getValue, Collectors.toSet())));\n+\n+    this.taskSideInputStorageManager = new TaskSideInputStorageManager(taskName,\n+        taskMode,\n+        storeBaseDir,\n+        storeToStorageEngines,\n+        storeToSSPs,\n+        clock);\n+\n+    validateProcessorConfiguration();\n+  }\n+\n+  public TaskName getTaskName() {\n+    return this.taskName;\n+  }\n+\n+  public void init() {\n+    this.taskSideInputStorageManager.init();\n+\n+    Map<SystemStreamPartition, String> fileOffsets = taskSideInputStorageManager.getFileOffsets();\n+    this.lastProcessedOffsets.putAll(fileOffsets);\n+    this.startingOffsets = getStartingOffsets(fileOffsets, getOldestOffsets());\n+  }", "originalCommit": "9e6bde0c8c288615330ab88151b3742cc4bb251c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg3ODk1OQ==", "url": "https://github.com/apache/samza/pull/1367#discussion_r430878959", "bodyText": "Ah good catch! No, Probably copy paste error by me. I'll put them back.", "author": "bkonold", "createdAt": "2020-05-27T06:13:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg2MTc1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg2MjM5Mw==", "url": "https://github.com/apache/samza/pull/1367#discussion_r430862393", "bodyText": "where is this getting used? or is it just for logging purposes?", "author": "lakshmi-manasa-g", "createdAt": "2020-05-27T05:19:18Z", "path": "samza-core/src/main/java/org/apache/samza/storage/TaskSideInputStorageManager.java", "diffHunk": "@@ -120,35 +76,32 @@ public void init() {\n     Map<SystemStreamPartition, String> fileOffsets = getFileOffsets();\n     LOG.info(\"File offsets for the task {}: {}\", taskName, fileOffsets);\n ", "originalCommit": "9e6bde0c8c288615330ab88151b3742cc4bb251c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4NDYzNQ==", "url": "https://github.com/apache/samza/pull/1367#discussion_r430884635", "bodyText": "Good point. Nope, not used here. I'll remove this and add the log statement into the handler's init method.", "author": "bkonold", "createdAt": "2020-05-27T06:28:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg2MjM5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg2MjcxNA==", "url": "https://github.com/apache/samza/pull/1367#discussion_r430862714", "bodyText": "Nit: Can you please add the doc for this method that was in the original code. I feel it is helpful", "author": "lakshmi-manasa-g", "createdAt": "2020-05-27T05:20:40Z", "path": "samza-core/src/main/java/org/apache/samza/storage/TaskSideInputHandler.java", "diffHunk": "@@ -0,0 +1,233 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.samza.storage;\n+\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import java.io.File;\n+import java.util.AbstractMap;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+import org.apache.samza.Partition;\n+import org.apache.samza.SamzaException;\n+import org.apache.samza.container.TaskName;\n+import org.apache.samza.job.model.TaskMode;\n+import org.apache.samza.storage.kv.Entry;\n+import org.apache.samza.storage.kv.KeyValueStore;\n+import org.apache.samza.system.IncomingMessageEnvelope;\n+import org.apache.samza.system.StreamMetadataCache;\n+import org.apache.samza.system.SystemAdmins;\n+import org.apache.samza.system.SystemStream;\n+import org.apache.samza.system.SystemStreamMetadata;\n+import org.apache.samza.system.SystemStreamPartition;\n+import org.apache.samza.util.Clock;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import scala.collection.JavaConverters;\n+\n+\n+/**\n+ * This class encapsulates all processing logic / state for all side input SSPs within a task.\n+ */\n+public class TaskSideInputHandler {\n+  private static final Logger LOG = LoggerFactory.getLogger(TaskSideInputHandler.class);\n+\n+  private final StorageManagerUtil storageManagerUtil = new StorageManagerUtil();\n+\n+  private final TaskName taskName;\n+  private final TaskSideInputStorageManager taskSideInputStorageManager;\n+  private final Map<SystemStreamPartition, Set<String>> sspToStores;\n+  private final Map<String, SideInputsProcessor> storeToProcessor;\n+  private final SystemAdmins systemAdmins;\n+  private final StreamMetadataCache streamMetadataCache;\n+  private final Map<SystemStreamPartition, String> lastProcessedOffsets = new ConcurrentHashMap<>();\n+\n+  private Map<SystemStreamPartition, String> startingOffsets;\n+\n+  public TaskSideInputHandler(\n+      TaskName taskName,\n+      TaskMode taskMode,\n+      File storeBaseDir,\n+      Map<String, StorageEngine> storeToStorageEngines,\n+      Map<String, Set<SystemStreamPartition>> storeToSSPs,\n+      Map<String, SideInputsProcessor> storeToProcessor,\n+      SystemAdmins systemAdmins,\n+      StreamMetadataCache streamMetadataCache,\n+      Clock clock) {\n+    this.taskName = taskName;\n+    this.systemAdmins = systemAdmins;\n+    this.streamMetadataCache = streamMetadataCache;\n+    this.storeToProcessor = storeToProcessor;\n+\n+    this.sspToStores = storeToSSPs.entrySet().stream()\n+        .flatMap(storeAndSSPs -> storeAndSSPs.getValue().stream()\n+            .map(ssp -> new AbstractMap.SimpleImmutableEntry<>(ssp, storeAndSSPs.getKey())))\n+        .collect(Collectors.groupingBy(\n+            Map.Entry::getKey,\n+            Collectors.mapping(Map.Entry::getValue, Collectors.toSet())));\n+\n+    this.taskSideInputStorageManager = new TaskSideInputStorageManager(taskName,\n+        taskMode,\n+        storeBaseDir,\n+        storeToStorageEngines,\n+        storeToSSPs,\n+        clock);\n+\n+    validateProcessorConfiguration();\n+  }\n+\n+  public TaskName getTaskName() {\n+    return this.taskName;\n+  }\n+\n+  public void init() {\n+    this.taskSideInputStorageManager.init();\n+\n+    Map<SystemStreamPartition, String> fileOffsets = taskSideInputStorageManager.getFileOffsets();\n+    this.lastProcessedOffsets.putAll(fileOffsets);\n+    this.startingOffsets = getStartingOffsets(fileOffsets, getOldestOffsets());\n+  }\n+\n+  public void process(IncomingMessageEnvelope envelope) {", "originalCommit": "9e6bde0c8c288615330ab88151b3742cc4bb251c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4MDA1OQ==", "url": "https://github.com/apache/samza/pull/1367#discussion_r430880059", "bodyText": "Yes - in fact I will add better javadoc to each method in this class.", "author": "bkonold", "createdAt": "2020-05-27T06:16:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg2MjcxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg2NDc5Mw==", "url": "https://github.com/apache/samza/pull/1367#discussion_r430864793", "bodyText": "Major: I believe this was supposed to be \"synchronized\" so that it is exclusive with flush method. I see that sync is dropped in both the methods for the TaskSideInputHandler but is present in the manager.flush..\nwont it lead to process in handler and flush in manager being parallel?\nis there some change that makes it okay for them to be not exclusive? If so, please call it out.", "author": "lakshmi-manasa-g", "createdAt": "2020-05-27T05:28:50Z", "path": "samza-core/src/main/java/org/apache/samza/storage/TaskSideInputHandler.java", "diffHunk": "@@ -0,0 +1,233 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.samza.storage;\n+\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import java.io.File;\n+import java.util.AbstractMap;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+import org.apache.samza.Partition;\n+import org.apache.samza.SamzaException;\n+import org.apache.samza.container.TaskName;\n+import org.apache.samza.job.model.TaskMode;\n+import org.apache.samza.storage.kv.Entry;\n+import org.apache.samza.storage.kv.KeyValueStore;\n+import org.apache.samza.system.IncomingMessageEnvelope;\n+import org.apache.samza.system.StreamMetadataCache;\n+import org.apache.samza.system.SystemAdmins;\n+import org.apache.samza.system.SystemStream;\n+import org.apache.samza.system.SystemStreamMetadata;\n+import org.apache.samza.system.SystemStreamPartition;\n+import org.apache.samza.util.Clock;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import scala.collection.JavaConverters;\n+\n+\n+/**\n+ * This class encapsulates all processing logic / state for all side input SSPs within a task.\n+ */\n+public class TaskSideInputHandler {\n+  private static final Logger LOG = LoggerFactory.getLogger(TaskSideInputHandler.class);\n+\n+  private final StorageManagerUtil storageManagerUtil = new StorageManagerUtil();\n+\n+  private final TaskName taskName;\n+  private final TaskSideInputStorageManager taskSideInputStorageManager;\n+  private final Map<SystemStreamPartition, Set<String>> sspToStores;\n+  private final Map<String, SideInputsProcessor> storeToProcessor;\n+  private final SystemAdmins systemAdmins;\n+  private final StreamMetadataCache streamMetadataCache;\n+  private final Map<SystemStreamPartition, String> lastProcessedOffsets = new ConcurrentHashMap<>();\n+\n+  private Map<SystemStreamPartition, String> startingOffsets;\n+\n+  public TaskSideInputHandler(\n+      TaskName taskName,\n+      TaskMode taskMode,\n+      File storeBaseDir,\n+      Map<String, StorageEngine> storeToStorageEngines,\n+      Map<String, Set<SystemStreamPartition>> storeToSSPs,\n+      Map<String, SideInputsProcessor> storeToProcessor,\n+      SystemAdmins systemAdmins,\n+      StreamMetadataCache streamMetadataCache,\n+      Clock clock) {\n+    this.taskName = taskName;\n+    this.systemAdmins = systemAdmins;\n+    this.streamMetadataCache = streamMetadataCache;\n+    this.storeToProcessor = storeToProcessor;\n+\n+    this.sspToStores = storeToSSPs.entrySet().stream()\n+        .flatMap(storeAndSSPs -> storeAndSSPs.getValue().stream()\n+            .map(ssp -> new AbstractMap.SimpleImmutableEntry<>(ssp, storeAndSSPs.getKey())))\n+        .collect(Collectors.groupingBy(\n+            Map.Entry::getKey,\n+            Collectors.mapping(Map.Entry::getValue, Collectors.toSet())));\n+\n+    this.taskSideInputStorageManager = new TaskSideInputStorageManager(taskName,\n+        taskMode,\n+        storeBaseDir,\n+        storeToStorageEngines,\n+        storeToSSPs,\n+        clock);\n+\n+    validateProcessorConfiguration();\n+  }\n+\n+  public TaskName getTaskName() {\n+    return this.taskName;\n+  }\n+\n+  public void init() {\n+    this.taskSideInputStorageManager.init();\n+\n+    Map<SystemStreamPartition, String> fileOffsets = taskSideInputStorageManager.getFileOffsets();\n+    this.lastProcessedOffsets.putAll(fileOffsets);\n+    this.startingOffsets = getStartingOffsets(fileOffsets, getOldestOffsets());\n+  }\n+\n+  public void process(IncomingMessageEnvelope envelope) {", "originalCommit": "9e6bde0c8c288615330ab88151b3742cc4bb251c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg4MDY1MA==", "url": "https://github.com/apache/samza/pull/1367#discussion_r430880650", "bodyText": "This is a very good catch. You are correct - I likely got ahead of myself as this synchronization will become unnecessary when side input processing moves into RunLoop. However, as it stands,flush and process within this class still need to be exclusive, and thus require synchronization modifiers.\nThanks for noticing this.", "author": "bkonold", "createdAt": "2020-05-27T06:18:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg2NDc5Mw=="}], "type": "inlineReview"}, {"oid": "7a7523faf419b1c47f7c48dec2729d9a3ce1c755", "url": "https://github.com/apache/samza/commit/7a7523faf419b1c47f7c48dec2729d9a3ce1c755", "message": "Addressing review feedback", "committedDate": "2020-05-27T06:44:38Z", "type": "commit"}, {"oid": "a4f4e43dac69e8ac6dba56b78f1dc0341f478093", "url": "https://github.com/apache/samza/commit/a4f4e43dac69e8ac6dba56b78f1dc0341f478093", "message": "Fixing initialization order of hasSideInputs, and removing use of 'sideInputsPresent()' in favor of direct access of the member variable", "committedDate": "2020-05-28T20:11:03Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTAxNzY5MA==", "url": "https://github.com/apache/samza/pull/1367#discussion_r435017690", "bodyText": "nit: why is separate from the other private fields. If the intention is the separate private final fields that are initialized here, then should lastProcessedOffset moved here?", "author": "mynameborat", "createdAt": "2020-06-04T06:23:30Z", "path": "samza-core/src/main/java/org/apache/samza/storage/TaskSideInputHandler.java", "diffHunk": "@@ -0,0 +1,278 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.samza.storage;\n+\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import java.io.File;\n+import java.util.AbstractMap;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+import org.apache.samza.Partition;\n+import org.apache.samza.SamzaException;\n+import org.apache.samza.container.TaskName;\n+import org.apache.samza.job.model.TaskMode;\n+import org.apache.samza.storage.kv.Entry;\n+import org.apache.samza.storage.kv.KeyValueStore;\n+import org.apache.samza.system.IncomingMessageEnvelope;\n+import org.apache.samza.system.StreamMetadataCache;\n+import org.apache.samza.system.SystemAdmins;\n+import org.apache.samza.system.SystemStream;\n+import org.apache.samza.system.SystemStreamMetadata;\n+import org.apache.samza.system.SystemStreamPartition;\n+import org.apache.samza.util.Clock;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import scala.collection.JavaConverters;\n+\n+\n+/**\n+ * This class encapsulates all processing logic / state for all side input SSPs within a task.\n+ */\n+public class TaskSideInputHandler {\n+  private static final Logger LOG = LoggerFactory.getLogger(TaskSideInputHandler.class);\n+\n+  private final StorageManagerUtil storageManagerUtil = new StorageManagerUtil();\n+\n+  private final TaskName taskName;", "originalCommit": "a4f4e43dac69e8ac6dba56b78f1dc0341f478093", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTA3OTk4OQ==", "url": "https://github.com/apache/samza/pull/1367#discussion_r435079989", "bodyText": "yeah, that was the intent in which case i should move lastProcessedOffsets as well. unless you have any objections", "author": "bkonold", "createdAt": "2020-06-04T08:26:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTAxNzY5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTAxODc3NQ==", "url": "https://github.com/apache/samza/pull/1367#discussion_r435018775", "bodyText": "suggest moving this to the top of the constructor with taking in the stores as parameter to fail fast and prevent initializations.", "author": "mynameborat", "createdAt": "2020-06-04T06:26:16Z", "path": "samza-core/src/main/java/org/apache/samza/storage/TaskSideInputHandler.java", "diffHunk": "@@ -0,0 +1,278 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.samza.storage;\n+\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import java.io.File;\n+import java.util.AbstractMap;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+import org.apache.samza.Partition;\n+import org.apache.samza.SamzaException;\n+import org.apache.samza.container.TaskName;\n+import org.apache.samza.job.model.TaskMode;\n+import org.apache.samza.storage.kv.Entry;\n+import org.apache.samza.storage.kv.KeyValueStore;\n+import org.apache.samza.system.IncomingMessageEnvelope;\n+import org.apache.samza.system.StreamMetadataCache;\n+import org.apache.samza.system.SystemAdmins;\n+import org.apache.samza.system.SystemStream;\n+import org.apache.samza.system.SystemStreamMetadata;\n+import org.apache.samza.system.SystemStreamPartition;\n+import org.apache.samza.util.Clock;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import scala.collection.JavaConverters;\n+\n+\n+/**\n+ * This class encapsulates all processing logic / state for all side input SSPs within a task.\n+ */\n+public class TaskSideInputHandler {\n+  private static final Logger LOG = LoggerFactory.getLogger(TaskSideInputHandler.class);\n+\n+  private final StorageManagerUtil storageManagerUtil = new StorageManagerUtil();\n+\n+  private final TaskName taskName;\n+  private final TaskSideInputStorageManager taskSideInputStorageManager;\n+  private final Map<SystemStreamPartition, Set<String>> sspToStores;\n+  private final Map<String, SideInputsProcessor> storeToProcessor;\n+  private final SystemAdmins systemAdmins;\n+  private final StreamMetadataCache streamMetadataCache;\n+  private final Map<SystemStreamPartition, String> lastProcessedOffsets = new ConcurrentHashMap<>();\n+\n+  private Map<SystemStreamPartition, String> startingOffsets;\n+\n+  public TaskSideInputHandler(\n+      TaskName taskName,\n+      TaskMode taskMode,\n+      File storeBaseDir,\n+      Map<String, StorageEngine> storeToStorageEngines,\n+      Map<String, Set<SystemStreamPartition>> storeToSSPs,\n+      Map<String, SideInputsProcessor> storeToProcessor,\n+      SystemAdmins systemAdmins,\n+      StreamMetadataCache streamMetadataCache,\n+      Clock clock) {\n+    this.taskName = taskName;\n+    this.systemAdmins = systemAdmins;\n+    this.streamMetadataCache = streamMetadataCache;\n+    this.storeToProcessor = storeToProcessor;\n+\n+    this.sspToStores = storeToSSPs.entrySet().stream()\n+        .flatMap(storeAndSSPs -> storeAndSSPs.getValue().stream()\n+            .map(ssp -> new AbstractMap.SimpleImmutableEntry<>(ssp, storeAndSSPs.getKey())))\n+        .collect(Collectors.groupingBy(\n+            Map.Entry::getKey,\n+            Collectors.mapping(Map.Entry::getValue, Collectors.toSet())));\n+\n+    this.taskSideInputStorageManager = new TaskSideInputStorageManager(taskName,\n+        taskMode,\n+        storeBaseDir,\n+        storeToStorageEngines,\n+        storeToSSPs,\n+        clock);\n+\n+    validateProcessorConfiguration();", "originalCommit": "a4f4e43dac69e8ac6dba56b78f1dc0341f478093", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTExMzkxNg==", "url": "https://github.com/apache/samza/pull/1367#discussion_r435113916", "bodyText": "agree, i will do the same in TaskSideInputStorageManager as well since that validation also happens at the end of the constructor and doesn't need to.", "author": "bkonold", "createdAt": "2020-06-04T09:22:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTAxODc3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTAyMzAzOQ==", "url": "https://github.com/apache/samza/pull/1367#discussion_r435023039", "bodyText": "Can we synchronize on a specific block or just make lastProcessedOffsets a thread safe data structure?\nIf no to both, can you add a documentation to clarify that?", "author": "mynameborat", "createdAt": "2020-06-04T06:37:10Z", "path": "samza-core/src/main/java/org/apache/samza/storage/TaskSideInputHandler.java", "diffHunk": "@@ -0,0 +1,278 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.samza.storage;\n+\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import java.io.File;\n+import java.util.AbstractMap;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+import org.apache.samza.Partition;\n+import org.apache.samza.SamzaException;\n+import org.apache.samza.container.TaskName;\n+import org.apache.samza.job.model.TaskMode;\n+import org.apache.samza.storage.kv.Entry;\n+import org.apache.samza.storage.kv.KeyValueStore;\n+import org.apache.samza.system.IncomingMessageEnvelope;\n+import org.apache.samza.system.StreamMetadataCache;\n+import org.apache.samza.system.SystemAdmins;\n+import org.apache.samza.system.SystemStream;\n+import org.apache.samza.system.SystemStreamMetadata;\n+import org.apache.samza.system.SystemStreamPartition;\n+import org.apache.samza.util.Clock;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import scala.collection.JavaConverters;\n+\n+\n+/**\n+ * This class encapsulates all processing logic / state for all side input SSPs within a task.\n+ */\n+public class TaskSideInputHandler {\n+  private static final Logger LOG = LoggerFactory.getLogger(TaskSideInputHandler.class);\n+\n+  private final StorageManagerUtil storageManagerUtil = new StorageManagerUtil();\n+\n+  private final TaskName taskName;\n+  private final TaskSideInputStorageManager taskSideInputStorageManager;\n+  private final Map<SystemStreamPartition, Set<String>> sspToStores;\n+  private final Map<String, SideInputsProcessor> storeToProcessor;\n+  private final SystemAdmins systemAdmins;\n+  private final StreamMetadataCache streamMetadataCache;\n+  private final Map<SystemStreamPartition, String> lastProcessedOffsets = new ConcurrentHashMap<>();\n+\n+  private Map<SystemStreamPartition, String> startingOffsets;\n+\n+  public TaskSideInputHandler(\n+      TaskName taskName,\n+      TaskMode taskMode,\n+      File storeBaseDir,\n+      Map<String, StorageEngine> storeToStorageEngines,\n+      Map<String, Set<SystemStreamPartition>> storeToSSPs,\n+      Map<String, SideInputsProcessor> storeToProcessor,\n+      SystemAdmins systemAdmins,\n+      StreamMetadataCache streamMetadataCache,\n+      Clock clock) {\n+    this.taskName = taskName;\n+    this.systemAdmins = systemAdmins;\n+    this.streamMetadataCache = streamMetadataCache;\n+    this.storeToProcessor = storeToProcessor;\n+\n+    this.sspToStores = storeToSSPs.entrySet().stream()\n+        .flatMap(storeAndSSPs -> storeAndSSPs.getValue().stream()\n+            .map(ssp -> new AbstractMap.SimpleImmutableEntry<>(ssp, storeAndSSPs.getKey())))\n+        .collect(Collectors.groupingBy(\n+            Map.Entry::getKey,\n+            Collectors.mapping(Map.Entry::getValue, Collectors.toSet())));\n+\n+    this.taskSideInputStorageManager = new TaskSideInputStorageManager(taskName,\n+        taskMode,\n+        storeBaseDir,\n+        storeToStorageEngines,\n+        storeToSSPs,\n+        clock);\n+\n+    validateProcessorConfiguration();\n+  }\n+\n+  /**\n+   * The {@link TaskName} associated with this {@link TaskSideInputHandler}\n+   *\n+   * @return the task name for this handler\n+   */\n+  public TaskName getTaskName() {\n+    return this.taskName;\n+  }\n+\n+  /**\n+   * Initializes the underlying {@link TaskSideInputStorageManager} and determines starting offsets for each SSP.\n+   */\n+  public void init() {\n+    this.taskSideInputStorageManager.init();\n+\n+    Map<SystemStreamPartition, String> fileOffsets = this.taskSideInputStorageManager.getFileOffsets();\n+    LOG.info(\"File offsets for the task {}: {}\", taskName, fileOffsets);\n+\n+    this.lastProcessedOffsets.putAll(fileOffsets);\n+    LOG.info(\"Last processed offsets for the task {}: {}\", taskName, lastProcessedOffsets);\n+\n+    this.startingOffsets = getStartingOffsets(fileOffsets, getOldestOffsets());\n+    LOG.info(\"Starting offsets for the task {}: {}\", taskName, startingOffsets);\n+  }\n+\n+  /**\n+   * Processes the incoming side input message envelope and updates the last processed offset for its SSP.\n+   * Synchronized inorder to be exclusive with flush().\n+   *\n+   * @param envelope incoming envelope to be processed\n+   */\n+  public synchronized void process(IncomingMessageEnvelope envelope) {", "originalCommit": "a4f4e43dac69e8ac6dba56b78f1dc0341f478093", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTE0ODAxMA==", "url": "https://github.com/apache/samza/pull/1367#discussion_r435148010", "bodyText": "i was only preserving the existing synchronization so don't know full context, but it appears to be necessary since flush and process are currently invoked from different threads concurrently. seems to imply that the rational was so that writeOffsetFiles would write the same offset for SSPs shared between stores. so i don't think lastProcessedOffsets being thread-safe is enough. in fact, i don't think it needs to be thread-safe at all since init and all process calls are exclusive from one another.", "author": "bkonold", "createdAt": "2020-06-04T10:19:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTAyMzAzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2MDIxMg==", "url": "https://github.com/apache/samza/pull/1367#discussion_r437760212", "bodyText": "will revisit in subsequent PR", "author": "bkonold", "createdAt": "2020-06-09T22:36:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTAyMzAzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTAyNjMzNw==", "url": "https://github.com/apache/samza/pull/1367#discussion_r435026337", "bodyText": "I might have forgotten the need for synchronization between flush & process. If it is related to lastProcessedOffsets then we may have to do it in other places too.\nOr, if it is related to access to taskSideInputStorageManager because of lack of thread safety of that class.\nEither way, stop looks like it requires synchronization.", "author": "mynameborat", "createdAt": "2020-06-04T06:45:10Z", "path": "samza-core/src/main/java/org/apache/samza/storage/TaskSideInputHandler.java", "diffHunk": "@@ -0,0 +1,278 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.samza.storage;\n+\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import java.io.File;\n+import java.util.AbstractMap;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+import org.apache.samza.Partition;\n+import org.apache.samza.SamzaException;\n+import org.apache.samza.container.TaskName;\n+import org.apache.samza.job.model.TaskMode;\n+import org.apache.samza.storage.kv.Entry;\n+import org.apache.samza.storage.kv.KeyValueStore;\n+import org.apache.samza.system.IncomingMessageEnvelope;\n+import org.apache.samza.system.StreamMetadataCache;\n+import org.apache.samza.system.SystemAdmins;\n+import org.apache.samza.system.SystemStream;\n+import org.apache.samza.system.SystemStreamMetadata;\n+import org.apache.samza.system.SystemStreamPartition;\n+import org.apache.samza.util.Clock;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import scala.collection.JavaConverters;\n+\n+\n+/**\n+ * This class encapsulates all processing logic / state for all side input SSPs within a task.\n+ */\n+public class TaskSideInputHandler {\n+  private static final Logger LOG = LoggerFactory.getLogger(TaskSideInputHandler.class);\n+\n+  private final StorageManagerUtil storageManagerUtil = new StorageManagerUtil();\n+\n+  private final TaskName taskName;\n+  private final TaskSideInputStorageManager taskSideInputStorageManager;\n+  private final Map<SystemStreamPartition, Set<String>> sspToStores;\n+  private final Map<String, SideInputsProcessor> storeToProcessor;\n+  private final SystemAdmins systemAdmins;\n+  private final StreamMetadataCache streamMetadataCache;\n+  private final Map<SystemStreamPartition, String> lastProcessedOffsets = new ConcurrentHashMap<>();\n+\n+  private Map<SystemStreamPartition, String> startingOffsets;\n+\n+  public TaskSideInputHandler(\n+      TaskName taskName,\n+      TaskMode taskMode,\n+      File storeBaseDir,\n+      Map<String, StorageEngine> storeToStorageEngines,\n+      Map<String, Set<SystemStreamPartition>> storeToSSPs,\n+      Map<String, SideInputsProcessor> storeToProcessor,\n+      SystemAdmins systemAdmins,\n+      StreamMetadataCache streamMetadataCache,\n+      Clock clock) {\n+    this.taskName = taskName;\n+    this.systemAdmins = systemAdmins;\n+    this.streamMetadataCache = streamMetadataCache;\n+    this.storeToProcessor = storeToProcessor;\n+\n+    this.sspToStores = storeToSSPs.entrySet().stream()\n+        .flatMap(storeAndSSPs -> storeAndSSPs.getValue().stream()\n+            .map(ssp -> new AbstractMap.SimpleImmutableEntry<>(ssp, storeAndSSPs.getKey())))\n+        .collect(Collectors.groupingBy(\n+            Map.Entry::getKey,\n+            Collectors.mapping(Map.Entry::getValue, Collectors.toSet())));\n+\n+    this.taskSideInputStorageManager = new TaskSideInputStorageManager(taskName,\n+        taskMode,\n+        storeBaseDir,\n+        storeToStorageEngines,\n+        storeToSSPs,\n+        clock);\n+\n+    validateProcessorConfiguration();\n+  }\n+\n+  /**\n+   * The {@link TaskName} associated with this {@link TaskSideInputHandler}\n+   *\n+   * @return the task name for this handler\n+   */\n+  public TaskName getTaskName() {\n+    return this.taskName;\n+  }\n+\n+  /**\n+   * Initializes the underlying {@link TaskSideInputStorageManager} and determines starting offsets for each SSP.\n+   */\n+  public void init() {\n+    this.taskSideInputStorageManager.init();\n+\n+    Map<SystemStreamPartition, String> fileOffsets = this.taskSideInputStorageManager.getFileOffsets();\n+    LOG.info(\"File offsets for the task {}: {}\", taskName, fileOffsets);\n+\n+    this.lastProcessedOffsets.putAll(fileOffsets);\n+    LOG.info(\"Last processed offsets for the task {}: {}\", taskName, lastProcessedOffsets);\n+\n+    this.startingOffsets = getStartingOffsets(fileOffsets, getOldestOffsets());\n+    LOG.info(\"Starting offsets for the task {}: {}\", taskName, startingOffsets);\n+  }\n+\n+  /**\n+   * Processes the incoming side input message envelope and updates the last processed offset for its SSP.\n+   * Synchronized inorder to be exclusive with flush().\n+   *\n+   * @param envelope incoming envelope to be processed\n+   */\n+  public synchronized void process(IncomingMessageEnvelope envelope) {\n+    SystemStreamPartition envelopeSSP = envelope.getSystemStreamPartition();\n+    String envelopeOffset = envelope.getOffset();\n+\n+    for (String store: this.sspToStores.get(envelopeSSP)) {\n+      SideInputsProcessor storeProcessor = this.storeToProcessor.get(store);\n+      KeyValueStore keyValueStore = (KeyValueStore) this.taskSideInputStorageManager.getStore(store);\n+      Collection<Entry<?, ?>> entriesToBeWritten = storeProcessor.process(envelope, keyValueStore);\n+\n+      // TODO: SAMZA-2255: optimize writes to side input stores\n+      for (Entry entry : entriesToBeWritten) {\n+        // If the key is null we ignore, if the value is null, we issue a delete, else we issue a put\n+        if (entry.getKey() != null) {\n+          if (entry.getValue() != null) {\n+            keyValueStore.put(entry.getKey(), entry.getValue());\n+          } else {\n+            keyValueStore.delete(entry.getKey());\n+          }\n+        }\n+      }\n+    }\n+\n+    this.lastProcessedOffsets.put(envelopeSSP, envelopeOffset);\n+  }\n+\n+  /**\n+   * Flushes the underlying {@link TaskSideInputStorageManager}\n+   * Synchronized inorder to be exclusive with process()\n+   */\n+  public synchronized void flush() {\n+    this.taskSideInputStorageManager.flush(this.lastProcessedOffsets);\n+  }\n+\n+  /**\n+   * Gets the starting offset for the given side input {@link SystemStreamPartition}.\n+   *\n+   * Note: The method doesn't respect {@link org.apache.samza.config.StreamConfig#CONSUMER_OFFSET_DEFAULT} and\n+   * {@link org.apache.samza.config.StreamConfig#CONSUMER_RESET_OFFSET} configurations. It will use the local offset\n+   * file if it is valid, else it will fall back to oldest offset in the stream.\n+   *\n+   * @param ssp side input system stream partition to get the starting offset for\n+   * @return the starting offset\n+   */\n+  public String getStartingOffset(SystemStreamPartition ssp) {\n+    return this.startingOffsets.get(ssp);\n+  }\n+\n+  /**\n+   * Gets the last processed offset for the given side input {@link SystemStreamPartition}.\n+   *\n+   * @param ssp side input system stream partition to get the last processed offset for\n+   * @return the last processed offset\n+   */\n+  public String getLastProcessedOffset(SystemStreamPartition ssp) {\n+    return this.lastProcessedOffsets.get(ssp);\n+  }\n+\n+  /**\n+   * Stops the underlying storage manager at the last processed offsets.\n+   */\n+  public void stop() {", "originalCommit": "a4f4e43dac69e8ac6dba56b78f1dc0341f478093", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTE0OTQyNA==", "url": "https://github.com/apache/samza/pull/1367#discussion_r435149424", "bodyText": "i don't think stop requires synchronization? CSM will have ceased interaction with the instance before invoking stop, so there will be nothing else to synchronize between. though i should probably doc that precondition", "author": "bkonold", "createdAt": "2020-06-04T10:22:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTAyNjMzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTAyOTcxOQ==", "url": "https://github.com/apache/samza/pull/1367#discussion_r435029719", "bodyText": "Prefer to keep the old way of initializing this\nthis.sspsToStores = new HashMap<>();\t  \n    storesToSSPs.forEach((store, ssps) -> {\t  \n        for (SystemStreamPartition ssp: ssps) {\t    \n          sspsToStores.computeIfAbsent(ssp, key -> new HashSet<>());\t\n          sspsToStores.computeIfPresent(ssp, (key, value) -> {\t\n              value.add(store);\t\n              return value;\t\n            });\t\n        }\t\n      });\n\nas its much more readable and simpler.", "author": "mynameborat", "createdAt": "2020-06-04T06:52:52Z", "path": "samza-core/src/main/java/org/apache/samza/storage/TaskSideInputHandler.java", "diffHunk": "@@ -0,0 +1,278 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.samza.storage;\n+\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import java.io.File;\n+import java.util.AbstractMap;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+import org.apache.samza.Partition;\n+import org.apache.samza.SamzaException;\n+import org.apache.samza.container.TaskName;\n+import org.apache.samza.job.model.TaskMode;\n+import org.apache.samza.storage.kv.Entry;\n+import org.apache.samza.storage.kv.KeyValueStore;\n+import org.apache.samza.system.IncomingMessageEnvelope;\n+import org.apache.samza.system.StreamMetadataCache;\n+import org.apache.samza.system.SystemAdmins;\n+import org.apache.samza.system.SystemStream;\n+import org.apache.samza.system.SystemStreamMetadata;\n+import org.apache.samza.system.SystemStreamPartition;\n+import org.apache.samza.util.Clock;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import scala.collection.JavaConverters;\n+\n+\n+/**\n+ * This class encapsulates all processing logic / state for all side input SSPs within a task.\n+ */\n+public class TaskSideInputHandler {\n+  private static final Logger LOG = LoggerFactory.getLogger(TaskSideInputHandler.class);\n+\n+  private final StorageManagerUtil storageManagerUtil = new StorageManagerUtil();\n+\n+  private final TaskName taskName;\n+  private final TaskSideInputStorageManager taskSideInputStorageManager;\n+  private final Map<SystemStreamPartition, Set<String>> sspToStores;\n+  private final Map<String, SideInputsProcessor> storeToProcessor;\n+  private final SystemAdmins systemAdmins;\n+  private final StreamMetadataCache streamMetadataCache;\n+  private final Map<SystemStreamPartition, String> lastProcessedOffsets = new ConcurrentHashMap<>();\n+\n+  private Map<SystemStreamPartition, String> startingOffsets;\n+\n+  public TaskSideInputHandler(\n+      TaskName taskName,\n+      TaskMode taskMode,\n+      File storeBaseDir,\n+      Map<String, StorageEngine> storeToStorageEngines,\n+      Map<String, Set<SystemStreamPartition>> storeToSSPs,\n+      Map<String, SideInputsProcessor> storeToProcessor,\n+      SystemAdmins systemAdmins,\n+      StreamMetadataCache streamMetadataCache,\n+      Clock clock) {\n+    this.taskName = taskName;\n+    this.systemAdmins = systemAdmins;\n+    this.streamMetadataCache = streamMetadataCache;\n+    this.storeToProcessor = storeToProcessor;\n+\n+    this.sspToStores = storeToSSPs.entrySet().stream()\n+        .flatMap(storeAndSSPs -> storeAndSSPs.getValue().stream()\n+            .map(ssp -> new AbstractMap.SimpleImmutableEntry<>(ssp, storeAndSSPs.getKey())))\n+        .collect(Collectors.groupingBy(\n+            Map.Entry::getKey,\n+            Collectors.mapping(Map.Entry::getValue, Collectors.toSet())));\n+", "originalCommit": "a4f4e43dac69e8ac6dba56b78f1dc0341f478093", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTExMTg3OQ==", "url": "https://github.com/apache/samza/pull/1367#discussion_r435111879", "bodyText": "no strong feelings on this. generally i favor streams over imperative when it comes to transforms as i find them easier to conceptualize and less error-prone since they make any modification of the source explicit.\nfine reverting... but interested to hear any additional thoughts you have", "author": "bkonold", "createdAt": "2020-06-04T09:18:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTAyOTcxOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU5Njg4NA==", "url": "https://github.com/apache/samza/pull/1367#discussion_r435596884", "bodyText": "per offline conversation will revert this", "author": "bkonold", "createdAt": "2020-06-04T22:57:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTAyOTcxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTAzNTYxNg==", "url": "https://github.com/apache/samza/pull/1367#discussion_r435035616", "bodyText": "why are we constructing the storage manager here? why not have the CSM pass the constructed storage manager to the handler?", "author": "mynameborat", "createdAt": "2020-06-04T07:05:14Z", "path": "samza-core/src/main/java/org/apache/samza/storage/TaskSideInputHandler.java", "diffHunk": "@@ -0,0 +1,278 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.samza.storage;\n+\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import java.io.File;\n+import java.util.AbstractMap;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+import org.apache.samza.Partition;\n+import org.apache.samza.SamzaException;\n+import org.apache.samza.container.TaskName;\n+import org.apache.samza.job.model.TaskMode;\n+import org.apache.samza.storage.kv.Entry;\n+import org.apache.samza.storage.kv.KeyValueStore;\n+import org.apache.samza.system.IncomingMessageEnvelope;\n+import org.apache.samza.system.StreamMetadataCache;\n+import org.apache.samza.system.SystemAdmins;\n+import org.apache.samza.system.SystemStream;\n+import org.apache.samza.system.SystemStreamMetadata;\n+import org.apache.samza.system.SystemStreamPartition;\n+import org.apache.samza.util.Clock;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import scala.collection.JavaConverters;\n+\n+\n+/**\n+ * This class encapsulates all processing logic / state for all side input SSPs within a task.\n+ */\n+public class TaskSideInputHandler {\n+  private static final Logger LOG = LoggerFactory.getLogger(TaskSideInputHandler.class);\n+\n+  private final StorageManagerUtil storageManagerUtil = new StorageManagerUtil();\n+\n+  private final TaskName taskName;\n+  private final TaskSideInputStorageManager taskSideInputStorageManager;\n+  private final Map<SystemStreamPartition, Set<String>> sspToStores;\n+  private final Map<String, SideInputsProcessor> storeToProcessor;\n+  private final SystemAdmins systemAdmins;\n+  private final StreamMetadataCache streamMetadataCache;\n+  private final Map<SystemStreamPartition, String> lastProcessedOffsets = new ConcurrentHashMap<>();\n+\n+  private Map<SystemStreamPartition, String> startingOffsets;\n+\n+  public TaskSideInputHandler(\n+      TaskName taskName,\n+      TaskMode taskMode,\n+      File storeBaseDir,\n+      Map<String, StorageEngine> storeToStorageEngines,\n+      Map<String, Set<SystemStreamPartition>> storeToSSPs,\n+      Map<String, SideInputsProcessor> storeToProcessor,\n+      SystemAdmins systemAdmins,\n+      StreamMetadataCache streamMetadataCache,\n+      Clock clock) {\n+    this.taskName = taskName;\n+    this.systemAdmins = systemAdmins;\n+    this.streamMetadataCache = streamMetadataCache;\n+    this.storeToProcessor = storeToProcessor;\n+\n+    this.sspToStores = storeToSSPs.entrySet().stream()\n+        .flatMap(storeAndSSPs -> storeAndSSPs.getValue().stream()\n+            .map(ssp -> new AbstractMap.SimpleImmutableEntry<>(ssp, storeAndSSPs.getKey())))\n+        .collect(Collectors.groupingBy(\n+            Map.Entry::getKey,\n+            Collectors.mapping(Map.Entry::getValue, Collectors.toSet())));\n+\n+    this.taskSideInputStorageManager = new TaskSideInputStorageManager(taskName,\n+        taskMode,\n+        storeBaseDir,\n+        storeToStorageEngines,\n+        storeToSSPs,\n+        clock);", "originalCommit": "a4f4e43dac69e8ac6dba56b78f1dc0341f478093", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTA5NjAxNA==", "url": "https://github.com/apache/samza/pull/1367#discussion_r435096014", "bodyText": "ended up moving since CSM had otherwise no reason to keep track of the instance and i thought it better encapsulated lifecycle management (e.g. CSM can't mistakenly hold on to an instance that has been closed)\ni may actually end up moving this back out depending on particular impl details when i move side input processing onto RunLoop. i may end up sharing the storage manager instances across the handler class and a new class which implements RunLoopTask\nwhat are your thoughts for/against? if this is relatively inconsequential, i suggest we table this as it's likely to change again in a subsequent PR.", "author": "bkonold", "createdAt": "2020-06-04T08:52:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTAzNTYxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTAzNTk0Mg==", "url": "https://github.com/apache/samza/pull/1367#discussion_r435035942", "bodyText": "replace with actual imports.", "author": "mynameborat", "createdAt": "2020-06-04T07:05:58Z", "path": "samza-core/src/test/java/org/apache/samza/storage/TestTaskSideInputHandler.java", "diffHunk": "@@ -0,0 +1,197 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.samza.storage;\n+\n+import java.io.File;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+import org.apache.samza.Partition;\n+import org.apache.samza.container.TaskName;\n+import org.apache.samza.job.model.TaskMode;\n+import org.apache.samza.system.StreamMetadataCache;\n+import org.apache.samza.system.SystemAdmin;\n+import org.apache.samza.system.SystemAdmins;\n+import org.apache.samza.system.SystemStream;\n+import org.apache.samza.system.SystemStreamMetadata;\n+import org.apache.samza.system.SystemStreamPartition;\n+import org.apache.samza.util.Clock;\n+import org.apache.samza.util.ScalaJavaUtil;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import static org.junit.Assert.*;\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Mockito.*;", "originalCommit": "a4f4e43dac69e8ac6dba56b78f1dc0341f478093", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTEzMTkwMg==", "url": "https://github.com/apache/samza/pull/1367#discussion_r435131902", "bodyText": "fwiw i see a lot of usage of both styles, * static import and per method\nwill change", "author": "bkonold", "createdAt": "2020-06-04T09:52:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTAzNTk0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTA0MjE4Ng==", "url": "https://github.com/apache/samza/pull/1367#discussion_r435042186", "bodyText": "minor: prefer to use method reference.\nif you choose to, please do in the rest of places as well.", "author": "mynameborat", "createdAt": "2020-06-04T07:18:55Z", "path": "samza-core/src/main/scala/org/apache/samza/storage/ContainerStorageManager.java", "diffHunk": "@@ -714,15 +729,15 @@ private void startSideInputs() {\n     LOG.info(\"SideInput Restore started\");\n \n     // initialize the sideInputStorageManagers\n-    getSideInputStorageManagers().forEach(sideInputStorageManager -> sideInputStorageManager.init());\n+    getSideInputHandlers().forEach(handler -> handler.init());", "originalCommit": "a4f4e43dac69e8ac6dba56b78f1dc0341f478093", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTEyNjQzNA==", "url": "https://github.com/apache/samza/pull/1367#discussion_r435126434", "bodyText": "agree - left this alone initially to try to minimize changes. will use reference instead", "author": "bkonold", "createdAt": "2020-06-04T09:43:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTA0MjE4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTA0NjAxMw==", "url": "https://github.com/apache/samza/pull/1367#discussion_r435046013", "bodyText": "can we give a meaningful name instead of systems? I see the call site passes containerSideInputSystems and containerChangelogSystems. so maybe keep storeSystems or anything that conveys more information than systems :)", "author": "mynameborat", "createdAt": "2020-06-04T07:25:53Z", "path": "samza-core/src/main/scala/org/apache/samza/storage/ContainerStorageManager.java", "diffHunk": "@@ -329,18 +345,14 @@ public ContainerStorageManager(\n   /**\n    *  Creates SystemConsumer objects for store restoration, creating one consumer per system.\n    */\n-  private static Map<String, SystemConsumer> createConsumers(Map<String, Set<SystemStream>> systemStreams,\n+  private static Map<String, SystemConsumer> createConsumers(Set<String> systems,", "originalCommit": "a4f4e43dac69e8ac6dba56b78f1dc0341f478093", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTEyNTQ2OQ==", "url": "https://github.com/apache/samza/pull/1367#discussion_r435125469", "bodyText": "sure, i'll keep storeSystems", "author": "bkonold", "createdAt": "2020-06-04T09:41:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTA0NjAxMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTA1Mjk2MA==", "url": "https://github.com/apache/samza/pull/1367#discussion_r435052960", "bodyText": "You have single line parameter pattern here but modified from the single line pattern of constructor to few lines of constructor in the storage manager.\nI'd prefer this to also follow the suit of TaskSideInputStorageManager since that is concise and having a breakdown of parameter per line doesn't add too much value in constructor.", "author": "mynameborat", "createdAt": "2020-06-04T07:39:08Z", "path": "samza-core/src/main/java/org/apache/samza/storage/TaskSideInputHandler.java", "diffHunk": "@@ -0,0 +1,278 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.samza.storage;\n+\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import java.io.File;\n+import java.util.AbstractMap;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.stream.Collectors;\n+import org.apache.samza.Partition;\n+import org.apache.samza.SamzaException;\n+import org.apache.samza.container.TaskName;\n+import org.apache.samza.job.model.TaskMode;\n+import org.apache.samza.storage.kv.Entry;\n+import org.apache.samza.storage.kv.KeyValueStore;\n+import org.apache.samza.system.IncomingMessageEnvelope;\n+import org.apache.samza.system.StreamMetadataCache;\n+import org.apache.samza.system.SystemAdmins;\n+import org.apache.samza.system.SystemStream;\n+import org.apache.samza.system.SystemStreamMetadata;\n+import org.apache.samza.system.SystemStreamPartition;\n+import org.apache.samza.util.Clock;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import scala.collection.JavaConverters;\n+\n+\n+/**\n+ * This class encapsulates all processing logic / state for all side input SSPs within a task.\n+ */\n+public class TaskSideInputHandler {\n+  private static final Logger LOG = LoggerFactory.getLogger(TaskSideInputHandler.class);\n+\n+  private final StorageManagerUtil storageManagerUtil = new StorageManagerUtil();\n+\n+  private final TaskName taskName;\n+  private final TaskSideInputStorageManager taskSideInputStorageManager;\n+  private final Map<SystemStreamPartition, Set<String>> sspToStores;\n+  private final Map<String, SideInputsProcessor> storeToProcessor;\n+  private final SystemAdmins systemAdmins;\n+  private final StreamMetadataCache streamMetadataCache;\n+  private final Map<SystemStreamPartition, String> lastProcessedOffsets = new ConcurrentHashMap<>();\n+\n+  private Map<SystemStreamPartition, String> startingOffsets;\n+\n+  public TaskSideInputHandler(\n+      TaskName taskName,\n+      TaskMode taskMode,\n+      File storeBaseDir,\n+      Map<String, StorageEngine> storeToStorageEngines,\n+      Map<String, Set<SystemStreamPartition>> storeToSSPs,\n+      Map<String, SideInputsProcessor> storeToProcessor,\n+      SystemAdmins systemAdmins,\n+      StreamMetadataCache streamMetadataCache,\n+      Clock clock) {", "originalCommit": "a4f4e43dac69e8ac6dba56b78f1dc0341f478093", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTA4MjQ2OA==", "url": "https://github.com/apache/samza/pull/1367#discussion_r435082468", "bodyText": "that's fine. i think what probably happened was i did a \"change signature\" refactor with intellij that changed the formatting in the storage manager class. personally i prefer single line for readability, but don't have a strong opinion.\ni do think though that we should some sort of style pattern guidelines as part of open source docs - i don't see any there now.", "author": "bkonold", "createdAt": "2020-06-04T08:30:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTA1Mjk2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTA1NDY3NA==", "url": "https://github.com/apache/samza/pull/1367#discussion_r435054674", "bodyText": "nit: now that you are changing the signature anyways, can we rename this to writeFileOffsets so that is consistent with getFileOffsets.\nwhat do you think?", "author": "mynameborat", "createdAt": "2020-06-04T07:42:29Z", "path": "samza-core/src/main/java/org/apache/samza/storage/TaskSideInputStorageManager.java", "diffHunk": "@@ -258,9 +142,10 @@ private void initializeStoreDirectories() {\n   /**\n    * Writes the offset files for all side input stores one by one. There is one offset file per store.\n    * Its contents are a JSON encoded mapping from each side input SSP to its last processed offset, and a checksum.\n+   *\n+   * @param lastProcessedOffsets The offset per SSP to write\n    */\n-  @VisibleForTesting\n-  void writeOffsetFiles() {\n+  public void writeOffsetFiles(Map<SystemStreamPartition, String> lastProcessedOffsets) {", "originalCommit": "a4f4e43dac69e8ac6dba56b78f1dc0341f478093", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTExNjQ2Nw==", "url": "https://github.com/apache/samza/pull/1367#discussion_r435116467", "bodyText": "sure, good suggestion. i'll change the name", "author": "bkonold", "createdAt": "2020-06-04T09:26:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTA1NDY3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTA1NTkxMg==", "url": "https://github.com/apache/samza/pull/1367#discussion_r435055912", "bodyText": "what happens if it is executed after initialization?\nIf you really expect this to be only executed once before init, should we have a precondition check and throw exception to explicitly warn about the consequence of this being invoked multiple times?", "author": "mynameborat", "createdAt": "2020-06-04T07:44:52Z", "path": "samza-core/src/main/java/org/apache/samza/storage/TaskSideInputStorageManager.java", "diffHunk": "@@ -279,13 +164,12 @@ void writeOffsetFiles() {\n   }\n \n   /**\n-   * Gets the side input SSP offsets for all stores from their local offset files.\n+   * Gets the side input SSP offsets for all stores from their local offset files. This method should be executed only\n+   * once at class initialization.", "originalCommit": "a4f4e43dac69e8ac6dba56b78f1dc0341f478093", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTEyMTYxMg==", "url": "https://github.com/apache/samza/pull/1367#discussion_r435121612", "bodyText": "ah, i think i should actually remove this. there is no problem calling multiple times. at some point when writing this refactor i was unsure what the contract of this would be with TaskSideInputHandler when it came to initialization and wrote this comment. but all this does is read the offset files - caller can do as they please.", "author": "bkonold", "createdAt": "2020-06-04T09:34:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTA1NTkxMg=="}], "type": "inlineReview"}, {"oid": "a56bbd9f130a8257ad40ea5700c9413fca3f9ada", "url": "https://github.com/apache/samza/commit/a56bbd9f130a8257ad40ea5700c9413fca3f9ada", "message": "Addressing most review feedback", "committedDate": "2020-06-04T10:48:58Z", "type": "commit"}, {"oid": "773aa6c95394c120a6250c361f17f28ebd4c0590", "url": "https://github.com/apache/samza/commit/773aa6c95394c120a6250c361f17f28ebd4c0590", "message": "Reverting to imperative style initialization of sspToStores and adding docs to #stop", "committedDate": "2020-06-08T20:22:26Z", "type": "commit"}, {"oid": "db1194f80d9ac9f174931bcf957c932124233f2f", "url": "https://github.com/apache/samza/commit/db1194f80d9ac9f174931bcf957c932124233f2f", "message": "formatting", "committedDate": "2020-06-08T20:34:14Z", "type": "commit"}]}