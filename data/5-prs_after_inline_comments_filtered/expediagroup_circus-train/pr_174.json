{"pr_number": 174, "pr_title": "Issue 173 struct evolution", "pr_createdAt": "2020-03-10T16:35:10Z", "pr_url": "https://github.com/ExpediaGroup/circus-train/pull/174", "timeline": [{"oid": "25560f7f63641462582e51dd0683885f044a8770", "url": "https://github.com/ExpediaGroup/circus-train/commit/25560f7f63641462582e51dd0683885f044a8770", "message": "Initial commit with flakey test", "committedDate": "2020-03-05T16:41:40Z", "type": "commit"}, {"oid": "0000ac52659bc5f568298aade29a6bbf34c0469f", "url": "https://github.com/ExpediaGroup/circus-train/commit/0000ac52659bc5f568298aade29a6bbf34c0469f", "message": "Updates to test", "committedDate": "2020-03-06T10:38:51Z", "type": "commit"}, {"oid": "42dc731e5d0c2ef13062160472ca6970ad3c417e", "url": "https://github.com/ExpediaGroup/circus-train/commit/42dc731e5d0c2ef13062160472ca6970ad3c417e", "message": "Updates to test", "committedDate": "2020-03-06T10:59:10Z", "type": "commit"}, {"oid": "2d0d1003a2e13d146672676d3e7734fdc83c2209", "url": "https://github.com/ExpediaGroup/circus-train/commit/2d0d1003a2e13d146672676d3e7734fdc83c2209", "message": "Adding column in between two columns", "committedDate": "2020-03-06T11:56:59Z", "type": "commit"}, {"oid": "56ab02c2016946200ef75378abb5eba7e9160d53", "url": "https://github.com/ExpediaGroup/circus-train/commit/56ab02c2016946200ef75378abb5eba7e9160d53", "message": "Some changes to use Parquet", "committedDate": "2020-03-06T15:22:25Z", "type": "commit"}, {"oid": "85b74ba8cd7433ef729e7821612b5bb66e9efd15", "url": "https://github.com/ExpediaGroup/circus-train/commit/85b74ba8cd7433ef729e7821612b5bb66e9efd15", "message": "Test now failing successfully", "committedDate": "2020-03-09T17:33:36Z", "type": "commit"}, {"oid": "a548c9558a3bdba13050e8c6fb94eece4451f056", "url": "https://github.com/ExpediaGroup/circus-train/commit/a548c9558a3bdba13050e8c6fb94eece4451f056", "message": "Creating AlterTableService and operations", "committedDate": "2020-03-10T15:12:32Z", "type": "commit"}, {"oid": "0f6ff366016d268c2e93976d46fc50e46b8dde2e", "url": "https://github.com/ExpediaGroup/circus-train/commit/0f6ff366016d268c2e93976d46fc50e46b8dde2e", "message": "Fixing integration test", "committedDate": "2020-03-10T15:50:07Z", "type": "commit"}, {"oid": "c304abc4f55f8828e0e6777d2bf607e6942d5a35", "url": "https://github.com/ExpediaGroup/circus-train/commit/c304abc4f55f8828e0e6777d2bf607e6942d5a35", "message": "Fixing integration test", "committedDate": "2020-03-10T16:01:35Z", "type": "commit"}, {"oid": "8638af1b9b822b534bfd864a7c2f702d6810c6ae", "url": "https://github.com/ExpediaGroup/circus-train/commit/8638af1b9b822b534bfd864a7c2f702d6810c6ae", "message": "Fixing unit tests and copyright", "committedDate": "2020-03-10T16:15:11Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDQ1ODMyMQ==", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r390458321", "bodyText": "Why you have to refresh the tables?", "author": "patduin", "createdAt": "2020-03-10T16:46:40Z", "path": "circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/hive/RenameTableOperation.java", "diffHunk": "@@ -0,0 +1,54 @@\n+/**\n+ * Copyright (C) 2016-2020 Expedia, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hotels.bdp.circustrain.core.replica.hive;\n+\n+import org.apache.hadoop.hive.metastore.api.Table;\n+import org.apache.thrift.TException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.hotels.hcommon.hive.metastore.client.api.CloseableMetaStoreClient;\n+\n+public class RenameTableOperation {\n+\n+  private final static Logger LOG = LoggerFactory.getLogger(RenameTableOperation.class);\n+\n+  /**\n+   * <p>\n+   * NOTE: assumes both `from` and `to` exist\n+   * </p>\n+   * Renames tables 'from' table into 'to' table, at the end of the operation 'from' will be gone and 'to' will be\n+   * renamed.\n+   */\n+  public void execute(CloseableMetaStoreClient client, Table from, Table to) throws TException {\n+    LOG\n+        .info(\"Renaming table {}.{} to {}.{}\", from.getDbName(), from.getTableName(), to.getDbName(),\n+            to.getTableName());\n+    from = client.getTable(from.getDbName(), from.getTableName());", "originalCommit": "8638af1b9b822b534bfd864a7c2f702d6810c6ae", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDQ3NjkwMA==", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r390476900", "bodyText": "The \"to\" table has to be refreshed I think because it doesn't have the new schema applied, only the temp table does (from the previous operation). So we could just grab the to table. But I've done both anyway for good measure. Happy to take from out.", "author": "max-jacobs", "createdAt": "2020-03-10T17:13:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDQ1ODMyMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDkyMzU1Mw==", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r390923553", "bodyText": "I'm ok leaving them in that case.", "author": "patduin", "createdAt": "2020-03-11T12:02:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDQ1ODMyMQ=="}], "type": "inlineReview"}, {"oid": "8d5ededfcc255059e1dfccca72b31d0d23daf55f", "url": "https://github.com/ExpediaGroup/circus-train/commit/8d5ededfcc255059e1dfccca72b31d0d23daf55f", "message": "Some fixes", "committedDate": "2020-03-10T17:15:49Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDg4OTg2OQ==", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r390889869", "bodyText": "This was for debugging ?", "author": "abhimanyugupta07", "createdAt": "2020-03-11T10:55:06Z", "path": "circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainHdfsHdfsIntegrationTest.java", "diffHunk": "@@ -1398,4 +1404,115 @@ public void checkAssertion() throws Exception {\n     runner.run(config.getAbsolutePath());\n   }\n \n+  @Test\n+  public void partitionedTableColumnAdditionInStruct() throws Exception {\n+    // Create a table with a struct in the replica db (setting a Circus Train event id manually).\n+    Schema schema = SchemaBuilder\n+        .builder(\"name.space\")\n+        .record(PARTITIONED_TABLE)\n+        .fields()\n+        .requiredInt(\"id\")\n+        .name(\"details\")\n+        .type()\n+        .record(\"details_struct\")\n+        .fields()\n+        .requiredString(\"name\")\n+        .requiredString(\"city\")\n+        .endRecord()\n+        .noDefault()\n+        .endRecord();\n+\n+    HashMap<String, String> structData = new HashMap<>();\n+    structData.put(\"name\", \"adam\");\n+    structData.put(\"city\", \"blackpool\");\n+\n+    Table replicaTable = replicaHelper.createParquetPartitionedTableWithStruct(\n+        toUri(replicaWarehouseUri, DATABASE, PARTITIONED_TABLE),\n+        schema,\n+        \"struct<name:string, city:string>\",\n+        structData,\n+        1);\n+    LOG.info(\">>>> Table {} \", replicaCatalog.client().getTable(DATABASE, PARTITIONED_TABLE));", "originalCommit": "8d5ededfcc255059e1dfccca72b31d0d23daf55f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDkwODE4Mg==", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r390908182", "bodyText": "Hmm.. I see it in all the other tests too. So, may be it has some purpose. @patduin ?", "author": "abhimanyugupta07", "createdAt": "2020-03-11T11:31:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDg4OTg2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDkxNDkwMQ==", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r390914901", "bodyText": "Yeah its in all the tests, think its just for logging purposes. It's kind of handy, especially when checking a build", "author": "max-jacobs", "createdAt": "2020-03-11T11:44:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDg4OTg2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDkxNjU2Mg==", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r390916562", "bodyText": "I think it's just for logging, you can leave it if you find it handy, I'm ok either way", "author": "patduin", "createdAt": "2020-03-11T11:47:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDg4OTg2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDg4OTk2Nw==", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r390889967", "bodyText": "this one too.", "author": "abhimanyugupta07", "createdAt": "2020-03-11T10:55:18Z", "path": "circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainHdfsHdfsIntegrationTest.java", "diffHunk": "@@ -1398,4 +1404,115 @@ public void checkAssertion() throws Exception {\n     runner.run(config.getAbsolutePath());\n   }\n \n+  @Test\n+  public void partitionedTableColumnAdditionInStruct() throws Exception {\n+    // Create a table with a struct in the replica db (setting a Circus Train event id manually).\n+    Schema schema = SchemaBuilder\n+        .builder(\"name.space\")\n+        .record(PARTITIONED_TABLE)\n+        .fields()\n+        .requiredInt(\"id\")\n+        .name(\"details\")\n+        .type()\n+        .record(\"details_struct\")\n+        .fields()\n+        .requiredString(\"name\")\n+        .requiredString(\"city\")\n+        .endRecord()\n+        .noDefault()\n+        .endRecord();\n+\n+    HashMap<String, String> structData = new HashMap<>();\n+    structData.put(\"name\", \"adam\");\n+    structData.put(\"city\", \"blackpool\");\n+\n+    Table replicaTable = replicaHelper.createParquetPartitionedTableWithStruct(\n+        toUri(replicaWarehouseUri, DATABASE, PARTITIONED_TABLE),\n+        schema,\n+        \"struct<name:string, city:string>\",\n+        structData,\n+        1);\n+    LOG.info(\">>>> Table {} \", replicaCatalog.client().getTable(DATABASE, PARTITIONED_TABLE));\n+\n+    replicaTable.getParameters().put(\"com.hotels.bdp.circustrain.replication.event\", \"event_id\");\n+    replicaCatalog.client().alter_table(DATABASE, PARTITIONED_TABLE, replicaTable);\n+\n+    // Create the source partition with the original struct.\n+    helper.createData(toUri(sourceWarehouseUri, DATABASE, PARTITIONED_TABLE), schema, \"1\", 1, structData);\n+\n+    // Create the source table with an additional column in the struct.\n+    Schema schemaV2 = SchemaBuilder\n+        .builder(\"name.space\")\n+        .record(PARTITIONED_TABLE)\n+        .fields()\n+        .requiredInt(\"id\")\n+        .name(\"details\")\n+        .type()\n+        .record(\"details_struct\")\n+        .fields()\n+        .requiredString(\"name\")\n+        .requiredString(\"city\")\n+        .optionalString(\"dob\")\n+        .endRecord()\n+        .noDefault()\n+        .endRecord();\n+\n+    structData = new HashMap<>();\n+    structData.put(\"name\", \"adam\");\n+    structData.put(\"city\", \"blackpool\");\n+    structData.put(\"dob\", \"22/09/1992\");\n+\n+    Table table = helper.createParquetPartitionedTableWithStruct(\n+        toUri(sourceWarehouseUri, DATABASE, PARTITIONED_TABLE),\n+        schemaV2,\n+        \"struct<name:string, city:string, dob:string>\",\n+        structData,\n+        2);\n+    LOG.info(\">>>> Table {} \", sourceCatalog.client().getTable(DATABASE, PARTITIONED_TABLE));", "originalCommit": "8d5ededfcc255059e1dfccca72b31d0d23daf55f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDkyMTExOA==", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r390921118", "bodyText": "Does this copy all the table properties?", "author": "patduin", "createdAt": "2020-03-11T11:57:25Z", "path": "circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/hive/AlterTableService.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/**\n+ * Copyright (C) 2016-2020 Expedia, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hotels.bdp.circustrain.core.replica.hive;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import org.apache.hadoop.hive.metastore.api.FieldSchema;\n+import org.apache.hadoop.hive.metastore.api.Table;\n+import org.apache.thrift.TException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.hotels.bdp.circustrain.core.replica.Replica;\n+import com.hotels.hcommon.hive.metastore.client.api.CloseableMetaStoreClient;\n+\n+public class AlterTableService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(Replica.class);\n+\n+  private CopyPartitionsOperation copyPartitionsOperation;\n+  private RenameTableOperation renameTableOperation;\n+\n+  public AlterTableService(\n+      CopyPartitionsOperation copyPartitionsOperation,\n+      RenameTableOperation renameTableOperation) {\n+    this.copyPartitionsOperation = copyPartitionsOperation;\n+    this.renameTableOperation = renameTableOperation;\n+  }\n+\n+  public void alterTable(CloseableMetaStoreClient client, Table oldTable, Table newTable) throws TException {\n+    List<FieldSchema> oldColumns = oldTable.getSd().getCols();\n+    List<FieldSchema> newColumns = newTable.getSd().getCols();\n+    if (hasAnyChangedColumns(oldColumns, newColumns)) {\n+      LOG\n+          .info(\"Found columns that have changed type, attempting to recreate target table with the new columns.\"\n+              + \"Old columns: {}, new columns: {}\", oldColumns, newColumns);\n+      Table tempTable = new Table(newTable);", "originalCommit": "8d5ededfcc255059e1dfccca72b31d0d23daf55f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTAyMDczOQ==", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r391020739", "bodyText": "It does indeed. We can either (1) scrub all the table params here, or (2) I've created a DropTableService which removes custom table params before calling the drop table command. If thats overly complicated I can remove the new service and just do (1) instead.", "author": "max-jacobs", "createdAt": "2020-03-11T14:41:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDkyMTExOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTc2NDc1Ng==", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r391764756", "bodyText": "OK so if we removed the params here then we don't have to worry about the potential of Beekeeper picking up the drop of the temp table etc.? I think I prefer that approach unless some of the params are useful to have on the temp table? I don't think any of the intermediate operations use them in any way so probably not? And to be clear, the original table params will be kept on the final end result table?", "author": "massdosage", "createdAt": "2020-03-12T17:05:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDkyMTExOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjE0MjAwMA==", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r392142000", "bodyText": "Okay cool, I'm happy to do this, I'll remove the DropTableService, and just remove the params as part of this service.\nThe intermediate ops dont use the params, but i think beekeeper may pick up on the alter partition events (though will ignore them as the location doesnt change). And yes, the original params will be on the final table - i'll add some tests for this.", "author": "max-jacobs", "createdAt": "2020-03-13T10:21:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDkyMTExOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjE2MjQ2Mg==", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r392162462", "bodyText": "Tried this out, and actually it doesn't seem possible. We can't do an alter table on the table as it still has the old schema, so it fails with the same error. So the DropTableService looks better as we do the alter/drop once everything has been updated.", "author": "max-jacobs", "createdAt": "2020-03-13T11:04:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDkyMTExOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjE5MzAxNw==", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r392193017", "bodyText": "OK, let's go with that for now and keep an eye on it when this is in use.", "author": "massdosage", "createdAt": "2020-03-13T12:17:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDkyMTExOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDkyNDA1Nw==", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r390924057", "bodyText": "We need to double check beekeeper props and we don't accidentally delete folders when we drop this table.", "author": "patduin", "createdAt": "2020-03-11T12:03:40Z", "path": "circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/hive/RenameTableOperation.java", "diffHunk": "@@ -0,0 +1,54 @@\n+/**\n+ * Copyright (C) 2016-2020 Expedia, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hotels.bdp.circustrain.core.replica.hive;\n+\n+import org.apache.hadoop.hive.metastore.api.Table;\n+import org.apache.thrift.TException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.hotels.hcommon.hive.metastore.client.api.CloseableMetaStoreClient;\n+\n+public class RenameTableOperation {\n+\n+  private final static Logger LOG = LoggerFactory.getLogger(RenameTableOperation.class);\n+\n+  /**\n+   * <p>\n+   * NOTE: assumes both `from` and `to` exist\n+   * </p>\n+   * Renames tables 'from' table into 'to' table, at the end of the operation 'from' will be gone and 'to' will be\n+   * renamed.\n+   */\n+  public void execute(CloseableMetaStoreClient client, Table from, Table to) throws TException {\n+    LOG\n+        .info(\"Renaming table {}.{} to {}.{}\", from.getDbName(), from.getTableName(), to.getDbName(),\n+            to.getTableName());\n+    from = client.getTable(from.getDbName(), from.getTableName());\n+    to = client.getTable(to.getDbName(), to.getTableName());\n+    String fromTableName = from.getTableName();\n+    String toTableName = to.getTableName();\n+    String toTableNameTemp = toTableName + \"_original\";\n+    try {\n+      from.setTableName(toTableName);\n+      to.setTableName(toTableNameTemp);\n+      client.alter_table(to.getDbName(), toTableName, to);\n+      client.alter_table(from.getDbName(), fromTableName, from);\n+    } finally {\n+      client.dropTable(to.getDbName(), toTableNameTemp, false, true);", "originalCommit": "8d5ededfcc255059e1dfccca72b31d0d23daf55f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "12aa8157e72b1efc4679aca55943e1f25be3cbf0", "url": "https://github.com/ExpediaGroup/circus-train/commit/12aa8157e72b1efc4679aca55943e1f25be3cbf0", "message": "Adding DropTableService which removes custom table parameters before dropping", "committedDate": "2020-03-11T14:40:15Z", "type": "commit"}, {"oid": "e1b2eac5e822353acd52855a6f607262166f1116", "url": "https://github.com/ExpediaGroup/circus-train/commit/e1b2eac5e822353acd52855a6f607262166f1116", "message": "Adding changelog and other bits", "committedDate": "2020-03-11T14:45:15Z", "type": "commit"}, {"oid": "4ce2b900d03183a48b66efd01c2322bf3999bd20", "url": "https://github.com/ExpediaGroup/circus-train/commit/4ce2b900d03183a48b66efd01c2322bf3999bd20", "message": "Added catch for non existent table", "committedDate": "2020-03-11T15:15:18Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTA5ODUwOA==", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r391098508", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              private static final Logger LOG = LoggerFactory.getLogger(AlterTableService.class);\n          \n          \n            \n              private static final Logger log = LoggerFactory.getLogger(AlterTableService.class);\n          \n      \n    \n    \n  \n\n(it's not a constant)", "author": "massdosage", "createdAt": "2020-03-11T16:25:38Z", "path": "circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/hive/AlterTableService.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/**\n+ * Copyright (C) 2016-2020 Expedia, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hotels.bdp.circustrain.core.replica.hive;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import org.apache.hadoop.hive.metastore.api.FieldSchema;\n+import org.apache.hadoop.hive.metastore.api.Table;\n+import org.apache.thrift.TException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.hotels.hcommon.hive.metastore.client.api.CloseableMetaStoreClient;\n+\n+public class AlterTableService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(AlterTableService.class);", "originalCommit": "4ce2b900d03183a48b66efd01c2322bf3999bd20", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTY3MTMzOQ==", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r391671339", "bodyText": "Will change all these in a further PR", "author": "max-jacobs", "createdAt": "2020-03-12T14:45:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTA5ODUwOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTc2Mjg5Ng==", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r391762896", "bodyText": "Ack", "author": "massdosage", "createdAt": "2020-03-12T17:02:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTA5ODUwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTA5ODcwOQ==", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r391098709", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  ReplicaTableFactoryProvider replicaTableFactoryPicker,\n          \n          \n            \n                  ReplicaTableFactoryProvider replicaTableFactoryProvider,", "author": "massdosage", "createdAt": "2020-03-11T16:25:55Z", "path": "circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/ReplicaFactory.java", "diffHunk": "@@ -49,19 +55,24 @@ public ReplicaFactory(\n       Supplier<CloseableMetaStoreClient> replicaMetaStoreClientSupplier,\n       HousekeepingListener housekeepingListener,\n       ReplicaCatalogListener replicaCatalogListener,\n-      ReplicaTableFactoryProvider replicaTableFactoryPicker) {\n+      ReplicaTableFactoryProvider replicaTableFactoryPicker,", "originalCommit": "4ce2b900d03183a48b66efd01c2322bf3999bd20", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTY3MTQ0Ng==", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r391671446", "bodyText": "done :)", "author": "max-jacobs", "createdAt": "2020-03-12T14:45:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTA5ODcwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTExMzE2MQ==", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r391113161", "bodyText": "to be deleted?", "author": "max-jacobs", "createdAt": "2020-03-11T16:47:04Z", "path": "circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/hive/RenameTableOperation.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/**\n+ * Copyright (C) 2016-2020 Expedia, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hotels.bdp.circustrain.core.replica.hive;\n+\n+import org.apache.hadoop.hive.metastore.api.Table;\n+import org.apache.thrift.TException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.hotels.hcommon.hive.metastore.client.api.CloseableMetaStoreClient;\n+\n+public class RenameTableOperation {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(RenameTableOperation.class);\n+  private static final String TEMP_SUFFIX = \"_original\";\n+\n+  private DropTableService dropTableService;\n+\n+  public RenameTableOperation(DropTableService dropTableService) {\n+    this.dropTableService = dropTableService;\n+  }\n+\n+  /**\n+   * <p>\n+   * NOTE: assumes both `from` and `to` exist\n+   * </p>\n+   * Renames tables 'from' table into 'to' table, at the end of the operation 'from' will be gone and 'to' will be\n+   * renamed.\n+   */\n+  public void execute(CloseableMetaStoreClient client, Table from, Table to) throws TException {\n+    LOG\n+        .info(\"Renaming table {}.{} to {}.{}\", from.getDbName(), from.getTableName(), to.getDbName(),\n+            to.getTableName());\n+    Table fromTable = client.getTable(from.getDbName(), from.getTableName());\n+    Table toTable = client.getTable(to.getDbName(), to.getTableName());\n+    String fromTableName = fromTable.getTableName();\n+    String toTableName = toTable.getTableName();\n+    try {\n+      fromTable.setTableName(toTableName);\n+      toTable.setTableName(toTableName + TEMP_SUFFIX);", "originalCommit": "4ce2b900d03183a48b66efd01c2322bf3999bd20", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "7ee9d232ad75ca78653032f00a649d832a906da0", "url": "https://github.com/ExpediaGroup/circus-train/commit/7ee9d232ad75ca78653032f00a649d832a906da0", "message": "Fixing some bits, renaming, adding external key to table when dropping", "committedDate": "2020-03-12T11:54:34Z", "type": "commit"}, {"oid": "94ea2eef4ded3c7d2a5004a67dd346e1df8485f8", "url": "https://github.com/ExpediaGroup/circus-train/commit/94ea2eef4ded3c7d2a5004a67dd346e1df8485f8", "message": "Undoing unnecessary changes", "committedDate": "2020-03-12T12:06:46Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTc2NjcyNg==", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r391766726", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              private StorageDescriptor getSd(List<FieldSchema> columns) {\n          \n          \n            \n              private StorageDescriptor createStorageDescriptor(List<FieldSchema> columns) {", "author": "massdosage", "createdAt": "2020-03-12T17:08:31Z", "path": "circus-train-core/src/test/java/com/hotels/bdp/circustrain/core/replica/hive/AlterTableServiceTest.java", "diffHunk": "@@ -0,0 +1,145 @@\n+/**\n+ * Copyright (C) 2016-2020 Expedia, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hotels.bdp.circustrain.core.replica.hive;\n+\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.junit.Assert.assertThat;\n+import static org.junit.Assert.fail;\n+import static org.mockito.Mockito.doThrow;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.verifyNoMoreInteractions;\n+import static org.mockito.Mockito.verifyZeroInteractions;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import org.apache.hadoop.hive.metastore.api.FieldSchema;\n+import org.apache.hadoop.hive.metastore.api.StorageDescriptor;\n+import org.apache.hadoop.hive.metastore.api.Table;\n+import org.apache.thrift.TException;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.mockito.Mock;\n+import org.mockito.runners.MockitoJUnitRunner;\n+\n+import com.hotels.hcommon.hive.metastore.client.api.CloseableMetaStoreClient;\n+\n+@RunWith(MockitoJUnitRunner.class)\n+public class AlterTableServiceTest {\n+\n+  private static final String OLD_TABLE_NAME = \"old_table\";\n+  private static final String NEW_TABLE_NAME = \"new_table\";\n+  private static final String NEW_TABLE_NAME_TEMP = NEW_TABLE_NAME + \"_temp\";\n+  private static final String OLD_DB_NAME = \"old_db\";\n+  private static final String NEW_DB_NAME = \"new_db\";\n+\n+  private @Mock CloseableMetaStoreClient client;\n+  private @Mock DropTableService dropTableService;\n+  private @Mock CopyPartitionsOperation copyPartitionsOperation;\n+  private @Mock RenameTableOperation renameTableOperation;\n+\n+  private AlterTableService service;\n+  private Table oldTable = new Table();\n+  private Table newTable = new Table();\n+\n+  @Before\n+  public void setUp() {\n+    service = new AlterTableService(dropTableService, copyPartitionsOperation, renameTableOperation);\n+    oldTable.setTableName(OLD_TABLE_NAME);\n+    newTable.setTableName(NEW_TABLE_NAME);\n+    oldTable.setDbName(OLD_DB_NAME);\n+    newTable.setDbName(NEW_DB_NAME);\n+  }\n+\n+  @Test\n+  public void typicalAlterTable() throws TException {\n+    oldTable.setSd(getSd(Arrays.asList(new FieldSchema(\"colA\", \"string\", \"some comment\"))));\n+    newTable.setSd(getSd(Arrays.asList(new FieldSchema(\"colA\", \"string\", \"some comment\"))));\n+\n+    service.alterTable(client, oldTable, newTable);\n+\n+    verify(client).alter_table(NEW_DB_NAME, NEW_TABLE_NAME, newTable);\n+    verifyNoMoreInteractions(client);\n+  }\n+\n+  @Test\n+  public void alterTableColumnChange() throws TException {\n+    oldTable.setSd(getSd(Arrays.asList(new FieldSchema(\"colA\", \"string\", \"some comment\"))));\n+    newTable.setSd(getSd(Arrays.asList(new FieldSchema(\"colA\", \"int\", \"some comment\"))));\n+    Table tempTable = new Table(newTable);\n+    tempTable.setTableName(NEW_TABLE_NAME_TEMP);\n+\n+    service.alterTable(client, oldTable, newTable);\n+\n+    verify(client).createTable(tempTable);\n+    verify(dropTableService).removeTableParamsAndDrop(client, NEW_DB_NAME, NEW_TABLE_NAME_TEMP);\n+    verify(copyPartitionsOperation).execute(client, newTable, tempTable);\n+    verify(renameTableOperation).execute(client, tempTable, newTable);\n+    verifyNoMoreInteractions(client);\n+  }\n+\n+  @Test\n+  public void alterTableCopyPartitionsFails() throws TException {\n+    oldTable.setSd(getSd(Arrays.asList(new FieldSchema(\"colA\", \"string\", \"some comment\"))));\n+    newTable.setSd(getSd(Arrays.asList(new FieldSchema(\"colA\", \"int\", \"some comment\"))));\n+    Table tempTable = new Table(newTable);\n+    tempTable.setTableName(NEW_TABLE_NAME_TEMP);\n+    TException toBeThrown = new TException(\"error\");\n+    doThrow(toBeThrown).when(copyPartitionsOperation).execute(client, newTable, tempTable);\n+\n+    try {\n+      service.alterTable(client, oldTable, newTable);\n+      fail(\"Should have thrown exception.\");\n+    } catch (Exception e) {\n+      verify(client).createTable(tempTable);\n+      verify(dropTableService).removeTableParamsAndDrop(client, NEW_DB_NAME, NEW_TABLE_NAME_TEMP);\n+      verify(copyPartitionsOperation).execute(client, newTable, tempTable);\n+      verifyZeroInteractions(renameTableOperation);\n+      verifyNoMoreInteractions(client);\n+      assertThat(e, is(toBeThrown));\n+    }\n+  }\n+\n+  @Test\n+  public void alterTableRenameTableFails() throws TException {\n+    oldTable.setSd(getSd(Arrays.asList(new FieldSchema(\"colA\", \"string\", \"some comment\"))));\n+    newTable.setSd(getSd(Arrays.asList(new FieldSchema(\"colA\", \"int\", \"some comment\"))));\n+    Table tempTable = new Table(newTable);\n+    tempTable.setTableName(NEW_TABLE_NAME_TEMP);\n+    TException toBeThrown = new TException(\"error\");\n+    doThrow(toBeThrown).when(renameTableOperation).execute(client, tempTable, newTable);\n+\n+    try {\n+      service.alterTable(client, oldTable, newTable);\n+      fail(\"Should have thrown exception.\");\n+    } catch (Exception e) {\n+      verify(client).createTable(tempTable);\n+      verify(dropTableService).removeTableParamsAndDrop(client, NEW_DB_NAME, NEW_TABLE_NAME_TEMP);\n+      verify(copyPartitionsOperation).execute(client, newTable, tempTable);\n+      verify(renameTableOperation).execute(client, tempTable, newTable);\n+      verifyNoMoreInteractions(client);\n+      assertThat(e, is(toBeThrown));\n+    }\n+  }\n+\n+  private StorageDescriptor getSd(List<FieldSchema> columns) {", "originalCommit": "94ea2eef4ded3c7d2a5004a67dd346e1df8485f8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTc2NzA2MQ==", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r391767061", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                ArrayList<Partition> partitions = new ArrayList<>();\n          \n          \n            \n                List<Partition> partitions = new ArrayList<>();", "author": "massdosage", "createdAt": "2020-03-12T17:09:04Z", "path": "circus-train-core/src/test/java/com/hotels/bdp/circustrain/core/replica/hive/CopyPartitionsOperationTest.java", "diffHunk": "@@ -0,0 +1,146 @@\n+/**\n+ * Copyright (C) 2016-2020 Expedia, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hotels.bdp.circustrain.core.replica.hive;\n+\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.junit.Assert.assertThat;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.verifyNoMoreInteractions;\n+import static org.mockito.Mockito.when;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+\n+import org.apache.hadoop.hive.metastore.api.FieldSchema;\n+import org.apache.hadoop.hive.metastore.api.Partition;\n+import org.apache.hadoop.hive.metastore.api.StorageDescriptor;\n+import org.apache.hadoop.hive.metastore.api.Table;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.runners.MockitoJUnitRunner;\n+\n+import com.hotels.hcommon.hive.metastore.client.api.CloseableMetaStoreClient;\n+\n+@RunWith(MockitoJUnitRunner.class)\n+public class CopyPartitionsOperationTest {\n+\n+  private static final short BATCH_SIZE = 2;\n+  private static final String OLD_TABLE_NAME = \"old_table\";\n+  private static final String NEW_TABLE_NAME = \"new_table\";\n+  private static final String OLD_DB_NAME = \"old_db\";\n+  private static final String NEW_DB_NAME = \"new_db\";\n+\n+  private @Mock CloseableMetaStoreClient client;\n+  private @Captor ArgumentCaptor<List<Partition>> partitionCaptor;\n+  private Table oldTable = new Table();\n+  private Table newTable = new Table();\n+  private CopyPartitionsOperation operation;\n+\n+  @Before\n+  public void setUp() {\n+    operation = new CopyPartitionsOperation(BATCH_SIZE);\n+    oldTable.setTableName(OLD_TABLE_NAME);\n+    newTable.setTableName(NEW_TABLE_NAME);\n+    oldTable.setDbName(OLD_DB_NAME);\n+    newTable.setDbName(NEW_DB_NAME);\n+    StorageDescriptor sd = new StorageDescriptor();\n+    sd.setCols(Arrays.asList(new FieldSchema(\"id\", \"bigint\", \"\")));\n+    newTable.setSd(sd);\n+  }\n+\n+  @Test\n+  public void typicalCopyPartitions() throws Exception {\n+    List<String> partitionNames = Arrays.asList(\"part1\");\n+    when(client.listPartitionNames(OLD_DB_NAME, OLD_TABLE_NAME, (short) -1))\n+        .thenReturn(partitionNames);\n+    when(client.getPartitionsByNames(OLD_DB_NAME, OLD_TABLE_NAME, Arrays.asList(\"part1\")))\n+        .thenReturn(createPartitions(1));\n+\n+    operation.execute(client, oldTable, newTable);\n+\n+    verify(client, times(1)).add_partitions(partitionCaptor.capture());\n+    List<List<Partition>> captured = partitionCaptor.getAllValues();\n+    assertThat(captured.size(), is(1));\n+    assertThat(captured.get(0).size(), is(1));\n+  }\n+\n+  @Test\n+  public void singleBatch() throws Exception {\n+    List<String> partitionNames = Arrays.asList(\"part1\", \"part2\");\n+    when(client.listPartitionNames(OLD_DB_NAME, OLD_TABLE_NAME, (short) -1))\n+        .thenReturn(partitionNames);\n+    when(client.getPartitionsByNames(OLD_DB_NAME, OLD_TABLE_NAME, Arrays.asList(\"part1\", \"part2\")))\n+        .thenReturn(createPartitions(2));\n+\n+    operation.execute(client, oldTable, newTable);\n+\n+    verify(client, times(1)).add_partitions(partitionCaptor.capture());\n+    List<List<Partition>> captured = partitionCaptor.getAllValues();\n+    assertThat(captured.size(), is(1));\n+    assertThat(captured.get(0).size(), is(2));\n+  }\n+\n+  @Test\n+  public void multipleBatches() throws Exception {\n+    List<String> partitionNames = Arrays.asList(\"part1\", \"part2\", \"part3\");\n+    when(client.listPartitionNames(OLD_DB_NAME, OLD_TABLE_NAME, (short) -1))\n+        .thenReturn(partitionNames);\n+    when(client.getPartitionsByNames(OLD_DB_NAME, OLD_TABLE_NAME, Arrays.asList(\"part1\", \"part2\")))\n+        .thenReturn(createPartitions(2));\n+    when(client.getPartitionsByNames(OLD_DB_NAME, OLD_TABLE_NAME, Arrays.asList(\"part3\")))\n+        .thenReturn(createPartitions(1));\n+\n+    operation.execute(client, oldTable, newTable);\n+\n+    verify(client, times(2)).add_partitions(partitionCaptor.capture());\n+    List<List<Partition>> captured = partitionCaptor.getAllValues();\n+    assertThat(captured.size(), is(2));\n+    assertThat(captured.get(0).size(), is(2));\n+    assertThat(captured.get(1).size(), is(1));\n+  }\n+\n+  @Test\n+  public void noPartitions() throws Exception {\n+    when(client.listPartitionNames(OLD_DB_NAME, OLD_TABLE_NAME, (short) -1))\n+        .thenReturn(Collections.emptyList());\n+    when(client.getPartitionsByNames(OLD_DB_NAME, OLD_TABLE_NAME, Collections.emptyList()))\n+        .thenReturn(Collections.emptyList());\n+\n+    operation.execute(client, oldTable, newTable);\n+\n+    verify(client).listPartitionNames(OLD_DB_NAME, OLD_TABLE_NAME, (short) -1);\n+    verify(client).getPartitionsByNames(OLD_DB_NAME, OLD_TABLE_NAME, Collections.emptyList());\n+    verifyNoMoreInteractions(client);\n+  }\n+\n+  private List<Partition> createPartitions(int count) {\n+    ArrayList<Partition> partitions = new ArrayList<>();", "originalCommit": "94ea2eef4ded3c7d2a5004a67dd346e1df8485f8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTc2NzM1OQ==", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r391767359", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                HashMap<String, String> params = new HashMap<>();\n          \n          \n            \n                Map<String, String> params = new HashMap<>();", "author": "massdosage", "createdAt": "2020-03-12T17:09:35Z", "path": "circus-train-core/src/test/java/com/hotels/bdp/circustrain/core/replica/hive/DropTableServiceTest.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/**\n+ * Copyright (C) 2016-2020 Expedia, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hotels.bdp.circustrain.core.replica.hive;\n+\n+import static org.hamcrest.Matchers.is;\n+import static org.junit.Assert.assertThat;\n+import static org.mockito.Matchers.eq;\n+import static org.mockito.Mockito.doThrow;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.verifyNoMoreInteractions;\n+import static org.mockito.Mockito.when;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import org.apache.hadoop.hive.metastore.api.NoSuchObjectException;\n+import org.apache.hadoop.hive.metastore.api.Table;\n+import org.apache.thrift.TException;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.runners.MockitoJUnitRunner;\n+\n+import com.hotels.hcommon.hive.metastore.client.api.CloseableMetaStoreClient;\n+\n+@RunWith(MockitoJUnitRunner.class)\n+public class DropTableServiceTest {\n+\n+  private static final String TABLE_NAME = \"table\";\n+  private static final String DB_NAME = \"db\";\n+\n+  private @Mock CloseableMetaStoreClient client;\n+  private @Captor ArgumentCaptor<Table> tableCaptor;\n+\n+  private DropTableService service;\n+  private Table table = new Table();\n+\n+  @Before\n+  public void setUp() throws TException {\n+    service = new DropTableService();\n+    table.setTableName(TABLE_NAME);\n+    table.setDbName(DB_NAME);\n+    when(client.getTable(DB_NAME, TABLE_NAME)).thenReturn(table);\n+  }\n+\n+  @Test\n+  public void removeParamsAndDropNullParams() throws TException {\n+    service.removeTableParamsAndDrop(client, DB_NAME, TABLE_NAME);\n+\n+    verify(client).dropTable(DB_NAME, TABLE_NAME, false, true);\n+    verify(client).getTable(DB_NAME, TABLE_NAME);\n+    verifyNoMoreInteractions(client);\n+  }\n+\n+  @Test\n+  public void removeParamsAndDropEmptyParams() throws TException {\n+    table.setParameters(Collections.emptyMap());\n+\n+    service.removeTableParamsAndDrop(client, DB_NAME, TABLE_NAME);\n+\n+    verify(client).getTable(DB_NAME, TABLE_NAME);\n+    verify(client).dropTable(DB_NAME, TABLE_NAME, false, true);\n+    verifyNoMoreInteractions(client);\n+  }\n+\n+  @Test\n+  public void removeParamsAndDrop() throws TException {\n+    HashMap<String, String> params = new HashMap<>();", "originalCommit": "94ea2eef4ded3c7d2a5004a67dd346e1df8485f8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTc2NzQ1MQ==", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r391767451", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                HashMap<String, String> params = new HashMap<>();\n          \n          \n            \n                Map<String, String> params = new HashMap<>();", "author": "massdosage", "createdAt": "2020-03-12T17:09:44Z", "path": "circus-train-core/src/test/java/com/hotels/bdp/circustrain/core/replica/hive/DropTableServiceTest.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/**\n+ * Copyright (C) 2016-2020 Expedia, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hotels.bdp.circustrain.core.replica.hive;\n+\n+import static org.hamcrest.Matchers.is;\n+import static org.junit.Assert.assertThat;\n+import static org.mockito.Matchers.eq;\n+import static org.mockito.Mockito.doThrow;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.verifyNoMoreInteractions;\n+import static org.mockito.Mockito.when;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import org.apache.hadoop.hive.metastore.api.NoSuchObjectException;\n+import org.apache.hadoop.hive.metastore.api.Table;\n+import org.apache.thrift.TException;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.runners.MockitoJUnitRunner;\n+\n+import com.hotels.hcommon.hive.metastore.client.api.CloseableMetaStoreClient;\n+\n+@RunWith(MockitoJUnitRunner.class)\n+public class DropTableServiceTest {\n+\n+  private static final String TABLE_NAME = \"table\";\n+  private static final String DB_NAME = \"db\";\n+\n+  private @Mock CloseableMetaStoreClient client;\n+  private @Captor ArgumentCaptor<Table> tableCaptor;\n+\n+  private DropTableService service;\n+  private Table table = new Table();\n+\n+  @Before\n+  public void setUp() throws TException {\n+    service = new DropTableService();\n+    table.setTableName(TABLE_NAME);\n+    table.setDbName(DB_NAME);\n+    when(client.getTable(DB_NAME, TABLE_NAME)).thenReturn(table);\n+  }\n+\n+  @Test\n+  public void removeParamsAndDropNullParams() throws TException {\n+    service.removeTableParamsAndDrop(client, DB_NAME, TABLE_NAME);\n+\n+    verify(client).dropTable(DB_NAME, TABLE_NAME, false, true);\n+    verify(client).getTable(DB_NAME, TABLE_NAME);\n+    verifyNoMoreInteractions(client);\n+  }\n+\n+  @Test\n+  public void removeParamsAndDropEmptyParams() throws TException {\n+    table.setParameters(Collections.emptyMap());\n+\n+    service.removeTableParamsAndDrop(client, DB_NAME, TABLE_NAME);\n+\n+    verify(client).getTable(DB_NAME, TABLE_NAME);\n+    verify(client).dropTable(DB_NAME, TABLE_NAME, false, true);\n+    verifyNoMoreInteractions(client);\n+  }\n+\n+  @Test\n+  public void removeParamsAndDrop() throws TException {\n+    HashMap<String, String> params = new HashMap<>();\n+    params.put(\"key1\", \"value\");\n+    params.put(\"key2\", \"value\");\n+    params.put(\"EXTERNAL\", \"true\");\n+    table.setParameters(params);\n+\n+    service.removeTableParamsAndDrop(client, DB_NAME, TABLE_NAME);\n+\n+    verify(client).getTable(DB_NAME, TABLE_NAME);\n+    verify(client).alter_table(eq(DB_NAME), eq(TABLE_NAME), tableCaptor.capture());\n+    verify(client).dropTable(DB_NAME, TABLE_NAME, false, true);\n+    verifyNoMoreInteractions(client);\n+    List<Table> capturedTables = tableCaptor.getAllValues();\n+    assertThat(capturedTables.size(), is(1));\n+    Map<String, String> parameters = capturedTables.get(0).getParameters();\n+    assertThat(parameters.size(), is(1));\n+    assertThat(parameters.get(\"EXTERNAL\"), is(\"true\"));\n+  }\n+\n+  @Test\n+  public void removeParamsAndDropCaseInsensitiveExternalTable() throws TException {\n+    HashMap<String, String> params = new HashMap<>();", "originalCommit": "94ea2eef4ded3c7d2a5004a67dd346e1df8485f8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTc2OTI5OA==", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r391769298", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                HashMap<String, String> structData = new HashMap<>();\n          \n          \n            \n                Map<String, String> structData = new HashMap<>();", "author": "massdosage", "createdAt": "2020-03-12T17:12:49Z", "path": "circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainHdfsHdfsIntegrationTest.java", "diffHunk": "@@ -1398,4 +1404,119 @@ public void checkAssertion() throws Exception {\n     runner.run(config.getAbsolutePath());\n   }\n \n+  @Test\n+  public void partitionedTableColumnAdditionInStruct() throws Exception {\n+    // Create a table with a struct in the replica db (setting a Circus Train event id manually).\n+    Schema schema = SchemaBuilder\n+        .builder(\"name.space\")\n+        .record(PARTITIONED_TABLE)\n+        .fields()\n+        .requiredInt(\"id\")\n+        .name(\"details\")\n+        .type()\n+        .record(\"details_struct\")\n+        .fields()\n+        .requiredString(\"name\")\n+        .requiredString(\"city\")\n+        .endRecord()\n+        .noDefault()\n+        .endRecord();\n+\n+    HashMap<String, String> structData = new HashMap<>();", "originalCommit": "94ea2eef4ded3c7d2a5004a67dd346e1df8485f8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTc2OTgxNw==", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r391769817", "bodyText": "Don't we want to throw this and fail the test if this happens?", "author": "massdosage", "createdAt": "2020-03-12T17:13:38Z", "path": "circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/IntegrationTestHelper.java", "diffHunk": "@@ -74,6 +87,60 @@ void createPartitionedTable(URI sourceTableUri) throws Exception {\n                         newTablePartition(hiveTable, Arrays.asList(\"Asia\", \"China\"), partitionChina))));\n   }\n \n+  Table createParquetPartitionedTableWithStruct(\n+      URI tableUri,\n+      Schema schema,\n+      String structType,\n+      Map<String, String> structData,\n+      int version) throws Exception {\n+    List<FieldSchema> columns = Arrays.asList(\n+        new FieldSchema(\"id\", \"string\", \"\"),\n+        new FieldSchema(\"details\", structType, \"\")\n+    );\n+    List<FieldSchema> partitionKeys = Arrays.asList(new FieldSchema(\"hour\", \"string\", \"\"));\n+    Table table = TestUtils\n+        .createPartitionedTable(metaStoreClient, DATABASE, PARTITIONED_TABLE, tableUri, columns, partitionKeys,\n+            \"org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe\", ParquetInputFormat.class.getName(),\n+            ParquetOutputFormat.class.getName());\n+    URI partition = createData(tableUri, schema, Integer.toString(version), version, structData);\n+    metaStoreClient.add_partitions(Arrays.asList(newTablePartition(table,\n+        Arrays.asList(Integer.toString(version)), partition)));\n+    return metaStoreClient.getTable(DATABASE, PARTITIONED_TABLE);\n+  }\n+\n+  URI createData(\n+      URI tableUri,\n+      Schema schema,\n+      String hour,\n+      int id,\n+      Map<String, String> detailsStruct) throws IOException {\n+    GenericData.Record record = new GenericData.Record(schema);\n+    Schema detailsSchema = schema.getField(\"details\").schema();\n+    GenericData.Record details = new GenericData.Record(detailsSchema);\n+    detailsStruct.forEach(details::put);\n+    record.put(\"id\", id);\n+    record.put(\"details\", details);\n+\n+    URI partition = URI.create(tableUri + \"/hour=\" + hour);\n+    String path = partition.getPath();\n+    File parentFolder = new File(path);\n+    parentFolder.mkdirs();\n+    File partitionFile = new File(parentFolder, \"parquet0000\");\n+    Path filePath = new Path(partitionFile.toURI());\n+    ParquetWriter<GenericData.Record> writer = AvroParquetWriter.<GenericData.Record>builder(filePath)\n+        .withSchema(schema)\n+        .withConf(new Configuration())\n+        .build();\n+\n+    try {\n+      writer.write(record);\n+    } catch (IOException e) {\n+      e.printStackTrace();", "originalCommit": "94ea2eef4ded3c7d2a5004a67dd346e1df8485f8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "890ea8d1a8319bab6dbb82258cdd21d2a26bc6de", "url": "https://github.com/ExpediaGroup/circus-train/commit/890ea8d1a8319bab6dbb82258cdd21d2a26bc6de", "message": "Fixes", "committedDate": "2020-03-13T11:12:32Z", "type": "commit"}, {"oid": "2b933684b80afe94031fb06103e198f6d7571af3", "url": "https://github.com/ExpediaGroup/circus-train/commit/2b933684b80afe94031fb06103e198f6d7571af3", "message": "Fixing pom", "committedDate": "2020-03-13T11:18:53Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjE5NTYxMA==", "url": "https://github.com/ExpediaGroup/circus-train/pull/174#discussion_r392195610", "bodyText": "NABD but would be nice to replace \"1\" and \"2\" in this and the next method with something more descriptive as to what the difference is. From what I can see it's about where the exception is thrown, when altering the to or the from table? So maybe something like renameToTableException and renameFromTableException?", "author": "massdosage", "createdAt": "2020-03-13T12:23:50Z", "path": "circus-train-core/src/test/java/com/hotels/bdp/circustrain/core/replica/hive/RenameTableOperationTest.java", "diffHunk": "@@ -0,0 +1,118 @@\n+/**\n+ * Copyright (C) 2016-2020 Expedia, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hotels.bdp.circustrain.core.replica.hive;\n+\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.junit.Assert.assertThat;\n+import static org.junit.Assert.fail;\n+import static org.mockito.Mockito.doThrow;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.verifyNoMoreInteractions;\n+import static org.mockito.Mockito.when;\n+\n+import org.apache.hadoop.hive.metastore.api.Table;\n+import org.apache.thrift.TException;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.mockito.Mock;\n+import org.mockito.runners.MockitoJUnitRunner;\n+\n+import com.hotels.hcommon.hive.metastore.client.api.CloseableMetaStoreClient;\n+\n+@RunWith(MockitoJUnitRunner.class)\n+public class RenameTableOperationTest {\n+\n+  private static final String FROM_TABLE_NAME = \"old_table\";\n+  private static final String TO_TABLE_NAME = \"new_table\";\n+  private static final String TO_TABLE_NAME_TEMP = TO_TABLE_NAME + \"_delete_me\";\n+  private static final String FROM_DB_NAME = \"old_db\";\n+  private static final String TO_DB_NAME = \"new_db\";\n+\n+  private @Mock CloseableMetaStoreClient client;\n+  private @Mock DropTableService dropTableService;\n+  private Table fromTable = new Table();\n+  private Table toTable = new Table();\n+  private RenameTableOperation operation;\n+\n+  @Before\n+  public void setUp() throws TException {\n+    operation = new RenameTableOperation(dropTableService);\n+    fromTable.setTableName(FROM_TABLE_NAME);\n+    toTable.setTableName(TO_TABLE_NAME);\n+    fromTable.setDbName(FROM_DB_NAME);\n+    toTable.setDbName(TO_DB_NAME);\n+    when(client.getTable(FROM_DB_NAME, FROM_TABLE_NAME)).thenReturn(fromTable);\n+    when(client.getTable(TO_DB_NAME, TO_TABLE_NAME)).thenReturn(toTable);\n+  }\n+\n+  @Test\n+  public void typicalRenameTable() throws Exception {\n+    Table toTableTemp = new Table(toTable);\n+    toTableTemp.setTableName(TO_TABLE_NAME_TEMP);\n+\n+    operation.execute(client, fromTable, toTable);\n+\n+    fromTable.setTableName(TO_TABLE_NAME);\n+    verify(client).alter_table(TO_DB_NAME, TO_TABLE_NAME, toTableTemp);\n+    verify(client).alter_table(FROM_DB_NAME, FROM_TABLE_NAME, fromTable);\n+    verify(dropTableService).removeTableParamsAndDrop(client, TO_DB_NAME, TO_TABLE_NAME_TEMP);\n+  }\n+\n+  @Test\n+  public void renameTableExceptionThrown1() throws Exception {", "originalCommit": "2b933684b80afe94031fb06103e198f6d7571af3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "2b2664f8eb5a3757b1a531868387eb50516a9f66", "url": "https://github.com/ExpediaGroup/circus-train/commit/2b2664f8eb5a3757b1a531868387eb50516a9f66", "message": "Fixing pom and test names", "committedDate": "2020-03-13T12:54:20Z", "type": "commit"}, {"oid": "e8cd3a80e502048fa97999d52bbad460f07ded75", "url": "https://github.com/ExpediaGroup/circus-train/commit/e8cd3a80e502048fa97999d52bbad460f07ded75", "message": "Minor change", "committedDate": "2020-03-16T18:17:11Z", "type": "commit"}, {"oid": "4e40d296706864874e46b430285b4ef390f71373", "url": "https://github.com/ExpediaGroup/circus-train/commit/4e40d296706864874e46b430285b4ef390f71373", "message": "Merge branch 'master' into issue-173-struct-evolution", "committedDate": "2020-03-16T18:20:30Z", "type": "commit"}, {"oid": "971e66912f4343a8c282df993e804c7185329542", "url": "https://github.com/ExpediaGroup/circus-train/commit/971e66912f4343a8c282df993e804c7185329542", "message": "Fixing tests", "committedDate": "2020-03-16T18:35:45Z", "type": "commit"}]}