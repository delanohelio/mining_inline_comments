{"pr_number": 759, "pr_title": "Object store/ azure", "pr_createdAt": "2020-07-20T20:13:08Z", "pr_url": "https://github.com/phac-nml/irida/pull/759", "timeline": [{"oid": "0445c89578747aac1142ce23e532c5edcc401053", "url": "https://github.com/phac-nml/irida/commit/0445c89578747aac1142ce23e532c5edcc401053", "message": "Added azure file storage implementation", "committedDate": "2020-04-20T21:21:44Z", "type": "commit"}, {"oid": "74a8321c54e160dd9e90d0e8334bd71a1592618e", "url": "https://github.com/phac-nml/irida/commit/74a8321c54e160dd9e90d0e8334bd71a1592618e", "message": "Removed aws dependencies", "committedDate": "2020-04-20T21:32:33Z", "type": "commit"}, {"oid": "d551c2fe591feb148ff467010f70e6b792bb12a0", "url": "https://github.com/phac-nml/irida/commit/d551c2fe591feb148ff467010f70e6b792bb12a0", "message": "Merged base branch and fixed merge conflicts", "committedDate": "2020-04-22T19:36:30Z", "type": "commit"}, {"oid": "f3429d99afc7a0bd179ae7ecbaeb31ffbc33610e", "url": "https://github.com/phac-nml/irida/commit/f3429d99afc7a0bd179ae7ecbaeb31ffbc33610e", "message": "Removed unused imports", "committedDate": "2020-04-22T19:50:39Z", "type": "commit"}, {"oid": "9ce1be7b8f077b7854d2e2acde4a1f34b9e1ef74", "url": "https://github.com/phac-nml/irida/commit/9ce1be7b8f077b7854d2e2acde4a1f34b9e1ef74", "message": "Upped the version of azure to fix race condition when opening blob stream. Updated comments and refactored code", "committedDate": "2020-04-23T15:52:33Z", "type": "commit"}, {"oid": "101099a6b1ef2f7159e70927e5c062f3030bf7d9", "url": "https://github.com/phac-nml/irida/commit/101099a6b1ef2f7159e70927e5c062f3030bf7d9", "message": "Merge branch 'object_store/_base' into object_store/_azure", "committedDate": "2020-04-27T19:35:11Z", "type": "commit"}, {"oid": "ce85c264c2101c58af82305b22c3e0834d6f2aa3", "url": "https://github.com/phac-nml/irida/commit/ce85c264c2101c58af82305b22c3e0834d6f2aa3", "message": "Updated tests", "committedDate": "2020-04-27T21:50:26Z", "type": "commit"}, {"oid": "ed8865f30d2231b6e77c329ff02e65cc8a936d72", "url": "https://github.com/phac-nml/irida/commit/ed8865f30d2231b6e77c329ff02e65cc8a936d72", "message": "Updated code to work with newer version of jackson-core", "committedDate": "2020-04-29T00:27:05Z", "type": "commit"}, {"oid": "c217c4d0ac3fe00dadc281ed632faf9e2e040437", "url": "https://github.com/phac-nml/irida/commit/c217c4d0ac3fe00dadc281ed632faf9e2e040437", "message": "Merge branch 'object_store/_base' into object_store/_azure", "committedDate": "2020-04-29T15:58:20Z", "type": "commit"}, {"oid": "b4e3f7f0b661a09eb16bcfa91cc1eed46a6bb7f5", "url": "https://github.com/phac-nml/irida/commit/b4e3f7f0b661a09eb16bcfa91cc1eed46a6bb7f5", "message": "Merge branch 'object_store/_base' into object_store/_azure", "committedDate": "2020-04-30T18:55:09Z", "type": "commit"}, {"oid": "4f8c98839535c513553bf2e631a0931f485b1215", "url": "https://github.com/phac-nml/irida/commit/4f8c98839535c513553bf2e631a0931f485b1215", "message": "Merge branch 'object_store/_base' into object_store/_azure", "committedDate": "2020-05-06T13:57:51Z", "type": "commit"}, {"oid": "e973db16d219e031e22491940f1474092f08563a", "url": "https://github.com/phac-nml/irida/commit/e973db16d219e031e22491940f1474092f08563a", "message": "Merge branch 'object_store/_base' into object_store/_azure", "committedDate": "2020-05-20T19:40:32Z", "type": "commit"}, {"oid": "90cfe53775e71c23153b9fde660abf5751052bee", "url": "https://github.com/phac-nml/irida/commit/90cfe53775e71c23153b9fde660abf5751052bee", "message": "Updated controller to fix failing tests", "committedDate": "2020-05-20T21:00:46Z", "type": "commit"}, {"oid": "91f6ab21233ed70229d975769fe2d9fe73514134", "url": "https://github.com/phac-nml/irida/commit/91f6ab21233ed70229d975769fe2d9fe73514134", "message": "Merge branch 'object_store/_base' into object_store/_azure", "committedDate": "2020-05-22T23:33:20Z", "type": "commit"}, {"oid": "cd96c3493b5c8149955db9d28e046b6ddc5ebdbe", "url": "https://github.com/phac-nml/irida/commit/cd96c3493b5c8149955db9d28e046b6ddc5ebdbe", "message": "Merge branch 'object_store/_base' into object_store/_azure", "committedDate": "2020-05-26T19:23:47Z", "type": "commit"}, {"oid": "94589440146b32ec5321a9b836aaa76cf2a613dc", "url": "https://github.com/phac-nml/irida/commit/94589440146b32ec5321a9b836aaa76cf2a613dc", "message": "Merged base branch and fixed merge conflict", "committedDate": "2020-06-16T20:09:08Z", "type": "commit"}, {"oid": "089e266b987e1cdb2a2d57b48400709b09237416", "url": "https://github.com/phac-nml/irida/commit/089e266b987e1cdb2a2d57b48400709b09237416", "message": "Merged base branch, fixed merge conflict. Updated name to IridaFileStorageAzureUtilityImpl for azure implementation", "committedDate": "2020-06-17T18:36:06Z", "type": "commit"}, {"oid": "7efb45d0e13a4d517edc3e626811a1cf1f5ebdb0", "url": "https://github.com/phac-nml/irida/commit/7efb45d0e13a4d517edc3e626811a1cf1f5ebdb0", "message": "Merged base branch and fixed merge conflict", "committedDate": "2020-07-15T15:45:56Z", "type": "commit"}, {"oid": "34cd883c2658a9e931632d050caf94477797af03", "url": "https://github.com/phac-nml/irida/commit/34cd883c2658a9e931632d050caf94477797af03", "message": "Merge branch 'object-store' into object_store/_azure", "committedDate": "2020-07-17T15:52:06Z", "type": "commit"}, {"oid": "4e01fe6b246dd047f1f56f039c7f4554b555eed2", "url": "https://github.com/phac-nml/irida/commit/4e01fe6b246dd047f1f56f039c7f4554b555eed2", "message": "Merge branch 'object-store' into object_store/_azure", "committedDate": "2020-07-20T20:09:48Z", "type": "commit"}, {"oid": "8b92448777d5c6315b6bcf15cba595ade32246d2", "url": "https://github.com/phac-nml/irida/commit/8b92448777d5c6315b6bcf15cba595ade32246d2", "message": "Changed concateexception to ioexception. Updated getFileSize method in azure implementation of iridafilestorageutility to return a string", "committedDate": "2020-07-20T20:32:54Z", "type": "commit"}, {"oid": "95e89d3e27aec6c6e87ee4d679ceeb40362f91c1", "url": "https://github.com/phac-nml/irida/commit/95e89d3e27aec6c6e87ee4d679ceeb40362f91c1", "message": "Renamed method parameter to be generic. Updated text displayed when an IOException is thrown", "committedDate": "2020-07-20T20:35:16Z", "type": "commit"}, {"oid": "c8583556018d5858fe0a79335181d1877154c442", "url": "https://github.com/phac-nml/irida/commit/c8583556018d5858fe0a79335181d1877154c442", "message": "Removed unused imports", "committedDate": "2020-07-20T21:19:42Z", "type": "commit"}, {"oid": "e91bafbbf743a246c50ac4f4acac398217beafd4", "url": "https://github.com/phac-nml/irida/commit/e91bafbbf743a246c50ac4f4acac398217beafd4", "message": "Updated test variable", "committedDate": "2020-07-20T21:52:59Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTA2MDYzNA==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r461060634", "bodyText": "Why do we need the @ResponseBody stuff here?  The REST API should automatically be returning JSON without it.  What happens without these?", "author": "tom114", "createdAt": "2020-07-27T17:43:25Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/web/controller/api/projects/RESTProjectAnalysisController.java", "diffHunk": "@@ -65,6 +66,7 @@ public RESTProjectAnalysisController(ProjectService projectService,\n \t *         {@link Project}.\n \t */\n \t@RequestMapping(value = \"/api/projects/{projectId}/analyses\", method = RequestMethod.GET)\n+\t@ResponseBody", "originalCommit": "e91bafbbf743a246c50ac4f4acac398217beafd4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU5NjU5Mw==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r462596593", "bodyText": "Since the Azure sdk required jackson >2.10 the tests for this as well as the AnalysisAjaxTableController tests broke. My guess is the response is not being serialized properly", "author": "deepsidhu85", "createdAt": "2020-07-29T21:21:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTA2MDYzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzg0MTY5Ng==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r463841696", "bodyText": "Ok.  So I think something is going funny that made this necessary.  Our REST config in https://github.com/phac-nml/irida/blob/development/src/main/java/ca/corefacility/bioinformatics/irida/config/web/IridaRestApiWebConfig.java should serialize any resource to JSON automatically without the @ResponseBody annotation.  When I'm going through the rest api with curl I'm noticing some controllers being pretty-printed and some that aren't.  Pretty print is set up in https://github.com/phac-nml/irida/blob/development/src/main/java/ca/corefacility/bioinformatics/irida/config/web/IridaRestApiWebConfig.java#L73 and I think should be universal through the REST API.\nSo long story short, something funny is going on to need this.  I think we'll have to dig because there's something going wrong with configuration somehow.", "author": "tom114", "createdAt": "2020-07-31T21:06:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTA2MDYzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTExMTM4OQ==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r465111389", "bodyText": "Sure I will take a look into it and see if I can figure out what's going on", "author": "deepsidhu85", "createdAt": "2020-08-04T14:53:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTA2MDYzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTMzNTM4NQ==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r469335385", "bodyText": "Updated with PR #769", "author": "deepsidhu85", "createdAt": "2020-08-12T15:14:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTA2MDYzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTEwMDc1Mg==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r461100752", "bodyText": "This section looks like duplicate imports to me.  Aren't these already imported somewhere else?", "author": "tom114", "createdAt": "2020-07-27T18:54:58Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/web/controller/api/projects/RESTProjectSamplesController.java", "diffHunk": "@@ -35,6 +35,16 @@\n import ca.corefacility.bioinformatics.irida.web.controller.api.samples.RESTSampleMetadataController;\n import ca.corefacility.bioinformatics.irida.web.controller.api.samples.RESTSampleSequenceFilesController;\n \n+import com.google.common.net.HttpHeaders;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.hateoas.Link;\n+import org.springframework.http.HttpStatus;\n+import org.springframework.http.MediaType;\n+import org.springframework.stereotype.Controller;\n+import org.springframework.ui.ModelMap;\n+import org.springframework.web.bind.annotation.*;\n+import org.springframework.web.servlet.ModelAndView;\n+import org.springframework.web.servlet.view.RedirectView;", "originalCommit": "e91bafbbf743a246c50ac4f4acac398217beafd4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU5MzY1NQ==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r462593655", "bodyText": "Looks like they were missed. I will remove these", "author": "deepsidhu85", "createdAt": "2020-07-29T21:15:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTEwMDc1Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTE2OTk0Ng==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r465169946", "bodyText": "Removed in 23c0b6d", "author": "deepsidhu85", "createdAt": "2020-08-04T16:16:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTEwMDc1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTU5OTY5Mw==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r461599693", "bodyText": "Rather than directly creating a file in /tmp use the Files.createTempDirectory method.  This will automatically create a unique directory in the appropriate location.", "author": "tom114", "createdAt": "2020-07-28T13:56:24Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,243 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\tprivate BlobClient blobClient;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\t// Create a file that will be unique in the /tmp/ folder. We append the current date/time\n+\t\t\t// to the file name\n+\t\t\tString tmpDir = \"/tmp/\" + new Date().toString().replaceAll(\"\\\\W\", \"\");", "originalCommit": "e91bafbbf743a246c50ac4f4acac398217beafd4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU5NDAwMQ==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r462594001", "bodyText": "This has been completely changed. If you take a look at the object_store/_analysis_submissions PR, I've made use of the existing folders", "author": "deepsidhu85", "createdAt": "2020-07-29T21:16:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTU5OTY5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzg0ODI1OQ==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r463848259", "bodyText": "I see the getFile method in that branch, but it looks like it might have a slightly different use?  I understand the change later in the chain, but can it get pulled down to this PR since it was found here?  Its too easy for temporary stuff like this to accidentally slip by when getting reviewed later.", "author": "tom114", "createdAt": "2020-07-31T21:15:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTU5OTY5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTExMTg1Mg==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r465111852", "bodyText": "Sure I can pull it down into here. The use is the same just renamed the method in a later branch", "author": "deepsidhu85", "createdAt": "2020-08-04T14:53:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTU5OTY5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTE3MDAxNA==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r465170014", "bodyText": "Updated in 23c0b6d", "author": "deepsidhu85", "createdAt": "2020-08-04T16:16:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTU5OTY5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTYwMTE3Nw==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r461601177", "bodyText": "Should this be a global?  It looks like it's initialized in every method.", "author": "tom114", "createdAt": "2020-07-28T13:58:24Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,243 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\tprivate BlobClient blobClient;", "originalCommit": "e91bafbbf743a246c50ac4f4acac398217beafd4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTE3MzM5Ng==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r465173396", "bodyText": "Removed global in 23c0b6d", "author": "deepsidhu85", "createdAt": "2020-08-04T16:22:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTYwMTE3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY1MTMwNA==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r461651304", "bodyText": "What's this for?  If it's just some random requirement for this code can you write a long comment about why it's here?", "author": "tom114", "createdAt": "2020-07-28T14:59:30Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,243 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\tprivate BlobClient blobClient;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\t// Create a file that will be unique in the /tmp/ folder. We append the current date/time\n+\t\t\t// to the file name\n+\t\t\tString tmpDir = \"/tmp/\" + new Date().toString().replaceAll(\"\\\\W\", \"\");\n+\t\t\t// Since the file system is virtual the full file path is the file name.\n+\t\t\t// We split it on \"/\" and get the last token which is the actual file name.\n+\t\t\tString [] blobNameTokens = blobClient.getBlobName().split(\"/\");\n+\t\t\tString fileName = blobNameTokens[blobNameTokens.length-1];\n+\t\t\tString filePath = tmpDir + fileName;\n+\t\t\tblobClient.downloadToFile(filePath);\n+\t\t\tfileToProcess = new File(filePath);\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t}\n+\n+\t\treturn fileToProcess;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic String getFileSize(Path file) {\n+\t\tString fileSize = \"N/A\";\n+\t\ttry {\n+\t\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\t\tfileSize = FileUtils.humanReadableByteCount(blobClient.getProperties().getBlobSize(), true);\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't calculate size as the file was not found on azure [\" + e + \"]\");\n+\t\t}\n+\t\treturn fileSize;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic void writeFile(Path source, Path target, Path sequenceFileDir, Path sequenceFileDirWithRevision) {\n+\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(target));\n+\t\ttry {\n+\t\t\tlogger.trace(\"Uploading file to azure: [\" + target.getFileName() + \"]\");\n+\t\t\tblobClient.uploadFromFile(source.toString(), false);\n+\t\t\tlogger.trace(\"File uploaded to: [\" + blobClient.getBlobUrl() + \"]\");\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Unable to upload file to azure [\" + e + \"]\");\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic boolean storageTypeIsLocal(){\n+\t\treturn false;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\tpublic String getFileName(Path file) {\n+\t\tString fileName = \"\";\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\ttry {\n+\t\t\t// Since the file system is virtual the full file path is the file name.\n+\t\t\t// We split it on \"/\" and get the last token which is the actual file name.\n+\t\t\tString[] blobNameTokens = blobClient.getBlobName()\n+\t\t\t\t\t.split(\"/\");\n+\t\t\tfileName = blobNameTokens[blobNameTokens.length - 1];\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t}\n+\n+\t\treturn fileName;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic boolean fileExists(Path file) {\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\tif(blobClient.exists()) {\n+\t\t\treturn true;\n+\t\t}\n+\t\treturn false;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic InputStream getFileInputStream(Path file) {\n+\t\ttry {\n+\t\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't read file from azure [\" + e + \"]\");\n+\t\t}\n+\t\treturn blobClient.openInputStream();\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic boolean isGzipped(Path file) throws IOException {\n+\t\ttry (InputStream is = getFileInputStream(file)) {\n+\t\t\tbyte[] bytes = new byte[2];\n+\t\t\tis.read(bytes);\n+\t\t\treturn ((bytes[0] == (byte) (GZIPInputStream.GZIP_MAGIC))\n+\t\t\t\t\t&& (bytes[1] == (byte) (GZIPInputStream.GZIP_MAGIC >> 8)));\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Removes the leading \"/\" from the absolute path\n+\t * returns the rest of the path.\n+\t *\n+\t * @param file\n+\t * @return\n+\t */\n+\tprivate String getAzureFileAbsolutePath(Path file) {", "originalCommit": "e91bafbbf743a246c50ac4f4acac398217beafd4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU5NjExMQ==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r462596111", "bodyText": "Azure and AWS use a virtual filesystem. For example /opt/irida/data/sequence/1/filename.fastq would be the object. The file paths stored in the db have a leading slash which if we attempt to locate in the object store it tries to find containerName//object instead of containerName/object resulting in the bucket object (s3) or the blob(azure) not being found.\nI will update the comment to make this clear", "author": "deepsidhu85", "createdAt": "2020-07-29T21:20:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY1MTMwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzg1MzAxMw==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r463853013", "bodyText": "Ok.  Is there maybe a different implementation of Path that should be used for these cloud types?  Or maybe the Path class isn't the appropriate thing to store for this anymore?  I think Path is something that is assumed to be a file system reference.  Here since it's no longer a file on a file system we need to keep converting it.  Maybe we should be storing these paths in another way.  Lets talk about it next week.", "author": "tom114", "createdAt": "2020-07-31T21:22:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY1MTMwNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY1MjY0OA==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r461652648", "bodyText": "The VALID_EXTENSIONS thing is for concatenating right?  Can you rename that variable and the comments around it with that info please?  It confuses me every time.", "author": "tom114", "createdAt": "2020-07-28T15:01:15Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,243 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\tprivate BlobClient blobClient;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\t// Create a file that will be unique in the /tmp/ folder. We append the current date/time\n+\t\t\t// to the file name\n+\t\t\tString tmpDir = \"/tmp/\" + new Date().toString().replaceAll(\"\\\\W\", \"\");\n+\t\t\t// Since the file system is virtual the full file path is the file name.\n+\t\t\t// We split it on \"/\" and get the last token which is the actual file name.\n+\t\t\tString [] blobNameTokens = blobClient.getBlobName().split(\"/\");\n+\t\t\tString fileName = blobNameTokens[blobNameTokens.length-1];\n+\t\t\tString filePath = tmpDir + fileName;\n+\t\t\tblobClient.downloadToFile(filePath);\n+\t\t\tfileToProcess = new File(filePath);\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t}\n+\n+\t\treturn fileToProcess;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic String getFileSize(Path file) {\n+\t\tString fileSize = \"N/A\";\n+\t\ttry {\n+\t\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\t\tfileSize = FileUtils.humanReadableByteCount(blobClient.getProperties().getBlobSize(), true);\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't calculate size as the file was not found on azure [\" + e + \"]\");\n+\t\t}\n+\t\treturn fileSize;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic void writeFile(Path source, Path target, Path sequenceFileDir, Path sequenceFileDirWithRevision) {\n+\t\t// We set the blobClient \"path\" to which we want to upload our file to\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(target));\n+\t\ttry {\n+\t\t\tlogger.trace(\"Uploading file to azure: [\" + target.getFileName() + \"]\");\n+\t\t\tblobClient.uploadFromFile(source.toString(), false);\n+\t\t\tlogger.trace(\"File uploaded to: [\" + blobClient.getBlobUrl() + \"]\");\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Unable to upload file to azure [\" + e + \"]\");\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic boolean storageTypeIsLocal(){\n+\t\treturn false;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\tpublic String getFileName(Path file) {\n+\t\tString fileName = \"\";\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\ttry {\n+\t\t\t// Since the file system is virtual the full file path is the file name.\n+\t\t\t// We split it on \"/\" and get the last token which is the actual file name.\n+\t\t\tString[] blobNameTokens = blobClient.getBlobName()\n+\t\t\t\t\t.split(\"/\");\n+\t\t\tfileName = blobNameTokens[blobNameTokens.length - 1];\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t}\n+\n+\t\treturn fileName;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic boolean fileExists(Path file) {\n+\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\tif(blobClient.exists()) {\n+\t\t\treturn true;\n+\t\t}\n+\t\treturn false;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic InputStream getFileInputStream(Path file) {\n+\t\ttry {\n+\t\t\tblobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't read file from azure [\" + e + \"]\");\n+\t\t}\n+\t\treturn blobClient.openInputStream();\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic boolean isGzipped(Path file) throws IOException {\n+\t\ttry (InputStream is = getFileInputStream(file)) {\n+\t\t\tbyte[] bytes = new byte[2];\n+\t\t\tis.read(bytes);\n+\t\t\treturn ((bytes[0] == (byte) (GZIPInputStream.GZIP_MAGIC))\n+\t\t\t\t\t&& (bytes[1] == (byte) (GZIPInputStream.GZIP_MAGIC >> 8)));\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Removes the leading \"/\" from the absolute path\n+\t * returns the rest of the path.\n+\t *\n+\t * @param file\n+\t * @return\n+\t */\n+\tprivate String getAzureFileAbsolutePath(Path file) {\n+\t\tString absolutePath = file.toAbsolutePath().toString();\n+\t\tif(absolutePath.charAt(0) == '/') {\n+\t\t\tabsolutePath = file.toAbsolutePath()\n+\t\t\t\t\t.toString()\n+\t\t\t\t\t.substring(1);\n+\t\t}\n+\t\treturn absolutePath;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic void appendToFile(Path target, SequenceFile file) throws IOException{\n+\t\ttry (FileChannel out = FileChannel.open(target, StandardOpenOption.CREATE, StandardOpenOption.APPEND,\n+\t\t\t\tStandardOpenOption.WRITE)) {\n+\t\t\ttry (FileChannel in = new FileInputStream(getTemporaryFile(file.getFile())).getChannel()) {\n+\t\t\t\tfor (long p = 0, l = in.size(); p < l; ) {\n+\t\t\t\t\tp += in.transferTo(p, l - p, out);\n+\t\t\t\t}\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tthrow new IOException(\"Could not open input file for reading\", e);\n+\t\t\t}\n+\n+\t\t} catch (IOException e) {\n+\t\t\tthrow new IOException(\"Could not open target file for writing\", e);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic String getFileExtension(List<? extends SequencingObject> sequencingObjects) throws IOException {\n+\t\tString selectedExtension = null;\n+\t\tfor (SequencingObject object : sequencingObjects) {\n+\n+\t\t\tfor (SequenceFile file : object.getFiles()) {\n+\t\t\t\tString fileName = getFileName(file.getFile());\n+\n+\t\t\t\tOptional<String> currentExtensionOpt = VALID_EXTENSIONS.stream()", "originalCommit": "e91bafbbf743a246c50ac4f4acac398217beafd4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU5NjI1NQ==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r462596255", "bodyText": "Sure I will get that updated", "author": "deepsidhu85", "createdAt": "2020-07-29T21:20:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY1MjY0OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTE4ODcxNQ==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r465188715", "bodyText": "Updated in fdd25e1", "author": "deepsidhu85", "createdAt": "2020-08-04T16:47:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY1MjY0OA=="}], "type": "inlineReview"}, {"oid": "23c0b6d48cdf222b4c5674c280f79ed361766082", "url": "https://github.com/phac-nml/irida/commit/23c0b6d48cdf222b4c5674c280f79ed361766082", "message": "Removed @ResponseBody from rest controllers. Updated azure storage utility getTemporaryFile method. Removed duplicate imports", "committedDate": "2020-08-04T16:16:10Z", "type": "commit"}, {"oid": "2fbdcba5960698104c64d60d0dc1e65ac704d670", "url": "https://github.com/phac-nml/irida/commit/2fbdcba5960698104c64d60d0dc1e65ac704d670", "message": "Removed unused imports", "committedDate": "2020-08-04T16:28:10Z", "type": "commit"}, {"oid": "fdd25e1d2dc4f0342951f50e259cf2ec0657dfb2", "url": "https://github.com/phac-nml/irida/commit/fdd25e1d2dc4f0342951f50e259cf2ec0657dfb2", "message": "Updated variable name", "committedDate": "2020-08-04T16:46:47Z", "type": "commit"}, {"oid": "51d1b298f6f6d0e5746810c1742022ea2c4a1d9e", "url": "https://github.com/phac-nml/irida/commit/51d1b298f6f6d0e5746810c1742022ea2c4a1d9e", "message": "Updated variable name", "committedDate": "2020-08-04T17:54:09Z", "type": "commit"}, {"oid": "ed912d41e3c61a6f49f0641acb0a16d93790af26", "url": "https://github.com/phac-nml/irida/commit/ed912d41e3c61a6f49f0641acb0a16d93790af26", "message": "Merge branch 'object-store' into object_store/_azure", "committedDate": "2020-08-12T15:00:52Z", "type": "commit"}, {"oid": "eea5f064c73e6ad6b63c67e60d129480dcb974a3", "url": "https://github.com/phac-nml/irida/commit/eea5f064c73e6ad6b63c67e60d129480dcb974a3", "message": "Removed dependency not required. Updated comments", "committedDate": "2020-08-12T15:04:46Z", "type": "commit"}, {"oid": "1d77db91ce07dee1b577890082d13ee5360a0717", "url": "https://github.com/phac-nml/irida/commit/1d77db91ce07dee1b577890082d13ee5360a0717", "message": "Removed @ResponseBody annotation not required", "committedDate": "2020-08-12T15:08:29Z", "type": "commit"}, {"oid": "4d7418652545636565ceb4389f8db1cc6166e90b", "url": "https://github.com/phac-nml/irida/commit/4d7418652545636565ceb4389f8db1cc6166e90b", "message": "Merge branch 'object-store' into object_store/_azure", "committedDate": "2020-08-13T16:37:47Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU0ODAxMw==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r469548013", "bodyText": "These exceptions should be logger.error level at least.  Honestly I'm not even sure these should be caught.  Should they maybe just be let go so that an appropriate error gets thrown up?  Just swallowing them here and logging could cause issues.", "author": "tom114", "createdAt": "2020-08-12T21:08:35Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,240 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which file we want to get\n+\t\tBlobClient blobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\tInputStream initialStream = blobClient.openInputStream();\n+\t\t\tFile targetFile = new File(file.toAbsolutePath().toString());\n+\t\t\torg.apache.commons.io.FileUtils.copyInputStreamToFile(initialStream, targetFile);\n+\t\t\tinitialStream.close();\n+\t\t\tfileToProcess = targetFile;\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.trace(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t} catch (IOException e) {\n+\t\t\tlogger.debug(e.getMessage());\n+\t\t}", "originalCommit": "1d77db91ce07dee1b577890082d13ee5360a0717", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDE2MTkwNg==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r470161906", "bodyText": "As we discussed I think it would be good to wrap these exceptions in a StorageException.  We're already using that in the local storage utility so it would be good to use the same thing.\nPlease add that to any of the places in this file where we're just wrapping the BlobStorageException and logging.", "author": "tom114", "createdAt": "2020-08-13T18:30:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU0ODAxMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUwNzU3Mw==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r472507573", "bodyText": "Updated in 4b16c81", "author": "deepsidhu85", "createdAt": "2020-08-18T21:37:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU0ODAxMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDE2MjQzMA==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r470162430", "bodyText": "As discussed lets try switching this to use Files.createTempFile instead of downloading to this specified location.", "author": "tom114", "createdAt": "2020-08-13T18:31:44Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,240 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which file we want to get\n+\t\tBlobClient blobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\tInputStream initialStream = blobClient.openInputStream();\n+\t\t\tFile targetFile = new File(file.toAbsolutePath().toString());\n+\t\t\torg.apache.commons.io.FileUtils.copyInputStreamToFile(initialStream, targetFile);\n+\t\t\tinitialStream.close();\n+\t\t\tfileToProcess = targetFile;", "originalCommit": "4d7418652545636565ceb4389f8db1cc6166e90b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUwNzc2MQ==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r472507761", "bodyText": "Updated in bdee3fd", "author": "deepsidhu85", "createdAt": "2020-08-18T21:37:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDE2MjQzMA=="}], "type": "inlineReview"}, {"oid": "bdee3fd5ecbe7c0e5096d3f5889a51af59eac4f2", "url": "https://github.com/phac-nml/irida/commit/bdee3fd5ecbe7c0e5096d3f5889a51af59eac4f2", "message": "Updated to use temporary files which are cleaned up after they have been used", "committedDate": "2020-08-18T21:22:16Z", "type": "commit"}, {"oid": "4b16c81a35cbfe72080cf3818046d989db28fcad", "url": "https://github.com/phac-nml/irida/commit/4b16c81a35cbfe72080cf3818046d989db28fcad", "message": "Updated to throw a storageexception if file is not found on azure rather than just logging a message", "committedDate": "2020-08-18T21:36:51Z", "type": "commit"}, {"oid": "d1684d340301b0ee6445ac72a903ac6019342a4c", "url": "https://github.com/phac-nml/irida/commit/d1684d340301b0ee6445ac72a903ac6019342a4c", "message": "Updated FastQCFileProcessor to clean up temp files in a finally block. Updated cleanupLocalFiles method to removed temp directories", "committedDate": "2020-08-20T20:12:16Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTY1NzY3NA==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r475657674", "bodyText": "This class should be throwing a StorageException in all of these catch cases.  This method and all of the below.", "author": "tom114", "createdAt": "2020-08-24T14:34:24Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,279 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.exceptions.StorageException;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which file we want to get\n+\t\tBlobClient blobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\tlogger.trace(\"Getting file from azure [\" + file.toString() + \"]\");\n+\t\t\tPath tempDirectory = Files.createTempDirectory(null);\n+\t\t\tPath tempFile = tempDirectory.resolve(file.getFileName().toString());\n+\t\t\tInputStream initialStream = blobClient.openInputStream();\n+\t\t\torg.apache.commons.io.FileUtils.copyInputStreamToFile(initialStream, tempFile.toFile());\n+\t\t\tinitialStream.close();\n+\t\t\tfileToProcess = tempFile.toFile();\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.error(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t\tthrow new StorageException(\"Unable to locate file on azure\", e);\n+\t\t} catch (IOException e) {\n+\t\t\tlogger.error(e.getMessage());", "originalCommit": "d1684d340301b0ee6445ac72a903ac6019342a4c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjU4MjgxMw==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r476582813", "bodyText": "Updated in 5988e06", "author": "deepsidhu85", "createdAt": "2020-08-25T16:33:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTY1NzY3NA=="}], "type": "inlineReview"}, {"oid": "5988e06b794923529c3dd6889ff54b983970516a", "url": "https://github.com/phac-nml/irida/commit/5988e06b794923529c3dd6889ff54b983970516a", "message": "Changed from throwing ioexception to storageexception in azure file storage utility class", "committedDate": "2020-08-25T16:32:55Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODUzMjAxNg==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r478532016", "bodyText": "I don't think we should walk up to delete a parent directory.  While this shouldn't be an issue with our temp directories, it has the possibility of being accidentally misused and deleting a required directory.  if we're deleting a directory, I think it should be explicitly called to be deleted.", "author": "tom114", "createdAt": "2020-08-27T16:06:10Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,281 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.exceptions.StorageException;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic File getTemporaryFile(Path file) {\n+\t\tFile fileToProcess = null;\n+\n+\t\t// We set the blobClient \"path\" to which file we want to get\n+\t\tBlobClient blobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\tlogger.trace(\"Getting file from azure [\" + file.toString() + \"]\");\n+\t\t\tPath tempDirectory = Files.createTempDirectory(null);\n+\t\t\tPath tempFile = tempDirectory.resolve(file.getFileName().toString());\n+\t\t\tInputStream initialStream = blobClient.openInputStream();\n+\t\t\torg.apache.commons.io.FileUtils.copyInputStreamToFile(initialStream, tempFile.toFile());\n+\t\t\tinitialStream.close();\n+\t\t\tfileToProcess = tempFile.toFile();\n+\t\t} catch (BlobStorageException e) {\n+\t\t\tlogger.error(\"Couldn't find file on azure [\" + e + \"]\");\n+\t\t\tthrow new StorageException(\"Unable to locate file on azure\", e);\n+\t\t} catch (IOException e) {\n+\t\t\tlogger.error(e.getMessage());\n+\t\t\tthrow new StorageException(e.getMessage());\n+\t\t}\n+\n+\t\treturn fileToProcess;\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic void cleanupLocalFiles(Path path) {\n+\t\tlogger.trace(\"Cleaning up temporary file downloaded from azure [\" + path.toString() + \"]\");\n+\n+\t\tPath origPath = path;\n+\t\tif(Files.isRegularFile(path)) {\n+\t\t\torigPath = path;\n+\t\t\tpath = path.getParent();", "originalCommit": "5988e06b794923529c3dd6889ff54b983970516a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjE2Njg0Ng==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r482166846", "bodyText": "Updated in 05feefc", "author": "deepsidhu85", "createdAt": "2020-09-02T15:34:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODUzMjAxNg=="}], "type": "inlineReview"}, {"oid": "46fe13d1c605f4f904ff4b5ec6f433dc322d8737", "url": "https://github.com/phac-nml/irida/commit/46fe13d1c605f4f904ff4b5ec6f433dc322d8737", "message": "Updated getTemporaryFile method to return an IridaTemporaryFile object which has the path to the file and temporary directory. Updating directory removal", "committedDate": "2020-08-31T22:29:11Z", "type": "commit"}, {"oid": "4cf54992305acf71bf222471ec4fc5d0e5d4d5fe", "url": "https://github.com/phac-nml/irida/commit/4cf54992305acf71bf222471ec4fc5d0e5d4d5fe", "message": "Fixed nullpointer", "committedDate": "2020-08-31T22:59:58Z", "type": "commit"}, {"oid": "64984255444dfcf7490e7e32af61ca717a135937", "url": "https://github.com/phac-nml/irida/commit/64984255444dfcf7490e7e32af61ca717a135937", "message": "Removed unused imports", "committedDate": "2020-08-31T23:47:27Z", "type": "commit"}, {"oid": "05feefc11ed7c0e21deb78ad450036145ace7e5f", "url": "https://github.com/phac-nml/irida/commit/05feefc11ed7c0e21deb78ad450036145ace7e5f", "message": "Added a new method to cleanup local temporary files/directories and renamed previous method named cleanupLocalFiles. Updated logic in SamplesAjaxController to cleanup temp files/directories that are created.", "committedDate": "2020-09-01T18:07:05Z", "type": "commit"}, {"oid": "8978508ddb1c7efcf74bea343516ea5fdb24b867", "url": "https://github.com/phac-nml/irida/commit/8978508ddb1c7efcf74bea343516ea5fdb24b867", "message": "Fixed logic so if the instance is using local storage it will clean up the file in a diretory if it exists", "committedDate": "2020-09-01T18:46:02Z", "type": "commit"}, {"oid": "7275c81aec8be26d33a80a302ad2a5a2484fd91a", "url": "https://github.com/phac-nml/irida/commit/7275c81aec8be26d33a80a302ad2a5a2484fd91a", "message": "Updated concatenator classes to return an iridaconcatenatortemporyfile pojo which contains the sequencing object and temporary file directory path which can be cleaned up in the sequencingobjectservice. Updated tests", "committedDate": "2020-09-01T20:33:06Z", "type": "commit"}, {"oid": "fa0aca42498ea6647309db43637647e544db2b81", "url": "https://github.com/phac-nml/irida/commit/fa0aca42498ea6647309db43637647e544db2b81", "message": "Updated gzipfileprocessor to cleanup temporary local files and directories if the removeTemporaryFiles variable is set to true (defaults to true for autowired constructor but second constructor has an extra variable which is used by the gzipfileprocessortest to not delete the temporary files as the files are cleaned up once the test has finished running). Updated logger text.", "committedDate": "2020-09-02T15:13:30Z", "type": "commit"}, {"oid": "8bd9018d94882d33a9f10ab0a3007f64ec632e0b", "url": "https://github.com/phac-nml/irida/commit/8bd9018d94882d33a9f10ab0a3007f64ec632e0b", "message": "Updated method comment", "committedDate": "2020-09-02T15:21:17Z", "type": "commit"}, {"oid": "a3254d00f733d0780c7d91896177e6f5da2b883c", "url": "https://github.com/phac-nml/irida/commit/a3254d00f733d0780c7d91896177e6f5da2b883c", "message": "Removed @Responsebody annotation for test methods as it is a restcontroller and the contentnegotiator returns the data as json", "committedDate": "2020-09-02T15:27:39Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzgxMDE2NA==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r483810164", "bodyText": "Something feels wrong with needing this file.  Particularily seeing where you use it the filePath portion is often null.  Is there a way to do this just returning either the SequencingObject or just an IridaTemporaryFile?", "author": "tom114", "createdAt": "2020-09-04T19:29:58Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/ria/web/dto/IridaConcatenatorTemporaryFile.java", "diffHunk": "@@ -0,0 +1,46 @@\n+package ca.corefacility.bioinformatics.irida.ria.web.dto;\n+\n+import java.nio.file.Path;\n+\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+\n+/**\n+ * Used as a response for encapsulating a temporary file and it's directory\n+ * for a concatenator object\n+ */\n+\n+public class IridaConcatenatorTemporaryFile {", "originalCommit": "a3254d00f733d0780c7d91896177e6f5da2b883c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTU5NDI0MQ==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r485594241", "bodyText": "Removed this in 1dbdb47 as we will deal with cleaning up local temporary files in a future branch if needed", "author": "deepsidhu85", "createdAt": "2020-09-09T13:04:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzgxMDE2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzgyNTcxMw==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r483825713", "bodyText": "If we're having this IridaTemporaryFile class we should likely have it be the responsibility of IridaFiles to create those files.  Not creating them in places like this.", "author": "tom114", "createdAt": "2020-09-04T20:11:52Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/ria/web/samples/SamplesAjaxController.java", "diffHunk": "@@ -188,22 +199,24 @@ private void createSequenceFileInSample(MultipartFile file, Sample sample) throw\n \t * @throws IOException Exception thrown if there is an error handling the file.\n \t */\n \tprivate void createFast5FileInSample(MultipartFile file, Sample sample) throws IOException {\n-\t\tSequenceFile sequenceFile = createSequenceFile(file);\n+\t\tIridaTemporaryFile iridaTemporaryFile = createSequenceFile(file);\n+\t\tSequenceFile sequenceFile = new SequenceFile(iridaTemporaryFile.getFile());\n \t\tsequencingObjectService.createSequencingObjectInSample(new Fast5Object(sequenceFile), sample);\n+\t\tIridaFiles.cleanupLocalTemporaryFiles(iridaTemporaryFile.getFile(), iridaTemporaryFile.getDirectoryPath());\n \t}\n \n \t/**\n \t * Private method to move the sequence file into the correct directory and\n-\t * create the {@link SequenceFile} object.\n+\t * create the {@link IridaTemporaryFile} object.\n \t *\n \t * @param file {@link MultipartFile} sequence file uploaded.\n-\t * @return {@link SequenceFile}\n+\t * @return {@link IridaTemporaryFile}\n \t * @throws IOException Exception thrown if there is an error handling the file.\n \t */\n-\tprivate SequenceFile createSequenceFile(MultipartFile file) throws IOException {\n+\tprivate IridaTemporaryFile createSequenceFile(MultipartFile file) throws IOException {\n \t\tPath temp = Files.createTempDirectory(null);\n \t\tPath target = temp.resolve(file.getOriginalFilename());\n \t\tfile.transferTo(target.toFile());\n-\t\treturn new SequenceFile(target);\n+\t\treturn new IridaTemporaryFile(target, temp);", "originalCommit": "a3254d00f733d0780c7d91896177e6f5da2b883c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTE4MDEzNA==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r485180134", "bodyText": "Yeah I think we should revert this to returning the SequenceFile for now.  It's back to the same issue of dealing with those temp directories.  We can address that in the future.", "author": "tom114", "createdAt": "2020-09-08T20:33:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzgyNTcxMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTU5NDM2MQ==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r485594361", "bodyText": "Reverted in 1dbdb47", "author": "deepsidhu85", "createdAt": "2020-09-09T13:04:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzgyNTcxMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTE3OTc3NQ==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r485179775", "bodyText": "As discussed lets revert these changes back to the deleteIfExists stuff for now.  We can refactor this in a later branch when needed.", "author": "tom114", "createdAt": "2020-09-08T20:32:42Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/web/controller/api/samples/RESTSampleAssemblyController.java", "diffHunk": "@@ -182,8 +183,7 @@ public ModelMap addNewAssemblyToSample(@PathVariable Long sampleId, @RequestPart\n \t\t} finally {\n \t\t\t// clean up the temporary files.\n \t\t\tlogger.trace(\"Deleted temp files\");\n-\t\t\tFiles.deleteIfExists(target);\n-\t\t\tFiles.deleteIfExists(temp);\n+\t\t\tIridaFiles.cleanupLocalTemporaryFiles(target, temp);", "originalCommit": "a3254d00f733d0780c7d91896177e6f5da2b883c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTU5NDQ0OA==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r485594448", "bodyText": "Reverted in 1dbdb47", "author": "deepsidhu85", "createdAt": "2020-09-09T13:04:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTE3OTc3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTE4MDcwNw==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r485180707", "bodyText": "If it makes sense can we just leave this method accessable form the IridaFileStorageUtility class and not in IridaFiles?  That way it's only responsible for dealing with those temporarily downloaded files.", "author": "tom114", "createdAt": "2020-09-08T20:34:42Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/util/IridaFiles.java", "diffHunk": "@@ -65,4 +66,34 @@ public static String getFileExtension(List<? extends SequencingObject> files) th\n \t\treturn iridaFileStorageUtility.getFileExtension(files);\n \t}\n \n+\t/**\n+\t * Cleans up temporary downloaded files.\n+\t *\n+\t * @param filePath The path to the file\n+\t * @param directoryPath The path to the directory which has the file\n+\t */\n+\tpublic static void cleanupDownloadedLocalTemporaryFiles(Path filePath, Path directoryPath) {\n+\t\tiridaFileStorageUtility.cleanupDownloadedLocalTemporaryFiles(filePath, directoryPath);\n+\t}\n+\n+\t/**\n+\t * Cleans up temporary files.\n+\t *\n+\t * @param filePath The path to the file\n+\t * @param directoryPath The path to the directory which has the file\n+\t */\n+\tpublic static void cleanupLocalTemporaryFiles(Path filePath, Path directoryPath) {", "originalCommit": "a3254d00f733d0780c7d91896177e6f5da2b883c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTU5NTUxMg==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r485595512", "bodyText": "Removed this method in 1dbdb47 as it is not required. We have the cleanupDownloadedTemporaryFiles method in the irida files storage utility classes to clean up any files downloaded from an object store", "author": "deepsidhu85", "createdAt": "2020-09-09T13:06:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTE4MDcwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTE4MTcwNw==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r485181707", "bodyText": "For this method please accept an IridaTemporaryFile instead of the 2 Paths.  That will help ensure we only use this in the appropriate cases.", "author": "tom114", "createdAt": "2020-09-08T20:36:43Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageUtility.java", "diffHunk": "@@ -16,15 +21,25 @@\n  */\n \n public interface IridaFileStorageUtility {\n-\t//Valid extensions to try to concatenate with this tool\n-\tpublic static final List<String> VALID_EXTENSIONS = Lists.newArrayList(\"fastq\", \"fastq.gz\");\n+\tLogger logger = LoggerFactory.getLogger(IridaFileStorageUtility.class);\n+\n+\t//Valid file extensions for sample file concatenation\n+\tpublic static final List<String> VALID_CONCATENATION_EXTENSIONS = Lists.newArrayList(\"fastq\", \"fastq.gz\");\n \t/**\n \t * Get a temporarry file from storage\n \t *\n \t * @param file The {@link Path} to the file\n-\t * @return {@link File} which was retrieved from path\n+\t * @return {@link IridaTemporaryFile} which includes the file and optional temporary directory\n+\t */\n+\tpublic IridaTemporaryFile getTemporaryFile(Path file);\n+\n+\t/**\n+\t * Delete temporary downloaded file and/or directory.\n+\t *\n+\t * @param filePath The {@link Path} to the file\n+\t * @param directoryPath The {@link Path} to the directory which has the file\n \t */\n-\tpublic File getTemporaryFile(Path file);\n+\tpublic void cleanupDownloadedLocalTemporaryFiles(Path filePath, Path directoryPath);", "originalCommit": "a3254d00f733d0780c7d91896177e6f5da2b883c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTU5NTYwOA==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r485595608", "bodyText": "Updated in 1dbdb47", "author": "deepsidhu85", "createdAt": "2020-09-09T13:06:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTE4MTcwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTE4MjQ2Mg==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r485182462", "bodyText": "After reverting back to Files.deleteIfExists in those places we discussed, you should be able to remove this static method.  I think it should likely go away.", "author": "tom114", "createdAt": "2020-09-08T20:38:11Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageUtility.java", "diffHunk": "@@ -106,4 +121,26 @@\n \t * @throws IOException if the files have different or invalid extensions\n \t */\n \tpublic String getFileExtension(List<? extends SequencingObject> sequencingObjects) throws IOException;\n+\n+\t/**\n+\t * Delete local temporary file and/or directory.\n+\t *\n+\t * @param filePath The {@link Path} to the file\n+\t * @param directoryPath The {@link Path} to the directory which has the file\n+\t */\n+\tpublic static void cleanupLocalTemporaryFiles(Path filePath, Path directoryPath) {", "originalCommit": "a3254d00f733d0780c7d91896177e6f5da2b883c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTU5NTY5Mw==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r485595693", "bodyText": "Removed in 1dbdb47", "author": "deepsidhu85", "createdAt": "2020-09-09T13:06:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTE4MjQ2Mg=="}], "type": "inlineReview"}, {"oid": "1dbdb47af3eedeee57410916380b562e92a85c41", "url": "https://github.com/phac-nml/irida/commit/1dbdb47af3eedeee57410916380b562e92a85c41", "message": "Reverted changes to clean up local temporary files. Updated cleanup downloaded local files method to accept an IridaTemporaryFile object instead of paths.", "committedDate": "2020-09-09T13:03:25Z", "type": "commit"}, {"oid": "4d3af6f73a93c490f5c649ca2b6124130711e4af", "url": "https://github.com/phac-nml/irida/commit/4d3af6f73a93c490f5c649ca2b6124130711e4af", "message": "Removed unused import and removed newlines", "committedDate": "2020-09-09T13:11:09Z", "type": "commit"}, {"oid": "852f5b9327fe79f60ef841cdec400c1466061dd7", "url": "https://github.com/phac-nml/irida/commit/852f5b9327fe79f60ef841cdec400c1466061dd7", "message": "Removed unused imports", "committedDate": "2020-09-09T14:59:23Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc3ODY2OQ==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r504778669", "bodyText": "Can we update this comment to say something about how this is a temporarily downloaded file from an online service and should be cleaned up after it's done being used?", "author": "tom114", "createdAt": "2020-10-14T15:37:49Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/ria/web/dto/IridaTemporaryFile.java", "diffHunk": "@@ -0,0 +1,33 @@\n+package ca.corefacility.bioinformatics.irida.ria.web.dto;\n+\n+import java.nio.file.Path;\n+\n+/**\n+ * Used as a response for encapsulating a temporary file and it's directory", "originalCommit": "852f5b9327fe79f60ef841cdec400c1466061dd7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDkyNDA3OQ==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r504924079", "bodyText": "Updated in 117eedc", "author": "deepsidhu85", "createdAt": "2020-10-14T19:35:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc3ODY2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTM5MTMxMA==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r509391310", "bodyText": "Just noticed the package of this file.  Definitely shouldn't be in dto.  Probably more in something like ca/corefacility/bioinformatics/irida/repositories/filesystem", "author": "tom114", "createdAt": "2020-10-21T15:35:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc3ODY2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTcwODg0Mw==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r509708843", "bodyText": "My bad. Been putting all dtos in that directory. Updated in d15b2a0", "author": "deepsidhu85", "createdAt": "2020-10-21T21:21:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc3ODY2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc3OTg1OA==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r504779858", "bodyText": "Got 2 parts of this if resulting in the same thing ZIPPED.  Should the extension checking be added as an || to the top condition?", "author": "tom114", "createdAt": "2020-10-14T15:39:30Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/model/sequenceFile/Fast5Object.java", "diffHunk": "@@ -103,7 +105,10 @@ private Fast5Type setType(SequenceFile file) {\n \t\ttry {\r\n \t\t\tString extension = FilenameUtils.getExtension(getFile().getFileName());\r\n \r\n-\t\t\tif (file.isGzipped()) {\r\n+\t\t\t// Checks if file is where it should be before it checks if it is gzipped\r\n+\t\t\tif (IridaFiles.fileExists(file.getFile()) && file.isGzipped()) {\r\n+\t\t\t\ttype = Fast5Object.Fast5Type.ZIPPED;\r\n+\t\t\t} else if (extension.equals(\"gz\")) {\r\n \t\t\t\ttype = Fast5Object.Fast5Type.ZIPPED;\r", "originalCommit": "852f5b9327fe79f60ef841cdec400c1466061dd7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDkyNDAyMg==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r504924022", "bodyText": "Yup I can't believe I did that. Updated in 117eedc", "author": "deepsidhu85", "createdAt": "2020-10-14T19:35:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc3OTg1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc4MTIyNw==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r504781227", "bodyText": "This processor gets a bit complicated.  Can you add comments through this file please about what's going on.  So up here something saying \"we're getting a local copy of the files\", down below \"we're creating a temp directory\", \"we're running the fastqc modules\", etc.", "author": "tom114", "createdAt": "2020-10-14T15:41:28Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/processing/impl/FastqcFileProcessor.java", "diffHunk": "@@ -95,44 +98,62 @@ private void processSingleFile(SequenceFile sequenceFile) throws FileProcessorEx\n \t\t\t\t.executionManagerAnalysisId(EXECUTION_MANAGER_ANALYSIS_ID)\n \t\t\t\t.description(messageSource.getMessage(\"fastqc.file.processor.analysis.description\", new Object[] {FastQCApplication.VERSION},\n \t\t\t\t\t\tLocaleContextHolder.getLocale()));\n+\n+\t\tIridaTemporaryFile iridaTemporaryFile = iridaFileStorageUtility.getTemporaryFile(fileToProcess);", "originalCommit": "852f5b9327fe79f60ef841cdec400c1466061dd7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDkyMzczNw==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r504923737", "bodyText": "Added in 117eedc", "author": "deepsidhu85", "createdAt": "2020-10-14T19:34:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc4MTIyNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc4MjE2NA==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r504782164", "bodyText": "Should this exception be wrapped and re-thrown as a StorageException or FileProcessorException rather than just logging?", "author": "tom114", "createdAt": "2020-10-14T15:42:47Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/processing/impl/FastqcFileProcessor.java", "diffHunk": "@@ -95,44 +98,62 @@ private void processSingleFile(SequenceFile sequenceFile) throws FileProcessorEx\n \t\t\t\t.executionManagerAnalysisId(EXECUTION_MANAGER_ANALYSIS_ID)\n \t\t\t\t.description(messageSource.getMessage(\"fastqc.file.processor.analysis.description\", new Object[] {FastQCApplication.VERSION},\n \t\t\t\t\t\tLocaleContextHolder.getLocale()));\n+\n+\t\tIridaTemporaryFile iridaTemporaryFile = iridaFileStorageUtility.getTemporaryFile(fileToProcess);\n+\t\tFile fastQCSequenceFileToProcess = iridaTemporaryFile.getFile().toFile();\n+\t\tPath outputDirectory = null;\n+\n \t\ttry {\n-\t\t\tuk.ac.babraham.FastQC.Sequence.SequenceFile fastQCSequenceFile = SequenceFactory.getSequenceFile(\n-\t\t\t\t\tiridaFileStorageUtility.getTemporaryFile(fileToProcess));\n-\t\t\tBasicStats basicStats = new BasicStats();\n-\t\t\tPerBaseQualityScores pbqs = new PerBaseQualityScores();\n-\t\t\tPerSequenceQualityScores psqs = new PerSequenceQualityScores();\n-\t\t\tOverRepresentedSeqs overRep = new OverRepresentedSeqs();\n-\t\t\tQCModule[] moduleList = new QCModule[] { basicStats, pbqs, psqs, overRep };\n-\n-\t\t\tlogger.debug(\"Launching FastQC analysis modules on all sequences.\");\n-\t\t\twhile (fastQCSequenceFile.hasNext()) {\n-\t\t\t\tSequence sequence = fastQCSequenceFile.next();\n-\t\t\t\tfor (QCModule module : moduleList) {\n-\t\t\t\t\tmodule.processSequence(sequence);\n+\t\t\toutputDirectory = Files.createTempDirectory(\"analysis-output\");\n+\n+\t\t\ttry {\n+\t\t\t\tuk.ac.babraham.FastQC.Sequence.SequenceFile fastQCSequenceFile = SequenceFactory.getSequenceFile(\n+\t\t\t\t\t\tfastQCSequenceFileToProcess);\n+\t\t\t\tBasicStats basicStats = new BasicStats();\n+\t\t\t\tPerBaseQualityScores pbqs = new PerBaseQualityScores();\n+\t\t\t\tPerSequenceQualityScores psqs = new PerSequenceQualityScores();\n+\t\t\t\tOverRepresentedSeqs overRep = new OverRepresentedSeqs();\n+\t\t\t\tQCModule[] moduleList = new QCModule[] { basicStats, pbqs, psqs, overRep };\n+\n+\t\t\t\tlogger.debug(\"Launching FastQC analysis modules on all sequences.\");\n+\t\t\t\twhile (fastQCSequenceFile.hasNext()) {\n+\t\t\t\t\tSequence sequence = fastQCSequenceFile.next();\n+\t\t\t\t\tfor (QCModule module : moduleList) {\n+\t\t\t\t\t\tmodule.processSequence(sequence);\n+\t\t\t\t\t}\n \t\t\t\t}\n-\t\t\t}\n \n-\t\t\tlogger.debug(\"Finished FastQC analysis modules.\");\n+\t\t\t\tlogger.debug(\"Finished FastQC analysis modules.\");\n \n-\t\t\tPath outputDirectory = Files.createTempDirectory(\"analysis-output\");\n+\t\t\t\thandleBasicStats(basicStats, analysis);\n+\t\t\t\thandlePerBaseQualityScores(pbqs, analysis, outputDirectory);\n+\t\t\t\thandlePerSequenceQualityScores(psqs, analysis, outputDirectory);\n+\t\t\t\thandleDuplicationLevel(overRep.duplicationLevelModule(), analysis, outputDirectory);\n+\t\t\t\tSet<OverrepresentedSequence> overrepresentedSequences = handleOverRepresentedSequences(overRep);\n \n-\t\t\thandleBasicStats(basicStats, analysis);\n-\t\t\thandlePerBaseQualityScores(pbqs, analysis, outputDirectory);\n-\t\t\thandlePerSequenceQualityScores(psqs, analysis, outputDirectory);\n-\t\t\thandleDuplicationLevel(overRep.duplicationLevelModule(), analysis, outputDirectory);\n-\t\t\tSet<OverrepresentedSequence> overrepresentedSequences = handleOverRepresentedSequences(overRep);\n+\t\t\t\tlogger.trace(\"Saving FastQC analysis.\");\n+\t\t\t\tanalysis.overrepresentedSequences(overrepresentedSequences);\n \n-\t\t\tlogger.trace(\"Saving FastQC analysis.\");\n-\t\t\tanalysis.overrepresentedSequences(overrepresentedSequences);\n+\t\t\t\tAnalysisFastQC analysisFastQC = analysis.build();\n \n-\t\t\tAnalysisFastQC analysisFastQC = analysis.build();\n+\t\t\t\tsequenceFile.setFastQCAnalysis(analysis.build());\n \n-\t\t\tsequenceFile.setFastQCAnalysis(analysis.build());\n-\n-\t\t\tsequenceFileRepository.saveMetadata(sequenceFile);\n-\t\t} catch (Exception e) {\n-\t\t\tlogger.error(\"FastQC failed to process the sequence file: \" + e.getMessage());\n-\t\t\tthrow new FileProcessorException(\"FastQC failed to parse the sequence file.\", e);\n+\t\t\t\tsequenceFileRepository.saveMetadata(sequenceFile);\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tlogger.error(\"FastQC failed to process the sequence file: \" + e.getMessage());\n+\t\t\t\tthrow new FileProcessorException(\"FastQC failed to parse the sequence file.\", e);\n+\t\t\t}\n+\t\t} catch (IOException e) {\n+\t\t\tlogger.error(\"Unable to create temporary directory \", e);\n+\t\t\tthrow new StorageException(\"Unable to create temporary directory\", e);\n+\t\t} finally {\n+\t\t\t\tiridaFileStorageUtility.cleanupDownloadedLocalTemporaryFiles(iridaTemporaryFile);\n+\t\t\t\ttry {\n+\t\t\t\t\t// Delete the analysis-output* temp directory\n+\t\t\t\t\tFiles.deleteIfExists(outputDirectory);\n+\t\t\t\t} catch (IOException e) {\n+\t\t\t\t\tlogger.error(\"Unable to remove directory\", e);", "originalCommit": "852f5b9327fe79f60ef841cdec400c1466061dd7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDkyMzY4MA==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r504923680", "bodyText": "Updated in 117eedc", "author": "deepsidhu85", "createdAt": "2020-10-14T19:34:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc4MjE2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc4Mzk4MQ==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r504783981", "bodyText": "Can we add a prefix here instead of null?  That will make things easier to debug if something is going wrong leaving temp directories around.  Maybe something like \"azure-tmp-\".  We could add similar for the S3 stuff in its PR.", "author": "tom114", "createdAt": "2020-10-14T15:45:20Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAzureUtilityImpl.java", "diffHunk": "@@ -0,0 +1,283 @@\n+package ca.corefacility.bioinformatics.irida.repositories.filesystem;\n+\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.StandardOpenOption;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.zip.GZIPInputStream;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.beans.factory.annotation.Autowired;\n+import org.springframework.stereotype.Component;\n+\n+import ca.corefacility.bioinformatics.irida.exceptions.StorageException;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequenceFile;\n+import ca.corefacility.bioinformatics.irida.model.sequenceFile.SequencingObject;\n+import ca.corefacility.bioinformatics.irida.ria.web.dto.IridaTemporaryFile;\n+import ca.corefacility.bioinformatics.irida.util.FileUtils;\n+\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobStorageException;\n+\n+/**\n+ * Component implementation of file utitlities for azure storage\n+ */\n+@Component\n+public class IridaFileStorageAzureUtilityImpl implements IridaFileStorageUtility {\n+\tprivate static final Logger logger = LoggerFactory.getLogger(IridaFileStorageAzureUtilityImpl.class);\n+\n+\tprivate BlobServiceClient blobServiceClient;\n+\tprivate BlobContainerClient containerClient ;\n+\n+\t@Autowired\n+\tpublic IridaFileStorageAzureUtilityImpl(String connectionStr, String containerName){\n+\t\tthis.blobServiceClient = new BlobServiceClientBuilder().connectionString(connectionStr)\n+\t\t\t\t.buildClient();\n+\t\tthis.containerClient = blobServiceClient.getBlobContainerClient(containerName);\n+\t}\n+\n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic IridaTemporaryFile getTemporaryFile(Path file) {\n+\t\t// We set the blobClient \"path\" to which file we want to get\n+\t\tBlobClient blobClient = containerClient.getBlobClient(getAzureFileAbsolutePath(file));\n+\n+\t\ttry {\n+\t\t\tlogger.trace(\"Getting file from azure [\" + file.toString() + \"]\");\n+\t\t\tPath tempDirectory = Files.createTempDirectory(null);", "originalCommit": "852f5b9327fe79f60ef841cdec400c1466061dd7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDkyMzYyNg==", "url": "https://github.com/phac-nml/irida/pull/759#discussion_r504923626", "bodyText": "Sure good idea! Added in 117eedc", "author": "deepsidhu85", "createdAt": "2020-10-14T19:34:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc4Mzk4MQ=="}], "type": "inlineReview"}, {"oid": "117eedc7f06e586f08eed0fca9d520de62ca3c6f", "url": "https://github.com/phac-nml/irida/commit/117eedc7f06e586f08eed0fca9d520de62ca3c6f", "message": "Added comments. Updated exception thrown instead of a logging statement when trying to clean up the analysis outputs directory. Added prefix to temporary directory for azure files.", "committedDate": "2020-10-14T19:33:45Z", "type": "commit"}, {"oid": "1dd0672eb3b8f066928f5efd3862d9c5eab3be50", "url": "https://github.com/phac-nml/irida/commit/1dd0672eb3b8f066928f5efd3862d9c5eab3be50", "message": "Changed package to delete temp analysis outputs directory", "committedDate": "2020-10-14T23:35:58Z", "type": "commit"}, {"oid": "8c5f601869cd0ec4090be803a7df2167c3b06fbb", "url": "https://github.com/phac-nml/irida/commit/8c5f601869cd0ec4090be803a7df2167c3b06fbb", "message": "Merge branch 'object-store' into object_store/_azure", "committedDate": "2020-10-15T13:17:40Z", "type": "commit"}, {"oid": "d15b2a07ea240feaf6f39b90428d985fca96efa8", "url": "https://github.com/phac-nml/irida/commit/d15b2a07ea240feaf6f39b90428d985fca96efa8", "message": "Moved into filesystem directory", "committedDate": "2020-10-21T21:20:42Z", "type": "commit"}, {"oid": "2dc172a7c93d54c819c83356ed1270526877b050", "url": "https://github.com/phac-nml/irida/commit/2dc172a7c93d54c819c83356ed1270526877b050", "message": "Updated authentication for azure storage utility class", "committedDate": "2020-10-22T21:49:58Z", "type": "commit"}, {"oid": "c3f19b3a9265e51837347ea39913dd8e5dad9293", "url": "https://github.com/phac-nml/irida/commit/c3f19b3a9265e51837347ea39913dd8e5dad9293", "message": "Merge branch 'object-store' into object_store/_azure", "committedDate": "2020-11-02T15:19:23Z", "type": "commit"}, {"oid": "74049bc35efe3096cf568b220f513eeb6ba1a0ea", "url": "https://github.com/phac-nml/irida/commit/74049bc35efe3096cf568b220f513eeb6ba1a0ea", "message": "Updated getFileSize and getFileName methods to not error out if an exception is thrown.", "committedDate": "2020-11-04T01:07:08Z", "type": "commit"}, {"oid": "c43265bd650f0a96e09d9dc086e9775f7dd660c6", "url": "https://github.com/phac-nml/irida/commit/c43265bd650f0a96e09d9dc086e9775f7dd660c6", "message": "Removed finally blocks and storageexceptions", "committedDate": "2020-11-04T17:00:19Z", "type": "commit"}]}