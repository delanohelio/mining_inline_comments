{"pr_number": 1885, "pr_title": "[cygnus-ngsi-ld] New cygnus agent for NGSLD support ", "pr_createdAt": "2020-06-09T16:09:12Z", "pr_url": "https://github.com/telefonicaid/fiware-cygnus/pull/1885", "timeline": [{"oid": "602b8bf13b02709a049d6c4d27e05cbc447481d4", "url": "https://github.com/telefonicaid/fiware-cygnus/commit/602b8bf13b02709a049d6c4d27e05cbc447481d4", "message": "New cygnus-ngsi-ld bundle for proving a new cygnus-ngsi-ld agent to store ngsi-ld notification in Postgresql, including documetation and Docker files", "committedDate": "2020-06-09T15:48:51Z", "type": "commit"}, {"oid": "829bd381b7e449e3b02c760402d783e358d3fdf6", "url": "https://github.com/telefonicaid/fiware-cygnus/commit/829bd381b7e449e3b02c760402d783e358d3fdf6", "message": "Update Documentation", "committedDate": "2020-06-09T15:54:40Z", "type": "commit"}, {"oid": "0fa241fd29492785a13ba81fe8cadeb3536d004f", "url": "https://github.com/telefonicaid/fiware-cygnus/commit/0fa241fd29492785a13ba81fe8cadeb3536d004f", "message": "Update code files for removing service path validation", "committedDate": "2020-06-09T15:59:50Z", "type": "commit"}, {"oid": "2b1f0c8f78e873601cd0a9a68656585b9f52956e", "url": "https://github.com/telefonicaid/fiware-cygnus/commit/2b1f0c8f78e873601cd0a9a68656585b9f52956e", "message": "Update Readme", "committedDate": "2020-06-09T16:01:23Z", "type": "commit"}, {"oid": "15c53b26605d5ed1a692878403f62f051b22837d", "url": "https://github.com/telefonicaid/fiware-cygnus/commit/15c53b26605d5ed1a692878403f62f051b22837d", "message": "Fix mkdocs and Add User and Programmers Guide", "committedDate": "2020-06-10T11:01:21Z", "type": "commit"}, {"oid": "5dee33e077166bd0c7e87d87fadd589a8c4ea877", "url": "https://github.com/telefonicaid/fiware-cygnus/commit/5dee33e077166bd0c7e87d87fadd589a8c4ea877", "message": "Merge branch 'master' of https://github.com/ging/fiware-cygnus", "committedDate": "2020-06-10T11:30:37Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTI2OTkwOA==", "url": "https://github.com/telefonicaid/fiware-cygnus/pull/1885#discussion_r439269908", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    // TBD: What about:  ?\n          \n          \n            \n                    // FIXME: What about:  ?\n          \n      \n    \n    \n  \n\n(Our \"convention\" is to use FIXME as mark for pending stuff)", "author": "fgalan", "createdAt": "2020-06-12T08:04:13Z", "path": "cygnus-ngsi-ld/src/main/java/com/telefonica/iot/cygnus/utils/NGSIUtils.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/**\n+ * Copyright 2015-2017 Telefonica Investigaci\u00f3n y Desarrollo, S.A.U\n+ *\n+ * This file is part of fiware-cygnus (FIWARE project).\n+ *\n+ * fiware-cygnus is free software: you can redistribute it and/or modify it under the terms of the GNU Affero\n+ * General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your\n+ * option) any later version.\n+ * fiware-cygnus is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the\n+ * implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Affero General Public License\n+ * for more details.\n+ *\n+ * You should have received a copy of the GNU Affero General Public License along with fiware-cygnus. If not, see\n+ * http://www.gnu.org/licenses/.\n+ *\n+ * For those usages not covered by the GNU Affero General Public License please contact with iot_support at tid dot es\n+ */\n+\n+package com.telefonica.iot.cygnus.utils;\n+\n+import com.telefonica.iot.cygnus.log.CygnusLogger;\n+import java.util.regex.Pattern;\n+import org.apache.commons.lang3.tuple.ImmutablePair;\n+import org.apache.ivy.osgi.p2.P2Artifact;\n+import org.json.simple.JSONArray;\n+import org.json.simple.JSONObject;\n+import org.json.simple.parser.JSONParser;\n+import org.json.simple.parser.ParseException;\n+\n+/**\n+ *\n+ * @author frb\n+ */\n+public final class NGSIUtils {\n+    \n+    private static final CygnusLogger LOGGER = new CygnusLogger(NGSIUtils.class);\n+    private static final Pattern ENCODEPATTERN = Pattern.compile(\"[^a-zA-Z0-9\\\\.\\\\-]\");\n+    private static final Pattern ENCODEPATTERNSLASH = Pattern.compile(\"[^a-zA-Z0-9\\\\.\\\\-\\\\/]\");\n+    private static final Pattern ENCODEPOSTGRESQL = Pattern.compile(\"[^a-zA-Z0-9\\\\/]\");\n+    private static final Pattern ENCODEHIVEPATTERN = Pattern.compile(\"[^a-zA-Z0-9]\");\n+    private static final Pattern ENCODESTHDBPATTERN = Pattern.compile(\"[=\\\\/\\\\\\\\.\\\\$\\\" ]\");\n+    private static final Pattern ENCODESTHCOLLECTIONPATTERN = Pattern.compile(\"[=\\\\$]\");\n+    \n+    /**\n+     * Constructor. It is private since utility classes should not have a public or default constructor.\n+     */\n+    private NGSIUtils() {\n+    } // NGSIUtils\n+    \n+    /**\n+     * Encodes a string replacing all the non alphanumeric characters by '_' (except by '-' and '.').\n+     * This should be only called when building a persistence element name, such as table names, file paths, etc.\n+     * \n+     * @param in\n+     * @param deleteSlash\n+     * @param encodeSlash\n+     * @return The encoded version of the input string.\n+     */\n+    public static String encode(String in, boolean deleteSlash, boolean encodeSlash) {\n+        if (deleteSlash) {\n+            return ENCODEPATTERN.matcher(in.substring(1)).replaceAll(\"_\");\n+        } else if (encodeSlash) {\n+            return ENCODEPATTERN.matcher(in).replaceAll(\"_\");\n+        } else {\n+            return ENCODEPATTERNSLASH.matcher(in).replaceAll(\"_\");\n+        } // if else\n+    } // encode\n+\n+    /**\n+     * Encodes a string replacing all the non alphanumeric characters by '_' (except by '-' and '.').\n+     * This should be only called when building a persistence element name, such as table names, file paths, etc.\n+     *\n+     * @param in\n+     * @return The encoded version of the input string.\n+     */\n+    public static String encodePostgreSQL(String in) {\n+        return ENCODEPOSTGRESQL.matcher(in).replaceAll(\"_\");\n+    } // encode\n+\n+    /**\n+     * Encodes a string replacing all '/', '\\', '.', ' ', '\"' and '$' by '_'.\n+     * @param in\n+     * @return The encoded version of the input string\n+     */\n+    public static String encodeSTHDB(String in) {\n+        return ENCODESTHDBPATTERN.matcher(in).replaceAll(\"_\");\n+    } // encodeSTHDB\n+    \n+    /**\n+     * Encodes a string replacing all '$' by '_'.\n+     * @param in\n+     * @return The encoded version of the input string\n+     */\n+    public static String encodeSTHCollection(String in) {\n+        return ENCODESTHCOLLECTIONPATTERN.matcher(in).replaceAll(\"_\");\n+    } // encodeSTHCollection\n+    \n+    /**\n+     * Gets a geometry value, ready for insertion in CartoDB, given a NGSI attribute value and its metadata.\n+     * If the attribute is not geo-related, it is returned as it is.\n+     * @param attrValue\n+     * @param attrType\n+     * @param metadata\n+     * @param swapCoordinates\n+     * @return The geometry value, ready for insertion in CartoDB/PostGIS, or the value as it is\n+     */\n+    public static ImmutablePair<String, Boolean> getGeometry(String attrValue, String attrType, String metadata,\n+            boolean swapCoordinates) {\n+        // First, check the attribute type\n+        if (attrType.equals(\"geo:point\")) {\n+            String[] split = attrValue.split(\",\");\n+                \n+            if (swapCoordinates) {\n+                return new ImmutablePair(\n+                        \"ST_SetSRID(ST_MakePoint(\" + split[1].trim() + \",\" + split[0].trim() + \"), 4326)\", true);\n+            } else {\n+                return new ImmutablePair(\n+                        \"ST_SetSRID(ST_MakePoint(\" + split[0].trim() + \",\" + split[1].trim() + \"), 4326)\", true);\n+            } // if else\n+        } // if\n+        \n+        if (attrType.equals(\"geo:json\")) {\n+            return new ImmutablePair(\"ST_GeomFromGeoJSON(\" + attrValue + \")\", true);\n+        } // if\n+\n+        // TBD: What about:  ?", "originalCommit": "5dee33e077166bd0c7e87d87fadd589a8c4ea877", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTI3MDA3Mw==", "url": "https://github.com/telefonicaid/fiware-cygnus/pull/1885#discussion_r439270073", "bodyText": "Pending in this PR?", "author": "fgalan", "createdAt": "2020-06-12T08:04:36Z", "path": "cygnus-ngsi-ld/src/test/java/com/telefonica/iot/cygnus/sinks/NGSIPostgreSQLSinkTest.java", "diffHunk": "@@ -0,0 +1,708 @@\n+/**\n+ * Copyright 2020 Telefonica Investigaci\u00f3n y Desarrollo, S.A.U\n+ *\n+ * This file is part of fiware-cygnus (FIWARE project).\n+ *\n+ * fiware-cygnus is free software: you can redistribute it and/or modify it under the terms of the GNU Affero\n+ * General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your\n+ * option) any later version.\n+ * fiware-cygnus is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the\n+ * implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Affero General Public License\n+ * for more details.\n+ *\n+ * You should have received a copy of the GNU Affero General Public License along with fiware-cygnus. If not, see\n+ * http://www.gnu.org/licenses/.\n+ *\n+ * For those usages not covered by the GNU Affero General Public License please contact with iot_support at tid dot es\n+ */\n+package com.telefonica.iot.cygnus.sinks;\n+\n+import org.apache.flume.Context;\n+import org.apache.log4j.Level;\n+import org.apache.log4j.LogManager;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.mockito.runners.MockitoJUnitRunner;\n+\n+import static com.telefonica.iot.cygnus.utils.CommonUtilsForTests.getTestTraceHead;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ *\n+ * @author anmunoz\n+ */\n+@RunWith(MockitoJUnitRunner.class)\n+public class NGSIPostgreSQLSinkTest {\n+\n+    /**\n+     * Constructor.\n+     */\n+    public NGSIPostgreSQLSinkTest() {\n+        LogManager.getRootLogger().setLevel(Level.FATAL);\n+    } // NGSIPostgreSQLSinkTest\n+\n+    /**\n+     * [NGSIPostgreSQLSink.configure] -------- enable_encoding can only be 'true' or 'false'.\n+     */\n+    @Test\n+    public void testConfigureEnableEncoding() {\n+        System.out.println(getTestTraceHead(\"[NGSIPostgreSQLSink.configure]\")\n+                + \"-------- enable_encoding can only be 'true' or 'false'\");\n+        String attrPersistence = null; // default\n+        String batchSize = null; // default\n+        String batchTime = null; // default\n+        String batchTTL = null; // default\n+        String dataModel = null; // default\n+        String enableEncoding = \"falso\";\n+        String enableGrouping = null; // default\n+        String enableLowercase = null; // default\n+        String host = null; // default\n+        String password = null; // default\n+        String port = null; // default\n+        String username = null; // default\n+        String cache = null; // default\n+        NGSIPostgreSQLSink sink = new NGSIPostgreSQLSink();\n+        sink.configure(createContext(attrPersistence, batchSize, batchTime, batchTTL, dataModel, enableEncoding,\n+                enableGrouping, enableLowercase, host, password, port, username, cache));\n+\n+        try {\n+            assertTrue(sink.getInvalidConfiguration());\n+            System.out.println(getTestTraceHead(\"[NGSILDPostgreSQLSink.configure]\")\n+                    + \"-  OK  - 'enable_encoding=false' was detected\");\n+        } catch (AssertionError e) {\n+            System.out.println(getTestTraceHead(\"[NGSILDPostgreSQLSink.configure]\")\n+                    + \"- FAIL - 'enable_encoding=false' was not detected\");\n+            throw e;\n+        } // try catch\n+    } // testConfigureEnableEncoding\n+\n+    /**\n+     * [NGSIPostgreSQLSink.configure] -------- enable_lowercase can only be 'true' or 'false'.\n+     */\n+    @Test\n+    public void testConfigureEnableLowercase() {\n+        System.out.println(getTestTraceHead(\"[NGSIPostgreSQLSink.configure]\")\n+                + \"-------- enable_lowercase can only be 'true' or 'false'\");\n+        String attrPersistence = null; // default\n+        String batchSize = null; // default\n+        String batchTime = null; // default\n+        String batchTTL = null; // default\n+        String dataModel = null; // default\n+        String enableEncoding = null; // default\n+        String enableGrouping = null; // default\n+        String enableLowercase = \"falso\";\n+        String host = null; // default\n+        String password = null; // default\n+        String port = null; // default\n+        String username = null; // default\n+        String cache = null; // default\n+        NGSIPostgreSQLSink sink = new NGSIPostgreSQLSink();\n+        sink.configure(createContext(attrPersistence, batchSize, batchTime, batchTTL, dataModel, enableEncoding,\n+                enableGrouping, enableLowercase, host, password, port, username, cache));\n+\n+        try {\n+            assertTrue(sink.getInvalidConfiguration());\n+            System.out.println(getTestTraceHead(\"[NGSIPostgreSQLSink.configure]\")\n+                    + \"-  OK  - 'enable_lowercase=false' was detected\");\n+        } catch (AssertionError e) {\n+            System.out.println(getTestTraceHead(\"[NGSIPostgreSQLSink.configure]\")\n+                    + \"- FAIL - 'enable_lowercase=false' was not detected\");\n+            throw e;\n+        } // try catch\n+    } // testConfigureEnableLowercase\n+\n+    /**\n+     * [NGSIPostgreSQLSink.configure] -------- enable_grouping can only be 'true' or 'false'.\n+     */\n+    @Test\n+    public void testConfigureEnableGrouping() {\n+        System.out.println(getTestTraceHead(\"[NGSIPostgreSQLSink.configure]\")\n+                + \"-------- enable_grouping can only be 'true' or 'false'\");\n+        String attrPersistence = null; // default\n+        String batchSize = null; // default\n+        String batchTime = null; // default\n+        String batchTTL = null; // default\n+        String dataModel = null; // default\n+        String enableEncoding = null; // default\n+        String enableGrouping = \"falso\";\n+        String enableLowercase = null; // default\n+        String host = null; // default\n+        String password = null; // default\n+        String port = null; // default\n+        String username = null; // default\n+        String cache = null; // default\n+        NGSIPostgreSQLSink sink = new NGSIPostgreSQLSink();\n+        sink.configure(createContext(attrPersistence, batchSize, batchTime, batchTTL, dataModel, enableEncoding,\n+                enableGrouping, enableLowercase, host, password, port, username, cache));\n+\n+        try {\n+            assertTrue(sink.getInvalidConfiguration());\n+            System.out.println(getTestTraceHead(\"[NGSILDPostgreSQLSink.configure]\")\n+                    + \"-  OK  - 'enable_grouping=falso' was detected\");\n+        } catch (AssertionError e) {\n+            System.out.println(getTestTraceHead(\"[NGSILDPostgreSQLSink.configure]\")\n+                    + \"- FAIL - 'enable_grouping=falso' was not detected\");\n+            throw e;\n+        } // try catch\n+    } // testConfigureEnableGrouping\n+\n+    /**\n+     * [NGSIPostgreSQLSink.configure] -------- data_model can only be 'dm-by-service-path' or 'dm-by-entity'.\n+     */\n+    // TBD: check for dataModel values in NGSIMySQLSink and uncomment this test.", "originalCommit": "5dee33e077166bd0c7e87d87fadd589a8c4ea877", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTMyMTc1Mw==", "url": "https://github.com/telefonicaid/fiware-cygnus/pull/1885#discussion_r439321753", "bodyText": "Update and available after df578ad", "author": "anmunoz", "createdAt": "2020-06-12T09:51:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTI3MDA3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTI3MDI3OA==", "url": "https://github.com/telefonicaid/fiware-cygnus/pull/1885#discussion_r439270278", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        // TBD: https://github.com/telefonicaid/fiware-cygnus/issues/562\n          \n          \n            \n                        // FIXME: https://github.com/telefonicaid/fiware-cygnus/issues/562", "author": "fgalan", "createdAt": "2020-06-12T08:05:01Z", "path": "cygnus-ngsi-ld/src/main/java/com/telefonica/iot/cygnus/sinks/NGSILDSink.java", "diffHunk": "@@ -0,0 +1,905 @@\n+/**\n+ * Copyright 2020 Telefonica Investigaci\u00f3n y Desarrollo, S.A.U\n+ *\n+ * This file is part of fiware-cygnus (FIWARE project).\n+ *\n+ * fiware-cygnus is free software: you can redistribute it and/or modify it under the terms of the GNU Affero\n+ * General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your\n+ * option) any later version.\n+ * fiware-cygnus is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the\n+ * implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Affero General Public License\n+ * for more details.\n+ *\n+ * You should have received a copy of the GNU Affero General Public License along with fiware-cygnus. If not, see\n+ * http://www.gnu.org/licenses/.\n+ *\n+ * For those usages not covered by the GNU Affero General Public License please contact with iot_support at tid dot es\n+ */\n+package com.telefonica.iot.cygnus.sinks;\n+\n+import com.google.gson.Gson;\n+import com.telefonica.iot.cygnus.containers.NotifyContextRequestLD.ContextElement;\n+import com.telefonica.iot.cygnus.errors.*;\n+import com.telefonica.iot.cygnus.interceptors.NGSILDEvent;\n+import com.telefonica.iot.cygnus.log.CygnusLogger;\n+import com.telefonica.iot.cygnus.sinks.Enums.DataModel;\n+import com.telefonica.iot.cygnus.utils.CommonConstants;\n+import com.telefonica.iot.cygnus.utils.NGSIConstants;\n+import org.apache.flume.*;\n+import org.apache.flume.conf.Configurable;\n+import org.apache.log4j.MDC;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Date;\n+import java.util.Map;\n+\n+/**\n+ *\n+ * @author amunoz\n+ Abstract class containing the common code to all the sinks persisting data comming from Orion Context Broker.\n+\n+ The common attributes are:\n+  - there is no common attributes\n+ The common methods are:\n+  - void stop()\n+  - Status process() throws EventDeliveryException\n+  - void persistOne(Event getRecvTimeTs) throws Exception\n+ The non common parts, and therefore those that are sink dependant and must be implemented are:\n+  - void configure(Context context)\n+  - void start()\n+  - void persistOne(Map<String, String> eventHeaders, NotifyContextRequest notification) throws Exception\n+ */\n+public abstract class NGSILDSink extends CygnusSink implements Configurable {\n+\n+    // Logger\n+    private static final CygnusLogger LOGGER = new CygnusLogger(NGSILDSink.class);\n+    // General parameters for all the sinks\n+    protected DataModel dataModel;\n+    protected boolean enableGrouping;\n+    protected int batchSize;\n+    protected int batchTimeout;\n+    protected int batchTTL;\n+    protected int[] batchRetryIntervals;\n+    protected boolean enableLowercase;\n+    protected boolean invalidConfiguration;\n+    protected boolean enableEncoding;\n+    protected boolean enableNameMappings;\n+    private long persistencePolicyMaxRecords;\n+    private long persistencePolicyExpirationTime;\n+    private long persistencePolicyCheckingTime;\n+    // Accumulator utility\n+    private final Accumulator accumulator;\n+    // Rollback queues\n+    private ArrayList<Accumulator> rollbackedAccumulations;\n+    // Expiration thread\n+    private ExpirationTimeChecker expirationTimeChecker;\n+\n+    /**\n+     * Constructor.\n+     */\n+    public NGSILDSink() {\n+        super();\n+\n+        // Configuration is supposed to be valid\n+        invalidConfiguration = false;\n+\n+        // Create the accumulator utility\n+        accumulator = new Accumulator();\n+\n+        // Create the rollbacking queue\n+        rollbackedAccumulations = new ArrayList<>();\n+    } // NGSISink\n+    \n+    protected String getBatchRetryIntervals() {\n+        return Arrays.toString(batchRetryIntervals).replaceAll(\"\\\\[\", \"\").replaceAll(\"\\\\]\", \"\");\n+    } // getBatchRetryIntervals\n+    \n+    /**\n+     * Gets the batch size.\n+     * @return The batch size.\n+     */\n+    protected int getBatchSize() {\n+        return batchSize;\n+    } // getBatchSize\n+    \n+    /**\n+     * Gets the batch timeout.\n+     * @return The batch timeout.\n+     */\n+    protected int getBatchTimeout() {\n+        return batchTimeout;\n+    } // getBatchTimeout\n+    \n+    /**\n+     * Gets the batch TTL.\n+     * @return The batch TTL.\n+     */\n+    protected int getBatchTTL() {\n+        return batchTTL;\n+    } // getBatchTTL\n+    \n+    /**\n+     * Gets the data model.\n+     * @return The data model\n+     */\n+    protected DataModel getDataModel() {\n+        return dataModel;\n+    } // getDataModel\n+\n+    /**\n+     * Gets if the grouping feature is enabled.\n+     * @return True if the grouping feature is enabled, false otherwise.\n+     */\n+    protected boolean getEnableGrouping() {\n+        return enableGrouping;\n+    } // getEnableGrouping\n+\n+    /**\n+     * Gets if lower case is enabled.\n+     * @return True is lower case is enabled, false otherwise.\n+     */\n+    protected boolean getEnableLowerCase() {\n+        return enableLowercase;\n+    } // getEnableLowerCase\n+    \n+    /**\n+     * Gets if the encoding is enabled.\n+     * @return True is the encoding is enabled, false otherwise.\n+     */\n+    protected boolean getEnableEncoding() {\n+        return enableEncoding;\n+    } // getEnableEncoding\n+    \n+    protected boolean getEnableNameMappings() {\n+        return enableNameMappings;\n+    } // getEnableNameMappings\n+    \n+    /**\n+     * Gets true if the configuration is invalid, false otherwise. It is protected due to it is only\n+     * required for testing purposes.\n+     * @return\n+     */\n+    protected boolean getInvalidConfiguration() {\n+        return invalidConfiguration;\n+    } // getInvalidConfiguration\n+    \n+    protected ArrayList<Accumulator> getRollbackedAccumulations() {\n+        return rollbackedAccumulations;\n+    } // getRollbackedAccumulations\n+    \n+    protected void setRollbackedAccumulations(ArrayList<Accumulator> rollbackedAccumulations) {\n+        this.rollbackedAccumulations = rollbackedAccumulations;\n+    } // setRollbackedAccumulations\n+    \n+    protected long getPersistencePolicyMaxRecords() {\n+        return persistencePolicyMaxRecords;\n+    } // getPersistencePolicyMaxRecords\n+    \n+    protected long getPersistencePolicyExpirationTime() {\n+        return persistencePolicyExpirationTime;\n+    } // getPersistencePolicyExpirationTime\n+    \n+    protected long getPersistencePolicyCheckingTime() {\n+        return persistencePolicyCheckingTime;\n+    } // getPersistencePolicyCheckingTime\n+\n+    @Override\n+    public void configure(Context context) {\n+        String dataModelStr = context.getString(\"data_model\", \"dm-by-entity\");\n+\n+        try {\n+            dataModel = DataModel.valueOf(dataModelStr.replaceAll(\"-\", \"\").toUpperCase());\n+            LOGGER.debug(\"[\" + this.getName() + \"] Reading configuration (data_model=\"\n+                    + dataModelStr + \")\");\n+        } catch (Exception e) {\n+            invalidConfiguration = true;\n+            LOGGER.debug(\"[\" + this.getName() + \"] Invalid configuration (data_model=\"\n+                    + dataModelStr + \")\");\n+        } // catch\n+\n+        String enableGroupingStr = context.getString(\"enable_grouping\", \"false\");\n+        \n+        if (enableGroupingStr.equals(\"true\") || enableGroupingStr.equals(\"false\")) {\n+            enableGrouping = Boolean.valueOf(enableGroupingStr);\n+            LOGGER.debug(\"[\" + this.getName() + \"] Reading configuration (enable_grouping=\"\n+                + enableGroupingStr + \")\");\n+        }  else {\n+            invalidConfiguration = true;\n+            LOGGER.debug(\"[\" + this.getName() + \"] Invalid configuration (enable_grouping=\"\n+                + enableGroupingStr + \") -- Must be 'true' or 'false'\");\n+        }  // if else\n+        \n+        String enableLowercaseStr = context.getString(\"enable_lowercase\", \"false\");\n+        \n+        if (enableLowercaseStr.equals(\"true\") || enableLowercaseStr.equals(\"false\")) {\n+            enableLowercase = Boolean.valueOf(enableLowercaseStr);\n+            LOGGER.debug(\"[\" + this.getName() + \"] Reading configuration (enable_lowercase=\"\n+                + enableLowercaseStr + \")\");\n+        }  else {\n+            invalidConfiguration = true;\n+            LOGGER.debug(\"[\" + this.getName() + \"] Invalid configuration (enable_lowercase=\"\n+                + enableLowercaseStr + \") -- Must be 'true' or 'false'\");\n+        }  // if else\n+\n+        batchSize = context.getInteger(\"batch_size\", 1);\n+\n+        if (batchSize <= 0) {\n+            invalidConfiguration = true;\n+            LOGGER.debug(\"[\" + this.getName() + \"] Invalid configuration (batch_size=\"\n+                    + batchSize + \") -- Must be greater than 0\");\n+        } else {\n+            LOGGER.debug(\"[\" + this.getName() + \"] Reading configuration (batch_size=\"\n+                    + batchSize + \")\");\n+        } // if else\n+\n+        batchTimeout = context.getInteger(\"batch_timeout\", 30);\n+\n+        if (batchTimeout <= 0) {\n+            invalidConfiguration = true;\n+            LOGGER.debug(\"[\" + this.getName() + \"] Invalid configuration (batch_timeout=\"\n+                    + batchTimeout + \") -- Must be greater than 0\");\n+        } else {\n+            LOGGER.debug(\"[\" + this.getName() + \"] Reading configuration (batch_timeout=\"\n+                    + batchTimeout + \")\");\n+        } // if\n+\n+        batchTTL = context.getInteger(\"batch_ttl\", 10);\n+        \n+        if (batchTTL < -1) {\n+            invalidConfiguration = true;\n+            LOGGER.debug(\"[\" + this.getName() + \"] Invalid configuration (batch_ttl=\"\n+                    + batchTTL + \") -- Must be greater than -2\");\n+        } else {\n+            LOGGER.debug(\"[\" + this.getName() + \"] Reading configuration (batch_ttl=\"\n+                    + batchTTL + \")\");\n+        } // if else\n+        \n+        String enableEncodingStr = context.getString(\"enable_encoding\", \"false\");\n+        \n+        if (enableEncodingStr.equals(\"true\") || enableEncodingStr.equals(\"false\")) {\n+            enableEncoding = Boolean.valueOf(enableEncodingStr);\n+            LOGGER.debug(\"[\" + this.getName() + \"] Reading configuration (enable_encoding=\"\n+                + enableEncodingStr + \")\");\n+        }  else {\n+            invalidConfiguration = true;\n+            LOGGER.debug(\"[\" + this.getName() + \"] Invalid configuration (enable_encoding=\"\n+                + enableEncodingStr + \") -- Must be 'true' or 'false'\");\n+        }  // if else\n+        \n+        String enableNameMappingsStr = context.getString(\"enable_name_mappings\", \"false\");\n+        \n+        if (enableNameMappingsStr.equals(\"true\") || enableNameMappingsStr.equals(\"false\")) {\n+            enableNameMappings = Boolean.valueOf(enableNameMappingsStr);\n+            LOGGER.debug(\"[\" + this.getName() + \"] Reading configuration (enable_name_mappings=\"\n+                + enableNameMappingsStr + \")\");\n+        }  else {\n+            invalidConfiguration = true;\n+            LOGGER.debug(\"[\" + this.getName() + \"] Invalid configuration (enable_name_mappings=\"\n+                + enableNameMappingsStr + \") -- Must be 'true' or 'false'\");\n+        }  // if else\n+        \n+        String batchRetryIntervalsStr = context.getString(\"batch_retry_intervals\", \"5000\");\n+        String[] batchRetryIntervalsSplit = batchRetryIntervalsStr.split(\",\");\n+        batchRetryIntervals = new int[batchRetryIntervalsSplit.length];\n+        boolean allOK = true;\n+        \n+        for (int i = 0; i < batchRetryIntervalsSplit.length; i++) {\n+            String batchRetryIntervalStr = batchRetryIntervalsSplit[i];\n+            int batchRetryInterval = new Integer(batchRetryIntervalStr);\n+            \n+            if (batchRetryInterval <= 0) {\n+                invalidConfiguration = true;\n+                LOGGER.debug(\"[\" + this.getName() + \"] Invalid configuration (batch_retry_intervals=\"\n+                        + batchRetryIntervalStr + \") -- Members must be greater than 0\");\n+                allOK = false;\n+                break;\n+            } else {\n+                batchRetryIntervals[i] = batchRetryInterval;\n+            } // if else\n+        } // for\n+        \n+        if (allOK) {\n+            LOGGER.debug(\"[\" + this.getName() + \"] Reading configuration (batch_retry_intervals=\"\n+                    + batchRetryIntervalsStr + \")\");\n+        } // if\n+        \n+        persistencePolicyMaxRecords = context.getInteger(\"persistence_policy.max_records\", -1);\n+        LOGGER.debug(\"[\" + this.getName() + \"] Reading configuration (persistence_policy.max_records=\"\n+                    + persistencePolicyMaxRecords + \")\");\n+        persistencePolicyExpirationTime = context.getInteger(\"persistence_policy.expiration_time\", -1);\n+        LOGGER.debug(\"[\" + this.getName() + \"] Reading configuration (persistence_policy.expiration_time=\"\n+                    + persistencePolicyExpirationTime + \")\");\n+        persistencePolicyCheckingTime = context.getInteger(\"persistence_policy.checking_time\", 3600);\n+        \n+        if (persistencePolicyCheckingTime <= 0) {\n+            invalidConfiguration = true;\n+            LOGGER.debug(\"[\" + this.getName() + \"] Invalid configuration (persistence_policy.checking_time=\"\n+                    + persistencePolicyCheckingTime + \") -- Must be greater than 0\");\n+        } else {\n+            LOGGER.debug(\"[\" + this.getName() + \"] Reading configuration (persistence_policy.checking_time=\"\n+                    + persistencePolicyCheckingTime + \")\");\n+        } // if else\n+    } // configure\n+\n+    @Override\n+    public void start() {\n+        super.start();\n+\n+        if (invalidConfiguration) {\n+            LOGGER.info(\"[\" + this.getName() + \"] Startup completed. Nevertheless, there are errors \"\n+                    + \"in the configuration, thus this sink will not run the expected logic\");\n+        } else {\n+            // The accumulator must be initialized once read the configuration\n+            accumulator.initialize(new Date().getTime());\n+            // Crate and start the expiration time checker thread... this has to be created here in order to have a not\n+            // null name for the sink (i.e. after configuration)\n+            expirationTimeChecker = new ExpirationTimeChecker(this.getName());\n+            expirationTimeChecker.start();\n+            \n+            LOGGER.info(\"[\" + this.getName() + \"] Startup completed\");\n+        } // if else\n+    } // start\n+\n+    @Override\n+    public void stop() {\n+        super.stop();\n+    } // stop\n+\n+    @Override\n+    public Status process() throws EventDeliveryException {\n+        if (invalidConfiguration) {\n+            return Status.BACKOFF;\n+        } else if (rollbackedAccumulations.isEmpty()) {\n+            return processNewBatches();\n+        } else {\n+            processRollbackedBatches();\n+            return processNewBatches();\n+        } // if else\n+    } // process\n+\n+    private Status processRollbackedBatches() {\n+        // Get a rollbacked accumulation\n+        Accumulator rollbackedAccumulation = getRollbackedAccumulationForRetry();\n+\n+        if (rollbackedAccumulation == null) {\n+            setMDCToNA();\n+            return Status.READY; // No rollbacked batch was ready for retry, so we are ready to process new batches\n+        } // if\n+            \n+        // Try persisting the rollbacked accumulation\n+        NGSILDBatch batch = rollbackedAccumulation.getBatch();\n+        \n+        try {\n+            persistBatch(batch);\n+        } catch (CygnusBadConfiguration | CygnusBadContextData | CygnusRuntimeError e) {\n+            updateServiceMetrics(batch, true);\n+            LOGGER.error(e.getMessage() + \"Stack trace: \" + Arrays.toString(e.getStackTrace()));\n+            setMDCToNA();\n+            return Status.READY;\n+        } catch (CygnusPersistenceError e) {\n+            updateServiceMetrics(batch, true);\n+            LOGGER.error(e.getMessage() + \"Stack trace: \" + Arrays.toString(e.getStackTrace()));\n+            doRollbackAgain(rollbackedAccumulation);\n+            setMDCToNA();\n+            return Status.BACKOFF; // Slow down the sink since there are problems with the persistence backend\n+        } // try catch\n+\n+        if (persistencePolicyMaxRecords > -1) {\n+            try {\n+                capRecords(batch, persistencePolicyMaxRecords);\n+            } catch (CygnusCappingError e) {\n+                LOGGER.error(e.getMessage() + \"Stack trace: \" + Arrays.toString(e.getStackTrace()));\n+            } // try catch\n+        } // if\n+        \n+        updateServiceMetrics(batch, false);\n+\n+        if (!rollbackedAccumulation.getAccTransactionIds().isEmpty()) {\n+            LOGGER.info(\"Finishing internal transaction (\" + rollbackedAccumulation.getAccTransactionIds() + \")\");\n+        } // if\n+\n+        rollbackedAccumulations.remove(0);\n+        numPersistedEvents += rollbackedAccumulation.getBatch().getNumEvents();\n+        setMDCToNA();\n+        return Status.READY;\n+    } // processRollbackedBatches\n+    \n+    /**\n+     * Gets a rollbacked accumulation for retry.\n+     * @return A rollbacked accumulation for retry.\n+     */\n+    protected Accumulator getRollbackedAccumulationForRetry() {\n+        Accumulator rollbackedAccumulation = null;\n+        \n+        for (Accumulator rollbackedAcc : rollbackedAccumulations) {\n+            rollbackedAccumulation = rollbackedAcc;\n+            \n+            // Check the last retry\n+            int retryIntervalIndex = batchTTL - rollbackedAccumulation.ttl;\n+            \n+            if (retryIntervalIndex >= batchRetryIntervals.length) {\n+                retryIntervalIndex = batchRetryIntervals.length - 1;\n+            } // if\n+            \n+            if (rollbackedAccumulation.getLastRetry() + batchRetryIntervals[retryIntervalIndex]\n+                    <= new Date().getTime()) {\n+                break;\n+            } // if\n+            \n+            rollbackedAccumulation = null;\n+        } // for\n+        \n+        return rollbackedAccumulation;\n+    } // getRollbackedAccumulationForRetry\n+    \n+    /**\n+     * Rollbacks the accumulation once more.\n+     * @param rollbackedAccumulation\n+     */\n+    protected void doRollbackAgain(Accumulator rollbackedAccumulation) {\n+        if (rollbackedAccumulation.getTTL() == -1) {\n+            rollbackedAccumulation.setLastRetry(new Date().getTime());\n+            LOGGER.info(\"Rollbacking again (\" + rollbackedAccumulation.getAccTransactionIds() + \"), \"\n+                    + \"infinite batch TTL\");\n+        } else if (rollbackedAccumulation.getTTL() > 1) {\n+            rollbackedAccumulation.setLastRetry(new Date().getTime());\n+            rollbackedAccumulation.setTTL(rollbackedAccumulation.getTTL() - 1);\n+            LOGGER.info(\"Rollbacking again (\" + rollbackedAccumulation.getAccTransactionIds() + \"), \"\n+                    + \"this was retry #\" + (batchTTL - rollbackedAccumulation.getTTL()));\n+        } else {\n+            rollbackedAccumulations.remove(rollbackedAccumulation);\n+\n+            if (!rollbackedAccumulation.getAccTransactionIds().isEmpty()) {\n+                LOGGER.info(\"Finishing internal transaction (\"\n+                        + rollbackedAccumulation.getAccTransactionIds() + \"), this was retry #\" + batchTTL);\n+            } // if\n+        } // if else\n+    } // doRollbackAgain\n+\n+    private Status processNewBatches() {\n+        // Get the channel\n+        Channel ch = getChannel();\n+        \n+        // Start a Flume transaction (it is not the same than a Cygnus transaction!)\n+        Transaction txn = ch.getTransaction();\n+        txn.begin();\n+\n+        // Get and process as many events as the batch size\n+        int currentIndex;\n+\n+        for (currentIndex = accumulator.getAccIndex(); currentIndex < batchSize; currentIndex++) {\n+            // Check if the batch accumulation timeout has been reached\n+            if ((new Date().getTime() - accumulator.getAccStartDate()) > (batchTimeout * 1000)) {\n+                LOGGER.debug(\"Batch accumulation time reached, the batch will be processed as it is\");\n+                break;\n+            } // if\n+\n+            // Get an event\n+            Event event = ch.take();\n+            \n+            // Check if the event is null\n+            if (event == null) {\n+                accumulator.setAccIndex(currentIndex);\n+                txn.commit();\n+                txn.close();\n+                // to-do: this must be uncomment once multiple transaction and correlation IDs are traced in logs\n+                //setMDCToNA();\n+                return Status.BACKOFF; // Slow down the sink since no events are available\n+            } // if\n+            \n+            // Cast the event to a NGSI event\n+            NGSILDEvent ngsiEvent;\n+            \n+            if (event instanceof NGSILDEvent) {\n+                // Event comes from memory... everything is already in memory\n+                ngsiEvent = (NGSILDEvent)event;\n+            } else {\n+                // Event comes from file... original and mapped context elements must be re-created\n+                String[] contextElementsStr = (new String(event.getBody())).split(CommonConstants.CONCATENATOR);\n+                Gson gson = new Gson();\n+                ContextElement originalCE = null;\n+                ContextElement mappedCE = null;\n+                \n+                if (contextElementsStr.length == 1) {\n+                    originalCE = gson.fromJson(contextElementsStr[0], ContextElement.class);\n+                } else if (contextElementsStr.length == 2) {\n+                    originalCE = gson.fromJson(contextElementsStr[0], ContextElement.class);\n+                    mappedCE = gson.fromJson(contextElementsStr[1], ContextElement.class);\n+                } // if else\n+                \n+                // Re-create the NGSI event\n+                ngsiEvent = new NGSILDEvent(event.getHeaders(), event.getBody(), originalCE);\n+                LOGGER.debug(\"Re-creating NGSI event from raw bytes in file channel, original context element: \"\n+                        + (originalCE == null ? null : originalCE.toString()) + \", mapped context element: \"\n+                        + (mappedCE == null ? null : mappedCE.toString()));\n+            } // if else\n+\n+            // Set the correlation ID, transaction ID, service and service path in MDC\n+            MDC.put(CommonConstants.LOG4J_CORR,\n+                    ngsiEvent.getHeaders().get(CommonConstants.HEADER_CORRELATOR_ID));\n+            MDC.put(CommonConstants.LOG4J_TRANS,\n+                    ngsiEvent.getHeaders().get(NGSIConstants.FLUME_HEADER_TRANSACTION_ID));\n+            MDC.put(CommonConstants.LOG4J_SVC,\n+                    ngsiEvent.getHeaders().get(CommonConstants.HEADER_FIWARE_SERVICE));\n+\n+\n+            // Accumulate the event\n+            accumulator.accumulate(ngsiEvent);\n+            numProcessedEvents++;\n+        } // for\n+\n+        // Save the current index for next run of the process() method\n+        accumulator.setAccIndex(currentIndex);\n+\n+        // Persist the accumulation\n+        if (accumulator.getAccIndex() != 0) {\n+            LOGGER.debug(\"Batch completed\");\n+            NGSILDBatch batch = accumulator.getBatch();\n+\n+            try {\n+                persistBatch(batch);\n+            } catch (CygnusBadConfiguration | CygnusBadContextData | CygnusRuntimeError e) {\n+                updateServiceMetrics(batch, true);\n+                LOGGER.error(e.getMessage() + \"Stack trace: \" + Arrays.toString(e.getStackTrace()));\n+                accumulator.initialize(new Date().getTime());\n+                txn.commit();\n+                txn.close();\n+                setMDCToNA();\n+                return Status.READY;\n+            } catch (CygnusPersistenceError e) {\n+                updateServiceMetrics(batch, true);\n+                LOGGER.error(e.getMessage() + \"Stack trace: \" + Arrays.toString(e.getStackTrace()));\n+                doRollback(accumulator.clone()); // the global accumulator has to be cloned for rollbacking purposes\n+                accumulator.initialize(new Date().getTime());\n+                txn.commit();\n+                txn.close();\n+                setMDCToNA();\n+                return Status.BACKOFF; // slow down the sink since there are problems with the persistence backend\n+            } // try catch\n+\n+            if (persistencePolicyMaxRecords > -1) {\n+                try {\n+                    capRecords(batch, persistencePolicyMaxRecords);\n+                } catch (CygnusCappingError e) {\n+                    LOGGER.error(e.getMessage() + \"Stack trace: \" + Arrays.toString(e.getStackTrace()));\n+                } // try\n+            } // if\n+            \n+            updateServiceMetrics(batch, false);\n+        } // if\n+\n+        if (!accumulator.getAccTransactionIds().isEmpty()) {\n+            LOGGER.info(\"Finishing internal transaction (\" + accumulator.getAccTransactionIds() + \")\");\n+        } // if\n+\n+        numPersistedEvents += accumulator.getBatch().getNumEvents();\n+        accumulator.initialize(new Date().getTime());\n+        txn.commit();\n+        txn.close();\n+        setMDCToNA();\n+        return Status.READY;\n+    } // processNewBatches\n+    \n+    /**\n+     * Sets some MDC logging fields to 'N/A' for this thread. Value for the component field is inherited from main\n+     * thread (CygnusApplication.java).\n+     */\n+    private void setMDCToNA() {\n+        MDC.put(CommonConstants.LOG4J_CORR, CommonConstants.NA);\n+        MDC.put(CommonConstants.LOG4J_TRANS, CommonConstants.NA);\n+        MDC.put(CommonConstants.LOG4J_SVC, CommonConstants.NA);\n+        MDC.put(CommonConstants.LOG4J_SUBSVC, CommonConstants.NA);\n+    } // setMDCToNA\n+\n+    /**\n+     * Rollbacks the accumulator for the first time.\n+     * @param accumulator Accumulator to be rollbacked\n+     */\n+    protected void doRollback(Accumulator accumulator) {\n+        if (accumulator.getTTL() == -1) {\n+            accumulator.setLastRetry(new Date().getTime());\n+            rollbackedAccumulations.add(accumulator);\n+            LOGGER.info(\"Rollbacking (\" + accumulator.getAccTransactionIds() + \"), \"\n+                    + \"infinite batch TTL\");\n+        } else if (accumulator.getTTL() > 0) {\n+            accumulator.setLastRetry(new Date().getTime());\n+            rollbackedAccumulations.add(accumulator);\n+            LOGGER.info(\"Rollbacking (\" + accumulator.getAccTransactionIds() + \"), \"\n+                    + batchTTL + \" retries will be done\");\n+        } else {\n+            if (!accumulator.getAccTransactionIds().isEmpty()) {\n+                LOGGER.info(\"Finishing internal transaction (\"\n+                        + accumulator.getAccTransactionIds() + \"), 0 retries will be done\");\n+            } // if\n+        } // if else\n+    } // doRollback\n+    \n+    private void updateServiceMetrics(NGSILDBatch batch, boolean error) {\n+        batch.startIterator();\n+        \n+        while (batch.hasNext()) {\n+            ArrayList<NGSILDEvent> events = batch.getNextEvents();\n+            NGSILDEvent event = events.get(0);\n+            String service = event.getServiceForData();\n+            String servicePath = event.getServicePathForData();\n+            long time = (new Date().getTime() - event.getRecvTimeTs()) * events.size();\n+            serviceMetrics.add(service, servicePath, 0, 0, 0, 0, time, events.size(), 0, 0, error ? events.size() : 0);\n+        } // while\n+    } // updateServiceMetrics\n+\n+    /**\n+     * Utility class for batch-like getRecvTimeTs accumulation purposes.\n+     */\n+    protected class Accumulator implements Cloneable {\n+\n+        // accumulated events\n+        private NGSILDBatch batch;\n+        private long accStartDate;\n+        private int accIndex;\n+        private String accTransactionIds;\n+        private int ttl;\n+        private long lastRetry;\n+\n+        /**\n+         * Constructor.\n+         */\n+        public Accumulator() {\n+            batch = new NGSILDBatch();\n+            accStartDate = 0;\n+            accIndex = 0;\n+            accTransactionIds = null;\n+            ttl = batchTTL;\n+            lastRetry = 0;\n+        } // Accumulator\n+\n+        public long getAccStartDate() {\n+            return accStartDate;\n+        } // getAccStartDate\n+\n+        public int getAccIndex() {\n+            return accIndex;\n+        } // getAccIndex\n+\n+        public void setAccIndex(int accIndex) {\n+            this.accIndex = accIndex;\n+        } // setAccIndex\n+\n+        public NGSILDBatch getBatch() {\n+            return batch;\n+        } // getBatch\n+\n+        public String getAccTransactionIds() {\n+            return accTransactionIds;\n+        } // getAccTransactionIds\n+        \n+        public long getLastRetry() {\n+            return lastRetry;\n+        } // getLastRetry\n+        \n+        public void setLastRetry(long lastRetry) {\n+            this.lastRetry = lastRetry;\n+        } // setLastRetry\n+        \n+        public int getTTL() {\n+            return ttl;\n+        } // getTTL\n+        \n+        public void setTTL(int ttl) {\n+            this.ttl = ttl;\n+        } // setTTL\n+\n+        /**\n+         * Accumulates an getRecvTimeTs given its headers and context data.\n+         * @param event\n+         */\n+        public void accumulate(NGSILDEvent event) {\n+            String transactionId = event.getHeaders().get(CommonConstants.HEADER_CORRELATOR_ID);\n+\n+            if (accTransactionIds.isEmpty()) {\n+                accTransactionIds = transactionId;\n+            } else {\n+                accTransactionIds += \",\" + transactionId;\n+            } // if else\n+\n+            switch (dataModel) {\n+                case DMBYSERVICE:\n+                    accumulateByService(event);\n+                    break;\n+                case DMBYSERVICEPATH:\n+                    accumulateByServicePath(event);\n+                    break;\n+                case DMBYENTITY:\n+                    accumulateByEntity(event);\n+                    break;\n+                case DMBYENTITYTYPE:\n+                    accumulateByEntityType(event);\n+                    break;\n+                case DMBYATTRIBUTE:\n+                    accumulateByAttribute(event);\n+                    break;\n+                default:\n+                    LOGGER.error(\"Unknown data model. Details=\" + dataModel.toString());\n+            } // switch\n+        } // accumulate\n+\n+        private void accumulateByService(NGSILDEvent event) {\n+            Map<String, String> headers = event.getHeaders();\n+            String destination;\n+\n+            if (enableNameMappings) {\n+                destination = headers.get(NGSIConstants.FLUME_HEADER_MAPPED_SERVICE);\n+            } else {\n+                destination = headers.get(CommonConstants.HEADER_FIWARE_SERVICE);\n+            } // if else\n+\n+            \n+            batch.addEvent(destination, event);\n+        } // accumulateByService\n+\n+        private void accumulateByServicePath(NGSILDEvent event) {\n+            Map<String, String> headers = event.getHeaders();\n+            String destination;\n+            String service = headers.get(CommonConstants.HEADER_FIWARE_SERVICE);\n+\n+            if (enableGrouping) {\n+                destination = service + \"_\" + headers.get(NGSIConstants.FLUME_HEADER_GROUPED_SERVICE_PATH);\n+            } else {\n+                destination = service + \"_\" + headers.get(CommonConstants.HEADER_FIWARE_SERVICE_PATH);\n+            } // if else\n+\n+            batch.addEvent(destination, event);\n+        } // accumulateByServicePath\n+\n+        private void accumulateByEntity(NGSILDEvent event) {\n+            Map<String, String> headers = event.getHeaders();\n+            ContextElement originalCE = event.getOriginalCELD();\n+            String destination;\n+            \n+                String service = headers.get(CommonConstants.HEADER_FIWARE_SERVICE);\n+                \n+                if (enableGrouping) {\n+                    destination = service + \"_\" + headers.get(NGSIConstants.FLUME_HEADER_GROUPED_SERVICE_PATH)\n+                            + \"_\" + headers.get(NGSIConstants.FLUME_HEADER_GROUPED_ENTITY);\n+                } else {\n+                    destination = service + \"_\" + headers.get(CommonConstants.HEADER_FIWARE_SERVICE_PATH)\n+                            + \"_\" + headers.get(NGSIConstants.FLUME_HEADER_NOTIFIED_ENTITY);\n+                } // if else\n+                if (enableNameMappings) {\n+                    destination = headers.get(NGSIConstants.FLUME_HEADER_MAPPED_SERVICE) + \"_\"\n+                            + headers.get(NGSIConstants.FLUME_HEADER_MAPPED_SERVICE_PATH);\n+                } else {\n+                    destination = headers.get(CommonConstants.HEADER_FIWARE_SERVICE) + \"_\"\n+                            + headers.get(CommonConstants.HEADER_FIWARE_SERVICE_PATH) + \"_\"\n+                            + originalCE.getId() + \"_\" + originalCE.getType();\n+                } // if else\n+\n+            batch.addEvent(destination, event);\n+        } // accumulateByEntity\n+\n+        private void accumulateByEntityType(NGSILDEvent event) {\n+            Map<String, String> headers = event.getHeaders();\n+            ContextElement originalCE = event.getOriginalCELD();\n+            String destination;\n+            String service = headers.get(CommonConstants.HEADER_FIWARE_SERVICE);\n+\n+            if (enableGrouping) {\n+                destination = service + \"_\" + headers.get(NGSIConstants.FLUME_HEADER_GROUPED_SERVICE_PATH)\n+                        + \"_\" + headers.get(NGSIConstants.FLUME_HEADER_GROUPED_ENTITY_TYPE);\n+            } else {\n+                destination = service + \"_\" + headers.get(CommonConstants.HEADER_FIWARE_SERVICE_PATH)\n+                        + \"_\" + headers.get(NGSIConstants.FLUME_HEADER_GROUPED_ENTITY_TYPE);\n+            } // if else\n+            batch.addEvent(destination, event);\n+        } // accumulateByEntityType\n+\n+        private void accumulateByAttribute(NGSILDEvent event) {\n+            Map<String, String> headers = event.getHeaders();\n+            ContextElement originalCE = event.getOriginalCELD();\n+            String destination;\n+\n+        } // accumulateByAttribute\n+\n+        /**\n+         * Initialize the batch.\n+         * @param startDateMs\n+         */\n+        public void initialize(long startDateMs) {\n+            // what happens if Cygnus falls down while accumulating the batch?\n+            // TBD: https://github.com/telefonicaid/fiware-cygnus/issues/562", "originalCommit": "5dee33e077166bd0c7e87d87fadd589a8c4ea877", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "287586a170991d1bfcf8b1248db4a2388c6dbfe5", "url": "https://github.com/telefonicaid/fiware-cygnus/commit/287586a170991d1bfcf8b1248db4a2388c6dbfe5", "message": "Update cygnus-ngsi-ld/src/main/java/com/telefonica/iot/cygnus/utils/NGSIUtils.java\n\nCo-authored-by: Ferm\u00edn Gal\u00e1n M\u00e1rquez <fgalan@users.noreply.github.com>", "committedDate": "2020-06-12T09:30:51Z", "type": "commit"}, {"oid": "8a53ac431edf58865daef6f17606f758a66e0af0", "url": "https://github.com/telefonicaid/fiware-cygnus/commit/8a53ac431edf58865daef6f17606f758a66e0af0", "message": "Update cygnus-ngsi-ld/src/main/java/com/telefonica/iot/cygnus/sinks/NGSILDSink.java\n\nCo-authored-by: Ferm\u00edn Gal\u00e1n M\u00e1rquez <fgalan@users.noreply.github.com>", "committedDate": "2020-06-12T09:31:07Z", "type": "commit"}, {"oid": "df578add378e618c297f0ee15ec256549b684a46", "url": "https://github.com/telefonicaid/fiware-cygnus/commit/df578add378e618c297f0ee15ec256549b684a46", "message": " Update testConfigureDataModel", "committedDate": "2020-06-12T09:46:01Z", "type": "commit"}, {"oid": "242ee26e16925d71078f158f783a5a2d14f6f19f", "url": "https://github.com/telefonicaid/fiware-cygnus/commit/242ee26e16925d71078f158f783a5a2d14f6f19f", "message": "Merge branch 'master' of https://github.com/ging/fiware-cygnus", "committedDate": "2020-06-12T09:48:30Z", "type": "commit"}, {"oid": "e772818f2cb398995667a0daa5b79ba8e3e3d351", "url": "https://github.com/telefonicaid/fiware-cygnus/commit/e772818f2cb398995667a0daa5b79ba8e3e3d351", "message": "Update changes file  Hive-jdbc dependency from version 2.3.4 to version 3.1.2", "committedDate": "2020-06-12T10:02:13Z", "type": "commit"}, {"oid": "078980fe35afabdcf3f2ba1adcca26c3c96a1a9d", "url": "https://github.com/telefonicaid/fiware-cygnus/commit/078980fe35afabdcf3f2ba1adcca26c3c96a1a9d", "message": "Update changes file  including the creation of the new cygnus-ngsi-ld bundle", "committedDate": "2020-06-12T10:06:10Z", "type": "commit"}, {"oid": "246d23b9727c1d81ae2ff1003f752fe98563237d", "url": "https://github.com/telefonicaid/fiware-cygnus/commit/246d23b9727c1d81ae2ff1003f752fe98563237d", "message": "Update doc/cygnus-ngsi-ld/user_and_programmer_guide/adding_new_sink.md\n\nCo-authored-by: Ferm\u00edn Gal\u00e1n M\u00e1rquez <fgalan@users.noreply.github.com>", "committedDate": "2020-06-16T16:13:30Z", "type": "commit"}, {"oid": "58ac9e6ed7ebe9431acbecaa457814a36d8c8915", "url": "https://github.com/telefonicaid/fiware-cygnus/commit/58ac9e6ed7ebe9431acbecaa457814a36d8c8915", "message": "Update CHANGES_NEXT_RELEASE", "committedDate": "2020-06-16T16:19:34Z", "type": "commit"}, {"oid": "9d14528f9450b627d8bbef3511628d5c6673ccf8", "url": "https://github.com/telefonicaid/fiware-cygnus/commit/9d14528f9450b627d8bbef3511628d5c6673ccf8", "message": "Merge branch 'master' into master", "committedDate": "2020-06-16T16:21:23Z", "type": "commit"}, {"oid": "b2083b22dfaec756c536e3968bdd99993a420706", "url": "https://github.com/telefonicaid/fiware-cygnus/commit/b2083b22dfaec756c536e3968bdd99993a420706", "message": "Update doc/cygnus-ngsi-ld/flume_extensions_catalogue/ngsi_rest_handler.md\n\nCo-authored-by: Ferm\u00edn Gal\u00e1n M\u00e1rquez <fgalan@users.noreply.github.com>", "committedDate": "2020-06-16T16:22:26Z", "type": "commit"}, {"oid": "917bf6a7094ed130f1dd27463f62d130b01c79d5", "url": "https://github.com/telefonicaid/fiware-cygnus/commit/917bf6a7094ed130f1dd27463f62d130b01c79d5", "message": "Merge branch 'master' into master", "committedDate": "2020-06-24T13:09:44Z", "type": "commit"}, {"oid": "1dc0f555185c4399d1f873c8f4a9d0568e7113dd", "url": "https://github.com/telefonicaid/fiware-cygnus/commit/1dc0f555185c4399d1f873c8f4a9d0568e7113dd", "message": "Revert hive dependency version", "committedDate": "2020-06-24T14:28:44Z", "type": "commit"}, {"oid": "75c3a8dd631f81c49719566fb812ecfbf552f80e", "url": "https://github.com/telefonicaid/fiware-cygnus/commit/75c3a8dd631f81c49719566fb812ecfbf552f80e", "message": "Revert NEXT_RELEASE", "committedDate": "2020-06-24T14:29:31Z", "type": "commit"}, {"oid": "6a012af2535887ed6464ee013fe338b178b7b66b", "url": "https://github.com/telefonicaid/fiware-cygnus/commit/6a012af2535887ed6464ee013fe338b178b7b66b", "message": "Update CHANGES_NEXT_RELEASE\n\nCo-authored-by: Ferm\u00edn Gal\u00e1n M\u00e1rquez <fgalan@users.noreply.github.com>", "committedDate": "2020-06-24T14:43:14Z", "type": "commit"}, {"oid": "a9516edf84c6472fd4485e8075905d158c38b024", "url": "https://github.com/telefonicaid/fiware-cygnus/commit/a9516edf84c6472fd4485e8075905d158c38b024", "message": "Add cygnus-ngsi-ld tests", "committedDate": "2020-06-26T09:26:23Z", "type": "commit"}, {"oid": "e6493ce154654d391d0b2cc0c853052765291a0a", "url": "https://github.com/telefonicaid/fiware-cygnus/commit/e6493ce154654d391d0b2cc0c853052765291a0a", "message": "Remove ArcGIS dependencies", "committedDate": "2020-07-06T10:35:57Z", "type": "commit"}, {"oid": "6a91d976a0c3439d089d16f7fbda69e4d371103c", "url": "https://github.com/telefonicaid/fiware-cygnus/commit/6a91d976a0c3439d089d16f7fbda69e4d371103c", "message": "Update cygnus-common version", "committedDate": "2020-07-06T11:05:46Z", "type": "commit"}]}