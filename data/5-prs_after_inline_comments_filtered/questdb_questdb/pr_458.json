{"pr_number": 458, "pr_title": "Tcp line", "pr_createdAt": "2020-06-29T08:49:57Z", "pr_url": "https://github.com/questdb/questdb/pull/458", "timeline": [{"oid": "3f72542c2df6654af3b68c3bc9f310cd2b782138", "url": "https://github.com/questdb/questdb/commit/3f72542c2df6654af3b68c3bc9f310cd2b782138", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-06-23T17:33:36Z", "type": "commit"}, {"oid": "f824420ba3a9712d6d37eb6277d662d87ad28d0c", "url": "https://github.com/questdb/questdb/commit/f824420ba3a9712d6d37eb6277d662d87ad28d0c", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-06-23T17:33:36Z", "type": "commit"}, {"oid": "a48a4c31046c76bc0e3384f313d5e16ec071fde6", "url": "https://github.com/questdb/questdb/commit/a48a4c31046c76bc0e3384f313d5e16ec071fde6", "message": "chore: Fix merge issue", "committedDate": "2020-06-23T17:37:54Z", "type": "commit"}, {"oid": "bb48d9e60f90e360ab7543ef5e513b0a97abc53e", "url": "https://github.com/questdb/questdb/commit/bb48d9e60f90e360ab7543ef5e513b0a97abc53e", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-06-24T08:39:58Z", "type": "commit"}, {"oid": "bf44d5f1e145e964cc7bf9f70b56e43e67d757bd", "url": "https://github.com/questdb/questdb/commit/bf44d5f1e145e964cc7bf9f70b56e43e67d757bd", "message": "Merge remote-tracking branch 'origin/master' into tcp-line", "committedDate": "2020-06-24T08:40:26Z", "type": "commit"}, {"oid": "3f264a5f0faa291edeb76f3623d2a7317e420bfb", "url": "https://github.com/questdb/questdb/commit/3f264a5f0faa291edeb76f3623d2a7317e420bfb", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-06-24T09:16:19Z", "type": "commit"}, {"oid": "e97387d6a7b7ce5bd2e231ff2dc2312a1636be1a", "url": "https://github.com/questdb/questdb/commit/e97387d6a7b7ce5bd2e231ff2dc2312a1636be1a", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-06-25T08:47:35Z", "type": "commit"}, {"oid": "9626c1cc6b11cb5bfc0fe0a4af2256795a85396a", "url": "https://github.com/questdb/questdb/commit/9626c1cc6b11cb5bfc0fe0a4af2256795a85396a", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-06-25T13:36:30Z", "type": "commit"}, {"oid": "c6a8590e6fc63044142628403448ae31775d2a92", "url": "https://github.com/questdb/questdb/commit/c6a8590e6fc63044142628403448ae31775d2a92", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-06-25T14:15:27Z", "type": "commit"}, {"oid": "373af9110f82847bd7ea4e633932f7d446773b2e", "url": "https://github.com/questdb/questdb/commit/373af9110f82847bd7ea4e633932f7d446773b2e", "message": "feature(cutlass): Add support for influxdb line protocol over TCP\n switch to WorkerPool for writers", "committedDate": "2020-06-26T10:19:20Z", "type": "commit"}, {"oid": "a95d756694952f559d5a1719b54c61e6331aaf67", "url": "https://github.com/questdb/questdb/commit/a95d756694952f559d5a1719b54c61e6331aaf67", "message": "feature(cutlass): Add support for influxdb line protocol over TCP\n fix issue on disconnect when writers havn't been able to keep up", "committedDate": "2020-06-26T12:49:56Z", "type": "commit"}, {"oid": "425aa7ac6a326a156d60b2f25b75c176b8a5ddc9", "url": "https://github.com/questdb/questdb/commit/425aa7ac6a326a156d60b2f25b75c176b8a5ddc9", "message": "feature(cutlass): Add support for influxdb line protocol over TCP\n add configuration for worker pools", "committedDate": "2020-06-26T13:43:42Z", "type": "commit"}, {"oid": "2b6fdad53778923d934984c354aaf68b25b84e53", "url": "https://github.com/questdb/questdb/commit/2b6fdad53778923d934984c354aaf68b25b84e53", "message": "Merge remote-tracking branch 'origin/master' into tcp-line", "committedDate": "2020-06-26T13:49:21Z", "type": "commit"}, {"oid": "8609aa8bb2cb7d75fa383a2b51c610d097327b77", "url": "https://github.com/questdb/questdb/commit/8609aa8bb2cb7d75fa383a2b51c610d097327b77", "message": "feature(cutlass): Add support for influxdb line protocol over TCP\n add table stats", "committedDate": "2020-06-26T14:29:53Z", "type": "commit"}, {"oid": "09797e8111a678ee1b437967eb4a3fe28309af92", "url": "https://github.com/questdb/questdb/commit/09797e8111a678ee1b437967eb4a3fe28309af92", "message": "feature(cutlass): Add support for influxdb line protocol over TCP\n add load balancing", "committedDate": "2020-06-26T21:39:41Z", "type": "commit"}, {"oid": "bf033314f942ddd78cfd0790d76097c019c610e9", "url": "https://github.com/questdb/questdb/commit/bf033314f942ddd78cfd0790d76097c019c610e9", "message": "feature(cutlass): Add support for influxdb line protocol over TCP\n fix test", "committedDate": "2020-06-27T07:32:26Z", "type": "commit"}, {"oid": "216efe6f6ef6849c83782e9df3d3e498af89f17b", "url": "https://github.com/questdb/questdb/commit/216efe6f6ef6849c83782e9df3d3e498af89f17b", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-06-29T08:42:58Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjkyMzE5MA==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r446923190", "bodyText": "could be\n(value.charAt(0) | 32) == 't'", "author": "bluestreak01", "createdAt": "2020-06-29T12:13:52Z", "path": "core/src/main/java/io/questdb/cutlass/line/CairoLineProtoParserSupport.java", "diffHunk": "@@ -0,0 +1,93 @@\n+package io.questdb.cutlass.line;\n+\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.std.Numbers;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+\n+public class CairoLineProtoParserSupport {\n+    private final static Log LOG = LogFactory.getLog(CairoLineProtoParserSupport.class);\n+    public static final ObjList<ColumnWriter> writers = new ObjList<>();\n+\n+    static {\n+        writers.extendAndSet(ColumnType.LONG, CairoLineProtoParserSupport::putLong);\n+        writers.extendAndSet(ColumnType.BOOLEAN, CairoLineProtoParserSupport::putBoolean);\n+        writers.extendAndSet(ColumnType.STRING, CairoLineProtoParserSupport::putStr);\n+        writers.extendAndSet(ColumnType.SYMBOL, CairoLineProtoParserSupport::putSymbol);\n+        writers.extendAndSet(ColumnType.DOUBLE, CairoLineProtoParserSupport::putDouble);\n+    }\n+\n+    public interface ColumnWriter {\n+        void write(TableWriter.Row row, int columnIndex, CharSequence value) throws BadCastException;\n+    }\n+\n+    public static class BadCastException extends Exception {\n+        private static final BadCastException INSTANCE = new BadCastException();\n+    }\n+\n+    public static int getValueType(CharSequence token) {\n+        int len = token.length();\n+        switch (token.charAt(len - 1)) {\n+            case 'i':\n+                return ColumnType.LONG;\n+            case 'e':\n+                // tru(e)\n+                // fals(e)\n+            case 't':\n+            case 'T':\n+                // t\n+                // T\n+            case 'f':\n+            case 'F':\n+                // f\n+                // F\n+                return ColumnType.BOOLEAN;\n+            case '\"':\n+                if (len < 2 || token.charAt(0) != '\\\"') {\n+                    LOG.error().$(\"incorrectly quoted string: \").$(token).$();\n+                    return -1;\n+                }\n+                return ColumnType.STRING;\n+            default:\n+                return ColumnType.DOUBLE;\n+        }\n+    }\n+\n+    private static boolean isTrue(CharSequence value) {\n+        final char firstChar = value.charAt(0);\n+        return firstChar == 't' || firstChar == 'T';", "originalCommit": "216efe6f6ef6849c83782e9df3d3e498af89f17b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjkyNDUwMA==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r446924500", "bodyText": "this is controversial. So here we have data from socket, but no internal queue items to handle the input. We are failing in essence. I think we need to stay in the loop or have a way to return to the job without being triggered by the IO", "author": "bluestreak01", "createdAt": "2020-06-29T12:16:10Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpConnectionContext.java", "diffHunk": "@@ -0,0 +1,148 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import io.questdb.cutlass.line.tcp.LineTcpMeasurementScheduler.LineTcpMeasurementEvent;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.network.IOContext;\n+import io.questdb.network.IODispatcher;\n+import io.questdb.network.IOOperation;\n+import io.questdb.network.NetworkFacade;\n+import io.questdb.std.Mutable;\n+import io.questdb.std.Unsafe;\n+import io.questdb.std.str.DirectByteCharSequence;\n+\n+class LineTcpConnectionContext implements IOContext, Mutable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpConnectionContext.class);\n+    private final NetworkFacade nf;\n+    private final LineTcpMeasurementScheduler scheduler;\n+    private long fd;\n+    private IODispatcher<LineTcpConnectionContext> dispatcher;\n+    private long recvBufStart;\n+    private long recvBufEnd;\n+    private long recvBufPos;\n+    private boolean peerDisconnected;\n+    private final DirectByteCharSequence byteCharSequence = new DirectByteCharSequence();\n+\n+    LineTcpConnectionContext(LineTcpReceiverConfiguration configuration, LineTcpMeasurementScheduler scheduler) {\n+        nf = configuration.getNetworkFacade();\n+        this.scheduler = scheduler;\n+        recvBufStart = Unsafe.malloc(configuration.getNetMsgBufferSize());\n+        recvBufEnd = recvBufStart + configuration.getNetMsgBufferSize();\n+    }\n+\n+    // returns true if busy\n+    boolean handleIO() {\n+        try {\n+            LineTcpMeasurementEvent event = scheduler.getNewEvent();\n+            if (null == event) {\n+                // Waiting for writer threads to drain queue, request callback as soon as possible\n+                dispatcher.registerChannel(this, IOOperation.READ);\n+                dispatcher.registerChannel(this, IOOperation.WRITE);", "originalCommit": "216efe6f6ef6849c83782e9df3d3e498af89f17b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjkyNjI3MA==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r446926270", "bodyText": "same here, we do not have enough throughput. Cannot rely on IO to help us restart,", "author": "bluestreak01", "createdAt": "2020-06-29T12:19:19Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpConnectionContext.java", "diffHunk": "@@ -0,0 +1,148 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import io.questdb.cutlass.line.tcp.LineTcpMeasurementScheduler.LineTcpMeasurementEvent;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.network.IOContext;\n+import io.questdb.network.IODispatcher;\n+import io.questdb.network.IOOperation;\n+import io.questdb.network.NetworkFacade;\n+import io.questdb.std.Mutable;\n+import io.questdb.std.Unsafe;\n+import io.questdb.std.str.DirectByteCharSequence;\n+\n+class LineTcpConnectionContext implements IOContext, Mutable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpConnectionContext.class);\n+    private final NetworkFacade nf;\n+    private final LineTcpMeasurementScheduler scheduler;\n+    private long fd;\n+    private IODispatcher<LineTcpConnectionContext> dispatcher;\n+    private long recvBufStart;\n+    private long recvBufEnd;\n+    private long recvBufPos;\n+    private boolean peerDisconnected;\n+    private final DirectByteCharSequence byteCharSequence = new DirectByteCharSequence();\n+\n+    LineTcpConnectionContext(LineTcpReceiverConfiguration configuration, LineTcpMeasurementScheduler scheduler) {\n+        nf = configuration.getNetworkFacade();\n+        this.scheduler = scheduler;\n+        recvBufStart = Unsafe.malloc(configuration.getNetMsgBufferSize());\n+        recvBufEnd = recvBufStart + configuration.getNetMsgBufferSize();\n+    }\n+\n+    // returns true if busy\n+    boolean handleIO() {\n+        try {\n+            LineTcpMeasurementEvent event = scheduler.getNewEvent();\n+            if (null == event) {\n+                // Waiting for writer threads to drain queue, request callback as soon as possible\n+                dispatcher.registerChannel(this, IOOperation.READ);\n+                dispatcher.registerChannel(this, IOOperation.WRITE);\n+                return true;\n+            }\n+\n+            // Read as much data as possible\n+            int len = (int) (recvBufEnd - recvBufPos);\n+            if (len > 0 && !peerDisconnected) {\n+                int nRead = nf.recv(fd, recvBufPos, len);\n+                if (nRead < 0) {\n+                    if (recvBufPos != recvBufStart) {\n+                        LOG.info().$('[').$(fd).$(\"] disconnected with partial measurement, \").$(recvBufPos - recvBufStart).$(\" unprocessed bytes\").$();\n+                    }\n+                    peerDisconnected = true;\n+                } else {\n+                    recvBufPos += nRead;\n+                }\n+            }\n+\n+            // Process as much data as possible\n+            long recvBufLineStart = recvBufStart;\n+            do {\n+                long recvBufLineNext = event.parseLine(recvBufLineStart, recvBufPos);\n+                if (recvBufLineNext == -1) {\n+                    break;\n+                }\n+                if (!event.isError()) {\n+                    scheduler.commitNewEvent(event);\n+                    event = scheduler.getNewEvent();\n+                } else {\n+                    LOG.error().$('[').$(fd).$(\"] failed to parse measurement, code \").$(event.getErrorCode()).$(\" at \").$(event.getErrorPosition()).$(\" in \")\n+                            .$(byteCharSequence.of(recvBufLineStart, recvBufLineNext - 1)).$();\n+                }\n+                recvBufLineStart = recvBufLineNext;\n+            } while (recvBufLineStart != recvBufPos && null != event);\n+\n+            // Compact input buffer\n+            if (recvBufLineStart != recvBufStart) {\n+                len = (int) (recvBufPos - recvBufLineStart);\n+                if (len > 0) {\n+                    Unsafe.getUnsafe().copyMemory(recvBufLineStart, recvBufStart, len);\n+                }\n+                recvBufPos = recvBufStart + len;\n+            }\n+\n+            // Check if we are waiting for writer threads\n+            if (null == event) {\n+                // Waiting for writer threads to drain queue, request callback as soon as possible\n+                dispatcher.registerChannel(this, IOOperation.READ);\n+                dispatcher.registerChannel(this, IOOperation.WRITE);", "originalCommit": "216efe6f6ef6849c83782e9df3d3e498af89f17b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjkyOTA4OQ==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r446929089", "bodyText": "There is Chars.toString() to track instances where we convert char sequence to string more easier", "author": "bluestreak01", "createdAt": "2020-06-29T12:24:16Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,745 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableStats> statsByTableName;\n+    private final int[] loadByThread;\n+    // TODO\n+    private final int nUpdatesPerLoadRebalance = 1000;\n+    private final double maxLoadRatio;\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        statsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        maxLoadRatio = 1d + 1d / writerWorkerPool.getWorkerCount();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            do {\n+                nextEventCursor = pubSeq.next();\n+            } while (nextEventCursor == -2);\n+            if (nextEventCursor < 0) {\n+                nextEventCursor = -1;\n+                return null;\n+            }\n+        }\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableStats stats = statsByTableName.get(event.getTableName());\n+        if (null == stats) {\n+            String tableName = event.getTableName().toString();", "originalCommit": "216efe6f6ef6849c83782e9df3d3e498af89f17b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjkzMjIzOA==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r446932238", "bodyText": "there is more efficient way to check that map item exists and then insert it\nint keyIndex = map.keyIndex(tableName);\nif ( keyIndex > -1) {\n // table name is new to the map\n ...\n value = new ...\n map.putAt(keyIndex, tableName, value);\n} else {\n  value = map.valueAt(keyIndex);\n}", "author": "bluestreak01", "createdAt": "2020-06-29T12:29:19Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,745 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableStats> statsByTableName;\n+    private final int[] loadByThread;\n+    // TODO\n+    private final int nUpdatesPerLoadRebalance = 1000;\n+    private final double maxLoadRatio;\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        statsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        maxLoadRatio = 1d + 1d / writerWorkerPool.getWorkerCount();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            do {\n+                nextEventCursor = pubSeq.next();\n+            } while (nextEventCursor == -2);\n+            if (nextEventCursor < 0) {\n+                nextEventCursor = -1;\n+                return null;\n+            }\n+        }\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableStats stats = statsByTableName.get(event.getTableName());", "originalCommit": "216efe6f6ef6849c83782e9df3d3e498af89f17b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njk0Nzc4Mw==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r446947783", "bodyText": "We might be able to get away creating stats objects. Table name is already a key in map, does not have to be on object.\nCharSequenceLongHashMap does not exist, but i can be easily created using CharSequenceIntHashMap.\nThen the long can be decoded using Numbers.decodeHighInt() and Numbers.decodeLowInt", "author": "bluestreak01", "createdAt": "2020-06-29T12:53:56Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,745 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableStats> statsByTableName;\n+    private final int[] loadByThread;\n+    // TODO\n+    private final int nUpdatesPerLoadRebalance = 1000;\n+    private final double maxLoadRatio;\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        statsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        maxLoadRatio = 1d + 1d / writerWorkerPool.getWorkerCount();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            do {\n+                nextEventCursor = pubSeq.next();\n+            } while (nextEventCursor == -2);\n+            if (nextEventCursor < 0) {\n+                nextEventCursor = -1;\n+                return null;\n+            }\n+        }\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableStats stats = statsByTableName.get(event.getTableName());\n+        if (null == stats) {\n+            String tableName = event.getTableName().toString();\n+            calcThreadLoad();\n+            int leastLoad = Integer.MAX_VALUE;\n+            int threadId = 0;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] < leastLoad) {\n+                    leastLoad = loadByThread[n];\n+                    threadId = n;\n+                }\n+            }\n+            stats = new TableStats(tableName, threadId);\n+            statsByTableName.put(tableName, stats);\n+            LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+        }\n+        event.threadId = stats.threadId;\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (stats.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = statsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableStats stats = statsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableStats stats = statsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableStats stats = statsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = statsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableStats stats = statsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            statsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {\n+            return errorPosition != -1;\n+        }\n+\n+        int getErrorPosition() {\n+            return errorPosition;\n+        }\n+\n+        int getErrorCode() {\n+            return errorCode;\n+        }\n+\n+        CharSequence getTableName() {\n+            return cache.get(measurementNameAddress);\n+        }\n+\n+        long getTimestamp() {\n+            if (timestampAddress != 0) {\n+                try {\n+                    timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n+                    timestampAddress = 0;\n+                } catch (NumericException e) {\n+                    LOG.info().$(\"invalid timestamp: \").$(cache.get(timestampAddress)).$();\n+                    timestamp = Long.MIN_VALUE;\n+                }\n+            }\n+            return timestamp;\n+        }\n+\n+        CharSequence getName(int i) {\n+            return cache.get(addresses.getQuick(2 * i));\n+        }\n+\n+        int getNValues() {\n+            return addresses.size() / 2;\n+        }\n+\n+        CharSequence getValue(int i) {\n+            return cache.get(addresses.getQuick(2 * i + 1));\n+        }\n+\n+        int getFirstFieldIndex() {\n+            return firstFieldIndex;\n+        }\n+\n+        LineTcpMeasurementEvent createRebalanceEvent(int fromThreadId, int toThreadId, String tableName) {\n+            clear();\n+            threadId = -1;\n+            rebalanceFromThreadId = fromThreadId;\n+            rebalanceToThreadId = toThreadId;\n+            rebalanceTableName = tableName;\n+            return this;\n+        }\n+\n+        boolean isRebalanceEvent() {\n+            return threadId == -1;\n+        }\n+\n+        @Override\n+        public void close() {\n+            lexer.close();\n+            lexer = null;\n+        }\n+    }\n+\n+    private class WriterJob implements Job {\n+        private final int id;\n+        private final Sequence sequence;\n+        private final CharSequenceObjHashMap<Parser> parserCache = new CharSequenceObjHashMap<>();\n+        private final AppendMemory appendMemory = new AppendMemory();\n+        private final Path path = new Path();\n+        private final TableStructureAdapter tableStructureAdapter = new TableStructureAdapter();\n+        private final String name;\n+\n+        private WriterJob(int id, Sequence sequence) {\n+            super();\n+            this.id = id;\n+            this.sequence = sequence;\n+            this.name = \"tcp-line-writer-\" + id;\n+        }\n+\n+        private void close() {\n+            // Finish all jobs in the queue before stopping\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                if (!run(id)) {\n+                    break;\n+                }\n+            }\n+\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0; n < tableNames.size(); n++) {\n+                parserCache.get(tableNames.get(n)).close();\n+            }\n+            parserCache.clear();\n+            appendMemory.close();\n+            path.close();\n+        }\n+\n+        @Override\n+        public boolean run(int workerId) {\n+            assert workerId == id;\n+            try {\n+                long cursor;\n+                while ((cursor = sequence.next()) < 0) {\n+                    if (cursor == -1) {\n+                        return false;\n+                    }\n+                }\n+                LineTcpMeasurementEvent event = queue.get(cursor);\n+                boolean eventProcessed;\n+                try {\n+                    if (event.threadId == id) {\n+                        eventProcessed = processNextEvent(event);\n+                    } else {\n+                        if (event.isRebalanceEvent()) {\n+                            eventProcessed = processRebalance(event);\n+                        } else {\n+                            eventProcessed = true;\n+                        }\n+                    }\n+                } catch (RuntimeException ex) {\n+                    LOG.error().$(ex).$();\n+                    eventProcessed = true;\n+                }\n+                if (eventProcessed) {\n+                    sequence.done(cursor);\n+                }\n+            } catch (RuntimeException ex) {\n+                LOG.error().$(ex).$();\n+            }\n+            return true;\n+        }\n+\n+        private boolean processNextEvent(LineTcpMeasurementEvent event) {\n+            Parser parser = parserCache.get(event.getTableName());\n+            if (null == parser) {\n+                parser = new Parser();\n+                try {\n+                    parser.processFirstEvent(engine, securityContext, event);\n+                } catch (CairoException ex) {\n+                    LOG.info().$(name).$(\" could not create parser [name=\").$(event.getTableName()).$(\", ex=\").$(ex.getFlyweightMessage()).$(']').$();\n+                    parser.close();\n+                    return false;\n+                }\n+                LOG.info().$(name).$(\" created parser [name=\").$(event.getTableName()).$(']').$();\n+                parserCache.put(event.getTableName().toString(), parser);\n+                return true;\n+            } else {\n+                parser.processEvent(event);\n+                return true;\n+            }\n+        }\n+\n+        private boolean processRebalance(LineTcpMeasurementEvent event) {\n+            if (event.rebalanceToThreadId == id) {\n+                if (!event.rebalanceReleasedByFromThread) {\n+                    return false;\n+                }\n+\n+                return true;\n+            }\n+\n+            if (event.rebalanceFromThreadId == id) {\n+                Parser parser = parserCache.get(event.rebalanceTableName);\n+                parserCache.remove(event.rebalanceTableName);\n+                parser.close();\n+                event.rebalanceReleasedByFromThread = true;\n+                return true;\n+            }\n+\n+            return true;\n+        }\n+\n+        private class Parser implements Closeable {\n+            private TableWriter writer;\n+            private final IntList colTypes = new IntList();\n+            private final IntList colIndexMappings = new IntList();\n+\n+            private transient int nMeasurementValues;\n+            private transient boolean error;\n+\n+            private void processFirstEvent(CairoEngine engine, CairoSecurityContext securityContext, LineTcpMeasurementEvent event) {\n+                assert null == writer;\n+                int status = engine.getStatus(securityContext, path, event.getTableName(), 0, event.getTableName().length());\n+                if (status == TableUtils.TABLE_EXISTS) {\n+                    writer = engine.getWriter(securityContext, event.getTableName());\n+                    processEvent(event);\n+                    return;\n+                }\n+\n+                preprocessEvent(event);\n+                engine.creatTable(\n+                        securityContext,\n+                        appendMemory,\n+                        path,\n+                        tableStructureAdapter.of(event, this));\n+                int nValues = event.getNValues();\n+                for (int n = 0; n < nValues; n++) {\n+                    colIndexMappings.add(n, n);\n+                }\n+                writer = engine.getWriter(securityContext, event.getTableName());\n+                addRow(event);\n+            }\n+\n+            private void processEvent(LineTcpMeasurementEvent event) {\n+                assert event.getTableName().equals(writer.getName());\n+                preprocessEvent(event);\n+                parseNames(event);\n+                addRow(event);\n+            }\n+\n+            private void addRow(LineTcpMeasurementEvent event) {\n+                if (error) {\n+                    return;\n+                }\n+                long timestamp = event.getTimestamp();\n+                Row row = writer.newRow(timestamp);\n+                try {\n+                    for (int i = 0; i < nMeasurementValues; i++) {\n+                        int columnType = colTypes.getQuick(i);\n+                        int columnIndex = colIndexMappings.getQuick(i);\n+                        CairoLineProtoParserSupport.writers.getQuick(columnType).write(row, columnIndex, event.getValue(i));\n+                    }\n+                    row.append();\n+                } catch (BadCastException ignore) {\n+                    row.cancel();\n+                }\n+                writer.commit();\n+            }\n+\n+            private void preprocessEvent(LineTcpMeasurementEvent event) {\n+                error = false;\n+                nMeasurementValues = event.getNValues();\n+                colTypes.ensureCapacity(nMeasurementValues);\n+                colIndexMappings.ensureCapacity(nMeasurementValues);\n+                parseTypes(event);\n+            }\n+\n+            private void parseTypes(LineTcpMeasurementEvent event) {\n+                for (int n = 0; n < nMeasurementValues; n++) {\n+                    int colType;\n+                    if (n < event.getFirstFieldIndex()) {\n+                        colType = ColumnType.SYMBOL;\n+                    } else {\n+                        colType = CairoLineProtoParserSupport.getValueType(event.getValue(n));\n+                    }\n+                    colTypes.add(n, colType);\n+                }\n+            }\n+\n+            private void parseNames(LineTcpMeasurementEvent event) {\n+                RecordMetadata metadata = writer.getMetadata();\n+                for (int n = 0; n < nMeasurementValues; n++) {\n+                    int colIndex = metadata.getColumnIndexQuiet(event.getName(n));\n+                    if (colIndex == -1) {\n+                        colIndex = metadata.getColumnCount();\n+                        writer.addColumn(event.getName(n), colTypes.getQuick(n));\n+                    } else {\n+                        if (metadata.getColumnType(colIndex) != colTypes.getQuick(n)) {\n+                            LOG.error().$(\"mismatched column and value types [table=\").$(writer.getName())\n+                                    .$(\", column=\").$(metadata.getColumnName(colIndex))\n+                                    .$(\", columnType=\").$(ColumnType.nameOf(metadata.getColumnType(colIndex)))\n+                                    .$(\", valueType=\").$(ColumnType.nameOf(colTypes.getQuick(n)))\n+                                    .$(']').$();\n+                            error = true;\n+                            return;\n+                        }\n+                    }\n+                    colIndexMappings.add(n, colIndex);\n+                }\n+            }\n+\n+            private int getColumnType(int i) {\n+                return colTypes.getQuick(i);\n+            }\n+\n+            @Override\n+            public void close() {\n+                if (null != writer) {\n+                    LOG.info().$(name).$(\" closed parser [name=\").$(writer.getName()).$(']').$();\n+                    writer.close();\n+                    writer = null;\n+                }\n+            }\n+\n+        }\n+\n+        private class TableStructureAdapter implements TableStructure {\n+            private LineTcpMeasurementEvent event;\n+            private Parser parser;\n+            private int columnCount;\n+            private int timestampIndex;\n+\n+            @Override\n+            public int getColumnCount() {\n+                return columnCount;\n+            }\n+\n+            @Override\n+            public CharSequence getColumnName(int columnIndex) {\n+                if (columnIndex == getTimestampIndex()) {\n+                    return \"timestamp\";\n+                }\n+                return event.getName(columnIndex);\n+            }\n+\n+            @Override\n+            public int getColumnType(int columnIndex) {\n+                if (columnIndex == getTimestampIndex()) {\n+                    return ColumnType.TIMESTAMP;\n+                }\n+                return parser.getColumnType(columnIndex);\n+            }\n+\n+            @Override\n+            public int getIndexBlockCapacity(int columnIndex) {\n+                return 0;\n+            }\n+\n+            @Override\n+            public boolean isIndexed(int columnIndex) {\n+                return false;\n+            }\n+\n+            @Override\n+            public boolean isSequential(int columnIndex) {\n+                return false;\n+            }\n+\n+            @Override\n+            public int getPartitionBy() {\n+                return PartitionBy.NONE;\n+            }\n+\n+            @Override\n+            public boolean getSymbolCacheFlag(int columnIndex) {\n+                return cairoConfiguration.getDefaultSymbolCacheFlag();\n+            }\n+\n+            @Override\n+            public int getSymbolCapacity(int columnIndex) {\n+                return cairoConfiguration.getDefaultSymbolCapacity();\n+            }\n+\n+            @Override\n+            public CharSequence getTableName() {\n+                return event.getTableName();\n+            }\n+\n+            @Override\n+            public int getTimestampIndex() {\n+                return timestampIndex;\n+            }\n+\n+            TableStructureAdapter of(LineTcpMeasurementEvent event, Parser parser) {\n+                this.event = event;\n+                this.parser = parser;\n+                this.timestampIndex = event.getNValues();\n+                this.columnCount = timestampIndex + 1;\n+                return this;\n+            }\n+        }\n+    }\n+\n+    private static class TableStats {", "originalCommit": "216efe6f6ef6849c83782e9df3d3e498af89f17b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njk0ODM1Nw==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r446948357", "bodyText": "could be a single return statement", "author": "bluestreak01", "createdAt": "2020-06-29T12:54:53Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,745 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableStats> statsByTableName;\n+    private final int[] loadByThread;\n+    // TODO\n+    private final int nUpdatesPerLoadRebalance = 1000;\n+    private final double maxLoadRatio;\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        statsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        maxLoadRatio = 1d + 1d / writerWorkerPool.getWorkerCount();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            do {\n+                nextEventCursor = pubSeq.next();\n+            } while (nextEventCursor == -2);\n+            if (nextEventCursor < 0) {\n+                nextEventCursor = -1;\n+                return null;\n+            }\n+        }\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableStats stats = statsByTableName.get(event.getTableName());\n+        if (null == stats) {\n+            String tableName = event.getTableName().toString();\n+            calcThreadLoad();\n+            int leastLoad = Integer.MAX_VALUE;\n+            int threadId = 0;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] < leastLoad) {\n+                    leastLoad = loadByThread[n];\n+                    threadId = n;\n+                }\n+            }\n+            stats = new TableStats(tableName, threadId);\n+            statsByTableName.put(tableName, stats);\n+            LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+        }\n+        event.threadId = stats.threadId;\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (stats.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = statsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableStats stats = statsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableStats stats = statsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableStats stats = statsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = statsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableStats stats = statsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            statsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {\n+            return errorPosition != -1;\n+        }\n+\n+        int getErrorPosition() {\n+            return errorPosition;\n+        }\n+\n+        int getErrorCode() {\n+            return errorCode;\n+        }\n+\n+        CharSequence getTableName() {\n+            return cache.get(measurementNameAddress);\n+        }\n+\n+        long getTimestamp() {\n+            if (timestampAddress != 0) {\n+                try {\n+                    timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n+                    timestampAddress = 0;\n+                } catch (NumericException e) {\n+                    LOG.info().$(\"invalid timestamp: \").$(cache.get(timestampAddress)).$();\n+                    timestamp = Long.MIN_VALUE;\n+                }\n+            }\n+            return timestamp;\n+        }\n+\n+        CharSequence getName(int i) {\n+            return cache.get(addresses.getQuick(2 * i));\n+        }\n+\n+        int getNValues() {\n+            return addresses.size() / 2;\n+        }\n+\n+        CharSequence getValue(int i) {\n+            return cache.get(addresses.getQuick(2 * i + 1));\n+        }\n+\n+        int getFirstFieldIndex() {\n+            return firstFieldIndex;\n+        }\n+\n+        LineTcpMeasurementEvent createRebalanceEvent(int fromThreadId, int toThreadId, String tableName) {\n+            clear();\n+            threadId = -1;\n+            rebalanceFromThreadId = fromThreadId;\n+            rebalanceToThreadId = toThreadId;\n+            rebalanceTableName = tableName;\n+            return this;\n+        }\n+\n+        boolean isRebalanceEvent() {\n+            return threadId == -1;\n+        }\n+\n+        @Override\n+        public void close() {\n+            lexer.close();\n+            lexer = null;\n+        }\n+    }\n+\n+    private class WriterJob implements Job {\n+        private final int id;\n+        private final Sequence sequence;\n+        private final CharSequenceObjHashMap<Parser> parserCache = new CharSequenceObjHashMap<>();\n+        private final AppendMemory appendMemory = new AppendMemory();\n+        private final Path path = new Path();\n+        private final TableStructureAdapter tableStructureAdapter = new TableStructureAdapter();\n+        private final String name;\n+\n+        private WriterJob(int id, Sequence sequence) {\n+            super();\n+            this.id = id;\n+            this.sequence = sequence;\n+            this.name = \"tcp-line-writer-\" + id;\n+        }\n+\n+        private void close() {\n+            // Finish all jobs in the queue before stopping\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                if (!run(id)) {\n+                    break;\n+                }\n+            }\n+\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0; n < tableNames.size(); n++) {\n+                parserCache.get(tableNames.get(n)).close();\n+            }\n+            parserCache.clear();\n+            appendMemory.close();\n+            path.close();\n+        }\n+\n+        @Override\n+        public boolean run(int workerId) {\n+            assert workerId == id;\n+            try {\n+                long cursor;\n+                while ((cursor = sequence.next()) < 0) {\n+                    if (cursor == -1) {\n+                        return false;\n+                    }\n+                }\n+                LineTcpMeasurementEvent event = queue.get(cursor);\n+                boolean eventProcessed;\n+                try {\n+                    if (event.threadId == id) {\n+                        eventProcessed = processNextEvent(event);\n+                    } else {\n+                        if (event.isRebalanceEvent()) {\n+                            eventProcessed = processRebalance(event);\n+                        } else {\n+                            eventProcessed = true;\n+                        }\n+                    }\n+                } catch (RuntimeException ex) {\n+                    LOG.error().$(ex).$();\n+                    eventProcessed = true;\n+                }\n+                if (eventProcessed) {\n+                    sequence.done(cursor);\n+                }\n+            } catch (RuntimeException ex) {\n+                LOG.error().$(ex).$();\n+            }\n+            return true;\n+        }\n+\n+        private boolean processNextEvent(LineTcpMeasurementEvent event) {\n+            Parser parser = parserCache.get(event.getTableName());\n+            if (null == parser) {\n+                parser = new Parser();\n+                try {\n+                    parser.processFirstEvent(engine, securityContext, event);\n+                } catch (CairoException ex) {\n+                    LOG.info().$(name).$(\" could not create parser [name=\").$(event.getTableName()).$(\", ex=\").$(ex.getFlyweightMessage()).$(']').$();\n+                    parser.close();\n+                    return false;\n+                }\n+                LOG.info().$(name).$(\" created parser [name=\").$(event.getTableName()).$(']').$();\n+                parserCache.put(event.getTableName().toString(), parser);\n+                return true;\n+            } else {\n+                parser.processEvent(event);\n+                return true;\n+            }\n+        }\n+\n+        private boolean processRebalance(LineTcpMeasurementEvent event) {\n+            if (event.rebalanceToThreadId == id) {\n+                if (!event.rebalanceReleasedByFromThread) {\n+                    return false;\n+                }\n+\n+                return true;", "originalCommit": "216efe6f6ef6849c83782e9df3d3e498af89f17b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njk0ODY1Nw==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r446948657", "bodyText": "return is unnecessary", "author": "bluestreak01", "createdAt": "2020-06-29T12:55:20Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,745 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableStats> statsByTableName;\n+    private final int[] loadByThread;\n+    // TODO\n+    private final int nUpdatesPerLoadRebalance = 1000;\n+    private final double maxLoadRatio;\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        statsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        maxLoadRatio = 1d + 1d / writerWorkerPool.getWorkerCount();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            do {\n+                nextEventCursor = pubSeq.next();\n+            } while (nextEventCursor == -2);\n+            if (nextEventCursor < 0) {\n+                nextEventCursor = -1;\n+                return null;\n+            }\n+        }\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableStats stats = statsByTableName.get(event.getTableName());\n+        if (null == stats) {\n+            String tableName = event.getTableName().toString();\n+            calcThreadLoad();\n+            int leastLoad = Integer.MAX_VALUE;\n+            int threadId = 0;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] < leastLoad) {\n+                    leastLoad = loadByThread[n];\n+                    threadId = n;\n+                }\n+            }\n+            stats = new TableStats(tableName, threadId);\n+            statsByTableName.put(tableName, stats);\n+            LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+        }\n+        event.threadId = stats.threadId;\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (stats.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = statsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableStats stats = statsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableStats stats = statsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableStats stats = statsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = statsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableStats stats = statsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            statsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {\n+            return errorPosition != -1;\n+        }\n+\n+        int getErrorPosition() {\n+            return errorPosition;\n+        }\n+\n+        int getErrorCode() {\n+            return errorCode;\n+        }\n+\n+        CharSequence getTableName() {\n+            return cache.get(measurementNameAddress);\n+        }\n+\n+        long getTimestamp() {\n+            if (timestampAddress != 0) {\n+                try {\n+                    timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n+                    timestampAddress = 0;\n+                } catch (NumericException e) {\n+                    LOG.info().$(\"invalid timestamp: \").$(cache.get(timestampAddress)).$();\n+                    timestamp = Long.MIN_VALUE;\n+                }\n+            }\n+            return timestamp;\n+        }\n+\n+        CharSequence getName(int i) {\n+            return cache.get(addresses.getQuick(2 * i));\n+        }\n+\n+        int getNValues() {\n+            return addresses.size() / 2;\n+        }\n+\n+        CharSequence getValue(int i) {\n+            return cache.get(addresses.getQuick(2 * i + 1));\n+        }\n+\n+        int getFirstFieldIndex() {\n+            return firstFieldIndex;\n+        }\n+\n+        LineTcpMeasurementEvent createRebalanceEvent(int fromThreadId, int toThreadId, String tableName) {\n+            clear();\n+            threadId = -1;\n+            rebalanceFromThreadId = fromThreadId;\n+            rebalanceToThreadId = toThreadId;\n+            rebalanceTableName = tableName;\n+            return this;\n+        }\n+\n+        boolean isRebalanceEvent() {\n+            return threadId == -1;\n+        }\n+\n+        @Override\n+        public void close() {\n+            lexer.close();\n+            lexer = null;\n+        }\n+    }\n+\n+    private class WriterJob implements Job {\n+        private final int id;\n+        private final Sequence sequence;\n+        private final CharSequenceObjHashMap<Parser> parserCache = new CharSequenceObjHashMap<>();\n+        private final AppendMemory appendMemory = new AppendMemory();\n+        private final Path path = new Path();\n+        private final TableStructureAdapter tableStructureAdapter = new TableStructureAdapter();\n+        private final String name;\n+\n+        private WriterJob(int id, Sequence sequence) {\n+            super();\n+            this.id = id;\n+            this.sequence = sequence;\n+            this.name = \"tcp-line-writer-\" + id;\n+        }\n+\n+        private void close() {\n+            // Finish all jobs in the queue before stopping\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                if (!run(id)) {\n+                    break;\n+                }\n+            }\n+\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0; n < tableNames.size(); n++) {\n+                parserCache.get(tableNames.get(n)).close();\n+            }\n+            parserCache.clear();\n+            appendMemory.close();\n+            path.close();\n+        }\n+\n+        @Override\n+        public boolean run(int workerId) {\n+            assert workerId == id;\n+            try {\n+                long cursor;\n+                while ((cursor = sequence.next()) < 0) {\n+                    if (cursor == -1) {\n+                        return false;\n+                    }\n+                }\n+                LineTcpMeasurementEvent event = queue.get(cursor);\n+                boolean eventProcessed;\n+                try {\n+                    if (event.threadId == id) {\n+                        eventProcessed = processNextEvent(event);\n+                    } else {\n+                        if (event.isRebalanceEvent()) {\n+                            eventProcessed = processRebalance(event);\n+                        } else {\n+                            eventProcessed = true;\n+                        }\n+                    }\n+                } catch (RuntimeException ex) {\n+                    LOG.error().$(ex).$();\n+                    eventProcessed = true;\n+                }\n+                if (eventProcessed) {\n+                    sequence.done(cursor);\n+                }\n+            } catch (RuntimeException ex) {\n+                LOG.error().$(ex).$();\n+            }\n+            return true;\n+        }\n+\n+        private boolean processNextEvent(LineTcpMeasurementEvent event) {\n+            Parser parser = parserCache.get(event.getTableName());\n+            if (null == parser) {\n+                parser = new Parser();\n+                try {\n+                    parser.processFirstEvent(engine, securityContext, event);\n+                } catch (CairoException ex) {\n+                    LOG.info().$(name).$(\" could not create parser [name=\").$(event.getTableName()).$(\", ex=\").$(ex.getFlyweightMessage()).$(']').$();\n+                    parser.close();\n+                    return false;\n+                }\n+                LOG.info().$(name).$(\" created parser [name=\").$(event.getTableName()).$(']').$();\n+                parserCache.put(event.getTableName().toString(), parser);\n+                return true;\n+            } else {\n+                parser.processEvent(event);\n+                return true;\n+            }\n+        }\n+\n+        private boolean processRebalance(LineTcpMeasurementEvent event) {\n+            if (event.rebalanceToThreadId == id) {\n+                if (!event.rebalanceReleasedByFromThread) {\n+                    return false;\n+                }\n+\n+                return true;\n+            }\n+\n+            if (event.rebalanceFromThreadId == id) {\n+                Parser parser = parserCache.get(event.rebalanceTableName);\n+                parserCache.remove(event.rebalanceTableName);\n+                parser.close();\n+                event.rebalanceReleasedByFromThread = true;\n+                return true;", "originalCommit": "216efe6f6ef6849c83782e9df3d3e498af89f17b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njk5MTM0Ng==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r446991346", "bodyText": "Locking up queue element for so long is not great. The job has to be able to parse the event into its own, thread-local state. Then copy the state onto queue as quickly as possible. This will also deal with the situation when queue being full in a localized way.", "author": "bluestreak01", "createdAt": "2020-06-29T13:56:52Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpConnectionContext.java", "diffHunk": "@@ -0,0 +1,148 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import io.questdb.cutlass.line.tcp.LineTcpMeasurementScheduler.LineTcpMeasurementEvent;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.network.IOContext;\n+import io.questdb.network.IODispatcher;\n+import io.questdb.network.IOOperation;\n+import io.questdb.network.NetworkFacade;\n+import io.questdb.std.Mutable;\n+import io.questdb.std.Unsafe;\n+import io.questdb.std.str.DirectByteCharSequence;\n+\n+class LineTcpConnectionContext implements IOContext, Mutable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpConnectionContext.class);\n+    private final NetworkFacade nf;\n+    private final LineTcpMeasurementScheduler scheduler;\n+    private long fd;\n+    private IODispatcher<LineTcpConnectionContext> dispatcher;\n+    private long recvBufStart;\n+    private long recvBufEnd;\n+    private long recvBufPos;\n+    private boolean peerDisconnected;\n+    private final DirectByteCharSequence byteCharSequence = new DirectByteCharSequence();\n+\n+    LineTcpConnectionContext(LineTcpReceiverConfiguration configuration, LineTcpMeasurementScheduler scheduler) {\n+        nf = configuration.getNetworkFacade();\n+        this.scheduler = scheduler;\n+        recvBufStart = Unsafe.malloc(configuration.getNetMsgBufferSize());\n+        recvBufEnd = recvBufStart + configuration.getNetMsgBufferSize();\n+    }\n+\n+    // returns true if busy\n+    boolean handleIO() {\n+        try {\n+            LineTcpMeasurementEvent event = scheduler.getNewEvent();", "originalCommit": "216efe6f6ef6849c83782e9df3d3e498af89f17b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY0MTI2MQ==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r447641261", "bodyText": "There is a trade off here, we can either always commit the queue state quickly (within one call to handelO()) or propagate our waiting state back to the TCP peer producer by not reading from the TCP socket. Since the Sequence  implementation is for a single producer, holding onto the sequence cursor for long has no bad effects.", "author": "patrickSpaceSurfer", "createdAt": "2020-06-30T12:24:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njk5MTM0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzAwMDI0MA==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r447000240", "bodyText": "it looks like parser can boil down to the map of table writers. Parser state is transient for the row of data and can be part of the WriterJob", "author": "bluestreak01", "createdAt": "2020-06-29T14:09:10Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,745 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableStats> statsByTableName;\n+    private final int[] loadByThread;\n+    // TODO\n+    private final int nUpdatesPerLoadRebalance = 1000;\n+    private final double maxLoadRatio;\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        statsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        maxLoadRatio = 1d + 1d / writerWorkerPool.getWorkerCount();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            do {\n+                nextEventCursor = pubSeq.next();\n+            } while (nextEventCursor == -2);\n+            if (nextEventCursor < 0) {\n+                nextEventCursor = -1;\n+                return null;\n+            }\n+        }\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableStats stats = statsByTableName.get(event.getTableName());\n+        if (null == stats) {\n+            String tableName = event.getTableName().toString();\n+            calcThreadLoad();\n+            int leastLoad = Integer.MAX_VALUE;\n+            int threadId = 0;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] < leastLoad) {\n+                    leastLoad = loadByThread[n];\n+                    threadId = n;\n+                }\n+            }\n+            stats = new TableStats(tableName, threadId);\n+            statsByTableName.put(tableName, stats);\n+            LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+        }\n+        event.threadId = stats.threadId;\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (stats.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = statsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableStats stats = statsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableStats stats = statsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableStats stats = statsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = statsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableStats stats = statsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            statsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {\n+            return errorPosition != -1;\n+        }\n+\n+        int getErrorPosition() {\n+            return errorPosition;\n+        }\n+\n+        int getErrorCode() {\n+            return errorCode;\n+        }\n+\n+        CharSequence getTableName() {\n+            return cache.get(measurementNameAddress);\n+        }\n+\n+        long getTimestamp() {\n+            if (timestampAddress != 0) {\n+                try {\n+                    timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n+                    timestampAddress = 0;\n+                } catch (NumericException e) {\n+                    LOG.info().$(\"invalid timestamp: \").$(cache.get(timestampAddress)).$();\n+                    timestamp = Long.MIN_VALUE;\n+                }\n+            }\n+            return timestamp;\n+        }\n+\n+        CharSequence getName(int i) {\n+            return cache.get(addresses.getQuick(2 * i));\n+        }\n+\n+        int getNValues() {\n+            return addresses.size() / 2;\n+        }\n+\n+        CharSequence getValue(int i) {\n+            return cache.get(addresses.getQuick(2 * i + 1));\n+        }\n+\n+        int getFirstFieldIndex() {\n+            return firstFieldIndex;\n+        }\n+\n+        LineTcpMeasurementEvent createRebalanceEvent(int fromThreadId, int toThreadId, String tableName) {\n+            clear();\n+            threadId = -1;\n+            rebalanceFromThreadId = fromThreadId;\n+            rebalanceToThreadId = toThreadId;\n+            rebalanceTableName = tableName;\n+            return this;\n+        }\n+\n+        boolean isRebalanceEvent() {\n+            return threadId == -1;\n+        }\n+\n+        @Override\n+        public void close() {\n+            lexer.close();\n+            lexer = null;\n+        }\n+    }\n+\n+    private class WriterJob implements Job {\n+        private final int id;\n+        private final Sequence sequence;\n+        private final CharSequenceObjHashMap<Parser> parserCache = new CharSequenceObjHashMap<>();\n+        private final AppendMemory appendMemory = new AppendMemory();\n+        private final Path path = new Path();\n+        private final TableStructureAdapter tableStructureAdapter = new TableStructureAdapter();\n+        private final String name;\n+\n+        private WriterJob(int id, Sequence sequence) {\n+            super();\n+            this.id = id;\n+            this.sequence = sequence;\n+            this.name = \"tcp-line-writer-\" + id;\n+        }\n+\n+        private void close() {\n+            // Finish all jobs in the queue before stopping\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                if (!run(id)) {\n+                    break;\n+                }\n+            }\n+\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0; n < tableNames.size(); n++) {\n+                parserCache.get(tableNames.get(n)).close();\n+            }\n+            parserCache.clear();\n+            appendMemory.close();\n+            path.close();\n+        }\n+\n+        @Override\n+        public boolean run(int workerId) {\n+            assert workerId == id;\n+            try {\n+                long cursor;\n+                while ((cursor = sequence.next()) < 0) {\n+                    if (cursor == -1) {\n+                        return false;\n+                    }\n+                }\n+                LineTcpMeasurementEvent event = queue.get(cursor);\n+                boolean eventProcessed;\n+                try {\n+                    if (event.threadId == id) {\n+                        eventProcessed = processNextEvent(event);\n+                    } else {\n+                        if (event.isRebalanceEvent()) {\n+                            eventProcessed = processRebalance(event);\n+                        } else {\n+                            eventProcessed = true;\n+                        }\n+                    }\n+                } catch (RuntimeException ex) {\n+                    LOG.error().$(ex).$();\n+                    eventProcessed = true;\n+                }\n+                if (eventProcessed) {\n+                    sequence.done(cursor);\n+                }\n+            } catch (RuntimeException ex) {\n+                LOG.error().$(ex).$();\n+            }\n+            return true;\n+        }\n+\n+        private boolean processNextEvent(LineTcpMeasurementEvent event) {\n+            Parser parser = parserCache.get(event.getTableName());\n+            if (null == parser) {\n+                parser = new Parser();\n+                try {\n+                    parser.processFirstEvent(engine, securityContext, event);\n+                } catch (CairoException ex) {\n+                    LOG.info().$(name).$(\" could not create parser [name=\").$(event.getTableName()).$(\", ex=\").$(ex.getFlyweightMessage()).$(']').$();\n+                    parser.close();\n+                    return false;\n+                }\n+                LOG.info().$(name).$(\" created parser [name=\").$(event.getTableName()).$(']').$();\n+                parserCache.put(event.getTableName().toString(), parser);\n+                return true;\n+            } else {\n+                parser.processEvent(event);\n+                return true;\n+            }\n+        }\n+\n+        private boolean processRebalance(LineTcpMeasurementEvent event) {\n+            if (event.rebalanceToThreadId == id) {\n+                if (!event.rebalanceReleasedByFromThread) {\n+                    return false;\n+                }\n+\n+                return true;\n+            }\n+\n+            if (event.rebalanceFromThreadId == id) {\n+                Parser parser = parserCache.get(event.rebalanceTableName);\n+                parserCache.remove(event.rebalanceTableName);\n+                parser.close();\n+                event.rebalanceReleasedByFromThread = true;\n+                return true;\n+            }\n+\n+            return true;\n+        }\n+\n+        private class Parser implements Closeable {\n+            private TableWriter writer;", "originalCommit": "216efe6f6ef6849c83782e9df3d3e498af89f17b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzAwMTM5NA==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r447001394", "bodyText": "commit() rate should be configurable to avoid committing every row. Commit can definitely be done when either X rows reached or queue becomes empty", "author": "bluestreak01", "createdAt": "2020-06-29T14:10:46Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,745 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableStats> statsByTableName;\n+    private final int[] loadByThread;\n+    // TODO\n+    private final int nUpdatesPerLoadRebalance = 1000;\n+    private final double maxLoadRatio;\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        statsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        maxLoadRatio = 1d + 1d / writerWorkerPool.getWorkerCount();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            do {\n+                nextEventCursor = pubSeq.next();\n+            } while (nextEventCursor == -2);\n+            if (nextEventCursor < 0) {\n+                nextEventCursor = -1;\n+                return null;\n+            }\n+        }\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableStats stats = statsByTableName.get(event.getTableName());\n+        if (null == stats) {\n+            String tableName = event.getTableName().toString();\n+            calcThreadLoad();\n+            int leastLoad = Integer.MAX_VALUE;\n+            int threadId = 0;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] < leastLoad) {\n+                    leastLoad = loadByThread[n];\n+                    threadId = n;\n+                }\n+            }\n+            stats = new TableStats(tableName, threadId);\n+            statsByTableName.put(tableName, stats);\n+            LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+        }\n+        event.threadId = stats.threadId;\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (stats.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = statsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableStats stats = statsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableStats stats = statsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableStats stats = statsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = statsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableStats stats = statsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            statsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {\n+            return errorPosition != -1;\n+        }\n+\n+        int getErrorPosition() {\n+            return errorPosition;\n+        }\n+\n+        int getErrorCode() {\n+            return errorCode;\n+        }\n+\n+        CharSequence getTableName() {\n+            return cache.get(measurementNameAddress);\n+        }\n+\n+        long getTimestamp() {\n+            if (timestampAddress != 0) {\n+                try {\n+                    timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n+                    timestampAddress = 0;\n+                } catch (NumericException e) {\n+                    LOG.info().$(\"invalid timestamp: \").$(cache.get(timestampAddress)).$();\n+                    timestamp = Long.MIN_VALUE;\n+                }\n+            }\n+            return timestamp;\n+        }\n+\n+        CharSequence getName(int i) {\n+            return cache.get(addresses.getQuick(2 * i));\n+        }\n+\n+        int getNValues() {\n+            return addresses.size() / 2;\n+        }\n+\n+        CharSequence getValue(int i) {\n+            return cache.get(addresses.getQuick(2 * i + 1));\n+        }\n+\n+        int getFirstFieldIndex() {\n+            return firstFieldIndex;\n+        }\n+\n+        LineTcpMeasurementEvent createRebalanceEvent(int fromThreadId, int toThreadId, String tableName) {\n+            clear();\n+            threadId = -1;\n+            rebalanceFromThreadId = fromThreadId;\n+            rebalanceToThreadId = toThreadId;\n+            rebalanceTableName = tableName;\n+            return this;\n+        }\n+\n+        boolean isRebalanceEvent() {\n+            return threadId == -1;\n+        }\n+\n+        @Override\n+        public void close() {\n+            lexer.close();\n+            lexer = null;\n+        }\n+    }\n+\n+    private class WriterJob implements Job {\n+        private final int id;\n+        private final Sequence sequence;\n+        private final CharSequenceObjHashMap<Parser> parserCache = new CharSequenceObjHashMap<>();\n+        private final AppendMemory appendMemory = new AppendMemory();\n+        private final Path path = new Path();\n+        private final TableStructureAdapter tableStructureAdapter = new TableStructureAdapter();\n+        private final String name;\n+\n+        private WriterJob(int id, Sequence sequence) {\n+            super();\n+            this.id = id;\n+            this.sequence = sequence;\n+            this.name = \"tcp-line-writer-\" + id;\n+        }\n+\n+        private void close() {\n+            // Finish all jobs in the queue before stopping\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                if (!run(id)) {\n+                    break;\n+                }\n+            }\n+\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0; n < tableNames.size(); n++) {\n+                parserCache.get(tableNames.get(n)).close();\n+            }\n+            parserCache.clear();\n+            appendMemory.close();\n+            path.close();\n+        }\n+\n+        @Override\n+        public boolean run(int workerId) {\n+            assert workerId == id;\n+            try {\n+                long cursor;\n+                while ((cursor = sequence.next()) < 0) {\n+                    if (cursor == -1) {\n+                        return false;\n+                    }\n+                }\n+                LineTcpMeasurementEvent event = queue.get(cursor);\n+                boolean eventProcessed;\n+                try {\n+                    if (event.threadId == id) {\n+                        eventProcessed = processNextEvent(event);\n+                    } else {\n+                        if (event.isRebalanceEvent()) {\n+                            eventProcessed = processRebalance(event);\n+                        } else {\n+                            eventProcessed = true;\n+                        }\n+                    }\n+                } catch (RuntimeException ex) {\n+                    LOG.error().$(ex).$();\n+                    eventProcessed = true;\n+                }\n+                if (eventProcessed) {\n+                    sequence.done(cursor);\n+                }\n+            } catch (RuntimeException ex) {\n+                LOG.error().$(ex).$();\n+            }\n+            return true;\n+        }\n+\n+        private boolean processNextEvent(LineTcpMeasurementEvent event) {\n+            Parser parser = parserCache.get(event.getTableName());\n+            if (null == parser) {\n+                parser = new Parser();\n+                try {\n+                    parser.processFirstEvent(engine, securityContext, event);\n+                } catch (CairoException ex) {\n+                    LOG.info().$(name).$(\" could not create parser [name=\").$(event.getTableName()).$(\", ex=\").$(ex.getFlyweightMessage()).$(']').$();\n+                    parser.close();\n+                    return false;\n+                }\n+                LOG.info().$(name).$(\" created parser [name=\").$(event.getTableName()).$(']').$();\n+                parserCache.put(event.getTableName().toString(), parser);\n+                return true;\n+            } else {\n+                parser.processEvent(event);\n+                return true;\n+            }\n+        }\n+\n+        private boolean processRebalance(LineTcpMeasurementEvent event) {\n+            if (event.rebalanceToThreadId == id) {\n+                if (!event.rebalanceReleasedByFromThread) {\n+                    return false;\n+                }\n+\n+                return true;\n+            }\n+\n+            if (event.rebalanceFromThreadId == id) {\n+                Parser parser = parserCache.get(event.rebalanceTableName);\n+                parserCache.remove(event.rebalanceTableName);\n+                parser.close();\n+                event.rebalanceReleasedByFromThread = true;\n+                return true;\n+            }\n+\n+            return true;\n+        }\n+\n+        private class Parser implements Closeable {\n+            private TableWriter writer;\n+            private final IntList colTypes = new IntList();\n+            private final IntList colIndexMappings = new IntList();\n+\n+            private transient int nMeasurementValues;\n+            private transient boolean error;\n+\n+            private void processFirstEvent(CairoEngine engine, CairoSecurityContext securityContext, LineTcpMeasurementEvent event) {\n+                assert null == writer;\n+                int status = engine.getStatus(securityContext, path, event.getTableName(), 0, event.getTableName().length());\n+                if (status == TableUtils.TABLE_EXISTS) {\n+                    writer = engine.getWriter(securityContext, event.getTableName());\n+                    processEvent(event);\n+                    return;\n+                }\n+\n+                preprocessEvent(event);\n+                engine.creatTable(\n+                        securityContext,\n+                        appendMemory,\n+                        path,\n+                        tableStructureAdapter.of(event, this));\n+                int nValues = event.getNValues();\n+                for (int n = 0; n < nValues; n++) {\n+                    colIndexMappings.add(n, n);\n+                }\n+                writer = engine.getWriter(securityContext, event.getTableName());\n+                addRow(event);\n+            }\n+\n+            private void processEvent(LineTcpMeasurementEvent event) {\n+                assert event.getTableName().equals(writer.getName());\n+                preprocessEvent(event);\n+                parseNames(event);\n+                addRow(event);\n+            }\n+\n+            private void addRow(LineTcpMeasurementEvent event) {\n+                if (error) {\n+                    return;\n+                }\n+                long timestamp = event.getTimestamp();\n+                Row row = writer.newRow(timestamp);\n+                try {\n+                    for (int i = 0; i < nMeasurementValues; i++) {\n+                        int columnType = colTypes.getQuick(i);\n+                        int columnIndex = colIndexMappings.getQuick(i);\n+                        CairoLineProtoParserSupport.writers.getQuick(columnType).write(row, columnIndex, event.getValue(i));\n+                    }\n+                    row.append();\n+                } catch (BadCastException ignore) {\n+                    row.cancel();\n+                }\n+                writer.commit();", "originalCommit": "216efe6f6ef6849c83782e9df3d3e498af89f17b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzAwMTYzNQ==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r447001635", "bodyText": "we also need to cancel row on CairoException", "author": "bluestreak01", "createdAt": "2020-06-29T14:11:06Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,745 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableStats> statsByTableName;\n+    private final int[] loadByThread;\n+    // TODO\n+    private final int nUpdatesPerLoadRebalance = 1000;\n+    private final double maxLoadRatio;\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        statsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        maxLoadRatio = 1d + 1d / writerWorkerPool.getWorkerCount();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            do {\n+                nextEventCursor = pubSeq.next();\n+            } while (nextEventCursor == -2);\n+            if (nextEventCursor < 0) {\n+                nextEventCursor = -1;\n+                return null;\n+            }\n+        }\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableStats stats = statsByTableName.get(event.getTableName());\n+        if (null == stats) {\n+            String tableName = event.getTableName().toString();\n+            calcThreadLoad();\n+            int leastLoad = Integer.MAX_VALUE;\n+            int threadId = 0;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] < leastLoad) {\n+                    leastLoad = loadByThread[n];\n+                    threadId = n;\n+                }\n+            }\n+            stats = new TableStats(tableName, threadId);\n+            statsByTableName.put(tableName, stats);\n+            LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+        }\n+        event.threadId = stats.threadId;\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (stats.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = statsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableStats stats = statsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableStats stats = statsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableStats stats = statsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = statsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableStats stats = statsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            statsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {\n+            return errorPosition != -1;\n+        }\n+\n+        int getErrorPosition() {\n+            return errorPosition;\n+        }\n+\n+        int getErrorCode() {\n+            return errorCode;\n+        }\n+\n+        CharSequence getTableName() {\n+            return cache.get(measurementNameAddress);\n+        }\n+\n+        long getTimestamp() {\n+            if (timestampAddress != 0) {\n+                try {\n+                    timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n+                    timestampAddress = 0;\n+                } catch (NumericException e) {\n+                    LOG.info().$(\"invalid timestamp: \").$(cache.get(timestampAddress)).$();\n+                    timestamp = Long.MIN_VALUE;\n+                }\n+            }\n+            return timestamp;\n+        }\n+\n+        CharSequence getName(int i) {\n+            return cache.get(addresses.getQuick(2 * i));\n+        }\n+\n+        int getNValues() {\n+            return addresses.size() / 2;\n+        }\n+\n+        CharSequence getValue(int i) {\n+            return cache.get(addresses.getQuick(2 * i + 1));\n+        }\n+\n+        int getFirstFieldIndex() {\n+            return firstFieldIndex;\n+        }\n+\n+        LineTcpMeasurementEvent createRebalanceEvent(int fromThreadId, int toThreadId, String tableName) {\n+            clear();\n+            threadId = -1;\n+            rebalanceFromThreadId = fromThreadId;\n+            rebalanceToThreadId = toThreadId;\n+            rebalanceTableName = tableName;\n+            return this;\n+        }\n+\n+        boolean isRebalanceEvent() {\n+            return threadId == -1;\n+        }\n+\n+        @Override\n+        public void close() {\n+            lexer.close();\n+            lexer = null;\n+        }\n+    }\n+\n+    private class WriterJob implements Job {\n+        private final int id;\n+        private final Sequence sequence;\n+        private final CharSequenceObjHashMap<Parser> parserCache = new CharSequenceObjHashMap<>();\n+        private final AppendMemory appendMemory = new AppendMemory();\n+        private final Path path = new Path();\n+        private final TableStructureAdapter tableStructureAdapter = new TableStructureAdapter();\n+        private final String name;\n+\n+        private WriterJob(int id, Sequence sequence) {\n+            super();\n+            this.id = id;\n+            this.sequence = sequence;\n+            this.name = \"tcp-line-writer-\" + id;\n+        }\n+\n+        private void close() {\n+            // Finish all jobs in the queue before stopping\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                if (!run(id)) {\n+                    break;\n+                }\n+            }\n+\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0; n < tableNames.size(); n++) {\n+                parserCache.get(tableNames.get(n)).close();\n+            }\n+            parserCache.clear();\n+            appendMemory.close();\n+            path.close();\n+        }\n+\n+        @Override\n+        public boolean run(int workerId) {\n+            assert workerId == id;\n+            try {\n+                long cursor;\n+                while ((cursor = sequence.next()) < 0) {\n+                    if (cursor == -1) {\n+                        return false;\n+                    }\n+                }\n+                LineTcpMeasurementEvent event = queue.get(cursor);\n+                boolean eventProcessed;\n+                try {\n+                    if (event.threadId == id) {\n+                        eventProcessed = processNextEvent(event);\n+                    } else {\n+                        if (event.isRebalanceEvent()) {\n+                            eventProcessed = processRebalance(event);\n+                        } else {\n+                            eventProcessed = true;\n+                        }\n+                    }\n+                } catch (RuntimeException ex) {\n+                    LOG.error().$(ex).$();\n+                    eventProcessed = true;\n+                }\n+                if (eventProcessed) {\n+                    sequence.done(cursor);\n+                }\n+            } catch (RuntimeException ex) {\n+                LOG.error().$(ex).$();\n+            }\n+            return true;\n+        }\n+\n+        private boolean processNextEvent(LineTcpMeasurementEvent event) {\n+            Parser parser = parserCache.get(event.getTableName());\n+            if (null == parser) {\n+                parser = new Parser();\n+                try {\n+                    parser.processFirstEvent(engine, securityContext, event);\n+                } catch (CairoException ex) {\n+                    LOG.info().$(name).$(\" could not create parser [name=\").$(event.getTableName()).$(\", ex=\").$(ex.getFlyweightMessage()).$(']').$();\n+                    parser.close();\n+                    return false;\n+                }\n+                LOG.info().$(name).$(\" created parser [name=\").$(event.getTableName()).$(']').$();\n+                parserCache.put(event.getTableName().toString(), parser);\n+                return true;\n+            } else {\n+                parser.processEvent(event);\n+                return true;\n+            }\n+        }\n+\n+        private boolean processRebalance(LineTcpMeasurementEvent event) {\n+            if (event.rebalanceToThreadId == id) {\n+                if (!event.rebalanceReleasedByFromThread) {\n+                    return false;\n+                }\n+\n+                return true;\n+            }\n+\n+            if (event.rebalanceFromThreadId == id) {\n+                Parser parser = parserCache.get(event.rebalanceTableName);\n+                parserCache.remove(event.rebalanceTableName);\n+                parser.close();\n+                event.rebalanceReleasedByFromThread = true;\n+                return true;\n+            }\n+\n+            return true;\n+        }\n+\n+        private class Parser implements Closeable {\n+            private TableWriter writer;\n+            private final IntList colTypes = new IntList();\n+            private final IntList colIndexMappings = new IntList();\n+\n+            private transient int nMeasurementValues;\n+            private transient boolean error;\n+\n+            private void processFirstEvent(CairoEngine engine, CairoSecurityContext securityContext, LineTcpMeasurementEvent event) {\n+                assert null == writer;\n+                int status = engine.getStatus(securityContext, path, event.getTableName(), 0, event.getTableName().length());\n+                if (status == TableUtils.TABLE_EXISTS) {\n+                    writer = engine.getWriter(securityContext, event.getTableName());\n+                    processEvent(event);\n+                    return;\n+                }\n+\n+                preprocessEvent(event);\n+                engine.creatTable(\n+                        securityContext,\n+                        appendMemory,\n+                        path,\n+                        tableStructureAdapter.of(event, this));\n+                int nValues = event.getNValues();\n+                for (int n = 0; n < nValues; n++) {\n+                    colIndexMappings.add(n, n);\n+                }\n+                writer = engine.getWriter(securityContext, event.getTableName());\n+                addRow(event);\n+            }\n+\n+            private void processEvent(LineTcpMeasurementEvent event) {\n+                assert event.getTableName().equals(writer.getName());\n+                preprocessEvent(event);\n+                parseNames(event);\n+                addRow(event);\n+            }\n+\n+            private void addRow(LineTcpMeasurementEvent event) {\n+                if (error) {\n+                    return;\n+                }\n+                long timestamp = event.getTimestamp();\n+                Row row = writer.newRow(timestamp);\n+                try {\n+                    for (int i = 0; i < nMeasurementValues; i++) {\n+                        int columnType = colTypes.getQuick(i);\n+                        int columnIndex = colIndexMappings.getQuick(i);\n+                        CairoLineProtoParserSupport.writers.getQuick(columnType).write(row, columnIndex, event.getValue(i));\n+                    }\n+                    row.append();\n+                } catch (BadCastException ignore) {", "originalCommit": "216efe6f6ef6849c83782e9df3d3e498af89f17b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "51bb90d218b0b843ff671f5410836fb822833e73", "url": "https://github.com/questdb/questdb/commit/51bb90d218b0b843ff671f5410836fb822833e73", "message": "chore: Create LineTCPSenderMain benchmark", "committedDate": "2020-06-30T12:00:47Z", "type": "commit"}, {"oid": "e3452b15d99990624cd6adc89193dde71cfce0d3", "url": "https://github.com/questdb/questdb/commit/e3452b15d99990624cd6adc89193dde71cfce0d3", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-06-30T12:28:41Z", "type": "commit"}, {"oid": "4da1dee8c65869f3c7cc612c5c825a733ee38f9f", "url": "https://github.com/questdb/questdb/commit/4da1dee8c65869f3c7cc612c5c825a733ee38f9f", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-06-30T12:43:31Z", "type": "commit"}, {"oid": "37e77a3ec71f88d0766c4f6010dab4b8ccd09066", "url": "https://github.com/questdb/questdb/commit/37e77a3ec71f88d0766c4f6010dab4b8ccd09066", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-06-30T14:02:47Z", "type": "commit"}, {"oid": "c5b3609592c1a8027d75382d1b2d5246557dc0e1", "url": "https://github.com/questdb/questdb/commit/c5b3609592c1a8027d75382d1b2d5246557dc0e1", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-01T10:21:34Z", "type": "commit"}, {"oid": "7195d602b56edb80b5417bd316bb4ecb44a1925e", "url": "https://github.com/questdb/questdb/commit/7195d602b56edb80b5417bd316bb4ecb44a1925e", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-01T10:41:19Z", "type": "commit"}, {"oid": "0f39e159e090833b01ba11b9eaa1ed6cf2f13b1e", "url": "https://github.com/questdb/questdb/commit/0f39e159e090833b01ba11b9eaa1ed6cf2f13b1e", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-01T13:23:35Z", "type": "commit"}, {"oid": "2a8db1080a2f129b1fef81713f5fbdb45f41802e", "url": "https://github.com/questdb/questdb/commit/2a8db1080a2f129b1fef81713f5fbdb45f41802e", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-01T13:39:04Z", "type": "commit"}, {"oid": "b13b945253cdadd139b7fb56c5a9404652511687", "url": "https://github.com/questdb/questdb/commit/b13b945253cdadd139b7fb56c5a9404652511687", "message": "chore: Create LineTCPSenderMain benchmark", "committedDate": "2020-07-01T13:39:28Z", "type": "commit"}, {"oid": "28efc299dea57a715a3b72defbe8f2bc75c6d3f5", "url": "https://github.com/questdb/questdb/commit/28efc299dea57a715a3b72defbe8f2bc75c6d3f5", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-01T14:34:47Z", "type": "commit"}, {"oid": "23103b296e04c7d637539f6da343d6207ce401cb", "url": "https://github.com/questdb/questdb/commit/23103b296e04c7d637539f6da343d6207ce401cb", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-01T14:56:51Z", "type": "commit"}, {"oid": "560fa8f8302a5ec05c315ec9e363fde1c5a2529b", "url": "https://github.com/questdb/questdb/commit/560fa8f8302a5ec05c315ec9e363fde1c5a2529b", "message": "Merge remote-tracking branch 'origin/master' into tcp-line", "committedDate": "2020-07-01T15:04:40Z", "type": "commit"}, {"oid": "026b8e7c6aaf31bc3887103eebc323a38b432871", "url": "https://github.com/questdb/questdb/commit/026b8e7c6aaf31bc3887103eebc323a38b432871", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-01T18:22:38Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODY0NjExMA==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448646110", "bodyText": "This is a little bit of rock'n'roll style server inclusion :)\nWe should do this orderly:\n\ncreate an instance if configuration enables one\ndispose of the instance when server shuts down", "author": "bluestreak01", "createdAt": "2020-07-01T22:21:57Z", "path": "core/src/main/java/io/questdb/ServerMain.java", "diffHunk": "@@ -187,6 +204,7 @@ public static void main(String[] args) throws Exception {\n                 );\n             }\n \n+            LineTcpServer.create(configuration.getCairoConfiguration(), configuration.getLineTcpReceiverConfiguration(), workerPool, log, cairoEngine, messageBus);", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkxODEyMw==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448918123", "bodyText": "this is a defunct pool, how does this work?", "author": "bluestreak01", "createdAt": "2020-07-02T10:53:47Z", "path": "core/src/main/java/io/questdb/WorkerPoolAwareConfiguration.java", "diffHunk": "@@ -24,16 +24,39 @@\n \n package io.questdb;\n \n+import java.io.Closeable;\n+\n+import org.jetbrains.annotations.Nullable;\n+\n import io.questdb.cairo.CairoEngine;\n import io.questdb.griffin.FunctionFactoryCache;\n import io.questdb.log.Log;\n import io.questdb.mp.WorkerPool;\n import io.questdb.mp.WorkerPoolConfiguration;\n-import org.jetbrains.annotations.Nullable;\n-\n-import java.io.Closeable;\n \n public interface WorkerPoolAwareConfiguration extends WorkerPoolConfiguration {\n+    public static WorkerPoolAwareConfiguration USE_SHARED_CONFIGURATION = new WorkerPoolAwareConfiguration() {\n+        @Override\n+        public int[] getWorkerAffinity() {\n+            throw new UnsupportedOperationException();\n+        }\n+\n+        @Override\n+        public int getWorkerCount() {\n+            return 0;", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQ0NjA4Ng==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r449446086", "bodyText": "WorkerPoolAwareConfiguration.configureWorkerPool uses the shared pool if workerCount is 0", "author": "patrickSpaceSurfer", "createdAt": "2020-07-03T08:19:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkxODEyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk0ODA5Mg==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448948092", "bodyText": "this can be a character switch", "author": "bluestreak01", "createdAt": "2020-07-02T11:56:42Z", "path": "core/src/main/java/io/questdb/PropServerConfiguration.java", "diffHunk": "@@ -458,27 +516,56 @@ public PropServerConfiguration(String root, Properties properties) throws Server\n         this.lineUdpOwnThread = getBoolean(properties, \"line.udp.own.thread\", false);\n         this.lineUdpUnicast = getBoolean(properties, \"line.udp.unicast\", false);\n         this.lineUdpCommitMode = getCommitMode(properties, \"line.udp.commit.mode\");\n+        this.lineUdpTimestampAdapter = getLineTimestampAdaptor(properties, \"line.udp.timestamp\");\n+\n+        this.lineTcpEnabled = getBoolean(properties, \"line.tcp.enabled\", true);\n+        if (lineTcpEnabled) {\n+            lineTcpNetActiveConnectionLimit = getInt(properties, \"line.tcp.net.active.connection.limit\", 10);\n+            parseBindTo(properties, \"line.tcp.net.bind.to\", \"0.0.0.0:9009\", (a, p) -> {\n+                lineTcpNetBindIPv4Address = a;\n+                lineTcpNetBindPort = p;\n+            });\n \n-        final String lineUdpTimestampSwitch = getString(properties, \"line.udp.timestamp\", \"n\");\n+            this.lineTcpNetEventCapacity = getInt(properties, \"line.tcp.net.event.capacity\", 1024);\n+            this.lineTcpNetIOQueueCapacity = getInt(properties, \"line.tcp.net.io.queue.capacity\", 1024);\n+            this.lineTcpNetIdleConnectionTimeout = getLong(properties, \"line.tcp.net.idle.timeout\", 300_000);\n+            this.lineTcpNetInterestQueueCapacity = getInt(properties, \"line.tcp.net.interest.queue.capacity\", 1024);\n+            this.lineTcpNetListenBacklog = getInt(properties, \"line.tcp.net.listen.backlog\", 50_000);\n+            this.lineTcpNetRcvBufSize = getIntSize(properties, \"line.tcp.net.recv.buf.size\", -1);\n+            this.lineTcpConnectionPoolInitialCapacity = getInt(properties, \"line.tcp.connection.pool.capacity\", 64);\n+            this.lineTcpTimestampAdapter = getLineTimestampAdaptor(properties, \"line.tcp.timestamp\");\n+            this.lineTcpMsgBufferSize = getIntSize(properties, \"line.tcp.msg.buffer.size\", 2048);\n+            this.lineTcpMaxMeasurementSize = getIntSize(properties, \"line.tcp.max.measurement.size\", 2048);\n+            if (lineTcpMaxMeasurementSize > lineTcpMsgBufferSize) {\n+                throw new IllegalArgumentException(\n+                        \"line.tcp.max.measurement.size (\" + this.lineTcpMaxMeasurementSize + \") cannot be more than line.tcp.msg.buffer.size (\" + this.lineTcpMsgBufferSize + \")\");\n+            }\n+            this.lineTcpWriterQueueSize = getIntSize(properties, \"line.tcp.writer.queue.size\", 128);\n+            this.lineTcpWorkerCount = getInt(properties, \"line.tcp.worker.count\", 0);\n+            this.lineTcpWorkerAffinity = getAffinity(properties, \"line.tcp.worker.affinity\", lineTcpWorkerCount);\n+            this.lineTcpWorkerPoolHaltOnError = getBoolean(properties, \"line.tcp.halt.on.error\", false);\n+            this.lineTcpNUpdatesPerLoadRebalance = getInt(properties, \"line.tcp.n.updates.per.load.balance\", 10_000);\n+            this.lineTcpMaxLoadRatio = getDouble(properties, \"line.tcp.max.load.ratio\", 1.9);\n+            this.lineTcpMaxUncommittedRows = getInt(properties, \"line.tcp.max.uncommitted.rows\", 1000);\n+            this.lineTcpMaintenanceJobHysteresisInMs = getInt(properties, \"line.tcp.maintenance.job.hysteresis.in.ms\", 250);\n+        }\n+    }\n+\n+    private LineProtoTimestampAdapter getLineTimestampAdaptor(Properties properties, String propNm) {\n+        final String lineUdpTimestampSwitch = getString(properties, propNm, \"n\");", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQ0Njk5MA==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r449446990", "bodyText": "The property allows millisecond \"ms\" and minute \"m\"", "author": "patrickSpaceSurfer", "createdAt": "2020-07-03T08:21:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk0ODA5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk1OTIxMA==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448959210", "bodyText": "this isn't a big deal, but on a server with 20 cores there will be 20 identical classes created by java for this lambda. Perhaps we can create lambda instance outside of the loop?", "author": "bluestreak01", "createdAt": "2020-07-02T12:17:45Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpServer.java", "diffHunk": "@@ -0,0 +1,150 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+\n+import org.jetbrains.annotations.Nullable;\n+\n+import io.questdb.MessageBus;\n+import io.questdb.WorkerPoolAwareConfiguration;\n+import io.questdb.WorkerPoolAwareConfiguration.ServerFactory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.EagerThreadSetup;\n+import io.questdb.mp.SynchronizedJob;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.network.IOContextFactory;\n+import io.questdb.network.IODispatcher;\n+import io.questdb.network.IODispatchers;\n+import io.questdb.network.IORequestProcessor;\n+import io.questdb.std.Misc;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.ThreadLocal;\n+import io.questdb.std.WeakObjectPool;\n+\n+public class LineTcpServer implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpServer.class);\n+\n+    @Nullable\n+    public static LineTcpServer create(\n+            CairoConfiguration cairoConfiguration,\n+            LineTcpReceiverConfiguration lineConfiguration,\n+            WorkerPool sharedWorkerPool,\n+            Log log,\n+            CairoEngine cairoEngine,\n+            MessageBus messageBus\n+    ) {\n+        if (!lineConfiguration.isEnabled()) {\n+            return null;\n+        }\n+\n+        ServerFactory<LineTcpServer, WorkerPoolAwareConfiguration> factory = (netWorkerPoolConfiguration, engine, workerPool, local, bus,\n+                functionfactory) -> new LineTcpServer(\n+                        cairoConfiguration,\n+                        lineConfiguration,\n+                        cairoEngine,\n+                        workerPool,\n+                        bus);\n+        LineTcpServer server = WorkerPoolAwareConfiguration.create(lineConfiguration.getWorkerPoolConfiguration(), sharedWorkerPool, log, cairoEngine, factory, messageBus, null);\n+        return server;\n+    }\n+\n+    private final IODispatcher<LineTcpConnectionContext> dispatcher;\n+    private final LineTcpConnectionContextFactory contextFactory;\n+    private final LineTcpMeasurementScheduler scheduler;\n+    private final ObjList<LineTcpConnectionContext> busyContexts = new ObjList<>();\n+\n+    public LineTcpServer(\n+            CairoConfiguration cairoConfiguration,\n+            LineTcpReceiverConfiguration lineConfiguration,\n+            CairoEngine engine,\n+            WorkerPool workerPool,\n+            MessageBus messageBus\n+    ) {\n+        this.contextFactory = new LineTcpConnectionContextFactory(engine, lineConfiguration, messageBus, workerPool.getWorkerCount());\n+        this.dispatcher = IODispatchers.create(\n+                lineConfiguration\n+                        .getNetDispatcherConfiguration(),\n+                contextFactory);\n+        workerPool.assign(dispatcher);\n+        scheduler = new LineTcpMeasurementScheduler(cairoConfiguration, lineConfiguration, engine, workerPool);\n+        final IORequestProcessor<LineTcpConnectionContext> processor = (operation, context) -> {\n+            if (context.handleIO()) {\n+                busyContexts.add(context);\n+            }\n+        };\n+        workerPool.assign(new SynchronizedJob() {\n+            @Override\n+            protected boolean runSerially() {\n+                int n = busyContexts.size();\n+                while (n > 0) {\n+                    n--;\n+                    if (!busyContexts.getQuick(n).handleIO()) {\n+                        busyContexts.remove(n);\n+                    }\n+                }\n+                return dispatcher.processIOQueue(processor);\n+            }\n+        });\n+\n+        for (int i = 0, n = workerPool.getWorkerCount(); i < n; i++) {\n+            // http context factory has thread local pools\n+            // therefore we need each thread to clean their thread locals individually\n+            workerPool.assign(i, () -> {", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk2MDMyNA==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448960324", "bodyText": "same minor thing here, creating identical lambdas in a loop", "author": "bluestreak01", "createdAt": "2020-07-02T12:19:55Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQ2MDE4NQ==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r449460185", "bodyText": "These are not identical writerJob is scoped to the inside of the loop", "author": "patrickSpaceSurfer", "createdAt": "2020-07-03T08:47:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk2MDMyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk2MDkzMw==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448960933", "bodyText": "rebalances  is not a word. It gets consistently highlighted with spell check. Perhaps we can create a different term?", "author": "bluestreak01", "createdAt": "2020-07-02T12:20:58Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        nUpdatesPerLoadRebalance = lineConfiguration.getnUpdatesPerLoadRebalance();\n+        maxLoadRatio = lineConfiguration.getMaxLoadRatio();\n+        maxUncommittedRows = lineConfiguration.getMaxUncommittedRows();\n+        maintenanceJobHysteresisInMs = lineConfiguration.getMaintenanceJobHysteresisInMs();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n+        }\n+\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event, boolean complete) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableUpdateDetails tableUpdateDetails;\n+        if (complete) {\n+            int keyIndex = tableUpdateDetailsByTableName.keyIndex(event.getTableName());\n+            if (keyIndex > -1) {\n+                String tableName = Chars.toString(event.getTableName());\n+                calcThreadLoad();\n+                int leastLoad = Integer.MAX_VALUE;\n+                int threadId = 0;\n+                for (int n = 0; n < loadByThread.length; n++) {\n+                    if (loadByThread[n] < leastLoad) {\n+                        leastLoad = loadByThread[n];\n+                        threadId = n;\n+                    }\n+                }\n+                tableUpdateDetails = new TableUpdateDetails(tableName, threadId);\n+                tableUpdateDetailsByTableName.putAt(keyIndex, tableName, tableUpdateDetails);\n+                LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+            } else {\n+                tableUpdateDetails = tableUpdateDetailsByTableName.valueAt(keyIndex);\n+            }\n+\n+            event.threadId = tableUpdateDetails.threadId;\n+        } else {\n+            tableUpdateDetails = null;\n+            event.threadId = INCOMPLETE_EVENT_ID;\n+        }\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (null != tableUpdateDetails && tableUpdateDetails.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDA2NzYzMg==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r450067632", "bodyText": "https://dictionary.cambridge.org/dictionary/english/rebalance", "author": "patrickSpaceSurfer", "createdAt": "2020-07-06T08:35:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk2MDkzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDA2OTk0Nw==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r450069947", "bodyText": "haha, intellij doesn't agree", "author": "bluestreak01", "createdAt": "2020-07-06T08:39:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk2MDkzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk2MTQ1Mw==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448961453", "bodyText": "This un-typed, perhaps not logged correctly and un-tested. In any case we should not be throwing new instance and concatenating strings here.\nWe need to throw some \"bad\" line protocol text at the system.", "author": "bluestreak01", "createdAt": "2020-07-02T12:22:02Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        nUpdatesPerLoadRebalance = lineConfiguration.getnUpdatesPerLoadRebalance();\n+        maxLoadRatio = lineConfiguration.getMaxLoadRatio();\n+        maxUncommittedRows = lineConfiguration.getMaxUncommittedRows();\n+        maintenanceJobHysteresisInMs = lineConfiguration.getMaintenanceJobHysteresisInMs();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n+        }\n+\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event, boolean complete) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableUpdateDetails tableUpdateDetails;\n+        if (complete) {\n+            int keyIndex = tableUpdateDetailsByTableName.keyIndex(event.getTableName());\n+            if (keyIndex > -1) {\n+                String tableName = Chars.toString(event.getTableName());\n+                calcThreadLoad();\n+                int leastLoad = Integer.MAX_VALUE;\n+                int threadId = 0;\n+                for (int n = 0; n < loadByThread.length; n++) {\n+                    if (loadByThread[n] < leastLoad) {\n+                        leastLoad = loadByThread[n];\n+                        threadId = n;\n+                    }\n+                }\n+                tableUpdateDetails = new TableUpdateDetails(tableName, threadId);\n+                tableUpdateDetailsByTableName.putAt(keyIndex, tableName, tableUpdateDetails);\n+                LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+            } else {\n+                tableUpdateDetails = tableUpdateDetailsByTableName.valueAt(keyIndex);\n+            }\n+\n+            event.threadId = tableUpdateDetails.threadId;\n+        } else {\n+            tableUpdateDetails = null;\n+            event.threadId = INCOMPLETE_EVENT_ID;\n+        }\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (null != tableUpdateDetails && tableUpdateDetails.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            tableUpdateDetailsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDA2OTA5Mw==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r450069093", "bodyText": "This is a failure scenario, bug in our code (not triggered by third party input). I can change it to an assert or an Error if you like", "author": "patrickSpaceSurfer", "createdAt": "2020-07-06T08:37:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk2MTQ1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk2MjI0Mg==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448962242", "bodyText": "this can potentially be done branch-free, would be interesting to know if JIT does it for us", "author": "bluestreak01", "createdAt": "2020-07-02T12:23:36Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        nUpdatesPerLoadRebalance = lineConfiguration.getnUpdatesPerLoadRebalance();\n+        maxLoadRatio = lineConfiguration.getMaxLoadRatio();\n+        maxUncommittedRows = lineConfiguration.getMaxUncommittedRows();\n+        maintenanceJobHysteresisInMs = lineConfiguration.getMaintenanceJobHysteresisInMs();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n+        }\n+\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event, boolean complete) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableUpdateDetails tableUpdateDetails;\n+        if (complete) {\n+            int keyIndex = tableUpdateDetailsByTableName.keyIndex(event.getTableName());\n+            if (keyIndex > -1) {\n+                String tableName = Chars.toString(event.getTableName());\n+                calcThreadLoad();\n+                int leastLoad = Integer.MAX_VALUE;\n+                int threadId = 0;\n+                for (int n = 0; n < loadByThread.length; n++) {\n+                    if (loadByThread[n] < leastLoad) {\n+                        leastLoad = loadByThread[n];\n+                        threadId = n;\n+                    }\n+                }\n+                tableUpdateDetails = new TableUpdateDetails(tableName, threadId);\n+                tableUpdateDetailsByTableName.putAt(keyIndex, tableName, tableUpdateDetails);\n+                LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+            } else {\n+                tableUpdateDetails = tableUpdateDetailsByTableName.valueAt(keyIndex);\n+            }\n+\n+            event.threadId = tableUpdateDetails.threadId;\n+        } else {\n+            tableUpdateDetails = null;\n+            event.threadId = INCOMPLETE_EVENT_ID;\n+        }\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (null != tableUpdateDetails && tableUpdateDetails.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            tableUpdateDetailsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk2NDg2OA==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448964868", "bodyText": "this method is inverted everywhere, perhaps we can optimise here", "author": "bluestreak01", "createdAt": "2020-07-02T12:28:37Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        nUpdatesPerLoadRebalance = lineConfiguration.getnUpdatesPerLoadRebalance();\n+        maxLoadRatio = lineConfiguration.getMaxLoadRatio();\n+        maxUncommittedRows = lineConfiguration.getMaxUncommittedRows();\n+        maintenanceJobHysteresisInMs = lineConfiguration.getMaintenanceJobHysteresisInMs();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n+        }\n+\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event, boolean complete) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableUpdateDetails tableUpdateDetails;\n+        if (complete) {\n+            int keyIndex = tableUpdateDetailsByTableName.keyIndex(event.getTableName());\n+            if (keyIndex > -1) {\n+                String tableName = Chars.toString(event.getTableName());\n+                calcThreadLoad();\n+                int leastLoad = Integer.MAX_VALUE;\n+                int threadId = 0;\n+                for (int n = 0; n < loadByThread.length; n++) {\n+                    if (loadByThread[n] < leastLoad) {\n+                        leastLoad = loadByThread[n];\n+                        threadId = n;\n+                    }\n+                }\n+                tableUpdateDetails = new TableUpdateDetails(tableName, threadId);\n+                tableUpdateDetailsByTableName.putAt(keyIndex, tableName, tableUpdateDetails);\n+                LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+            } else {\n+                tableUpdateDetails = tableUpdateDetailsByTableName.valueAt(keyIndex);\n+            }\n+\n+            event.threadId = tableUpdateDetails.threadId;\n+        } else {\n+            tableUpdateDetails = null;\n+            event.threadId = INCOMPLETE_EVENT_ID;\n+        }\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (null != tableUpdateDetails && tableUpdateDetails.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            tableUpdateDetailsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk2NTYwNQ==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448965605", "bodyText": "This is strange line, I can see below that timestampAddress does get set to 0, but this line is never triggered by any of the tests. Can we review what's happening here?", "author": "bluestreak01", "createdAt": "2020-07-02T12:30:00Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        nUpdatesPerLoadRebalance = lineConfiguration.getnUpdatesPerLoadRebalance();\n+        maxLoadRatio = lineConfiguration.getMaxLoadRatio();\n+        maxUncommittedRows = lineConfiguration.getMaxUncommittedRows();\n+        maintenanceJobHysteresisInMs = lineConfiguration.getMaintenanceJobHysteresisInMs();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n+        }\n+\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event, boolean complete) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableUpdateDetails tableUpdateDetails;\n+        if (complete) {\n+            int keyIndex = tableUpdateDetailsByTableName.keyIndex(event.getTableName());\n+            if (keyIndex > -1) {\n+                String tableName = Chars.toString(event.getTableName());\n+                calcThreadLoad();\n+                int leastLoad = Integer.MAX_VALUE;\n+                int threadId = 0;\n+                for (int n = 0; n < loadByThread.length; n++) {\n+                    if (loadByThread[n] < leastLoad) {\n+                        leastLoad = loadByThread[n];\n+                        threadId = n;\n+                    }\n+                }\n+                tableUpdateDetails = new TableUpdateDetails(tableName, threadId);\n+                tableUpdateDetailsByTableName.putAt(keyIndex, tableName, tableUpdateDetails);\n+                LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+            } else {\n+                tableUpdateDetails = tableUpdateDetailsByTableName.valueAt(keyIndex);\n+            }\n+\n+            event.threadId = tableUpdateDetails.threadId;\n+        } else {\n+            tableUpdateDetails = null;\n+            event.threadId = INCOMPLETE_EVENT_ID;\n+        }\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (null != tableUpdateDetails && tableUpdateDetails.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            tableUpdateDetailsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDA4NTM4Mw==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r450085383", "bodyText": "This happens when the measurement does not include a timestamp and we use the received time.\nI have added the following test to cover it\nLineTcpConnectionContextTest#testUseReceivedTimestamp1", "author": "patrickSpaceSurfer", "createdAt": "2020-07-06T09:05:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk2NTYwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk2NjgyNQ==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448966825", "bodyText": "this is untested", "author": "bluestreak01", "createdAt": "2020-07-02T12:32:19Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        nUpdatesPerLoadRebalance = lineConfiguration.getnUpdatesPerLoadRebalance();\n+        maxLoadRatio = lineConfiguration.getMaxLoadRatio();\n+        maxUncommittedRows = lineConfiguration.getMaxUncommittedRows();\n+        maintenanceJobHysteresisInMs = lineConfiguration.getMaintenanceJobHysteresisInMs();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n+        }\n+\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event, boolean complete) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableUpdateDetails tableUpdateDetails;\n+        if (complete) {\n+            int keyIndex = tableUpdateDetailsByTableName.keyIndex(event.getTableName());\n+            if (keyIndex > -1) {\n+                String tableName = Chars.toString(event.getTableName());\n+                calcThreadLoad();\n+                int leastLoad = Integer.MAX_VALUE;\n+                int threadId = 0;\n+                for (int n = 0; n < loadByThread.length; n++) {\n+                    if (loadByThread[n] < leastLoad) {\n+                        leastLoad = loadByThread[n];\n+                        threadId = n;\n+                    }\n+                }\n+                tableUpdateDetails = new TableUpdateDetails(tableName, threadId);\n+                tableUpdateDetailsByTableName.putAt(keyIndex, tableName, tableUpdateDetails);\n+                LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+            } else {\n+                tableUpdateDetails = tableUpdateDetailsByTableName.valueAt(keyIndex);\n+            }\n+\n+            event.threadId = tableUpdateDetails.threadId;\n+        } else {\n+            tableUpdateDetails = null;\n+            event.threadId = INCOMPLETE_EVENT_ID;\n+        }\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (null != tableUpdateDetails && tableUpdateDetails.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            tableUpdateDetailsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {\n+            return errorPosition != -1;\n+        }\n+\n+        int getErrorPosition() {\n+            return errorPosition;\n+        }\n+\n+        int getErrorCode() {\n+            return errorCode;\n+        }\n+\n+        CharSequence getTableName() {\n+            return cache.get(measurementNameAddress);\n+        }\n+\n+        long getTimestamp() {\n+            if (timestampAddress != 0) {\n+                try {\n+                    timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n+                    timestampAddress = 0;\n+                } catch (NumericException e) {\n+                    LOG.info().$(\"invalid timestamp: \").$(cache.get(timestampAddress)).$();", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk2Njk2OQ==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448966969", "bodyText": "return value is unused", "author": "bluestreak01", "createdAt": "2020-07-02T12:32:35Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        nUpdatesPerLoadRebalance = lineConfiguration.getnUpdatesPerLoadRebalance();\n+        maxLoadRatio = lineConfiguration.getMaxLoadRatio();\n+        maxUncommittedRows = lineConfiguration.getMaxUncommittedRows();\n+        maintenanceJobHysteresisInMs = lineConfiguration.getMaintenanceJobHysteresisInMs();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n+        }\n+\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event, boolean complete) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableUpdateDetails tableUpdateDetails;\n+        if (complete) {\n+            int keyIndex = tableUpdateDetailsByTableName.keyIndex(event.getTableName());\n+            if (keyIndex > -1) {\n+                String tableName = Chars.toString(event.getTableName());\n+                calcThreadLoad();\n+                int leastLoad = Integer.MAX_VALUE;\n+                int threadId = 0;\n+                for (int n = 0; n < loadByThread.length; n++) {\n+                    if (loadByThread[n] < leastLoad) {\n+                        leastLoad = loadByThread[n];\n+                        threadId = n;\n+                    }\n+                }\n+                tableUpdateDetails = new TableUpdateDetails(tableName, threadId);\n+                tableUpdateDetailsByTableName.putAt(keyIndex, tableName, tableUpdateDetails);\n+                LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+            } else {\n+                tableUpdateDetails = tableUpdateDetailsByTableName.valueAt(keyIndex);\n+            }\n+\n+            event.threadId = tableUpdateDetails.threadId;\n+        } else {\n+            tableUpdateDetails = null;\n+            event.threadId = INCOMPLETE_EVENT_ID;\n+        }\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (null != tableUpdateDetails && tableUpdateDetails.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            tableUpdateDetailsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {\n+            return errorPosition != -1;\n+        }\n+\n+        int getErrorPosition() {\n+            return errorPosition;\n+        }\n+\n+        int getErrorCode() {\n+            return errorCode;\n+        }\n+\n+        CharSequence getTableName() {\n+            return cache.get(measurementNameAddress);\n+        }\n+\n+        long getTimestamp() {\n+            if (timestampAddress != 0) {\n+                try {\n+                    timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n+                    timestampAddress = 0;\n+                } catch (NumericException e) {\n+                    LOG.info().$(\"invalid timestamp: \").$(cache.get(timestampAddress)).$();\n+                    timestamp = Long.MIN_VALUE;\n+                }\n+            }\n+            return timestamp;\n+        }\n+\n+        CharSequence getName(int i) {\n+            return cache.get(addresses.getQuick(2 * i));\n+        }\n+\n+        int getNValues() {\n+            return addresses.size() / 2;\n+        }\n+\n+        CharSequence getValue(int i) {\n+            return cache.get(addresses.getQuick(2 * i + 1));\n+        }\n+\n+        int getFirstFieldIndex() {\n+            return firstFieldIndex;\n+        }\n+\n+        LineTcpMeasurementEvent createRebalanceEvent(int fromThreadId, int toThreadId, String tableName) {", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk2NzY1Mg==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448967652", "bodyText": "exception typing is lacking. This code is untested.", "author": "bluestreak01", "createdAt": "2020-07-02T12:33:54Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        nUpdatesPerLoadRebalance = lineConfiguration.getnUpdatesPerLoadRebalance();\n+        maxLoadRatio = lineConfiguration.getMaxLoadRatio();\n+        maxUncommittedRows = lineConfiguration.getMaxUncommittedRows();\n+        maintenanceJobHysteresisInMs = lineConfiguration.getMaintenanceJobHysteresisInMs();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n+        }\n+\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event, boolean complete) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableUpdateDetails tableUpdateDetails;\n+        if (complete) {\n+            int keyIndex = tableUpdateDetailsByTableName.keyIndex(event.getTableName());\n+            if (keyIndex > -1) {\n+                String tableName = Chars.toString(event.getTableName());\n+                calcThreadLoad();\n+                int leastLoad = Integer.MAX_VALUE;\n+                int threadId = 0;\n+                for (int n = 0; n < loadByThread.length; n++) {\n+                    if (loadByThread[n] < leastLoad) {\n+                        leastLoad = loadByThread[n];\n+                        threadId = n;\n+                    }\n+                }\n+                tableUpdateDetails = new TableUpdateDetails(tableName, threadId);\n+                tableUpdateDetailsByTableName.putAt(keyIndex, tableName, tableUpdateDetails);\n+                LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+            } else {\n+                tableUpdateDetails = tableUpdateDetailsByTableName.valueAt(keyIndex);\n+            }\n+\n+            event.threadId = tableUpdateDetails.threadId;\n+        } else {\n+            tableUpdateDetails = null;\n+            event.threadId = INCOMPLETE_EVENT_ID;\n+        }\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (null != tableUpdateDetails && tableUpdateDetails.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            tableUpdateDetailsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {\n+            return errorPosition != -1;\n+        }\n+\n+        int getErrorPosition() {\n+            return errorPosition;\n+        }\n+\n+        int getErrorCode() {\n+            return errorCode;\n+        }\n+\n+        CharSequence getTableName() {\n+            return cache.get(measurementNameAddress);\n+        }\n+\n+        long getTimestamp() {\n+            if (timestampAddress != 0) {\n+                try {\n+                    timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n+                    timestampAddress = 0;\n+                } catch (NumericException e) {\n+                    LOG.info().$(\"invalid timestamp: \").$(cache.get(timestampAddress)).$();\n+                    timestamp = Long.MIN_VALUE;\n+                }\n+            }\n+            return timestamp;\n+        }\n+\n+        CharSequence getName(int i) {\n+            return cache.get(addresses.getQuick(2 * i));\n+        }\n+\n+        int getNValues() {\n+            return addresses.size() / 2;\n+        }\n+\n+        CharSequence getValue(int i) {\n+            return cache.get(addresses.getQuick(2 * i + 1));\n+        }\n+\n+        int getFirstFieldIndex() {\n+            return firstFieldIndex;\n+        }\n+\n+        LineTcpMeasurementEvent createRebalanceEvent(int fromThreadId, int toThreadId, String tableName) {\n+            clear();\n+            threadId = REBALANCE_EVENT_ID;\n+            rebalanceFromThreadId = fromThreadId;\n+            rebalanceToThreadId = toThreadId;\n+            rebalanceTableName = tableName;\n+            return this;\n+        }\n+\n+        boolean isRebalanceEvent() {\n+            return threadId == REBALANCE_EVENT_ID;\n+        }\n+\n+        @Override\n+        public void close() {\n+            lexer.close();\n+            lexer = null;\n+        }\n+    }\n+\n+    private class WriterJob implements Job {\n+        private final int id;\n+        private final Sequence sequence;\n+        private final CharSequenceObjHashMap<Parser> parserCache = new CharSequenceObjHashMap<>();\n+        private final AppendMemory appendMemory = new AppendMemory();\n+        private final Path path = new Path();\n+        private final TableStructureAdapter tableStructureAdapter = new TableStructureAdapter();\n+        private final String name;\n+        private long lastMaintenanceJobMillis = 0;\n+\n+        private WriterJob(int id, Sequence sequence) {\n+            super();\n+            this.id = id;\n+            this.sequence = sequence;\n+            this.name = \"tcp-line-writer-\" + id;\n+        }\n+\n+        private void close() {\n+            // Finish all jobs in the queue before stopping\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                if (!run(id)) {\n+                    break;\n+                }\n+            }\n+\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0; n < tableNames.size(); n++) {\n+                parserCache.get(tableNames.get(n)).close();\n+            }\n+            parserCache.clear();\n+            appendMemory.close();\n+            path.close();\n+        }\n+\n+        @Override\n+        public boolean run(int workerId) {\n+            assert workerId == id;\n+            boolean busy = drainQueue();\n+            doMaintenance(busy);\n+            return busy;\n+        }\n+\n+        private boolean drainQueue() {\n+            boolean busy = false;\n+            while (true) {\n+                try {\n+                    long cursor;\n+                    while ((cursor = sequence.next()) < 0) {\n+                        if (cursor == -1) {\n+                            return busy;\n+                        }\n+                    }\n+                    busy = true;\n+                    LineTcpMeasurementEvent event = queue.get(cursor);\n+                    boolean eventProcessed;\n+                    try {\n+                        if (event.threadId == id) {\n+                            eventProcessed = processNextEvent(event);\n+                        } else {\n+                            if (event.isRebalanceEvent()) {\n+                                eventProcessed = processRebalance(event);\n+                            } else {\n+                                eventProcessed = true;\n+                            }\n+                        }\n+                    } catch (RuntimeException ex) {\n+                        LOG.error().$(ex).$();\n+                        eventProcessed = true;\n+                    }\n+                    if (eventProcessed) {\n+                        sequence.done(cursor);\n+                    }\n+                } catch (RuntimeException ex) {", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3MDQ4Ng==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448970486", "bodyText": "this is never called", "author": "bluestreak01", "createdAt": "2020-07-02T12:39:03Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        nUpdatesPerLoadRebalance = lineConfiguration.getnUpdatesPerLoadRebalance();\n+        maxLoadRatio = lineConfiguration.getMaxLoadRatio();\n+        maxUncommittedRows = lineConfiguration.getMaxUncommittedRows();\n+        maintenanceJobHysteresisInMs = lineConfiguration.getMaintenanceJobHysteresisInMs();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n+        }\n+\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event, boolean complete) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableUpdateDetails tableUpdateDetails;\n+        if (complete) {\n+            int keyIndex = tableUpdateDetailsByTableName.keyIndex(event.getTableName());\n+            if (keyIndex > -1) {\n+                String tableName = Chars.toString(event.getTableName());\n+                calcThreadLoad();\n+                int leastLoad = Integer.MAX_VALUE;\n+                int threadId = 0;\n+                for (int n = 0; n < loadByThread.length; n++) {\n+                    if (loadByThread[n] < leastLoad) {\n+                        leastLoad = loadByThread[n];\n+                        threadId = n;\n+                    }\n+                }\n+                tableUpdateDetails = new TableUpdateDetails(tableName, threadId);\n+                tableUpdateDetailsByTableName.putAt(keyIndex, tableName, tableUpdateDetails);\n+                LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+            } else {\n+                tableUpdateDetails = tableUpdateDetailsByTableName.valueAt(keyIndex);\n+            }\n+\n+            event.threadId = tableUpdateDetails.threadId;\n+        } else {\n+            tableUpdateDetails = null;\n+            event.threadId = INCOMPLETE_EVENT_ID;\n+        }\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (null != tableUpdateDetails && tableUpdateDetails.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            tableUpdateDetailsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3MTMxNg==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448971316", "bodyText": "This never happens in tests. We should also catch \"CairoError\". writer.commit() is liable to throw that.\nCould we stick to \"message [context]\" style of logging for the thread name too?", "author": "bluestreak01", "createdAt": "2020-07-02T12:40:28Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        nUpdatesPerLoadRebalance = lineConfiguration.getnUpdatesPerLoadRebalance();\n+        maxLoadRatio = lineConfiguration.getMaxLoadRatio();\n+        maxUncommittedRows = lineConfiguration.getMaxUncommittedRows();\n+        maintenanceJobHysteresisInMs = lineConfiguration.getMaintenanceJobHysteresisInMs();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n+        }\n+\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event, boolean complete) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableUpdateDetails tableUpdateDetails;\n+        if (complete) {\n+            int keyIndex = tableUpdateDetailsByTableName.keyIndex(event.getTableName());\n+            if (keyIndex > -1) {\n+                String tableName = Chars.toString(event.getTableName());\n+                calcThreadLoad();\n+                int leastLoad = Integer.MAX_VALUE;\n+                int threadId = 0;\n+                for (int n = 0; n < loadByThread.length; n++) {\n+                    if (loadByThread[n] < leastLoad) {\n+                        leastLoad = loadByThread[n];\n+                        threadId = n;\n+                    }\n+                }\n+                tableUpdateDetails = new TableUpdateDetails(tableName, threadId);\n+                tableUpdateDetailsByTableName.putAt(keyIndex, tableName, tableUpdateDetails);\n+                LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+            } else {\n+                tableUpdateDetails = tableUpdateDetailsByTableName.valueAt(keyIndex);\n+            }\n+\n+            event.threadId = tableUpdateDetails.threadId;\n+        } else {\n+            tableUpdateDetails = null;\n+            event.threadId = INCOMPLETE_EVENT_ID;\n+        }\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (null != tableUpdateDetails && tableUpdateDetails.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            tableUpdateDetailsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {\n+            return errorPosition != -1;\n+        }\n+\n+        int getErrorPosition() {\n+            return errorPosition;\n+        }\n+\n+        int getErrorCode() {\n+            return errorCode;\n+        }\n+\n+        CharSequence getTableName() {\n+            return cache.get(measurementNameAddress);\n+        }\n+\n+        long getTimestamp() {\n+            if (timestampAddress != 0) {\n+                try {\n+                    timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n+                    timestampAddress = 0;\n+                } catch (NumericException e) {\n+                    LOG.info().$(\"invalid timestamp: \").$(cache.get(timestampAddress)).$();\n+                    timestamp = Long.MIN_VALUE;\n+                }\n+            }\n+            return timestamp;\n+        }\n+\n+        CharSequence getName(int i) {\n+            return cache.get(addresses.getQuick(2 * i));\n+        }\n+\n+        int getNValues() {\n+            return addresses.size() / 2;\n+        }\n+\n+        CharSequence getValue(int i) {\n+            return cache.get(addresses.getQuick(2 * i + 1));\n+        }\n+\n+        int getFirstFieldIndex() {\n+            return firstFieldIndex;\n+        }\n+\n+        LineTcpMeasurementEvent createRebalanceEvent(int fromThreadId, int toThreadId, String tableName) {\n+            clear();\n+            threadId = REBALANCE_EVENT_ID;\n+            rebalanceFromThreadId = fromThreadId;\n+            rebalanceToThreadId = toThreadId;\n+            rebalanceTableName = tableName;\n+            return this;\n+        }\n+\n+        boolean isRebalanceEvent() {\n+            return threadId == REBALANCE_EVENT_ID;\n+        }\n+\n+        @Override\n+        public void close() {\n+            lexer.close();\n+            lexer = null;\n+        }\n+    }\n+\n+    private class WriterJob implements Job {\n+        private final int id;\n+        private final Sequence sequence;\n+        private final CharSequenceObjHashMap<Parser> parserCache = new CharSequenceObjHashMap<>();\n+        private final AppendMemory appendMemory = new AppendMemory();\n+        private final Path path = new Path();\n+        private final TableStructureAdapter tableStructureAdapter = new TableStructureAdapter();\n+        private final String name;\n+        private long lastMaintenanceJobMillis = 0;\n+\n+        private WriterJob(int id, Sequence sequence) {\n+            super();\n+            this.id = id;\n+            this.sequence = sequence;\n+            this.name = \"tcp-line-writer-\" + id;\n+        }\n+\n+        private void close() {\n+            // Finish all jobs in the queue before stopping\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                if (!run(id)) {\n+                    break;\n+                }\n+            }\n+\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0; n < tableNames.size(); n++) {\n+                parserCache.get(tableNames.get(n)).close();\n+            }\n+            parserCache.clear();\n+            appendMemory.close();\n+            path.close();\n+        }\n+\n+        @Override\n+        public boolean run(int workerId) {\n+            assert workerId == id;\n+            boolean busy = drainQueue();\n+            doMaintenance(busy);\n+            return busy;\n+        }\n+\n+        private boolean drainQueue() {\n+            boolean busy = false;\n+            while (true) {\n+                try {\n+                    long cursor;\n+                    while ((cursor = sequence.next()) < 0) {\n+                        if (cursor == -1) {\n+                            return busy;\n+                        }\n+                    }\n+                    busy = true;\n+                    LineTcpMeasurementEvent event = queue.get(cursor);\n+                    boolean eventProcessed;\n+                    try {\n+                        if (event.threadId == id) {\n+                            eventProcessed = processNextEvent(event);\n+                        } else {\n+                            if (event.isRebalanceEvent()) {\n+                                eventProcessed = processRebalance(event);\n+                            } else {\n+                                eventProcessed = true;\n+                            }\n+                        }\n+                    } catch (RuntimeException ex) {\n+                        LOG.error().$(ex).$();\n+                        eventProcessed = true;\n+                    }\n+                    if (eventProcessed) {\n+                        sequence.done(cursor);\n+                    }\n+                } catch (RuntimeException ex) {\n+                    LOG.error().$(ex).$();\n+                }\n+            }\n+        }\n+\n+        private void doMaintenance(boolean busy) {\n+            long millis = milliClock.getTicks();\n+            if (busy && (millis - lastMaintenanceJobMillis) < maintenanceJobHysteresisInMs) {\n+                return;\n+            }\n+\n+            lastMaintenanceJobMillis = millis;\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                Parser parser = parserCache.get(tableNames.get(n));\n+                parser.doMaintenance();\n+            }\n+        }\n+\n+        private boolean processNextEvent(LineTcpMeasurementEvent event) {\n+            Parser parser = parserCache.get(event.getTableName());\n+            if (null == parser) {\n+                parser = new Parser();\n+                try {\n+                    parser.processFirstEvent(engine, securityContext, event);\n+                } catch (CairoException ex) {\n+                    LOG.info().$(name).$(\" could not create parser [name=\").$(event.getTableName()).$(\", ex=\").$(ex.getFlyweightMessage()).$(']').$();", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3MTczOQ==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448971739", "bodyText": "toString() at the end is unnecessary", "author": "bluestreak01", "createdAt": "2020-07-02T12:41:05Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        nUpdatesPerLoadRebalance = lineConfiguration.getnUpdatesPerLoadRebalance();\n+        maxLoadRatio = lineConfiguration.getMaxLoadRatio();\n+        maxUncommittedRows = lineConfiguration.getMaxUncommittedRows();\n+        maintenanceJobHysteresisInMs = lineConfiguration.getMaintenanceJobHysteresisInMs();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n+        }\n+\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event, boolean complete) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableUpdateDetails tableUpdateDetails;\n+        if (complete) {\n+            int keyIndex = tableUpdateDetailsByTableName.keyIndex(event.getTableName());\n+            if (keyIndex > -1) {\n+                String tableName = Chars.toString(event.getTableName());\n+                calcThreadLoad();\n+                int leastLoad = Integer.MAX_VALUE;\n+                int threadId = 0;\n+                for (int n = 0; n < loadByThread.length; n++) {\n+                    if (loadByThread[n] < leastLoad) {\n+                        leastLoad = loadByThread[n];\n+                        threadId = n;\n+                    }\n+                }\n+                tableUpdateDetails = new TableUpdateDetails(tableName, threadId);\n+                tableUpdateDetailsByTableName.putAt(keyIndex, tableName, tableUpdateDetails);\n+                LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+            } else {\n+                tableUpdateDetails = tableUpdateDetailsByTableName.valueAt(keyIndex);\n+            }\n+\n+            event.threadId = tableUpdateDetails.threadId;\n+        } else {\n+            tableUpdateDetails = null;\n+            event.threadId = INCOMPLETE_EVENT_ID;\n+        }\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (null != tableUpdateDetails && tableUpdateDetails.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            tableUpdateDetailsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {\n+            return errorPosition != -1;\n+        }\n+\n+        int getErrorPosition() {\n+            return errorPosition;\n+        }\n+\n+        int getErrorCode() {\n+            return errorCode;\n+        }\n+\n+        CharSequence getTableName() {\n+            return cache.get(measurementNameAddress);\n+        }\n+\n+        long getTimestamp() {\n+            if (timestampAddress != 0) {\n+                try {\n+                    timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n+                    timestampAddress = 0;\n+                } catch (NumericException e) {\n+                    LOG.info().$(\"invalid timestamp: \").$(cache.get(timestampAddress)).$();\n+                    timestamp = Long.MIN_VALUE;\n+                }\n+            }\n+            return timestamp;\n+        }\n+\n+        CharSequence getName(int i) {\n+            return cache.get(addresses.getQuick(2 * i));\n+        }\n+\n+        int getNValues() {\n+            return addresses.size() / 2;\n+        }\n+\n+        CharSequence getValue(int i) {\n+            return cache.get(addresses.getQuick(2 * i + 1));\n+        }\n+\n+        int getFirstFieldIndex() {\n+            return firstFieldIndex;\n+        }\n+\n+        LineTcpMeasurementEvent createRebalanceEvent(int fromThreadId, int toThreadId, String tableName) {\n+            clear();\n+            threadId = REBALANCE_EVENT_ID;\n+            rebalanceFromThreadId = fromThreadId;\n+            rebalanceToThreadId = toThreadId;\n+            rebalanceTableName = tableName;\n+            return this;\n+        }\n+\n+        boolean isRebalanceEvent() {\n+            return threadId == REBALANCE_EVENT_ID;\n+        }\n+\n+        @Override\n+        public void close() {\n+            lexer.close();\n+            lexer = null;\n+        }\n+    }\n+\n+    private class WriterJob implements Job {\n+        private final int id;\n+        private final Sequence sequence;\n+        private final CharSequenceObjHashMap<Parser> parserCache = new CharSequenceObjHashMap<>();\n+        private final AppendMemory appendMemory = new AppendMemory();\n+        private final Path path = new Path();\n+        private final TableStructureAdapter tableStructureAdapter = new TableStructureAdapter();\n+        private final String name;\n+        private long lastMaintenanceJobMillis = 0;\n+\n+        private WriterJob(int id, Sequence sequence) {\n+            super();\n+            this.id = id;\n+            this.sequence = sequence;\n+            this.name = \"tcp-line-writer-\" + id;\n+        }\n+\n+        private void close() {\n+            // Finish all jobs in the queue before stopping\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                if (!run(id)) {\n+                    break;\n+                }\n+            }\n+\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0; n < tableNames.size(); n++) {\n+                parserCache.get(tableNames.get(n)).close();\n+            }\n+            parserCache.clear();\n+            appendMemory.close();\n+            path.close();\n+        }\n+\n+        @Override\n+        public boolean run(int workerId) {\n+            assert workerId == id;\n+            boolean busy = drainQueue();\n+            doMaintenance(busy);\n+            return busy;\n+        }\n+\n+        private boolean drainQueue() {\n+            boolean busy = false;\n+            while (true) {\n+                try {\n+                    long cursor;\n+                    while ((cursor = sequence.next()) < 0) {\n+                        if (cursor == -1) {\n+                            return busy;\n+                        }\n+                    }\n+                    busy = true;\n+                    LineTcpMeasurementEvent event = queue.get(cursor);\n+                    boolean eventProcessed;\n+                    try {\n+                        if (event.threadId == id) {\n+                            eventProcessed = processNextEvent(event);\n+                        } else {\n+                            if (event.isRebalanceEvent()) {\n+                                eventProcessed = processRebalance(event);\n+                            } else {\n+                                eventProcessed = true;\n+                            }\n+                        }\n+                    } catch (RuntimeException ex) {\n+                        LOG.error().$(ex).$();\n+                        eventProcessed = true;\n+                    }\n+                    if (eventProcessed) {\n+                        sequence.done(cursor);\n+                    }\n+                } catch (RuntimeException ex) {\n+                    LOG.error().$(ex).$();\n+                }\n+            }\n+        }\n+\n+        private void doMaintenance(boolean busy) {\n+            long millis = milliClock.getTicks();\n+            if (busy && (millis - lastMaintenanceJobMillis) < maintenanceJobHysteresisInMs) {\n+                return;\n+            }\n+\n+            lastMaintenanceJobMillis = millis;\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                Parser parser = parserCache.get(tableNames.get(n));\n+                parser.doMaintenance();\n+            }\n+        }\n+\n+        private boolean processNextEvent(LineTcpMeasurementEvent event) {\n+            Parser parser = parserCache.get(event.getTableName());\n+            if (null == parser) {\n+                parser = new Parser();\n+                try {\n+                    parser.processFirstEvent(engine, securityContext, event);\n+                } catch (CairoException ex) {\n+                    LOG.info().$(name).$(\" could not create parser [name=\").$(event.getTableName()).$(\", ex=\").$(ex.getFlyweightMessage()).$(']').$();\n+                    parser.close();\n+                    return false;\n+                }\n+                LOG.info().$(name).$(\" created parser [name=\").$(event.getTableName()).$(']').$();\n+                parserCache.put(Chars.toString(event.getTableName()).toString(), parser);", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3MTkwMA==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448971900", "bodyText": "this branch can be simplified", "author": "bluestreak01", "createdAt": "2020-07-02T12:41:23Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        nUpdatesPerLoadRebalance = lineConfiguration.getnUpdatesPerLoadRebalance();\n+        maxLoadRatio = lineConfiguration.getMaxLoadRatio();\n+        maxUncommittedRows = lineConfiguration.getMaxUncommittedRows();\n+        maintenanceJobHysteresisInMs = lineConfiguration.getMaintenanceJobHysteresisInMs();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n+        }\n+\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event, boolean complete) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableUpdateDetails tableUpdateDetails;\n+        if (complete) {\n+            int keyIndex = tableUpdateDetailsByTableName.keyIndex(event.getTableName());\n+            if (keyIndex > -1) {\n+                String tableName = Chars.toString(event.getTableName());\n+                calcThreadLoad();\n+                int leastLoad = Integer.MAX_VALUE;\n+                int threadId = 0;\n+                for (int n = 0; n < loadByThread.length; n++) {\n+                    if (loadByThread[n] < leastLoad) {\n+                        leastLoad = loadByThread[n];\n+                        threadId = n;\n+                    }\n+                }\n+                tableUpdateDetails = new TableUpdateDetails(tableName, threadId);\n+                tableUpdateDetailsByTableName.putAt(keyIndex, tableName, tableUpdateDetails);\n+                LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+            } else {\n+                tableUpdateDetails = tableUpdateDetailsByTableName.valueAt(keyIndex);\n+            }\n+\n+            event.threadId = tableUpdateDetails.threadId;\n+        } else {\n+            tableUpdateDetails = null;\n+            event.threadId = INCOMPLETE_EVENT_ID;\n+        }\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (null != tableUpdateDetails && tableUpdateDetails.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            tableUpdateDetailsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {\n+            return errorPosition != -1;\n+        }\n+\n+        int getErrorPosition() {\n+            return errorPosition;\n+        }\n+\n+        int getErrorCode() {\n+            return errorCode;\n+        }\n+\n+        CharSequence getTableName() {\n+            return cache.get(measurementNameAddress);\n+        }\n+\n+        long getTimestamp() {\n+            if (timestampAddress != 0) {\n+                try {\n+                    timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n+                    timestampAddress = 0;\n+                } catch (NumericException e) {\n+                    LOG.info().$(\"invalid timestamp: \").$(cache.get(timestampAddress)).$();\n+                    timestamp = Long.MIN_VALUE;\n+                }\n+            }\n+            return timestamp;\n+        }\n+\n+        CharSequence getName(int i) {\n+            return cache.get(addresses.getQuick(2 * i));\n+        }\n+\n+        int getNValues() {\n+            return addresses.size() / 2;\n+        }\n+\n+        CharSequence getValue(int i) {\n+            return cache.get(addresses.getQuick(2 * i + 1));\n+        }\n+\n+        int getFirstFieldIndex() {\n+            return firstFieldIndex;\n+        }\n+\n+        LineTcpMeasurementEvent createRebalanceEvent(int fromThreadId, int toThreadId, String tableName) {\n+            clear();\n+            threadId = REBALANCE_EVENT_ID;\n+            rebalanceFromThreadId = fromThreadId;\n+            rebalanceToThreadId = toThreadId;\n+            rebalanceTableName = tableName;\n+            return this;\n+        }\n+\n+        boolean isRebalanceEvent() {\n+            return threadId == REBALANCE_EVENT_ID;\n+        }\n+\n+        @Override\n+        public void close() {\n+            lexer.close();\n+            lexer = null;\n+        }\n+    }\n+\n+    private class WriterJob implements Job {\n+        private final int id;\n+        private final Sequence sequence;\n+        private final CharSequenceObjHashMap<Parser> parserCache = new CharSequenceObjHashMap<>();\n+        private final AppendMemory appendMemory = new AppendMemory();\n+        private final Path path = new Path();\n+        private final TableStructureAdapter tableStructureAdapter = new TableStructureAdapter();\n+        private final String name;\n+        private long lastMaintenanceJobMillis = 0;\n+\n+        private WriterJob(int id, Sequence sequence) {\n+            super();\n+            this.id = id;\n+            this.sequence = sequence;\n+            this.name = \"tcp-line-writer-\" + id;\n+        }\n+\n+        private void close() {\n+            // Finish all jobs in the queue before stopping\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                if (!run(id)) {\n+                    break;\n+                }\n+            }\n+\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0; n < tableNames.size(); n++) {\n+                parserCache.get(tableNames.get(n)).close();\n+            }\n+            parserCache.clear();\n+            appendMemory.close();\n+            path.close();\n+        }\n+\n+        @Override\n+        public boolean run(int workerId) {\n+            assert workerId == id;\n+            boolean busy = drainQueue();\n+            doMaintenance(busy);\n+            return busy;\n+        }\n+\n+        private boolean drainQueue() {\n+            boolean busy = false;\n+            while (true) {\n+                try {\n+                    long cursor;\n+                    while ((cursor = sequence.next()) < 0) {\n+                        if (cursor == -1) {\n+                            return busy;\n+                        }\n+                    }\n+                    busy = true;\n+                    LineTcpMeasurementEvent event = queue.get(cursor);\n+                    boolean eventProcessed;\n+                    try {\n+                        if (event.threadId == id) {\n+                            eventProcessed = processNextEvent(event);\n+                        } else {\n+                            if (event.isRebalanceEvent()) {\n+                                eventProcessed = processRebalance(event);\n+                            } else {\n+                                eventProcessed = true;\n+                            }\n+                        }\n+                    } catch (RuntimeException ex) {\n+                        LOG.error().$(ex).$();\n+                        eventProcessed = true;\n+                    }\n+                    if (eventProcessed) {\n+                        sequence.done(cursor);\n+                    }\n+                } catch (RuntimeException ex) {\n+                    LOG.error().$(ex).$();\n+                }\n+            }\n+        }\n+\n+        private void doMaintenance(boolean busy) {\n+            long millis = milliClock.getTicks();\n+            if (busy && (millis - lastMaintenanceJobMillis) < maintenanceJobHysteresisInMs) {\n+                return;\n+            }\n+\n+            lastMaintenanceJobMillis = millis;\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                Parser parser = parserCache.get(tableNames.get(n));\n+                parser.doMaintenance();\n+            }\n+        }\n+\n+        private boolean processNextEvent(LineTcpMeasurementEvent event) {\n+            Parser parser = parserCache.get(event.getTableName());\n+            if (null == parser) {\n+                parser = new Parser();\n+                try {\n+                    parser.processFirstEvent(engine, securityContext, event);\n+                } catch (CairoException ex) {\n+                    LOG.info().$(name).$(\" could not create parser [name=\").$(event.getTableName()).$(\", ex=\").$(ex.getFlyweightMessage()).$(']').$();\n+                    parser.close();\n+                    return false;\n+                }\n+                LOG.info().$(name).$(\" created parser [name=\").$(event.getTableName()).$(']').$();\n+                parserCache.put(Chars.toString(event.getTableName()).toString(), parser);\n+                return true;\n+            } else {\n+                parser.processEvent(event);\n+                return true;\n+            }\n+        }\n+\n+        private boolean processRebalance(LineTcpMeasurementEvent event) {\n+            if (event.rebalanceToThreadId == id) {\n+                if (!event.rebalanceReleasedByFromThread) {", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3NjU3NQ==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448976575", "bodyText": "this property is never read", "author": "bluestreak01", "createdAt": "2020-07-02T12:49:42Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        nUpdatesPerLoadRebalance = lineConfiguration.getnUpdatesPerLoadRebalance();\n+        maxLoadRatio = lineConfiguration.getMaxLoadRatio();\n+        maxUncommittedRows = lineConfiguration.getMaxUncommittedRows();\n+        maintenanceJobHysteresisInMs = lineConfiguration.getMaintenanceJobHysteresisInMs();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n+        }\n+\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event, boolean complete) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableUpdateDetails tableUpdateDetails;\n+        if (complete) {\n+            int keyIndex = tableUpdateDetailsByTableName.keyIndex(event.getTableName());\n+            if (keyIndex > -1) {\n+                String tableName = Chars.toString(event.getTableName());\n+                calcThreadLoad();\n+                int leastLoad = Integer.MAX_VALUE;\n+                int threadId = 0;\n+                for (int n = 0; n < loadByThread.length; n++) {\n+                    if (loadByThread[n] < leastLoad) {\n+                        leastLoad = loadByThread[n];\n+                        threadId = n;\n+                    }\n+                }\n+                tableUpdateDetails = new TableUpdateDetails(tableName, threadId);\n+                tableUpdateDetailsByTableName.putAt(keyIndex, tableName, tableUpdateDetails);\n+                LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+            } else {\n+                tableUpdateDetails = tableUpdateDetailsByTableName.valueAt(keyIndex);\n+            }\n+\n+            event.threadId = tableUpdateDetails.threadId;\n+        } else {\n+            tableUpdateDetails = null;\n+            event.threadId = INCOMPLETE_EVENT_ID;\n+        }\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (null != tableUpdateDetails && tableUpdateDetails.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            tableUpdateDetailsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {\n+            return errorPosition != -1;\n+        }\n+\n+        int getErrorPosition() {\n+            return errorPosition;\n+        }\n+\n+        int getErrorCode() {\n+            return errorCode;\n+        }\n+\n+        CharSequence getTableName() {\n+            return cache.get(measurementNameAddress);\n+        }\n+\n+        long getTimestamp() {\n+            if (timestampAddress != 0) {\n+                try {\n+                    timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n+                    timestampAddress = 0;\n+                } catch (NumericException e) {\n+                    LOG.info().$(\"invalid timestamp: \").$(cache.get(timestampAddress)).$();\n+                    timestamp = Long.MIN_VALUE;\n+                }\n+            }\n+            return timestamp;\n+        }\n+\n+        CharSequence getName(int i) {\n+            return cache.get(addresses.getQuick(2 * i));\n+        }\n+\n+        int getNValues() {\n+            return addresses.size() / 2;\n+        }\n+\n+        CharSequence getValue(int i) {\n+            return cache.get(addresses.getQuick(2 * i + 1));\n+        }\n+\n+        int getFirstFieldIndex() {\n+            return firstFieldIndex;\n+        }\n+\n+        LineTcpMeasurementEvent createRebalanceEvent(int fromThreadId, int toThreadId, String tableName) {\n+            clear();\n+            threadId = REBALANCE_EVENT_ID;\n+            rebalanceFromThreadId = fromThreadId;\n+            rebalanceToThreadId = toThreadId;\n+            rebalanceTableName = tableName;\n+            return this;\n+        }\n+\n+        boolean isRebalanceEvent() {\n+            return threadId == REBALANCE_EVENT_ID;\n+        }\n+\n+        @Override\n+        public void close() {\n+            lexer.close();\n+            lexer = null;\n+        }\n+    }\n+\n+    private class WriterJob implements Job {\n+        private final int id;\n+        private final Sequence sequence;\n+        private final CharSequenceObjHashMap<Parser> parserCache = new CharSequenceObjHashMap<>();\n+        private final AppendMemory appendMemory = new AppendMemory();\n+        private final Path path = new Path();\n+        private final TableStructureAdapter tableStructureAdapter = new TableStructureAdapter();\n+        private final String name;\n+        private long lastMaintenanceJobMillis = 0;\n+\n+        private WriterJob(int id, Sequence sequence) {\n+            super();\n+            this.id = id;\n+            this.sequence = sequence;\n+            this.name = \"tcp-line-writer-\" + id;\n+        }\n+\n+        private void close() {\n+            // Finish all jobs in the queue before stopping\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                if (!run(id)) {\n+                    break;\n+                }\n+            }\n+\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0; n < tableNames.size(); n++) {\n+                parserCache.get(tableNames.get(n)).close();\n+            }\n+            parserCache.clear();\n+            appendMemory.close();\n+            path.close();\n+        }\n+\n+        @Override\n+        public boolean run(int workerId) {\n+            assert workerId == id;\n+            boolean busy = drainQueue();\n+            doMaintenance(busy);\n+            return busy;\n+        }\n+\n+        private boolean drainQueue() {\n+            boolean busy = false;\n+            while (true) {\n+                try {\n+                    long cursor;\n+                    while ((cursor = sequence.next()) < 0) {\n+                        if (cursor == -1) {\n+                            return busy;\n+                        }\n+                    }\n+                    busy = true;\n+                    LineTcpMeasurementEvent event = queue.get(cursor);\n+                    boolean eventProcessed;\n+                    try {\n+                        if (event.threadId == id) {\n+                            eventProcessed = processNextEvent(event);\n+                        } else {\n+                            if (event.isRebalanceEvent()) {\n+                                eventProcessed = processRebalance(event);\n+                            } else {\n+                                eventProcessed = true;\n+                            }\n+                        }\n+                    } catch (RuntimeException ex) {\n+                        LOG.error().$(ex).$();\n+                        eventProcessed = true;\n+                    }\n+                    if (eventProcessed) {\n+                        sequence.done(cursor);\n+                    }\n+                } catch (RuntimeException ex) {\n+                    LOG.error().$(ex).$();\n+                }\n+            }\n+        }\n+\n+        private void doMaintenance(boolean busy) {\n+            long millis = milliClock.getTicks();\n+            if (busy && (millis - lastMaintenanceJobMillis) < maintenanceJobHysteresisInMs) {\n+                return;\n+            }\n+\n+            lastMaintenanceJobMillis = millis;\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                Parser parser = parserCache.get(tableNames.get(n));\n+                parser.doMaintenance();\n+            }\n+        }\n+\n+        private boolean processNextEvent(LineTcpMeasurementEvent event) {\n+            Parser parser = parserCache.get(event.getTableName());\n+            if (null == parser) {\n+                parser = new Parser();\n+                try {\n+                    parser.processFirstEvent(engine, securityContext, event);\n+                } catch (CairoException ex) {\n+                    LOG.info().$(name).$(\" could not create parser [name=\").$(event.getTableName()).$(\", ex=\").$(ex.getFlyweightMessage()).$(']').$();\n+                    parser.close();\n+                    return false;\n+                }\n+                LOG.info().$(name).$(\" created parser [name=\").$(event.getTableName()).$(']').$();\n+                parserCache.put(Chars.toString(event.getTableName()).toString(), parser);\n+                return true;\n+            } else {\n+                parser.processEvent(event);\n+                return true;\n+            }\n+        }\n+\n+        private boolean processRebalance(LineTcpMeasurementEvent event) {\n+            if (event.rebalanceToThreadId == id) {\n+                if (!event.rebalanceReleasedByFromThread) {\n+                    return false;\n+                }\n+\n+                return true;\n+            }\n+\n+            if (event.rebalanceFromThreadId == id) {\n+                Parser parser = parserCache.get(event.rebalanceTableName);\n+                parserCache.remove(event.rebalanceTableName);\n+                parser.close();\n+                event.rebalanceReleasedByFromThread = true;\n+            }\n+\n+            return true;\n+        }\n+\n+        private class Parser implements Closeable {\n+            private TableWriter writer;\n+            private final IntList colTypes = new IntList();\n+            private final IntList colIndexMappings = new IntList();\n+            private int nUncommitted = 0;\n+            private long lastCommitMillis = 0;", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3Njk2MQ==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448976961", "bodyText": "likewise here, we should catch CairoError as well", "author": "bluestreak01", "createdAt": "2020-07-02T12:50:16Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        nUpdatesPerLoadRebalance = lineConfiguration.getnUpdatesPerLoadRebalance();\n+        maxLoadRatio = lineConfiguration.getMaxLoadRatio();\n+        maxUncommittedRows = lineConfiguration.getMaxUncommittedRows();\n+        maintenanceJobHysteresisInMs = lineConfiguration.getMaintenanceJobHysteresisInMs();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n+        }\n+\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event, boolean complete) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableUpdateDetails tableUpdateDetails;\n+        if (complete) {\n+            int keyIndex = tableUpdateDetailsByTableName.keyIndex(event.getTableName());\n+            if (keyIndex > -1) {\n+                String tableName = Chars.toString(event.getTableName());\n+                calcThreadLoad();\n+                int leastLoad = Integer.MAX_VALUE;\n+                int threadId = 0;\n+                for (int n = 0; n < loadByThread.length; n++) {\n+                    if (loadByThread[n] < leastLoad) {\n+                        leastLoad = loadByThread[n];\n+                        threadId = n;\n+                    }\n+                }\n+                tableUpdateDetails = new TableUpdateDetails(tableName, threadId);\n+                tableUpdateDetailsByTableName.putAt(keyIndex, tableName, tableUpdateDetails);\n+                LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+            } else {\n+                tableUpdateDetails = tableUpdateDetailsByTableName.valueAt(keyIndex);\n+            }\n+\n+            event.threadId = tableUpdateDetails.threadId;\n+        } else {\n+            tableUpdateDetails = null;\n+            event.threadId = INCOMPLETE_EVENT_ID;\n+        }\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (null != tableUpdateDetails && tableUpdateDetails.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            tableUpdateDetailsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {\n+            return errorPosition != -1;\n+        }\n+\n+        int getErrorPosition() {\n+            return errorPosition;\n+        }\n+\n+        int getErrorCode() {\n+            return errorCode;\n+        }\n+\n+        CharSequence getTableName() {\n+            return cache.get(measurementNameAddress);\n+        }\n+\n+        long getTimestamp() {\n+            if (timestampAddress != 0) {\n+                try {\n+                    timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n+                    timestampAddress = 0;\n+                } catch (NumericException e) {\n+                    LOG.info().$(\"invalid timestamp: \").$(cache.get(timestampAddress)).$();\n+                    timestamp = Long.MIN_VALUE;\n+                }\n+            }\n+            return timestamp;\n+        }\n+\n+        CharSequence getName(int i) {\n+            return cache.get(addresses.getQuick(2 * i));\n+        }\n+\n+        int getNValues() {\n+            return addresses.size() / 2;\n+        }\n+\n+        CharSequence getValue(int i) {\n+            return cache.get(addresses.getQuick(2 * i + 1));\n+        }\n+\n+        int getFirstFieldIndex() {\n+            return firstFieldIndex;\n+        }\n+\n+        LineTcpMeasurementEvent createRebalanceEvent(int fromThreadId, int toThreadId, String tableName) {\n+            clear();\n+            threadId = REBALANCE_EVENT_ID;\n+            rebalanceFromThreadId = fromThreadId;\n+            rebalanceToThreadId = toThreadId;\n+            rebalanceTableName = tableName;\n+            return this;\n+        }\n+\n+        boolean isRebalanceEvent() {\n+            return threadId == REBALANCE_EVENT_ID;\n+        }\n+\n+        @Override\n+        public void close() {\n+            lexer.close();\n+            lexer = null;\n+        }\n+    }\n+\n+    private class WriterJob implements Job {\n+        private final int id;\n+        private final Sequence sequence;\n+        private final CharSequenceObjHashMap<Parser> parserCache = new CharSequenceObjHashMap<>();\n+        private final AppendMemory appendMemory = new AppendMemory();\n+        private final Path path = new Path();\n+        private final TableStructureAdapter tableStructureAdapter = new TableStructureAdapter();\n+        private final String name;\n+        private long lastMaintenanceJobMillis = 0;\n+\n+        private WriterJob(int id, Sequence sequence) {\n+            super();\n+            this.id = id;\n+            this.sequence = sequence;\n+            this.name = \"tcp-line-writer-\" + id;\n+        }\n+\n+        private void close() {\n+            // Finish all jobs in the queue before stopping\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                if (!run(id)) {\n+                    break;\n+                }\n+            }\n+\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0; n < tableNames.size(); n++) {\n+                parserCache.get(tableNames.get(n)).close();\n+            }\n+            parserCache.clear();\n+            appendMemory.close();\n+            path.close();\n+        }\n+\n+        @Override\n+        public boolean run(int workerId) {\n+            assert workerId == id;\n+            boolean busy = drainQueue();\n+            doMaintenance(busy);\n+            return busy;\n+        }\n+\n+        private boolean drainQueue() {\n+            boolean busy = false;\n+            while (true) {\n+                try {\n+                    long cursor;\n+                    while ((cursor = sequence.next()) < 0) {\n+                        if (cursor == -1) {\n+                            return busy;\n+                        }\n+                    }\n+                    busy = true;\n+                    LineTcpMeasurementEvent event = queue.get(cursor);\n+                    boolean eventProcessed;\n+                    try {\n+                        if (event.threadId == id) {\n+                            eventProcessed = processNextEvent(event);\n+                        } else {\n+                            if (event.isRebalanceEvent()) {\n+                                eventProcessed = processRebalance(event);\n+                            } else {\n+                                eventProcessed = true;\n+                            }\n+                        }\n+                    } catch (RuntimeException ex) {\n+                        LOG.error().$(ex).$();\n+                        eventProcessed = true;\n+                    }\n+                    if (eventProcessed) {\n+                        sequence.done(cursor);\n+                    }\n+                } catch (RuntimeException ex) {\n+                    LOG.error().$(ex).$();\n+                }\n+            }\n+        }\n+\n+        private void doMaintenance(boolean busy) {\n+            long millis = milliClock.getTicks();\n+            if (busy && (millis - lastMaintenanceJobMillis) < maintenanceJobHysteresisInMs) {\n+                return;\n+            }\n+\n+            lastMaintenanceJobMillis = millis;\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                Parser parser = parserCache.get(tableNames.get(n));\n+                parser.doMaintenance();\n+            }\n+        }\n+\n+        private boolean processNextEvent(LineTcpMeasurementEvent event) {\n+            Parser parser = parserCache.get(event.getTableName());\n+            if (null == parser) {\n+                parser = new Parser();\n+                try {\n+                    parser.processFirstEvent(engine, securityContext, event);\n+                } catch (CairoException ex) {\n+                    LOG.info().$(name).$(\" could not create parser [name=\").$(event.getTableName()).$(\", ex=\").$(ex.getFlyweightMessage()).$(']').$();\n+                    parser.close();\n+                    return false;\n+                }\n+                LOG.info().$(name).$(\" created parser [name=\").$(event.getTableName()).$(']').$();\n+                parserCache.put(Chars.toString(event.getTableName()).toString(), parser);\n+                return true;\n+            } else {\n+                parser.processEvent(event);\n+                return true;\n+            }\n+        }\n+\n+        private boolean processRebalance(LineTcpMeasurementEvent event) {\n+            if (event.rebalanceToThreadId == id) {\n+                if (!event.rebalanceReleasedByFromThread) {\n+                    return false;\n+                }\n+\n+                return true;\n+            }\n+\n+            if (event.rebalanceFromThreadId == id) {\n+                Parser parser = parserCache.get(event.rebalanceTableName);\n+                parserCache.remove(event.rebalanceTableName);\n+                parser.close();\n+                event.rebalanceReleasedByFromThread = true;\n+            }\n+\n+            return true;\n+        }\n+\n+        private class Parser implements Closeable {\n+            private TableWriter writer;\n+            private final IntList colTypes = new IntList();\n+            private final IntList colIndexMappings = new IntList();\n+            private int nUncommitted = 0;\n+            private long lastCommitMillis = 0;\n+\n+            private transient int nMeasurementValues;\n+            private transient boolean error;\n+\n+            private void processFirstEvent(CairoEngine engine, CairoSecurityContext securityContext, LineTcpMeasurementEvent event) {\n+                assert null == writer;\n+                int status = engine.getStatus(securityContext, path, event.getTableName(), 0, event.getTableName().length());\n+                if (status == TableUtils.TABLE_EXISTS) {\n+                    writer = engine.getWriter(securityContext, event.getTableName());\n+                    processEvent(event);\n+                    return;\n+                }\n+\n+                preprocessEvent(event);\n+                engine.creatTable(\n+                        securityContext,\n+                        appendMemory,\n+                        path,\n+                        tableStructureAdapter.of(event, this));\n+                int nValues = event.getNValues();\n+                for (int n = 0; n < nValues; n++) {\n+                    colIndexMappings.add(n, n);\n+                }\n+                writer = engine.getWriter(securityContext, event.getTableName());\n+                addRow(event);\n+            }\n+\n+            private void processEvent(LineTcpMeasurementEvent event) {\n+                assert event.getTableName().equals(writer.getName());\n+                preprocessEvent(event);\n+                parseNames(event);\n+                addRow(event);\n+            }\n+\n+            private void addRow(LineTcpMeasurementEvent event) {\n+                if (error) {\n+                    return;\n+                }\n+                long timestamp = event.getTimestamp();\n+                Row row = writer.newRow(timestamp);\n+                try {\n+                    for (int i = 0; i < nMeasurementValues; i++) {\n+                        int columnType = colTypes.getQuick(i);\n+                        int columnIndex = colIndexMappings.getQuick(i);\n+                        CairoLineProtoParserSupport.writers.getQuick(columnType).write(row, columnIndex, event.getValue(i));\n+                    }\n+                    row.append();\n+                } catch (CairoException | BadCastException ignore) {", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3NzEzMA==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448977130", "bodyText": "cancel is untested", "author": "bluestreak01", "createdAt": "2020-07-02T12:50:32Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        nUpdatesPerLoadRebalance = lineConfiguration.getnUpdatesPerLoadRebalance();\n+        maxLoadRatio = lineConfiguration.getMaxLoadRatio();\n+        maxUncommittedRows = lineConfiguration.getMaxUncommittedRows();\n+        maintenanceJobHysteresisInMs = lineConfiguration.getMaintenanceJobHysteresisInMs();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n+        }\n+\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event, boolean complete) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableUpdateDetails tableUpdateDetails;\n+        if (complete) {\n+            int keyIndex = tableUpdateDetailsByTableName.keyIndex(event.getTableName());\n+            if (keyIndex > -1) {\n+                String tableName = Chars.toString(event.getTableName());\n+                calcThreadLoad();\n+                int leastLoad = Integer.MAX_VALUE;\n+                int threadId = 0;\n+                for (int n = 0; n < loadByThread.length; n++) {\n+                    if (loadByThread[n] < leastLoad) {\n+                        leastLoad = loadByThread[n];\n+                        threadId = n;\n+                    }\n+                }\n+                tableUpdateDetails = new TableUpdateDetails(tableName, threadId);\n+                tableUpdateDetailsByTableName.putAt(keyIndex, tableName, tableUpdateDetails);\n+                LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+            } else {\n+                tableUpdateDetails = tableUpdateDetailsByTableName.valueAt(keyIndex);\n+            }\n+\n+            event.threadId = tableUpdateDetails.threadId;\n+        } else {\n+            tableUpdateDetails = null;\n+            event.threadId = INCOMPLETE_EVENT_ID;\n+        }\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (null != tableUpdateDetails && tableUpdateDetails.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            tableUpdateDetailsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {\n+            return errorPosition != -1;\n+        }\n+\n+        int getErrorPosition() {\n+            return errorPosition;\n+        }\n+\n+        int getErrorCode() {\n+            return errorCode;\n+        }\n+\n+        CharSequence getTableName() {\n+            return cache.get(measurementNameAddress);\n+        }\n+\n+        long getTimestamp() {\n+            if (timestampAddress != 0) {\n+                try {\n+                    timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n+                    timestampAddress = 0;\n+                } catch (NumericException e) {\n+                    LOG.info().$(\"invalid timestamp: \").$(cache.get(timestampAddress)).$();\n+                    timestamp = Long.MIN_VALUE;\n+                }\n+            }\n+            return timestamp;\n+        }\n+\n+        CharSequence getName(int i) {\n+            return cache.get(addresses.getQuick(2 * i));\n+        }\n+\n+        int getNValues() {\n+            return addresses.size() / 2;\n+        }\n+\n+        CharSequence getValue(int i) {\n+            return cache.get(addresses.getQuick(2 * i + 1));\n+        }\n+\n+        int getFirstFieldIndex() {\n+            return firstFieldIndex;\n+        }\n+\n+        LineTcpMeasurementEvent createRebalanceEvent(int fromThreadId, int toThreadId, String tableName) {\n+            clear();\n+            threadId = REBALANCE_EVENT_ID;\n+            rebalanceFromThreadId = fromThreadId;\n+            rebalanceToThreadId = toThreadId;\n+            rebalanceTableName = tableName;\n+            return this;\n+        }\n+\n+        boolean isRebalanceEvent() {\n+            return threadId == REBALANCE_EVENT_ID;\n+        }\n+\n+        @Override\n+        public void close() {\n+            lexer.close();\n+            lexer = null;\n+        }\n+    }\n+\n+    private class WriterJob implements Job {\n+        private final int id;\n+        private final Sequence sequence;\n+        private final CharSequenceObjHashMap<Parser> parserCache = new CharSequenceObjHashMap<>();\n+        private final AppendMemory appendMemory = new AppendMemory();\n+        private final Path path = new Path();\n+        private final TableStructureAdapter tableStructureAdapter = new TableStructureAdapter();\n+        private final String name;\n+        private long lastMaintenanceJobMillis = 0;\n+\n+        private WriterJob(int id, Sequence sequence) {\n+            super();\n+            this.id = id;\n+            this.sequence = sequence;\n+            this.name = \"tcp-line-writer-\" + id;\n+        }\n+\n+        private void close() {\n+            // Finish all jobs in the queue before stopping\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                if (!run(id)) {\n+                    break;\n+                }\n+            }\n+\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0; n < tableNames.size(); n++) {\n+                parserCache.get(tableNames.get(n)).close();\n+            }\n+            parserCache.clear();\n+            appendMemory.close();\n+            path.close();\n+        }\n+\n+        @Override\n+        public boolean run(int workerId) {\n+            assert workerId == id;\n+            boolean busy = drainQueue();\n+            doMaintenance(busy);\n+            return busy;\n+        }\n+\n+        private boolean drainQueue() {\n+            boolean busy = false;\n+            while (true) {\n+                try {\n+                    long cursor;\n+                    while ((cursor = sequence.next()) < 0) {\n+                        if (cursor == -1) {\n+                            return busy;\n+                        }\n+                    }\n+                    busy = true;\n+                    LineTcpMeasurementEvent event = queue.get(cursor);\n+                    boolean eventProcessed;\n+                    try {\n+                        if (event.threadId == id) {\n+                            eventProcessed = processNextEvent(event);\n+                        } else {\n+                            if (event.isRebalanceEvent()) {\n+                                eventProcessed = processRebalance(event);\n+                            } else {\n+                                eventProcessed = true;\n+                            }\n+                        }\n+                    } catch (RuntimeException ex) {\n+                        LOG.error().$(ex).$();\n+                        eventProcessed = true;\n+                    }\n+                    if (eventProcessed) {\n+                        sequence.done(cursor);\n+                    }\n+                } catch (RuntimeException ex) {\n+                    LOG.error().$(ex).$();\n+                }\n+            }\n+        }\n+\n+        private void doMaintenance(boolean busy) {\n+            long millis = milliClock.getTicks();\n+            if (busy && (millis - lastMaintenanceJobMillis) < maintenanceJobHysteresisInMs) {\n+                return;\n+            }\n+\n+            lastMaintenanceJobMillis = millis;\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                Parser parser = parserCache.get(tableNames.get(n));\n+                parser.doMaintenance();\n+            }\n+        }\n+\n+        private boolean processNextEvent(LineTcpMeasurementEvent event) {\n+            Parser parser = parserCache.get(event.getTableName());\n+            if (null == parser) {\n+                parser = new Parser();\n+                try {\n+                    parser.processFirstEvent(engine, securityContext, event);\n+                } catch (CairoException ex) {\n+                    LOG.info().$(name).$(\" could not create parser [name=\").$(event.getTableName()).$(\", ex=\").$(ex.getFlyweightMessage()).$(']').$();\n+                    parser.close();\n+                    return false;\n+                }\n+                LOG.info().$(name).$(\" created parser [name=\").$(event.getTableName()).$(']').$();\n+                parserCache.put(Chars.toString(event.getTableName()).toString(), parser);\n+                return true;\n+            } else {\n+                parser.processEvent(event);\n+                return true;\n+            }\n+        }\n+\n+        private boolean processRebalance(LineTcpMeasurementEvent event) {\n+            if (event.rebalanceToThreadId == id) {\n+                if (!event.rebalanceReleasedByFromThread) {\n+                    return false;\n+                }\n+\n+                return true;\n+            }\n+\n+            if (event.rebalanceFromThreadId == id) {\n+                Parser parser = parserCache.get(event.rebalanceTableName);\n+                parserCache.remove(event.rebalanceTableName);\n+                parser.close();\n+                event.rebalanceReleasedByFromThread = true;\n+            }\n+\n+            return true;\n+        }\n+\n+        private class Parser implements Closeable {\n+            private TableWriter writer;\n+            private final IntList colTypes = new IntList();\n+            private final IntList colIndexMappings = new IntList();\n+            private int nUncommitted = 0;\n+            private long lastCommitMillis = 0;\n+\n+            private transient int nMeasurementValues;\n+            private transient boolean error;\n+\n+            private void processFirstEvent(CairoEngine engine, CairoSecurityContext securityContext, LineTcpMeasurementEvent event) {\n+                assert null == writer;\n+                int status = engine.getStatus(securityContext, path, event.getTableName(), 0, event.getTableName().length());\n+                if (status == TableUtils.TABLE_EXISTS) {\n+                    writer = engine.getWriter(securityContext, event.getTableName());\n+                    processEvent(event);\n+                    return;\n+                }\n+\n+                preprocessEvent(event);\n+                engine.creatTable(\n+                        securityContext,\n+                        appendMemory,\n+                        path,\n+                        tableStructureAdapter.of(event, this));\n+                int nValues = event.getNValues();\n+                for (int n = 0; n < nValues; n++) {\n+                    colIndexMappings.add(n, n);\n+                }\n+                writer = engine.getWriter(securityContext, event.getTableName());\n+                addRow(event);\n+            }\n+\n+            private void processEvent(LineTcpMeasurementEvent event) {\n+                assert event.getTableName().equals(writer.getName());\n+                preprocessEvent(event);\n+                parseNames(event);\n+                addRow(event);\n+            }\n+\n+            private void addRow(LineTcpMeasurementEvent event) {\n+                if (error) {\n+                    return;\n+                }\n+                long timestamp = event.getTimestamp();\n+                Row row = writer.newRow(timestamp);\n+                try {\n+                    for (int i = 0; i < nMeasurementValues; i++) {\n+                        int columnType = colTypes.getQuick(i);\n+                        int columnIndex = colIndexMappings.getQuick(i);\n+                        CairoLineProtoParserSupport.writers.getQuick(columnType).write(row, columnIndex, event.getValue(i));\n+                    }\n+                    row.append();\n+                } catch (CairoException | BadCastException ignore) {\n+                    row.cancel();", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3NzMyOQ==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448977329", "bodyText": "type mismatch is untested", "author": "bluestreak01", "createdAt": "2020-07-02T12:50:49Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        nUpdatesPerLoadRebalance = lineConfiguration.getnUpdatesPerLoadRebalance();\n+        maxLoadRatio = lineConfiguration.getMaxLoadRatio();\n+        maxUncommittedRows = lineConfiguration.getMaxUncommittedRows();\n+        maintenanceJobHysteresisInMs = lineConfiguration.getMaintenanceJobHysteresisInMs();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n+        }\n+\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event, boolean complete) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableUpdateDetails tableUpdateDetails;\n+        if (complete) {\n+            int keyIndex = tableUpdateDetailsByTableName.keyIndex(event.getTableName());\n+            if (keyIndex > -1) {\n+                String tableName = Chars.toString(event.getTableName());\n+                calcThreadLoad();\n+                int leastLoad = Integer.MAX_VALUE;\n+                int threadId = 0;\n+                for (int n = 0; n < loadByThread.length; n++) {\n+                    if (loadByThread[n] < leastLoad) {\n+                        leastLoad = loadByThread[n];\n+                        threadId = n;\n+                    }\n+                }\n+                tableUpdateDetails = new TableUpdateDetails(tableName, threadId);\n+                tableUpdateDetailsByTableName.putAt(keyIndex, tableName, tableUpdateDetails);\n+                LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+            } else {\n+                tableUpdateDetails = tableUpdateDetailsByTableName.valueAt(keyIndex);\n+            }\n+\n+            event.threadId = tableUpdateDetails.threadId;\n+        } else {\n+            tableUpdateDetails = null;\n+            event.threadId = INCOMPLETE_EVENT_ID;\n+        }\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (null != tableUpdateDetails && tableUpdateDetails.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            tableUpdateDetailsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {\n+            return errorPosition != -1;\n+        }\n+\n+        int getErrorPosition() {\n+            return errorPosition;\n+        }\n+\n+        int getErrorCode() {\n+            return errorCode;\n+        }\n+\n+        CharSequence getTableName() {\n+            return cache.get(measurementNameAddress);\n+        }\n+\n+        long getTimestamp() {\n+            if (timestampAddress != 0) {\n+                try {\n+                    timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n+                    timestampAddress = 0;\n+                } catch (NumericException e) {\n+                    LOG.info().$(\"invalid timestamp: \").$(cache.get(timestampAddress)).$();\n+                    timestamp = Long.MIN_VALUE;\n+                }\n+            }\n+            return timestamp;\n+        }\n+\n+        CharSequence getName(int i) {\n+            return cache.get(addresses.getQuick(2 * i));\n+        }\n+\n+        int getNValues() {\n+            return addresses.size() / 2;\n+        }\n+\n+        CharSequence getValue(int i) {\n+            return cache.get(addresses.getQuick(2 * i + 1));\n+        }\n+\n+        int getFirstFieldIndex() {\n+            return firstFieldIndex;\n+        }\n+\n+        LineTcpMeasurementEvent createRebalanceEvent(int fromThreadId, int toThreadId, String tableName) {\n+            clear();\n+            threadId = REBALANCE_EVENT_ID;\n+            rebalanceFromThreadId = fromThreadId;\n+            rebalanceToThreadId = toThreadId;\n+            rebalanceTableName = tableName;\n+            return this;\n+        }\n+\n+        boolean isRebalanceEvent() {\n+            return threadId == REBALANCE_EVENT_ID;\n+        }\n+\n+        @Override\n+        public void close() {\n+            lexer.close();\n+            lexer = null;\n+        }\n+    }\n+\n+    private class WriterJob implements Job {\n+        private final int id;\n+        private final Sequence sequence;\n+        private final CharSequenceObjHashMap<Parser> parserCache = new CharSequenceObjHashMap<>();\n+        private final AppendMemory appendMemory = new AppendMemory();\n+        private final Path path = new Path();\n+        private final TableStructureAdapter tableStructureAdapter = new TableStructureAdapter();\n+        private final String name;\n+        private long lastMaintenanceJobMillis = 0;\n+\n+        private WriterJob(int id, Sequence sequence) {\n+            super();\n+            this.id = id;\n+            this.sequence = sequence;\n+            this.name = \"tcp-line-writer-\" + id;\n+        }\n+\n+        private void close() {\n+            // Finish all jobs in the queue before stopping\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                if (!run(id)) {\n+                    break;\n+                }\n+            }\n+\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0; n < tableNames.size(); n++) {\n+                parserCache.get(tableNames.get(n)).close();\n+            }\n+            parserCache.clear();\n+            appendMemory.close();\n+            path.close();\n+        }\n+\n+        @Override\n+        public boolean run(int workerId) {\n+            assert workerId == id;\n+            boolean busy = drainQueue();\n+            doMaintenance(busy);\n+            return busy;\n+        }\n+\n+        private boolean drainQueue() {\n+            boolean busy = false;\n+            while (true) {\n+                try {\n+                    long cursor;\n+                    while ((cursor = sequence.next()) < 0) {\n+                        if (cursor == -1) {\n+                            return busy;\n+                        }\n+                    }\n+                    busy = true;\n+                    LineTcpMeasurementEvent event = queue.get(cursor);\n+                    boolean eventProcessed;\n+                    try {\n+                        if (event.threadId == id) {\n+                            eventProcessed = processNextEvent(event);\n+                        } else {\n+                            if (event.isRebalanceEvent()) {\n+                                eventProcessed = processRebalance(event);\n+                            } else {\n+                                eventProcessed = true;\n+                            }\n+                        }\n+                    } catch (RuntimeException ex) {\n+                        LOG.error().$(ex).$();\n+                        eventProcessed = true;\n+                    }\n+                    if (eventProcessed) {\n+                        sequence.done(cursor);\n+                    }\n+                } catch (RuntimeException ex) {\n+                    LOG.error().$(ex).$();\n+                }\n+            }\n+        }\n+\n+        private void doMaintenance(boolean busy) {\n+            long millis = milliClock.getTicks();\n+            if (busy && (millis - lastMaintenanceJobMillis) < maintenanceJobHysteresisInMs) {\n+                return;\n+            }\n+\n+            lastMaintenanceJobMillis = millis;\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                Parser parser = parserCache.get(tableNames.get(n));\n+                parser.doMaintenance();\n+            }\n+        }\n+\n+        private boolean processNextEvent(LineTcpMeasurementEvent event) {\n+            Parser parser = parserCache.get(event.getTableName());\n+            if (null == parser) {\n+                parser = new Parser();\n+                try {\n+                    parser.processFirstEvent(engine, securityContext, event);\n+                } catch (CairoException ex) {\n+                    LOG.info().$(name).$(\" could not create parser [name=\").$(event.getTableName()).$(\", ex=\").$(ex.getFlyweightMessage()).$(']').$();\n+                    parser.close();\n+                    return false;\n+                }\n+                LOG.info().$(name).$(\" created parser [name=\").$(event.getTableName()).$(']').$();\n+                parserCache.put(Chars.toString(event.getTableName()).toString(), parser);\n+                return true;\n+            } else {\n+                parser.processEvent(event);\n+                return true;\n+            }\n+        }\n+\n+        private boolean processRebalance(LineTcpMeasurementEvent event) {\n+            if (event.rebalanceToThreadId == id) {\n+                if (!event.rebalanceReleasedByFromThread) {\n+                    return false;\n+                }\n+\n+                return true;\n+            }\n+\n+            if (event.rebalanceFromThreadId == id) {\n+                Parser parser = parserCache.get(event.rebalanceTableName);\n+                parserCache.remove(event.rebalanceTableName);\n+                parser.close();\n+                event.rebalanceReleasedByFromThread = true;\n+            }\n+\n+            return true;\n+        }\n+\n+        private class Parser implements Closeable {\n+            private TableWriter writer;\n+            private final IntList colTypes = new IntList();\n+            private final IntList colIndexMappings = new IntList();\n+            private int nUncommitted = 0;\n+            private long lastCommitMillis = 0;\n+\n+            private transient int nMeasurementValues;\n+            private transient boolean error;\n+\n+            private void processFirstEvent(CairoEngine engine, CairoSecurityContext securityContext, LineTcpMeasurementEvent event) {\n+                assert null == writer;\n+                int status = engine.getStatus(securityContext, path, event.getTableName(), 0, event.getTableName().length());\n+                if (status == TableUtils.TABLE_EXISTS) {\n+                    writer = engine.getWriter(securityContext, event.getTableName());\n+                    processEvent(event);\n+                    return;\n+                }\n+\n+                preprocessEvent(event);\n+                engine.creatTable(\n+                        securityContext,\n+                        appendMemory,\n+                        path,\n+                        tableStructureAdapter.of(event, this));\n+                int nValues = event.getNValues();\n+                for (int n = 0; n < nValues; n++) {\n+                    colIndexMappings.add(n, n);\n+                }\n+                writer = engine.getWriter(securityContext, event.getTableName());\n+                addRow(event);\n+            }\n+\n+            private void processEvent(LineTcpMeasurementEvent event) {\n+                assert event.getTableName().equals(writer.getName());\n+                preprocessEvent(event);\n+                parseNames(event);\n+                addRow(event);\n+            }\n+\n+            private void addRow(LineTcpMeasurementEvent event) {\n+                if (error) {\n+                    return;\n+                }\n+                long timestamp = event.getTimestamp();\n+                Row row = writer.newRow(timestamp);\n+                try {\n+                    for (int i = 0; i < nMeasurementValues; i++) {\n+                        int columnType = colTypes.getQuick(i);\n+                        int columnIndex = colIndexMappings.getQuick(i);\n+                        CairoLineProtoParserSupport.writers.getQuick(columnType).write(row, columnIndex, event.getValue(i));\n+                    }\n+                    row.append();\n+                } catch (CairoException | BadCastException ignore) {\n+                    row.cancel();\n+                }\n+                nUncommitted++;\n+                if (nUncommitted > maxUncommittedRows) {\n+                    commit();\n+                }\n+            }\n+\n+            private void commit() {\n+                writer.commit();\n+                nUncommitted = 0;\n+                lastCommitMillis = milliClock.getTicks();\n+            }\n+\n+            private void preprocessEvent(LineTcpMeasurementEvent event) {\n+                error = false;\n+                nMeasurementValues = event.getNValues();\n+                colTypes.ensureCapacity(nMeasurementValues);\n+                colIndexMappings.ensureCapacity(nMeasurementValues);\n+                parseTypes(event);\n+            }\n+\n+            private void parseTypes(LineTcpMeasurementEvent event) {\n+                for (int n = 0; n < nMeasurementValues; n++) {\n+                    int colType;\n+                    if (n < event.getFirstFieldIndex()) {\n+                        colType = ColumnType.SYMBOL;\n+                    } else {\n+                        colType = CairoLineProtoParserSupport.getValueType(event.getValue(n));\n+                    }\n+                    colTypes.add(n, colType);\n+                }\n+            }\n+\n+            private void parseNames(LineTcpMeasurementEvent event) {\n+                RecordMetadata metadata = writer.getMetadata();\n+                for (int n = 0; n < nMeasurementValues; n++) {\n+                    int colIndex = metadata.getColumnIndexQuiet(event.getName(n));\n+                    if (colIndex == -1) {\n+                        colIndex = metadata.getColumnCount();\n+                        writer.addColumn(event.getName(n), colTypes.getQuick(n));\n+                    } else {\n+                        if (metadata.getColumnType(colIndex) != colTypes.getQuick(n)) {\n+                            LOG.error().$(\"mismatched column and value types [table=\").$(writer.getName())", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3Nzg3MA==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448977870", "bodyText": "this entire class is untested", "author": "bluestreak01", "createdAt": "2020-07-02T12:51:43Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpServer.java", "diffHunk": "@@ -0,0 +1,150 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+\n+import org.jetbrains.annotations.Nullable;\n+\n+import io.questdb.MessageBus;\n+import io.questdb.WorkerPoolAwareConfiguration;\n+import io.questdb.WorkerPoolAwareConfiguration.ServerFactory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.EagerThreadSetup;\n+import io.questdb.mp.SynchronizedJob;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.network.IOContextFactory;\n+import io.questdb.network.IODispatcher;\n+import io.questdb.network.IODispatchers;\n+import io.questdb.network.IORequestProcessor;\n+import io.questdb.std.Misc;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.ThreadLocal;\n+import io.questdb.std.WeakObjectPool;\n+\n+public class LineTcpServer implements Closeable {", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3ODQ3Nw==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448978477", "bodyText": "exception is redundant", "author": "bluestreak01", "createdAt": "2020-07-02T12:52:34Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpServer.java", "diffHunk": "@@ -0,0 +1,150 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+\n+import org.jetbrains.annotations.Nullable;\n+\n+import io.questdb.MessageBus;\n+import io.questdb.WorkerPoolAwareConfiguration;\n+import io.questdb.WorkerPoolAwareConfiguration.ServerFactory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.EagerThreadSetup;\n+import io.questdb.mp.SynchronizedJob;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.network.IOContextFactory;\n+import io.questdb.network.IODispatcher;\n+import io.questdb.network.IODispatchers;\n+import io.questdb.network.IORequestProcessor;\n+import io.questdb.std.Misc;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.ThreadLocal;\n+import io.questdb.std.WeakObjectPool;\n+\n+public class LineTcpServer implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpServer.class);\n+\n+    @Nullable\n+    public static LineTcpServer create(\n+            CairoConfiguration cairoConfiguration,\n+            LineTcpReceiverConfiguration lineConfiguration,\n+            WorkerPool sharedWorkerPool,\n+            Log log,\n+            CairoEngine cairoEngine,\n+            MessageBus messageBus\n+    ) {\n+        if (!lineConfiguration.isEnabled()) {\n+            return null;\n+        }\n+\n+        ServerFactory<LineTcpServer, WorkerPoolAwareConfiguration> factory = (netWorkerPoolConfiguration, engine, workerPool, local, bus,\n+                functionfactory) -> new LineTcpServer(\n+                        cairoConfiguration,\n+                        lineConfiguration,\n+                        cairoEngine,\n+                        workerPool,\n+                        bus);\n+        LineTcpServer server = WorkerPoolAwareConfiguration.create(lineConfiguration.getWorkerPoolConfiguration(), sharedWorkerPool, log, cairoEngine, factory, messageBus, null);\n+        return server;\n+    }\n+\n+    private final IODispatcher<LineTcpConnectionContext> dispatcher;\n+    private final LineTcpConnectionContextFactory contextFactory;\n+    private final LineTcpMeasurementScheduler scheduler;\n+    private final ObjList<LineTcpConnectionContext> busyContexts = new ObjList<>();\n+\n+    public LineTcpServer(\n+            CairoConfiguration cairoConfiguration,\n+            LineTcpReceiverConfiguration lineConfiguration,\n+            CairoEngine engine,\n+            WorkerPool workerPool,\n+            MessageBus messageBus\n+    ) {\n+        this.contextFactory = new LineTcpConnectionContextFactory(engine, lineConfiguration, messageBus, workerPool.getWorkerCount());\n+        this.dispatcher = IODispatchers.create(\n+                lineConfiguration\n+                        .getNetDispatcherConfiguration(),\n+                contextFactory);\n+        workerPool.assign(dispatcher);\n+        scheduler = new LineTcpMeasurementScheduler(cairoConfiguration, lineConfiguration, engine, workerPool);\n+        final IORequestProcessor<LineTcpConnectionContext> processor = (operation, context) -> {\n+            if (context.handleIO()) {\n+                busyContexts.add(context);\n+            }\n+        };\n+        workerPool.assign(new SynchronizedJob() {\n+            @Override\n+            protected boolean runSerially() {\n+                int n = busyContexts.size();\n+                while (n > 0) {\n+                    n--;\n+                    if (!busyContexts.getQuick(n).handleIO()) {\n+                        busyContexts.remove(n);\n+                    }\n+                }\n+                return dispatcher.processIOQueue(processor);\n+            }\n+        });\n+\n+        for (int i = 0, n = workerPool.getWorkerCount(); i < n; i++) {\n+            // http context factory has thread local pools\n+            // therefore we need each thread to clean their thread locals individually\n+            workerPool.assign(i, () -> {\n+                contextFactory.closeContextPool();\n+            });\n+        }\n+    }\n+\n+    @Override\n+    public void close() {\n+        Misc.free(scheduler);\n+        Misc.free(contextFactory);\n+        Misc.free(dispatcher);\n+    }\n+\n+    private class LineTcpConnectionContextFactory implements IOContextFactory<LineTcpConnectionContext>, Closeable, EagerThreadSetup {\n+        private final ThreadLocal<WeakObjectPool<LineTcpConnectionContext>> contextPool;\n+        private boolean closed = false;\n+\n+        public LineTcpConnectionContextFactory(CairoEngine engine, LineTcpReceiverConfiguration configuration, @Nullable MessageBus messageBus, int workerCount) {\n+            this.contextPool = new ThreadLocal<>(\n+                    () -> new WeakObjectPool<>(() -> new LineTcpConnectionContext(configuration, scheduler, engine.getConfiguration().getMillisecondClock()),\n+                            configuration.getConnectionPoolInitialCapacity()));\n+        }\n+\n+        @Override\n+        public void setup() {\n+            contextPool.get();\n+        }\n+\n+        @Override\n+        public void close() throws IOException {", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk4Mjg3OQ==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448982879", "bodyText": "When queue is full, we should put backpressure on TCP stack. Right now we will start filling up busyContexts list, which does not feel right.\nI would like to suggest cache last context we could not put on the queue and stay on it until it goes away. Only then call dispatcher.processIOQueue()", "author": "bluestreak01", "createdAt": "2020-07-02T12:59:41Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpServer.java", "diffHunk": "@@ -0,0 +1,150 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+\n+import org.jetbrains.annotations.Nullable;\n+\n+import io.questdb.MessageBus;\n+import io.questdb.WorkerPoolAwareConfiguration;\n+import io.questdb.WorkerPoolAwareConfiguration.ServerFactory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.EagerThreadSetup;\n+import io.questdb.mp.SynchronizedJob;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.network.IOContextFactory;\n+import io.questdb.network.IODispatcher;\n+import io.questdb.network.IODispatchers;\n+import io.questdb.network.IORequestProcessor;\n+import io.questdb.std.Misc;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.ThreadLocal;\n+import io.questdb.std.WeakObjectPool;\n+\n+public class LineTcpServer implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpServer.class);\n+\n+    @Nullable\n+    public static LineTcpServer create(\n+            CairoConfiguration cairoConfiguration,\n+            LineTcpReceiverConfiguration lineConfiguration,\n+            WorkerPool sharedWorkerPool,\n+            Log log,\n+            CairoEngine cairoEngine,\n+            MessageBus messageBus\n+    ) {\n+        if (!lineConfiguration.isEnabled()) {\n+            return null;\n+        }\n+\n+        ServerFactory<LineTcpServer, WorkerPoolAwareConfiguration> factory = (netWorkerPoolConfiguration, engine, workerPool, local, bus,\n+                functionfactory) -> new LineTcpServer(\n+                        cairoConfiguration,\n+                        lineConfiguration,\n+                        cairoEngine,\n+                        workerPool,\n+                        bus);\n+        LineTcpServer server = WorkerPoolAwareConfiguration.create(lineConfiguration.getWorkerPoolConfiguration(), sharedWorkerPool, log, cairoEngine, factory, messageBus, null);\n+        return server;\n+    }\n+\n+    private final IODispatcher<LineTcpConnectionContext> dispatcher;\n+    private final LineTcpConnectionContextFactory contextFactory;\n+    private final LineTcpMeasurementScheduler scheduler;\n+    private final ObjList<LineTcpConnectionContext> busyContexts = new ObjList<>();\n+\n+    public LineTcpServer(\n+            CairoConfiguration cairoConfiguration,\n+            LineTcpReceiverConfiguration lineConfiguration,\n+            CairoEngine engine,\n+            WorkerPool workerPool,\n+            MessageBus messageBus\n+    ) {\n+        this.contextFactory = new LineTcpConnectionContextFactory(engine, lineConfiguration, messageBus, workerPool.getWorkerCount());\n+        this.dispatcher = IODispatchers.create(\n+                lineConfiguration\n+                        .getNetDispatcherConfiguration(),\n+                contextFactory);\n+        workerPool.assign(dispatcher);\n+        scheduler = new LineTcpMeasurementScheduler(cairoConfiguration, lineConfiguration, engine, workerPool);\n+        final IORequestProcessor<LineTcpConnectionContext> processor = (operation, context) -> {\n+            if (context.handleIO()) {\n+                busyContexts.add(context);", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTU0Mjk2NA==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r449542964", "bodyText": "We do need to maintain a list, because once the context cant get a queue event it no longer registers with the despatcher. However, I have changed the code to not call the dispatcher.processIOQueue() until there queue is not blocked.", "author": "patrickSpaceSurfer", "createdAt": "2020-07-03T11:51:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk4Mjg3OQ=="}], "type": "inlineReview"}, {"oid": "0d4cb369d689e010b841a6449c591e194c591ad8", "url": "https://github.com/questdb/questdb/commit/0d4cb369d689e010b841a6449c591e194c591ad8", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-03T08:56:22Z", "type": "commit"}, {"oid": "a60f02bf0d674c400141d05c9887434c513d739b", "url": "https://github.com/questdb/questdb/commit/a60f02bf0d674c400141d05c9887434c513d739b", "message": "chore: Fix logging", "committedDate": "2020-07-03T10:39:27Z", "type": "commit"}, {"oid": "bae8e79d437385f144130e81b6d362f96d324614", "url": "https://github.com/questdb/questdb/commit/bae8e79d437385f144130e81b6d362f96d324614", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-03T12:01:42Z", "type": "commit"}, {"oid": "18b0fa6ae740bf722987bf0a94e1ef506f00ba51", "url": "https://github.com/questdb/questdb/commit/18b0fa6ae740bf722987bf0a94e1ef506f00ba51", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-03T12:10:06Z", "type": "commit"}, {"oid": "9b6b34fd474aa5a0fdc68716ddefda630048b7fe", "url": "https://github.com/questdb/questdb/commit/9b6b34fd474aa5a0fdc68716ddefda630048b7fe", "message": "Merge remote-tracking branch 'origin/master' into tcp-line", "committedDate": "2020-07-03T12:15:24Z", "type": "commit"}, {"oid": "6d30c4340cb3486b9810d1059d5cd1a1194ca285", "url": "https://github.com/questdb/questdb/commit/6d30c4340cb3486b9810d1059d5cd1a1194ca285", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-03T14:33:34Z", "type": "commit"}, {"oid": "37fedc698406b47427a3a4f8658cde1e6aee01b9", "url": "https://github.com/questdb/questdb/commit/37fedc698406b47427a3a4f8658cde1e6aee01b9", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-03T17:39:02Z", "type": "commit"}, {"oid": "2d4cb18f5ccaefc27d96f6a9a4bf6fe31859e0e3", "url": "https://github.com/questdb/questdb/commit/2d4cb18f5ccaefc27d96f6a9a4bf6fe31859e0e3", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-03T21:07:14Z", "type": "commit"}, {"oid": "72c907453a86e33dc990a5c16fef5791921b5ce7", "url": "https://github.com/questdb/questdb/commit/72c907453a86e33dc990a5c16fef5791921b5ce7", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-06T10:08:29Z", "type": "commit"}, {"oid": "7aedf3bcefb15950003092da621bf23c9907cd59", "url": "https://github.com/questdb/questdb/commit/7aedf3bcefb15950003092da621bf23c9907cd59", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-06T10:25:16Z", "type": "commit"}, {"oid": "fd5b6bc5a6f61a23a331a396a592adea6def32a6", "url": "https://github.com/questdb/questdb/commit/fd5b6bc5a6f61a23a331a396a592adea6def32a6", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-06T10:29:01Z", "type": "commit"}, {"oid": "aa23c1e18821c47aac4ea13fc4cdeffd4c773d71", "url": "https://github.com/questdb/questdb/commit/aa23c1e18821c47aac4ea13fc4cdeffd4c773d71", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-06T12:27:05Z", "type": "commit"}, {"oid": "fb241985c325fa70ff7173e42eaaeac170cb36c6", "url": "https://github.com/questdb/questdb/commit/fb241985c325fa70ff7173e42eaaeac170cb36c6", "message": "chore(cairo): code cleanup", "committedDate": "2020-07-06T16:31:12Z", "type": "commit"}]}