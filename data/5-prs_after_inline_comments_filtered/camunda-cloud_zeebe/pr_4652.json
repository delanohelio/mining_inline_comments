{"pr_number": 4652, "pr_title": "Gateway do not send requests to non-available partitions", "pr_createdAt": "2020-06-02T14:21:00Z", "pr_url": "https://github.com/camunda-cloud/zeebe/pull/4652", "timeline": [{"oid": "03614a3f2bf037804199d990ce67f81790ab25ac", "url": "https://github.com/camunda-cloud/zeebe/commit/03614a3f2bf037804199d990ce67f81790ab25ac", "message": "chore(transport): do not retry request when specified", "committedDate": "2020-06-02T09:45:38Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDM5MzkxNg==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r434393916", "bodyText": "Maybe we can improve a little here and tell the user what they can do? e.g. \"Check the gateway logs for errors\" or some such.", "author": "npepinpe", "createdAt": "2020-06-03T08:23:45Z", "path": "gateway/src/main/java/io/zeebe/gateway/impl/broker/RequestRetryFailedException.java", "diffHunk": "@@ -0,0 +1,18 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.gateway.impl.broker;\n+\n+import io.zeebe.gateway.cmd.ClientException;\n+\n+class RequestRetryFailedException extends ClientException {\n+\n+  RequestRetryFailedException() {\n+    super(\n+        \"Expected to execute the command on one of the partitions, but all failed; no partition left to retry.\");", "originalCommit": "c444addd0b0f21ed224ee45592d0aea311eb6d1a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjU1MTAzOQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r436551039", "bodyText": "Users probably don't have access to the gateway logs, right?", "author": "deepthidevaki", "createdAt": "2020-06-08T09:00:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDM5MzkxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDM5NjQwMg==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r434396402", "bodyText": "Should we rename this? From the name I expected something different, e.g. a retry failed, but here it's that we exhausted all partitions. PartitionsExhaustedException? Or we could still use PartitionNotFoundException but with a clearer message specifying we could not find a partition on which to execute this command successfully.", "author": "npepinpe", "createdAt": "2020-06-03T08:27:43Z", "path": "gateway/src/main/java/io/zeebe/gateway/impl/broker/RequestRetryFailedException.java", "diffHunk": "@@ -0,0 +1,18 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.gateway.impl.broker;\n+\n+import io.zeebe.gateway.cmd.ClientException;\n+\n+class RequestRetryFailedException extends ClientException {", "originalCommit": "c444addd0b0f21ed224ee45592d0aea311eb6d1a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDYyODg1Mw==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r434628853", "bodyText": "Not sure if \"PartitionNotFound\" is the right exception here. What we want to convey to the user is the request failed even after multiple retries. If all retries returns resource exhausted, is it really partition not found?  But I agree that the current message is also not clear.", "author": "deepthidevaki", "createdAt": "2020-06-03T14:52:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDM5NjQwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTMzMDk2MQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r435330961", "bodyText": "Yeah, was just an idea \ud83d\ude05 RequestRetriesExhaustedException is also ok? I think for me it was more than RequestRetryFailed sounds like a single request, when what we mean is we have no more \"retries\" left.", "author": "npepinpe", "createdAt": "2020-06-04T15:05:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDM5NjQwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjU1MTA5OQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r436551099", "bodyText": "RequestRetriedExhaustedException sounds good.", "author": "deepthidevaki", "createdAt": "2020-06-08T09:00:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDM5NjQwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDM5NzY4MA==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r434397680", "bodyText": "Is there a reason this is not final anymore?", "author": "npepinpe", "createdAt": "2020-06-03T08:29:48Z", "path": "gateway/src/main/java/io/zeebe/gateway/impl/broker/PartitionIdIterator.java", "diffHunk": "@@ -5,26 +5,40 @@\n  * Licensed under the Zeebe Community License 1.0. You may not use this file\n  * except in compliance with the Zeebe Community License 1.0.\n  */\n-package io.zeebe.gateway.impl.job;\n+package io.zeebe.gateway.impl.broker;\n \n import static io.zeebe.protocol.Protocol.START_PARTITION_ID;\n \n+import io.zeebe.gateway.impl.broker.cluster.BrokerClusterState;\n+import io.zeebe.gateway.impl.broker.cluster.BrokerTopologyManager;\n import java.util.Iterator;\n import java.util.PrimitiveIterator.OfInt;\n import java.util.stream.IntStream;\n \n-public final class PartitionIdIterator implements Iterator<Integer> {\n+public class PartitionIdIterator implements Iterator<Integer> {", "originalCommit": "c444addd0b0f21ed224ee45592d0aea311eb6d1a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDM5NzgzOA==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r434397838", "bodyText": "Any reason this isn't final? Also the name is quite generic - what does this class do? It handles retrying requests, but that doesn't tell me much \ud83d\ude09", "author": "npepinpe", "createdAt": "2020-06-03T08:30:04Z", "path": "gateway/src/main/java/io/zeebe/gateway/impl/broker/RequestRetryHandler.java", "diffHunk": "@@ -0,0 +1,140 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.gateway.impl.broker;\n+\n+import io.zeebe.gateway.Loggers;\n+import io.zeebe.gateway.cmd.BrokerErrorException;\n+import io.zeebe.gateway.impl.broker.cluster.BrokerTopologyManager;\n+import io.zeebe.gateway.impl.broker.request.BrokerRequest;\n+import io.zeebe.gateway.impl.broker.response.BrokerResponse;\n+import io.zeebe.protocol.record.ErrorCode;\n+import java.net.ConnectException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+\n+public class RequestRetryHandler {", "originalCommit": "c444addd0b0f21ed224ee45592d0aea311eb6d1a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjU1MTMzNg==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r436551336", "bodyText": "Added some description for the class.", "author": "deepthidevaki", "createdAt": "2020-06-08T09:00:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDM5NzgzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQwMDk0OQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r434400949", "bodyText": "We use this signature in several places (the Function<BrokerRequest<T>, CompletableFuture<BrokerResponse<T>>). Should we extract this to a functional interface, e.g. AsyncBrokerRequestSender or some such? I would propose to even have it be more like\n@FunctionalInterface\npublic interface AsyncBrokerRequestSender {\n  <T> CompletableFuture<BrokerResponse<T>> sendBrokerRequest(final BrokerClient client, final BrokerRequest<T> request);\n}\nWhat do you think? This might also help get rid of the boolean arguments in the BrokerRequestManager (maybe?).", "author": "npepinpe", "createdAt": "2020-06-03T08:35:15Z", "path": "gateway/src/main/java/io/zeebe/gateway/impl/broker/RequestRetryHandler.java", "diffHunk": "@@ -0,0 +1,140 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.gateway.impl.broker;\n+\n+import io.zeebe.gateway.Loggers;\n+import io.zeebe.gateway.cmd.BrokerErrorException;\n+import io.zeebe.gateway.impl.broker.cluster.BrokerTopologyManager;\n+import io.zeebe.gateway.impl.broker.request.BrokerRequest;\n+import io.zeebe.gateway.impl.broker.response.BrokerResponse;\n+import io.zeebe.protocol.record.ErrorCode;\n+import java.net.ConnectException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+\n+public class RequestRetryHandler {\n+\n+  private final BrokerClient brokerClient;\n+  private final RoundRobinDispatchStrategy roundRobinDispatchStrategy;\n+  private final BrokerTopologyManager topologyManager;\n+\n+  public RequestRetryHandler(\n+      final BrokerClient brokerClient, final BrokerTopologyManager topologyManager) {\n+    this.brokerClient = brokerClient;\n+    roundRobinDispatchStrategy = new RoundRobinDispatchStrategy(topologyManager);\n+    this.topologyManager = topologyManager;\n+  }\n+\n+  public <BrokerResponseT> void sendRequest(\n+      final BrokerRequest<BrokerResponseT> request,\n+      final BrokerResponseConsumer<BrokerResponseT> responseConsumer,\n+      final Consumer<Throwable> throwableConsumer) {\n+    final Function<\n+            BrokerRequest<BrokerResponseT>, CompletableFuture<BrokerResponse<BrokerResponseT>>>\n+        requestSender = r -> brokerClient.sendRequest(r, false);\n+    sendRequestInternal(request, requestSender, responseConsumer, throwableConsumer);\n+  }\n+\n+  public <BrokerResponseT> void sendRequest(\n+      final BrokerRequest<BrokerResponseT> request,\n+      final BrokerResponseConsumer<BrokerResponseT> responseConsumer,\n+      final Consumer<Throwable> throwableConsumer,\n+      final Duration requestTimeout) {\n+    final Function<", "originalCommit": "c444addd0b0f21ed224ee45592d0aea311eb6d1a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDYzMDIzOQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r434630239", "bodyText": "It's used only internally in this class at two places. I don't think we can reuse the interface in BrokerRequestManager as it is operating at different abstraction.", "author": "deepthidevaki", "createdAt": "2020-06-03T14:54:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQwMDk0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTMzMjQ4MA==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r435332480", "bodyText": "I know it's not used in the request manager, but I thought it might be reused there to avoid using boolean arguments (just an idea, not sure it'd be the best anyhow).\nAlso I see it used 4 times in this file? What did you mean by 2?", "author": "npepinpe", "createdAt": "2020-06-04T15:07:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQwMDk0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjU1MjE2NQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r436552165", "bodyText": "Ya. There are 4. But it's all internal to this class.", "author": "deepthidevaki", "createdAt": "2020-06-08T09:02:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQwMDk0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzIyNDE2Mg==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r437224162", "bodyText": "I find having specific types easier to understand and faster to refactor, as function is pretty generic, but I get that Java doesn't have the concept of type aliasing, so it means creating a new interface/class. I'm not going to insist more if you feel strongly about it, as I don't have strong objective arguments \ud83d\ude42", "author": "npepinpe", "createdAt": "2020-06-09T08:22:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQwMDk0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQwNjY4OQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r434406689", "bodyText": "If there is no topology, nothing happens, right? So what happens to the gRPC request that triggered this? It is just left hanging, and eventually times out?", "author": "npepinpe", "createdAt": "2020-06-03T08:44:56Z", "path": "gateway/src/main/java/io/zeebe/gateway/impl/broker/RequestRetryHandler.java", "diffHunk": "@@ -0,0 +1,140 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.gateway.impl.broker;\n+\n+import io.zeebe.gateway.Loggers;\n+import io.zeebe.gateway.cmd.BrokerErrorException;\n+import io.zeebe.gateway.impl.broker.cluster.BrokerTopologyManager;\n+import io.zeebe.gateway.impl.broker.request.BrokerRequest;\n+import io.zeebe.gateway.impl.broker.response.BrokerResponse;\n+import io.zeebe.protocol.record.ErrorCode;\n+import java.net.ConnectException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+\n+public class RequestRetryHandler {\n+\n+  private final BrokerClient brokerClient;\n+  private final RoundRobinDispatchStrategy roundRobinDispatchStrategy;\n+  private final BrokerTopologyManager topologyManager;\n+\n+  public RequestRetryHandler(\n+      final BrokerClient brokerClient, final BrokerTopologyManager topologyManager) {\n+    this.brokerClient = brokerClient;\n+    roundRobinDispatchStrategy = new RoundRobinDispatchStrategy(topologyManager);\n+    this.topologyManager = topologyManager;\n+  }\n+\n+  public <BrokerResponseT> void sendRequest(\n+      final BrokerRequest<BrokerResponseT> request,\n+      final BrokerResponseConsumer<BrokerResponseT> responseConsumer,\n+      final Consumer<Throwable> throwableConsumer) {\n+    final Function<\n+            BrokerRequest<BrokerResponseT>, CompletableFuture<BrokerResponse<BrokerResponseT>>>\n+        requestSender = r -> brokerClient.sendRequest(r, false);\n+    sendRequestInternal(request, requestSender, responseConsumer, throwableConsumer);\n+  }\n+\n+  public <BrokerResponseT> void sendRequest(\n+      final BrokerRequest<BrokerResponseT> request,\n+      final BrokerResponseConsumer<BrokerResponseT> responseConsumer,\n+      final Consumer<Throwable> throwableConsumer,\n+      final Duration requestTimeout) {\n+    final Function<\n+            BrokerRequest<BrokerResponseT>, CompletableFuture<BrokerResponse<BrokerResponseT>>>\n+        requestSender = r -> brokerClient.sendRequest(r, false, requestTimeout);\n+    sendRequestInternal(request, requestSender, responseConsumer, throwableConsumer);\n+  }\n+\n+  private <BrokerResponseT> void sendRequestInternal(\n+      final BrokerRequest<BrokerResponseT> request,\n+      final Function<\n+              BrokerRequest<BrokerResponseT>, CompletableFuture<BrokerResponse<BrokerResponseT>>>\n+          requestSender,\n+      final BrokerResponseConsumer<BrokerResponseT> responseConsumer,\n+      final Consumer<Throwable> throwableConsumer) {\n+    final var topology = topologyManager.getTopology();\n+    if (topology != null) {", "originalCommit": "c444addd0b0f21ed224ee45592d0aea311eb6d1a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDYzMzUxMA==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r434633510", "bodyText": "Right. Nothing happens now and grpc request times out eventually. May be we can return a topology NOT_FOUND here.", "author": "deepthidevaki", "createdAt": "2020-06-03T14:59:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQwNjY4OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTMzMzI0MQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r435333241", "bodyText": "Hm, not sure. Is this what we return, NOT_FOUND, when there is no leader for a given partition? If so then yes, let's do that. If we know we can't do anything then let's immediately quit instead of waiting for a time out.", "author": "npepinpe", "createdAt": "2020-06-04T15:08:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQwNjY4OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjU1MzQwNA==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r436553404", "bodyText": "For other requests, they timeout eventually while transport is trying to find the leader. So the response will be timeout. But here I now added 'NoTopologyAvailableException'", "author": "deepthidevaki", "createdAt": "2020-06-08T09:04:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQwNjY4OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQxMzc3Ng==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r434413776", "bodyText": "Nice, we should use addSuppressed more :)", "author": "npepinpe", "createdAt": "2020-06-03T08:56:41Z", "path": "gateway/src/main/java/io/zeebe/gateway/impl/broker/RequestRetryHandler.java", "diffHunk": "@@ -0,0 +1,140 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.gateway.impl.broker;\n+\n+import io.zeebe.gateway.Loggers;\n+import io.zeebe.gateway.cmd.BrokerErrorException;\n+import io.zeebe.gateway.impl.broker.cluster.BrokerTopologyManager;\n+import io.zeebe.gateway.impl.broker.request.BrokerRequest;\n+import io.zeebe.gateway.impl.broker.response.BrokerResponse;\n+import io.zeebe.protocol.record.ErrorCode;\n+import java.net.ConnectException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+\n+public class RequestRetryHandler {\n+\n+  private final BrokerClient brokerClient;\n+  private final RoundRobinDispatchStrategy roundRobinDispatchStrategy;\n+  private final BrokerTopologyManager topologyManager;\n+\n+  public RequestRetryHandler(\n+      final BrokerClient brokerClient, final BrokerTopologyManager topologyManager) {\n+    this.brokerClient = brokerClient;\n+    roundRobinDispatchStrategy = new RoundRobinDispatchStrategy(topologyManager);\n+    this.topologyManager = topologyManager;\n+  }\n+\n+  public <BrokerResponseT> void sendRequest(\n+      final BrokerRequest<BrokerResponseT> request,\n+      final BrokerResponseConsumer<BrokerResponseT> responseConsumer,\n+      final Consumer<Throwable> throwableConsumer) {\n+    final Function<\n+            BrokerRequest<BrokerResponseT>, CompletableFuture<BrokerResponse<BrokerResponseT>>>\n+        requestSender = r -> brokerClient.sendRequest(r, false);\n+    sendRequestInternal(request, requestSender, responseConsumer, throwableConsumer);\n+  }\n+\n+  public <BrokerResponseT> void sendRequest(\n+      final BrokerRequest<BrokerResponseT> request,\n+      final BrokerResponseConsumer<BrokerResponseT> responseConsumer,\n+      final Consumer<Throwable> throwableConsumer,\n+      final Duration requestTimeout) {\n+    final Function<\n+            BrokerRequest<BrokerResponseT>, CompletableFuture<BrokerResponse<BrokerResponseT>>>\n+        requestSender = r -> brokerClient.sendRequest(r, false, requestTimeout);\n+    sendRequestInternal(request, requestSender, responseConsumer, throwableConsumer);\n+  }\n+\n+  private <BrokerResponseT> void sendRequestInternal(\n+      final BrokerRequest<BrokerResponseT> request,\n+      final Function<\n+              BrokerRequest<BrokerResponseT>, CompletableFuture<BrokerResponse<BrokerResponseT>>>\n+          requestSender,\n+      final BrokerResponseConsumer<BrokerResponseT> responseConsumer,\n+      final Consumer<Throwable> throwableConsumer) {\n+    final var topology = topologyManager.getTopology();\n+    if (topology != null) {\n+      sendRequestWithRetry(\n+          request,\n+          requestSender,\n+          partitionIdIteratorForType(topology.getPartitionsCount()),\n+          responseConsumer,\n+          throwableConsumer,\n+          new ArrayList<>());\n+    }\n+  }\n+\n+  private <BrokerResponseT> void sendRequestWithRetry(\n+      final BrokerRequest<BrokerResponseT> request,\n+      final Function<\n+              BrokerRequest<BrokerResponseT>, CompletableFuture<BrokerResponse<BrokerResponseT>>>\n+          requestSender,\n+      final PartitionIdIterator partitionIdIterator,\n+      final BrokerResponseConsumer<BrokerResponseT> responseConsumer,\n+      final Consumer<Throwable> throwableConsumer,\n+      final Collection<Throwable> errors) {\n+\n+    if (partitionIdIterator.hasNext()) {\n+      final int partitionId = partitionIdIterator.next();\n+\n+      // partitions to check\n+      request.setPartitionId(partitionId);\n+      requestSender\n+          .apply(request)\n+          .whenComplete(\n+              (response, error) -> {\n+                if (error == null) {\n+                  responseConsumer.accept(response.getKey(), response.getResponse());\n+                } else {\n+                  if (shouldRetryWithNextPartition(error)) {\n+                    Loggers.GATEWAY_LOGGER.trace(\n+                        \"Failed to create workflow on partition {}\",\n+                        partitionIdIterator.getCurrentPartitionId(),\n+                        error);\n+                    errors.add(error);\n+                    sendRequestWithRetry(\n+                        request,\n+                        requestSender,\n+                        partitionIdIterator,\n+                        responseConsumer,\n+                        throwableConsumer,\n+                        errors);\n+                  } else {\n+                    throwableConsumer.accept(error);\n+                  }\n+                }\n+              });\n+    } else {\n+      // no partition left to check\n+      final var exception = new RequestRetryFailedException();\n+      errors.forEach(exception::addSuppressed);", "originalCommit": "c444addd0b0f21ed224ee45592d0aea311eb6d1a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQxNTI5OA==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r434415298", "bodyText": "this can probably be combined as if (error == null) { ... } else if (shouldRetryWithNextPartition(error)) { ... } else { ... }", "author": "npepinpe", "createdAt": "2020-06-03T08:58:59Z", "path": "gateway/src/main/java/io/zeebe/gateway/impl/broker/RequestRetryHandler.java", "diffHunk": "@@ -0,0 +1,140 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.gateway.impl.broker;\n+\n+import io.zeebe.gateway.Loggers;\n+import io.zeebe.gateway.cmd.BrokerErrorException;\n+import io.zeebe.gateway.impl.broker.cluster.BrokerTopologyManager;\n+import io.zeebe.gateway.impl.broker.request.BrokerRequest;\n+import io.zeebe.gateway.impl.broker.response.BrokerResponse;\n+import io.zeebe.protocol.record.ErrorCode;\n+import java.net.ConnectException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+\n+public class RequestRetryHandler {\n+\n+  private final BrokerClient brokerClient;\n+  private final RoundRobinDispatchStrategy roundRobinDispatchStrategy;\n+  private final BrokerTopologyManager topologyManager;\n+\n+  public RequestRetryHandler(\n+      final BrokerClient brokerClient, final BrokerTopologyManager topologyManager) {\n+    this.brokerClient = brokerClient;\n+    roundRobinDispatchStrategy = new RoundRobinDispatchStrategy(topologyManager);\n+    this.topologyManager = topologyManager;\n+  }\n+\n+  public <BrokerResponseT> void sendRequest(\n+      final BrokerRequest<BrokerResponseT> request,\n+      final BrokerResponseConsumer<BrokerResponseT> responseConsumer,\n+      final Consumer<Throwable> throwableConsumer) {\n+    final Function<\n+            BrokerRequest<BrokerResponseT>, CompletableFuture<BrokerResponse<BrokerResponseT>>>\n+        requestSender = r -> brokerClient.sendRequest(r, false);\n+    sendRequestInternal(request, requestSender, responseConsumer, throwableConsumer);\n+  }\n+\n+  public <BrokerResponseT> void sendRequest(\n+      final BrokerRequest<BrokerResponseT> request,\n+      final BrokerResponseConsumer<BrokerResponseT> responseConsumer,\n+      final Consumer<Throwable> throwableConsumer,\n+      final Duration requestTimeout) {\n+    final Function<\n+            BrokerRequest<BrokerResponseT>, CompletableFuture<BrokerResponse<BrokerResponseT>>>\n+        requestSender = r -> brokerClient.sendRequest(r, false, requestTimeout);\n+    sendRequestInternal(request, requestSender, responseConsumer, throwableConsumer);\n+  }\n+\n+  private <BrokerResponseT> void sendRequestInternal(\n+      final BrokerRequest<BrokerResponseT> request,\n+      final Function<\n+              BrokerRequest<BrokerResponseT>, CompletableFuture<BrokerResponse<BrokerResponseT>>>\n+          requestSender,\n+      final BrokerResponseConsumer<BrokerResponseT> responseConsumer,\n+      final Consumer<Throwable> throwableConsumer) {\n+    final var topology = topologyManager.getTopology();\n+    if (topology != null) {\n+      sendRequestWithRetry(\n+          request,\n+          requestSender,\n+          partitionIdIteratorForType(topology.getPartitionsCount()),\n+          responseConsumer,\n+          throwableConsumer,\n+          new ArrayList<>());\n+    }\n+  }\n+\n+  private <BrokerResponseT> void sendRequestWithRetry(\n+      final BrokerRequest<BrokerResponseT> request,\n+      final Function<\n+              BrokerRequest<BrokerResponseT>, CompletableFuture<BrokerResponse<BrokerResponseT>>>\n+          requestSender,\n+      final PartitionIdIterator partitionIdIterator,\n+      final BrokerResponseConsumer<BrokerResponseT> responseConsumer,\n+      final Consumer<Throwable> throwableConsumer,\n+      final Collection<Throwable> errors) {\n+\n+    if (partitionIdIterator.hasNext()) {\n+      final int partitionId = partitionIdIterator.next();\n+\n+      // partitions to check\n+      request.setPartitionId(partitionId);\n+      requestSender\n+          .apply(request)\n+          .whenComplete(\n+              (response, error) -> {\n+                if (error == null) {\n+                  responseConsumer.accept(response.getKey(), response.getResponse());\n+                } else {\n+                  if (shouldRetryWithNextPartition(error)) {", "originalCommit": "c444addd0b0f21ed224ee45592d0aea311eb6d1a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQxNTg0NA==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r434415844", "bodyText": "Can we declare a variable for the code here?", "author": "npepinpe", "createdAt": "2020-06-03T08:59:48Z", "path": "gateway/src/main/java/io/zeebe/gateway/impl/broker/RequestRetryHandler.java", "diffHunk": "@@ -0,0 +1,140 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.gateway.impl.broker;\n+\n+import io.zeebe.gateway.Loggers;\n+import io.zeebe.gateway.cmd.BrokerErrorException;\n+import io.zeebe.gateway.impl.broker.cluster.BrokerTopologyManager;\n+import io.zeebe.gateway.impl.broker.request.BrokerRequest;\n+import io.zeebe.gateway.impl.broker.response.BrokerResponse;\n+import io.zeebe.protocol.record.ErrorCode;\n+import java.net.ConnectException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+\n+public class RequestRetryHandler {\n+\n+  private final BrokerClient brokerClient;\n+  private final RoundRobinDispatchStrategy roundRobinDispatchStrategy;\n+  private final BrokerTopologyManager topologyManager;\n+\n+  public RequestRetryHandler(\n+      final BrokerClient brokerClient, final BrokerTopologyManager topologyManager) {\n+    this.brokerClient = brokerClient;\n+    roundRobinDispatchStrategy = new RoundRobinDispatchStrategy(topologyManager);\n+    this.topologyManager = topologyManager;\n+  }\n+\n+  public <BrokerResponseT> void sendRequest(\n+      final BrokerRequest<BrokerResponseT> request,\n+      final BrokerResponseConsumer<BrokerResponseT> responseConsumer,\n+      final Consumer<Throwable> throwableConsumer) {\n+    final Function<\n+            BrokerRequest<BrokerResponseT>, CompletableFuture<BrokerResponse<BrokerResponseT>>>\n+        requestSender = r -> brokerClient.sendRequest(r, false);\n+    sendRequestInternal(request, requestSender, responseConsumer, throwableConsumer);\n+  }\n+\n+  public <BrokerResponseT> void sendRequest(\n+      final BrokerRequest<BrokerResponseT> request,\n+      final BrokerResponseConsumer<BrokerResponseT> responseConsumer,\n+      final Consumer<Throwable> throwableConsumer,\n+      final Duration requestTimeout) {\n+    final Function<\n+            BrokerRequest<BrokerResponseT>, CompletableFuture<BrokerResponse<BrokerResponseT>>>\n+        requestSender = r -> brokerClient.sendRequest(r, false, requestTimeout);\n+    sendRequestInternal(request, requestSender, responseConsumer, throwableConsumer);\n+  }\n+\n+  private <BrokerResponseT> void sendRequestInternal(\n+      final BrokerRequest<BrokerResponseT> request,\n+      final Function<\n+              BrokerRequest<BrokerResponseT>, CompletableFuture<BrokerResponse<BrokerResponseT>>>\n+          requestSender,\n+      final BrokerResponseConsumer<BrokerResponseT> responseConsumer,\n+      final Consumer<Throwable> throwableConsumer) {\n+    final var topology = topologyManager.getTopology();\n+    if (topology != null) {\n+      sendRequestWithRetry(\n+          request,\n+          requestSender,\n+          partitionIdIteratorForType(topology.getPartitionsCount()),\n+          responseConsumer,\n+          throwableConsumer,\n+          new ArrayList<>());\n+    }\n+  }\n+\n+  private <BrokerResponseT> void sendRequestWithRetry(\n+      final BrokerRequest<BrokerResponseT> request,\n+      final Function<\n+              BrokerRequest<BrokerResponseT>, CompletableFuture<BrokerResponse<BrokerResponseT>>>\n+          requestSender,\n+      final PartitionIdIterator partitionIdIterator,\n+      final BrokerResponseConsumer<BrokerResponseT> responseConsumer,\n+      final Consumer<Throwable> throwableConsumer,\n+      final Collection<Throwable> errors) {\n+\n+    if (partitionIdIterator.hasNext()) {\n+      final int partitionId = partitionIdIterator.next();\n+\n+      // partitions to check\n+      request.setPartitionId(partitionId);\n+      requestSender\n+          .apply(request)\n+          .whenComplete(\n+              (response, error) -> {\n+                if (error == null) {\n+                  responseConsumer.accept(response.getKey(), response.getResponse());\n+                } else {\n+                  if (shouldRetryWithNextPartition(error)) {\n+                    Loggers.GATEWAY_LOGGER.trace(\n+                        \"Failed to create workflow on partition {}\",\n+                        partitionIdIterator.getCurrentPartitionId(),\n+                        error);\n+                    errors.add(error);\n+                    sendRequestWithRetry(\n+                        request,\n+                        requestSender,\n+                        partitionIdIterator,\n+                        responseConsumer,\n+                        throwableConsumer,\n+                        errors);\n+                  } else {\n+                    throwableConsumer.accept(error);\n+                  }\n+                }\n+              });\n+    } else {\n+      // no partition left to check\n+      final var exception = new RequestRetryFailedException();\n+      errors.forEach(exception::addSuppressed);\n+      throwableConsumer.accept(exception);\n+    }\n+  }\n+\n+  private boolean shouldRetryWithNextPartition(final Throwable error) {\n+    if (error instanceof ConnectException) {\n+      return true;\n+    } else if (error instanceof BrokerErrorException) {\n+      return ((BrokerErrorException) error).getError().getCode()\n+              == ErrorCode.PARTITION_LEADER_MISMATCH\n+          || ((BrokerErrorException) error).getError().getCode() == ErrorCode.RESOURCE_EXHAUSTED;", "originalCommit": "c444addd0b0f21ed224ee45592d0aea311eb6d1a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ5MDI1Nw==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r434490257", "bodyText": "If we don't need a different broker every time, we can use a ClassRule, no?", "author": "npepinpe", "createdAt": "2020-06-03T11:13:29Z", "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/clustering/AvailabilityTest.java", "diffHunk": "@@ -0,0 +1,175 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.clustering;\n+\n+import static io.zeebe.test.util.TestUtil.waitUntil;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import io.zeebe.broker.it.util.GrpcClientRule;\n+import io.zeebe.client.api.response.ActivatedJob;\n+import io.zeebe.client.api.response.BrokerInfo;\n+import io.zeebe.model.bpmn.Bpmn;\n+import io.zeebe.model.bpmn.BpmnModelInstance;\n+import io.zeebe.protocol.record.Record;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceCreationIntent;\n+import io.zeebe.test.util.record.RecordingExporter;\n+import java.time.Duration;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.RuleChain;\n+import org.junit.rules.Timeout;\n+\n+public class AvailabilityTest {\n+\n+  private static final String JOBTYPE = \"availability-test\";\n+  private static final BpmnModelInstance WORKFLOW =\n+      Bpmn.createExecutableProcess(\"process\")\n+          .startEvent()\n+          .serviceTask(\n+              \"task\",\n+              t -> {\n+                t.zeebeJobType(JOBTYPE);\n+              })\n+          .endEvent()\n+          .done();\n+  private final int partitionCount = 3;\n+  private final Timeout testTimeout = Timeout.seconds(120);\n+  private final ClusteringRule clusteringRule = new ClusteringRule(partitionCount, 1, 3);\n+  private final GrpcClientRule clientRule = new GrpcClientRule(clusteringRule);\n+\n+  @Rule", "originalCommit": "c444addd0b0f21ed224ee45592d0aea311eb6d1a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjU1NDUyNQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r436554525", "bodyText": "Using ClassRule makes the tests more complicated. Are we gaining anything by using ClassRule?", "author": "deepthidevaki", "createdAt": "2020-06-08T09:06:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ5MDI1Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzIyNTM1MQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r437225351", "bodyText": "I was under the impression it can make test more complicated, but here I didn't think it would - if you think it would make it harder to read, then it's fine. My very weak argument here would be if we can use the ClassRule, better to do it at the start than later as it's more of a pain to refactor to use than to start with it immediately. (yes I realize that I'm softly implying that they are more complicated \ud83d\ude09)", "author": "npepinpe", "createdAt": "2020-06-09T08:23:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ5MDI1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ5NDEyNg==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r434494126", "bodyText": "Do you think we should also make sure that we are creating on all other partitions? Or is the property we want to test here just that we can create?", "author": "npepinpe", "createdAt": "2020-06-03T11:21:48Z", "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/clustering/AvailabilityTest.java", "diffHunk": "@@ -0,0 +1,175 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.clustering;\n+\n+import static io.zeebe.test.util.TestUtil.waitUntil;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import io.zeebe.broker.it.util.GrpcClientRule;\n+import io.zeebe.client.api.response.ActivatedJob;\n+import io.zeebe.client.api.response.BrokerInfo;\n+import io.zeebe.model.bpmn.Bpmn;\n+import io.zeebe.model.bpmn.BpmnModelInstance;\n+import io.zeebe.protocol.record.Record;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceCreationIntent;\n+import io.zeebe.test.util.record.RecordingExporter;\n+import java.time.Duration;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.RuleChain;\n+import org.junit.rules.Timeout;\n+\n+public class AvailabilityTest {\n+\n+  private static final String JOBTYPE = \"availability-test\";\n+  private static final BpmnModelInstance WORKFLOW =\n+      Bpmn.createExecutableProcess(\"process\")\n+          .startEvent()\n+          .serviceTask(\n+              \"task\",\n+              t -> {\n+                t.zeebeJobType(JOBTYPE);\n+              })\n+          .endEvent()\n+          .done();\n+  private final int partitionCount = 3;\n+  private final Timeout testTimeout = Timeout.seconds(120);\n+  private final ClusteringRule clusteringRule = new ClusteringRule(partitionCount, 1, 3);\n+  private final GrpcClientRule clientRule = new GrpcClientRule(clusteringRule);\n+\n+  @Rule\n+  public RuleChain ruleChain =\n+      RuleChain.outerRule(testTimeout).around(clusteringRule).around(clientRule);\n+\n+  private long workflowKey;\n+\n+  @Before\n+  public void setup() {\n+    workflowKey = clientRule.deployWorkflow(WORKFLOW);\n+  }\n+\n+  @Test\n+  public void shouldCreateWorkflowWhenOnePartitionDown() {\n+    final BrokerInfo leaderForPartition = clusteringRule.getLeaderForPartition(partitionCount);\n+\n+    // when\n+    clusteringRule.stopBroker(leaderForPartition.getNodeId());\n+\n+    for (int i = 0; i < 2 * partitionCount; i++) {\n+      clientRule.createWorkflowInstance(workflowKey);\n+    }\n+\n+    // then\n+    // all create instance requests should complete successfully\n+    assertThat(", "originalCommit": "c444addd0b0f21ed224ee45592d0aea311eb6d1a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjU1NDY4OQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r436554689", "bodyText": "Agreed. I have updated the test.", "author": "deepthidevaki", "createdAt": "2020-06-08T09:06:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ5NDEyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ5NDQwMw==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r434494403", "bodyText": "Can the comment explain why we do this?", "author": "npepinpe", "createdAt": "2020-06-03T11:22:21Z", "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/clustering/AvailabilityTest.java", "diffHunk": "@@ -0,0 +1,175 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.clustering;\n+\n+import static io.zeebe.test.util.TestUtil.waitUntil;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import io.zeebe.broker.it.util.GrpcClientRule;\n+import io.zeebe.client.api.response.ActivatedJob;\n+import io.zeebe.client.api.response.BrokerInfo;\n+import io.zeebe.model.bpmn.Bpmn;\n+import io.zeebe.model.bpmn.BpmnModelInstance;\n+import io.zeebe.protocol.record.Record;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceCreationIntent;\n+import io.zeebe.test.util.record.RecordingExporter;\n+import java.time.Duration;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.RuleChain;\n+import org.junit.rules.Timeout;\n+\n+public class AvailabilityTest {\n+\n+  private static final String JOBTYPE = \"availability-test\";\n+  private static final BpmnModelInstance WORKFLOW =\n+      Bpmn.createExecutableProcess(\"process\")\n+          .startEvent()\n+          .serviceTask(\n+              \"task\",\n+              t -> {\n+                t.zeebeJobType(JOBTYPE);\n+              })\n+          .endEvent()\n+          .done();\n+  private final int partitionCount = 3;\n+  private final Timeout testTimeout = Timeout.seconds(120);\n+  private final ClusteringRule clusteringRule = new ClusteringRule(partitionCount, 1, 3);\n+  private final GrpcClientRule clientRule = new GrpcClientRule(clusteringRule);\n+\n+  @Rule\n+  public RuleChain ruleChain =\n+      RuleChain.outerRule(testTimeout).around(clusteringRule).around(clientRule);\n+\n+  private long workflowKey;\n+\n+  @Before\n+  public void setup() {\n+    workflowKey = clientRule.deployWorkflow(WORKFLOW);\n+  }\n+\n+  @Test\n+  public void shouldCreateWorkflowWhenOnePartitionDown() {\n+    final BrokerInfo leaderForPartition = clusteringRule.getLeaderForPartition(partitionCount);\n+\n+    // when\n+    clusteringRule.stopBroker(leaderForPartition.getNodeId());\n+\n+    for (int i = 0; i < 2 * partitionCount; i++) {\n+      clientRule.createWorkflowInstance(workflowKey);\n+    }\n+\n+    // then\n+    // all create instance requests should complete successfully\n+    assertThat(\n+            RecordingExporter.workflowInstanceCreationRecords()\n+                .withIntent(WorkflowInstanceCreationIntent.CREATED)\n+                .map(Record::getPartitionId)\n+                .limit(2 * partitionCount)\n+                .count())\n+        .isEqualTo(2 * partitionCount);\n+  }\n+\n+  @Test\n+  public void shouldCreateWorkflowWhenPartitionRecovers() {\n+    // given\n+    final int failingPartition = partitionCount;\n+    final BrokerInfo leaderForPartition = clusteringRule.getLeaderForPartition(failingPartition);\n+    clusteringRule.stopBroker(leaderForPartition.getNodeId());\n+\n+    for (int i = 0; i < partitionCount; i++) {\n+      clientRule.createWorkflowInstance(workflowKey);\n+    }\n+\n+    // when\n+    clusteringRule.restartBroker(leaderForPartition.getNodeId());\n+\n+    for (int i = 0; i < partitionCount; i++) {\n+      clientRule.createWorkflowInstance(workflowKey);\n+    }\n+\n+    // then\n+    assertThat(\n+            RecordingExporter.workflowInstanceCreationRecords()\n+                .withIntent(WorkflowInstanceCreationIntent.CREATED)\n+                .filter(r -> r.getPartitionId() == failingPartition))\n+        .hasSizeGreaterThanOrEqualTo(1);\n+  }\n+\n+  @Test\n+  public void shouldActivateJobsWhenOnePartitionDown() {\n+    // given\n+    final int numInstances = 2 * partitionCount;\n+    final BrokerInfo leaderForPartition = clusteringRule.getLeaderForPartition(partitionCount);\n+    clusteringRule.stopBroker(leaderForPartition.getNodeId());\n+\n+    for (int i = 0; i < numInstances; i++) {\n+      clientRule.createWorkflowInstance(workflowKey);\n+    }\n+\n+    // when\n+\n+    final Set<Long> activatedJobsKey = new HashSet<>();\n+    for (int i = 0; i < numInstances; i++) {\n+      final List<ActivatedJob> jobs =\n+          clientRule\n+              .getClient()\n+              .newActivateJobsCommand()\n+              .jobType(JOBTYPE)\n+              .maxJobsToActivate(1)\n+              .timeout(Duration.ofMinutes(5))\n+              .requestTimeout(Duration.ofSeconds(5)) // put a lower timeout than gateway timeout", "originalCommit": "c444addd0b0f21ed224ee45592d0aea311eb6d1a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ5OTYxMA==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r434499610", "bodyText": "You can use Awaitility here", "author": "npepinpe", "createdAt": "2020-06-03T11:33:14Z", "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/clustering/AvailabilityTest.java", "diffHunk": "@@ -0,0 +1,175 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.clustering;\n+\n+import static io.zeebe.test.util.TestUtil.waitUntil;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import io.zeebe.broker.it.util.GrpcClientRule;\n+import io.zeebe.client.api.response.ActivatedJob;\n+import io.zeebe.client.api.response.BrokerInfo;\n+import io.zeebe.model.bpmn.Bpmn;\n+import io.zeebe.model.bpmn.BpmnModelInstance;\n+import io.zeebe.protocol.record.Record;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceCreationIntent;\n+import io.zeebe.test.util.record.RecordingExporter;\n+import java.time.Duration;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.RuleChain;\n+import org.junit.rules.Timeout;\n+\n+public class AvailabilityTest {\n+\n+  private static final String JOBTYPE = \"availability-test\";\n+  private static final BpmnModelInstance WORKFLOW =\n+      Bpmn.createExecutableProcess(\"process\")\n+          .startEvent()\n+          .serviceTask(\n+              \"task\",\n+              t -> {\n+                t.zeebeJobType(JOBTYPE);\n+              })\n+          .endEvent()\n+          .done();\n+  private final int partitionCount = 3;\n+  private final Timeout testTimeout = Timeout.seconds(120);\n+  private final ClusteringRule clusteringRule = new ClusteringRule(partitionCount, 1, 3);\n+  private final GrpcClientRule clientRule = new GrpcClientRule(clusteringRule);\n+\n+  @Rule\n+  public RuleChain ruleChain =\n+      RuleChain.outerRule(testTimeout).around(clusteringRule).around(clientRule);\n+\n+  private long workflowKey;\n+\n+  @Before\n+  public void setup() {\n+    workflowKey = clientRule.deployWorkflow(WORKFLOW);\n+  }\n+\n+  @Test\n+  public void shouldCreateWorkflowWhenOnePartitionDown() {\n+    final BrokerInfo leaderForPartition = clusteringRule.getLeaderForPartition(partitionCount);\n+\n+    // when\n+    clusteringRule.stopBroker(leaderForPartition.getNodeId());\n+\n+    for (int i = 0; i < 2 * partitionCount; i++) {\n+      clientRule.createWorkflowInstance(workflowKey);\n+    }\n+\n+    // then\n+    // all create instance requests should complete successfully\n+    assertThat(\n+            RecordingExporter.workflowInstanceCreationRecords()\n+                .withIntent(WorkflowInstanceCreationIntent.CREATED)\n+                .map(Record::getPartitionId)\n+                .limit(2 * partitionCount)\n+                .count())\n+        .isEqualTo(2 * partitionCount);\n+  }\n+\n+  @Test\n+  public void shouldCreateWorkflowWhenPartitionRecovers() {\n+    // given\n+    final int failingPartition = partitionCount;\n+    final BrokerInfo leaderForPartition = clusteringRule.getLeaderForPartition(failingPartition);\n+    clusteringRule.stopBroker(leaderForPartition.getNodeId());\n+\n+    for (int i = 0; i < partitionCount; i++) {\n+      clientRule.createWorkflowInstance(workflowKey);\n+    }\n+\n+    // when\n+    clusteringRule.restartBroker(leaderForPartition.getNodeId());\n+\n+    for (int i = 0; i < partitionCount; i++) {\n+      clientRule.createWorkflowInstance(workflowKey);\n+    }\n+\n+    // then\n+    assertThat(\n+            RecordingExporter.workflowInstanceCreationRecords()\n+                .withIntent(WorkflowInstanceCreationIntent.CREATED)\n+                .filter(r -> r.getPartitionId() == failingPartition))\n+        .hasSizeGreaterThanOrEqualTo(1);\n+  }\n+\n+  @Test\n+  public void shouldActivateJobsWhenOnePartitionDown() {\n+    // given\n+    final int numInstances = 2 * partitionCount;\n+    final BrokerInfo leaderForPartition = clusteringRule.getLeaderForPartition(partitionCount);\n+    clusteringRule.stopBroker(leaderForPartition.getNodeId());\n+\n+    for (int i = 0; i < numInstances; i++) {\n+      clientRule.createWorkflowInstance(workflowKey);\n+    }\n+\n+    // when\n+\n+    final Set<Long> activatedJobsKey = new HashSet<>();\n+    for (int i = 0; i < numInstances; i++) {\n+      final List<ActivatedJob> jobs =\n+          clientRule\n+              .getClient()\n+              .newActivateJobsCommand()\n+              .jobType(JOBTYPE)\n+              .maxJobsToActivate(1)\n+              .timeout(Duration.ofMinutes(5))\n+              .requestTimeout(Duration.ofSeconds(5)) // put a lower timeout than gateway timeout\n+              .send()\n+              .join()\n+              .getJobs();\n+      jobs.forEach(job -> activatedJobsKey.add(job.getKey()));\n+    }\n+\n+    // then\n+    assertThat(activatedJobsKey).hasSize(numInstances);\n+  }\n+\n+  @Test\n+  public void shouldActivateJobsRoundRobinWhenOnePartitionDown() {\n+    // given\n+    final int numInstances = 2 * partitionCount;\n+    final BrokerInfo leaderForPartition = clusteringRule.getLeaderForPartition(partitionCount);\n+    clusteringRule.stopBroker(leaderForPartition.getNodeId());\n+\n+    for (int i = 0; i < numInstances; i++) {\n+      clientRule.createWorkflowInstance(workflowKey);\n+    }\n+\n+    // when\n+    waitUntil(", "originalCommit": "c444addd0b0f21ed224ee45592d0aea311eb6d1a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "c2991a01c58c2e304b7d86b03be6b12f9b2c81be", "url": "https://github.com/camunda-cloud/zeebe/commit/c2991a01c58c2e304b7d86b03be6b12f9b2c81be", "message": "chore(qa): update test", "committedDate": "2020-06-08T09:19:06Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzIyNzMwMA==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r437227300", "bodyText": "Nit: inlining ClientTransport::sendRequest will produce the same result under the hood, as the JVM will constantize it eventually. But if you were going for readability then this is fine, no need to change.", "author": "npepinpe", "createdAt": "2020-06-09T08:26:57Z", "path": "gateway/src/main/java/io/zeebe/gateway/impl/broker/BrokerRequestManager.java", "diffHunk": "@@ -20,32 +20,32 @@\n import io.zeebe.gateway.impl.broker.cluster.BrokerTopologyManagerImpl;\n import io.zeebe.gateway.impl.broker.request.BrokerPublishMessageRequest;\n import io.zeebe.gateway.impl.broker.request.BrokerRequest;\n-import io.zeebe.gateway.impl.broker.response.BrokerError;\n-import io.zeebe.gateway.impl.broker.response.BrokerRejection;\n import io.zeebe.gateway.impl.broker.response.BrokerResponse;\n import io.zeebe.protocol.Protocol;\n import io.zeebe.protocol.impl.SubscriptionUtil;\n import io.zeebe.protocol.record.ErrorCode;\n import io.zeebe.protocol.record.MessageHeaderDecoder;\n+import io.zeebe.transport.ClientRequest;\n import io.zeebe.transport.ClientTransport;\n import io.zeebe.util.sched.Actor;\n import io.zeebe.util.sched.future.ActorFuture;\n-import io.zeebe.util.sched.future.CompletableActorFuture;\n import java.time.Duration;\n-import java.util.function.BiConsumer;\n-import java.util.function.Consumer;\n-import java.util.function.Function;\n+import java.util.concurrent.CompletableFuture;\n import java.util.function.Supplier;\n+import java.util.function.ToIntFunction;\n import org.agrona.DirectBuffer;\n \n-public final class BrokerRequestManager extends Actor {\n+final class BrokerRequestManager extends Actor {\n \n+  private static final TransportRequestSender SENDER_WITH_RETRY =\n+      (c, s, r, t) -> c.sendRequestWithRetry(s, BrokerRequestManager::responseValidation, r, t);\n+  private static final TransportRequestSender SENDER_WITHOUT_RETRY = ClientTransport::sendRequest;", "originalCommit": "c2991a01c58c2e304b7d86b03be6b12f9b2c81be", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzIyOTc0OQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r437229749", "bodyText": "Sorry to be nit picky, but let's put on our user hats here. I'm a user, I tried to create a workflow instance, I get this error back: what should I do? Should I retry? Should I not retry, because it says everything failed? Should I contact the Zeebe operator? \ud83e\udd14", "author": "npepinpe", "createdAt": "2020-06-09T08:30:47Z", "path": "gateway/src/main/java/io/zeebe/gateway/impl/broker/RequestRetriesExhaustedException.java", "diffHunk": "@@ -0,0 +1,18 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.gateway.impl.broker;\n+\n+import io.zeebe.gateway.cmd.ClientException;\n+\n+class RequestRetriesExhaustedException extends ClientException {\n+\n+  RequestRetriesExhaustedException() {\n+    super(\n+        \"Expected to execute the command on one of the partitions, but all failed; there are no more partitions available to retry.\");", "originalCommit": "c2991a01c58c2e304b7d86b03be6b12f9b2c81be", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzQzNzExMg==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r437437112", "bodyText": "Same as the other error message: what should I do with this error as a user? Should I retry (probably)?", "author": "npepinpe", "createdAt": "2020-06-09T13:51:48Z", "path": "gateway/src/main/java/io/zeebe/gateway/impl/broker/RequestRetryHandler.java", "diffHunk": "@@ -0,0 +1,147 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.gateway.impl.broker;\n+\n+import io.zeebe.gateway.Loggers;\n+import io.zeebe.gateway.cmd.BrokerErrorException;\n+import io.zeebe.gateway.cmd.NoTopologyAvailableException;\n+import io.zeebe.gateway.impl.broker.cluster.BrokerTopologyManager;\n+import io.zeebe.gateway.impl.broker.request.BrokerRequest;\n+import io.zeebe.gateway.impl.broker.response.BrokerResponse;\n+import io.zeebe.protocol.record.ErrorCode;\n+import java.net.ConnectException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+\n+/**\n+ * When a requests to a partition fails, request will be retried with a different partition until\n+ * all partitions are tried. The request is retried only for specific errors such as connection\n+ * errors or resource exhausted errors. The request is not retried for time outs.\n+ */\n+public final class RequestRetryHandler {\n+\n+  private final BrokerClient brokerClient;\n+  private final RequestDispatchStrategy roundRobinDispatchStrategy;\n+  private final BrokerTopologyManager topologyManager;\n+\n+  public RequestRetryHandler(\n+      final BrokerClient brokerClient, final BrokerTopologyManager topologyManager) {\n+    this.brokerClient = brokerClient;\n+    roundRobinDispatchStrategy = new RoundRobinDispatchStrategy(topologyManager);\n+    this.topologyManager = topologyManager;\n+  }\n+\n+  public <BrokerResponseT> void sendRequest(\n+      final BrokerRequest<BrokerResponseT> request,\n+      final BrokerResponseConsumer<BrokerResponseT> responseConsumer,\n+      final Consumer<Throwable> throwableConsumer) {\n+    final Function<\n+            BrokerRequest<BrokerResponseT>, CompletableFuture<BrokerResponse<BrokerResponseT>>>\n+        requestSender = brokerClient::sendRequest;\n+    sendRequestInternal(request, requestSender, responseConsumer, throwableConsumer);\n+  }\n+\n+  public <BrokerResponseT> void sendRequest(\n+      final BrokerRequest<BrokerResponseT> request,\n+      final BrokerResponseConsumer<BrokerResponseT> responseConsumer,\n+      final Consumer<Throwable> throwableConsumer,\n+      final Duration requestTimeout) {\n+    final Function<\n+            BrokerRequest<BrokerResponseT>, CompletableFuture<BrokerResponse<BrokerResponseT>>>\n+        requestSender = r -> brokerClient.sendRequest(r, requestTimeout);\n+    sendRequestInternal(request, requestSender, responseConsumer, throwableConsumer);\n+  }\n+\n+  private <BrokerResponseT> void sendRequestInternal(\n+      final BrokerRequest<BrokerResponseT> request,\n+      final Function<\n+              BrokerRequest<BrokerResponseT>, CompletableFuture<BrokerResponse<BrokerResponseT>>>\n+          requestSender,\n+      final BrokerResponseConsumer<BrokerResponseT> responseConsumer,\n+      final Consumer<Throwable> throwableConsumer) {\n+    final var topology = topologyManager.getTopology();\n+    if (topology != null) {\n+      sendRequestWithRetry(\n+          request,\n+          requestSender,\n+          partitionIdIteratorForType(topology.getPartitionsCount()),\n+          responseConsumer,\n+          throwableConsumer,\n+          new ArrayList<>());\n+    } else {\n+      throwableConsumer.accept(\n+          new NoTopologyAvailableException(\n+              \"Expected to send the request to a partition in the topology, but gateway does not know broker topology\"));", "originalCommit": "c2991a01c58c2e304b7d86b03be6b12f9b2c81be", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzU3NzQwOA==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r437577408", "bodyText": "I can't find where this is extended, but I assume from the removal of final and switching fields to protected that it is? Or is that a leftover from another refactoring?", "author": "npepinpe", "createdAt": "2020-06-09T16:52:11Z", "path": "gateway/src/main/java/io/zeebe/gateway/impl/broker/RoundRobinDispatchStrategy.java", "diffHunk": "@@ -8,15 +8,19 @@\n package io.zeebe.gateway.impl.broker;\n \n import io.zeebe.gateway.impl.broker.cluster.BrokerClusterState;\n-import io.zeebe.gateway.impl.broker.cluster.BrokerTopologyManagerImpl;\n+import io.zeebe.gateway.impl.broker.cluster.BrokerTopologyManager;\n import java.util.concurrent.atomic.AtomicInteger;\n \n-public final class RoundRobinDispatchStrategy implements RequestDispatchStrategy {\n+/**\n+ * Return the next partition using a round robin strategy, but skips the partitions where there is\n+ * no leader at the moment.\n+ */\n+public class RoundRobinDispatchStrategy implements RequestDispatchStrategy {", "originalCommit": "c2991a01c58c2e304b7d86b03be6b12f9b2c81be", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzU4MjEyNw==", "url": "https://github.com/camunda-cloud/zeebe/pull/4652#discussion_r437582127", "bodyText": "Nit: you can assertThat(error).isInstanceOf", "author": "npepinpe", "createdAt": "2020-06-09T16:59:38Z", "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/gateway/GatewayIntegrationTest.java", "diffHunk": "@@ -61,18 +62,27 @@ public void tearDown() {\n   }\n \n   @Test\n-  public void shouldReturnRejectionWithCorrectTypeAndReason() {\n+  public void shouldReturnRejectionWithCorrectTypeAndReason() throws InterruptedException {\n     // given\n+    final CountDownLatch latch = new CountDownLatch(1);\n+    final AtomicReference<Throwable> errorResponse = new AtomicReference<>();\n \n     // when\n-    final BrokerResponse<WorkflowInstanceCreationRecord> response =\n-        client.sendRequest(new BrokerCreateWorkflowInstanceRequest()).join();\n+    client.sendRequestWithRetry(\n+        new BrokerCreateWorkflowInstanceRequest(),\n+        (k, r) -> {},\n+        error -> {\n+          errorResponse.set(error);\n+          latch.countDown();\n+        });\n \n     // then\n-    assertThat(response.isRejection()).isTrue();\n-    final BrokerRejection error = response.getRejection();\n-    assertThat(error.getType()).isEqualTo(RejectionType.INVALID_ARGUMENT);\n-    assertThat(error.getReason())\n+    latch.await();\n+    final var error = errorResponse.get();\n+    assertThat(error instanceof BrokerRejectionException).isTrue();", "originalCommit": "c2991a01c58c2e304b7d86b03be6b12f9b2c81be", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "21adb3d7761da0ff38a8a9ffabe9777ce04eaa62", "url": "https://github.com/camunda-cloud/zeebe/commit/21adb3d7761da0ff38a8a9ffabe9777ce04eaa62", "message": "chore(qa): add test for availability when one partition down", "committedDate": "2020-06-10T08:41:08Z", "type": "forcePushed"}, {"oid": "49c75a4d821a9db22d02eb88a18104934b13fb6c", "url": "https://github.com/camunda-cloud/zeebe/commit/49c75a4d821a9db22d02eb88a18104934b13fb6c", "message": "chore(gateway): donot retry partition-independent requests when node not available\n\n* Do not retry activate job and create workflow when the leader for partition is not available\n* Retry create workflow request with a new partition immediately", "committedDate": "2020-06-10T09:43:07Z", "type": "commit"}, {"oid": "c15e29df5371ed36d52c13d3c34163a0a21c6ac8", "url": "https://github.com/camunda-cloud/zeebe/commit/c15e29df5371ed36d52c13d3c34163a0a21c6ac8", "message": "chore(qa): add test for availability when one partition down", "committedDate": "2020-06-10T09:43:07Z", "type": "commit"}, {"oid": "c15e29df5371ed36d52c13d3c34163a0a21c6ac8", "url": "https://github.com/camunda-cloud/zeebe/commit/c15e29df5371ed36d52c13d3c34163a0a21c6ac8", "message": "chore(qa): add test for availability when one partition down", "committedDate": "2020-06-10T09:43:07Z", "type": "forcePushed"}]}