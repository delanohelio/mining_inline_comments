{"pr_number": 4782, "pr_title": "chore(broker): handle out of disk space in broker", "pr_createdAt": "2020-06-22T06:26:24Z", "pr_url": "https://github.com/camunda-cloud/zeebe/pull/4782", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE1MTUyMQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444151521", "bodyText": "Maybe Space instead of Buffer", "author": "Zelldon", "createdAt": "2020-06-23T11:26:03Z", "path": "atomix/cluster/src/main/java/io/atomix/raft/partition/RaftPartitionGroup.java", "diffHunk": "@@ -440,6 +440,17 @@ public Builder withMaxEntrySize(final MemorySize maxEntrySize) {\n       return this;\n     }\n \n+    /**\n+     * Set the minimum free disk space (in bytes) to leave when allocating a new segment\n+     *\n+     * @param freeDiskBuffer free disk space in bytes\n+     * @return the Raft partition group builder\n+     */\n+    public Builder withFreeDiskBuffer(final long freeDiskBuffer) {", "originalCommit": "dd6fcd629b4ef93f6531638f77fb74942691a4bb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE1MzQ5NA==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444153494", "bodyText": "This was just again reordering? Seems that there is still something wrong with my setup \ud83d\ude05", "author": "Zelldon", "createdAt": "2020-06-23T11:30:01Z", "path": "atomix/cluster/src/test/java/io/atomix/raft/RaftRule.java", "diffHunk": "@@ -623,4 +597,31 @@ public long awaitCommit() throws Exception {\n       return commitFuture.get(30, TimeUnit.SECONDS);\n     }\n   }\n+\n+  private final class RaftSnapshotListener implements PersistedSnapshotListener {", "originalCommit": "dd6fcd629b4ef93f6531638f77fb74942691a4bb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE1NTg0Nw==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444155847", "bodyText": "IF you would add as a separate last step the disk space monitor installation then you dont need this if.", "author": "Zelldon", "createdAt": "2020-06-23T11:34:51Z", "path": "broker/src/main/java/io/zeebe/broker/Broker.java", "diffHunk": "@@ -253,9 +258,18 @@ private AutoCloseable subscriptionAPIStep(final BrokerInfo localBroker) {\n         new SubscriptionApiCommandMessageHandlerService(localBroker, atomix);\n     partitionListeners.add(messageHandlerService);\n     scheduleActor(messageHandlerService);\n+    addDiskSpaceUsageListener(messageHandlerService);\n     return messageHandlerService;\n   }\n \n+  private void addDiskSpaceUsageListener(final DiskSpaceUsageListener diskSpaceUsageListener) {\n+    if (diskSpaceUsageMonitor == null) {", "originalCommit": "dd6fcd629b4ef93f6531638f77fb74942691a4bb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE2MDM4Nw==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444160387", "bodyText": "As I said I would felt more comfortable if we use percentage here, because I have the feeling the user need to set that setting currently in respect to there used pvc size always. If we had a percentage we would be more dynamically and then the user only needs to set it when he has really small pvcs, but even then I think it would be possible to run it. If the user uses a small pvc it might even not have such a big load or expect not a big state at all.", "author": "Zelldon", "createdAt": "2020-06-23T11:43:53Z", "path": "broker/src/main/java/io/zeebe/broker/system/configuration/DataCfg.java", "diffHunk": "@@ -19,6 +19,9 @@\n public final class DataCfg implements ConfigurationEntry {\n   public static final String DEFAULT_DIRECTORY = \"data\";\n   private static final DataSize DEFAULT_DATA_SIZE = DataSize.ofMegabytes(512);\n+  private static final DataSize DEFAULT_LOW_FREE_DISKSPACE_WATERMARK = DataSize.ofGigabytes(1);", "originalCommit": "dd6fcd629b4ef93f6531638f77fb74942691a4bb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE2MTQwMg==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444161402", "bodyText": "If you make this as an parameter you would be able to unit test the complete logic much easier", "author": "Zelldon", "createdAt": "2020-06-23T11:45:52Z", "path": "broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageMonitor.java", "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.system.monitoring;\n+\n+import static io.zeebe.broker.Broker.LOG;\n+\n+import io.zeebe.broker.system.configuration.DataCfg;\n+import io.zeebe.util.sched.Actor;\n+import java.io.File;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.function.LongSupplier;\n+\n+public class DiskSpaceUsageMonitor extends Actor {\n+\n+  private final List<DiskSpaceUsageListener> diskSpaceUsageListeners = new ArrayList<>();\n+  private boolean currentDiskAvailableStatus = true;\n+  private LongSupplier diskSpaceSupplier;\n+  private final Duration monitoringDelay;\n+  private final long minFreeDiskRequired;\n+\n+  public DiskSpaceUsageMonitor(final DataCfg dataCfg) {\n+    this.monitoringDelay = dataCfg.getDiskUsageCheckDelay();\n+    this.minFreeDiskRequired = dataCfg.getHighFreeDiskSpaceWatermarkInBytes();\n+    final var directory = new File(dataCfg.getDirectories().get(0));\n+    diskSpaceSupplier = directory::getUsableSpace;", "originalCommit": "dd6fcd629b4ef93f6531638f77fb74942691a4bb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDY4NTY3Mg==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444685672", "bodyText": "Do you mean unit testing DiskSpaceUsageMonitor ? Is it required when we have the integration test?", "author": "deepthidevaki", "createdAt": "2020-06-24T07:02:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE2MTQwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE2MjA4Mg==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444162082", "bodyText": "This variable name is a bit misleading. It should be diskFreeSpace or usable space", "author": "Zelldon", "createdAt": "2020-06-23T11:47:08Z", "path": "broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageMonitor.java", "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.system.monitoring;\n+\n+import static io.zeebe.broker.Broker.LOG;\n+\n+import io.zeebe.broker.system.configuration.DataCfg;\n+import io.zeebe.util.sched.Actor;\n+import java.io.File;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.function.LongSupplier;\n+\n+public class DiskSpaceUsageMonitor extends Actor {\n+\n+  private final List<DiskSpaceUsageListener> diskSpaceUsageListeners = new ArrayList<>();\n+  private boolean currentDiskAvailableStatus = true;\n+  private LongSupplier diskSpaceSupplier;\n+  private final Duration monitoringDelay;\n+  private final long minFreeDiskRequired;\n+\n+  public DiskSpaceUsageMonitor(final DataCfg dataCfg) {\n+    this.monitoringDelay = dataCfg.getDiskUsageCheckDelay();\n+    this.minFreeDiskRequired = dataCfg.getHighFreeDiskSpaceWatermarkInBytes();\n+    final var directory = new File(dataCfg.getDirectories().get(0));\n+    diskSpaceSupplier = directory::getUsableSpace;\n+  }\n+\n+  @Override\n+  protected void onActorStarted() {\n+    actor.runAtFixedRate(monitoringDelay, this::checkDiskUsageAndNotifyListeners);\n+  }\n+\n+  private void checkDiskUsageAndNotifyListeners() {\n+    final long diskSpaceUsage = diskSpaceSupplier.getAsLong();", "originalCommit": "dd6fcd629b4ef93f6531638f77fb74942691a4bb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE2MjkwNg==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444162906", "bodyText": "Maybe also rename the methods to diskSpace available; noDiskSpace available. I think it makes it more clear then below and above threshold", "author": "Zelldon", "createdAt": "2020-06-23T11:48:39Z", "path": "broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageMonitor.java", "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.system.monitoring;\n+\n+import static io.zeebe.broker.Broker.LOG;\n+\n+import io.zeebe.broker.system.configuration.DataCfg;\n+import io.zeebe.util.sched.Actor;\n+import java.io.File;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.function.LongSupplier;\n+\n+public class DiskSpaceUsageMonitor extends Actor {\n+\n+  private final List<DiskSpaceUsageListener> diskSpaceUsageListeners = new ArrayList<>();\n+  private boolean currentDiskAvailableStatus = true;\n+  private LongSupplier diskSpaceSupplier;\n+  private final Duration monitoringDelay;\n+  private final long minFreeDiskRequired;\n+\n+  public DiskSpaceUsageMonitor(final DataCfg dataCfg) {\n+    this.monitoringDelay = dataCfg.getDiskUsageCheckDelay();\n+    this.minFreeDiskRequired = dataCfg.getHighFreeDiskSpaceWatermarkInBytes();\n+    final var directory = new File(dataCfg.getDirectories().get(0));\n+    diskSpaceSupplier = directory::getUsableSpace;\n+  }\n+\n+  @Override\n+  protected void onActorStarted() {\n+    actor.runAtFixedRate(monitoringDelay, this::checkDiskUsageAndNotifyListeners);\n+  }\n+\n+  private void checkDiskUsageAndNotifyListeners() {\n+    final long diskSpaceUsage = diskSpaceSupplier.getAsLong();\n+    final boolean previousStatus = currentDiskAvailableStatus;\n+    currentDiskAvailableStatus = diskSpaceUsage >= minFreeDiskRequired;\n+    if (currentDiskAvailableStatus != previousStatus) {\n+      if (!currentDiskAvailableStatus) {\n+        LOG.debug(\n+            \"Out of disk space. Current available {} bytes. Minimum needed {} bytes.\",\n+            diskSpaceUsage,\n+            minFreeDiskRequired);\n+        diskSpaceUsageListeners.forEach(\n+            DiskSpaceUsageListener::onDiskSpaceUsageIncreasedAboveThreshold);\n+      } else {\n+        LOG.debug(\"Disk space available again. Current available {} bytes\", diskSpaceUsage);\n+        diskSpaceUsageListeners.forEach(\n+            DiskSpaceUsageListener::onDiskSpaceUsageReducedBelowThreshold);", "originalCommit": "dd6fcd629b4ef93f6531638f77fb74942691a4bb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE2NDEzNg==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444164136", "bodyText": "So many listeners \ud83d\ude06", "author": "Zelldon", "createdAt": "2020-06-23T11:51:02Z", "path": "broker/src/main/java/io/zeebe/broker/system/partitions/ZeebePartition.java", "diffHunk": "@@ -66,7 +67,11 @@\n import org.slf4j.Logger;\n \n public final class ZeebePartition extends Actor\n-    implements RaftCommitListener, RaftRoleChangeListener, HealthMonitorable, FailureListener {\n+    implements RaftCommitListener,\n+        RaftRoleChangeListener,\n+        HealthMonitorable,\n+        FailureListener,\n+        DiskSpaceUsageListener {", "originalCommit": "dd6fcd629b4ef93f6531638f77fb74942691a4bb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM1MjM1OQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448352359", "bodyText": "Just waiting for the ListenerListener interface now \ud83d\udc40", "author": "npepinpe", "createdAt": "2020-07-01T13:11:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE2NDEzNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE5Nzg3OA==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444197878", "bodyText": "Maybe assert that we get an response", "author": "Zelldon", "createdAt": "2020-06-23T12:51:04Z", "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryTest.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+\n+import io.zeebe.broker.it.util.GrpcClientRule;\n+import io.zeebe.broker.system.monitoring.DiskSpaceUsageListener;\n+import io.zeebe.broker.test.EmbeddedBrokerRule;\n+import io.zeebe.model.bpmn.Bpmn;\n+import io.zeebe.model.bpmn.BpmnModelInstance;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.TimerIntent;\n+import io.zeebe.protocol.record.value.JobRecordValueAssert;\n+import io.zeebe.protocol.record.value.TimerRecordValueAssert;\n+import io.zeebe.test.util.record.RecordingExporter;\n+import java.time.Duration;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import org.assertj.core.api.Assertions;\n+import org.awaitility.Awaitility;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.RuleChain;\n+import org.junit.rules.Timeout;\n+import org.springframework.util.unit.DataSize;\n+\n+public class DiskSpaceRecoveryTest {\n+  private final Timeout testTimeout = Timeout.seconds(120);\n+  private final EmbeddedBrokerRule embeddedBrokerRule =\n+      new EmbeddedBrokerRule(\n+          cfg -> {\n+            cfg.getData().setDiskUsageCheckDelay(Duration.ofSeconds(1));\n+            cfg.getData().setHighFreeDiskSpaceWatermark(DataSize.ofGigabytes(4));\n+          });\n+  private final GrpcClientRule clientRule = new GrpcClientRule(embeddedBrokerRule);\n+\n+  @Rule\n+  public RuleChain ruleChain =\n+      RuleChain.outerRule(testTimeout).around(embeddedBrokerRule).around(clientRule);\n+\n+  @Test\n+  public void shouldStopAcceptingRequestWhenDiskSpaceFull() throws InterruptedException {\n+    // given\n+    waitUntilDiskSpaceNotAvailable();\n+\n+    // when\n+    final var resultFuture =\n+        clientRule\n+            .getClient()\n+            .newPublishMessageCommand()\n+            .messageName(\"test\")\n+            .correlationKey(\"test\")\n+            .send();\n+\n+    // then\n+    Assertions.assertThatThrownBy(resultFuture::join)\n+        .hasRootCauseMessage(\n+            \"RESOURCE_EXHAUSTED: Cannot accept requests for partition 1. Broker is out of disk space\");\n+  }\n+\n+  @Test\n+  public void shouldRestartAcceptingRequestWhenDiskSpaceAvailableAgain()\n+      throws InterruptedException {\n+    // given\n+    waitUntilDiskSpaceNotAvailable();\n+\n+    // when\n+    waitUntilDiskSpaceAvailable();\n+    final var resultFuture =\n+        clientRule\n+            .getClient()\n+            .newPublishMessageCommand()\n+            .messageName(\"test\")\n+            .correlationKey(\"Test\")\n+            .send();\n+\n+    // then\n+    assertThatCode(resultFuture::join).doesNotThrowAnyException();", "originalCommit": "dd6fcd629b4ef93f6531638f77fb74942691a4bb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDY4NDc4NQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444684785", "bodyText": "assertThat(resultFuture.join()).isNotNull(); did not work because the response is empty for publish message.", "author": "deepthidevaki", "createdAt": "2020-06-24T07:00:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE5Nzg3OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NTc2Nw==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448365767", "bodyText": "Can we use another command then?", "author": "npepinpe", "createdAt": "2020-07-01T13:32:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE5Nzg3OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc3MjE1NA==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448772154", "bodyText": "Why is it no good if we assert doesNotThrowAnyException? I can use deploy workflow command instead, if you insist.", "author": "deepthidevaki", "createdAt": "2020-07-02T06:19:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE5Nzg3OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDg0MDU5MA==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r450840590", "bodyText": "Code shouldn't generally throw exception so it's usually a weird assertion to have. But I'm not insisting, it's more of a rule of thumb - I'd rather we assert something happened than it didn't, e.g. no exception thrown.", "author": "npepinpe", "createdAt": "2020-07-07T12:53:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE5Nzg3OA=="}], "type": "inlineReview"}, {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514", "url": "https://github.com/camunda-cloud/zeebe/commit/ef515fed93020dc76d7b339d99e86b0fc50d4514", "message": "chore(qa): add integration test", "committedDate": "2020-06-29T12:20:24Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODIyNzQ2MA==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448227460", "bodyText": "Could you reference here the issue please", "author": "Zelldon", "createdAt": "2020-07-01T09:11:18Z", "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryClusteredTest.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertWorkflowInstanceCompleted;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import io.zeebe.broker.Broker;\n+import io.zeebe.broker.it.clustering.ClusteringRule;\n+import io.zeebe.broker.it.util.GrpcClientRule;\n+import io.zeebe.broker.system.monitoring.DiskSpaceUsageListener;\n+import io.zeebe.client.api.response.DeploymentEvent;\n+import io.zeebe.model.bpmn.Bpmn;\n+import io.zeebe.model.bpmn.BpmnModelInstance;\n+import io.zeebe.protocol.record.intent.DeploymentIntent;\n+import io.zeebe.protocol.record.intent.MessageSubscriptionIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceSubscriptionIntent;\n+import io.zeebe.test.util.record.RecordingExporter;\n+import java.time.Duration;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import org.awaitility.Awaitility;\n+import org.junit.Ignore;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.RuleChain;\n+import org.junit.rules.Timeout;\n+import org.springframework.util.unit.DataSize;\n+\n+public class DiskSpaceRecoveryClusteredTest {\n+  private static final String CORRELATION_KEY = \"item-2\";\n+  private final String messageName = \"test\";\n+  private final Timeout testTimeout = Timeout.seconds(120);\n+  private final ClusteringRule clusteringRule =\n+      new ClusteringRule(\n+          3,\n+          1,\n+          3,\n+          cfg -> {\n+            cfg.getData().setDiskUsageCheckDelay(Duration.ofSeconds(1));\n+            cfg.getData().setHighFreeDiskSpaceWatermark(DataSize.ofGigabytes(4));\n+          });\n+  private final GrpcClientRule clientRule = new GrpcClientRule(clusteringRule);\n+\n+  @Rule\n+  public RuleChain ruleChain =\n+      RuleChain.outerRule(testTimeout).around(clusteringRule).around(clientRule);\n+\n+  @Test\n+  public void shouldDistributeDeploymentAfterDiskSpaceAvailableAgain() throws InterruptedException {\n+    // given\n+    final var failingBroker =\n+        clusteringRule.getBroker(clusteringRule.getLeaderForPartition(3).getNodeId());\n+    waitUntilDiskSpaceNotAvailable(failingBroker);\n+\n+    final long deploymentKey =\n+        deployWorkflow(Bpmn.createExecutableProcess(\"test\").startEvent().endEvent().done());\n+\n+    // when\n+    Awaitility.await()\n+        .timeout(Duration.ofSeconds(60))\n+        .until(\n+            () ->\n+                RecordingExporter.deploymentRecords(DeploymentIntent.DISTRIBUTE).limit(1).exists());\n+\n+    waitUntilDiskSpaceAvailable(failingBroker);\n+\n+    // then\n+    clientRule.waitUntilDeploymentIsDone(deploymentKey);\n+  }\n+\n+  @Ignore(\"Apparently a message correlation is not retried if failed\")", "originalCommit": "a28589048f8248828671adc6cb0ecec032c4fc87", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODI5MTUxMg==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448291512", "bodyText": "Ok this test will take at least 1 minute right - wouldn't be nice to have something like zeebe-io/enhancements#5", "author": "Zelldon", "createdAt": "2020-07-01T11:12:54Z", "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static org.awaitility.Awaitility.await;\n+\n+import com.github.dockerjava.api.model.Bind;\n+import com.github.dockerjava.api.model.Volume;\n+import io.zeebe.client.ZeebeClient;\n+import io.zeebe.containers.ZeebeBrokerContainer;\n+import java.time.Duration;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.elasticsearch.client.RestClient;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.elasticsearch.ElasticsearchContainer;\n+\n+public class DiskSpaceRecoveryITTest {\n+  static ZeebeBrokerContainer zeebeBroker;\n+  private static final Logger LOG = LoggerFactory.getLogger(\"TEST\");\n+  private static final String VOLUME_NAME = \"tmpdata1\";\n+  private static String containerIPAddress;\n+  private static Integer apiPort;\n+  private static ElasticsearchContainer elastic;\n+  private ZeebeClient client;\n+\n+  @BeforeClass\n+  public static void setUpClass() {\n+    final var elasticHostInternal = \"http://elastic:9200\";\n+    zeebeBroker = createZeebe(elasticHostInternal);\n+    final var network = zeebeBroker.getNetwork();\n+    elastic = createElastic(network);\n+    zeebeBroker.start();\n+\n+    apiPort = zeebeBroker.getMappedPort(26500);\n+    containerIPAddress = zeebeBroker.getContainerIpAddress();\n+  }\n+\n+  private static ZeebeBrokerContainer createZeebe(final String elasticHost) {\n+    zeebeBroker =\n+        new ZeebeBrokerContainer(\"current-test\")\n+            .withEnv(\n+                \"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_CLASSNAME\",\n+                \"io.zeebe.exporter.ElasticsearchExporter\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_URL\", elasticHost)\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_DELAY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_SIZE\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_SNAPSHOTPERIOD\", \"1m\")", "originalCommit": "ef515fed93020dc76d7b339d99e86b0fc50d4514", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NTQ0OA==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448365448", "bodyText": "Is there something else we could do at all? Just wondering", "author": "npepinpe", "createdAt": "2020-07-01T13:32:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODI5MTUxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMxODA0NQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448318045", "bodyText": "Is there any reason not to rename the getter if we rename the property?", "author": "npepinpe", "createdAt": "2020-07-01T12:08:19Z", "path": "atomix/cluster/src/main/java/io/atomix/raft/storage/RaftStorage.java", "diffHunk": "@@ -189,8 +189,8 @@ public boolean dynamicCompaction() {\n    *\n    * @return the percentage of disk space that must be available before log compaction is forced\n    */\n-  public double freeDiskBuffer() {\n-    return freeDiskBuffer;\n+  public long freeDiskBuffer() {", "originalCommit": "ef515fed93020dc76d7b339d99e86b0fc50d4514", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMyMDc1NQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448320755", "bodyText": "If the close could fail, we should wrap it in a try catch to make sure we also close the disk space usage monitor.", "author": "npepinpe", "createdAt": "2020-07-01T12:13:51Z", "path": "broker/src/main/java/io/zeebe/broker/Broker.java", "diffHunk": "@@ -271,20 +282,26 @@ private AutoCloseable topologyManagerStep(\n     return topologyManager;\n   }\n \n-  private AutoCloseable monitoringServerStep(\n-      final NetworkCfg networkCfg, final BrokerInfo localBroker) {\n+  private AutoCloseable monitoringServerStep(final DataCfg data, final BrokerInfo localBroker) {\n     healthCheckService = new BrokerHealthCheckService(localBroker, atomix);\n     springBrokerBridge.registerBrokerHealthCheckServiceSupplier(() -> healthCheckService);\n     partitionListeners.add(healthCheckService);\n     scheduleActor(healthCheckService);\n \n-    return () -> healthCheckService.close();\n+    diskSpaceUsageMonitor = new DiskSpaceUsageMonitor(data);\n+    scheduleActor(diskSpaceUsageMonitor);\n+    diskSpaceUsageListeners.forEach(l -> diskSpaceUsageMonitor.addDiskUsageListener(l));\n+    return () -> {\n+      healthCheckService.close();", "originalCommit": "ef515fed93020dc76d7b339d99e86b0fc50d4514", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMyNDk0OA==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448324948", "bodyText": "I assume this is to avoid the NoRemoteHandler errors - my question here would be, shouldn't we handle these as possible cases on the other side? Why are we expecting the service to always be there? I imagine that's a little out of scope though...just a question", "author": "npepinpe", "createdAt": "2020-07-01T12:22:16Z", "path": "broker/src/main/java/io/zeebe/broker/engine/impl/SubscriptionApiCommandMessageHandlerService.java", "diffHunk": "@@ -77,4 +82,31 @@ protected void onActorStarting() {\n                     }));\n     return future;\n   }\n+\n+  @Override\n+  public void onDiskSpaceNotAvailable() {\n+    actor.call(\n+        () -> {\n+          LOG.debug(\n+              \"Broker is out of disk space. All requests with topic {} will be rejected.\",\n+              SUBSCRIPTION_TOPIC);\n+          atomix.getCommunicationService().unsubscribe(SUBSCRIPTION_TOPIC);\n+          atomix", "originalCommit": "ef515fed93020dc76d7b339d99e86b0fc50d4514", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc2NzI0Nw==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448767247", "bodyText": "Here it doesn't make a difference because the sender is not expecting any response. Ideally this should respond with a \"Resource exhausted\" error similar to the deployment request. But the current interface for subscription message request returns nothing. This would probably be fixed by #4786", "author": "deepthidevaki", "createdAt": "2020-07-02T06:05:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMyNDk0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMyNzAzNg==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448327036", "bodyText": "Hm, at the moment I think we do most of our validation in SystemContext#validateConfiguration. Or maybe I'm mistaken? I'm not sure if that was a conscious decision or I just thought we did that.", "author": "npepinpe", "createdAt": "2020-07-01T12:26:00Z", "path": "broker/src/main/java/io/zeebe/broker/system/configuration/DataCfg.java", "diffHunk": "@@ -85,21 +92,67 @@ public StorageLevel getAtomixStorageLevel() {\n     return useMmap() ? StorageLevel.MAPPED : StorageLevel.DISK;\n   }\n \n+  public double getDiskUsageCommandWatermark() {\n+    return diskUsageCommandWatermark;\n+  }\n+\n+  public void setDiskUsageCommandWatermark(final double diskUsageCommandWatermark) {\n+    Preconditions.checkArgument(", "originalCommit": "ef515fed93020dc76d7b339d99e86b0fc50d4514", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc2NzU0NQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448767545", "bodyText": "Didn't knew about SystemContext#validateConfiguration. I can move the validation there.", "author": "deepthidevaki", "createdAt": "2020-07-02T06:05:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMyNzAzNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMzNDIwNw==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448334207", "bodyText": "If possible we should document public interfaces \ud83d\ude42", "author": "npepinpe", "createdAt": "2020-07-01T12:39:06Z", "path": "broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageListener.java", "diffHunk": "@@ -0,0 +1,15 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.system.monitoring;\n+\n+public interface DiskSpaceUsageListener {", "originalCommit": "ef515fed93020dc76d7b339d99e86b0fc50d4514", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM1MzIwMQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448353201", "bodyText": "Can we write the current disk space and the threshold as context info?", "author": "npepinpe", "createdAt": "2020-07-01T13:13:03Z", "path": "broker/src/main/java/io/zeebe/broker/transport/commandapi/CommandApiRequestHandler.java", "diffHunk": "@@ -81,6 +82,17 @@ private void handleExecuteCommandRequest(\n       final DirectBuffer buffer,\n       final int messageOffset,\n       final int messageLength) {\n+\n+    if (!isDiskSpaceAvailable) {\n+      errorResponseWriter\n+          .resourceExhausted(\n+              String.format(\n+                  \"Cannot accept requests for partition %d. Broker is out of disk space\",", "originalCommit": "ef515fed93020dc76d7b339d99e86b0fc50d4514", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc2ODIxNg==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448768216", "bodyText": "Is it useful for the clients? We log it in DiskSpaceUsageMonitor.", "author": "deepthidevaki", "createdAt": "2020-07-02T06:07:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM1MzIwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDg0Mjc3MQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r450842771", "bodyText": "It's useful for us that's for sure, hard to say yet if it's useful for normal users. Do you think adding it would confuse them? What are the reasons for omitting them?", "author": "npepinpe", "createdAt": "2020-07-07T12:56:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM1MzIwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDg0Nzk3Mg==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r450847972", "bodyText": "CommandApi does not now how much disk space is available or required. It only knows that there is not enough. If we want to provide this information to the users, the listener interface should be changed. Since user's can't do anything with that information, I don't think it is necessary. We log both required and available disk space in DiskSpaceUsageMonitor, which can be used by an operator.", "author": "deepthidevaki", "createdAt": "2020-07-07T13:05:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM1MzIwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2MTY4NQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448361685", "bodyText": "We don't have a test for user commands? I see we have one for deployment and messages (subscription API).", "author": "npepinpe", "createdAt": "2020-07-01T13:26:32Z", "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryClusteredTest.java", "diffHunk": "@@ -0,0 +1,214 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertWorkflowInstanceCompleted;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import io.zeebe.broker.Broker;\n+import io.zeebe.broker.it.clustering.ClusteringRule;\n+import io.zeebe.broker.it.util.GrpcClientRule;\n+import io.zeebe.broker.system.monitoring.DiskSpaceUsageListener;\n+import io.zeebe.client.api.response.DeploymentEvent;\n+import io.zeebe.model.bpmn.Bpmn;\n+import io.zeebe.model.bpmn.BpmnModelInstance;\n+import io.zeebe.protocol.record.intent.DeploymentIntent;\n+import io.zeebe.protocol.record.intent.MessageSubscriptionIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceSubscriptionIntent;\n+import io.zeebe.test.util.record.RecordingExporter;\n+import java.time.Duration;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import org.awaitility.Awaitility;\n+import org.junit.Ignore;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.RuleChain;\n+import org.junit.rules.Timeout;\n+import org.springframework.util.unit.DataSize;\n+\n+public class DiskSpaceRecoveryClusteredTest {", "originalCommit": "ef515fed93020dc76d7b339d99e86b0fc50d4514", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc2ODc2NQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448768765", "bodyText": "We have it in DiskSpaceRecoveryTest with single broker.", "author": "deepthidevaki", "createdAt": "2020-07-02T06:09:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2MTY4NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2MzIwOQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448363209", "bodyText": "I'm guessing this is testing left over?", "author": "npepinpe", "createdAt": "2020-07-01T13:28:53Z", "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static org.awaitility.Awaitility.await;\n+\n+import com.github.dockerjava.api.model.Bind;\n+import com.github.dockerjava.api.model.Volume;\n+import io.zeebe.client.ZeebeClient;\n+import io.zeebe.containers.ZeebeBrokerContainer;\n+import java.time.Duration;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.elasticsearch.client.RestClient;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.elasticsearch.ElasticsearchContainer;\n+\n+public class DiskSpaceRecoveryITTest {\n+  static ZeebeBrokerContainer zeebeBroker;\n+  private static final Logger LOG = LoggerFactory.getLogger(\"TEST\");\n+  private static final String VOLUME_NAME = \"tmpdata1\";\n+  private static String containerIPAddress;\n+  private static Integer apiPort;\n+  private static ElasticsearchContainer elastic;\n+  private ZeebeClient client;\n+\n+  @BeforeClass\n+  public static void setUpClass() {\n+    final var elasticHostInternal = \"http://elastic:9200\";\n+    zeebeBroker = createZeebe(elasticHostInternal);\n+    final var network = zeebeBroker.getNetwork();\n+    elastic = createElastic(network);\n+    zeebeBroker.start();\n+\n+    apiPort = zeebeBroker.getMappedPort(26500);\n+    containerIPAddress = zeebeBroker.getContainerIpAddress();\n+  }\n+\n+  private static ZeebeBrokerContainer createZeebe(final String elasticHost) {\n+    zeebeBroker =\n+        new ZeebeBrokerContainer(\"current-test\")\n+            .withEnv(\n+                \"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_CLASSNAME\",\n+                \"io.zeebe.exporter.ElasticsearchExporter\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_URL\", elasticHost)\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_DELAY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_SIZE\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_SNAPSHOTPERIOD\", \"1m\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_LOGSEGMENTSIZE\", \"4MB\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK\", \"0.5\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_LOGINDEXDENSITY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_INDEX_MESSAGE\", \"true\");\n+\n+    zeebeBroker\n+        .getDockerClient()\n+        .createVolumeCmd()\n+        .withDriver(\"local\")\n+        .withDriverOpts(Map.of(\"type\", \"tmpfs\", \"device\", \"tmpfs\", \"o\", \"size=32m\"))\n+        .withName(VOLUME_NAME)\n+        .exec();\n+    final Volume newVolume = new Volume(\"/usr/local/zeebe/data\");\n+    zeebeBroker.withCreateContainerCmdModifier(\n+        cmd ->\n+            cmd.withHostConfig(cmd.getHostConfig().withBinds(new Bind(VOLUME_NAME, newVolume)))\n+                .withName(\"zeebe-test\"));\n+\n+    return zeebeBroker;\n+  }\n+\n+  private static ElasticsearchContainer createElastic(final Network network) {\n+    final ElasticsearchContainer container =\n+        new ElasticsearchContainer(\n+            \"docker.elastic.co/elasticsearch/elasticsearch:\"\n+                + RestClient.class.getPackage().getImplementationVersion());\n+\n+    container.withNetwork(network).withEnv(\"discovery.type\", \"single-node\");\n+    container.withCreateContainerCmdModifier(cmd -> cmd.withName(\"elastic\"));\n+    return container;\n+  }\n+\n+  @AfterClass\n+  public static void tearDownClass() {\n+    LoggerFactory.getLogger(\"Test\").info(zeebeBroker.getLogs());", "originalCommit": "ef515fed93020dc76d7b339d99e86b0fc50d4514", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NDE1OA==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448364158", "bodyText": "Not sure if we have to do this - stop from Testcontainers is actually more of a kill command, so it may also already be cleaning up the volumes, though we'd have to verify that.", "author": "npepinpe", "createdAt": "2020-07-01T13:30:18Z", "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static org.awaitility.Awaitility.await;\n+\n+import com.github.dockerjava.api.model.Bind;\n+import com.github.dockerjava.api.model.Volume;\n+import io.zeebe.client.ZeebeClient;\n+import io.zeebe.containers.ZeebeBrokerContainer;\n+import java.time.Duration;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.elasticsearch.client.RestClient;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.elasticsearch.ElasticsearchContainer;\n+\n+public class DiskSpaceRecoveryITTest {\n+  static ZeebeBrokerContainer zeebeBroker;\n+  private static final Logger LOG = LoggerFactory.getLogger(\"TEST\");\n+  private static final String VOLUME_NAME = \"tmpdata1\";\n+  private static String containerIPAddress;\n+  private static Integer apiPort;\n+  private static ElasticsearchContainer elastic;\n+  private ZeebeClient client;\n+\n+  @BeforeClass\n+  public static void setUpClass() {\n+    final var elasticHostInternal = \"http://elastic:9200\";\n+    zeebeBroker = createZeebe(elasticHostInternal);\n+    final var network = zeebeBroker.getNetwork();\n+    elastic = createElastic(network);\n+    zeebeBroker.start();\n+\n+    apiPort = zeebeBroker.getMappedPort(26500);\n+    containerIPAddress = zeebeBroker.getContainerIpAddress();\n+  }\n+\n+  private static ZeebeBrokerContainer createZeebe(final String elasticHost) {\n+    zeebeBroker =\n+        new ZeebeBrokerContainer(\"current-test\")\n+            .withEnv(\n+                \"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_CLASSNAME\",\n+                \"io.zeebe.exporter.ElasticsearchExporter\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_URL\", elasticHost)\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_DELAY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_SIZE\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_SNAPSHOTPERIOD\", \"1m\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_LOGSEGMENTSIZE\", \"4MB\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK\", \"0.5\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_LOGINDEXDENSITY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_INDEX_MESSAGE\", \"true\");\n+\n+    zeebeBroker\n+        .getDockerClient()\n+        .createVolumeCmd()\n+        .withDriver(\"local\")\n+        .withDriverOpts(Map.of(\"type\", \"tmpfs\", \"device\", \"tmpfs\", \"o\", \"size=32m\"))\n+        .withName(VOLUME_NAME)\n+        .exec();\n+    final Volume newVolume = new Volume(\"/usr/local/zeebe/data\");\n+    zeebeBroker.withCreateContainerCmdModifier(\n+        cmd ->\n+            cmd.withHostConfig(cmd.getHostConfig().withBinds(new Bind(VOLUME_NAME, newVolume)))\n+                .withName(\"zeebe-test\"));\n+\n+    return zeebeBroker;\n+  }\n+\n+  private static ElasticsearchContainer createElastic(final Network network) {\n+    final ElasticsearchContainer container =\n+        new ElasticsearchContainer(\n+            \"docker.elastic.co/elasticsearch/elasticsearch:\"\n+                + RestClient.class.getPackage().getImplementationVersion());\n+\n+    container.withNetwork(network).withEnv(\"discovery.type\", \"single-node\");\n+    container.withCreateContainerCmdModifier(cmd -> cmd.withName(\"elastic\"));\n+    return container;\n+  }\n+\n+  @AfterClass\n+  public static void tearDownClass() {\n+    LoggerFactory.getLogger(\"Test\").info(zeebeBroker.getLogs());\n+    zeebeBroker.stop();\n+    zeebeBroker.getDockerClient().removeVolumeCmd(VOLUME_NAME).exec();", "originalCommit": "ef515fed93020dc76d7b339d99e86b0fc50d4514", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc3NTI1Mw==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448775253", "bodyText": "Volume should be closed explicitly. I just verified it.", "author": "deepthidevaki", "createdAt": "2020-07-02T06:27:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NDE1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NDc5Nw==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448364797", "bodyText": "I'm not a fan of doesNotThrowAnyException - can't we assert that the message was published in some way?", "author": "npepinpe", "createdAt": "2020-07-01T13:31:17Z", "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static org.awaitility.Awaitility.await;\n+\n+import com.github.dockerjava.api.model.Bind;\n+import com.github.dockerjava.api.model.Volume;\n+import io.zeebe.client.ZeebeClient;\n+import io.zeebe.containers.ZeebeBrokerContainer;\n+import java.time.Duration;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.elasticsearch.client.RestClient;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.elasticsearch.ElasticsearchContainer;\n+\n+public class DiskSpaceRecoveryITTest {\n+  static ZeebeBrokerContainer zeebeBroker;\n+  private static final Logger LOG = LoggerFactory.getLogger(\"TEST\");\n+  private static final String VOLUME_NAME = \"tmpdata1\";\n+  private static String containerIPAddress;\n+  private static Integer apiPort;\n+  private static ElasticsearchContainer elastic;\n+  private ZeebeClient client;\n+\n+  @BeforeClass\n+  public static void setUpClass() {\n+    final var elasticHostInternal = \"http://elastic:9200\";\n+    zeebeBroker = createZeebe(elasticHostInternal);\n+    final var network = zeebeBroker.getNetwork();\n+    elastic = createElastic(network);\n+    zeebeBroker.start();\n+\n+    apiPort = zeebeBroker.getMappedPort(26500);\n+    containerIPAddress = zeebeBroker.getContainerIpAddress();\n+  }\n+\n+  private static ZeebeBrokerContainer createZeebe(final String elasticHost) {\n+    zeebeBroker =\n+        new ZeebeBrokerContainer(\"current-test\")\n+            .withEnv(\n+                \"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_CLASSNAME\",\n+                \"io.zeebe.exporter.ElasticsearchExporter\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_URL\", elasticHost)\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_DELAY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_SIZE\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_SNAPSHOTPERIOD\", \"1m\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_LOGSEGMENTSIZE\", \"4MB\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK\", \"0.5\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_LOGINDEXDENSITY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_INDEX_MESSAGE\", \"true\");\n+\n+    zeebeBroker\n+        .getDockerClient()\n+        .createVolumeCmd()\n+        .withDriver(\"local\")\n+        .withDriverOpts(Map.of(\"type\", \"tmpfs\", \"device\", \"tmpfs\", \"o\", \"size=32m\"))\n+        .withName(VOLUME_NAME)\n+        .exec();\n+    final Volume newVolume = new Volume(\"/usr/local/zeebe/data\");\n+    zeebeBroker.withCreateContainerCmdModifier(\n+        cmd ->\n+            cmd.withHostConfig(cmd.getHostConfig().withBinds(new Bind(VOLUME_NAME, newVolume)))\n+                .withName(\"zeebe-test\"));\n+\n+    return zeebeBroker;\n+  }\n+\n+  private static ElasticsearchContainer createElastic(final Network network) {\n+    final ElasticsearchContainer container =\n+        new ElasticsearchContainer(\n+            \"docker.elastic.co/elasticsearch/elasticsearch:\"\n+                + RestClient.class.getPackage().getImplementationVersion());\n+\n+    container.withNetwork(network).withEnv(\"discovery.type\", \"single-node\");\n+    container.withCreateContainerCmdModifier(cmd -> cmd.withName(\"elastic\"));\n+    return container;\n+  }\n+\n+  @AfterClass\n+  public static void tearDownClass() {\n+    LoggerFactory.getLogger(\"Test\").info(zeebeBroker.getLogs());\n+    zeebeBroker.stop();\n+    zeebeBroker.getDockerClient().removeVolumeCmd(VOLUME_NAME).exec();\n+    elastic.stop();\n+  }\n+\n+  @Test\n+  public void shouldRecoverAfterOutOfDiskSpaceWhenExporterStarts() {\n+    // given\n+    client =\n+        ZeebeClient.newClientBuilder()\n+            .brokerContactPoint(containerIPAddress + \":\" + apiPort)\n+            .usePlaintext()\n+            .build();\n+\n+    // when\n+    LOG.info(\"Wait until broker is out of disk space\");\n+    await()\n+        .timeout(Duration.ofMinutes(3))\n+        .pollInterval(1, TimeUnit.MICROSECONDS)\n+        .untilAsserted(\n+            () ->\n+                assertThatThrownBy(this::publishMessage)\n+                    .hasRootCauseMessage(\n+                        \"RESOURCE_EXHAUSTED: Cannot accept requests for partition 1. Broker is out of disk space\"));\n+\n+    elastic.start();\n+\n+    // then\n+    await()\n+        .pollInterval(Duration.ofSeconds(10))\n+        .timeout(Duration.ofMinutes(5))\n+        .untilAsserted(() -> assertThatCode(this::publishMessage).doesNotThrowAnyException());", "originalCommit": "ef515fed93020dc76d7b339d99e86b0fc50d4514", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM3NDAxMg==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448374012", "bodyText": "Btw I thought we fixed that publish message doesnt return anything? Shouldn't it return a response now?", "author": "Zelldon", "createdAt": "2020-07-01T13:45:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NDc5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM3NTQ2MA==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448375460", "bodyText": "Was added with #3820", "author": "Zelldon", "createdAt": "2020-07-01T13:47:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NDc5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc3MDYzOQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448770639", "bodyText": "It returns a type 'PublishMessageResponse'. But it is still empty.", "author": "deepthidevaki", "createdAt": "2020-07-02T06:14:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NDc5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkwOTM3Ng==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448909376", "bodyText": "Similar as how we return deployment keys, we should return message keys - helpful to correlate things with an exporter stream, for example. @Zelldon already opened an issue for it \ud83d\ude09 #4794\nThat said, you can still assert you get an non null PublishMessageResponse (or whatever it is) as a result, no? Wouldn't that always indicate success?", "author": "npepinpe", "createdAt": "2020-07-02T10:36:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NDc5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkyNzgzNA==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448927834", "bodyText": "assert(..).isNotNull() did not work.", "author": "deepthidevaki", "createdAt": "2020-07-02T11:14:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NDc5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDg0MzM3Mg==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r450843372", "bodyText": "Hm, curious, wasn't expecting that. Well I'm fine leaving it like this, but I would propose we try to avoid it in general.", "author": "npepinpe", "createdAt": "2020-07-07T12:57:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NDc5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkwNjcyMg==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448906722", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n               * @return the percentage of disk space that must be available before log compaction is forced\n          \n          \n            \n               * @return the amount of disk space that must be available before log compaction is forced", "author": "npepinpe", "createdAt": "2020-07-02T10:31:06Z", "path": "atomix/cluster/src/main/java/io/atomix/raft/storage/RaftStorage.java", "diffHunk": "@@ -189,7 +189,7 @@ public boolean dynamicCompaction() {\n    *\n    * @return the percentage of disk space that must be available before log compaction is forced", "originalCommit": "3e908944dc07b3762a4370ca610633fcae49d05d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "27c71401e65fada4a7b2dbb82dcc43d622a278cb", "url": "https://github.com/camunda-cloud/zeebe/commit/27c71401e65fada4a7b2dbb82dcc43d622a278cb", "message": "chore(qa): increase timeout", "committedDate": "2020-07-03T06:39:01Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDAyNzc0OA==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r450027748", "bodyText": "This needs then probably also be changed\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n               * Returns the percentage of disk space that must be available before log compaction is forced.\n          \n          \n            \n               * Returns the amount of disk space that must be available before log compaction is forced.", "author": "Zelldon", "createdAt": "2020-07-06T07:17:44Z", "path": "atomix/cluster/src/main/java/io/atomix/raft/storage/RaftStorage.java", "diffHunk": "@@ -187,7 +187,7 @@ public boolean dynamicCompaction() {\n   /**\n    * Returns the percentage of disk space that must be available before log compaction is forced.", "originalCommit": "cf6a16feb70194668781c9f18e9733526ebd0f67", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "c491d7a819c2b520180353b9eef5ff80fe9d2d5b", "url": "https://github.com/camunda-cloud/zeebe/commit/c491d7a819c2b520180353b9eef5ff80fe9d2d5b", "message": "chore(broker): handle out of disk space in broker\n* expose configuration parameters for minimum free disk space\n* When broker free disk space available is less than configured min free disk,\n  - reject client requests\n  - reject commands from other partitions\n  - pause stream processor", "committedDate": "2020-07-06T09:12:37Z", "type": "forcePushed"}, {"oid": "602bcda664eae589ec7bd7d1c54b965ab65a46c6", "url": "https://github.com/camunda-cloud/zeebe/commit/602bcda664eae589ec7bd7d1c54b965ab65a46c6", "message": "chore(broker): handle out of disk space in broker\n* expose configuration parameters for minimum free disk space\n* When broker free disk space available is less than configured min free disk,\n  - reject client requests\n  - reject commands from other partitions\n  - pause stream processor", "committedDate": "2020-07-07T10:18:38Z", "type": "forcePushed"}, {"oid": "32a1434728701bb0df1e92ef6fcaf43bc42fcea4", "url": "https://github.com/camunda-cloud/zeebe/commit/32a1434728701bb0df1e92ef6fcaf43bc42fcea4", "message": "chore(broker): handle out of disk space in broker\n* expose configuration parameters for minimum free disk space\n* When broker free disk space available is less than configured min free disk,\n  - reject client requests\n  - reject commands from other partitions\n  - pause stream processor", "committedDate": "2020-07-08T07:12:55Z", "type": "forcePushed"}, {"oid": "9b14bc0955df46f870fb58b34d71a0ee967306c2", "url": "https://github.com/camunda-cloud/zeebe/commit/9b14bc0955df46f870fb58b34d71a0ee967306c2", "message": "chore(broker): handle out of disk space in broker\n* expose configuration parameters for minimum free disk space\n* When broker free disk space available is less than configured min free disk,\n  - reject client requests\n  - reject commands from other partitions\n  - pause stream processor", "committedDate": "2020-07-08T14:37:10Z", "type": "forcePushed"}, {"oid": "c1a0b019c2d29ac4cc998a20721661899da61052", "url": "https://github.com/camunda-cloud/zeebe/commit/c1a0b019c2d29ac4cc998a20721661899da61052", "message": "chore(broker): handle out of disk space in broker\n* expose configuration parameters for minimum free disk space\n* When broker free disk space available is less than configured min free disk,\n  - reject client requests\n  - reject commands from other partitions\n  - pause stream processor", "committedDate": "2020-07-09T13:38:19Z", "type": "commit"}, {"oid": "c1a0b019c2d29ac4cc998a20721661899da61052", "url": "https://github.com/camunda-cloud/zeebe/commit/c1a0b019c2d29ac4cc998a20721661899da61052", "message": "chore(broker): handle out of disk space in broker\n* expose configuration parameters for minimum free disk space\n* When broker free disk space available is less than configured min free disk,\n  - reject client requests\n  - reject commands from other partitions\n  - pause stream processor", "committedDate": "2020-07-09T13:38:19Z", "type": "forcePushed"}]}