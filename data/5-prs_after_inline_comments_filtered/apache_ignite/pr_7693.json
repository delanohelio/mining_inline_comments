{"pr_number": 7693, "pr_title": "IGNITE-12666 Provide cluster performance profiling tool", "pr_createdAt": "2020-04-20T07:45:18Z", "pr_url": "https://github.com/apache/ignite/pull/7693", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkxODE0Nw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r454918147", "bodyText": "Let's make this class internal in the AbstractPerformanceStatisticsTest.", "author": "nizhikov", "createdAt": "2020-07-15T09:29:14Z", "path": "modules/core/src/test/java/org/apache/ignite/internal/processors/performancestatistics/TestHandler.java", "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.util.UUID;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.lang.IgniteUuid;\n+\n+/**\n+ * Test performance statistics handler.\n+ */\n+public class TestHandler implements PerformanceStatisticsHandler {", "originalCommit": "470587263f9bddc8dd52b14cac35fbd1bff7f4d3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkyNjMwNQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r454926305", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-15T09:43:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkxODE0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkxODMxNA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r454918314", "bodyText": "Typo: javadoc required.", "author": "nizhikov", "createdAt": "2020-07-15T09:29:32Z", "path": "modules/core/src/test/java/org/apache/ignite/internal/processors/performancestatistics/TestHandler.java", "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.util.UUID;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.lang.IgniteUuid;\n+\n+/**\n+ * Test performance statistics handler.\n+ */\n+public class TestHandler implements PerformanceStatisticsHandler {\n+    @Override public void cacheOperation(UUID nodeId, OperationType type, int cacheId, long startTime, long duration) {\n+        // No-op.\n+    }\n+\n+    @Override public void transaction(UUID nodeId, GridIntList cacheIds, long startTime, long duration,", "originalCommit": "470587263f9bddc8dd52b14cac35fbd1bff7f4d3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkyNjM2NA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r454926364", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-15T09:43:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkxODMxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkyMDA4Mw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r454920083", "bodyText": "We should clear persistence value in the finally block.", "author": "nizhikov", "createdAt": "2020-07-15T09:32:21Z", "path": "modules/core/src/test/java/org/apache/ignite/internal/processors/performancestatistics/TopologyChangesTest.java", "diffHunk": "@@ -0,0 +1,136 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import org.apache.ignite.cluster.ClusterState;\n+import org.apache.ignite.configuration.DataRegionConfiguration;\n+import org.apache.ignite.configuration.DataStorageConfiguration;\n+import org.apache.ignite.configuration.IgniteConfiguration;\n+import org.apache.ignite.internal.IgniteEx;\n+import org.junit.Test;\n+\n+/**\n+ * Tests topology changes during collecting performance statistics.\n+ */\n+public class TopologyChangesTest extends AbstractPerformanceStatisticsTest {\n+    /** */\n+    private boolean persistence;\n+\n+    /** {@inheritDoc} */\n+    @Override protected IgniteConfiguration getConfiguration(String igniteInstanceName) throws Exception {\n+        IgniteConfiguration cfg = super.getConfiguration(igniteInstanceName);\n+\n+        cfg.setDataStorageConfiguration(\n+            new DataStorageConfiguration()\n+                .setDefaultDataRegionConfiguration(\n+                    new DataRegionConfiguration().setPersistenceEnabled(persistence)\n+                )\n+        );\n+\n+        return cfg;\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override protected void beforeTest() throws Exception {\n+        super.beforeTest();\n+\n+        stopAllGrids();\n+\n+        cleanPersistenceDir();\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override protected void afterTest() throws Exception {\n+        super.afterTest();\n+\n+        stopAllGrids();\n+\n+        cleanPersistenceDir();\n+    }\n+\n+    /** @throws Exception If failed. */\n+    @Test\n+    public void testNodeJoin() throws Exception {\n+        startGrid(0);\n+\n+        startCollectStatistics();\n+\n+        startGrid(1);\n+\n+        waitForStatisticsEnabled(true);\n+    }\n+\n+    /** @throws Exception If failed. */\n+    @Test\n+    public void testClusterRestartWithPersistence() throws Exception {\n+        persistence = true;", "originalCommit": "470587263f9bddc8dd52b14cac35fbd1bff7f4d3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkyMDYxOA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r454920618", "bodyText": "Can we execute all tests both in the persistence and non-persistence mode?\nWe can use Parametrized test for this.", "author": "nizhikov", "createdAt": "2020-07-15T09:33:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkyMDA4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkyMzA1OA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r454923058", "bodyText": "No, it is unnecessary. JUnit creates a new instance for each test", "author": "NSAmelchev", "createdAt": "2020-07-15T09:37:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkyMDA4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk3Njk4Mw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r454976983", "bodyText": "I have used Parametrized for tests.", "author": "NSAmelchev", "createdAt": "2020-07-15T11:18:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkyMDA4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkyNTIxMg==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r454925212", "bodyText": "Typo: formatting.", "author": "nizhikov", "createdAt": "2020-07-15T09:41:14Z", "path": "modules/core/src/test/java/org/apache/ignite/internal/processors/performancestatistics/PerformanceStatisticsSelfTest.java", "diffHunk": "@@ -0,0 +1,290 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.UUID;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.locks.Lock;\n+import java.util.function.Consumer;\n+import javax.cache.processor.EntryProcessor;\n+import javax.cache.processor.EntryProcessorException;\n+import javax.cache.processor.MutableEntry;\n+import org.apache.ignite.IgniteCache;\n+import org.apache.ignite.cache.CacheEntryProcessor;\n+import org.apache.ignite.cluster.ClusterState;\n+import org.apache.ignite.configuration.IgniteConfiguration;\n+import org.apache.ignite.internal.IgniteEx;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.lang.IgniteRunnable;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.testframework.ListeningTestLogger;\n+import org.apache.ignite.testframework.junits.GridAbstractTest;\n+import org.apache.ignite.transactions.Transaction;\n+import org.junit.Test;\n+\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_GET;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_GET_ALL;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_GET_AND_PUT;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_GET_AND_REMOVE;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_INVOKE;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_INVOKE_ALL;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_LOCK;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_PUT;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_PUT_ALL;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_REMOVE;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_REMOVE_ALL;\n+\n+/**\n+ * Tests performance statistics.\n+ */\n+@SuppressWarnings({\"LockAcquiredButNotSafelyReleased\"})\n+public class PerformanceStatisticsSelfTest extends AbstractPerformanceStatisticsTest {\n+    /** Test entry processor. */\n+    private static final EntryProcessor<Object, Object, Object> ENTRY_PROC =\n+        new EntryProcessor<Object, Object, Object>() {\n+        @Override public Object process(MutableEntry<Object, Object> entry, Object... arguments)\n+            throws EntryProcessorException {\n+            return null;\n+        }\n+    };\n+\n+    /** Test cache entry processor. */\n+    private static final CacheEntryProcessor<Object, Object, Object> CACHE_ENTRY_PROC =\n+        new CacheEntryProcessor<Object, Object, Object>() {\n+        @Override public Object process(MutableEntry<Object, Object> entry, Object... arguments)\n+            throws EntryProcessorException {\n+            return null;\n+        }\n+    };\n+\n+    /** Cache entry count. */\n+    private static final int ENTRY_COUNT = 100;\n+\n+    /** Ignite. */\n+    private static IgniteEx ignite;\n+\n+    /** Test cache. */\n+    private static IgniteCache<Object, Object> cache;\n+\n+    /** {@inheritDoc} */\n+    @Override protected IgniteConfiguration getConfiguration(String igniteInstanceName) throws Exception {\n+        IgniteConfiguration cfg = super.getConfiguration(igniteInstanceName);\n+\n+        cfg.setCacheConfiguration(defaultCacheConfiguration());\n+\n+        return cfg;\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override protected void beforeTestsStarted() throws Exception {\n+        log = new ListeningTestLogger(GridAbstractTest.log);\n+\n+        ignite = startGrid(0);\n+\n+        ignite.cluster().state(ClusterState.ACTIVE);\n+\n+        cache = ignite.cache(DEFAULT_CACHE_NAME);\n+\n+        for (int i = 0; i < ENTRY_COUNT; i++)\n+            cache.put(i, i);\n+    }\n+\n+    /** @throws Exception If failed. */\n+    @Test\n+    public void testCompute() throws Exception {\n+        String testTaskName = \"testTask\";\n+        int executions = 5;\n+\n+        startCollectStatistics();\n+\n+        IgniteRunnable task = new IgniteRunnable() {\n+            @Override public void run() {\n+                // No-op.\n+            }\n+        };\n+\n+        for (int i = 0; i < executions; i++)\n+            ignite.compute().withName(testTaskName).run(task);\n+\n+        HashMap<IgniteUuid, Integer> sessions = new HashMap<>();\n+        AtomicInteger tasks = new AtomicInteger();\n+        AtomicInteger jobs = new AtomicInteger();\n+\n+        stopCollectStatisticsAndRead(new TestHandler() {\n+            @Override public void task(UUID nodeId, IgniteUuid sesId, String taskName, long startTime, long duration,\n+                int affPartId) {\n+                sessions.compute(sesId, (uuid, val) -> val == null ? 1 : ++val);\n+\n+                tasks.incrementAndGet();\n+\n+                assertEquals(ignite.context().localNodeId(), nodeId);\n+                assertEquals(testTaskName, taskName);\n+                assertTrue(startTime > 0);\n+                assertTrue(duration >= 0);\n+                assertEquals(-1, affPartId);\n+            }\n+\n+            @Override public void job(UUID nodeId, IgniteUuid sesId, long queuedTime, long startTime, long duration,\n+            boolean timedOut) {", "originalCommit": "470587263f9bddc8dd52b14cac35fbd1bff7f4d3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkyNjQ1Mg==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r454926452", "bodyText": "Fixed.", "author": "NSAmelchev", "createdAt": "2020-07-15T09:43:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkyNTIxMg=="}], "type": "inlineReview"}, {"oid": "5e26fb7343649e764f433f528e93683ac783a8f3", "url": "https://github.com/apache/ignite/commit/5e26fb7343649e764f433f528e93683ac783a8f3", "message": "Review fixes", "committedDate": "2020-07-15T09:42:51Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkyODQyOQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r454928429", "bodyText": "val should be renamed to cnt here and below.", "author": "nizhikov", "createdAt": "2020-07-15T09:46:37Z", "path": "modules/core/src/test/java/org/apache/ignite/internal/processors/performancestatistics/PerformanceStatisticsSelfTest.java", "diffHunk": "@@ -0,0 +1,290 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.UUID;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.locks.Lock;\n+import java.util.function.Consumer;\n+import javax.cache.processor.EntryProcessor;\n+import javax.cache.processor.EntryProcessorException;\n+import javax.cache.processor.MutableEntry;\n+import org.apache.ignite.IgniteCache;\n+import org.apache.ignite.cache.CacheEntryProcessor;\n+import org.apache.ignite.cluster.ClusterState;\n+import org.apache.ignite.configuration.IgniteConfiguration;\n+import org.apache.ignite.internal.IgniteEx;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.lang.IgniteRunnable;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.testframework.ListeningTestLogger;\n+import org.apache.ignite.testframework.junits.GridAbstractTest;\n+import org.apache.ignite.transactions.Transaction;\n+import org.junit.Test;\n+\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_GET;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_GET_ALL;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_GET_AND_PUT;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_GET_AND_REMOVE;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_INVOKE;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_INVOKE_ALL;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_LOCK;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_PUT;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_PUT_ALL;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_REMOVE;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_REMOVE_ALL;\n+\n+/**\n+ * Tests performance statistics.\n+ */\n+@SuppressWarnings({\"LockAcquiredButNotSafelyReleased\"})\n+public class PerformanceStatisticsSelfTest extends AbstractPerformanceStatisticsTest {\n+    /** Test entry processor. */\n+    private static final EntryProcessor<Object, Object, Object> ENTRY_PROC =\n+        new EntryProcessor<Object, Object, Object>() {\n+        @Override public Object process(MutableEntry<Object, Object> entry, Object... arguments)\n+            throws EntryProcessorException {\n+            return null;\n+        }\n+    };\n+\n+    /** Test cache entry processor. */\n+    private static final CacheEntryProcessor<Object, Object, Object> CACHE_ENTRY_PROC =\n+        new CacheEntryProcessor<Object, Object, Object>() {\n+        @Override public Object process(MutableEntry<Object, Object> entry, Object... arguments)\n+            throws EntryProcessorException {\n+            return null;\n+        }\n+    };\n+\n+    /** Cache entry count. */\n+    private static final int ENTRY_COUNT = 100;\n+\n+    /** Ignite. */\n+    private static IgniteEx ignite;\n+\n+    /** Test cache. */\n+    private static IgniteCache<Object, Object> cache;\n+\n+    /** {@inheritDoc} */\n+    @Override protected IgniteConfiguration getConfiguration(String igniteInstanceName) throws Exception {\n+        IgniteConfiguration cfg = super.getConfiguration(igniteInstanceName);\n+\n+        cfg.setCacheConfiguration(defaultCacheConfiguration());\n+\n+        return cfg;\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override protected void beforeTestsStarted() throws Exception {\n+        log = new ListeningTestLogger(GridAbstractTest.log);\n+\n+        ignite = startGrid(0);\n+\n+        ignite.cluster().state(ClusterState.ACTIVE);\n+\n+        cache = ignite.cache(DEFAULT_CACHE_NAME);\n+\n+        for (int i = 0; i < ENTRY_COUNT; i++)\n+            cache.put(i, i);\n+    }\n+\n+    /** @throws Exception If failed. */\n+    @Test\n+    public void testCompute() throws Exception {\n+        String testTaskName = \"testTask\";\n+        int executions = 5;\n+\n+        startCollectStatistics();\n+\n+        IgniteRunnable task = new IgniteRunnable() {\n+            @Override public void run() {\n+                // No-op.\n+            }\n+        };\n+\n+        for (int i = 0; i < executions; i++)\n+            ignite.compute().withName(testTaskName).run(task);\n+\n+        HashMap<IgniteUuid, Integer> sessions = new HashMap<>();\n+        AtomicInteger tasks = new AtomicInteger();\n+        AtomicInteger jobs = new AtomicInteger();\n+\n+        stopCollectStatisticsAndRead(new TestHandler() {\n+            @Override public void task(UUID nodeId, IgniteUuid sesId, String taskName, long startTime, long duration,\n+                int affPartId) {\n+                sessions.compute(sesId, (uuid, val) -> val == null ? 1 : ++val);\n+\n+                tasks.incrementAndGet();\n+\n+                assertEquals(ignite.context().localNodeId(), nodeId);\n+                assertEquals(testTaskName, taskName);\n+                assertTrue(startTime > 0);\n+                assertTrue(duration >= 0);\n+                assertEquals(-1, affPartId);\n+            }\n+\n+            @Override public void job(UUID nodeId, IgniteUuid sesId, long queuedTime, long startTime, long duration,\n+            boolean timedOut) {\n+                sessions.compute(sesId, (uuid, val) -> val == null ? 1 : ++val);", "originalCommit": "470587263f9bddc8dd52b14cac35fbd1bff7f4d3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk0NjA1MA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r454946050", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-15T10:17:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkyODQyOQ=="}], "type": "inlineReview"}, {"oid": "4b886d5823f31a24bfb1b49e07ab45649c745b40", "url": "https://github.com/apache/ignite/commit/4b886d5823f31a24bfb1b49e07ab45649c745b40", "message": "Var renaming", "committedDate": "2020-07-15T10:17:42Z", "type": "commit"}, {"oid": "2ad9b68b0fc5937f94df34082cf4dd82863c736e", "url": "https://github.com/apache/ignite/commit/2ad9b68b0fc5937f94df34082cf4dd82863c736e", "message": "Parameterized test", "committedDate": "2020-07-15T11:15:02Z", "type": "commit"}, {"oid": "2c6643bb1d41f11484a1581b8b73b9e16632c627", "url": "https://github.com/apache/ignite/commit/2c6643bb1d41f11484a1581b8b73b9e16632c627", "message": "Remove unnecessary cleanup directory for non-persist tests", "committedDate": "2020-07-15T11:17:48Z", "type": "commit"}, {"oid": "644dc2845b2283c26a265c0357b0f9f361ce4cbd", "url": "https://github.com/apache/ignite/commit/644dc2845b2283c26a265c0357b0f9f361ce4cbd", "message": "Revert unnecessary changes", "committedDate": "2020-07-15T11:23:04Z", "type": "commit"}, {"oid": "2012653e3c1a2adebdd7103f21d2663ba7d5677b", "url": "https://github.com/apache/ignite/commit/2012653e3c1a2adebdd7103f21d2663ba7d5677b", "message": "Revert unnecessary changes 2", "committedDate": "2020-07-15T11:26:15Z", "type": "commit"}, {"oid": "abd7678b1d75421a7cff0ed1015757b0e6c32790", "url": "https://github.com/apache/ignite/commit/abd7678b1d75421a7cff0ed1015757b0e6c32790", "message": "Inlude system transactions", "committedDate": "2020-07-15T11:29:01Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTY1NDY4NQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r455654685", "bodyText": "We should add tests with pageSize less than the entire result set to ensure that with the several pages we track all query results correctly.", "author": "nizhikov", "createdAt": "2020-07-16T09:32:55Z", "path": "modules/indexing/src/test/java/org/apache/ignite/internal/processors/performancestatistics/PerformanceStatisticsQueryTest.java", "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.ignite.IgniteCache;\n+import org.apache.ignite.cache.QueryEntity;\n+import org.apache.ignite.cache.query.Query;\n+import org.apache.ignite.cache.query.ScanQuery;\n+import org.apache.ignite.cache.query.SqlFieldsQuery;\n+import org.apache.ignite.configuration.CacheConfiguration;\n+import org.apache.ignite.configuration.DataRegionConfiguration;\n+import org.apache.ignite.configuration.DataStorageConfiguration;\n+import org.apache.ignite.configuration.IgniteConfiguration;\n+import org.apache.ignite.internal.IgniteEx;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.junit.Test;\n+\n+import static org.apache.ignite.cluster.ClusterState.ACTIVE;\n+import static org.apache.ignite.cluster.ClusterState.INACTIVE;\n+import static org.apache.ignite.internal.processors.cache.query.GridCacheQueryType.SCAN;\n+import static org.apache.ignite.internal.processors.cache.query.GridCacheQueryType.SQL_FIELDS;\n+\n+/** Tests query performance statistics. */\n+public class PerformanceStatisticsQueryTest extends AbstractPerformanceStatisticsTest {\n+    /** Cache entry count. */\n+    private static final int ENTRY_COUNT = 100;", "originalCommit": "abd7678b1d75421a7cff0ed1015757b0e6c32790", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzkxODA2Nw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r457918067", "bodyText": "Page size added", "author": "NSAmelchev", "createdAt": "2020-07-21T08:14:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTY1NDY4NQ=="}], "type": "inlineReview"}, {"oid": "039199daf3005bb1b801096e304a5cda8d307dfb", "url": "https://github.com/apache/ignite/commit/039199daf3005bb1b801096e304a5cda8d307dfb", "message": "Add ddl dml query test", "committedDate": "2020-07-16T10:18:50Z", "type": "commit"}, {"oid": "750fa4ad1fb734dade599ef308e2a3a54bf15db9", "url": "https://github.com/apache/ignite/commit/750fa4ad1fb734dade599ef308e2a3a54bf15db9", "message": "Fix query reads multiple pages", "committedDate": "2020-07-20T11:26:07Z", "type": "commit"}, {"oid": "5284a7a5b8c05e7a71a985b5c9d2f5ad3f686b13", "url": "https://github.com/apache/ignite/commit/5284a7a5b8c05e7a71a985b5c9d2f5ad3f686b13", "message": "Fix reads ids for DML sql fields queries", "committedDate": "2020-07-20T22:02:32Z", "type": "commit"}, {"oid": "ad5539e33dac5274d0bfe21808b0df3979098145", "url": "https://github.com/apache/ignite/commit/ad5539e33dac5274d0bfe21808b0df3979098145", "message": "Handle only sql type queries", "committedDate": "2020-07-20T22:36:24Z", "type": "commit"}, {"oid": "cd11d9c78114a8db40e9a80be7d1caa3014ea93c", "url": "https://github.com/apache/ignite/commit/cd11d9c78114a8db40e9a80be7d1caa3014ea93c", "message": "Remove unnecessary reads holder", "committedDate": "2020-07-21T08:13:07Z", "type": "commit"}, {"oid": "3d4482e7006c7c5e5b467e7580b4304be3cfe73e", "url": "https://github.com/apache/ignite/commit/3d4482e7006c7c5e5b467e7580b4304be3cfe73e", "message": "+ join query tests, additional reads checks", "committedDate": "2020-07-21T14:23:28Z", "type": "commit"}, {"oid": "cf2c4bcb1fba572f0c765def10d7b628219b3e4e", "url": "https://github.com/apache/ignite/commit/cf2c4bcb1fba572f0c765def10d7b628219b3e4e", "message": "fix codestyle", "committedDate": "2020-07-23T13:39:30Z", "type": "commit"}, {"oid": "660203eb54f6ad58c949ada8f5950dfce41e3e69", "url": "https://github.com/apache/ignite/commit/660203eb54f6ad58c949ada8f5950dfce41e3e69", "message": "Merge branch 'master' into ignite-12666\n\n# Conflicts:\n#\tmodules/core/src/main/java/org/apache/ignite/internal/IgniteFeatures.java", "committedDate": "2020-07-23T13:40:24Z", "type": "commit"}, {"oid": "4e90d99909e9ae29ac7d2dc1607fd6a3079ccad9", "url": "https://github.com/apache/ignite/commit/4e90d99909e9ae29ac7d2dc1607fd6a3079ccad9", "message": "Merge branch 'master' into ignite-12666\n\n# Conflicts:\n#\tmodules/core/src/main/java/org/apache/ignite/internal/processors/cache/transactions/IgniteTxAdapter.java", "committedDate": "2020-08-10T08:14:33Z", "type": "commit"}, {"oid": "17446c4e7423aae2c63380e6b220eaade09e5ff4", "url": "https://github.com/apache/ignite/commit/17446c4e7423aae2c63380e6b220eaade09e5ff4", "message": "Merge branch 'master' into ignite-12666\n\n# Conflicts:\n#\tmodules/core/src/main/java/org/apache/ignite/internal/IgniteFeatures.java", "committedDate": "2020-08-19T13:46:19Z", "type": "commit"}, {"oid": "6ddcd4c7ac3d96975960ed605b6809731dec84bc", "url": "https://github.com/apache/ignite/commit/6ddcd4c7ac3d96975960ed605b6809731dec84bc", "message": "Fix feature ID.", "committedDate": "2020-08-19T13:47:52Z", "type": "commit"}, {"oid": "07480f1cc2668a794351ae9ab468a9ff4c358b82", "url": "https://github.com/apache/ignite/commit/07480f1cc2668a794351ae9ab468a9ff4c358b82", "message": "code review fixes", "committedDate": "2020-08-21T14:43:47Z", "type": "commit"}, {"oid": "167b3b680d45e0b11626675e75a242be56eee69b", "url": "https://github.com/apache/ignite/commit/167b3b680d45e0b11626675e75a242be56eee69b", "message": "Merge branch 'master' into ignite-12666\n\n# Conflicts:\n#\tmodules/core/src/main/java/org/apache/ignite/internal/IgniteFeatures.java", "committedDate": "2020-09-09T15:14:04Z", "type": "commit"}, {"oid": "e3e45a1e89d660006d424917bced69e00ec93c5c", "url": "https://github.com/apache/ignite/commit/e3e45a1e89d660006d424917bced69e00ec93c5c", "message": "Thin client tests. Gather local iterator stats. Minor fixes.", "committedDate": "2020-09-09T21:48:17Z", "type": "commit"}, {"oid": "176d8b57526304183ef06537d05c732a6bdbbab2", "url": "https://github.com/apache/ignite/commit/176d8b57526304183ef06537d05c732a6bdbbab2", "message": "fix modifiers", "committedDate": "2020-09-10T08:50:28Z", "type": "commit"}, {"oid": "a62a9b37f05c80ca3192287a29f3d429b7564a0c", "url": "https://github.com/apache/ignite/commit/a62a9b37f05c80ca3192287a29f3d429b7564a0c", "message": "Fix javadocs", "committedDate": "2020-09-10T10:35:13Z", "type": "commit"}, {"oid": "0ca93bbbf29a6e7cb2e70507a9a6bd387cd86285", "url": "https://github.com/apache/ignite/commit/0ca93bbbf29a6e7cb2e70507a9a6bd387cd86285", "message": "Fix try finally", "committedDate": "2020-09-10T11:48:38Z", "type": "commit"}, {"oid": "3bae9b099b021f0a83119fbedba5a394a8f4ea0d", "url": "https://github.com/apache/ignite/commit/3bae9b099b021f0a83119fbedba5a394a8f4ea0d", "message": "Add load from client node to tests", "committedDate": "2020-09-11T08:30:31Z", "type": "commit"}, {"oid": "4ff3aca00b06c356dcf2b465b01a62982db87982", "url": "https://github.com/apache/ignite/commit/4ff3aca00b06c356dcf2b465b01a62982db87982", "message": "Remove unnecessary changes", "committedDate": "2020-09-11T10:15:14Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzcwMDIxMA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r487700210", "bodyText": "LoadNode -> ClientType", "author": "nizhikov", "createdAt": "2020-09-14T07:20:07Z", "path": "modules/core/src/test/java/org/apache/ignite/internal/processors/performancestatistics/AbstractPerformanceStatisticsTest.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.lang.management.ThreadInfo;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.UUID;\n+import org.apache.ignite.Ignite;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.G;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.mxbean.PerformanceStatisticsMBean;\n+import org.apache.ignite.testframework.junits.common.GridCommonAbstractTest;\n+\n+import static org.apache.ignite.internal.processors.performancestatistics.FilePerformanceStatisticsWriter.PERF_STAT_DIR;\n+import static org.apache.ignite.internal.processors.performancestatistics.FilePerformanceStatisticsWriter.WRITER_THREAD_NAME;\n+import static org.apache.ignite.testframework.GridTestUtils.waitForCondition;\n+\n+/**\n+ * Ignite performance statistics abstract test.\n+ */\n+public abstract class AbstractPerformanceStatisticsTest extends GridCommonAbstractTest {\n+    /** */\n+    public static final long TIMEOUT = 30_000;\n+\n+    /** {@inheritDoc} */\n+    @Override protected void beforeTestsStarted() throws Exception {\n+        super.beforeTestsStarted();\n+\n+        U.resolveWorkDirectory(U.defaultWorkDirectory(), PERF_STAT_DIR, true);\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override protected void afterTestsStopped() throws Exception {\n+        super.afterTestsStopped();\n+\n+        stopAllGrids();\n+\n+        U.resolveWorkDirectory(U.defaultWorkDirectory(), PERF_STAT_DIR, true);\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    protected static void startCollectStatistics() throws Exception {\n+        List<Ignite> grids = G.allGrids();\n+\n+        assertFalse(grids.isEmpty());\n+\n+        statisticsMBean(grids.get(0).name()).start();\n+\n+        waitForStatisticsEnabled(true);\n+    }\n+\n+    /** Stops and reads collecting performance statistics. */\n+    protected static void stopCollectStatisticsAndRead(TestHandler... handlers) throws Exception {\n+        List<Ignite> grids = G.allGrids();\n+\n+        assertFalse(grids.isEmpty());\n+\n+        statisticsMBean(grids.get(0).name()).stop();\n+\n+        waitForStatisticsEnabled(false);\n+\n+        File dir = U.resolveWorkDirectory(U.defaultWorkDirectory(), PERF_STAT_DIR, false);\n+\n+        new FilePerformanceStatisticsReader(handlers).read(Collections.singletonList(dir));\n+    }\n+\n+    /** Wait for statistics started/stopped in the cluster. */\n+    protected static void waitForStatisticsEnabled(boolean performanceStatsEnabled) throws Exception {\n+        assertTrue(waitForCondition(() -> {\n+            List<Ignite> grids = G.allGrids();\n+\n+            for (Ignite grid : grids)\n+                if (performanceStatsEnabled != statisticsMBean(grid.name()).started())\n+                    return false;\n+\n+            // Make sure that writer flushed data and stopped.\n+            if (!performanceStatsEnabled) {\n+                for (long id : U.getThreadMx().getAllThreadIds()) {\n+                    ThreadInfo info = U.getThreadMx().getThreadInfo(id);\n+\n+                    if (info != null && info.getThreadState() != Thread.State.TERMINATED &&\n+                        info.getThreadName().startsWith(WRITER_THREAD_NAME))\n+                        return false;\n+                }\n+            }\n+\n+            return true;\n+        }, TIMEOUT));\n+    }\n+\n+    /**\n+     * @param igniteInstanceName Ignite instance name.\n+     * @return Ignite performance statistics MBean.\n+     */\n+    protected static PerformanceStatisticsMBean statisticsMBean(String igniteInstanceName) {\n+        return getMxBean(igniteInstanceName, \"PerformanceStatistics\", PerformanceStatisticsMBeanImpl.class,\n+            PerformanceStatisticsMBean.class);\n+    }\n+\n+    /** Test performance statistics handler. */\n+    public class TestHandler implements PerformanceStatisticsHandler {\n+        /** {@inheritDoc} */\n+        @Override public void cacheOperation(UUID nodeId, OperationType type, int cacheId, long startTime, long duration) {\n+            // No-op.\n+        }\n+\n+        /** {@inheritDoc} */\n+        @Override public void transaction(UUID nodeId, GridIntList cacheIds, long startTime, long duration,\n+            boolean commited) {\n+            // No-op.\n+        }\n+\n+        /** {@inheritDoc} */\n+        @Override public void query(UUID nodeId, GridCacheQueryType type, String text, long id, long startTime,\n+            long duration, boolean success) {\n+            // No-op.\n+        }\n+\n+        /** {@inheritDoc} */\n+        @Override public void queryReads(UUID nodeId, GridCacheQueryType type, UUID queryNodeId, long id,\n+            long logicalReads, long physicalReads) {\n+            // No-op.\n+        }\n+\n+        /** {@inheritDoc} */\n+        @Override public void task(UUID nodeId, IgniteUuid sesId, String taskName, long startTime, long duration,\n+            int affPartId) {\n+            // No-op.\n+        }\n+\n+        /** {@inheritDoc} */\n+        @Override public void job(UUID nodeId, IgniteUuid sesId, long queuedTime, long startTime, long duration,\n+            boolean timedOut) {\n+            // No-op.\n+        }\n+    }\n+\n+    /** Node to run load from. */\n+    enum LoadNode {", "originalCommit": "4ff3aca00b06c356dcf2b465b01a62982db87982", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzc1MzM2MQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r487753361", "bodyText": "Renamed", "author": "NSAmelchev", "createdAt": "2020-09-14T08:52:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzcwMDIxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzcwMTUyMQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r487701521", "bodyText": "Let's store System.currentTimeMillis before running jobs and here check.\nassertTrue(startTime >= jobsStartTime);", "author": "nizhikov", "createdAt": "2020-09-14T07:22:43Z", "path": "modules/core/src/test/java/org/apache/ignite/internal/processors/performancestatistics/PerformanceStatisticsSelfTest.java", "diffHunk": "@@ -0,0 +1,305 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.UUID;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.locks.Lock;\n+import java.util.function.Consumer;\n+import javax.cache.processor.EntryProcessor;\n+import javax.cache.processor.EntryProcessorException;\n+import javax.cache.processor.MutableEntry;\n+import org.apache.ignite.IgniteCache;\n+import org.apache.ignite.cache.CacheEntryProcessor;\n+import org.apache.ignite.configuration.IgniteConfiguration;\n+import org.apache.ignite.internal.IgniteEx;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.CU;\n+import org.apache.ignite.lang.IgniteRunnable;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.transactions.Transaction;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import static org.apache.ignite.internal.processors.performancestatistics.AbstractPerformanceStatisticsTest.LoadNode.CLIENT;\n+import static org.apache.ignite.internal.processors.performancestatistics.AbstractPerformanceStatisticsTest.LoadNode.SERVER;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_GET;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_GET_ALL;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_GET_AND_PUT;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_GET_AND_REMOVE;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_INVOKE;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_INVOKE_ALL;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_LOCK;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_PUT;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_PUT_ALL;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_REMOVE;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.CACHE_REMOVE_ALL;\n+\n+/**\n+ * Tests performance statistics.\n+ */\n+@RunWith(Parameterized.class)\n+@SuppressWarnings({\"LockAcquiredButNotSafelyReleased\"})\n+public class PerformanceStatisticsSelfTest extends AbstractPerformanceStatisticsTest {\n+    /** Test entry processor. */\n+    private static final EntryProcessor<Object, Object, Object> ENTRY_PROC =\n+        new EntryProcessor<Object, Object, Object>() {\n+        @Override public Object process(MutableEntry<Object, Object> entry, Object... arguments)\n+            throws EntryProcessorException {\n+            return null;\n+        }\n+    };\n+\n+    /** Test cache entry processor. */\n+    private static final CacheEntryProcessor<Object, Object, Object> CACHE_ENTRY_PROC =\n+        new CacheEntryProcessor<Object, Object, Object>() {\n+        @Override public Object process(MutableEntry<Object, Object> entry, Object... arguments)\n+            throws EntryProcessorException {\n+            return null;\n+        }\n+    };\n+\n+    /** Cache entry count. */\n+    private static final int ENTRY_COUNT = 100;\n+\n+    /** Load node to run operations from. */\n+    @Parameterized.Parameter\n+    public LoadNode loadNode;\n+\n+    /** @return Test parameters. */\n+    @Parameterized.Parameters(name = \"loadNode={0}\")\n+    public static Collection<?> parameters() {\n+        return Arrays.asList(new Object[][] {{SERVER}, {CLIENT}});\n+    }\n+\n+    /** Ignite. */\n+    private static IgniteEx srv;\n+\n+    /** Ignite node to run load from. */\n+    private static IgniteEx node;\n+\n+    /** Test cache. */\n+    private static IgniteCache<Object, Object> cache;\n+\n+    /** {@inheritDoc} */\n+    @Override protected IgniteConfiguration getConfiguration(String igniteInstanceName) throws Exception {\n+        IgniteConfiguration cfg = super.getConfiguration(igniteInstanceName);\n+\n+        cfg.setCacheConfiguration(defaultCacheConfiguration());\n+\n+        return cfg;\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override protected void beforeTestsStarted() throws Exception {\n+        srv = startGrid(0);\n+\n+        IgniteEx client = startClientGrid(1);\n+\n+        node = loadNode == SERVER ? srv : client;\n+\n+        cache = node.cache(DEFAULT_CACHE_NAME);\n+\n+        for (int i = 0; i < ENTRY_COUNT; i++)\n+            cache.put(i, i);\n+    }\n+\n+    /** @throws Exception If failed. */\n+    @Test\n+    public void testCompute() throws Exception {\n+        String testTaskName = \"testTask\";\n+        int executions = 5;\n+\n+        startCollectStatistics();\n+\n+        IgniteRunnable task = new IgniteRunnable() {\n+            @Override public void run() {\n+                // No-op.\n+            }\n+        };\n+\n+        for (int i = 0; i < executions; i++)\n+            node.compute().withName(testTaskName).run(task);\n+\n+        HashMap<IgniteUuid, Integer> sessions = new HashMap<>();\n+        AtomicInteger tasks = new AtomicInteger();\n+        AtomicInteger jobs = new AtomicInteger();\n+\n+        stopCollectStatisticsAndRead(new TestHandler() {\n+            @Override public void task(UUID nodeId, IgniteUuid sesId, String taskName, long startTime, long duration,\n+                int affPartId) {\n+                sessions.compute(sesId, (uuid, cnt) -> cnt == null ? 1 : ++cnt);\n+\n+                tasks.incrementAndGet();\n+\n+                assertEquals(node.context().localNodeId(), nodeId);\n+                assertEquals(testTaskName, taskName);\n+                assertTrue(startTime > 0);", "originalCommit": "4ff3aca00b06c356dcf2b465b01a62982db87982", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzc4OTI0Mg==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r487789242", "bodyText": "Done", "author": "NSAmelchev", "createdAt": "2020-09-14T09:52:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzcwMTUyMQ=="}], "type": "inlineReview"}, {"oid": "b80b399b985f4a4e655d6ac0462c44a453b62ca1", "url": "https://github.com/apache/ignite/commit/b80b399b985f4a4e655d6ac0462c44a453b62ca1", "message": "Review fixes", "committedDate": "2020-09-14T08:51:34Z", "type": "commit"}, {"oid": "dd4e55c57dacf0a2d8a9244e40eda304d11b3a49", "url": "https://github.com/apache/ignite/commit/dd4e55c57dacf0a2d8a9244e40eda304d11b3a49", "message": "Review fixes", "committedDate": "2020-09-14T09:50:47Z", "type": "commit"}, {"oid": "57539ab667d2ec6a61ee53dbd4c402f537008c17", "url": "https://github.com/apache/ignite/commit/57539ab667d2ec6a61ee53dbd4c402f537008c17", "message": "Warning on close", "committedDate": "2020-09-14T10:10:47Z", "type": "commit"}, {"oid": "dd4cf33c29dec47de59556564830300e413d96df", "url": "https://github.com/apache/ignite/commit/dd4cf33c29dec47de59556564830300e413d96df", "message": "Fix CacheLockImpl", "committedDate": "2020-09-14T10:34:42Z", "type": "commit"}, {"oid": "09de1eb618c998f5d6e0779c1c9d7fe6054168e3", "url": "https://github.com/apache/ignite/commit/09de1eb618c998f5d6e0779c1c9d7fe6054168e3", "message": "Fix codestyle", "committedDate": "2020-09-14T11:24:24Z", "type": "commit"}, {"oid": "51e539a5f356aaa1ec9967ba0506e23a63896381", "url": "https://github.com/apache/ignite/commit/51e539a5f356aaa1ec9967ba0506e23a63896381", "message": "Fix start time reset", "committedDate": "2020-09-14T11:35:52Z", "type": "commit"}, {"oid": "42796ebbc2af15426a6f4d6a5618cf8502561c52", "url": "https://github.com/apache/ignite/commit/42796ebbc2af15426a6f4d6a5618cf8502561c52", "message": "Merge branch 'master' into ignite-12666", "committedDate": "2020-09-18T14:53:09Z", "type": "commit"}, {"oid": "dfb216d092e7591d806980f9eb7a831ca22558af", "url": "https://github.com/apache/ignite/commit/dfb216d092e7591d806980f9eb7a831ca22558af", "message": "Merge branch 'master' into ignite-12666\n\n# Conflicts:\n#\tmodules/core/src/main/java/org/apache/ignite/internal/processors/query/GridRunningQueryInfo.java\n#\tmodules/indexing/src/main/java/org/apache/ignite/internal/processors/query/h2/twostep/GridMapQueryExecutor.java", "committedDate": "2020-09-23T15:20:21Z", "type": "commit"}, {"oid": "aa47ca1afc89505e602e0d5bcfc345e550f8ae95", "url": "https://github.com/apache/ignite/commit/aa47ca1afc89505e602e0d5bcfc345e550f8ae95", "message": "Fix merge master", "committedDate": "2020-09-24T07:45:21Z", "type": "commit"}, {"oid": "38ab4044b45bf49c8de9afe2316ecd3caf32512a", "url": "https://github.com/apache/ignite/commit/38ab4044b45bf49c8de9afe2316ecd3caf32512a", "message": "Performance statistics impl", "committedDate": "2020-09-29T07:55:53Z", "type": "commit"}, {"oid": "64867cf300324e1e952d72cc201b70d2fa25ee03", "url": "https://github.com/apache/ignite/commit/64867cf300324e1e952d72cc201b70d2fa25ee03", "message": "Fix merge", "committedDate": "2020-09-29T09:54:28Z", "type": "commit"}, {"oid": "b01c55755f9b2e074a189ae331df98a56bc26a16", "url": "https://github.com/apache/ignite/commit/b01c55755f9b2e074a189ae331df98a56bc26a16", "message": "Merge branch 'master' into ignite-12666-main\n\n# Conflicts:\n#\tmodules/core/src/main/java/org/apache/ignite/internal/GridKernalContextImpl.java\n#\tmodules/core/src/main/java/org/apache/ignite/internal/IgniteFeatures.java", "committedDate": "2020-10-19T12:07:48Z", "type": "commit"}, {"oid": "0de6276f256bf0043bd6f337fc6d8cb7f0c9e0c2", "url": "https://github.com/apache/ignite/commit/0de6276f256bf0043bd6f337fc6d8cb7f0c9e0c2", "message": "Merge branch 'master' into ignite-12666\n\n# Conflicts:\n#\tmodules/core/src/main/java/org/apache/ignite/internal/GridKernalContextImpl.java\n#\tmodules/core/src/main/java/org/apache/ignite/internal/IgniteFeatures.java", "committedDate": "2020-11-10T08:53:48Z", "type": "commit"}, {"oid": "c85df7099ab02eda78abc5da9d49db1660e0f3f6", "url": "https://github.com/apache/ignite/commit/c85df7099ab02eda78abc5da9d49db1660e0f3f6", "message": "Merge branch 'ignite-12666-main' into ignite-12666\n\n# Conflicts:\n#\tmodules/core/src/main/java/org/apache/ignite/IgniteSystemProperties.java\n#\tmodules/core/src/main/java/org/apache/ignite/internal/IgniteFeatures.java\n#\tmodules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsReader.java\n#\tmodules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java\n#\tmodules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/OperationType.java\n#\tmodules/core/src/test/java/org/apache/ignite/internal/processors/performancestatistics/AbstractPerformanceStatisticsTest.java\n#\tmodules/core/src/test/java/org/apache/ignite/internal/processors/performancestatistics/PerformanceStatisticsSelfTest.java\n#\tmodules/core/src/test/java/org/apache/ignite/internal/processors/performancestatistics/PerformanceStatisticsThinClientTest.java\n#\tmodules/core/src/test/java/org/apache/ignite/testsuites/IgniteBasicWithPersistenceTestSuite.java\n#\tmodules/indexing/src/test/java/org/apache/ignite/internal/processors/performancestatistics/PerformanceStatisticsQueryTest.java", "committedDate": "2020-11-10T09:00:36Z", "type": "commit"}, {"oid": "0a2ad06f0837fd884ba910160ba79cc78bae936d", "url": "https://github.com/apache/ignite/commit/0a2ad06f0837fd884ba910160ba79cc78bae936d", "message": "Fix codestyle", "committedDate": "2020-11-10T09:28:39Z", "type": "commit"}, {"oid": "b0e017e39fe80cc0dba61ceaaacc43d8bb9fb402", "url": "https://github.com/apache/ignite/commit/b0e017e39fe80cc0dba61ceaaacc43d8bb9fb402", "message": "Rename processor", "committedDate": "2020-11-11T12:33:09Z", "type": "commit"}, {"oid": "748e27dcd7b0588417ad4eb568afc40779463446", "url": "https://github.com/apache/ignite/commit/748e27dcd7b0588417ad4eb568afc40779463446", "message": "Merge branch 'master' into ignite-12666", "committedDate": "2020-12-01T06:48:10Z", "type": "commit"}, {"oid": "af9c68e4e08e88fc0113e3cdba49afc1894f0a78", "url": "https://github.com/apache/ignite/commit/af9c68e4e08e88fc0113e3cdba49afc1894f0a78", "message": "Add cache start op", "committedDate": "2020-12-01T09:54:00Z", "type": "commit"}, {"oid": "a8fb955975e79bf2aa5dc48862f36c8e941e4c7b", "url": "https://github.com/apache/ignite/commit/a8fb955975e79bf2aa5dc48862f36c8e941e4c7b", "message": "Fix modifier", "committedDate": "2020-12-03T22:36:37Z", "type": "commit"}, {"oid": "17260860a7e8bd439975a278897bf734757882b7", "url": "https://github.com/apache/ignite/commit/17260860a7e8bd439975a278897bf734757882b7", "message": "Merge branch 'master' into ignite-12666\n\n# Conflicts:\n#\tmodules/core/src/main/java/org/apache/ignite/IgniteSystemProperties.java", "committedDate": "2020-12-15T06:17:22Z", "type": "commit"}, {"oid": "82616b2c0035b71067fddf4e3ea65e11b126b44f", "url": "https://github.com/apache/ignite/commit/82616b2c0035b71067fddf4e3ea65e11b126b44f", "message": "Make class static", "committedDate": "2020-12-15T13:29:50Z", "type": "commit"}, {"oid": "74baca7b3cda982b52a02c0d434a5eefd3e0b2dc", "url": "https://github.com/apache/ignite/commit/74baca7b3cda982b52a02c0d434a5eefd3e0b2dc", "message": "Review fixes.", "committedDate": "2020-07-02T16:34:07Z", "type": "commit"}, {"oid": "ee29b199c5bd37354c9e6dfc7be23f0265601830", "url": "https://github.com/apache/ignite/commit/ee29b199c5bd37354c9e6dfc7be23f0265601830", "message": "Merge branch 'master' into ignite-12666\n\n# Conflicts:\n#\tmodules/core/src/main/java/org/apache/ignite/internal/managers/IgniteMBeansManager.java", "committedDate": "2020-07-02T16:36:14Z", "type": "commit"}, {"oid": "133d8e6ff4a28eb606bcb28af247d87bb1557c00", "url": "https://github.com/apache/ignite/commit/133d8e6ff4a28eb606bcb28af247d87bb1557c00", "message": "Fix merge.", "committedDate": "2020-07-02T16:37:35Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE5Mjg3NA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449192874", "bodyText": "Let's introduce the following method to generalize write:\npublic void doWrite(OperationType op, IntSupplier sizeSupplier, Consumer<ByteBuffer> writer) {\n        FileWriter writer = fileWriter;\n\n        if (writer == null)\n            return;\n\n        int size = sizeSupplier.apply();\n        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(op, size);\n\n        if (seg == null)\n            return;\n\n        writer.apply(seg.buffer());\n        seg.release();\n}\n\nThis will allow us to implement only size calculation and write to the ByteBuffer logic for specific operations.", "author": "nizhikov", "createdAt": "2020-07-02T18:17:58Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,643 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInternalFuture;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.future.GridFinishedFuture;\n+import org.apache.ignite.internal.util.future.GridFutureAdapter;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * 1024 * 1024 * 1024L;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = 32 * 1024 * 1024;\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = 8 * 1024 * 1024;\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** @return {@code True} if collecting performance statistics enabled. */\n+    public boolean enabled() {\n+        return enabled;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public synchronized void start() {\n+        if (enabled)\n+            return;\n+\n+        FileWriter writer = fileWriter;\n+\n+        // Writer is stopping.\n+        if (writer != null) {\n+            try {\n+                writer.shutdown().get();\n+            }\n+            catch (IgniteCheckedException e) {\n+                throw new IgniteException(\"Failed to wait for previous writer stopping.\", e);\n+            }\n+        }\n+\n+        try {\n+            File file = statisticsFile(ctx);\n+\n+            U.delete(file);\n+\n+            FileIO fileIo = fileIoFactory.create(file);\n+\n+            fileWriter = new FileWriter(ctx, fileIo, DFLT_FILE_MAX_SIZE, DFLT_BUFFER_SIZE, DFLT_FLUSH_SIZE, log);\n+\n+            new IgniteThread(fileWriter).start();\n+\n+            enabled = true;\n+\n+            log.info(\"Performance statistics writer started [file=\" + file.getAbsolutePath() + ']');\n+        }\n+        catch (IOException | IgniteCheckedException e) {\n+            log.error(\"Failed to start performance statistics writer.\", e);\n+\n+            throw new IgniteException(\"Failed to start performance statistics writer.\", e);\n+        }\n+    }\n+\n+    /** Stops collecting performance statistics. */\n+    public IgniteInternalFuture<Void> stop() {\n+        synchronized (this) {\n+            if (!enabled)\n+                return new GridFinishedFuture<>();\n+\n+            enabled = false;\n+        }\n+\n+        log.info(\"Stopping performance statistics writer.\");\n+\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        if (fileWriter == null)\n+            return new GridFinishedFuture<>();\n+\n+        return fileWriter.shutdown();\n+    }\n+\n+    /**\n+     * @param type Operation type.\n+     * @param cacheId Cache id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     */\n+    public void cacheOperation(CacheOperation type, int cacheId, long startTime, long duration) {\n+        int size = /*type*/ 1 +\n+            /*cacheId*/ 4 +\n+            /*startTime*/ 8 +\n+            /*duration*/ 8;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.CACHE_OPERATION, size);", "originalCommit": "133d8e6ff4a28eb606bcb28af247d87bb1557c00", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTIyNzE5Mg==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449227192", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-02T19:32:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE5Mjg3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTIwMzk2MA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449203960", "bodyText": "Why we distinguish CacheOperation and OperationType?\nIt seems to me that this two enums can be combiner into one pretty natural.", "author": "nizhikov", "createdAt": "2020-07-02T18:41:28Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/OperationType.java", "diffHunk": "@@ -0,0 +1,49 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+/**\n+ * Operation type.\n+ */\n+public enum OperationType {\n+    /** Cache operation. */\n+    CACHE_OPERATION,", "originalCommit": "133d8e6ff4a28eb606bcb28af247d87bb1557c00", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTIzMDk4NA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449230984", "bodyText": "IMHO, it'll be strange to provide method to read cache operation with not-only-cache-operation type:\nvoid cacheOperation(UUID nodeId, OperationType type, int cacheId, long startTime, long duration);", "author": "NSAmelchev", "createdAt": "2020-07-02T19:41:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTIwMzk2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTIwNjY1OQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449206659", "bodyText": "This constant not used now. Please, remove it.", "author": "nizhikov", "createdAt": "2020-07-02T18:47:16Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,643 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInternalFuture;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.future.GridFinishedFuture;\n+import org.apache.ignite.internal.util.future.GridFutureAdapter;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * 1024 * 1024 * 1024L;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = 32 * 1024 * 1024;\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = 8 * 1024 * 1024;\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** @return {@code True} if collecting performance statistics enabled. */\n+    public boolean enabled() {\n+        return enabled;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public synchronized void start() {\n+        if (enabled)\n+            return;\n+\n+        FileWriter writer = fileWriter;\n+\n+        // Writer is stopping.\n+        if (writer != null) {\n+            try {\n+                writer.shutdown().get();\n+            }\n+            catch (IgniteCheckedException e) {\n+                throw new IgniteException(\"Failed to wait for previous writer stopping.\", e);\n+            }\n+        }\n+\n+        try {\n+            File file = statisticsFile(ctx);\n+\n+            U.delete(file);\n+\n+            FileIO fileIo = fileIoFactory.create(file);\n+\n+            fileWriter = new FileWriter(ctx, fileIo, DFLT_FILE_MAX_SIZE, DFLT_BUFFER_SIZE, DFLT_FLUSH_SIZE, log);\n+\n+            new IgniteThread(fileWriter).start();\n+\n+            enabled = true;\n+\n+            log.info(\"Performance statistics writer started [file=\" + file.getAbsolutePath() + ']');\n+        }\n+        catch (IOException | IgniteCheckedException e) {\n+            log.error(\"Failed to start performance statistics writer.\", e);\n+\n+            throw new IgniteException(\"Failed to start performance statistics writer.\", e);\n+        }\n+    }\n+\n+    /** Stops collecting performance statistics. */\n+    public IgniteInternalFuture<Void> stop() {\n+        synchronized (this) {\n+            if (!enabled)\n+                return new GridFinishedFuture<>();\n+\n+            enabled = false;\n+        }\n+\n+        log.info(\"Stopping performance statistics writer.\");\n+\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        if (fileWriter == null)\n+            return new GridFinishedFuture<>();\n+\n+        return fileWriter.shutdown();\n+    }\n+\n+    /**\n+     * @param type Operation type.\n+     * @param cacheId Cache id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     */\n+    public void cacheOperation(CacheOperation type, int cacheId, long startTime, long duration) {\n+        int size = /*type*/ 1 +\n+            /*cacheId*/ 4 +\n+            /*startTime*/ 8 +\n+            /*duration*/ 8;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.CACHE_OPERATION, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)type.ordinal());\n+        buf.putInt(cacheId);\n+        buf.putLong(startTime);\n+        buf.putLong(duration);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * @param cacheIds Cache IDs.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param commited {@code True} if commited.\n+     */\n+    public void transaction(GridIntList cacheIds, long startTime, long duration, boolean commited) {\n+        int size = /*cacheIds*/ 4 + cacheIds.size() * 4 +\n+            /*startTime*/ 8 +\n+            /*duration*/ 8 +\n+            /*commit*/ 1;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.TRANSACTION, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.putInt(cacheIds.size());\n+\n+        GridIntIterator iter = cacheIds.iterator();\n+\n+        while (iter.hasNext())\n+            buf.putInt(iter.next());\n+\n+        buf.putLong(startTime);\n+        buf.putLong(duration);\n+        buf.put(commited ? (byte)1 : 0);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param text Query text in case of SQL query. Cache name in case of SCAN query.\n+     * @param id Query id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param success Success flag.\n+     */\n+    public void query(GridCacheQueryType type, String text, long id, long startTime, long duration, boolean success) {\n+        FileWriter writer = fileWriter;\n+\n+        if (writer == null)\n+            return;\n+\n+        boolean needWriteStr = !writer.stringCached(text);\n+\n+        byte[] strBytes = null;\n+\n+        int size = /*type*/ 1 +\n+            /*compactStringFlag*/ 1 +\n+            /*strId*/ 4 +\n+            /*id*/ 8 +\n+            /*startTime*/ 8 +\n+            /*duration*/ 8 +\n+            /*success*/ 1;\n+\n+        if (needWriteStr) {\n+            strBytes = text.getBytes();\n+\n+            size += /*text*/ 4 + strBytes.length;\n+        }\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.QUERY, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)type.ordinal());\n+        buf.put(needWriteStr ? (byte)1 : 0);\n+        buf.putInt(text.hashCode());\n+\n+        if (needWriteStr) {\n+            buf.putInt(strBytes.length);\n+            buf.put(strBytes);\n+        }\n+\n+        buf.putLong(id);\n+        buf.putLong(startTime);\n+        buf.putLong(duration);\n+        buf.put(success ? (byte)1 : 0);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param queryNodeId Originating node id.\n+     * @param id Query id.\n+     * @param logicalReads Number of logical reads.\n+     * @param physicalReads Number of physical reads.\n+     */\n+    public void queryReads(GridCacheQueryType type, UUID queryNodeId, long id, long logicalReads, long physicalReads) {\n+        int size = /*type*/ 1 +\n+            /*queryNodeId*/ 16 +\n+            /*id*/ 8 +\n+            /*logicalReads*/ 8 +\n+            /*physicalReads*/ 8;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.QUERY_READS, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)type.ordinal());\n+        writeUuid(buf, queryNodeId);\n+        buf.putLong(id);\n+        buf.putLong(logicalReads);\n+        buf.putLong(physicalReads);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param taskName Task name.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration.\n+     * @param affPartId Affinity partition id.\n+     */\n+    public void task(IgniteUuid sesId, String taskName, long startTime, long duration, int affPartId) {\n+        FileWriter writer = fileWriter;\n+\n+        if (writer == null)\n+            return;\n+\n+        boolean needWriteStr = !writer.stringCached(taskName);\n+\n+        byte[] strBytes = null;\n+\n+        int size = /*sesId*/ 24 +\n+            /*compactStringFlag*/ 1 +\n+            /*strId*/ 4 +\n+            /*startTime*/ 8 +\n+            /*duration*/ 8 +\n+            /*affPartId*/ 4;\n+\n+        if (needWriteStr) {\n+            strBytes = taskName.getBytes();\n+\n+            size += /*taskName*/ 4 + strBytes.length;\n+        }\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.TASK, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        writeIgniteUuid(buf, sesId);\n+        buf.put(needWriteStr ? (byte)1 : 0);\n+        buf.putInt(taskName.hashCode());\n+\n+        if (needWriteStr) {\n+            buf.putInt(strBytes.length);\n+            buf.put(strBytes);\n+        }\n+\n+        buf.putLong(startTime);\n+        buf.putLong(duration);\n+        buf.putInt(affPartId);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param queuedTime Time job spent on waiting queue.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Job execution time.\n+     * @param timedOut {@code True} if job is timed out.\n+     */\n+    public void job(IgniteUuid sesId, long queuedTime, long startTime, long duration, boolean timedOut) {\n+        int size = /*sesId*/ 24 +\n+            /*queuedTime*/ 8 +\n+            /*startTime*/ 8 +\n+            /*duration*/ 8 +\n+            /*timedOut*/ 1;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.JOB, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        writeIgniteUuid(buf, sesId);\n+        buf.putLong(queuedTime);\n+        buf.putLong(startTime);\n+        buf.putLong(duration);\n+        buf.put(timedOut ? (byte)1 : 0);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * Reserves buffer's write segment.\n+     *\n+     * @return Buffer's write segment or {@code null} if not enought space or writer stopping.\n+     */\n+    private SegmentedRingByteBuffer.WriteSegment reserveBuffer(OperationType type, int size) {\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        // Writer stopping.\n+        if (fileWriter == null)\n+            return null;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = fileWriter.writeSegment(size + /*type*/ 1);\n+\n+        if (seg == null) {\n+            fileWriter.logSmallBufferMessage();\n+\n+            return null;\n+        }\n+\n+        // Ring buffer closed (writer stopping) or maximum size reached.\n+        if (seg.buffer() == null) {\n+            seg.release();\n+\n+            if (!fileWriter.isCancelled())\n+                fileWriter.onMaxFileSizeReached();\n+\n+            return null;\n+        }\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)type.ordinal());\n+\n+        return seg;\n+    }\n+\n+    /** @return Performance statistics file. */\n+    public static File statisticsFile(GridKernalContext ctx) throws IgniteCheckedException {\n+        String igniteWorkDir = U.workDirectory(ctx.config().getWorkDirectory(), ctx.config().getIgniteHome());\n+\n+        File fileDir = U.resolveWorkDirectory(igniteWorkDir, PERFORMANCE_STAT_DIR, false);\n+\n+        return new File(fileDir, \"node-\" + ctx.localNodeId() + \".prf\");\n+    }\n+\n+    /** Writes {@link UUID} to buffer. */\n+    public static void writeUuid(ByteBuffer buf, UUID uuid) {\n+        buf.putLong(uuid.getMostSignificantBits());\n+        buf.putLong(uuid.getLeastSignificantBits());\n+    }\n+\n+    /** Reads {@link UUID} from buffer. */\n+    public static UUID readUuid(ByteBuffer buf) {\n+        return new UUID(buf.getLong(), buf.getLong());\n+    }\n+\n+    /** Writes {@link IgniteUuid} to buffer. */\n+    public static void writeIgniteUuid(ByteBuffer buf, IgniteUuid uuid) {\n+        buf.putLong(uuid.globalId().getMostSignificantBits());\n+        buf.putLong(uuid.globalId().getLeastSignificantBits());\n+        buf.putLong(uuid.localId());\n+    }\n+\n+    /** Reads {@link IgniteUuid} from buffer. */\n+    public static IgniteUuid readIgniteUuid(ByteBuffer buf) {\n+        UUID globalId = new UUID(buf.getLong(), buf.getLong());\n+\n+        return new IgniteUuid(globalId, buf.getLong());\n+    }\n+\n+    /** Worker to write to performance statistics file. */\n+    private class FileWriter extends GridWorker {\n+        /** Maximum cached string count. */\n+        private static final short MAX_CACHED_STRING_COUNT = Short.MAX_VALUE;", "originalCommit": "133d8e6ff4a28eb606bcb28af247d87bb1557c00", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTIyNzI1OA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449227258", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-02T19:32:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTIwNjY1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTIwNzc3OA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449207778", "bodyText": "Why we ignore poll results here?", "author": "nizhikov", "createdAt": "2020-07-02T18:49:49Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,643 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInternalFuture;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.future.GridFinishedFuture;\n+import org.apache.ignite.internal.util.future.GridFutureAdapter;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * 1024 * 1024 * 1024L;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = 32 * 1024 * 1024;\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = 8 * 1024 * 1024;\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** @return {@code True} if collecting performance statistics enabled. */\n+    public boolean enabled() {\n+        return enabled;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public synchronized void start() {\n+        if (enabled)\n+            return;\n+\n+        FileWriter writer = fileWriter;\n+\n+        // Writer is stopping.\n+        if (writer != null) {\n+            try {\n+                writer.shutdown().get();\n+            }\n+            catch (IgniteCheckedException e) {\n+                throw new IgniteException(\"Failed to wait for previous writer stopping.\", e);\n+            }\n+        }\n+\n+        try {\n+            File file = statisticsFile(ctx);\n+\n+            U.delete(file);\n+\n+            FileIO fileIo = fileIoFactory.create(file);\n+\n+            fileWriter = new FileWriter(ctx, fileIo, DFLT_FILE_MAX_SIZE, DFLT_BUFFER_SIZE, DFLT_FLUSH_SIZE, log);\n+\n+            new IgniteThread(fileWriter).start();\n+\n+            enabled = true;\n+\n+            log.info(\"Performance statistics writer started [file=\" + file.getAbsolutePath() + ']');\n+        }\n+        catch (IOException | IgniteCheckedException e) {\n+            log.error(\"Failed to start performance statistics writer.\", e);\n+\n+            throw new IgniteException(\"Failed to start performance statistics writer.\", e);\n+        }\n+    }\n+\n+    /** Stops collecting performance statistics. */\n+    public IgniteInternalFuture<Void> stop() {\n+        synchronized (this) {\n+            if (!enabled)\n+                return new GridFinishedFuture<>();\n+\n+            enabled = false;\n+        }\n+\n+        log.info(\"Stopping performance statistics writer.\");\n+\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        if (fileWriter == null)\n+            return new GridFinishedFuture<>();\n+\n+        return fileWriter.shutdown();\n+    }\n+\n+    /**\n+     * @param type Operation type.\n+     * @param cacheId Cache id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     */\n+    public void cacheOperation(CacheOperation type, int cacheId, long startTime, long duration) {\n+        int size = /*type*/ 1 +\n+            /*cacheId*/ 4 +\n+            /*startTime*/ 8 +\n+            /*duration*/ 8;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.CACHE_OPERATION, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)type.ordinal());\n+        buf.putInt(cacheId);\n+        buf.putLong(startTime);\n+        buf.putLong(duration);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * @param cacheIds Cache IDs.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param commited {@code True} if commited.\n+     */\n+    public void transaction(GridIntList cacheIds, long startTime, long duration, boolean commited) {\n+        int size = /*cacheIds*/ 4 + cacheIds.size() * 4 +\n+            /*startTime*/ 8 +\n+            /*duration*/ 8 +\n+            /*commit*/ 1;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.TRANSACTION, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.putInt(cacheIds.size());\n+\n+        GridIntIterator iter = cacheIds.iterator();\n+\n+        while (iter.hasNext())\n+            buf.putInt(iter.next());\n+\n+        buf.putLong(startTime);\n+        buf.putLong(duration);\n+        buf.put(commited ? (byte)1 : 0);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param text Query text in case of SQL query. Cache name in case of SCAN query.\n+     * @param id Query id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param success Success flag.\n+     */\n+    public void query(GridCacheQueryType type, String text, long id, long startTime, long duration, boolean success) {\n+        FileWriter writer = fileWriter;\n+\n+        if (writer == null)\n+            return;\n+\n+        boolean needWriteStr = !writer.stringCached(text);\n+\n+        byte[] strBytes = null;\n+\n+        int size = /*type*/ 1 +\n+            /*compactStringFlag*/ 1 +\n+            /*strId*/ 4 +\n+            /*id*/ 8 +\n+            /*startTime*/ 8 +\n+            /*duration*/ 8 +\n+            /*success*/ 1;\n+\n+        if (needWriteStr) {\n+            strBytes = text.getBytes();\n+\n+            size += /*text*/ 4 + strBytes.length;\n+        }\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.QUERY, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)type.ordinal());\n+        buf.put(needWriteStr ? (byte)1 : 0);\n+        buf.putInt(text.hashCode());\n+\n+        if (needWriteStr) {\n+            buf.putInt(strBytes.length);\n+            buf.put(strBytes);\n+        }\n+\n+        buf.putLong(id);\n+        buf.putLong(startTime);\n+        buf.putLong(duration);\n+        buf.put(success ? (byte)1 : 0);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param queryNodeId Originating node id.\n+     * @param id Query id.\n+     * @param logicalReads Number of logical reads.\n+     * @param physicalReads Number of physical reads.\n+     */\n+    public void queryReads(GridCacheQueryType type, UUID queryNodeId, long id, long logicalReads, long physicalReads) {\n+        int size = /*type*/ 1 +\n+            /*queryNodeId*/ 16 +\n+            /*id*/ 8 +\n+            /*logicalReads*/ 8 +\n+            /*physicalReads*/ 8;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.QUERY_READS, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)type.ordinal());\n+        writeUuid(buf, queryNodeId);\n+        buf.putLong(id);\n+        buf.putLong(logicalReads);\n+        buf.putLong(physicalReads);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param taskName Task name.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration.\n+     * @param affPartId Affinity partition id.\n+     */\n+    public void task(IgniteUuid sesId, String taskName, long startTime, long duration, int affPartId) {\n+        FileWriter writer = fileWriter;\n+\n+        if (writer == null)\n+            return;\n+\n+        boolean needWriteStr = !writer.stringCached(taskName);\n+\n+        byte[] strBytes = null;\n+\n+        int size = /*sesId*/ 24 +\n+            /*compactStringFlag*/ 1 +\n+            /*strId*/ 4 +\n+            /*startTime*/ 8 +\n+            /*duration*/ 8 +\n+            /*affPartId*/ 4;\n+\n+        if (needWriteStr) {\n+            strBytes = taskName.getBytes();\n+\n+            size += /*taskName*/ 4 + strBytes.length;\n+        }\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.TASK, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        writeIgniteUuid(buf, sesId);\n+        buf.put(needWriteStr ? (byte)1 : 0);\n+        buf.putInt(taskName.hashCode());\n+\n+        if (needWriteStr) {\n+            buf.putInt(strBytes.length);\n+            buf.put(strBytes);\n+        }\n+\n+        buf.putLong(startTime);\n+        buf.putLong(duration);\n+        buf.putInt(affPartId);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param queuedTime Time job spent on waiting queue.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Job execution time.\n+     * @param timedOut {@code True} if job is timed out.\n+     */\n+    public void job(IgniteUuid sesId, long queuedTime, long startTime, long duration, boolean timedOut) {\n+        int size = /*sesId*/ 24 +\n+            /*queuedTime*/ 8 +\n+            /*startTime*/ 8 +\n+            /*duration*/ 8 +\n+            /*timedOut*/ 1;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.JOB, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        writeIgniteUuid(buf, sesId);\n+        buf.putLong(queuedTime);\n+        buf.putLong(startTime);\n+        buf.putLong(duration);\n+        buf.put(timedOut ? (byte)1 : 0);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * Reserves buffer's write segment.\n+     *\n+     * @return Buffer's write segment or {@code null} if not enought space or writer stopping.\n+     */\n+    private SegmentedRingByteBuffer.WriteSegment reserveBuffer(OperationType type, int size) {\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        // Writer stopping.\n+        if (fileWriter == null)\n+            return null;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = fileWriter.writeSegment(size + /*type*/ 1);\n+\n+        if (seg == null) {\n+            fileWriter.logSmallBufferMessage();\n+\n+            return null;\n+        }\n+\n+        // Ring buffer closed (writer stopping) or maximum size reached.\n+        if (seg.buffer() == null) {\n+            seg.release();\n+\n+            if (!fileWriter.isCancelled())\n+                fileWriter.onMaxFileSizeReached();\n+\n+            return null;\n+        }\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)type.ordinal());\n+\n+        return seg;\n+    }\n+\n+    /** @return Performance statistics file. */\n+    public static File statisticsFile(GridKernalContext ctx) throws IgniteCheckedException {\n+        String igniteWorkDir = U.workDirectory(ctx.config().getWorkDirectory(), ctx.config().getIgniteHome());\n+\n+        File fileDir = U.resolveWorkDirectory(igniteWorkDir, PERFORMANCE_STAT_DIR, false);\n+\n+        return new File(fileDir, \"node-\" + ctx.localNodeId() + \".prf\");\n+    }\n+\n+    /** Writes {@link UUID} to buffer. */\n+    public static void writeUuid(ByteBuffer buf, UUID uuid) {\n+        buf.putLong(uuid.getMostSignificantBits());\n+        buf.putLong(uuid.getLeastSignificantBits());\n+    }\n+\n+    /** Reads {@link UUID} from buffer. */\n+    public static UUID readUuid(ByteBuffer buf) {\n+        return new UUID(buf.getLong(), buf.getLong());\n+    }\n+\n+    /** Writes {@link IgniteUuid} to buffer. */\n+    public static void writeIgniteUuid(ByteBuffer buf, IgniteUuid uuid) {\n+        buf.putLong(uuid.globalId().getMostSignificantBits());\n+        buf.putLong(uuid.globalId().getLeastSignificantBits());\n+        buf.putLong(uuid.localId());\n+    }\n+\n+    /** Reads {@link IgniteUuid} from buffer. */\n+    public static IgniteUuid readIgniteUuid(ByteBuffer buf) {\n+        UUID globalId = new UUID(buf.getLong(), buf.getLong());\n+\n+        return new IgniteUuid(globalId, buf.getLong());\n+    }\n+\n+    /** Worker to write to performance statistics file. */\n+    private class FileWriter extends GridWorker {\n+        /** Maximum cached string count. */\n+        private static final short MAX_CACHED_STRING_COUNT = Short.MAX_VALUE;\n+\n+        /** Performance statistics file I/O. */\n+        private final FileIO fileIo;\n+\n+        /** File write buffer. */\n+        private final SegmentedRingByteBuffer ringByteBuffer;\n+\n+        /** Minimal batch size to flush in bytes. */\n+        private final int flushBatchSize;\n+\n+        /** Size of ready for flushing bytes. */\n+        private final AtomicInteger readyForFlushSize = new AtomicInteger();\n+\n+        /** Stop file writer future. */\n+        GridFutureAdapter<Void> stopFut = new GridFutureAdapter<>();\n+\n+        /** Hashcodes of cached strings. */\n+        private final ConcurrentSkipListSet<Integer> cachedStrings = new ConcurrentSkipListSet<>();\n+\n+        /** {@code True} if the small buffer warning message logged. */\n+        private final AtomicBoolean smallBufLogged = new AtomicBoolean();\n+\n+        /** {@code True} if worker stopped due to maximum file size reached. */\n+        private final AtomicBoolean stopByMaxSize = new AtomicBoolean();\n+\n+        /**\n+         * @param ctx Kernal context.\n+         * @param fileIo Performance statistics file I/O.\n+         * @param maxFileSize Maximum file size in bytes.\n+         * @param bufferSize Off heap buffer size in bytes.\n+         * @param flushBatchSize Minimal batch size to flush in bytes.\n+         * @param log Logger.\n+         */\n+        FileWriter(GridKernalContext ctx, FileIO fileIo, long maxFileSize, int bufferSize, int flushBatchSize,\n+            IgniteLogger log) {\n+            super(ctx.igniteInstanceName(), \"performance-statistics-writer%\" + ctx.igniteInstanceName(), log);\n+\n+            this.fileIo = fileIo;\n+            this.flushBatchSize = flushBatchSize;\n+\n+            ringByteBuffer = new SegmentedRingByteBuffer(bufferSize, maxFileSize, BufferMode.DIRECT);\n+\n+            ringByteBuffer.init(0);\n+        }\n+\n+        /** {@inheritDoc} */\n+        @Override protected void body() throws InterruptedException, IgniteInterruptedCheckedException {\n+            while (!isCancelled()) {\n+                blockingSectionBegin();\n+\n+                try {\n+                    synchronized (this) {\n+                        while (readyForFlushSize.get() < flushBatchSize && !isCancelled())\n+                            wait();\n+                    }\n+                }\n+                finally {\n+                    blockingSectionEnd();\n+                }\n+\n+                flushBuffer();\n+            }\n+\n+            fileWriter = null;\n+\n+            ringByteBuffer.close();\n+\n+            // Make sure that all producers released their buffers to safe deallocate memory.\n+            ringByteBuffer.poll();", "originalCommit": "133d8e6ff4a28eb606bcb28af247d87bb1557c00", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTIyNzQ3Ng==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449227476", "bodyText": "Replaced with flushBuffer();", "author": "NSAmelchev", "createdAt": "2020-07-02T19:33:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTIwNzc3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTIxMDA1MA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449210050", "bodyText": "Can you, please, move this method to the bottom of the class, but above the FileWriter declaration to improve code readability.", "author": "nizhikov", "createdAt": "2020-07-02T18:54:43Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,643 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInternalFuture;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.future.GridFinishedFuture;\n+import org.apache.ignite.internal.util.future.GridFutureAdapter;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * 1024 * 1024 * 1024L;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = 32 * 1024 * 1024;\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = 8 * 1024 * 1024;\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** @return {@code True} if collecting performance statistics enabled. */\n+    public boolean enabled() {", "originalCommit": "133d8e6ff4a28eb606bcb28af247d87bb1557c00", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTIyNzI5NQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449227295", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-02T19:33:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTIxMDA1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTIxMDMxMQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449210311", "bodyText": "It seems, stop results are ignored.\nCan we make this method to return void?", "author": "nizhikov", "createdAt": "2020-07-02T18:55:19Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,643 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInternalFuture;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.future.GridFinishedFuture;\n+import org.apache.ignite.internal.util.future.GridFutureAdapter;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * 1024 * 1024 * 1024L;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = 32 * 1024 * 1024;\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = 8 * 1024 * 1024;\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** @return {@code True} if collecting performance statistics enabled. */\n+    public boolean enabled() {\n+        return enabled;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public synchronized void start() {\n+        if (enabled)\n+            return;\n+\n+        FileWriter writer = fileWriter;\n+\n+        // Writer is stopping.\n+        if (writer != null) {\n+            try {\n+                writer.shutdown().get();\n+            }\n+            catch (IgniteCheckedException e) {\n+                throw new IgniteException(\"Failed to wait for previous writer stopping.\", e);\n+            }\n+        }\n+\n+        try {\n+            File file = statisticsFile(ctx);\n+\n+            U.delete(file);\n+\n+            FileIO fileIo = fileIoFactory.create(file);\n+\n+            fileWriter = new FileWriter(ctx, fileIo, DFLT_FILE_MAX_SIZE, DFLT_BUFFER_SIZE, DFLT_FLUSH_SIZE, log);\n+\n+            new IgniteThread(fileWriter).start();\n+\n+            enabled = true;\n+\n+            log.info(\"Performance statistics writer started [file=\" + file.getAbsolutePath() + ']');\n+        }\n+        catch (IOException | IgniteCheckedException e) {\n+            log.error(\"Failed to start performance statistics writer.\", e);\n+\n+            throw new IgniteException(\"Failed to start performance statistics writer.\", e);\n+        }\n+    }\n+\n+    /** Stops collecting performance statistics. */\n+    public IgniteInternalFuture<Void> stop() {", "originalCommit": "133d8e6ff4a28eb606bcb28af247d87bb1557c00", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTIyNzMzMA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449227330", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-02T19:33:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTIxMDMxMQ=="}], "type": "inlineReview"}, {"oid": "66a46d52fb6469a3066f05ae97f19bc54f3af1f3", "url": "https://github.com/apache/ignite/commit/66a46d52fb6469a3066f05ae97f19bc54f3af1f3", "message": "Review fixes", "committedDate": "2020-07-02T19:32:39Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTM5NDM5OQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449394399", "bodyText": "this method used only once. Let's inline it.", "author": "nizhikov", "createdAt": "2020-07-03T06:14:23Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,580 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Consumer;\n+import java.util.function.IntSupplier;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * 1024 * 1024 * 1024L;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = 32 * 1024 * 1024;\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = 8 * 1024 * 1024;\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public synchronized void start() {\n+        if (enabled)\n+            return;\n+\n+        FileWriter writer = fileWriter;\n+\n+        // Writer is stopping.\n+        if (writer != null) {\n+            try {\n+                U.join(writer.runner());\n+            }\n+            catch (IgniteCheckedException e) {\n+                throw new IgniteException(\"Failed to wait for previous writer stopping.\", e);\n+            }\n+        }\n+\n+        try {\n+            File file = statisticsFile(ctx);\n+\n+            U.delete(file);\n+\n+            FileIO fileIo = fileIoFactory.create(file);\n+\n+            fileWriter = new FileWriter(ctx, fileIo, DFLT_FILE_MAX_SIZE, DFLT_BUFFER_SIZE, DFLT_FLUSH_SIZE, log);\n+\n+            new IgniteThread(fileWriter).start();\n+\n+            enabled = true;\n+\n+            log.info(\"Performance statistics writer started [file=\" + file.getAbsolutePath() + ']');\n+        }\n+        catch (IOException | IgniteCheckedException e) {\n+            log.error(\"Failed to start performance statistics writer.\", e);\n+\n+            throw new IgniteException(\"Failed to start performance statistics writer.\", e);\n+        }\n+    }\n+\n+    /** Stops collecting performance statistics. */\n+    public void stop() {\n+        synchronized (this) {\n+            if (!enabled)\n+                return;\n+\n+            enabled = false;\n+        }\n+\n+        log.info(\"Stopping performance statistics writer.\");\n+\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        if (fileWriter != null)\n+            fileWriter.shutdown();\n+    }\n+\n+    /**\n+     * @param type Operation type.\n+     * @param cacheId Cache id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     */\n+    public void cacheOperation(CacheOperation type, int cacheId, long startTime, long duration) {\n+        doWrite(OperationType.CACHE_OPERATION,\n+            () -> 1 + 4 + 8 + 8,\n+            buf -> {\n+                buf.put((byte)type.ordinal());\n+                buf.putInt(cacheId);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param cacheIds Cache IDs.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param commited {@code True} if commited.\n+     */\n+    public void transaction(GridIntList cacheIds, long startTime, long duration, boolean commited) {\n+        doWrite(OperationType.TRANSACTION,\n+            () -> 4 + cacheIds.size() * 4 + 8 + 8 + 1,\n+            buf -> {\n+                buf.putInt(cacheIds.size());\n+\n+                GridIntIterator iter = cacheIds.iterator();\n+\n+                while (iter.hasNext())\n+                    buf.putInt(iter.next());\n+\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+                buf.put(commited ? (byte)1 : 0);\n+            });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param text Query text in case of SQL query. Cache name in case of SCAN query.\n+     * @param id Query id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param success Success flag.\n+     */\n+    public void query(GridCacheQueryType type, String text, long id, long startTime, long duration, boolean success) {\n+        FileWriter writer = fileWriter;\n+\n+        if (writer == null)\n+            return;\n+\n+        boolean needWriteStr = !writer.stringCached(text);\n+        byte[] strBytes = needWriteStr ? text.getBytes() : null;\n+\n+        doWrite(OperationType.QUERY, () -> {\n+            int size = 1 + 1 + 4 + 8 + 8 + 8 + 1;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            buf.put((byte)type.ordinal());\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(text.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(id);\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.put(success ? (byte)1 : 0);\n+        });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param queryNodeId Originating node id.\n+     * @param id Query id.\n+     * @param logicalReads Number of logical reads.\n+     * @param physicalReads Number of physical reads.\n+     */\n+    public void queryReads(GridCacheQueryType type, UUID queryNodeId, long id, long logicalReads, long physicalReads) {\n+        doWrite(OperationType.QUERY_READS,\n+            () -> 1 + 16 + 8 + 8 + 8,\n+            buf -> {\n+                buf.put((byte)type.ordinal());\n+                writeUuid(buf, queryNodeId);\n+                buf.putLong(id);\n+                buf.putLong(logicalReads);\n+                buf.putLong(physicalReads);\n+            });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param taskName Task name.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration.\n+     * @param affPartId Affinity partition id.\n+     */\n+    public void task(IgniteUuid sesId, String taskName, long startTime, long duration, int affPartId) {\n+        FileWriter writer = fileWriter;\n+\n+        if (writer == null)\n+            return;\n+\n+        boolean needWriteStr = !writer.stringCached(taskName);\n+        byte[] strBytes = needWriteStr ? taskName.getBytes() : null;\n+\n+        doWrite(OperationType.TASK, () -> {\n+            int size = 24 + 1 + 4 + 8 + 8 + 4;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            writeIgniteUuid(buf, sesId);\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(taskName.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.putInt(affPartId);\n+        });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param queuedTime Time job spent on waiting queue.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Job execution time.\n+     * @param timedOut {@code True} if job is timed out.\n+     */\n+    public void job(IgniteUuid sesId, long queuedTime, long startTime, long duration, boolean timedOut) {\n+        doWrite(OperationType.JOB,\n+            () -> 24 + 8 + 8 + 8 + 1,\n+            buf -> {\n+                writeIgniteUuid(buf, sesId);\n+                buf.putLong(queuedTime);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+                buf.put(timedOut ? (byte)1 : 0);\n+            });\n+    }\n+\n+    /**\n+     * @param op Operation type.\n+     * @param sizeSupplier Record size supplier.\n+     * @param writer Record writer.\n+     */\n+    private void doWrite(OperationType op, IntSupplier sizeSupplier, Consumer<ByteBuffer> writer) {\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        // Writer stopping.\n+        if (fileWriter == null)\n+            return;\n+\n+        int size = sizeSupplier.getAsInt();\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(fileWriter, op, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        writer.accept(seg.buffer());\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * Reserves buffer's write segment.\n+     *\n+     * @param fileWriter File writer.\n+     * @param type Operation type.\n+     * @param size Record size.\n+     * @return Buffer's write segment or {@code null} if not enought space or writer stopping.\n+     */\n+    private SegmentedRingByteBuffer.WriteSegment reserveBuffer(FileWriter fileWriter, OperationType type, int size) {", "originalCommit": "66a46d52fb6469a3066f05ae97f19bc54f3af1f3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQzMzIzMA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449433230", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-03T07:52:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTM5NDM5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTM5ODgyNA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449398824", "bodyText": "This method should be moved to the reader.", "author": "nizhikov", "createdAt": "2020-07-03T06:28:46Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,580 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Consumer;\n+import java.util.function.IntSupplier;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * 1024 * 1024 * 1024L;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = 32 * 1024 * 1024;\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = 8 * 1024 * 1024;\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public synchronized void start() {\n+        if (enabled)\n+            return;\n+\n+        FileWriter writer = fileWriter;\n+\n+        // Writer is stopping.\n+        if (writer != null) {\n+            try {\n+                U.join(writer.runner());\n+            }\n+            catch (IgniteCheckedException e) {\n+                throw new IgniteException(\"Failed to wait for previous writer stopping.\", e);\n+            }\n+        }\n+\n+        try {\n+            File file = statisticsFile(ctx);\n+\n+            U.delete(file);\n+\n+            FileIO fileIo = fileIoFactory.create(file);\n+\n+            fileWriter = new FileWriter(ctx, fileIo, DFLT_FILE_MAX_SIZE, DFLT_BUFFER_SIZE, DFLT_FLUSH_SIZE, log);\n+\n+            new IgniteThread(fileWriter).start();\n+\n+            enabled = true;\n+\n+            log.info(\"Performance statistics writer started [file=\" + file.getAbsolutePath() + ']');\n+        }\n+        catch (IOException | IgniteCheckedException e) {\n+            log.error(\"Failed to start performance statistics writer.\", e);\n+\n+            throw new IgniteException(\"Failed to start performance statistics writer.\", e);\n+        }\n+    }\n+\n+    /** Stops collecting performance statistics. */\n+    public void stop() {\n+        synchronized (this) {\n+            if (!enabled)\n+                return;\n+\n+            enabled = false;\n+        }\n+\n+        log.info(\"Stopping performance statistics writer.\");\n+\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        if (fileWriter != null)\n+            fileWriter.shutdown();\n+    }\n+\n+    /**\n+     * @param type Operation type.\n+     * @param cacheId Cache id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     */\n+    public void cacheOperation(CacheOperation type, int cacheId, long startTime, long duration) {\n+        doWrite(OperationType.CACHE_OPERATION,\n+            () -> 1 + 4 + 8 + 8,\n+            buf -> {\n+                buf.put((byte)type.ordinal());\n+                buf.putInt(cacheId);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param cacheIds Cache IDs.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param commited {@code True} if commited.\n+     */\n+    public void transaction(GridIntList cacheIds, long startTime, long duration, boolean commited) {\n+        doWrite(OperationType.TRANSACTION,\n+            () -> 4 + cacheIds.size() * 4 + 8 + 8 + 1,\n+            buf -> {\n+                buf.putInt(cacheIds.size());\n+\n+                GridIntIterator iter = cacheIds.iterator();\n+\n+                while (iter.hasNext())\n+                    buf.putInt(iter.next());\n+\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+                buf.put(commited ? (byte)1 : 0);\n+            });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param text Query text in case of SQL query. Cache name in case of SCAN query.\n+     * @param id Query id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param success Success flag.\n+     */\n+    public void query(GridCacheQueryType type, String text, long id, long startTime, long duration, boolean success) {\n+        FileWriter writer = fileWriter;\n+\n+        if (writer == null)\n+            return;\n+\n+        boolean needWriteStr = !writer.stringCached(text);\n+        byte[] strBytes = needWriteStr ? text.getBytes() : null;\n+\n+        doWrite(OperationType.QUERY, () -> {\n+            int size = 1 + 1 + 4 + 8 + 8 + 8 + 1;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            buf.put((byte)type.ordinal());\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(text.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(id);\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.put(success ? (byte)1 : 0);\n+        });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param queryNodeId Originating node id.\n+     * @param id Query id.\n+     * @param logicalReads Number of logical reads.\n+     * @param physicalReads Number of physical reads.\n+     */\n+    public void queryReads(GridCacheQueryType type, UUID queryNodeId, long id, long logicalReads, long physicalReads) {\n+        doWrite(OperationType.QUERY_READS,\n+            () -> 1 + 16 + 8 + 8 + 8,\n+            buf -> {\n+                buf.put((byte)type.ordinal());\n+                writeUuid(buf, queryNodeId);\n+                buf.putLong(id);\n+                buf.putLong(logicalReads);\n+                buf.putLong(physicalReads);\n+            });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param taskName Task name.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration.\n+     * @param affPartId Affinity partition id.\n+     */\n+    public void task(IgniteUuid sesId, String taskName, long startTime, long duration, int affPartId) {\n+        FileWriter writer = fileWriter;\n+\n+        if (writer == null)\n+            return;\n+\n+        boolean needWriteStr = !writer.stringCached(taskName);\n+        byte[] strBytes = needWriteStr ? taskName.getBytes() : null;\n+\n+        doWrite(OperationType.TASK, () -> {\n+            int size = 24 + 1 + 4 + 8 + 8 + 4;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            writeIgniteUuid(buf, sesId);\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(taskName.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.putInt(affPartId);\n+        });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param queuedTime Time job spent on waiting queue.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Job execution time.\n+     * @param timedOut {@code True} if job is timed out.\n+     */\n+    public void job(IgniteUuid sesId, long queuedTime, long startTime, long duration, boolean timedOut) {\n+        doWrite(OperationType.JOB,\n+            () -> 24 + 8 + 8 + 8 + 1,\n+            buf -> {\n+                writeIgniteUuid(buf, sesId);\n+                buf.putLong(queuedTime);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+                buf.put(timedOut ? (byte)1 : 0);\n+            });\n+    }\n+\n+    /**\n+     * @param op Operation type.\n+     * @param sizeSupplier Record size supplier.\n+     * @param writer Record writer.\n+     */\n+    private void doWrite(OperationType op, IntSupplier sizeSupplier, Consumer<ByteBuffer> writer) {\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        // Writer stopping.\n+        if (fileWriter == null)\n+            return;\n+\n+        int size = sizeSupplier.getAsInt();\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(fileWriter, op, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        writer.accept(seg.buffer());\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * Reserves buffer's write segment.\n+     *\n+     * @param fileWriter File writer.\n+     * @param type Operation type.\n+     * @param size Record size.\n+     * @return Buffer's write segment or {@code null} if not enought space or writer stopping.\n+     */\n+    private SegmentedRingByteBuffer.WriteSegment reserveBuffer(FileWriter fileWriter, OperationType type, int size) {\n+        SegmentedRingByteBuffer.WriteSegment seg = fileWriter.writeSegment(size + /*type*/ 1);\n+\n+        if (seg == null) {\n+            fileWriter.logSmallBufferMessage();\n+\n+            return null;\n+        }\n+\n+        // Ring buffer closed (writer stopping) or maximum size reached.\n+        if (seg.buffer() == null) {\n+            seg.release();\n+\n+            if (!fileWriter.isCancelled())\n+                fileWriter.onMaxFileSizeReached();\n+\n+            return null;\n+        }\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)type.ordinal());\n+\n+        return seg;\n+    }\n+\n+    /** @return Performance statistics file. */\n+    public static File statisticsFile(GridKernalContext ctx) throws IgniteCheckedException {\n+        String igniteWorkDir = U.workDirectory(ctx.config().getWorkDirectory(), ctx.config().getIgniteHome());\n+\n+        File fileDir = U.resolveWorkDirectory(igniteWorkDir, PERFORMANCE_STAT_DIR, false);\n+\n+        return new File(fileDir, \"node-\" + ctx.localNodeId() + \".prf\");\n+    }\n+\n+    /** Writes {@link UUID} to buffer. */\n+    public static void writeUuid(ByteBuffer buf, UUID uuid) {\n+        buf.putLong(uuid.getMostSignificantBits());\n+        buf.putLong(uuid.getLeastSignificantBits());\n+    }\n+\n+    /** Reads {@link UUID} from buffer. */\n+    public static UUID readUuid(ByteBuffer buf) {\n+        return new UUID(buf.getLong(), buf.getLong());\n+    }\n+\n+    /** Writes {@link IgniteUuid} to buffer. */\n+    public static void writeIgniteUuid(ByteBuffer buf, IgniteUuid uuid) {\n+        buf.putLong(uuid.globalId().getMostSignificantBits());\n+        buf.putLong(uuid.globalId().getLeastSignificantBits());\n+        buf.putLong(uuid.localId());\n+    }\n+\n+    /** Reads {@link IgniteUuid} from buffer. */\n+    public static IgniteUuid readIgniteUuid(ByteBuffer buf) {", "originalCommit": "66a46d52fb6469a3066f05ae97f19bc54f3af1f3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQzMzI2OA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449433268", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-03T07:52:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTM5ODgyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTM5OTA0OQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449399049", "bodyText": "This method should be moved to the reader of some utility class.", "author": "nizhikov", "createdAt": "2020-07-03T06:29:26Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,580 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Consumer;\n+import java.util.function.IntSupplier;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * 1024 * 1024 * 1024L;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = 32 * 1024 * 1024;\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = 8 * 1024 * 1024;\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public synchronized void start() {\n+        if (enabled)\n+            return;\n+\n+        FileWriter writer = fileWriter;\n+\n+        // Writer is stopping.\n+        if (writer != null) {\n+            try {\n+                U.join(writer.runner());\n+            }\n+            catch (IgniteCheckedException e) {\n+                throw new IgniteException(\"Failed to wait for previous writer stopping.\", e);\n+            }\n+        }\n+\n+        try {\n+            File file = statisticsFile(ctx);\n+\n+            U.delete(file);\n+\n+            FileIO fileIo = fileIoFactory.create(file);\n+\n+            fileWriter = new FileWriter(ctx, fileIo, DFLT_FILE_MAX_SIZE, DFLT_BUFFER_SIZE, DFLT_FLUSH_SIZE, log);\n+\n+            new IgniteThread(fileWriter).start();\n+\n+            enabled = true;\n+\n+            log.info(\"Performance statistics writer started [file=\" + file.getAbsolutePath() + ']');\n+        }\n+        catch (IOException | IgniteCheckedException e) {\n+            log.error(\"Failed to start performance statistics writer.\", e);\n+\n+            throw new IgniteException(\"Failed to start performance statistics writer.\", e);\n+        }\n+    }\n+\n+    /** Stops collecting performance statistics. */\n+    public void stop() {\n+        synchronized (this) {\n+            if (!enabled)\n+                return;\n+\n+            enabled = false;\n+        }\n+\n+        log.info(\"Stopping performance statistics writer.\");\n+\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        if (fileWriter != null)\n+            fileWriter.shutdown();\n+    }\n+\n+    /**\n+     * @param type Operation type.\n+     * @param cacheId Cache id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     */\n+    public void cacheOperation(CacheOperation type, int cacheId, long startTime, long duration) {\n+        doWrite(OperationType.CACHE_OPERATION,\n+            () -> 1 + 4 + 8 + 8,\n+            buf -> {\n+                buf.put((byte)type.ordinal());\n+                buf.putInt(cacheId);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param cacheIds Cache IDs.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param commited {@code True} if commited.\n+     */\n+    public void transaction(GridIntList cacheIds, long startTime, long duration, boolean commited) {\n+        doWrite(OperationType.TRANSACTION,\n+            () -> 4 + cacheIds.size() * 4 + 8 + 8 + 1,\n+            buf -> {\n+                buf.putInt(cacheIds.size());\n+\n+                GridIntIterator iter = cacheIds.iterator();\n+\n+                while (iter.hasNext())\n+                    buf.putInt(iter.next());\n+\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+                buf.put(commited ? (byte)1 : 0);\n+            });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param text Query text in case of SQL query. Cache name in case of SCAN query.\n+     * @param id Query id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param success Success flag.\n+     */\n+    public void query(GridCacheQueryType type, String text, long id, long startTime, long duration, boolean success) {\n+        FileWriter writer = fileWriter;\n+\n+        if (writer == null)\n+            return;\n+\n+        boolean needWriteStr = !writer.stringCached(text);\n+        byte[] strBytes = needWriteStr ? text.getBytes() : null;\n+\n+        doWrite(OperationType.QUERY, () -> {\n+            int size = 1 + 1 + 4 + 8 + 8 + 8 + 1;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            buf.put((byte)type.ordinal());\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(text.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(id);\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.put(success ? (byte)1 : 0);\n+        });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param queryNodeId Originating node id.\n+     * @param id Query id.\n+     * @param logicalReads Number of logical reads.\n+     * @param physicalReads Number of physical reads.\n+     */\n+    public void queryReads(GridCacheQueryType type, UUID queryNodeId, long id, long logicalReads, long physicalReads) {\n+        doWrite(OperationType.QUERY_READS,\n+            () -> 1 + 16 + 8 + 8 + 8,\n+            buf -> {\n+                buf.put((byte)type.ordinal());\n+                writeUuid(buf, queryNodeId);\n+                buf.putLong(id);\n+                buf.putLong(logicalReads);\n+                buf.putLong(physicalReads);\n+            });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param taskName Task name.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration.\n+     * @param affPartId Affinity partition id.\n+     */\n+    public void task(IgniteUuid sesId, String taskName, long startTime, long duration, int affPartId) {\n+        FileWriter writer = fileWriter;\n+\n+        if (writer == null)\n+            return;\n+\n+        boolean needWriteStr = !writer.stringCached(taskName);\n+        byte[] strBytes = needWriteStr ? taskName.getBytes() : null;\n+\n+        doWrite(OperationType.TASK, () -> {\n+            int size = 24 + 1 + 4 + 8 + 8 + 4;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            writeIgniteUuid(buf, sesId);\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(taskName.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.putInt(affPartId);\n+        });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param queuedTime Time job spent on waiting queue.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Job execution time.\n+     * @param timedOut {@code True} if job is timed out.\n+     */\n+    public void job(IgniteUuid sesId, long queuedTime, long startTime, long duration, boolean timedOut) {\n+        doWrite(OperationType.JOB,\n+            () -> 24 + 8 + 8 + 8 + 1,\n+            buf -> {\n+                writeIgniteUuid(buf, sesId);\n+                buf.putLong(queuedTime);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+                buf.put(timedOut ? (byte)1 : 0);\n+            });\n+    }\n+\n+    /**\n+     * @param op Operation type.\n+     * @param sizeSupplier Record size supplier.\n+     * @param writer Record writer.\n+     */\n+    private void doWrite(OperationType op, IntSupplier sizeSupplier, Consumer<ByteBuffer> writer) {\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        // Writer stopping.\n+        if (fileWriter == null)\n+            return;\n+\n+        int size = sizeSupplier.getAsInt();\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(fileWriter, op, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        writer.accept(seg.buffer());\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * Reserves buffer's write segment.\n+     *\n+     * @param fileWriter File writer.\n+     * @param type Operation type.\n+     * @param size Record size.\n+     * @return Buffer's write segment or {@code null} if not enought space or writer stopping.\n+     */\n+    private SegmentedRingByteBuffer.WriteSegment reserveBuffer(FileWriter fileWriter, OperationType type, int size) {\n+        SegmentedRingByteBuffer.WriteSegment seg = fileWriter.writeSegment(size + /*type*/ 1);\n+\n+        if (seg == null) {\n+            fileWriter.logSmallBufferMessage();\n+\n+            return null;\n+        }\n+\n+        // Ring buffer closed (writer stopping) or maximum size reached.\n+        if (seg.buffer() == null) {\n+            seg.release();\n+\n+            if (!fileWriter.isCancelled())\n+                fileWriter.onMaxFileSizeReached();\n+\n+            return null;\n+        }\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)type.ordinal());\n+\n+        return seg;\n+    }\n+\n+    /** @return Performance statistics file. */\n+    public static File statisticsFile(GridKernalContext ctx) throws IgniteCheckedException {\n+        String igniteWorkDir = U.workDirectory(ctx.config().getWorkDirectory(), ctx.config().getIgniteHome());\n+\n+        File fileDir = U.resolveWorkDirectory(igniteWorkDir, PERFORMANCE_STAT_DIR, false);\n+\n+        return new File(fileDir, \"node-\" + ctx.localNodeId() + \".prf\");\n+    }\n+\n+    /** Writes {@link UUID} to buffer. */\n+    public static void writeUuid(ByteBuffer buf, UUID uuid) {\n+        buf.putLong(uuid.getMostSignificantBits());\n+        buf.putLong(uuid.getLeastSignificantBits());\n+    }\n+\n+    /** Reads {@link UUID} from buffer. */\n+    public static UUID readUuid(ByteBuffer buf) {", "originalCommit": "66a46d52fb6469a3066f05ae97f19bc54f3af1f3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQzMzI5MA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449433290", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-03T07:53:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTM5OTA0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTM5OTc1NA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449399754", "bodyText": "It seems to me that all resource cleaning should be done in finally block to prevent resource leaking on any unhandled exception.", "author": "nizhikov", "createdAt": "2020-07-03T06:31:24Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,580 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Consumer;\n+import java.util.function.IntSupplier;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * 1024 * 1024 * 1024L;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = 32 * 1024 * 1024;\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = 8 * 1024 * 1024;\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public synchronized void start() {\n+        if (enabled)\n+            return;\n+\n+        FileWriter writer = fileWriter;\n+\n+        // Writer is stopping.\n+        if (writer != null) {\n+            try {\n+                U.join(writer.runner());\n+            }\n+            catch (IgniteCheckedException e) {\n+                throw new IgniteException(\"Failed to wait for previous writer stopping.\", e);\n+            }\n+        }\n+\n+        try {\n+            File file = statisticsFile(ctx);\n+\n+            U.delete(file);\n+\n+            FileIO fileIo = fileIoFactory.create(file);\n+\n+            fileWriter = new FileWriter(ctx, fileIo, DFLT_FILE_MAX_SIZE, DFLT_BUFFER_SIZE, DFLT_FLUSH_SIZE, log);\n+\n+            new IgniteThread(fileWriter).start();\n+\n+            enabled = true;\n+\n+            log.info(\"Performance statistics writer started [file=\" + file.getAbsolutePath() + ']');\n+        }\n+        catch (IOException | IgniteCheckedException e) {\n+            log.error(\"Failed to start performance statistics writer.\", e);\n+\n+            throw new IgniteException(\"Failed to start performance statistics writer.\", e);\n+        }\n+    }\n+\n+    /** Stops collecting performance statistics. */\n+    public void stop() {\n+        synchronized (this) {\n+            if (!enabled)\n+                return;\n+\n+            enabled = false;\n+        }\n+\n+        log.info(\"Stopping performance statistics writer.\");\n+\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        if (fileWriter != null)\n+            fileWriter.shutdown();\n+    }\n+\n+    /**\n+     * @param type Operation type.\n+     * @param cacheId Cache id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     */\n+    public void cacheOperation(CacheOperation type, int cacheId, long startTime, long duration) {\n+        doWrite(OperationType.CACHE_OPERATION,\n+            () -> 1 + 4 + 8 + 8,\n+            buf -> {\n+                buf.put((byte)type.ordinal());\n+                buf.putInt(cacheId);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param cacheIds Cache IDs.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param commited {@code True} if commited.\n+     */\n+    public void transaction(GridIntList cacheIds, long startTime, long duration, boolean commited) {\n+        doWrite(OperationType.TRANSACTION,\n+            () -> 4 + cacheIds.size() * 4 + 8 + 8 + 1,\n+            buf -> {\n+                buf.putInt(cacheIds.size());\n+\n+                GridIntIterator iter = cacheIds.iterator();\n+\n+                while (iter.hasNext())\n+                    buf.putInt(iter.next());\n+\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+                buf.put(commited ? (byte)1 : 0);\n+            });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param text Query text in case of SQL query. Cache name in case of SCAN query.\n+     * @param id Query id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param success Success flag.\n+     */\n+    public void query(GridCacheQueryType type, String text, long id, long startTime, long duration, boolean success) {\n+        FileWriter writer = fileWriter;\n+\n+        if (writer == null)\n+            return;\n+\n+        boolean needWriteStr = !writer.stringCached(text);\n+        byte[] strBytes = needWriteStr ? text.getBytes() : null;\n+\n+        doWrite(OperationType.QUERY, () -> {\n+            int size = 1 + 1 + 4 + 8 + 8 + 8 + 1;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            buf.put((byte)type.ordinal());\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(text.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(id);\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.put(success ? (byte)1 : 0);\n+        });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param queryNodeId Originating node id.\n+     * @param id Query id.\n+     * @param logicalReads Number of logical reads.\n+     * @param physicalReads Number of physical reads.\n+     */\n+    public void queryReads(GridCacheQueryType type, UUID queryNodeId, long id, long logicalReads, long physicalReads) {\n+        doWrite(OperationType.QUERY_READS,\n+            () -> 1 + 16 + 8 + 8 + 8,\n+            buf -> {\n+                buf.put((byte)type.ordinal());\n+                writeUuid(buf, queryNodeId);\n+                buf.putLong(id);\n+                buf.putLong(logicalReads);\n+                buf.putLong(physicalReads);\n+            });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param taskName Task name.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration.\n+     * @param affPartId Affinity partition id.\n+     */\n+    public void task(IgniteUuid sesId, String taskName, long startTime, long duration, int affPartId) {\n+        FileWriter writer = fileWriter;\n+\n+        if (writer == null)\n+            return;\n+\n+        boolean needWriteStr = !writer.stringCached(taskName);\n+        byte[] strBytes = needWriteStr ? taskName.getBytes() : null;\n+\n+        doWrite(OperationType.TASK, () -> {\n+            int size = 24 + 1 + 4 + 8 + 8 + 4;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            writeIgniteUuid(buf, sesId);\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(taskName.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.putInt(affPartId);\n+        });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param queuedTime Time job spent on waiting queue.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Job execution time.\n+     * @param timedOut {@code True} if job is timed out.\n+     */\n+    public void job(IgniteUuid sesId, long queuedTime, long startTime, long duration, boolean timedOut) {\n+        doWrite(OperationType.JOB,\n+            () -> 24 + 8 + 8 + 8 + 1,\n+            buf -> {\n+                writeIgniteUuid(buf, sesId);\n+                buf.putLong(queuedTime);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+                buf.put(timedOut ? (byte)1 : 0);\n+            });\n+    }\n+\n+    /**\n+     * @param op Operation type.\n+     * @param sizeSupplier Record size supplier.\n+     * @param writer Record writer.\n+     */\n+    private void doWrite(OperationType op, IntSupplier sizeSupplier, Consumer<ByteBuffer> writer) {\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        // Writer stopping.\n+        if (fileWriter == null)\n+            return;\n+\n+        int size = sizeSupplier.getAsInt();\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(fileWriter, op, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        writer.accept(seg.buffer());\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * Reserves buffer's write segment.\n+     *\n+     * @param fileWriter File writer.\n+     * @param type Operation type.\n+     * @param size Record size.\n+     * @return Buffer's write segment or {@code null} if not enought space or writer stopping.\n+     */\n+    private SegmentedRingByteBuffer.WriteSegment reserveBuffer(FileWriter fileWriter, OperationType type, int size) {\n+        SegmentedRingByteBuffer.WriteSegment seg = fileWriter.writeSegment(size + /*type*/ 1);\n+\n+        if (seg == null) {\n+            fileWriter.logSmallBufferMessage();\n+\n+            return null;\n+        }\n+\n+        // Ring buffer closed (writer stopping) or maximum size reached.\n+        if (seg.buffer() == null) {\n+            seg.release();\n+\n+            if (!fileWriter.isCancelled())\n+                fileWriter.onMaxFileSizeReached();\n+\n+            return null;\n+        }\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)type.ordinal());\n+\n+        return seg;\n+    }\n+\n+    /** @return Performance statistics file. */\n+    public static File statisticsFile(GridKernalContext ctx) throws IgniteCheckedException {\n+        String igniteWorkDir = U.workDirectory(ctx.config().getWorkDirectory(), ctx.config().getIgniteHome());\n+\n+        File fileDir = U.resolveWorkDirectory(igniteWorkDir, PERFORMANCE_STAT_DIR, false);\n+\n+        return new File(fileDir, \"node-\" + ctx.localNodeId() + \".prf\");\n+    }\n+\n+    /** Writes {@link UUID} to buffer. */\n+    public static void writeUuid(ByteBuffer buf, UUID uuid) {\n+        buf.putLong(uuid.getMostSignificantBits());\n+        buf.putLong(uuid.getLeastSignificantBits());\n+    }\n+\n+    /** Reads {@link UUID} from buffer. */\n+    public static UUID readUuid(ByteBuffer buf) {\n+        return new UUID(buf.getLong(), buf.getLong());\n+    }\n+\n+    /** Writes {@link IgniteUuid} to buffer. */\n+    public static void writeIgniteUuid(ByteBuffer buf, IgniteUuid uuid) {\n+        buf.putLong(uuid.globalId().getMostSignificantBits());\n+        buf.putLong(uuid.globalId().getLeastSignificantBits());\n+        buf.putLong(uuid.localId());\n+    }\n+\n+    /** Reads {@link IgniteUuid} from buffer. */\n+    public static IgniteUuid readIgniteUuid(ByteBuffer buf) {\n+        UUID globalId = new UUID(buf.getLong(), buf.getLong());\n+\n+        return new IgniteUuid(globalId, buf.getLong());\n+    }\n+\n+    /** @return {@code True} if collecting performance statistics enabled. */\n+    public boolean enabled() {\n+        return enabled;\n+    }\n+\n+    /** Worker to write to performance statistics file. */\n+    private class FileWriter extends GridWorker {\n+        /** Performance statistics file I/O. */\n+        private final FileIO fileIo;\n+\n+        /** File write buffer. */\n+        private final SegmentedRingByteBuffer ringByteBuffer;\n+\n+        /** Minimal batch size to flush in bytes. */\n+        private final int flushBatchSize;\n+\n+        /** Size of ready for flushing bytes. */\n+        private final AtomicInteger readyForFlushSize = new AtomicInteger();\n+\n+        /** Hashcodes of cached strings. */\n+        private final ConcurrentSkipListSet<Integer> cachedStrings = new ConcurrentSkipListSet<>();\n+\n+        /** {@code True} if the small buffer warning message logged. */\n+        private final AtomicBoolean smallBufLogged = new AtomicBoolean();\n+\n+        /** {@code True} if worker stopped due to maximum file size reached. */\n+        private final AtomicBoolean stopByMaxSize = new AtomicBoolean();\n+\n+        /**\n+         * @param ctx Kernal context.\n+         * @param fileIo Performance statistics file I/O.\n+         * @param maxFileSize Maximum file size in bytes.\n+         * @param bufferSize Off heap buffer size in bytes.\n+         * @param flushBatchSize Minimal batch size to flush in bytes.\n+         * @param log Logger.\n+         */\n+        FileWriter(GridKernalContext ctx, FileIO fileIo, long maxFileSize, int bufferSize, int flushBatchSize,\n+            IgniteLogger log) {\n+            super(ctx.igniteInstanceName(), \"performance-statistics-writer%\" + ctx.igniteInstanceName(), log);\n+\n+            this.fileIo = fileIo;\n+            this.flushBatchSize = flushBatchSize;\n+\n+            ringByteBuffer = new SegmentedRingByteBuffer(bufferSize, maxFileSize, BufferMode.DIRECT);\n+\n+            ringByteBuffer.init(0);\n+        }\n+\n+        /** {@inheritDoc} */\n+        @Override protected void body() throws InterruptedException, IgniteInterruptedCheckedException {\n+            while (!isCancelled()) {\n+                blockingSectionBegin();\n+\n+                try {\n+                    synchronized (this) {\n+                        while (readyForFlushSize.get() < flushBatchSize && !isCancelled())\n+                            wait();\n+                    }\n+                }\n+                finally {\n+                    blockingSectionEnd();\n+                }\n+\n+                flushBuffer();\n+            }\n+\n+            fileWriter = null;\n+\n+            ringByteBuffer.close();", "originalCommit": "66a46d52fb6469a3066f05ae97f19bc54f3af1f3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQzMzMyNA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449433324", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-03T07:53:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTM5OTc1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTM5OTk2MA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449399960", "bodyText": "This method used only once. Let's inline it.", "author": "nizhikov", "createdAt": "2020-07-03T06:32:04Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,580 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Consumer;\n+import java.util.function.IntSupplier;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * 1024 * 1024 * 1024L;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = 32 * 1024 * 1024;\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = 8 * 1024 * 1024;\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public synchronized void start() {\n+        if (enabled)\n+            return;\n+\n+        FileWriter writer = fileWriter;\n+\n+        // Writer is stopping.\n+        if (writer != null) {\n+            try {\n+                U.join(writer.runner());\n+            }\n+            catch (IgniteCheckedException e) {\n+                throw new IgniteException(\"Failed to wait for previous writer stopping.\", e);\n+            }\n+        }\n+\n+        try {\n+            File file = statisticsFile(ctx);\n+\n+            U.delete(file);\n+\n+            FileIO fileIo = fileIoFactory.create(file);\n+\n+            fileWriter = new FileWriter(ctx, fileIo, DFLT_FILE_MAX_SIZE, DFLT_BUFFER_SIZE, DFLT_FLUSH_SIZE, log);\n+\n+            new IgniteThread(fileWriter).start();\n+\n+            enabled = true;\n+\n+            log.info(\"Performance statistics writer started [file=\" + file.getAbsolutePath() + ']');\n+        }\n+        catch (IOException | IgniteCheckedException e) {\n+            log.error(\"Failed to start performance statistics writer.\", e);\n+\n+            throw new IgniteException(\"Failed to start performance statistics writer.\", e);\n+        }\n+    }\n+\n+    /** Stops collecting performance statistics. */\n+    public void stop() {\n+        synchronized (this) {\n+            if (!enabled)\n+                return;\n+\n+            enabled = false;\n+        }\n+\n+        log.info(\"Stopping performance statistics writer.\");\n+\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        if (fileWriter != null)\n+            fileWriter.shutdown();\n+    }\n+\n+    /**\n+     * @param type Operation type.\n+     * @param cacheId Cache id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     */\n+    public void cacheOperation(CacheOperation type, int cacheId, long startTime, long duration) {\n+        doWrite(OperationType.CACHE_OPERATION,\n+            () -> 1 + 4 + 8 + 8,\n+            buf -> {\n+                buf.put((byte)type.ordinal());\n+                buf.putInt(cacheId);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param cacheIds Cache IDs.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param commited {@code True} if commited.\n+     */\n+    public void transaction(GridIntList cacheIds, long startTime, long duration, boolean commited) {\n+        doWrite(OperationType.TRANSACTION,\n+            () -> 4 + cacheIds.size() * 4 + 8 + 8 + 1,\n+            buf -> {\n+                buf.putInt(cacheIds.size());\n+\n+                GridIntIterator iter = cacheIds.iterator();\n+\n+                while (iter.hasNext())\n+                    buf.putInt(iter.next());\n+\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+                buf.put(commited ? (byte)1 : 0);\n+            });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param text Query text in case of SQL query. Cache name in case of SCAN query.\n+     * @param id Query id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param success Success flag.\n+     */\n+    public void query(GridCacheQueryType type, String text, long id, long startTime, long duration, boolean success) {\n+        FileWriter writer = fileWriter;\n+\n+        if (writer == null)\n+            return;\n+\n+        boolean needWriteStr = !writer.stringCached(text);\n+        byte[] strBytes = needWriteStr ? text.getBytes() : null;\n+\n+        doWrite(OperationType.QUERY, () -> {\n+            int size = 1 + 1 + 4 + 8 + 8 + 8 + 1;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            buf.put((byte)type.ordinal());\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(text.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(id);\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.put(success ? (byte)1 : 0);\n+        });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param queryNodeId Originating node id.\n+     * @param id Query id.\n+     * @param logicalReads Number of logical reads.\n+     * @param physicalReads Number of physical reads.\n+     */\n+    public void queryReads(GridCacheQueryType type, UUID queryNodeId, long id, long logicalReads, long physicalReads) {\n+        doWrite(OperationType.QUERY_READS,\n+            () -> 1 + 16 + 8 + 8 + 8,\n+            buf -> {\n+                buf.put((byte)type.ordinal());\n+                writeUuid(buf, queryNodeId);\n+                buf.putLong(id);\n+                buf.putLong(logicalReads);\n+                buf.putLong(physicalReads);\n+            });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param taskName Task name.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration.\n+     * @param affPartId Affinity partition id.\n+     */\n+    public void task(IgniteUuid sesId, String taskName, long startTime, long duration, int affPartId) {\n+        FileWriter writer = fileWriter;\n+\n+        if (writer == null)\n+            return;\n+\n+        boolean needWriteStr = !writer.stringCached(taskName);\n+        byte[] strBytes = needWriteStr ? taskName.getBytes() : null;\n+\n+        doWrite(OperationType.TASK, () -> {\n+            int size = 24 + 1 + 4 + 8 + 8 + 4;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            writeIgniteUuid(buf, sesId);\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(taskName.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.putInt(affPartId);\n+        });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param queuedTime Time job spent on waiting queue.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Job execution time.\n+     * @param timedOut {@code True} if job is timed out.\n+     */\n+    public void job(IgniteUuid sesId, long queuedTime, long startTime, long duration, boolean timedOut) {\n+        doWrite(OperationType.JOB,\n+            () -> 24 + 8 + 8 + 8 + 1,\n+            buf -> {\n+                writeIgniteUuid(buf, sesId);\n+                buf.putLong(queuedTime);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+                buf.put(timedOut ? (byte)1 : 0);\n+            });\n+    }\n+\n+    /**\n+     * @param op Operation type.\n+     * @param sizeSupplier Record size supplier.\n+     * @param writer Record writer.\n+     */\n+    private void doWrite(OperationType op, IntSupplier sizeSupplier, Consumer<ByteBuffer> writer) {\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        // Writer stopping.\n+        if (fileWriter == null)\n+            return;\n+\n+        int size = sizeSupplier.getAsInt();\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(fileWriter, op, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        writer.accept(seg.buffer());\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * Reserves buffer's write segment.\n+     *\n+     * @param fileWriter File writer.\n+     * @param type Operation type.\n+     * @param size Record size.\n+     * @return Buffer's write segment or {@code null} if not enought space or writer stopping.\n+     */\n+    private SegmentedRingByteBuffer.WriteSegment reserveBuffer(FileWriter fileWriter, OperationType type, int size) {\n+        SegmentedRingByteBuffer.WriteSegment seg = fileWriter.writeSegment(size + /*type*/ 1);\n+\n+        if (seg == null) {\n+            fileWriter.logSmallBufferMessage();\n+\n+            return null;\n+        }\n+\n+        // Ring buffer closed (writer stopping) or maximum size reached.\n+        if (seg.buffer() == null) {\n+            seg.release();\n+\n+            if (!fileWriter.isCancelled())\n+                fileWriter.onMaxFileSizeReached();\n+\n+            return null;\n+        }\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)type.ordinal());\n+\n+        return seg;\n+    }\n+\n+    /** @return Performance statistics file. */\n+    public static File statisticsFile(GridKernalContext ctx) throws IgniteCheckedException {\n+        String igniteWorkDir = U.workDirectory(ctx.config().getWorkDirectory(), ctx.config().getIgniteHome());\n+\n+        File fileDir = U.resolveWorkDirectory(igniteWorkDir, PERFORMANCE_STAT_DIR, false);\n+\n+        return new File(fileDir, \"node-\" + ctx.localNodeId() + \".prf\");\n+    }\n+\n+    /** Writes {@link UUID} to buffer. */\n+    public static void writeUuid(ByteBuffer buf, UUID uuid) {\n+        buf.putLong(uuid.getMostSignificantBits());\n+        buf.putLong(uuid.getLeastSignificantBits());\n+    }\n+\n+    /** Reads {@link UUID} from buffer. */\n+    public static UUID readUuid(ByteBuffer buf) {\n+        return new UUID(buf.getLong(), buf.getLong());\n+    }\n+\n+    /** Writes {@link IgniteUuid} to buffer. */\n+    public static void writeIgniteUuid(ByteBuffer buf, IgniteUuid uuid) {\n+        buf.putLong(uuid.globalId().getMostSignificantBits());\n+        buf.putLong(uuid.globalId().getLeastSignificantBits());\n+        buf.putLong(uuid.localId());\n+    }\n+\n+    /** Reads {@link IgniteUuid} from buffer. */\n+    public static IgniteUuid readIgniteUuid(ByteBuffer buf) {\n+        UUID globalId = new UUID(buf.getLong(), buf.getLong());\n+\n+        return new IgniteUuid(globalId, buf.getLong());\n+    }\n+\n+    /** @return {@code True} if collecting performance statistics enabled. */\n+    public boolean enabled() {\n+        return enabled;\n+    }\n+\n+    /** Worker to write to performance statistics file. */\n+    private class FileWriter extends GridWorker {\n+        /** Performance statistics file I/O. */\n+        private final FileIO fileIo;\n+\n+        /** File write buffer. */\n+        private final SegmentedRingByteBuffer ringByteBuffer;\n+\n+        /** Minimal batch size to flush in bytes. */\n+        private final int flushBatchSize;\n+\n+        /** Size of ready for flushing bytes. */\n+        private final AtomicInteger readyForFlushSize = new AtomicInteger();\n+\n+        /** Hashcodes of cached strings. */\n+        private final ConcurrentSkipListSet<Integer> cachedStrings = new ConcurrentSkipListSet<>();\n+\n+        /** {@code True} if the small buffer warning message logged. */\n+        private final AtomicBoolean smallBufLogged = new AtomicBoolean();\n+\n+        /** {@code True} if worker stopped due to maximum file size reached. */\n+        private final AtomicBoolean stopByMaxSize = new AtomicBoolean();\n+\n+        /**\n+         * @param ctx Kernal context.\n+         * @param fileIo Performance statistics file I/O.\n+         * @param maxFileSize Maximum file size in bytes.\n+         * @param bufferSize Off heap buffer size in bytes.\n+         * @param flushBatchSize Minimal batch size to flush in bytes.\n+         * @param log Logger.\n+         */\n+        FileWriter(GridKernalContext ctx, FileIO fileIo, long maxFileSize, int bufferSize, int flushBatchSize,\n+            IgniteLogger log) {\n+            super(ctx.igniteInstanceName(), \"performance-statistics-writer%\" + ctx.igniteInstanceName(), log);\n+\n+            this.fileIo = fileIo;\n+            this.flushBatchSize = flushBatchSize;\n+\n+            ringByteBuffer = new SegmentedRingByteBuffer(bufferSize, maxFileSize, BufferMode.DIRECT);\n+\n+            ringByteBuffer.init(0);\n+        }\n+\n+        /** {@inheritDoc} */\n+        @Override protected void body() throws InterruptedException, IgniteInterruptedCheckedException {\n+            while (!isCancelled()) {\n+                blockingSectionBegin();\n+\n+                try {\n+                    synchronized (this) {\n+                        while (readyForFlushSize.get() < flushBatchSize && !isCancelled())\n+                            wait();\n+                    }\n+                }\n+                finally {\n+                    blockingSectionEnd();\n+                }\n+\n+                flushBuffer();\n+            }\n+\n+            fileWriter = null;\n+\n+            ringByteBuffer.close();\n+\n+            // Make sure that all producers released their buffers to safe deallocate memory.\n+            flushBuffer();\n+\n+            ringByteBuffer.free();\n+\n+            U.closeQuiet(fileIo);\n+\n+            cachedStrings.clear();\n+\n+            log.info(\"Performance statistics writer stopped.\");\n+        }\n+\n+        /** @return {@code True} if string hash code is cached. {@code False} if need write string.  */\n+        boolean stringCached(String str) {\n+            boolean cached = cachedStrings.contains(str.hashCode());\n+\n+            if (!cached)\n+                cachedStrings.add(str.hashCode());\n+\n+            return cached;\n+        }\n+\n+        /** @return Write segment.*/\n+        SegmentedRingByteBuffer.WriteSegment writeSegment(int size) {", "originalCommit": "66a46d52fb6469a3066f05ae97f19bc54f3af1f3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQzMzE0NA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449433144", "bodyText": "IMHO, this is FileWriter entity. It uses private fields.", "author": "NSAmelchev", "createdAt": "2020-07-03T07:52:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTM5OTk2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQwMDM5Mw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449400393", "bodyText": "Can you please, add a comment to clarify that this notify required to start writing data to the file.", "author": "nizhikov", "createdAt": "2020-07-03T06:33:27Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,580 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Consumer;\n+import java.util.function.IntSupplier;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * 1024 * 1024 * 1024L;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = 32 * 1024 * 1024;\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = 8 * 1024 * 1024;\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public synchronized void start() {\n+        if (enabled)\n+            return;\n+\n+        FileWriter writer = fileWriter;\n+\n+        // Writer is stopping.\n+        if (writer != null) {\n+            try {\n+                U.join(writer.runner());\n+            }\n+            catch (IgniteCheckedException e) {\n+                throw new IgniteException(\"Failed to wait for previous writer stopping.\", e);\n+            }\n+        }\n+\n+        try {\n+            File file = statisticsFile(ctx);\n+\n+            U.delete(file);\n+\n+            FileIO fileIo = fileIoFactory.create(file);\n+\n+            fileWriter = new FileWriter(ctx, fileIo, DFLT_FILE_MAX_SIZE, DFLT_BUFFER_SIZE, DFLT_FLUSH_SIZE, log);\n+\n+            new IgniteThread(fileWriter).start();\n+\n+            enabled = true;\n+\n+            log.info(\"Performance statistics writer started [file=\" + file.getAbsolutePath() + ']');\n+        }\n+        catch (IOException | IgniteCheckedException e) {\n+            log.error(\"Failed to start performance statistics writer.\", e);\n+\n+            throw new IgniteException(\"Failed to start performance statistics writer.\", e);\n+        }\n+    }\n+\n+    /** Stops collecting performance statistics. */\n+    public void stop() {\n+        synchronized (this) {\n+            if (!enabled)\n+                return;\n+\n+            enabled = false;\n+        }\n+\n+        log.info(\"Stopping performance statistics writer.\");\n+\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        if (fileWriter != null)\n+            fileWriter.shutdown();\n+    }\n+\n+    /**\n+     * @param type Operation type.\n+     * @param cacheId Cache id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     */\n+    public void cacheOperation(CacheOperation type, int cacheId, long startTime, long duration) {\n+        doWrite(OperationType.CACHE_OPERATION,\n+            () -> 1 + 4 + 8 + 8,\n+            buf -> {\n+                buf.put((byte)type.ordinal());\n+                buf.putInt(cacheId);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param cacheIds Cache IDs.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param commited {@code True} if commited.\n+     */\n+    public void transaction(GridIntList cacheIds, long startTime, long duration, boolean commited) {\n+        doWrite(OperationType.TRANSACTION,\n+            () -> 4 + cacheIds.size() * 4 + 8 + 8 + 1,\n+            buf -> {\n+                buf.putInt(cacheIds.size());\n+\n+                GridIntIterator iter = cacheIds.iterator();\n+\n+                while (iter.hasNext())\n+                    buf.putInt(iter.next());\n+\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+                buf.put(commited ? (byte)1 : 0);\n+            });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param text Query text in case of SQL query. Cache name in case of SCAN query.\n+     * @param id Query id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param success Success flag.\n+     */\n+    public void query(GridCacheQueryType type, String text, long id, long startTime, long duration, boolean success) {\n+        FileWriter writer = fileWriter;\n+\n+        if (writer == null)\n+            return;\n+\n+        boolean needWriteStr = !writer.stringCached(text);\n+        byte[] strBytes = needWriteStr ? text.getBytes() : null;\n+\n+        doWrite(OperationType.QUERY, () -> {\n+            int size = 1 + 1 + 4 + 8 + 8 + 8 + 1;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            buf.put((byte)type.ordinal());\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(text.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(id);\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.put(success ? (byte)1 : 0);\n+        });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param queryNodeId Originating node id.\n+     * @param id Query id.\n+     * @param logicalReads Number of logical reads.\n+     * @param physicalReads Number of physical reads.\n+     */\n+    public void queryReads(GridCacheQueryType type, UUID queryNodeId, long id, long logicalReads, long physicalReads) {\n+        doWrite(OperationType.QUERY_READS,\n+            () -> 1 + 16 + 8 + 8 + 8,\n+            buf -> {\n+                buf.put((byte)type.ordinal());\n+                writeUuid(buf, queryNodeId);\n+                buf.putLong(id);\n+                buf.putLong(logicalReads);\n+                buf.putLong(physicalReads);\n+            });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param taskName Task name.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration.\n+     * @param affPartId Affinity partition id.\n+     */\n+    public void task(IgniteUuid sesId, String taskName, long startTime, long duration, int affPartId) {\n+        FileWriter writer = fileWriter;\n+\n+        if (writer == null)\n+            return;\n+\n+        boolean needWriteStr = !writer.stringCached(taskName);\n+        byte[] strBytes = needWriteStr ? taskName.getBytes() : null;\n+\n+        doWrite(OperationType.TASK, () -> {\n+            int size = 24 + 1 + 4 + 8 + 8 + 4;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            writeIgniteUuid(buf, sesId);\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(taskName.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.putInt(affPartId);\n+        });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param queuedTime Time job spent on waiting queue.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Job execution time.\n+     * @param timedOut {@code True} if job is timed out.\n+     */\n+    public void job(IgniteUuid sesId, long queuedTime, long startTime, long duration, boolean timedOut) {\n+        doWrite(OperationType.JOB,\n+            () -> 24 + 8 + 8 + 8 + 1,\n+            buf -> {\n+                writeIgniteUuid(buf, sesId);\n+                buf.putLong(queuedTime);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+                buf.put(timedOut ? (byte)1 : 0);\n+            });\n+    }\n+\n+    /**\n+     * @param op Operation type.\n+     * @param sizeSupplier Record size supplier.\n+     * @param writer Record writer.\n+     */\n+    private void doWrite(OperationType op, IntSupplier sizeSupplier, Consumer<ByteBuffer> writer) {\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        // Writer stopping.\n+        if (fileWriter == null)\n+            return;\n+\n+        int size = sizeSupplier.getAsInt();\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(fileWriter, op, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        writer.accept(seg.buffer());\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * Reserves buffer's write segment.\n+     *\n+     * @param fileWriter File writer.\n+     * @param type Operation type.\n+     * @param size Record size.\n+     * @return Buffer's write segment or {@code null} if not enought space or writer stopping.\n+     */\n+    private SegmentedRingByteBuffer.WriteSegment reserveBuffer(FileWriter fileWriter, OperationType type, int size) {\n+        SegmentedRingByteBuffer.WriteSegment seg = fileWriter.writeSegment(size + /*type*/ 1);\n+\n+        if (seg == null) {\n+            fileWriter.logSmallBufferMessage();\n+\n+            return null;\n+        }\n+\n+        // Ring buffer closed (writer stopping) or maximum size reached.\n+        if (seg.buffer() == null) {\n+            seg.release();\n+\n+            if (!fileWriter.isCancelled())\n+                fileWriter.onMaxFileSizeReached();\n+\n+            return null;\n+        }\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)type.ordinal());\n+\n+        return seg;\n+    }\n+\n+    /** @return Performance statistics file. */\n+    public static File statisticsFile(GridKernalContext ctx) throws IgniteCheckedException {\n+        String igniteWorkDir = U.workDirectory(ctx.config().getWorkDirectory(), ctx.config().getIgniteHome());\n+\n+        File fileDir = U.resolveWorkDirectory(igniteWorkDir, PERFORMANCE_STAT_DIR, false);\n+\n+        return new File(fileDir, \"node-\" + ctx.localNodeId() + \".prf\");\n+    }\n+\n+    /** Writes {@link UUID} to buffer. */\n+    public static void writeUuid(ByteBuffer buf, UUID uuid) {\n+        buf.putLong(uuid.getMostSignificantBits());\n+        buf.putLong(uuid.getLeastSignificantBits());\n+    }\n+\n+    /** Reads {@link UUID} from buffer. */\n+    public static UUID readUuid(ByteBuffer buf) {\n+        return new UUID(buf.getLong(), buf.getLong());\n+    }\n+\n+    /** Writes {@link IgniteUuid} to buffer. */\n+    public static void writeIgniteUuid(ByteBuffer buf, IgniteUuid uuid) {\n+        buf.putLong(uuid.globalId().getMostSignificantBits());\n+        buf.putLong(uuid.globalId().getLeastSignificantBits());\n+        buf.putLong(uuid.localId());\n+    }\n+\n+    /** Reads {@link IgniteUuid} from buffer. */\n+    public static IgniteUuid readIgniteUuid(ByteBuffer buf) {\n+        UUID globalId = new UUID(buf.getLong(), buf.getLong());\n+\n+        return new IgniteUuid(globalId, buf.getLong());\n+    }\n+\n+    /** @return {@code True} if collecting performance statistics enabled. */\n+    public boolean enabled() {\n+        return enabled;\n+    }\n+\n+    /** Worker to write to performance statistics file. */\n+    private class FileWriter extends GridWorker {\n+        /** Performance statistics file I/O. */\n+        private final FileIO fileIo;\n+\n+        /** File write buffer. */\n+        private final SegmentedRingByteBuffer ringByteBuffer;\n+\n+        /** Minimal batch size to flush in bytes. */\n+        private final int flushBatchSize;\n+\n+        /** Size of ready for flushing bytes. */\n+        private final AtomicInteger readyForFlushSize = new AtomicInteger();\n+\n+        /** Hashcodes of cached strings. */\n+        private final ConcurrentSkipListSet<Integer> cachedStrings = new ConcurrentSkipListSet<>();\n+\n+        /** {@code True} if the small buffer warning message logged. */\n+        private final AtomicBoolean smallBufLogged = new AtomicBoolean();\n+\n+        /** {@code True} if worker stopped due to maximum file size reached. */\n+        private final AtomicBoolean stopByMaxSize = new AtomicBoolean();\n+\n+        /**\n+         * @param ctx Kernal context.\n+         * @param fileIo Performance statistics file I/O.\n+         * @param maxFileSize Maximum file size in bytes.\n+         * @param bufferSize Off heap buffer size in bytes.\n+         * @param flushBatchSize Minimal batch size to flush in bytes.\n+         * @param log Logger.\n+         */\n+        FileWriter(GridKernalContext ctx, FileIO fileIo, long maxFileSize, int bufferSize, int flushBatchSize,\n+            IgniteLogger log) {\n+            super(ctx.igniteInstanceName(), \"performance-statistics-writer%\" + ctx.igniteInstanceName(), log);\n+\n+            this.fileIo = fileIo;\n+            this.flushBatchSize = flushBatchSize;\n+\n+            ringByteBuffer = new SegmentedRingByteBuffer(bufferSize, maxFileSize, BufferMode.DIRECT);\n+\n+            ringByteBuffer.init(0);\n+        }\n+\n+        /** {@inheritDoc} */\n+        @Override protected void body() throws InterruptedException, IgniteInterruptedCheckedException {\n+            while (!isCancelled()) {\n+                blockingSectionBegin();\n+\n+                try {\n+                    synchronized (this) {\n+                        while (readyForFlushSize.get() < flushBatchSize && !isCancelled())\n+                            wait();\n+                    }\n+                }\n+                finally {\n+                    blockingSectionEnd();\n+                }\n+\n+                flushBuffer();\n+            }\n+\n+            fileWriter = null;\n+\n+            ringByteBuffer.close();\n+\n+            // Make sure that all producers released their buffers to safe deallocate memory.\n+            flushBuffer();\n+\n+            ringByteBuffer.free();\n+\n+            U.closeQuiet(fileIo);\n+\n+            cachedStrings.clear();\n+\n+            log.info(\"Performance statistics writer stopped.\");\n+        }\n+\n+        /** @return {@code True} if string hash code is cached. {@code False} if need write string.  */\n+        boolean stringCached(String str) {\n+            boolean cached = cachedStrings.contains(str.hashCode());\n+\n+            if (!cached)\n+                cachedStrings.add(str.hashCode());\n+\n+            return cached;\n+        }\n+\n+        /** @return Write segment.*/\n+        SegmentedRingByteBuffer.WriteSegment writeSegment(int size) {\n+            SegmentedRingByteBuffer.WriteSegment seg = ringByteBuffer.offer(size);\n+\n+            if (seg != null) {\n+                int readySize = readyForFlushSize.addAndGet(size);\n+\n+                if (readySize >= DFLT_FLUSH_SIZE) {\n+                    synchronized (this) {\n+                        notify();", "originalCommit": "66a46d52fb6469a3066f05ae97f19bc54f3af1f3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQzMzM2MQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449433361", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-03T07:53:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQwMDM5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQwMzQ3OQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449403479", "bodyText": "Let's use IgniteUtils#GB here.", "author": "nizhikov", "createdAt": "2020-07-03T06:41:58Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,580 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Consumer;\n+import java.util.function.IntSupplier;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * 1024 * 1024 * 1024L;", "originalCommit": "66a46d52fb6469a3066f05ae97f19bc54f3af1f3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQzMzQ5MA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449433490", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-03T07:53:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQwMzQ3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQwMzY1MA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449403650", "bodyText": "Let's use IgniteUtils#MB here.", "author": "nizhikov", "createdAt": "2020-07-03T06:42:24Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,580 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Consumer;\n+import java.util.function.IntSupplier;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * 1024 * 1024 * 1024L;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = 32 * 1024 * 1024;", "originalCommit": "66a46d52fb6469a3066f05ae97f19bc54f3af1f3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQzMzQxOQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449433419", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-03T07:53:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQwMzY1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQwMzkzOA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449403938", "bodyText": "Let's use IgniteUtils#MB here.", "author": "nizhikov", "createdAt": "2020-07-03T06:43:16Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,580 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Consumer;\n+import java.util.function.IntSupplier;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * 1024 * 1024 * 1024L;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = 32 * 1024 * 1024;\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = 8 * 1024 * 1024;", "originalCommit": "66a46d52fb6469a3066f05ae97f19bc54f3af1f3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQzMzQ1Ng==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449433456", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-03T07:53:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQwMzkzOA=="}], "type": "inlineReview"}, {"oid": "679e11d8106d6e13030857428fd692446ffb9a86", "url": "https://github.com/apache/ignite/commit/679e11d8106d6e13030857428fd692446ffb9a86", "message": "Review fixes", "committedDate": "2020-07-03T07:50:13Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQzNjk5OA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449436998", "bodyText": "we can check writer inside doWrite", "author": "nizhikov", "createdAt": "2020-07-03T08:00:09Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,559 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Consumer;\n+import java.util.function.IntSupplier;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.JOB;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY_READS;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TASK;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_COMMIT;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_ROLLBACK;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * U.GB;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = (int)(32 * U.MB);\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = (int)(8 * U.MB);\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public synchronized void start() {\n+        if (enabled)\n+            return;\n+\n+        FileWriter writer = fileWriter;\n+\n+        // Writer is stopping.\n+        if (writer != null) {\n+            try {\n+                U.join(writer.runner());\n+            }\n+            catch (IgniteCheckedException e) {\n+                throw new IgniteException(\"Failed to wait for previous writer stopping.\", e);\n+            }\n+        }\n+\n+        try {\n+            File file = statisticsFile(ctx);\n+\n+            U.delete(file);\n+\n+            FileIO fileIo = fileIoFactory.create(file);\n+\n+            fileWriter = new FileWriter(ctx, fileIo, DFLT_FILE_MAX_SIZE, DFLT_BUFFER_SIZE, DFLT_FLUSH_SIZE, log);\n+\n+            new IgniteThread(fileWriter).start();\n+\n+            enabled = true;\n+\n+            log.info(\"Performance statistics writer started [file=\" + file.getAbsolutePath() + ']');\n+        }\n+        catch (IOException | IgniteCheckedException e) {\n+            log.error(\"Failed to start performance statistics writer.\", e);\n+\n+            throw new IgniteException(\"Failed to start performance statistics writer.\", e);\n+        }\n+    }\n+\n+    /** Stops collecting performance statistics. */\n+    public void stop() {\n+        synchronized (this) {\n+            if (!enabled)\n+                return;\n+\n+            enabled = false;\n+        }\n+\n+        log.info(\"Stopping performance statistics writer.\");\n+\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        if (fileWriter != null)\n+            fileWriter.shutdown();\n+    }\n+\n+    /**\n+     * @param type Operation type.\n+     * @param cacheId Cache id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     */\n+    public void cacheOperation(OperationType type, int cacheId, long startTime, long duration) {\n+        doWrite(type,\n+            () -> 4 + 8 + 8,\n+            buf -> {\n+                buf.putInt(cacheId);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param cacheIds Cache IDs.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param commited {@code True} if commited.\n+     */\n+    public void transaction(GridIntList cacheIds, long startTime, long duration, boolean commited) {\n+        doWrite(commited ? TX_COMMIT : TX_ROLLBACK,\n+            () -> 4 + cacheIds.size() * 4 + 8 + 8,\n+            buf -> {\n+                buf.putInt(cacheIds.size());\n+\n+                GridIntIterator iter = cacheIds.iterator();\n+\n+                while (iter.hasNext())\n+                    buf.putInt(iter.next());\n+\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param text Query text in case of SQL query. Cache name in case of SCAN query.\n+     * @param id Query id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param success Success flag.\n+     */\n+    public void query(GridCacheQueryType type, String text, long id, long startTime, long duration, boolean success) {\n+        FileWriter writer = fileWriter;", "originalCommit": "679e11d8106d6e13030857428fd692446ffb9a86", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQ4ODE4NQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449488185", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-03T09:42:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQzNjk5OA=="}], "type": "inlineReview"}, {"oid": "6027e11a98bcfac1b95690a32ac46e7b87b53726", "url": "https://github.com/apache/ignite/commit/6027e11a98bcfac1b95690a32ac46e7b87b53726", "message": "Review fixes", "committedDate": "2020-07-03T09:42:01Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTUxMTc4NQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449511785", "bodyText": "This method can be private.", "author": "nizhikov", "createdAt": "2020-07-03T10:32:58Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,549 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Consumer;\n+import java.util.function.IntSupplier;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.JOB;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY_READS;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TASK;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_COMMIT;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_ROLLBACK;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * U.GB;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = (int)(32 * U.MB);\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = (int)(8 * U.MB);\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Hashcodes of cached strings. */\n+    private final ConcurrentSkipListSet<Integer> cachedStrings = new ConcurrentSkipListSet<>();\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public synchronized void start() {\n+        if (enabled)\n+            return;\n+\n+        FileWriter writer = fileWriter;\n+\n+        // Writer is stopping.\n+        if (writer != null) {\n+            try {\n+                U.join(writer.runner());\n+            }\n+            catch (IgniteCheckedException e) {\n+                throw new IgniteException(\"Failed to wait for previous writer stopping.\", e);\n+            }\n+        }\n+\n+        try {\n+            File file = statisticsFile(ctx);\n+\n+            U.delete(file);\n+\n+            FileIO fileIo = fileIoFactory.create(file);\n+\n+            fileWriter = new FileWriter(ctx, fileIo, DFLT_FILE_MAX_SIZE, DFLT_BUFFER_SIZE, DFLT_FLUSH_SIZE, log);\n+\n+            new IgniteThread(fileWriter).start();\n+\n+            enabled = true;\n+\n+            log.info(\"Performance statistics writer started [file=\" + file.getAbsolutePath() + ']');\n+        }\n+        catch (IOException | IgniteCheckedException e) {\n+            log.error(\"Failed to start performance statistics writer.\", e);\n+\n+            throw new IgniteException(\"Failed to start performance statistics writer.\", e);\n+        }\n+    }\n+\n+    /** Stops collecting performance statistics. */\n+    public void stop() {\n+        synchronized (this) {\n+            if (!enabled)\n+                return;\n+\n+            enabled = false;\n+        }\n+\n+        log.info(\"Stopping performance statistics writer.\");\n+\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        if (fileWriter != null)\n+            fileWriter.shutdown();\n+    }\n+\n+    /**\n+     * @param type Operation type.\n+     * @param cacheId Cache id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     */\n+    public void cacheOperation(OperationType type, int cacheId, long startTime, long duration) {\n+        doWrite(type,\n+            () -> 4 + 8 + 8,\n+            buf -> {\n+                buf.putInt(cacheId);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param cacheIds Cache IDs.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param commited {@code True} if commited.\n+     */\n+    public void transaction(GridIntList cacheIds, long startTime, long duration, boolean commited) {\n+        doWrite(commited ? TX_COMMIT : TX_ROLLBACK,\n+            () -> 4 + cacheIds.size() * 4 + 8 + 8,\n+            buf -> {\n+                buf.putInt(cacheIds.size());\n+\n+                GridIntIterator iter = cacheIds.iterator();\n+\n+                while (iter.hasNext())\n+                    buf.putInt(iter.next());\n+\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param text Query text in case of SQL query. Cache name in case of SCAN query.\n+     * @param id Query id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param success Success flag.\n+     */\n+    public void query(GridCacheQueryType type, String text, long id, long startTime, long duration, boolean success) {\n+        boolean needWriteStr = !stringCached(text);\n+        byte[] strBytes = needWriteStr ? text.getBytes() : null;\n+\n+        doWrite(QUERY, () -> {\n+            int size = 1 + 1 + 4 + 8 + 8 + 8 + 1;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            buf.put((byte)type.ordinal());\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(text.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(id);\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.put(success ? (byte)1 : 0);\n+        });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param queryNodeId Originating node id.\n+     * @param id Query id.\n+     * @param logicalReads Number of logical reads.\n+     * @param physicalReads Number of physical reads.\n+     */\n+    public void queryReads(GridCacheQueryType type, UUID queryNodeId, long id, long logicalReads, long physicalReads) {\n+        doWrite(QUERY_READS,\n+            () -> 1 + 16 + 8 + 8 + 8,\n+            buf -> {\n+                buf.put((byte)type.ordinal());\n+                writeUuid(buf, queryNodeId);\n+                buf.putLong(id);\n+                buf.putLong(logicalReads);\n+                buf.putLong(physicalReads);\n+            });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param taskName Task name.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration.\n+     * @param affPartId Affinity partition id.\n+     */\n+    public void task(IgniteUuid sesId, String taskName, long startTime, long duration, int affPartId) {\n+        boolean needWriteStr = !stringCached(taskName);\n+        byte[] strBytes = needWriteStr ? taskName.getBytes() : null;\n+\n+        doWrite(TASK, () -> {\n+            int size = 24 + 1 + 4 + 8 + 8 + 4;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            writeIgniteUuid(buf, sesId);\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(taskName.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.putInt(affPartId);\n+        });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param queuedTime Time job spent on waiting queue.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Job execution time.\n+     * @param timedOut {@code True} if job is timed out.\n+     */\n+    public void job(IgniteUuid sesId, long queuedTime, long startTime, long duration, boolean timedOut) {\n+        doWrite(JOB,\n+            () -> 24 + 8 + 8 + 8 + 1,\n+            buf -> {\n+                writeIgniteUuid(buf, sesId);\n+                buf.putLong(queuedTime);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+                buf.put(timedOut ? (byte)1 : 0);\n+            });\n+    }\n+\n+    /**\n+     * @param op Operation type.\n+     * @param sizeSupplier Record size supplier.\n+     * @param writer Record writer.\n+     */\n+    private void doWrite(OperationType op, IntSupplier sizeSupplier, Consumer<ByteBuffer> writer) {\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        // Writer stopping.\n+        if (fileWriter == null)\n+            return;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = fileWriter.writeSegment(sizeSupplier.getAsInt() + /*type*/ 1);\n+\n+        if (seg == null) {\n+            fileWriter.logSmallBufferMessage();\n+\n+            return;\n+        }\n+\n+        // Ring buffer closed (writer stopping) or maximum size reached.\n+        if (seg.buffer() == null) {\n+            seg.release();\n+\n+            if (!fileWriter.isCancelled())\n+                fileWriter.onMaxFileSizeReached();\n+\n+            return;\n+        }\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)op.ordinal());\n+\n+        writer.accept(buf);\n+\n+        seg.release();\n+    }\n+\n+    /** @return {@code True} if string is cached. {@code False} if need write string.  */\n+    boolean stringCached(String str) {", "originalCommit": "6027e11a98bcfac1b95690a32ac46e7b87b53726", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTUyNjk2MQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449526961", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-03T11:10:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTUxMTc4NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTUxMjEzMQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449512131", "bodyText": "This method can be private.", "author": "nizhikov", "createdAt": "2020-07-03T10:33:45Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,549 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Consumer;\n+import java.util.function.IntSupplier;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.JOB;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY_READS;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TASK;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_COMMIT;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_ROLLBACK;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * U.GB;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = (int)(32 * U.MB);\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = (int)(8 * U.MB);\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Hashcodes of cached strings. */\n+    private final ConcurrentSkipListSet<Integer> cachedStrings = new ConcurrentSkipListSet<>();\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public synchronized void start() {\n+        if (enabled)\n+            return;\n+\n+        FileWriter writer = fileWriter;\n+\n+        // Writer is stopping.\n+        if (writer != null) {\n+            try {\n+                U.join(writer.runner());\n+            }\n+            catch (IgniteCheckedException e) {\n+                throw new IgniteException(\"Failed to wait for previous writer stopping.\", e);\n+            }\n+        }\n+\n+        try {\n+            File file = statisticsFile(ctx);\n+\n+            U.delete(file);\n+\n+            FileIO fileIo = fileIoFactory.create(file);\n+\n+            fileWriter = new FileWriter(ctx, fileIo, DFLT_FILE_MAX_SIZE, DFLT_BUFFER_SIZE, DFLT_FLUSH_SIZE, log);\n+\n+            new IgniteThread(fileWriter).start();\n+\n+            enabled = true;\n+\n+            log.info(\"Performance statistics writer started [file=\" + file.getAbsolutePath() + ']');\n+        }\n+        catch (IOException | IgniteCheckedException e) {\n+            log.error(\"Failed to start performance statistics writer.\", e);\n+\n+            throw new IgniteException(\"Failed to start performance statistics writer.\", e);\n+        }\n+    }\n+\n+    /** Stops collecting performance statistics. */\n+    public void stop() {\n+        synchronized (this) {\n+            if (!enabled)\n+                return;\n+\n+            enabled = false;\n+        }\n+\n+        log.info(\"Stopping performance statistics writer.\");\n+\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        if (fileWriter != null)\n+            fileWriter.shutdown();\n+    }\n+\n+    /**\n+     * @param type Operation type.\n+     * @param cacheId Cache id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     */\n+    public void cacheOperation(OperationType type, int cacheId, long startTime, long duration) {\n+        doWrite(type,\n+            () -> 4 + 8 + 8,\n+            buf -> {\n+                buf.putInt(cacheId);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param cacheIds Cache IDs.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param commited {@code True} if commited.\n+     */\n+    public void transaction(GridIntList cacheIds, long startTime, long duration, boolean commited) {\n+        doWrite(commited ? TX_COMMIT : TX_ROLLBACK,\n+            () -> 4 + cacheIds.size() * 4 + 8 + 8,\n+            buf -> {\n+                buf.putInt(cacheIds.size());\n+\n+                GridIntIterator iter = cacheIds.iterator();\n+\n+                while (iter.hasNext())\n+                    buf.putInt(iter.next());\n+\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param text Query text in case of SQL query. Cache name in case of SCAN query.\n+     * @param id Query id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param success Success flag.\n+     */\n+    public void query(GridCacheQueryType type, String text, long id, long startTime, long duration, boolean success) {\n+        boolean needWriteStr = !stringCached(text);\n+        byte[] strBytes = needWriteStr ? text.getBytes() : null;\n+\n+        doWrite(QUERY, () -> {\n+            int size = 1 + 1 + 4 + 8 + 8 + 8 + 1;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            buf.put((byte)type.ordinal());\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(text.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(id);\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.put(success ? (byte)1 : 0);\n+        });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param queryNodeId Originating node id.\n+     * @param id Query id.\n+     * @param logicalReads Number of logical reads.\n+     * @param physicalReads Number of physical reads.\n+     */\n+    public void queryReads(GridCacheQueryType type, UUID queryNodeId, long id, long logicalReads, long physicalReads) {\n+        doWrite(QUERY_READS,\n+            () -> 1 + 16 + 8 + 8 + 8,\n+            buf -> {\n+                buf.put((byte)type.ordinal());\n+                writeUuid(buf, queryNodeId);\n+                buf.putLong(id);\n+                buf.putLong(logicalReads);\n+                buf.putLong(physicalReads);\n+            });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param taskName Task name.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration.\n+     * @param affPartId Affinity partition id.\n+     */\n+    public void task(IgniteUuid sesId, String taskName, long startTime, long duration, int affPartId) {\n+        boolean needWriteStr = !stringCached(taskName);\n+        byte[] strBytes = needWriteStr ? taskName.getBytes() : null;\n+\n+        doWrite(TASK, () -> {\n+            int size = 24 + 1 + 4 + 8 + 8 + 4;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            writeIgniteUuid(buf, sesId);\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(taskName.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.putInt(affPartId);\n+        });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param queuedTime Time job spent on waiting queue.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Job execution time.\n+     * @param timedOut {@code True} if job is timed out.\n+     */\n+    public void job(IgniteUuid sesId, long queuedTime, long startTime, long duration, boolean timedOut) {\n+        doWrite(JOB,\n+            () -> 24 + 8 + 8 + 8 + 1,\n+            buf -> {\n+                writeIgniteUuid(buf, sesId);\n+                buf.putLong(queuedTime);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+                buf.put(timedOut ? (byte)1 : 0);\n+            });\n+    }\n+\n+    /**\n+     * @param op Operation type.\n+     * @param sizeSupplier Record size supplier.\n+     * @param writer Record writer.\n+     */\n+    private void doWrite(OperationType op, IntSupplier sizeSupplier, Consumer<ByteBuffer> writer) {\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        // Writer stopping.\n+        if (fileWriter == null)\n+            return;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = fileWriter.writeSegment(sizeSupplier.getAsInt() + /*type*/ 1);\n+\n+        if (seg == null) {\n+            fileWriter.logSmallBufferMessage();\n+\n+            return;\n+        }\n+\n+        // Ring buffer closed (writer stopping) or maximum size reached.\n+        if (seg.buffer() == null) {\n+            seg.release();\n+\n+            if (!fileWriter.isCancelled())\n+                fileWriter.onMaxFileSizeReached();\n+\n+            return;\n+        }\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)op.ordinal());\n+\n+        writer.accept(buf);\n+\n+        seg.release();\n+    }\n+\n+    /** @return {@code True} if string is cached. {@code False} if need write string.  */\n+    boolean stringCached(String str) {\n+        boolean cached = cachedStrings.contains(str.hashCode());\n+\n+        if (!cached)\n+            cachedStrings.add(str.hashCode());\n+\n+        return cached;\n+    }\n+\n+    /** @return Performance statistics file. */\n+    public static File statisticsFile(GridKernalContext ctx) throws IgniteCheckedException {", "originalCommit": "6027e11a98bcfac1b95690a32ac46e7b87b53726", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTUyNzAwMA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449527000", "bodyText": "Fixed.", "author": "NSAmelchev", "createdAt": "2020-07-03T11:10:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTUxMjEzMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTUxMjIxMw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449512213", "bodyText": "This method can be private.", "author": "nizhikov", "createdAt": "2020-07-03T10:33:57Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,549 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Consumer;\n+import java.util.function.IntSupplier;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.JOB;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY_READS;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TASK;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_COMMIT;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_ROLLBACK;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * U.GB;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = (int)(32 * U.MB);\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = (int)(8 * U.MB);\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Hashcodes of cached strings. */\n+    private final ConcurrentSkipListSet<Integer> cachedStrings = new ConcurrentSkipListSet<>();\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public synchronized void start() {\n+        if (enabled)\n+            return;\n+\n+        FileWriter writer = fileWriter;\n+\n+        // Writer is stopping.\n+        if (writer != null) {\n+            try {\n+                U.join(writer.runner());\n+            }\n+            catch (IgniteCheckedException e) {\n+                throw new IgniteException(\"Failed to wait for previous writer stopping.\", e);\n+            }\n+        }\n+\n+        try {\n+            File file = statisticsFile(ctx);\n+\n+            U.delete(file);\n+\n+            FileIO fileIo = fileIoFactory.create(file);\n+\n+            fileWriter = new FileWriter(ctx, fileIo, DFLT_FILE_MAX_SIZE, DFLT_BUFFER_SIZE, DFLT_FLUSH_SIZE, log);\n+\n+            new IgniteThread(fileWriter).start();\n+\n+            enabled = true;\n+\n+            log.info(\"Performance statistics writer started [file=\" + file.getAbsolutePath() + ']');\n+        }\n+        catch (IOException | IgniteCheckedException e) {\n+            log.error(\"Failed to start performance statistics writer.\", e);\n+\n+            throw new IgniteException(\"Failed to start performance statistics writer.\", e);\n+        }\n+    }\n+\n+    /** Stops collecting performance statistics. */\n+    public void stop() {\n+        synchronized (this) {\n+            if (!enabled)\n+                return;\n+\n+            enabled = false;\n+        }\n+\n+        log.info(\"Stopping performance statistics writer.\");\n+\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        if (fileWriter != null)\n+            fileWriter.shutdown();\n+    }\n+\n+    /**\n+     * @param type Operation type.\n+     * @param cacheId Cache id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     */\n+    public void cacheOperation(OperationType type, int cacheId, long startTime, long duration) {\n+        doWrite(type,\n+            () -> 4 + 8 + 8,\n+            buf -> {\n+                buf.putInt(cacheId);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param cacheIds Cache IDs.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param commited {@code True} if commited.\n+     */\n+    public void transaction(GridIntList cacheIds, long startTime, long duration, boolean commited) {\n+        doWrite(commited ? TX_COMMIT : TX_ROLLBACK,\n+            () -> 4 + cacheIds.size() * 4 + 8 + 8,\n+            buf -> {\n+                buf.putInt(cacheIds.size());\n+\n+                GridIntIterator iter = cacheIds.iterator();\n+\n+                while (iter.hasNext())\n+                    buf.putInt(iter.next());\n+\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param text Query text in case of SQL query. Cache name in case of SCAN query.\n+     * @param id Query id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param success Success flag.\n+     */\n+    public void query(GridCacheQueryType type, String text, long id, long startTime, long duration, boolean success) {\n+        boolean needWriteStr = !stringCached(text);\n+        byte[] strBytes = needWriteStr ? text.getBytes() : null;\n+\n+        doWrite(QUERY, () -> {\n+            int size = 1 + 1 + 4 + 8 + 8 + 8 + 1;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            buf.put((byte)type.ordinal());\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(text.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(id);\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.put(success ? (byte)1 : 0);\n+        });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param queryNodeId Originating node id.\n+     * @param id Query id.\n+     * @param logicalReads Number of logical reads.\n+     * @param physicalReads Number of physical reads.\n+     */\n+    public void queryReads(GridCacheQueryType type, UUID queryNodeId, long id, long logicalReads, long physicalReads) {\n+        doWrite(QUERY_READS,\n+            () -> 1 + 16 + 8 + 8 + 8,\n+            buf -> {\n+                buf.put((byte)type.ordinal());\n+                writeUuid(buf, queryNodeId);\n+                buf.putLong(id);\n+                buf.putLong(logicalReads);\n+                buf.putLong(physicalReads);\n+            });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param taskName Task name.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration.\n+     * @param affPartId Affinity partition id.\n+     */\n+    public void task(IgniteUuid sesId, String taskName, long startTime, long duration, int affPartId) {\n+        boolean needWriteStr = !stringCached(taskName);\n+        byte[] strBytes = needWriteStr ? taskName.getBytes() : null;\n+\n+        doWrite(TASK, () -> {\n+            int size = 24 + 1 + 4 + 8 + 8 + 4;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            writeIgniteUuid(buf, sesId);\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(taskName.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.putInt(affPartId);\n+        });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param queuedTime Time job spent on waiting queue.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Job execution time.\n+     * @param timedOut {@code True} if job is timed out.\n+     */\n+    public void job(IgniteUuid sesId, long queuedTime, long startTime, long duration, boolean timedOut) {\n+        doWrite(JOB,\n+            () -> 24 + 8 + 8 + 8 + 1,\n+            buf -> {\n+                writeIgniteUuid(buf, sesId);\n+                buf.putLong(queuedTime);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+                buf.put(timedOut ? (byte)1 : 0);\n+            });\n+    }\n+\n+    /**\n+     * @param op Operation type.\n+     * @param sizeSupplier Record size supplier.\n+     * @param writer Record writer.\n+     */\n+    private void doWrite(OperationType op, IntSupplier sizeSupplier, Consumer<ByteBuffer> writer) {\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        // Writer stopping.\n+        if (fileWriter == null)\n+            return;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = fileWriter.writeSegment(sizeSupplier.getAsInt() + /*type*/ 1);\n+\n+        if (seg == null) {\n+            fileWriter.logSmallBufferMessage();\n+\n+            return;\n+        }\n+\n+        // Ring buffer closed (writer stopping) or maximum size reached.\n+        if (seg.buffer() == null) {\n+            seg.release();\n+\n+            if (!fileWriter.isCancelled())\n+                fileWriter.onMaxFileSizeReached();\n+\n+            return;\n+        }\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)op.ordinal());\n+\n+        writer.accept(buf);\n+\n+        seg.release();\n+    }\n+\n+    /** @return {@code True} if string is cached. {@code False} if need write string.  */\n+    boolean stringCached(String str) {\n+        boolean cached = cachedStrings.contains(str.hashCode());\n+\n+        if (!cached)\n+            cachedStrings.add(str.hashCode());\n+\n+        return cached;\n+    }\n+\n+    /** @return Performance statistics file. */\n+    public static File statisticsFile(GridKernalContext ctx) throws IgniteCheckedException {\n+        String igniteWorkDir = U.workDirectory(ctx.config().getWorkDirectory(), ctx.config().getIgniteHome());\n+\n+        File fileDir = U.resolveWorkDirectory(igniteWorkDir, PERFORMANCE_STAT_DIR, false);\n+\n+        return new File(fileDir, \"node-\" + ctx.localNodeId() + \".prf\");\n+    }\n+\n+    /** Writes {@link UUID} to buffer. */\n+    public static void writeUuid(ByteBuffer buf, UUID uuid) {", "originalCommit": "6027e11a98bcfac1b95690a32ac46e7b87b53726", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTUyNzAyMA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449527020", "bodyText": "Fixed.", "author": "NSAmelchev", "createdAt": "2020-07-03T11:10:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTUxMjIxMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTUxMjI1MQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449512251", "bodyText": "This method can be private.", "author": "nizhikov", "createdAt": "2020-07-03T10:34:02Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,549 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Consumer;\n+import java.util.function.IntSupplier;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.JOB;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY_READS;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TASK;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_COMMIT;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_ROLLBACK;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * U.GB;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = (int)(32 * U.MB);\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = (int)(8 * U.MB);\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Hashcodes of cached strings. */\n+    private final ConcurrentSkipListSet<Integer> cachedStrings = new ConcurrentSkipListSet<>();\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public synchronized void start() {\n+        if (enabled)\n+            return;\n+\n+        FileWriter writer = fileWriter;\n+\n+        // Writer is stopping.\n+        if (writer != null) {\n+            try {\n+                U.join(writer.runner());\n+            }\n+            catch (IgniteCheckedException e) {\n+                throw new IgniteException(\"Failed to wait for previous writer stopping.\", e);\n+            }\n+        }\n+\n+        try {\n+            File file = statisticsFile(ctx);\n+\n+            U.delete(file);\n+\n+            FileIO fileIo = fileIoFactory.create(file);\n+\n+            fileWriter = new FileWriter(ctx, fileIo, DFLT_FILE_MAX_SIZE, DFLT_BUFFER_SIZE, DFLT_FLUSH_SIZE, log);\n+\n+            new IgniteThread(fileWriter).start();\n+\n+            enabled = true;\n+\n+            log.info(\"Performance statistics writer started [file=\" + file.getAbsolutePath() + ']');\n+        }\n+        catch (IOException | IgniteCheckedException e) {\n+            log.error(\"Failed to start performance statistics writer.\", e);\n+\n+            throw new IgniteException(\"Failed to start performance statistics writer.\", e);\n+        }\n+    }\n+\n+    /** Stops collecting performance statistics. */\n+    public void stop() {\n+        synchronized (this) {\n+            if (!enabled)\n+                return;\n+\n+            enabled = false;\n+        }\n+\n+        log.info(\"Stopping performance statistics writer.\");\n+\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        if (fileWriter != null)\n+            fileWriter.shutdown();\n+    }\n+\n+    /**\n+     * @param type Operation type.\n+     * @param cacheId Cache id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     */\n+    public void cacheOperation(OperationType type, int cacheId, long startTime, long duration) {\n+        doWrite(type,\n+            () -> 4 + 8 + 8,\n+            buf -> {\n+                buf.putInt(cacheId);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param cacheIds Cache IDs.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param commited {@code True} if commited.\n+     */\n+    public void transaction(GridIntList cacheIds, long startTime, long duration, boolean commited) {\n+        doWrite(commited ? TX_COMMIT : TX_ROLLBACK,\n+            () -> 4 + cacheIds.size() * 4 + 8 + 8,\n+            buf -> {\n+                buf.putInt(cacheIds.size());\n+\n+                GridIntIterator iter = cacheIds.iterator();\n+\n+                while (iter.hasNext())\n+                    buf.putInt(iter.next());\n+\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param text Query text in case of SQL query. Cache name in case of SCAN query.\n+     * @param id Query id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param success Success flag.\n+     */\n+    public void query(GridCacheQueryType type, String text, long id, long startTime, long duration, boolean success) {\n+        boolean needWriteStr = !stringCached(text);\n+        byte[] strBytes = needWriteStr ? text.getBytes() : null;\n+\n+        doWrite(QUERY, () -> {\n+            int size = 1 + 1 + 4 + 8 + 8 + 8 + 1;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            buf.put((byte)type.ordinal());\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(text.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(id);\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.put(success ? (byte)1 : 0);\n+        });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param queryNodeId Originating node id.\n+     * @param id Query id.\n+     * @param logicalReads Number of logical reads.\n+     * @param physicalReads Number of physical reads.\n+     */\n+    public void queryReads(GridCacheQueryType type, UUID queryNodeId, long id, long logicalReads, long physicalReads) {\n+        doWrite(QUERY_READS,\n+            () -> 1 + 16 + 8 + 8 + 8,\n+            buf -> {\n+                buf.put((byte)type.ordinal());\n+                writeUuid(buf, queryNodeId);\n+                buf.putLong(id);\n+                buf.putLong(logicalReads);\n+                buf.putLong(physicalReads);\n+            });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param taskName Task name.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration.\n+     * @param affPartId Affinity partition id.\n+     */\n+    public void task(IgniteUuid sesId, String taskName, long startTime, long duration, int affPartId) {\n+        boolean needWriteStr = !stringCached(taskName);\n+        byte[] strBytes = needWriteStr ? taskName.getBytes() : null;\n+\n+        doWrite(TASK, () -> {\n+            int size = 24 + 1 + 4 + 8 + 8 + 4;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            writeIgniteUuid(buf, sesId);\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(taskName.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.putInt(affPartId);\n+        });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param queuedTime Time job spent on waiting queue.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Job execution time.\n+     * @param timedOut {@code True} if job is timed out.\n+     */\n+    public void job(IgniteUuid sesId, long queuedTime, long startTime, long duration, boolean timedOut) {\n+        doWrite(JOB,\n+            () -> 24 + 8 + 8 + 8 + 1,\n+            buf -> {\n+                writeIgniteUuid(buf, sesId);\n+                buf.putLong(queuedTime);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+                buf.put(timedOut ? (byte)1 : 0);\n+            });\n+    }\n+\n+    /**\n+     * @param op Operation type.\n+     * @param sizeSupplier Record size supplier.\n+     * @param writer Record writer.\n+     */\n+    private void doWrite(OperationType op, IntSupplier sizeSupplier, Consumer<ByteBuffer> writer) {\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        // Writer stopping.\n+        if (fileWriter == null)\n+            return;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = fileWriter.writeSegment(sizeSupplier.getAsInt() + /*type*/ 1);\n+\n+        if (seg == null) {\n+            fileWriter.logSmallBufferMessage();\n+\n+            return;\n+        }\n+\n+        // Ring buffer closed (writer stopping) or maximum size reached.\n+        if (seg.buffer() == null) {\n+            seg.release();\n+\n+            if (!fileWriter.isCancelled())\n+                fileWriter.onMaxFileSizeReached();\n+\n+            return;\n+        }\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)op.ordinal());\n+\n+        writer.accept(buf);\n+\n+        seg.release();\n+    }\n+\n+    /** @return {@code True} if string is cached. {@code False} if need write string.  */\n+    boolean stringCached(String str) {\n+        boolean cached = cachedStrings.contains(str.hashCode());\n+\n+        if (!cached)\n+            cachedStrings.add(str.hashCode());\n+\n+        return cached;\n+    }\n+\n+    /** @return Performance statistics file. */\n+    public static File statisticsFile(GridKernalContext ctx) throws IgniteCheckedException {\n+        String igniteWorkDir = U.workDirectory(ctx.config().getWorkDirectory(), ctx.config().getIgniteHome());\n+\n+        File fileDir = U.resolveWorkDirectory(igniteWorkDir, PERFORMANCE_STAT_DIR, false);\n+\n+        return new File(fileDir, \"node-\" + ctx.localNodeId() + \".prf\");\n+    }\n+\n+    /** Writes {@link UUID} to buffer. */\n+    public static void writeUuid(ByteBuffer buf, UUID uuid) {\n+        buf.putLong(uuid.getMostSignificantBits());\n+        buf.putLong(uuid.getLeastSignificantBits());\n+    }\n+\n+    /** Writes {@link IgniteUuid} to buffer. */\n+    public static void writeIgniteUuid(ByteBuffer buf, IgniteUuid uuid) {", "originalCommit": "6027e11a98bcfac1b95690a32ac46e7b87b53726", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTUyNzA0OQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449527049", "bodyText": "Fixed.", "author": "NSAmelchev", "createdAt": "2020-07-03T11:10:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTUxMjI1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTUxMzQxOQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449513419", "bodyText": "We shouldn't remove gathered statistics on each restart.", "author": "nizhikov", "createdAt": "2020-07-03T10:36:43Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,549 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Consumer;\n+import java.util.function.IntSupplier;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.JOB;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY_READS;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TASK;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_COMMIT;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_ROLLBACK;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * U.GB;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = (int)(32 * U.MB);\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = (int)(8 * U.MB);\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Hashcodes of cached strings. */\n+    private final ConcurrentSkipListSet<Integer> cachedStrings = new ConcurrentSkipListSet<>();\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public synchronized void start() {\n+        if (enabled)\n+            return;\n+\n+        FileWriter writer = fileWriter;\n+\n+        // Writer is stopping.\n+        if (writer != null) {\n+            try {\n+                U.join(writer.runner());\n+            }\n+            catch (IgniteCheckedException e) {\n+                throw new IgniteException(\"Failed to wait for previous writer stopping.\", e);\n+            }\n+        }\n+\n+        try {\n+            File file = statisticsFile(ctx);\n+\n+            U.delete(file);", "originalCommit": "6027e11a98bcfac1b95690a32ac46e7b87b53726", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "d860c9d0a72ab744c7fac03894d2d57b055a1001", "url": "https://github.com/apache/ignite/commit/d860c9d0a72ab744c7fac03894d2d57b055a1001", "message": "Review fixes", "committedDate": "2020-07-03T11:08:25Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTU2NDAwMg==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449564002", "bodyText": "This method used only once. Let's inline it.", "author": "nizhikov", "createdAt": "2020-07-03T12:43:11Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,549 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Consumer;\n+import java.util.function.IntSupplier;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.JOB;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY_READS;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TASK;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_COMMIT;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_ROLLBACK;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * U.GB;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = (int)(32 * U.MB);\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = (int)(8 * U.MB);\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Hashcodes of cached strings. */\n+    private final ConcurrentSkipListSet<Integer> cachedStrings = new ConcurrentSkipListSet<>();\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public synchronized void start() {\n+        if (enabled)\n+            return;\n+\n+        FileWriter writer = fileWriter;\n+\n+        // Writer is stopping.\n+        if (writer != null) {\n+            try {\n+                U.join(writer.runner());\n+            }\n+            catch (IgniteCheckedException e) {\n+                throw new IgniteException(\"Failed to wait for previous writer stopping.\", e);\n+            }\n+        }\n+\n+        try {\n+            File file = statisticsFile(ctx);\n+\n+            U.delete(file);\n+\n+            FileIO fileIo = fileIoFactory.create(file);\n+\n+            fileWriter = new FileWriter(ctx, fileIo, DFLT_FILE_MAX_SIZE, DFLT_BUFFER_SIZE, DFLT_FLUSH_SIZE, log);\n+\n+            new IgniteThread(fileWriter).start();\n+\n+            enabled = true;\n+\n+            log.info(\"Performance statistics writer started [file=\" + file.getAbsolutePath() + ']');\n+        }\n+        catch (IOException | IgniteCheckedException e) {\n+            log.error(\"Failed to start performance statistics writer.\", e);\n+\n+            throw new IgniteException(\"Failed to start performance statistics writer.\", e);\n+        }\n+    }\n+\n+    /** Stops collecting performance statistics. */\n+    public void stop() {\n+        synchronized (this) {\n+            if (!enabled)\n+                return;\n+\n+            enabled = false;\n+        }\n+\n+        log.info(\"Stopping performance statistics writer.\");\n+\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        if (fileWriter != null)\n+            fileWriter.shutdown();\n+    }\n+\n+    /**\n+     * @param type Operation type.\n+     * @param cacheId Cache id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     */\n+    public void cacheOperation(OperationType type, int cacheId, long startTime, long duration) {\n+        doWrite(type,\n+            () -> 4 + 8 + 8,\n+            buf -> {\n+                buf.putInt(cacheId);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param cacheIds Cache IDs.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param commited {@code True} if commited.\n+     */\n+    public void transaction(GridIntList cacheIds, long startTime, long duration, boolean commited) {\n+        doWrite(commited ? TX_COMMIT : TX_ROLLBACK,\n+            () -> 4 + cacheIds.size() * 4 + 8 + 8,\n+            buf -> {\n+                buf.putInt(cacheIds.size());\n+\n+                GridIntIterator iter = cacheIds.iterator();\n+\n+                while (iter.hasNext())\n+                    buf.putInt(iter.next());\n+\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param text Query text in case of SQL query. Cache name in case of SCAN query.\n+     * @param id Query id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param success Success flag.\n+     */\n+    public void query(GridCacheQueryType type, String text, long id, long startTime, long duration, boolean success) {\n+        boolean needWriteStr = !stringCached(text);\n+        byte[] strBytes = needWriteStr ? text.getBytes() : null;\n+\n+        doWrite(QUERY, () -> {\n+            int size = 1 + 1 + 4 + 8 + 8 + 8 + 1;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            buf.put((byte)type.ordinal());\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(text.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(id);\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.put(success ? (byte)1 : 0);\n+        });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param queryNodeId Originating node id.\n+     * @param id Query id.\n+     * @param logicalReads Number of logical reads.\n+     * @param physicalReads Number of physical reads.\n+     */\n+    public void queryReads(GridCacheQueryType type, UUID queryNodeId, long id, long logicalReads, long physicalReads) {\n+        doWrite(QUERY_READS,\n+            () -> 1 + 16 + 8 + 8 + 8,\n+            buf -> {\n+                buf.put((byte)type.ordinal());\n+                writeUuid(buf, queryNodeId);\n+                buf.putLong(id);\n+                buf.putLong(logicalReads);\n+                buf.putLong(physicalReads);\n+            });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param taskName Task name.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration.\n+     * @param affPartId Affinity partition id.\n+     */\n+    public void task(IgniteUuid sesId, String taskName, long startTime, long duration, int affPartId) {\n+        boolean needWriteStr = !stringCached(taskName);\n+        byte[] strBytes = needWriteStr ? taskName.getBytes() : null;\n+\n+        doWrite(TASK, () -> {\n+            int size = 24 + 1 + 4 + 8 + 8 + 4;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            writeIgniteUuid(buf, sesId);\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(taskName.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.putInt(affPartId);\n+        });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param queuedTime Time job spent on waiting queue.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Job execution time.\n+     * @param timedOut {@code True} if job is timed out.\n+     */\n+    public void job(IgniteUuid sesId, long queuedTime, long startTime, long duration, boolean timedOut) {\n+        doWrite(JOB,\n+            () -> 24 + 8 + 8 + 8 + 1,\n+            buf -> {\n+                writeIgniteUuid(buf, sesId);\n+                buf.putLong(queuedTime);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+                buf.put(timedOut ? (byte)1 : 0);\n+            });\n+    }\n+\n+    /**\n+     * @param op Operation type.\n+     * @param sizeSupplier Record size supplier.\n+     * @param writer Record writer.\n+     */\n+    private void doWrite(OperationType op, IntSupplier sizeSupplier, Consumer<ByteBuffer> writer) {\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        // Writer stopping.\n+        if (fileWriter == null)\n+            return;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = fileWriter.writeSegment(sizeSupplier.getAsInt() + /*type*/ 1);\n+\n+        if (seg == null) {\n+            fileWriter.logSmallBufferMessage();\n+\n+            return;\n+        }\n+\n+        // Ring buffer closed (writer stopping) or maximum size reached.\n+        if (seg.buffer() == null) {\n+            seg.release();\n+\n+            if (!fileWriter.isCancelled())\n+                fileWriter.onMaxFileSizeReached();\n+\n+            return;\n+        }\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)op.ordinal());\n+\n+        writer.accept(buf);\n+\n+        seg.release();\n+    }\n+\n+    /** @return {@code True} if string is cached. {@code False} if need write string.  */\n+    private boolean stringCached(String str) {\n+        boolean cached = cachedStrings.contains(str.hashCode());\n+\n+        if (!cached)\n+            cachedStrings.add(str.hashCode());\n+\n+        return cached;\n+    }\n+\n+    /** @return Performance statistics file. */\n+    private static File statisticsFile(GridKernalContext ctx) throws IgniteCheckedException {\n+        String igniteWorkDir = U.workDirectory(ctx.config().getWorkDirectory(), ctx.config().getIgniteHome());\n+\n+        File fileDir = U.resolveWorkDirectory(igniteWorkDir, PERFORMANCE_STAT_DIR, false);\n+\n+        return new File(fileDir, \"node-\" + ctx.localNodeId() + \".prf\");\n+    }\n+\n+    /** Writes {@link UUID} to buffer. */\n+    private static void writeUuid(ByteBuffer buf, UUID uuid) {\n+        buf.putLong(uuid.getMostSignificantBits());\n+        buf.putLong(uuid.getLeastSignificantBits());\n+    }\n+\n+    /** Writes {@link IgniteUuid} to buffer. */\n+    private static void writeIgniteUuid(ByteBuffer buf, IgniteUuid uuid) {\n+        buf.putLong(uuid.globalId().getMostSignificantBits());\n+        buf.putLong(uuid.globalId().getLeastSignificantBits());\n+        buf.putLong(uuid.localId());\n+    }\n+\n+    /** @return {@code True} if collecting performance statistics enabled. */\n+    public boolean enabled() {\n+        return enabled;\n+    }\n+\n+    /** Worker to write to performance statistics file. */\n+    private class FileWriter extends GridWorker {\n+        /** Performance statistics file I/O. */\n+        private final FileIO fileIo;\n+\n+        /** File write buffer. */\n+        private final SegmentedRingByteBuffer ringByteBuffer;\n+\n+        /** Minimal batch size to flush in bytes. */\n+        private final int flushBatchSize;\n+\n+        /** Size of ready for flushing bytes. */\n+        private final AtomicInteger readyForFlushSize = new AtomicInteger();\n+\n+        /** {@code True} if the small buffer warning message logged. */\n+        private final AtomicBoolean smallBufLogged = new AtomicBoolean();\n+\n+        /** {@code True} if worker stopped due to maximum file size reached. */\n+        private final AtomicBoolean stopByMaxSize = new AtomicBoolean();\n+\n+        /**\n+         * @param ctx Kernal context.\n+         * @param fileIo Performance statistics file I/O.\n+         * @param maxFileSize Maximum file size in bytes.\n+         * @param bufferSize Off heap buffer size in bytes.\n+         * @param flushBatchSize Minimal batch size to flush in bytes.\n+         * @param log Logger.\n+         */\n+        FileWriter(GridKernalContext ctx, FileIO fileIo, long maxFileSize, int bufferSize, int flushBatchSize,\n+            IgniteLogger log) {\n+            super(ctx.igniteInstanceName(), \"performance-statistics-writer%\" + ctx.igniteInstanceName(), log);\n+\n+            this.fileIo = fileIo;\n+            this.flushBatchSize = flushBatchSize;\n+\n+            ringByteBuffer = new SegmentedRingByteBuffer(bufferSize, maxFileSize, BufferMode.DIRECT);\n+\n+            ringByteBuffer.init(0);\n+        }\n+\n+        /** {@inheritDoc} */\n+        @Override protected void body() throws InterruptedException, IgniteInterruptedCheckedException {\n+            try {\n+                while (!isCancelled()) {\n+                    blockingSectionBegin();\n+\n+                    try {\n+                        synchronized (this) {\n+                            while (readyForFlushSize.get() < flushBatchSize && !isCancelled())\n+                                wait();\n+                        }\n+                    }\n+                    finally {\n+                        blockingSectionEnd();\n+                    }\n+\n+                    flushBuffer();\n+                }\n+            }\n+            finally {\n+                fileWriter = null;\n+\n+                ringByteBuffer.close();\n+\n+                // Make sure that all producers released their buffers to safe deallocate memory.\n+                flushBuffer();\n+\n+                ringByteBuffer.free();\n+\n+                U.closeQuiet(fileIo);\n+\n+                cachedStrings.clear();\n+\n+                log.info(\"Performance statistics writer stopped.\");\n+            }\n+        }\n+\n+        /** @return Write segment.*/\n+        SegmentedRingByteBuffer.WriteSegment writeSegment(int size) {\n+            SegmentedRingByteBuffer.WriteSegment seg = ringByteBuffer.offer(size);\n+\n+            if (seg != null) {\n+                int readySize = readyForFlushSize.addAndGet(size);\n+\n+                if (readySize >= DFLT_FLUSH_SIZE) {\n+                    synchronized (this) {\n+                        // Required to start writing data to the file.\n+                        notify();\n+                    }\n+                }\n+            }\n+\n+            return seg;\n+        }\n+\n+        /** Flushes to disk available bytes from the ring buffer. */\n+        private void flushBuffer() {\n+            List<SegmentedRingByteBuffer.ReadSegment> segs = ringByteBuffer.poll();\n+\n+            if (segs == null)\n+                return;\n+\n+            try {\n+                for (int i = 0; i < segs.size(); i++) {\n+                    updateHeartbeat();\n+\n+                    SegmentedRingByteBuffer.ReadSegment seg = segs.get(i);\n+\n+                    try {\n+                        readyForFlushSize.addAndGet(-seg.buffer().remaining());\n+\n+                        fileIo.writeFully(seg.buffer());\n+                    }\n+                    finally {\n+                        seg.release();\n+                    }\n+                }\n+\n+                fileIo.force();\n+            } catch (IOException e) {\n+                log.error(\"Unable to write to file. Performance statistics collecting will be stopped.\", e);\n+\n+                fileWriter.shutdown();\n+\n+                stopStatistics();\n+            }\n+        }\n+\n+        /** Shutted down the worker. */\n+        private void shutdown() {\n+            isCancelled = true;\n+\n+            synchronized (this) {\n+                // Required to start writing data to the file.\n+                notify();\n+            }\n+        }\n+\n+        /** Logs warning message about small buffer size if not logged yet. */\n+        void logSmallBufferMessage() {", "originalCommit": "d860c9d0a72ab744c7fac03894d2d57b055a1001", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTEzOTE5Mw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r451139193", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-07T20:58:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTU2NDAwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTU2NDMwOA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449564308", "bodyText": "This method used only once. Let's inline it.", "author": "nizhikov", "createdAt": "2020-07-03T12:43:53Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,549 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Consumer;\n+import java.util.function.IntSupplier;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.JOB;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY_READS;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TASK;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_COMMIT;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_ROLLBACK;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * U.GB;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = (int)(32 * U.MB);\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = (int)(8 * U.MB);\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Hashcodes of cached strings. */\n+    private final ConcurrentSkipListSet<Integer> cachedStrings = new ConcurrentSkipListSet<>();\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public synchronized void start() {\n+        if (enabled)\n+            return;\n+\n+        FileWriter writer = fileWriter;\n+\n+        // Writer is stopping.\n+        if (writer != null) {\n+            try {\n+                U.join(writer.runner());\n+            }\n+            catch (IgniteCheckedException e) {\n+                throw new IgniteException(\"Failed to wait for previous writer stopping.\", e);\n+            }\n+        }\n+\n+        try {\n+            File file = statisticsFile(ctx);\n+\n+            U.delete(file);\n+\n+            FileIO fileIo = fileIoFactory.create(file);\n+\n+            fileWriter = new FileWriter(ctx, fileIo, DFLT_FILE_MAX_SIZE, DFLT_BUFFER_SIZE, DFLT_FLUSH_SIZE, log);\n+\n+            new IgniteThread(fileWriter).start();\n+\n+            enabled = true;\n+\n+            log.info(\"Performance statistics writer started [file=\" + file.getAbsolutePath() + ']');\n+        }\n+        catch (IOException | IgniteCheckedException e) {\n+            log.error(\"Failed to start performance statistics writer.\", e);\n+\n+            throw new IgniteException(\"Failed to start performance statistics writer.\", e);\n+        }\n+    }\n+\n+    /** Stops collecting performance statistics. */\n+    public void stop() {\n+        synchronized (this) {\n+            if (!enabled)\n+                return;\n+\n+            enabled = false;\n+        }\n+\n+        log.info(\"Stopping performance statistics writer.\");\n+\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        if (fileWriter != null)\n+            fileWriter.shutdown();\n+    }\n+\n+    /**\n+     * @param type Operation type.\n+     * @param cacheId Cache id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     */\n+    public void cacheOperation(OperationType type, int cacheId, long startTime, long duration) {\n+        doWrite(type,\n+            () -> 4 + 8 + 8,\n+            buf -> {\n+                buf.putInt(cacheId);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param cacheIds Cache IDs.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param commited {@code True} if commited.\n+     */\n+    public void transaction(GridIntList cacheIds, long startTime, long duration, boolean commited) {\n+        doWrite(commited ? TX_COMMIT : TX_ROLLBACK,\n+            () -> 4 + cacheIds.size() * 4 + 8 + 8,\n+            buf -> {\n+                buf.putInt(cacheIds.size());\n+\n+                GridIntIterator iter = cacheIds.iterator();\n+\n+                while (iter.hasNext())\n+                    buf.putInt(iter.next());\n+\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param text Query text in case of SQL query. Cache name in case of SCAN query.\n+     * @param id Query id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param success Success flag.\n+     */\n+    public void query(GridCacheQueryType type, String text, long id, long startTime, long duration, boolean success) {\n+        boolean needWriteStr = !stringCached(text);\n+        byte[] strBytes = needWriteStr ? text.getBytes() : null;\n+\n+        doWrite(QUERY, () -> {\n+            int size = 1 + 1 + 4 + 8 + 8 + 8 + 1;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            buf.put((byte)type.ordinal());\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(text.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(id);\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.put(success ? (byte)1 : 0);\n+        });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param queryNodeId Originating node id.\n+     * @param id Query id.\n+     * @param logicalReads Number of logical reads.\n+     * @param physicalReads Number of physical reads.\n+     */\n+    public void queryReads(GridCacheQueryType type, UUID queryNodeId, long id, long logicalReads, long physicalReads) {\n+        doWrite(QUERY_READS,\n+            () -> 1 + 16 + 8 + 8 + 8,\n+            buf -> {\n+                buf.put((byte)type.ordinal());\n+                writeUuid(buf, queryNodeId);\n+                buf.putLong(id);\n+                buf.putLong(logicalReads);\n+                buf.putLong(physicalReads);\n+            });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param taskName Task name.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration.\n+     * @param affPartId Affinity partition id.\n+     */\n+    public void task(IgniteUuid sesId, String taskName, long startTime, long duration, int affPartId) {\n+        boolean needWriteStr = !stringCached(taskName);\n+        byte[] strBytes = needWriteStr ? taskName.getBytes() : null;\n+\n+        doWrite(TASK, () -> {\n+            int size = 24 + 1 + 4 + 8 + 8 + 4;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            writeIgniteUuid(buf, sesId);\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(taskName.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.putInt(affPartId);\n+        });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param queuedTime Time job spent on waiting queue.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Job execution time.\n+     * @param timedOut {@code True} if job is timed out.\n+     */\n+    public void job(IgniteUuid sesId, long queuedTime, long startTime, long duration, boolean timedOut) {\n+        doWrite(JOB,\n+            () -> 24 + 8 + 8 + 8 + 1,\n+            buf -> {\n+                writeIgniteUuid(buf, sesId);\n+                buf.putLong(queuedTime);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+                buf.put(timedOut ? (byte)1 : 0);\n+            });\n+    }\n+\n+    /**\n+     * @param op Operation type.\n+     * @param sizeSupplier Record size supplier.\n+     * @param writer Record writer.\n+     */\n+    private void doWrite(OperationType op, IntSupplier sizeSupplier, Consumer<ByteBuffer> writer) {\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        // Writer stopping.\n+        if (fileWriter == null)\n+            return;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = fileWriter.writeSegment(sizeSupplier.getAsInt() + /*type*/ 1);\n+\n+        if (seg == null) {\n+            fileWriter.logSmallBufferMessage();\n+\n+            return;\n+        }\n+\n+        // Ring buffer closed (writer stopping) or maximum size reached.\n+        if (seg.buffer() == null) {\n+            seg.release();\n+\n+            if (!fileWriter.isCancelled())\n+                fileWriter.onMaxFileSizeReached();\n+\n+            return;\n+        }\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)op.ordinal());\n+\n+        writer.accept(buf);\n+\n+        seg.release();\n+    }\n+\n+    /** @return {@code True} if string is cached. {@code False} if need write string.  */\n+    private boolean stringCached(String str) {\n+        boolean cached = cachedStrings.contains(str.hashCode());\n+\n+        if (!cached)\n+            cachedStrings.add(str.hashCode());\n+\n+        return cached;\n+    }\n+\n+    /** @return Performance statistics file. */\n+    private static File statisticsFile(GridKernalContext ctx) throws IgniteCheckedException {\n+        String igniteWorkDir = U.workDirectory(ctx.config().getWorkDirectory(), ctx.config().getIgniteHome());\n+\n+        File fileDir = U.resolveWorkDirectory(igniteWorkDir, PERFORMANCE_STAT_DIR, false);\n+\n+        return new File(fileDir, \"node-\" + ctx.localNodeId() + \".prf\");\n+    }\n+\n+    /** Writes {@link UUID} to buffer. */\n+    private static void writeUuid(ByteBuffer buf, UUID uuid) {\n+        buf.putLong(uuid.getMostSignificantBits());\n+        buf.putLong(uuid.getLeastSignificantBits());\n+    }\n+\n+    /** Writes {@link IgniteUuid} to buffer. */\n+    private static void writeIgniteUuid(ByteBuffer buf, IgniteUuid uuid) {\n+        buf.putLong(uuid.globalId().getMostSignificantBits());\n+        buf.putLong(uuid.globalId().getLeastSignificantBits());\n+        buf.putLong(uuid.localId());\n+    }\n+\n+    /** @return {@code True} if collecting performance statistics enabled. */\n+    public boolean enabled() {\n+        return enabled;\n+    }\n+\n+    /** Worker to write to performance statistics file. */\n+    private class FileWriter extends GridWorker {\n+        /** Performance statistics file I/O. */\n+        private final FileIO fileIo;\n+\n+        /** File write buffer. */\n+        private final SegmentedRingByteBuffer ringByteBuffer;\n+\n+        /** Minimal batch size to flush in bytes. */\n+        private final int flushBatchSize;\n+\n+        /** Size of ready for flushing bytes. */\n+        private final AtomicInteger readyForFlushSize = new AtomicInteger();\n+\n+        /** {@code True} if the small buffer warning message logged. */\n+        private final AtomicBoolean smallBufLogged = new AtomicBoolean();\n+\n+        /** {@code True} if worker stopped due to maximum file size reached. */\n+        private final AtomicBoolean stopByMaxSize = new AtomicBoolean();\n+\n+        /**\n+         * @param ctx Kernal context.\n+         * @param fileIo Performance statistics file I/O.\n+         * @param maxFileSize Maximum file size in bytes.\n+         * @param bufferSize Off heap buffer size in bytes.\n+         * @param flushBatchSize Minimal batch size to flush in bytes.\n+         * @param log Logger.\n+         */\n+        FileWriter(GridKernalContext ctx, FileIO fileIo, long maxFileSize, int bufferSize, int flushBatchSize,\n+            IgniteLogger log) {\n+            super(ctx.igniteInstanceName(), \"performance-statistics-writer%\" + ctx.igniteInstanceName(), log);\n+\n+            this.fileIo = fileIo;\n+            this.flushBatchSize = flushBatchSize;\n+\n+            ringByteBuffer = new SegmentedRingByteBuffer(bufferSize, maxFileSize, BufferMode.DIRECT);\n+\n+            ringByteBuffer.init(0);\n+        }\n+\n+        /** {@inheritDoc} */\n+        @Override protected void body() throws InterruptedException, IgniteInterruptedCheckedException {\n+            try {\n+                while (!isCancelled()) {\n+                    blockingSectionBegin();\n+\n+                    try {\n+                        synchronized (this) {\n+                            while (readyForFlushSize.get() < flushBatchSize && !isCancelled())\n+                                wait();\n+                        }\n+                    }\n+                    finally {\n+                        blockingSectionEnd();\n+                    }\n+\n+                    flushBuffer();\n+                }\n+            }\n+            finally {\n+                fileWriter = null;\n+\n+                ringByteBuffer.close();\n+\n+                // Make sure that all producers released their buffers to safe deallocate memory.\n+                flushBuffer();\n+\n+                ringByteBuffer.free();\n+\n+                U.closeQuiet(fileIo);\n+\n+                cachedStrings.clear();\n+\n+                log.info(\"Performance statistics writer stopped.\");\n+            }\n+        }\n+\n+        /** @return Write segment.*/\n+        SegmentedRingByteBuffer.WriteSegment writeSegment(int size) {\n+            SegmentedRingByteBuffer.WriteSegment seg = ringByteBuffer.offer(size);\n+\n+            if (seg != null) {\n+                int readySize = readyForFlushSize.addAndGet(size);\n+\n+                if (readySize >= DFLT_FLUSH_SIZE) {\n+                    synchronized (this) {\n+                        // Required to start writing data to the file.\n+                        notify();\n+                    }\n+                }\n+            }\n+\n+            return seg;\n+        }\n+\n+        /** Flushes to disk available bytes from the ring buffer. */\n+        private void flushBuffer() {\n+            List<SegmentedRingByteBuffer.ReadSegment> segs = ringByteBuffer.poll();\n+\n+            if (segs == null)\n+                return;\n+\n+            try {\n+                for (int i = 0; i < segs.size(); i++) {\n+                    updateHeartbeat();\n+\n+                    SegmentedRingByteBuffer.ReadSegment seg = segs.get(i);\n+\n+                    try {\n+                        readyForFlushSize.addAndGet(-seg.buffer().remaining());\n+\n+                        fileIo.writeFully(seg.buffer());\n+                    }\n+                    finally {\n+                        seg.release();\n+                    }\n+                }\n+\n+                fileIo.force();\n+            } catch (IOException e) {\n+                log.error(\"Unable to write to file. Performance statistics collecting will be stopped.\", e);\n+\n+                fileWriter.shutdown();\n+\n+                stopStatistics();\n+            }\n+        }\n+\n+        /** Shutted down the worker. */\n+        private void shutdown() {\n+            isCancelled = true;\n+\n+            synchronized (this) {\n+                // Required to start writing data to the file.\n+                notify();\n+            }\n+        }\n+\n+        /** Logs warning message about small buffer size if not logged yet. */\n+        void logSmallBufferMessage() {\n+            if (smallBufLogged.compareAndSet(false, true)) {\n+                log.warning(\"The performance statistics in-memory buffer size is too small. Some operations \" +\n+                    \"will not be logged.\");\n+            }\n+        }\n+\n+        /** Logs warning message and stops collecting statistics. */\n+        void onMaxFileSizeReached() {", "originalCommit": "d860c9d0a72ab744c7fac03894d2d57b055a1001", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTEzOTIyOQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r451139229", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-07T20:58:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTU2NDMwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTU2NzczNQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449567735", "bodyText": "We should override or use existing cancel method to stop this worker.", "author": "nizhikov", "createdAt": "2020-07-03T12:51:51Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,549 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Consumer;\n+import java.util.function.IntSupplier;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.JOB;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY_READS;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TASK;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_COMMIT;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_ROLLBACK;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * U.GB;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = (int)(32 * U.MB);\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = (int)(8 * U.MB);\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Hashcodes of cached strings. */\n+    private final ConcurrentSkipListSet<Integer> cachedStrings = new ConcurrentSkipListSet<>();\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public synchronized void start() {\n+        if (enabled)\n+            return;\n+\n+        FileWriter writer = fileWriter;\n+\n+        // Writer is stopping.\n+        if (writer != null) {\n+            try {\n+                U.join(writer.runner());\n+            }\n+            catch (IgniteCheckedException e) {\n+                throw new IgniteException(\"Failed to wait for previous writer stopping.\", e);\n+            }\n+        }\n+\n+        try {\n+            File file = statisticsFile(ctx);\n+\n+            U.delete(file);\n+\n+            FileIO fileIo = fileIoFactory.create(file);\n+\n+            fileWriter = new FileWriter(ctx, fileIo, DFLT_FILE_MAX_SIZE, DFLT_BUFFER_SIZE, DFLT_FLUSH_SIZE, log);\n+\n+            new IgniteThread(fileWriter).start();\n+\n+            enabled = true;\n+\n+            log.info(\"Performance statistics writer started [file=\" + file.getAbsolutePath() + ']');\n+        }\n+        catch (IOException | IgniteCheckedException e) {\n+            log.error(\"Failed to start performance statistics writer.\", e);\n+\n+            throw new IgniteException(\"Failed to start performance statistics writer.\", e);\n+        }\n+    }\n+\n+    /** Stops collecting performance statistics. */\n+    public void stop() {\n+        synchronized (this) {\n+            if (!enabled)\n+                return;\n+\n+            enabled = false;\n+        }\n+\n+        log.info(\"Stopping performance statistics writer.\");\n+\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        if (fileWriter != null)\n+            fileWriter.shutdown();\n+    }\n+\n+    /**\n+     * @param type Operation type.\n+     * @param cacheId Cache id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     */\n+    public void cacheOperation(OperationType type, int cacheId, long startTime, long duration) {\n+        doWrite(type,\n+            () -> 4 + 8 + 8,\n+            buf -> {\n+                buf.putInt(cacheId);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param cacheIds Cache IDs.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param commited {@code True} if commited.\n+     */\n+    public void transaction(GridIntList cacheIds, long startTime, long duration, boolean commited) {\n+        doWrite(commited ? TX_COMMIT : TX_ROLLBACK,\n+            () -> 4 + cacheIds.size() * 4 + 8 + 8,\n+            buf -> {\n+                buf.putInt(cacheIds.size());\n+\n+                GridIntIterator iter = cacheIds.iterator();\n+\n+                while (iter.hasNext())\n+                    buf.putInt(iter.next());\n+\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param text Query text in case of SQL query. Cache name in case of SCAN query.\n+     * @param id Query id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param success Success flag.\n+     */\n+    public void query(GridCacheQueryType type, String text, long id, long startTime, long duration, boolean success) {\n+        boolean needWriteStr = !stringCached(text);\n+        byte[] strBytes = needWriteStr ? text.getBytes() : null;\n+\n+        doWrite(QUERY, () -> {\n+            int size = 1 + 1 + 4 + 8 + 8 + 8 + 1;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            buf.put((byte)type.ordinal());\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(text.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(id);\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.put(success ? (byte)1 : 0);\n+        });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param queryNodeId Originating node id.\n+     * @param id Query id.\n+     * @param logicalReads Number of logical reads.\n+     * @param physicalReads Number of physical reads.\n+     */\n+    public void queryReads(GridCacheQueryType type, UUID queryNodeId, long id, long logicalReads, long physicalReads) {\n+        doWrite(QUERY_READS,\n+            () -> 1 + 16 + 8 + 8 + 8,\n+            buf -> {\n+                buf.put((byte)type.ordinal());\n+                writeUuid(buf, queryNodeId);\n+                buf.putLong(id);\n+                buf.putLong(logicalReads);\n+                buf.putLong(physicalReads);\n+            });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param taskName Task name.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration.\n+     * @param affPartId Affinity partition id.\n+     */\n+    public void task(IgniteUuid sesId, String taskName, long startTime, long duration, int affPartId) {\n+        boolean needWriteStr = !stringCached(taskName);\n+        byte[] strBytes = needWriteStr ? taskName.getBytes() : null;\n+\n+        doWrite(TASK, () -> {\n+            int size = 24 + 1 + 4 + 8 + 8 + 4;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            writeIgniteUuid(buf, sesId);\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(taskName.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.putInt(affPartId);\n+        });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param queuedTime Time job spent on waiting queue.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Job execution time.\n+     * @param timedOut {@code True} if job is timed out.\n+     */\n+    public void job(IgniteUuid sesId, long queuedTime, long startTime, long duration, boolean timedOut) {\n+        doWrite(JOB,\n+            () -> 24 + 8 + 8 + 8 + 1,\n+            buf -> {\n+                writeIgniteUuid(buf, sesId);\n+                buf.putLong(queuedTime);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+                buf.put(timedOut ? (byte)1 : 0);\n+            });\n+    }\n+\n+    /**\n+     * @param op Operation type.\n+     * @param sizeSupplier Record size supplier.\n+     * @param writer Record writer.\n+     */\n+    private void doWrite(OperationType op, IntSupplier sizeSupplier, Consumer<ByteBuffer> writer) {\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        // Writer stopping.\n+        if (fileWriter == null)\n+            return;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = fileWriter.writeSegment(sizeSupplier.getAsInt() + /*type*/ 1);\n+\n+        if (seg == null) {\n+            fileWriter.logSmallBufferMessage();\n+\n+            return;\n+        }\n+\n+        // Ring buffer closed (writer stopping) or maximum size reached.\n+        if (seg.buffer() == null) {\n+            seg.release();\n+\n+            if (!fileWriter.isCancelled())\n+                fileWriter.onMaxFileSizeReached();\n+\n+            return;\n+        }\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)op.ordinal());\n+\n+        writer.accept(buf);\n+\n+        seg.release();\n+    }\n+\n+    /** @return {@code True} if string is cached. {@code False} if need write string.  */\n+    private boolean stringCached(String str) {\n+        boolean cached = cachedStrings.contains(str.hashCode());\n+\n+        if (!cached)\n+            cachedStrings.add(str.hashCode());\n+\n+        return cached;\n+    }\n+\n+    /** @return Performance statistics file. */\n+    private static File statisticsFile(GridKernalContext ctx) throws IgniteCheckedException {\n+        String igniteWorkDir = U.workDirectory(ctx.config().getWorkDirectory(), ctx.config().getIgniteHome());\n+\n+        File fileDir = U.resolveWorkDirectory(igniteWorkDir, PERFORMANCE_STAT_DIR, false);\n+\n+        return new File(fileDir, \"node-\" + ctx.localNodeId() + \".prf\");\n+    }\n+\n+    /** Writes {@link UUID} to buffer. */\n+    private static void writeUuid(ByteBuffer buf, UUID uuid) {\n+        buf.putLong(uuid.getMostSignificantBits());\n+        buf.putLong(uuid.getLeastSignificantBits());\n+    }\n+\n+    /** Writes {@link IgniteUuid} to buffer. */\n+    private static void writeIgniteUuid(ByteBuffer buf, IgniteUuid uuid) {\n+        buf.putLong(uuid.globalId().getMostSignificantBits());\n+        buf.putLong(uuid.globalId().getLeastSignificantBits());\n+        buf.putLong(uuid.localId());\n+    }\n+\n+    /** @return {@code True} if collecting performance statistics enabled. */\n+    public boolean enabled() {\n+        return enabled;\n+    }\n+\n+    /** Worker to write to performance statistics file. */\n+    private class FileWriter extends GridWorker {\n+        /** Performance statistics file I/O. */\n+        private final FileIO fileIo;\n+\n+        /** File write buffer. */\n+        private final SegmentedRingByteBuffer ringByteBuffer;\n+\n+        /** Minimal batch size to flush in bytes. */\n+        private final int flushBatchSize;\n+\n+        /** Size of ready for flushing bytes. */\n+        private final AtomicInteger readyForFlushSize = new AtomicInteger();\n+\n+        /** {@code True} if the small buffer warning message logged. */\n+        private final AtomicBoolean smallBufLogged = new AtomicBoolean();\n+\n+        /** {@code True} if worker stopped due to maximum file size reached. */\n+        private final AtomicBoolean stopByMaxSize = new AtomicBoolean();\n+\n+        /**\n+         * @param ctx Kernal context.\n+         * @param fileIo Performance statistics file I/O.\n+         * @param maxFileSize Maximum file size in bytes.\n+         * @param bufferSize Off heap buffer size in bytes.\n+         * @param flushBatchSize Minimal batch size to flush in bytes.\n+         * @param log Logger.\n+         */\n+        FileWriter(GridKernalContext ctx, FileIO fileIo, long maxFileSize, int bufferSize, int flushBatchSize,\n+            IgniteLogger log) {\n+            super(ctx.igniteInstanceName(), \"performance-statistics-writer%\" + ctx.igniteInstanceName(), log);\n+\n+            this.fileIo = fileIo;\n+            this.flushBatchSize = flushBatchSize;\n+\n+            ringByteBuffer = new SegmentedRingByteBuffer(bufferSize, maxFileSize, BufferMode.DIRECT);\n+\n+            ringByteBuffer.init(0);\n+        }\n+\n+        /** {@inheritDoc} */\n+        @Override protected void body() throws InterruptedException, IgniteInterruptedCheckedException {\n+            try {\n+                while (!isCancelled()) {\n+                    blockingSectionBegin();\n+\n+                    try {\n+                        synchronized (this) {\n+                            while (readyForFlushSize.get() < flushBatchSize && !isCancelled())\n+                                wait();\n+                        }\n+                    }\n+                    finally {\n+                        blockingSectionEnd();\n+                    }\n+\n+                    flushBuffer();\n+                }\n+            }\n+            finally {\n+                fileWriter = null;\n+\n+                ringByteBuffer.close();\n+\n+                // Make sure that all producers released their buffers to safe deallocate memory.\n+                flushBuffer();\n+\n+                ringByteBuffer.free();\n+\n+                U.closeQuiet(fileIo);\n+\n+                cachedStrings.clear();\n+\n+                log.info(\"Performance statistics writer stopped.\");\n+            }\n+        }\n+\n+        /** @return Write segment.*/\n+        SegmentedRingByteBuffer.WriteSegment writeSegment(int size) {\n+            SegmentedRingByteBuffer.WriteSegment seg = ringByteBuffer.offer(size);\n+\n+            if (seg != null) {\n+                int readySize = readyForFlushSize.addAndGet(size);\n+\n+                if (readySize >= DFLT_FLUSH_SIZE) {\n+                    synchronized (this) {\n+                        // Required to start writing data to the file.\n+                        notify();\n+                    }\n+                }\n+            }\n+\n+            return seg;\n+        }\n+\n+        /** Flushes to disk available bytes from the ring buffer. */\n+        private void flushBuffer() {\n+            List<SegmentedRingByteBuffer.ReadSegment> segs = ringByteBuffer.poll();\n+\n+            if (segs == null)\n+                return;\n+\n+            try {\n+                for (int i = 0; i < segs.size(); i++) {\n+                    updateHeartbeat();\n+\n+                    SegmentedRingByteBuffer.ReadSegment seg = segs.get(i);\n+\n+                    try {\n+                        readyForFlushSize.addAndGet(-seg.buffer().remaining());\n+\n+                        fileIo.writeFully(seg.buffer());\n+                    }\n+                    finally {\n+                        seg.release();\n+                    }\n+                }\n+\n+                fileIo.force();\n+            } catch (IOException e) {\n+                log.error(\"Unable to write to file. Performance statistics collecting will be stopped.\", e);\n+\n+                fileWriter.shutdown();\n+\n+                stopStatistics();\n+            }\n+        }\n+\n+        /** Shutted down the worker. */\n+        private void shutdown() {", "originalCommit": "d860c9d0a72ab744c7fac03894d2d57b055a1001", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDAwMzg4Mw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r450003883", "bodyText": "Yes, existing cancel method can be used", "author": "NSAmelchev", "createdAt": "2020-07-06T06:17:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTU2NzczNQ=="}], "type": "inlineReview"}, {"oid": "a595a08b976a6f3fabea1d4b54078331d37f1206", "url": "https://github.com/apache/ignite/commit/a595a08b976a6f3fabea1d4b54078331d37f1206", "message": "Use Worker#cancel", "committedDate": "2020-07-05T11:44:13Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDY4Njg3Nw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r450686877", "bodyText": "Let's use explicit list of the operation instead of range here.", "author": "nizhikov", "createdAt": "2020-07-07T08:13:53Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/OperationType.java", "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.util.EnumSet;\n+\n+/**\n+ * Operation type.\n+ */\n+public enum OperationType {\n+    /** Cache get. */\n+    CACHE_GET,\n+\n+    /** Cache put. */\n+    CACHE_PUT,\n+\n+    /** Cache remove. */\n+    CACHE_REMOVE,\n+\n+    /** Cache get and put. */\n+    CACHE_GET_AND_PUT,\n+\n+    /** Cache get and remove. */\n+    CACHE_GET_AND_REMOVE,\n+\n+    /** Cache invoke. */\n+    CACHE_INVOKE,\n+\n+    /** Cache lock. */\n+    CACHE_LOCK,\n+\n+    /** Cache get all. */\n+    CACHE_GET_ALL,\n+\n+    /** Cache put all. */\n+    CACHE_PUT_ALL,\n+\n+    /** Cache remove all. */\n+    CACHE_REMOVE_ALL,\n+\n+    /** Cache invoke all. */\n+    CACHE_INVOKE_ALL,\n+\n+    /** Transaction commit. */\n+    TX_COMMIT,\n+\n+    /** Transaction rollback. */\n+    TX_ROLLBACK,\n+\n+    /** Query. */\n+    QUERY,\n+\n+    /** Query reads. */\n+    QUERY_READS,\n+\n+    /** Task. */\n+    TASK,\n+\n+    /** Job. */\n+    JOB;\n+\n+    /** Cache operations. */\n+    public static final EnumSet<OperationType> CACHE_OPS = EnumSet.range(CACHE_GET, CACHE_INVOKE_ALL);", "originalCommit": "a595a08b976a6f3fabea1d4b54078331d37f1206", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDcwMzAwOQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r450703009", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-07T08:41:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDY4Njg3Nw=="}], "type": "inlineReview"}, {"oid": "7a9f63ef5ed1c27f4b1ad36e14baeb51ea09a072", "url": "https://github.com/apache/ignite/commit/7a9f63ef5ed1c27f4b1ad36e14baeb51ea09a072", "message": "Explicit enum list", "committedDate": "2020-07-07T08:40:53Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDc4NTMxNw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r450785317", "bodyText": "Let's use MB constant here.", "author": "nizhikov", "createdAt": "2020-07-07T11:08:57Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsReader.java", "diffHunk": "@@ -0,0 +1,375 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.FileVisitOption;\n+import java.nio.file.FileVisitResult;\n+import java.nio.file.Path;\n+import java.nio.file.SimpleFileVisitor;\n+import java.nio.file.attribute.BasicFileAttributes;\n+import java.util.Collections;\n+import java.util.EnumSet;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.GridUnsafe;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.jetbrains.annotations.Nullable;\n+\n+import static java.nio.ByteBuffer.allocateDirect;\n+import static java.nio.ByteOrder.nativeOrder;\n+import static java.nio.file.Files.walkFileTree;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.JOB;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY_READS;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TASK;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_COMMIT;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.cacheOperation;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.transactionOperation;\n+\n+/**\n+ * Walker over the performance statistics file.\n+ *\n+ * @see FilePerformanceStatisticsWriter\n+ */\n+public class FilePerformanceStatisticsReader {\n+    /** File read buffer size. */\n+    private static final int READ_BUFFER_SIZE = 8 * 1024 * 1024;", "originalCommit": "7a9f63ef5ed1c27f4b1ad36e14baeb51ea09a072", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDg5MzA0Mw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r450893043", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-07T14:08:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDc4NTMxNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDc4ODg4NA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r450788884", "bodyText": "Let's remove those 3 parameters, because we only use constants for it, for now.", "author": "nizhikov", "createdAt": "2020-07-07T11:16:22Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,539 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Consumer;\n+import java.util.function.IntSupplier;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.JOB;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY_READS;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TASK;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_COMMIT;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_ROLLBACK;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * U.GB;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = (int)(32 * U.MB);\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = (int)(8 * U.MB);\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Hashcodes of cached strings. */\n+    private final ConcurrentSkipListSet<Integer> cachedStrings = new ConcurrentSkipListSet<>();\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public synchronized void start() {\n+        if (enabled)\n+            return;\n+\n+        FileWriter writer = fileWriter;\n+\n+        // Writer is stopping.\n+        if (writer != null) {\n+            try {\n+                U.join(writer.runner());\n+            }\n+            catch (IgniteCheckedException e) {\n+                throw new IgniteException(\"Failed to wait for previous writer stopping.\", e);\n+            }\n+        }\n+\n+        try {\n+            File file = statisticsFile(ctx);\n+\n+            U.delete(file);\n+\n+            FileIO fileIo = fileIoFactory.create(file);\n+\n+            fileWriter = new FileWriter(ctx, fileIo, DFLT_FILE_MAX_SIZE, DFLT_BUFFER_SIZE, DFLT_FLUSH_SIZE, log);\n+\n+            new IgniteThread(fileWriter).start();\n+\n+            enabled = true;\n+\n+            log.info(\"Performance statistics writer started [file=\" + file.getAbsolutePath() + ']');\n+        }\n+        catch (IOException | IgniteCheckedException e) {\n+            log.error(\"Failed to start performance statistics writer.\", e);\n+\n+            throw new IgniteException(\"Failed to start performance statistics writer.\", e);\n+        }\n+    }\n+\n+    /** Stops collecting performance statistics. */\n+    public void stop() {\n+        synchronized (this) {\n+            if (!enabled)\n+                return;\n+\n+            enabled = false;\n+        }\n+\n+        log.info(\"Stopping performance statistics writer.\");\n+\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        if (fileWriter != null)\n+            fileWriter.cancel();\n+    }\n+\n+    /**\n+     * @param type Operation type.\n+     * @param cacheId Cache id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     */\n+    public void cacheOperation(OperationType type, int cacheId, long startTime, long duration) {\n+        doWrite(type,\n+            () -> 4 + 8 + 8,\n+            buf -> {\n+                buf.putInt(cacheId);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param cacheIds Cache IDs.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param commited {@code True} if commited.\n+     */\n+    public void transaction(GridIntList cacheIds, long startTime, long duration, boolean commited) {\n+        doWrite(commited ? TX_COMMIT : TX_ROLLBACK,\n+            () -> 4 + cacheIds.size() * 4 + 8 + 8,\n+            buf -> {\n+                buf.putInt(cacheIds.size());\n+\n+                GridIntIterator iter = cacheIds.iterator();\n+\n+                while (iter.hasNext())\n+                    buf.putInt(iter.next());\n+\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param text Query text in case of SQL query. Cache name in case of SCAN query.\n+     * @param id Query id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param success Success flag.\n+     */\n+    public void query(GridCacheQueryType type, String text, long id, long startTime, long duration, boolean success) {\n+        boolean needWriteStr = !stringCached(text);\n+        byte[] strBytes = needWriteStr ? text.getBytes() : null;\n+\n+        doWrite(QUERY, () -> {\n+            int size = 1 + 1 + 4 + 8 + 8 + 8 + 1;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            buf.put((byte)type.ordinal());\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(text.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(id);\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.put(success ? (byte)1 : 0);\n+        });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param queryNodeId Originating node id.\n+     * @param id Query id.\n+     * @param logicalReads Number of logical reads.\n+     * @param physicalReads Number of physical reads.\n+     */\n+    public void queryReads(GridCacheQueryType type, UUID queryNodeId, long id, long logicalReads, long physicalReads) {\n+        doWrite(QUERY_READS,\n+            () -> 1 + 16 + 8 + 8 + 8,\n+            buf -> {\n+                buf.put((byte)type.ordinal());\n+                writeUuid(buf, queryNodeId);\n+                buf.putLong(id);\n+                buf.putLong(logicalReads);\n+                buf.putLong(physicalReads);\n+            });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param taskName Task name.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration.\n+     * @param affPartId Affinity partition id.\n+     */\n+    public void task(IgniteUuid sesId, String taskName, long startTime, long duration, int affPartId) {\n+        boolean needWriteStr = !stringCached(taskName);\n+        byte[] strBytes = needWriteStr ? taskName.getBytes() : null;\n+\n+        doWrite(TASK, () -> {\n+            int size = 24 + 1 + 4 + 8 + 8 + 4;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            writeIgniteUuid(buf, sesId);\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(taskName.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.putInt(affPartId);\n+        });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param queuedTime Time job spent on waiting queue.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Job execution time.\n+     * @param timedOut {@code True} if job is timed out.\n+     */\n+    public void job(IgniteUuid sesId, long queuedTime, long startTime, long duration, boolean timedOut) {\n+        doWrite(JOB,\n+            () -> 24 + 8 + 8 + 8 + 1,\n+            buf -> {\n+                writeIgniteUuid(buf, sesId);\n+                buf.putLong(queuedTime);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+                buf.put(timedOut ? (byte)1 : 0);\n+            });\n+    }\n+\n+    /**\n+     * @param op Operation type.\n+     * @param sizeSupplier Record size supplier.\n+     * @param writer Record writer.\n+     */\n+    private void doWrite(OperationType op, IntSupplier sizeSupplier, Consumer<ByteBuffer> writer) {\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        // Writer stopping.\n+        if (fileWriter == null)\n+            return;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = fileWriter.writeSegment(sizeSupplier.getAsInt() + /*type*/ 1);\n+\n+        if (seg == null) {\n+            fileWriter.logSmallBufferMessage();\n+\n+            return;\n+        }\n+\n+        // Ring buffer closed (writer stopping) or maximum size reached.\n+        if (seg.buffer() == null) {\n+            seg.release();\n+\n+            if (!fileWriter.isCancelled())\n+                fileWriter.onMaxFileSizeReached();\n+\n+            return;\n+        }\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)op.ordinal());\n+\n+        writer.accept(buf);\n+\n+        seg.release();\n+    }\n+\n+    /** @return {@code True} if string is cached. {@code False} if need write string.  */\n+    private boolean stringCached(String str) {\n+        boolean cached = cachedStrings.contains(str.hashCode());\n+\n+        if (!cached)\n+            cachedStrings.add(str.hashCode());\n+\n+        return cached;\n+    }\n+\n+    /** @return Performance statistics file. */\n+    private static File statisticsFile(GridKernalContext ctx) throws IgniteCheckedException {\n+        String igniteWorkDir = U.workDirectory(ctx.config().getWorkDirectory(), ctx.config().getIgniteHome());\n+\n+        File fileDir = U.resolveWorkDirectory(igniteWorkDir, PERFORMANCE_STAT_DIR, false);\n+\n+        return new File(fileDir, \"node-\" + ctx.localNodeId() + \".prf\");\n+    }\n+\n+    /** Writes {@link UUID} to buffer. */\n+    private static void writeUuid(ByteBuffer buf, UUID uuid) {\n+        buf.putLong(uuid.getMostSignificantBits());\n+        buf.putLong(uuid.getLeastSignificantBits());\n+    }\n+\n+    /** Writes {@link IgniteUuid} to buffer. */\n+    private static void writeIgniteUuid(ByteBuffer buf, IgniteUuid uuid) {\n+        buf.putLong(uuid.globalId().getMostSignificantBits());\n+        buf.putLong(uuid.globalId().getLeastSignificantBits());\n+        buf.putLong(uuid.localId());\n+    }\n+\n+    /** @return {@code True} if collecting performance statistics enabled. */\n+    public boolean enabled() {\n+        return enabled;\n+    }\n+\n+    /** Worker to write to performance statistics file. */\n+    private class FileWriter extends GridWorker {\n+        /** Performance statistics file I/O. */\n+        private final FileIO fileIo;\n+\n+        /** File write buffer. */\n+        private final SegmentedRingByteBuffer ringByteBuffer;\n+\n+        /** Minimal batch size to flush in bytes. */\n+        private final int flushBatchSize;\n+\n+        /** Size of ready for flushing bytes. */\n+        private final AtomicInteger readyForFlushSize = new AtomicInteger();\n+\n+        /** {@code True} if the small buffer warning message logged. */\n+        private final AtomicBoolean smallBufLogged = new AtomicBoolean();\n+\n+        /** {@code True} if worker stopped due to maximum file size reached. */\n+        private final AtomicBoolean stopByMaxSize = new AtomicBoolean();\n+\n+        /**\n+         * @param ctx Kernal context.\n+         * @param fileIo Performance statistics file I/O.\n+         * @param maxFileSize Maximum file size in bytes.", "originalCommit": "7a9f63ef5ed1c27f4b1ad36e14baeb51ea09a072", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTEzOTI2NQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r451139265", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-07T20:58:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDc4ODg4NA=="}], "type": "inlineReview"}, {"oid": "862862df42e94ef723a01776b8d13ba0b8454e8e", "url": "https://github.com/apache/ignite/commit/862862df42e94ef723a01776b8d13ba0b8454e8e", "message": "Use U.MB + code review fixes", "committedDate": "2020-07-07T11:54:56Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDgxMDUyMA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r450810520", "bodyText": "We can use foreach loop here.", "author": "nizhikov", "createdAt": "2020-07-07T11:59:48Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,539 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Consumer;\n+import java.util.function.IntSupplier;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.JOB;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY_READS;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TASK;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_COMMIT;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_ROLLBACK;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * U.GB;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = (int)(32 * U.MB);\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = (int)(8 * U.MB);\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Hashcodes of cached strings. */\n+    private final ConcurrentSkipListSet<Integer> cachedStrings = new ConcurrentSkipListSet<>();\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public synchronized void start() {\n+        if (enabled)\n+            return;\n+\n+        FileWriter writer = fileWriter;\n+\n+        // Writer is stopping.\n+        if (writer != null) {\n+            try {\n+                U.join(writer.runner());\n+            }\n+            catch (IgniteCheckedException e) {\n+                throw new IgniteException(\"Failed to wait for previous writer stopping.\", e);\n+            }\n+        }\n+\n+        try {\n+            File file = statisticsFile(ctx);\n+\n+            U.delete(file);\n+\n+            FileIO fileIo = fileIoFactory.create(file);\n+\n+            fileWriter = new FileWriter(ctx, fileIo, DFLT_FILE_MAX_SIZE, DFLT_BUFFER_SIZE, DFLT_FLUSH_SIZE, log);\n+\n+            new IgniteThread(fileWriter).start();\n+\n+            enabled = true;\n+\n+            log.info(\"Performance statistics writer started [file=\" + file.getAbsolutePath() + ']');\n+        }\n+        catch (IOException | IgniteCheckedException e) {\n+            log.error(\"Failed to start performance statistics writer.\", e);\n+\n+            throw new IgniteException(\"Failed to start performance statistics writer.\", e);\n+        }\n+    }\n+\n+    /** Stops collecting performance statistics. */\n+    public void stop() {\n+        synchronized (this) {\n+            if (!enabled)\n+                return;\n+\n+            enabled = false;\n+        }\n+\n+        log.info(\"Stopping performance statistics writer.\");\n+\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        if (fileWriter != null)\n+            fileWriter.cancel();\n+    }\n+\n+    /**\n+     * @param type Operation type.\n+     * @param cacheId Cache id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     */\n+    public void cacheOperation(OperationType type, int cacheId, long startTime, long duration) {\n+        doWrite(type,\n+            () -> 4 + 8 + 8,\n+            buf -> {\n+                buf.putInt(cacheId);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param cacheIds Cache IDs.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param commited {@code True} if commited.\n+     */\n+    public void transaction(GridIntList cacheIds, long startTime, long duration, boolean commited) {\n+        doWrite(commited ? TX_COMMIT : TX_ROLLBACK,\n+            () -> 4 + cacheIds.size() * 4 + 8 + 8,\n+            buf -> {\n+                buf.putInt(cacheIds.size());\n+\n+                GridIntIterator iter = cacheIds.iterator();\n+\n+                while (iter.hasNext())\n+                    buf.putInt(iter.next());\n+\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param text Query text in case of SQL query. Cache name in case of SCAN query.\n+     * @param id Query id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param success Success flag.\n+     */\n+    public void query(GridCacheQueryType type, String text, long id, long startTime, long duration, boolean success) {\n+        boolean needWriteStr = !stringCached(text);\n+        byte[] strBytes = needWriteStr ? text.getBytes() : null;\n+\n+        doWrite(QUERY, () -> {\n+            int size = 1 + 1 + 4 + 8 + 8 + 8 + 1;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            buf.put((byte)type.ordinal());\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(text.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(id);\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.put(success ? (byte)1 : 0);\n+        });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param queryNodeId Originating node id.\n+     * @param id Query id.\n+     * @param logicalReads Number of logical reads.\n+     * @param physicalReads Number of physical reads.\n+     */\n+    public void queryReads(GridCacheQueryType type, UUID queryNodeId, long id, long logicalReads, long physicalReads) {\n+        doWrite(QUERY_READS,\n+            () -> 1 + 16 + 8 + 8 + 8,\n+            buf -> {\n+                buf.put((byte)type.ordinal());\n+                writeUuid(buf, queryNodeId);\n+                buf.putLong(id);\n+                buf.putLong(logicalReads);\n+                buf.putLong(physicalReads);\n+            });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param taskName Task name.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration.\n+     * @param affPartId Affinity partition id.\n+     */\n+    public void task(IgniteUuid sesId, String taskName, long startTime, long duration, int affPartId) {\n+        boolean needWriteStr = !stringCached(taskName);\n+        byte[] strBytes = needWriteStr ? taskName.getBytes() : null;\n+\n+        doWrite(TASK, () -> {\n+            int size = 24 + 1 + 4 + 8 + 8 + 4;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            writeIgniteUuid(buf, sesId);\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(taskName.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.putInt(affPartId);\n+        });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param queuedTime Time job spent on waiting queue.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Job execution time.\n+     * @param timedOut {@code True} if job is timed out.\n+     */\n+    public void job(IgniteUuid sesId, long queuedTime, long startTime, long duration, boolean timedOut) {\n+        doWrite(JOB,\n+            () -> 24 + 8 + 8 + 8 + 1,\n+            buf -> {\n+                writeIgniteUuid(buf, sesId);\n+                buf.putLong(queuedTime);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+                buf.put(timedOut ? (byte)1 : 0);\n+            });\n+    }\n+\n+    /**\n+     * @param op Operation type.\n+     * @param sizeSupplier Record size supplier.\n+     * @param writer Record writer.\n+     */\n+    private void doWrite(OperationType op, IntSupplier sizeSupplier, Consumer<ByteBuffer> writer) {\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        // Writer stopping.\n+        if (fileWriter == null)\n+            return;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = fileWriter.writeSegment(sizeSupplier.getAsInt() + /*type*/ 1);\n+\n+        if (seg == null) {\n+            fileWriter.logSmallBufferMessage();\n+\n+            return;\n+        }\n+\n+        // Ring buffer closed (writer stopping) or maximum size reached.\n+        if (seg.buffer() == null) {\n+            seg.release();\n+\n+            if (!fileWriter.isCancelled())\n+                fileWriter.onMaxFileSizeReached();\n+\n+            return;\n+        }\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)op.ordinal());\n+\n+        writer.accept(buf);\n+\n+        seg.release();\n+    }\n+\n+    /** @return {@code True} if string is cached. {@code False} if need write string.  */\n+    private boolean stringCached(String str) {\n+        boolean cached = cachedStrings.contains(str.hashCode());\n+\n+        if (!cached)\n+            cachedStrings.add(str.hashCode());\n+\n+        return cached;\n+    }\n+\n+    /** @return Performance statistics file. */\n+    private static File statisticsFile(GridKernalContext ctx) throws IgniteCheckedException {\n+        String igniteWorkDir = U.workDirectory(ctx.config().getWorkDirectory(), ctx.config().getIgniteHome());\n+\n+        File fileDir = U.resolveWorkDirectory(igniteWorkDir, PERFORMANCE_STAT_DIR, false);\n+\n+        return new File(fileDir, \"node-\" + ctx.localNodeId() + \".prf\");\n+    }\n+\n+    /** Writes {@link UUID} to buffer. */\n+    private static void writeUuid(ByteBuffer buf, UUID uuid) {\n+        buf.putLong(uuid.getMostSignificantBits());\n+        buf.putLong(uuid.getLeastSignificantBits());\n+    }\n+\n+    /** Writes {@link IgniteUuid} to buffer. */\n+    private static void writeIgniteUuid(ByteBuffer buf, IgniteUuid uuid) {\n+        buf.putLong(uuid.globalId().getMostSignificantBits());\n+        buf.putLong(uuid.globalId().getLeastSignificantBits());\n+        buf.putLong(uuid.localId());\n+    }\n+\n+    /** @return {@code True} if collecting performance statistics enabled. */\n+    public boolean enabled() {\n+        return enabled;\n+    }\n+\n+    /** Worker to write to performance statistics file. */\n+    private class FileWriter extends GridWorker {\n+        /** Performance statistics file I/O. */\n+        private final FileIO fileIo;\n+\n+        /** File write buffer. */\n+        private final SegmentedRingByteBuffer ringByteBuffer;\n+\n+        /** Minimal batch size to flush in bytes. */\n+        private final int flushBatchSize;\n+\n+        /** Size of ready for flushing bytes. */\n+        private final AtomicInteger readyForFlushSize = new AtomicInteger();\n+\n+        /** {@code True} if the small buffer warning message logged. */\n+        private final AtomicBoolean smallBufLogged = new AtomicBoolean();\n+\n+        /** {@code True} if worker stopped due to maximum file size reached. */\n+        private final AtomicBoolean stopByMaxSize = new AtomicBoolean();\n+\n+        /**\n+         * @param ctx Kernal context.\n+         * @param fileIo Performance statistics file I/O.\n+         * @param maxFileSize Maximum file size in bytes.\n+         * @param bufferSize Off heap buffer size in bytes.\n+         * @param flushBatchSize Minimal batch size to flush in bytes.\n+         * @param log Logger.\n+         */\n+        FileWriter(GridKernalContext ctx, FileIO fileIo, long maxFileSize, int bufferSize, int flushBatchSize,\n+            IgniteLogger log) {\n+            super(ctx.igniteInstanceName(), \"performance-statistics-writer%\" + ctx.igniteInstanceName(), log);\n+\n+            this.fileIo = fileIo;\n+            this.flushBatchSize = flushBatchSize;\n+\n+            ringByteBuffer = new SegmentedRingByteBuffer(bufferSize, maxFileSize, BufferMode.DIRECT);\n+\n+            ringByteBuffer.init(0);\n+        }\n+\n+        /** {@inheritDoc} */\n+        @Override protected void body() throws InterruptedException, IgniteInterruptedCheckedException {\n+            try {\n+                while (!isCancelled()) {\n+                    blockingSectionBegin();\n+\n+                    try {\n+                        synchronized (this) {\n+                            while (readyForFlushSize.get() < flushBatchSize && !isCancelled())\n+                                wait();\n+                        }\n+                    }\n+                    finally {\n+                        blockingSectionEnd();\n+                    }\n+\n+                    flushBuffer();\n+                }\n+            }\n+            finally {\n+                fileWriter = null;\n+\n+                ringByteBuffer.close();\n+\n+                // Make sure that all producers released their buffers to safe deallocate memory.\n+                flushBuffer();\n+\n+                ringByteBuffer.free();\n+\n+                U.closeQuiet(fileIo);\n+\n+                cachedStrings.clear();\n+\n+                log.info(\"Performance statistics writer stopped.\");\n+            }\n+        }\n+\n+        /** @return Write segment.*/\n+        SegmentedRingByteBuffer.WriteSegment writeSegment(int size) {\n+            SegmentedRingByteBuffer.WriteSegment seg = ringByteBuffer.offer(size);\n+\n+            if (seg != null) {\n+                int readySize = readyForFlushSize.addAndGet(size);\n+\n+                if (readySize >= DFLT_FLUSH_SIZE) {\n+                    synchronized (this) {\n+                        // Required to start writing data to the file.\n+                        notify();\n+                    }\n+                }\n+            }\n+\n+            return seg;\n+        }\n+\n+        /** Flushes to disk available bytes from the ring buffer. */\n+        private void flushBuffer() {\n+            List<SegmentedRingByteBuffer.ReadSegment> segs = ringByteBuffer.poll();\n+\n+            if (segs == null)\n+                return;\n+\n+            try {\n+                for (int i = 0; i < segs.size(); i++) {", "originalCommit": "7a9f63ef5ed1c27f4b1ad36e14baeb51ea09a072", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTEzOTI4MQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r451139281", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-07T20:58:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDgxMDUyMA=="}], "type": "inlineReview"}, {"oid": "65bbb89e8de96a223c6034cdac736174fa27a871", "url": "https://github.com/apache/ignite/commit/65bbb89e8de96a223c6034cdac736174fa27a871", "message": "Move ring buffer", "committedDate": "2020-07-07T14:06:19Z", "type": "commit"}, {"oid": "2e602a0d2726a4696b54f72c06a8ea810867e036", "url": "https://github.com/apache/ignite/commit/2e602a0d2726a4696b54f72c06a8ea810867e036", "message": "Fix tests", "committedDate": "2020-07-07T20:56:45Z", "type": "commit"}, {"oid": "513495bdee11a3e024a6a5efa1363b95be552511", "url": "https://github.com/apache/ignite/commit/513495bdee11a3e024a6a5efa1363b95be552511", "message": "Use foreach loop", "committedDate": "2020-07-07T20:57:53Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQ3NDM0NA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r451474344", "bodyText": "Let's append to the file if it exists.\nIt seems all we need to do is to remove this line.\nWe need a ticket to provide clear command, also.", "author": "nizhikov", "createdAt": "2020-07-08T11:34:13Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,517 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Consumer;\n+import java.util.function.IntSupplier;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.JOB;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY_READS;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TASK;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_COMMIT;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_ROLLBACK;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * U.GB;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = (int)(32 * U.MB);\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = (int)(8 * U.MB);\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Performance statistics file I/O. */\n+    @Nullable private volatile FileIO fileIo;\n+\n+    /** File write buffer. */\n+    @Nullable private volatile SegmentedRingByteBuffer ringByteBuffer;\n+\n+    /** Size of ready for flushing bytes. */\n+    private final AtomicInteger readyForFlushSize = new AtomicInteger();\n+\n+    /** {@code True} if the small buffer warning message logged. */\n+    private final AtomicBoolean smallBufLogged = new AtomicBoolean();\n+\n+    /** {@code True} if worker stopped due to maximum file size reached. */\n+    private final AtomicBoolean stopByMaxSize = new AtomicBoolean();\n+\n+    /** Hashcodes of cached strings. */\n+    private final ConcurrentSkipListSet<Integer> cachedStrings = new ConcurrentSkipListSet<>();\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public void start() {\n+        synchronized (this) {\n+            if (enabled)\n+                return;\n+\n+            enabled = true;\n+\n+            try {\n+                File file = statisticsFile(ctx);\n+\n+                U.delete(file);", "originalCommit": "513495bdee11a3e024a6a5efa1363b95be552511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQ4NDQyNA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r451484424", "bodyText": "The previous file can be closed during writing records. So the last record can be written not fully. It may lead to the case when the file can not be read.", "author": "NSAmelchev", "createdAt": "2020-07-08T11:54:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQ3NDM0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQ3NzQwNg==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r451477406", "bodyText": "It seems we can just use regular cancel implementation if we will catch InterruptedException and handle it accordingly.", "author": "nizhikov", "createdAt": "2020-07-08T11:40:23Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,517 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Consumer;\n+import java.util.function.IntSupplier;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.JOB;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY_READS;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TASK;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_COMMIT;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_ROLLBACK;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * U.GB;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = (int)(32 * U.MB);\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = (int)(8 * U.MB);\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Performance statistics file I/O. */\n+    @Nullable private volatile FileIO fileIo;\n+\n+    /** File write buffer. */\n+    @Nullable private volatile SegmentedRingByteBuffer ringByteBuffer;\n+\n+    /** Size of ready for flushing bytes. */\n+    private final AtomicInteger readyForFlushSize = new AtomicInteger();\n+\n+    /** {@code True} if the small buffer warning message logged. */\n+    private final AtomicBoolean smallBufLogged = new AtomicBoolean();\n+\n+    /** {@code True} if worker stopped due to maximum file size reached. */\n+    private final AtomicBoolean stopByMaxSize = new AtomicBoolean();\n+\n+    /** Hashcodes of cached strings. */\n+    private final ConcurrentSkipListSet<Integer> cachedStrings = new ConcurrentSkipListSet<>();\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public void start() {\n+        synchronized (this) {\n+            if (enabled)\n+                return;\n+\n+            enabled = true;\n+\n+            try {\n+                File file = statisticsFile(ctx);\n+\n+                U.delete(file);\n+\n+                fileIo = fileIoFactory.create(file);\n+\n+                ringByteBuffer = new SegmentedRingByteBuffer(DFLT_BUFFER_SIZE, DFLT_FILE_MAX_SIZE,\n+                    SegmentedRingByteBuffer.BufferMode.DIRECT);\n+\n+                ringByteBuffer.init(0);\n+\n+                fileWriter = new FileWriter(ctx, log);\n+\n+                new IgniteThread(fileWriter).start();\n+\n+                log.info(\"Performance statistics writer started [file=\" + file.getAbsolutePath() + ']');\n+            }\n+            catch (IOException | IgniteCheckedException e) {\n+                log.error(\"Failed to start performance statistics writer.\", e);\n+\n+                stopStatistics();\n+\n+                throw new IgniteException(\"Failed to start performance statistics writer.\", e);\n+            }\n+        }\n+    }\n+\n+    /** Stops collecting performance statistics. */\n+    public void stop() {\n+        synchronized (this) {\n+            if (!enabled)\n+                return;\n+\n+            enabled = false;\n+\n+            FileWriter fileWriter = this.fileWriter;\n+\n+            SegmentedRingByteBuffer buf = ringByteBuffer;\n+\n+            // Stop write new data.\n+            if (buf != null)\n+                buf.close();\n+\n+            // Make sure that all buffer's producers released to safe deallocate memory.\n+            if (fileWriter != null)\n+                U.awaitForWorkersStop(Collections.singleton(fileWriter), true, log);\n+\n+            if (buf != null)\n+                buf.free();\n+\n+            U.closeQuiet(fileIo);\n+\n+            readyForFlushSize.set(0);\n+            smallBufLogged.set(false);\n+            stopByMaxSize.set(false);\n+            cachedStrings.clear();\n+\n+            log.info(\"Performance statistics writer stopped.\");\n+        }\n+    }\n+\n+    /**\n+     * @param type Operation type.\n+     * @param cacheId Cache id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     */\n+    public void cacheOperation(OperationType type, int cacheId, long startTime, long duration) {\n+        doWrite(type,\n+            () -> 4 + 8 + 8,\n+            buf -> {\n+                buf.putInt(cacheId);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param cacheIds Cache IDs.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param commited {@code True} if commited.\n+     */\n+    public void transaction(GridIntList cacheIds, long startTime, long duration, boolean commited) {\n+        doWrite(commited ? TX_COMMIT : TX_ROLLBACK,\n+            () -> 4 + cacheIds.size() * 4 + 8 + 8,\n+            buf -> {\n+                buf.putInt(cacheIds.size());\n+\n+                GridIntIterator iter = cacheIds.iterator();\n+\n+                while (iter.hasNext())\n+                    buf.putInt(iter.next());\n+\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param text Query text in case of SQL query. Cache name in case of SCAN query.\n+     * @param id Query id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param success Success flag.\n+     */\n+    public void query(GridCacheQueryType type, String text, long id, long startTime, long duration, boolean success) {\n+        boolean needWriteStr = !stringCached(text);\n+        byte[] strBytes = needWriteStr ? text.getBytes() : null;\n+\n+        doWrite(QUERY, () -> {\n+            int size = 1 + 1 + 4 + 8 + 8 + 8 + 1;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            buf.put((byte)type.ordinal());\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(text.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(id);\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.put(success ? (byte)1 : 0);\n+        });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param queryNodeId Originating node id.\n+     * @param id Query id.\n+     * @param logicalReads Number of logical reads.\n+     * @param physicalReads Number of physical reads.\n+     */\n+    public void queryReads(GridCacheQueryType type, UUID queryNodeId, long id, long logicalReads, long physicalReads) {\n+        doWrite(QUERY_READS,\n+            () -> 1 + 16 + 8 + 8 + 8,\n+            buf -> {\n+                buf.put((byte)type.ordinal());\n+                writeUuid(buf, queryNodeId);\n+                buf.putLong(id);\n+                buf.putLong(logicalReads);\n+                buf.putLong(physicalReads);\n+            });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param taskName Task name.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration.\n+     * @param affPartId Affinity partition id.\n+     */\n+    public void task(IgniteUuid sesId, String taskName, long startTime, long duration, int affPartId) {\n+        boolean needWriteStr = !stringCached(taskName);\n+        byte[] strBytes = needWriteStr ? taskName.getBytes() : null;\n+\n+        doWrite(TASK, () -> {\n+            int size = 24 + 1 + 4 + 8 + 8 + 4;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            writeIgniteUuid(buf, sesId);\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(taskName.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.putInt(affPartId);\n+        });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param queuedTime Time job spent on waiting queue.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Job execution time.\n+     * @param timedOut {@code True} if job is timed out.\n+     */\n+    public void job(IgniteUuid sesId, long queuedTime, long startTime, long duration, boolean timedOut) {\n+        doWrite(JOB,\n+            () -> 24 + 8 + 8 + 8 + 1,\n+            buf -> {\n+                writeIgniteUuid(buf, sesId);\n+                buf.putLong(queuedTime);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+                buf.put(timedOut ? (byte)1 : 0);\n+            });\n+    }\n+\n+    /**\n+     * @param op Operation type.\n+     * @param sizeSupplier Record size supplier.\n+     * @param writer Record writer.\n+     */\n+    private void doWrite(OperationType op, IntSupplier sizeSupplier, Consumer<ByteBuffer> writer) {\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        // Writer stopping.\n+        if (fileWriter == null)\n+            return;\n+\n+        int size = sizeSupplier.getAsInt() + /*type*/ 1;\n+\n+        SegmentedRingByteBuffer ringBuf = ringByteBuffer;\n+\n+        // Starting.\n+        if (ringBuf == null)\n+            return;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = ringBuf.offer(size);\n+\n+        if (seg == null) {\n+            if (smallBufLogged.compareAndSet(false, true)) {\n+                log.warning(\"The performance statistics in-memory buffer size is too small. Some operations \" +\n+                    \"will not be logged.\");\n+            }\n+\n+            return;\n+        }\n+\n+        // Ring buffer closed (writer stopping) or maximum size reached.\n+        if (seg.buffer() == null) {\n+            seg.release();\n+\n+            if (!fileWriter.isCancelled() && stopByMaxSize.compareAndSet(false, true)) {\n+                stopStatistics();\n+\n+                log.warning(\"The performance statistics file maximum size is reached. \" +\n+                    \"Performance statistics collecting will be stopped.\");\n+            }\n+\n+            return;\n+        }\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)op.ordinal());\n+\n+        writer.accept(buf);\n+\n+        seg.release();\n+\n+        int readySize = readyForFlushSize.addAndGet(size);\n+\n+        if (readySize >= DFLT_FLUSH_SIZE)\n+            fileWriter.wakeUp();\n+    }\n+\n+    /** @return {@code True} if string is cached. {@code False} if need write string.  */\n+    private boolean stringCached(String str) {\n+        boolean cached = cachedStrings.contains(str.hashCode());\n+\n+        if (!cached)\n+            cachedStrings.add(str.hashCode());\n+\n+        return cached;\n+    }\n+\n+    /** @return Performance statistics file. */\n+    private static File statisticsFile(GridKernalContext ctx) throws IgniteCheckedException {\n+        String igniteWorkDir = U.workDirectory(ctx.config().getWorkDirectory(), ctx.config().getIgniteHome());\n+\n+        File fileDir = U.resolveWorkDirectory(igniteWorkDir, PERFORMANCE_STAT_DIR, false);\n+\n+        return new File(fileDir, \"node-\" + ctx.localNodeId() + \".prf\");\n+    }\n+\n+    /** Writes {@link UUID} to buffer. */\n+    private static void writeUuid(ByteBuffer buf, UUID uuid) {\n+        buf.putLong(uuid.getMostSignificantBits());\n+        buf.putLong(uuid.getLeastSignificantBits());\n+    }\n+\n+    /** Writes {@link IgniteUuid} to buffer. */\n+    private static void writeIgniteUuid(ByteBuffer buf, IgniteUuid uuid) {\n+        buf.putLong(uuid.globalId().getMostSignificantBits());\n+        buf.putLong(uuid.globalId().getLeastSignificantBits());\n+        buf.putLong(uuid.localId());\n+    }\n+\n+    /** @return {@code True} if collecting performance statistics enabled. */\n+    public boolean enabled() {\n+        return enabled;\n+    }\n+\n+    /** Stops collecting statistics in the cluster. */\n+    void stopStatistics() {\n+        try {\n+            ctx.performanceStatistics().stopCollectStatistics();\n+        }\n+        catch (IgniteCheckedException e) {\n+            log.error(\"Failed to stop performance statistics.\", e);\n+        }\n+    }\n+\n+    /** Worker to write to performance statistics file. */\n+    private class FileWriter extends GridWorker {\n+        /**\n+         * @param ctx Kernal context.\n+         * @param log Logger.\n+         */\n+        FileWriter(GridKernalContext ctx, IgniteLogger log) {\n+            super(ctx.igniteInstanceName(), \"performance-statistics-writer%\" + ctx.igniteInstanceName(), log,\n+                ctx.workersRegistry());\n+        }\n+\n+        /** {@inheritDoc} */\n+        @Override protected void body() throws InterruptedException, IgniteInterruptedCheckedException {\n+            while (!isCancelled()) {\n+                blockingSectionBegin();\n+\n+                try {\n+                    synchronized (this) {\n+                        while (readyForFlushSize.get() < DFLT_FLUSH_SIZE && !isCancelled())\n+                            wait();\n+                    }\n+                }\n+                finally {\n+                    blockingSectionEnd();\n+                }\n+\n+                flushBuffer();\n+            }\n+\n+            // Make sure that all producers released their buffers to safe deallocate memory.\n+            flushBuffer();\n+        }\n+\n+        /** Flushes to disk available bytes from the ring buffer. */\n+        private void flushBuffer() {\n+            List<SegmentedRingByteBuffer.ReadSegment> segs = ringByteBuffer.poll();\n+\n+            if (segs == null)\n+                return;\n+\n+            try {\n+                for (SegmentedRingByteBuffer.ReadSegment seg : segs) {\n+                    updateHeartbeat();\n+\n+                    try {\n+                        readyForFlushSize.addAndGet(-seg.buffer().remaining());\n+\n+                        fileIo.writeFully(seg.buffer());\n+                    }\n+                    finally {\n+                        seg.release();\n+                    }\n+                }\n+\n+                fileIo.force();\n+            } catch (IOException e) {\n+                log.error(\"Unable to write to file. Performance statistics collecting will be stopped.\", e);\n+\n+                stopStatistics();\n+            }\n+        }\n+\n+        /** {@inheritDoc} */\n+        @Override public void cancel() {", "originalCommit": "513495bdee11a3e024a6a5efa1363b95be552511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUxMDg4Nw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r451510887", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-08T12:36:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQ3NzQwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQ4MjAyNw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r451482027", "bodyText": "We have a race here.\n\nFileWriter - writes some data and decrease readyForFlushSize.\nOther threads executes doWrite and constantly increase readySize so it's become bigger than DFLT_FLUSH_SIZE. This leads that those threads will have contention of wakeUp synchronization.", "author": "nizhikov", "createdAt": "2020-07-08T11:49:43Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,517 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Consumer;\n+import java.util.function.IntSupplier;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.JOB;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY_READS;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TASK;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_COMMIT;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_ROLLBACK;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * U.GB;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = (int)(32 * U.MB);\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = (int)(8 * U.MB);\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Performance statistics file I/O. */\n+    @Nullable private volatile FileIO fileIo;\n+\n+    /** File write buffer. */\n+    @Nullable private volatile SegmentedRingByteBuffer ringByteBuffer;\n+\n+    /** Size of ready for flushing bytes. */\n+    private final AtomicInteger readyForFlushSize = new AtomicInteger();\n+\n+    /** {@code True} if the small buffer warning message logged. */\n+    private final AtomicBoolean smallBufLogged = new AtomicBoolean();\n+\n+    /** {@code True} if worker stopped due to maximum file size reached. */\n+    private final AtomicBoolean stopByMaxSize = new AtomicBoolean();\n+\n+    /** Hashcodes of cached strings. */\n+    private final ConcurrentSkipListSet<Integer> cachedStrings = new ConcurrentSkipListSet<>();\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public void start() {\n+        synchronized (this) {\n+            if (enabled)\n+                return;\n+\n+            enabled = true;\n+\n+            try {\n+                File file = statisticsFile(ctx);\n+\n+                U.delete(file);\n+\n+                fileIo = fileIoFactory.create(file);\n+\n+                ringByteBuffer = new SegmentedRingByteBuffer(DFLT_BUFFER_SIZE, DFLT_FILE_MAX_SIZE,\n+                    SegmentedRingByteBuffer.BufferMode.DIRECT);\n+\n+                ringByteBuffer.init(0);\n+\n+                fileWriter = new FileWriter(ctx, log);\n+\n+                new IgniteThread(fileWriter).start();\n+\n+                log.info(\"Performance statistics writer started [file=\" + file.getAbsolutePath() + ']');\n+            }\n+            catch (IOException | IgniteCheckedException e) {\n+                log.error(\"Failed to start performance statistics writer.\", e);\n+\n+                stopStatistics();\n+\n+                throw new IgniteException(\"Failed to start performance statistics writer.\", e);\n+            }\n+        }\n+    }\n+\n+    /** Stops collecting performance statistics. */\n+    public void stop() {\n+        synchronized (this) {\n+            if (!enabled)\n+                return;\n+\n+            enabled = false;\n+\n+            FileWriter fileWriter = this.fileWriter;\n+\n+            SegmentedRingByteBuffer buf = ringByteBuffer;\n+\n+            // Stop write new data.\n+            if (buf != null)\n+                buf.close();\n+\n+            // Make sure that all buffer's producers released to safe deallocate memory.\n+            if (fileWriter != null)\n+                U.awaitForWorkersStop(Collections.singleton(fileWriter), true, log);\n+\n+            if (buf != null)\n+                buf.free();\n+\n+            U.closeQuiet(fileIo);\n+\n+            readyForFlushSize.set(0);\n+            smallBufLogged.set(false);\n+            stopByMaxSize.set(false);\n+            cachedStrings.clear();\n+\n+            log.info(\"Performance statistics writer stopped.\");\n+        }\n+    }\n+\n+    /**\n+     * @param type Operation type.\n+     * @param cacheId Cache id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     */\n+    public void cacheOperation(OperationType type, int cacheId, long startTime, long duration) {\n+        doWrite(type,\n+            () -> 4 + 8 + 8,\n+            buf -> {\n+                buf.putInt(cacheId);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param cacheIds Cache IDs.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param commited {@code True} if commited.\n+     */\n+    public void transaction(GridIntList cacheIds, long startTime, long duration, boolean commited) {\n+        doWrite(commited ? TX_COMMIT : TX_ROLLBACK,\n+            () -> 4 + cacheIds.size() * 4 + 8 + 8,\n+            buf -> {\n+                buf.putInt(cacheIds.size());\n+\n+                GridIntIterator iter = cacheIds.iterator();\n+\n+                while (iter.hasNext())\n+                    buf.putInt(iter.next());\n+\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param text Query text in case of SQL query. Cache name in case of SCAN query.\n+     * @param id Query id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param success Success flag.\n+     */\n+    public void query(GridCacheQueryType type, String text, long id, long startTime, long duration, boolean success) {\n+        boolean needWriteStr = !stringCached(text);\n+        byte[] strBytes = needWriteStr ? text.getBytes() : null;\n+\n+        doWrite(QUERY, () -> {\n+            int size = 1 + 1 + 4 + 8 + 8 + 8 + 1;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            buf.put((byte)type.ordinal());\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(text.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(id);\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.put(success ? (byte)1 : 0);\n+        });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param queryNodeId Originating node id.\n+     * @param id Query id.\n+     * @param logicalReads Number of logical reads.\n+     * @param physicalReads Number of physical reads.\n+     */\n+    public void queryReads(GridCacheQueryType type, UUID queryNodeId, long id, long logicalReads, long physicalReads) {\n+        doWrite(QUERY_READS,\n+            () -> 1 + 16 + 8 + 8 + 8,\n+            buf -> {\n+                buf.put((byte)type.ordinal());\n+                writeUuid(buf, queryNodeId);\n+                buf.putLong(id);\n+                buf.putLong(logicalReads);\n+                buf.putLong(physicalReads);\n+            });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param taskName Task name.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration.\n+     * @param affPartId Affinity partition id.\n+     */\n+    public void task(IgniteUuid sesId, String taskName, long startTime, long duration, int affPartId) {\n+        boolean needWriteStr = !stringCached(taskName);\n+        byte[] strBytes = needWriteStr ? taskName.getBytes() : null;\n+\n+        doWrite(TASK, () -> {\n+            int size = 24 + 1 + 4 + 8 + 8 + 4;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            writeIgniteUuid(buf, sesId);\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(taskName.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.putInt(affPartId);\n+        });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param queuedTime Time job spent on waiting queue.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Job execution time.\n+     * @param timedOut {@code True} if job is timed out.\n+     */\n+    public void job(IgniteUuid sesId, long queuedTime, long startTime, long duration, boolean timedOut) {\n+        doWrite(JOB,\n+            () -> 24 + 8 + 8 + 8 + 1,\n+            buf -> {\n+                writeIgniteUuid(buf, sesId);\n+                buf.putLong(queuedTime);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+                buf.put(timedOut ? (byte)1 : 0);\n+            });\n+    }\n+\n+    /**\n+     * @param op Operation type.\n+     * @param sizeSupplier Record size supplier.\n+     * @param writer Record writer.\n+     */\n+    private void doWrite(OperationType op, IntSupplier sizeSupplier, Consumer<ByteBuffer> writer) {\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        // Writer stopping.\n+        if (fileWriter == null)\n+            return;\n+\n+        int size = sizeSupplier.getAsInt() + /*type*/ 1;\n+\n+        SegmentedRingByteBuffer ringBuf = ringByteBuffer;\n+\n+        // Starting.\n+        if (ringBuf == null)\n+            return;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = ringBuf.offer(size);\n+\n+        if (seg == null) {\n+            if (smallBufLogged.compareAndSet(false, true)) {\n+                log.warning(\"The performance statistics in-memory buffer size is too small. Some operations \" +\n+                    \"will not be logged.\");\n+            }\n+\n+            return;\n+        }\n+\n+        // Ring buffer closed (writer stopping) or maximum size reached.\n+        if (seg.buffer() == null) {\n+            seg.release();\n+\n+            if (!fileWriter.isCancelled() && stopByMaxSize.compareAndSet(false, true)) {\n+                stopStatistics();\n+\n+                log.warning(\"The performance statistics file maximum size is reached. \" +\n+                    \"Performance statistics collecting will be stopped.\");\n+            }\n+\n+            return;\n+        }\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)op.ordinal());\n+\n+        writer.accept(buf);\n+\n+        seg.release();\n+\n+        int readySize = readyForFlushSize.addAndGet(size);", "originalCommit": "513495bdee11a3e024a6a5efa1363b95be552511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQ4Njg4Mg==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r451486882", "bodyText": "I think we should do the following:\n\nEach time readyForFlushSize cross DFLT_FLUSH_SIZE we should clear it to zero.\nEach time we see zero as a result of updateAndGet we should notify FileWriter to be sure it start flushing.\nFileWriter just flush all the data it have for the moment(slightly more then DFLT_FLUSH_SIZE because of concurrent writes.\n\nWe shouldn't touch readyForFlushSize in the FileWriter.", "author": "nizhikov", "createdAt": "2020-07-08T11:59:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQ4MjAyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUyMDM1OA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r451520358", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-08T12:52:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQ4MjAyNw=="}], "type": "inlineReview"}, {"oid": "defa90f419a0ae63d46a941cff821c00a7fdd652", "url": "https://github.com/apache/ignite/commit/defa90f419a0ae63d46a941cff821c00a7fdd652", "message": "Review fixes", "committedDate": "2020-07-08T12:27:31Z", "type": "commit"}, {"oid": "6f23c9d2689a8322c63b13f2ab4f588ac74cdd5c", "url": "https://github.com/apache/ignite/commit/6f23c9d2689a8322c63b13f2ab4f588ac74cdd5c", "message": "Review fixes", "committedDate": "2020-07-08T12:30:30Z", "type": "commit"}, {"oid": "fd71cb92b01a9cc323da1333a4bc4dcf8669796c", "url": "https://github.com/apache/ignite/commit/fd71cb92b01a9cc323da1333a4bc4dcf8669796c", "message": "Review fixes", "committedDate": "2020-07-08T12:50:15Z", "type": "commit"}, {"oid": "df898c7ede051495ea4a88c50be9d4e28bcb1dff", "url": "https://github.com/apache/ignite/commit/df898c7ede051495ea4a88c50be9d4e28bcb1dff", "message": "Review fixes", "committedDate": "2020-07-08T12:58:17Z", "type": "commit"}, {"oid": "ecd46720db5181fb0c246197acce48d717fa2f82", "url": "https://github.com/apache/ignite/commit/ecd46720db5181fb0c246197acce48d717fa2f82", "message": "Review fixes", "committedDate": "2020-07-08T13:34:58Z", "type": "commit"}, {"oid": "688c8b6b4c4eb3d90e8eb0e05e10c259b3c9afda", "url": "https://github.com/apache/ignite/commit/688c8b6b4c4eb3d90e8eb0e05e10c259b3c9afda", "message": "Review fixes", "committedDate": "2020-07-08T14:42:05Z", "type": "commit"}, {"oid": "efca43559e82c709000e32511302fbc44f64e2f2", "url": "https://github.com/apache/ignite/commit/efca43559e82c709000e32511302fbc44f64e2f2", "message": "Review fixes", "committedDate": "2020-07-08T14:59:43Z", "type": "commit"}, {"oid": "e828f38aff3370ad6821d248e55b5e0250a4756d", "url": "https://github.com/apache/ignite/commit/e828f38aff3370ad6821d248e55b5e0250a4756d", "message": "Review fixes", "committedDate": "2020-07-08T15:34:53Z", "type": "commit"}, {"oid": "8213e492b09f0239d938ad9668026adb9bb72854", "url": "https://github.com/apache/ignite/commit/8213e492b09f0239d938ad9668026adb9bb72854", "message": "Review fixes", "committedDate": "2020-07-08T16:01:26Z", "type": "commit"}, {"oid": "1bb61c03914d34b30588e91c9ca00e5bd405fd1a", "url": "https://github.com/apache/ignite/commit/1bb61c03914d34b30588e91c9ca00e5bd405fd1a", "message": "Review fixes", "committedDate": "2020-07-08T16:09:15Z", "type": "commit"}, {"oid": "7f4ea4952dc4d7294c0fd90f5bcb0e1b4e3f7455", "url": "https://github.com/apache/ignite/commit/7f4ea4952dc4d7294c0fd90f5bcb0e1b4e3f7455", "message": "Review fixes", "committedDate": "2020-07-08T16:10:06Z", "type": "commit"}, {"oid": "8e5c295d6ea7254f459f0665ea8d669da59fe766", "url": "https://github.com/apache/ignite/commit/8e5c295d6ea7254f459f0665ea8d669da59fe766", "message": "Review fixes", "committedDate": "2020-07-08T16:13:46Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTk5OTY4Mg==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r451999682", "bodyText": "I can't see why we should cache this variable here?", "author": "nizhikov", "createdAt": "2020-07-09T06:49:55Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,529 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.ClosedByInterruptException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Consumer;\n+import java.util.function.IntSupplier;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.JOB;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY_READS;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TASK;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_COMMIT;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_ROLLBACK;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * U.GB;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = (int)(32 * U.MB);\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = (int)(8 * U.MB);\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Performance statistics file I/O. */\n+    private volatile FileIO fileIo;\n+\n+    /** File write buffer. */\n+    @Nullable private volatile SegmentedRingByteBuffer ringByteBuffer;\n+\n+    /** Count of written to buffer bytes. */\n+    private final AtomicInteger writtenToBuffer = new AtomicInteger();\n+\n+    /** {@code True} if the small buffer warning message logged. */\n+    private final AtomicBoolean smallBufLogged = new AtomicBoolean();\n+\n+    /** {@code True} if worker stopped due to maximum file size reached. */\n+    private final AtomicBoolean stopByMaxSize = new AtomicBoolean();\n+\n+    /** Hashcodes of cached strings. */\n+    private final ConcurrentSkipListSet<Integer> cachedStrings = new ConcurrentSkipListSet<>();\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public void start() {\n+        synchronized (this) {\n+            if (enabled)\n+                return;\n+\n+            enabled = true;\n+\n+            try {\n+                File file = statisticsFile(ctx);\n+\n+                U.delete(file);\n+\n+                fileIo = fileIoFactory.create(file);\n+\n+                ringByteBuffer = new SegmentedRingByteBuffer(DFLT_BUFFER_SIZE, DFLT_FILE_MAX_SIZE,\n+                    SegmentedRingByteBuffer.BufferMode.DIRECT);\n+\n+                ringByteBuffer.init(0);\n+\n+                fileWriter = new FileWriter(ctx, log);\n+\n+                new IgniteThread(fileWriter).start();\n+\n+                log.info(\"Performance statistics writer started [file=\" + file.getAbsolutePath() + ']');\n+            }\n+            catch (IOException | IgniteCheckedException e) {\n+                log.error(\"Failed to start performance statistics writer.\", e);\n+\n+                stopStatistics();\n+\n+                throw new IgniteException(\"Failed to start performance statistics writer.\", e);\n+            }\n+        }\n+    }\n+\n+    /** Stops collecting performance statistics. */\n+    public void stop() {\n+        synchronized (this) {\n+            if (!enabled)\n+                return;\n+\n+            enabled = false;\n+\n+            FileWriter fileWriter = this.fileWriter;", "originalCommit": "8e5c295d6ea7254f459f0665ea8d669da59fe766", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjAwMzQzNQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r452003435", "bodyText": "For example, if fileIo = fileIoFactory.create(file); throws an exception and the writer will not be created", "author": "NSAmelchev", "createdAt": "2020-07-09T06:57:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTk5OTY4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTk5OTg5MA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r451999890", "bodyText": "It seems we should set up default values in the start method.", "author": "nizhikov", "createdAt": "2020-07-09T06:50:19Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,529 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.ClosedByInterruptException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Consumer;\n+import java.util.function.IntSupplier;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.JOB;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY_READS;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TASK;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_COMMIT;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_ROLLBACK;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * U.GB;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = (int)(32 * U.MB);\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = (int)(8 * U.MB);\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Performance statistics file I/O. */\n+    private volatile FileIO fileIo;\n+\n+    /** File write buffer. */\n+    @Nullable private volatile SegmentedRingByteBuffer ringByteBuffer;\n+\n+    /** Count of written to buffer bytes. */\n+    private final AtomicInteger writtenToBuffer = new AtomicInteger();\n+\n+    /** {@code True} if the small buffer warning message logged. */\n+    private final AtomicBoolean smallBufLogged = new AtomicBoolean();\n+\n+    /** {@code True} if worker stopped due to maximum file size reached. */\n+    private final AtomicBoolean stopByMaxSize = new AtomicBoolean();\n+\n+    /** Hashcodes of cached strings. */\n+    private final ConcurrentSkipListSet<Integer> cachedStrings = new ConcurrentSkipListSet<>();\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public void start() {\n+        synchronized (this) {\n+            if (enabled)\n+                return;\n+\n+            enabled = true;\n+\n+            try {\n+                File file = statisticsFile(ctx);\n+\n+                U.delete(file);\n+\n+                fileIo = fileIoFactory.create(file);\n+\n+                ringByteBuffer = new SegmentedRingByteBuffer(DFLT_BUFFER_SIZE, DFLT_FILE_MAX_SIZE,\n+                    SegmentedRingByteBuffer.BufferMode.DIRECT);\n+\n+                ringByteBuffer.init(0);\n+\n+                fileWriter = new FileWriter(ctx, log);\n+\n+                new IgniteThread(fileWriter).start();\n+\n+                log.info(\"Performance statistics writer started [file=\" + file.getAbsolutePath() + ']');\n+            }\n+            catch (IOException | IgniteCheckedException e) {\n+                log.error(\"Failed to start performance statistics writer.\", e);\n+\n+                stopStatistics();\n+\n+                throw new IgniteException(\"Failed to start performance statistics writer.\", e);\n+            }\n+        }\n+    }\n+\n+    /** Stops collecting performance statistics. */\n+    public void stop() {\n+        synchronized (this) {\n+            if (!enabled)\n+                return;\n+\n+            enabled = false;\n+\n+            FileWriter fileWriter = this.fileWriter;\n+\n+            // Make sure that all buffer's producers released to safe deallocate memory.\n+            if (fileWriter != null)\n+                U.awaitForWorkersStop(Collections.singleton(fileWriter), true, log);\n+\n+            SegmentedRingByteBuffer buf = ringByteBuffer;\n+\n+            if (buf != null) {\n+                buf.close();\n+\n+                // Make sure that all producers released their buffers to safe deallocate memory.\n+                buf.poll();\n+\n+                buf.free();\n+            }\n+\n+            U.closeQuiet(fileIo);\n+\n+            writtenToBuffer.set(0);", "originalCommit": "8e5c295d6ea7254f459f0665ea8d669da59fe766", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjAwMDczOA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r452000738", "bodyText": "I can't see why we should cache this variable.\nWe also, should check enabled flag here, but assign it to true as a last statement in the start.", "author": "nizhikov", "createdAt": "2020-07-09T06:52:05Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,529 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.ClosedByInterruptException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Consumer;\n+import java.util.function.IntSupplier;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.JOB;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY_READS;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TASK;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_COMMIT;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_ROLLBACK;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * U.GB;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = (int)(32 * U.MB);\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = (int)(8 * U.MB);\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Performance statistics file I/O. */\n+    private volatile FileIO fileIo;\n+\n+    /** File write buffer. */\n+    @Nullable private volatile SegmentedRingByteBuffer ringByteBuffer;\n+\n+    /** Count of written to buffer bytes. */\n+    private final AtomicInteger writtenToBuffer = new AtomicInteger();\n+\n+    /** {@code True} if the small buffer warning message logged. */\n+    private final AtomicBoolean smallBufLogged = new AtomicBoolean();\n+\n+    /** {@code True} if worker stopped due to maximum file size reached. */\n+    private final AtomicBoolean stopByMaxSize = new AtomicBoolean();\n+\n+    /** Hashcodes of cached strings. */\n+    private final ConcurrentSkipListSet<Integer> cachedStrings = new ConcurrentSkipListSet<>();\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public void start() {\n+        synchronized (this) {\n+            if (enabled)\n+                return;\n+\n+            enabled = true;\n+\n+            try {\n+                File file = statisticsFile(ctx);\n+\n+                U.delete(file);\n+\n+                fileIo = fileIoFactory.create(file);\n+\n+                ringByteBuffer = new SegmentedRingByteBuffer(DFLT_BUFFER_SIZE, DFLT_FILE_MAX_SIZE,\n+                    SegmentedRingByteBuffer.BufferMode.DIRECT);\n+\n+                ringByteBuffer.init(0);\n+\n+                fileWriter = new FileWriter(ctx, log);\n+\n+                new IgniteThread(fileWriter).start();\n+\n+                log.info(\"Performance statistics writer started [file=\" + file.getAbsolutePath() + ']');\n+            }\n+            catch (IOException | IgniteCheckedException e) {\n+                log.error(\"Failed to start performance statistics writer.\", e);\n+\n+                stopStatistics();\n+\n+                throw new IgniteException(\"Failed to start performance statistics writer.\", e);\n+            }\n+        }\n+    }\n+\n+    /** Stops collecting performance statistics. */\n+    public void stop() {\n+        synchronized (this) {\n+            if (!enabled)\n+                return;\n+\n+            enabled = false;\n+\n+            FileWriter fileWriter = this.fileWriter;\n+\n+            // Make sure that all buffer's producers released to safe deallocate memory.\n+            if (fileWriter != null)\n+                U.awaitForWorkersStop(Collections.singleton(fileWriter), true, log);\n+\n+            SegmentedRingByteBuffer buf = ringByteBuffer;\n+\n+            if (buf != null) {\n+                buf.close();\n+\n+                // Make sure that all producers released their buffers to safe deallocate memory.\n+                buf.poll();\n+\n+                buf.free();\n+            }\n+\n+            U.closeQuiet(fileIo);\n+\n+            writtenToBuffer.set(0);\n+            smallBufLogged.set(false);\n+            stopByMaxSize.set(false);\n+            cachedStrings.clear();\n+\n+            log.info(\"Performance statistics writer stopped.\");\n+        }\n+    }\n+\n+    /**\n+     * @param type Operation type.\n+     * @param cacheId Cache id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     */\n+    public void cacheOperation(OperationType type, int cacheId, long startTime, long duration) {\n+        doWrite(type,\n+            () -> 4 + 8 + 8,\n+            buf -> {\n+                buf.putInt(cacheId);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param cacheIds Cache IDs.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param commited {@code True} if commited.\n+     */\n+    public void transaction(GridIntList cacheIds, long startTime, long duration, boolean commited) {\n+        doWrite(commited ? TX_COMMIT : TX_ROLLBACK,\n+            () -> 4 + cacheIds.size() * 4 + 8 + 8,\n+            buf -> {\n+                buf.putInt(cacheIds.size());\n+\n+                GridIntIterator iter = cacheIds.iterator();\n+\n+                while (iter.hasNext())\n+                    buf.putInt(iter.next());\n+\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param text Query text in case of SQL query. Cache name in case of SCAN query.\n+     * @param id Query id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param success Success flag.\n+     */\n+    public void query(GridCacheQueryType type, String text, long id, long startTime, long duration, boolean success) {\n+        boolean needWriteStr = !stringCached(text);\n+        byte[] strBytes = needWriteStr ? text.getBytes() : null;\n+\n+        doWrite(QUERY, () -> {\n+            int size = 1 + 1 + 4 + 8 + 8 + 8 + 1;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            buf.put((byte)type.ordinal());\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(text.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(id);\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.put(success ? (byte)1 : 0);\n+        });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param queryNodeId Originating node id.\n+     * @param id Query id.\n+     * @param logicalReads Number of logical reads.\n+     * @param physicalReads Number of physical reads.\n+     */\n+    public void queryReads(GridCacheQueryType type, UUID queryNodeId, long id, long logicalReads, long physicalReads) {\n+        doWrite(QUERY_READS,\n+            () -> 1 + 16 + 8 + 8 + 8,\n+            buf -> {\n+                buf.put((byte)type.ordinal());\n+                writeUuid(buf, queryNodeId);\n+                buf.putLong(id);\n+                buf.putLong(logicalReads);\n+                buf.putLong(physicalReads);\n+            });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param taskName Task name.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration.\n+     * @param affPartId Affinity partition id.\n+     */\n+    public void task(IgniteUuid sesId, String taskName, long startTime, long duration, int affPartId) {\n+        boolean needWriteStr = !stringCached(taskName);\n+        byte[] strBytes = needWriteStr ? taskName.getBytes() : null;\n+\n+        doWrite(TASK, () -> {\n+            int size = 24 + 1 + 4 + 8 + 8 + 4;\n+\n+            if (needWriteStr)\n+                size += 4 + strBytes.length;\n+\n+            return size;\n+        }, buf -> {\n+            writeIgniteUuid(buf, sesId);\n+            buf.put(needWriteStr ? (byte)1 : 0);\n+            buf.putInt(taskName.hashCode());\n+\n+            if (needWriteStr) {\n+                buf.putInt(strBytes.length);\n+                buf.put(strBytes);\n+            }\n+\n+            buf.putLong(startTime);\n+            buf.putLong(duration);\n+            buf.putInt(affPartId);\n+        });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param queuedTime Time job spent on waiting queue.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Job execution time.\n+     * @param timedOut {@code True} if job is timed out.\n+     */\n+    public void job(IgniteUuid sesId, long queuedTime, long startTime, long duration, boolean timedOut) {\n+        doWrite(JOB,\n+            () -> 24 + 8 + 8 + 8 + 1,\n+            buf -> {\n+                writeIgniteUuid(buf, sesId);\n+                buf.putLong(queuedTime);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+                buf.put(timedOut ? (byte)1 : 0);\n+            });\n+    }\n+\n+    /**\n+     * @param op Operation type.\n+     * @param sizeSupplier Record size supplier.\n+     * @param writer Record writer.\n+     */\n+    private void doWrite(OperationType op, IntSupplier sizeSupplier, Consumer<ByteBuffer> writer) {\n+        FileWriter fileWriter = this.fileWriter;", "originalCommit": "8e5c295d6ea7254f459f0665ea8d669da59fe766", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjAwMTI4NQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r452001285", "bodyText": "I can't see why we should cache this variable.", "author": "nizhikov", "createdAt": "2020-07-09T06:53:13Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,529 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.ClosedByInterruptException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Consumer;\n+import java.util.function.IntSupplier;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.JOB;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY_READS;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TASK;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_COMMIT;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_ROLLBACK;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * U.GB;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = (int)(32 * U.MB);\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = (int)(8 * U.MB);\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Performance statistics file I/O. */\n+    private volatile FileIO fileIo;\n+\n+    /** File write buffer. */\n+    @Nullable private volatile SegmentedRingByteBuffer ringByteBuffer;\n+\n+    /** Count of written to buffer bytes. */\n+    private final AtomicInteger writtenToBuffer = new AtomicInteger();\n+\n+    /** {@code True} if the small buffer warning message logged. */\n+    private final AtomicBoolean smallBufLogged = new AtomicBoolean();\n+\n+    /** {@code True} if worker stopped due to maximum file size reached. */\n+    private final AtomicBoolean stopByMaxSize = new AtomicBoolean();\n+\n+    /** Hashcodes of cached strings. */\n+    private final ConcurrentSkipListSet<Integer> cachedStrings = new ConcurrentSkipListSet<>();\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public void start() {\n+        synchronized (this) {\n+            if (enabled)\n+                return;\n+\n+            enabled = true;\n+\n+            try {\n+                File file = statisticsFile(ctx);\n+\n+                U.delete(file);\n+\n+                fileIo = fileIoFactory.create(file);\n+\n+                ringByteBuffer = new SegmentedRingByteBuffer(DFLT_BUFFER_SIZE, DFLT_FILE_MAX_SIZE,\n+                    SegmentedRingByteBuffer.BufferMode.DIRECT);\n+\n+                ringByteBuffer.init(0);\n+\n+                fileWriter = new FileWriter(ctx, log);\n+\n+                new IgniteThread(fileWriter).start();\n+\n+                log.info(\"Performance statistics writer started [file=\" + file.getAbsolutePath() + ']');\n+            }\n+            catch (IOException | IgniteCheckedException e) {\n+                log.error(\"Failed to start performance statistics writer.\", e);\n+\n+                stopStatistics();\n+\n+                throw new IgniteException(\"Failed to start performance statistics writer.\", e);\n+            }\n+        }\n+    }\n+\n+    /** Stops collecting performance statistics. */\n+    public void stop() {\n+        synchronized (this) {\n+            if (!enabled)\n+                return;\n+\n+            enabled = false;\n+\n+            FileWriter fileWriter = this.fileWriter;\n+\n+            // Make sure that all buffer's producers released to safe deallocate memory.\n+            if (fileWriter != null)\n+                U.awaitForWorkersStop(Collections.singleton(fileWriter), true, log);\n+\n+            SegmentedRingByteBuffer buf = ringByteBuffer;", "originalCommit": "8e5c295d6ea7254f459f0665ea8d669da59fe766", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "ccc53253b1d09326b624f41df47d152cd14c29ae", "url": "https://github.com/apache/ignite/commit/ccc53253b1d09326b624f41df47d152cd14c29ae", "message": "Review fixes", "committedDate": "2020-07-09T12:22:22Z", "type": "commit"}, {"oid": "e8982bb6cd5c1c667f41fadb7130280d29e5275e", "url": "https://github.com/apache/ignite/commit/e8982bb6cd5c1c667f41fadb7130280d29e5275e", "message": "Unnecessary stopWriter", "committedDate": "2020-07-09T12:42:05Z", "type": "commit"}, {"oid": "7466f2272a72ea0f97916251c0b67ce90f3af4a1", "url": "https://github.com/apache/ignite/commit/7466f2272a72ea0f97916251c0b67ce90f3af4a1", "message": "Refactor cache lock statistics", "committedDate": "2020-07-09T14:07:24Z", "type": "commit"}, {"oid": "c46c3ce43f82ec4b98a6d50a6e4ec72bc8f2a2e3", "url": "https://github.com/apache/ignite/commit/c46c3ce43f82ec4b98a6d50a6e4ec72bc8f2a2e3", "message": "Add and refactor tests", "committedDate": "2020-07-09T21:21:33Z", "type": "commit"}, {"oid": "8559a99fc1998ac5ad659bca4f2bed4a7bd2a20d", "url": "https://github.com/apache/ignite/commit/8559a99fc1998ac5ad659bca4f2bed4a7bd2a20d", "message": "Minor fixes", "committedDate": "2020-07-10T08:40:58Z", "type": "commit"}, {"oid": "ebf92fff45710c90104c18f7240b660b99b5dc4d", "url": "https://github.com/apache/ignite/commit/ebf92fff45710c90104c18f7240b660b99b5dc4d", "message": "Naming fixes", "committedDate": "2020-07-10T08:50:33Z", "type": "commit"}, {"oid": "8f8fb9b39309ead7b2e0e1d8b6bd19d804849738", "url": "https://github.com/apache/ignite/commit/8f8fb9b39309ead7b2e0e1d8b6bd19d804849738", "message": "Test suite and minor fixes", "committedDate": "2020-07-10T10:48:01Z", "type": "commit"}, {"oid": "65c083a7045a64ecb1500aada5bc040b29359d20", "url": "https://github.com/apache/ignite/commit/65c083a7045a64ecb1500aada5bc040b29359d20", "message": "Merge branch 'master' into ignite-12666\n\n# Conflicts:\n#\tmodules/core/src/main/java/org/apache/ignite/internal/IgniteFeatures.java", "committedDate": "2020-07-13T12:23:04Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzY4NTU0NQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r453685545", "bodyText": "We should log outside of the synchronized section.", "author": "nizhikov", "createdAt": "2020-07-13T14:21:20Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/PerformaceStatisticsProcessor.java", "diffHunk": "@@ -0,0 +1,262 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.util.UUID;\n+import java.util.function.Consumer;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteFeatures;\n+import org.apache.ignite.internal.NodeStoppingException;\n+import org.apache.ignite.internal.processors.GridProcessorAdapter;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.processors.metastorage.DistributedMetaStorage;\n+import org.apache.ignite.internal.processors.metastorage.DistributedMetastorageLifecycleListener;\n+import org.apache.ignite.internal.processors.metastorage.ReadableDistributedMetaStorage;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.A;\n+import org.apache.ignite.lang.IgniteFuture;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.jetbrains.annotations.Nullable;\n+\n+import static org.apache.ignite.internal.IgniteFeatures.allNodesSupports;\n+\n+/**\n+ * Performance statistics processor.\n+ * <p>\n+ * Manages collecting performance statistics.\n+ *\n+ * @see FilePerformanceStatisticsWriter\n+ * @see FilePerformanceStatisticsReader\n+ */\n+public class PerformaceStatisticsProcessor extends GridProcessorAdapter {\n+    /** Prefix for performance statistics enabled property name. */\n+    private static final String PERFORMANCE_STAT_ENABLED_PREFIX = \"performanceStatistics.enabled\";\n+\n+    /** Performance statistics writer. */\n+    @Nullable private volatile FilePerformanceStatisticsWriter writer;\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Metastorage with the write access. */\n+    @Nullable private volatile DistributedMetaStorage metastorage;\n+\n+    /** @param ctx Kernal context. */\n+    public PerformaceStatisticsProcessor(GridKernalContext ctx) {\n+        super(ctx);\n+\n+        ctx.internalSubscriptionProcessor().registerDistributedMetastorageListener(\n+            new DistributedMetastorageLifecycleListener() {\n+            @Override public void onReadyForRead(ReadableDistributedMetaStorage metastorage) {\n+                metastorage.listen(PERFORMANCE_STAT_ENABLED_PREFIX::equals, (key, oldVal, newVal) -> {\n+                    // Skip history on local join.\n+                    if (!ctx.discovery().localJoinFuture().isDone())\n+                        return;\n+\n+                    onMetastorageUpdate((boolean)newVal);\n+                });\n+            }\n+\n+            @Override public void onReadyForWrite(DistributedMetaStorage metastorage) {\n+                PerformaceStatisticsProcessor.this.metastorage = metastorage;\n+\n+                try {\n+                    Boolean performanceStatsEnabled = metastorage.read(PERFORMANCE_STAT_ENABLED_PREFIX);\n+\n+                    if (performanceStatsEnabled == null)\n+                        return;\n+\n+                    onMetastorageUpdate(performanceStatsEnabled);\n+                }\n+                catch (IgniteCheckedException e) {\n+                    throw new IgniteException(e);\n+                }\n+            }\n+        });\n+    }\n+\n+    /**\n+     * @param type Operation type.\n+     * @param cacheId Cache id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     */\n+    public void cacheOperation(OperationType type, int cacheId, long startTime, long duration) {\n+        write(writer -> writer.cacheOperation(type, cacheId, startTime, duration));\n+    }\n+\n+    /**\n+     * @param cacheIds Cache IDs.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param commited {@code True} if commited.\n+     */\n+    public void transaction(GridIntList cacheIds, long startTime, long duration, boolean commited) {\n+        write(writer -> writer.transaction(cacheIds, startTime, duration, commited));\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param text Query text in case of SQL query. Cache name in case of SCAN query.\n+     * @param id Query id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param success Success flag.\n+     */\n+    public void query(GridCacheQueryType type, String text, long id, long startTime, long duration, boolean success) {\n+        write(writer -> writer.query(type, text, id, startTime, duration, success));\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param queryNodeId Originating node id.\n+     * @param id Query id.\n+     * @param logicalReads Number of logical reads.\n+     * @param physicalReads Number of physical reads.\n+     */\n+    public void queryReads(GridCacheQueryType type, UUID queryNodeId, long id, long logicalReads, long physicalReads) {\n+        write(writer -> writer.queryReads(type, queryNodeId, id, logicalReads, physicalReads));\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param taskName Task name.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration.\n+     * @param affPartId Affinity partition id.\n+     */\n+    public void task(IgniteUuid sesId, String taskName, long startTime, long duration, int affPartId) {\n+        write(writer -> writer.task(sesId, taskName, startTime, duration, affPartId));\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param queuedTime Time job spent on waiting queue.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Job execution time.\n+     * @param timedOut {@code True} if job is timed out.\n+     */\n+    public void job(IgniteUuid sesId, long queuedTime, long startTime, long duration, boolean timedOut) {\n+        write(writer -> writer.job(sesId, queuedTime, startTime, duration, timedOut));\n+    }\n+\n+    /**\n+     * Starts collecting performance statistics.\n+     *\n+     * @throws IgniteCheckedException If starting failed.\n+     */\n+    public void startCollectStatistics() throws IgniteCheckedException {\n+        A.notNull(metastorage, \"Metastorage not ready. Node not started?\");\n+\n+        if (!allNodesSupports(ctx.discovery().allNodes(), IgniteFeatures.PERFORMANCE_STATISTICS))\n+            throw new IllegalStateException(\"Not all nodes in the cluster support collecting performance statistics.\");\n+\n+        if (ctx.isStopping())\n+            throw new NodeStoppingException(\"Operation has been cancelled (node is stopping)\");\n+\n+        metastorage.write(PERFORMANCE_STAT_ENABLED_PREFIX, true);\n+    }\n+\n+    /**\n+     * Stops collecting performance statistics.\n+     *\n+     * @throws IgniteCheckedException If stopping failed.\n+     */\n+    public void stopCollectStatistics() throws IgniteCheckedException {\n+        A.notNull(metastorage, \"Metastorage not ready. Node not started?\");\n+\n+        if (ctx.isStopping())\n+            throw new NodeStoppingException(\"Operation has been cancelled (node is stopping)\");\n+\n+        metastorage.write(PERFORMANCE_STAT_ENABLED_PREFIX, false);\n+    }\n+\n+    /** @return {@code True} if collecting performance statistics is enabled. */\n+    public boolean enabled() {\n+        return enabled;\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void onKernalStop(boolean cancel) {\n+        if (enabled())\n+            stopWriter();\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void onDisconnected(IgniteFuture<?> reconnectFut) {\n+        if (enabled())\n+            stopWriter();\n+    }\n+\n+    /** Starts or stops collecting statistics on metastorage update. */\n+    private void onMetastorageUpdate(boolean start) {\n+        ctx.closure().runLocalSafe(() -> {\n+            if (start)\n+                startWriter();\n+            else\n+                stopWriter();\n+        });\n+    }\n+\n+    /** Starts performance statistics writer. */\n+    private void startWriter() {\n+        try {\n+            synchronized (this) {\n+                if (enabled)\n+                    return;\n+\n+                writer = new FilePerformanceStatisticsWriter(ctx);\n+\n+                writer.start();\n+\n+                enabled = true;\n+\n+                log.info(\"Performance statistics writer started.\");", "originalCommit": "65c083a7045a64ecb1500aada5bc040b29359d20", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzcwMzU5Nw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r453703597", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-13T14:46:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzY4NTU0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzY4NTYxOA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r453685618", "bodyText": "We should log outside of synchronized section.", "author": "nizhikov", "createdAt": "2020-07-13T14:21:26Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/PerformaceStatisticsProcessor.java", "diffHunk": "@@ -0,0 +1,262 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.util.UUID;\n+import java.util.function.Consumer;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteFeatures;\n+import org.apache.ignite.internal.NodeStoppingException;\n+import org.apache.ignite.internal.processors.GridProcessorAdapter;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.processors.metastorage.DistributedMetaStorage;\n+import org.apache.ignite.internal.processors.metastorage.DistributedMetastorageLifecycleListener;\n+import org.apache.ignite.internal.processors.metastorage.ReadableDistributedMetaStorage;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.A;\n+import org.apache.ignite.lang.IgniteFuture;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.jetbrains.annotations.Nullable;\n+\n+import static org.apache.ignite.internal.IgniteFeatures.allNodesSupports;\n+\n+/**\n+ * Performance statistics processor.\n+ * <p>\n+ * Manages collecting performance statistics.\n+ *\n+ * @see FilePerformanceStatisticsWriter\n+ * @see FilePerformanceStatisticsReader\n+ */\n+public class PerformaceStatisticsProcessor extends GridProcessorAdapter {\n+    /** Prefix for performance statistics enabled property name. */\n+    private static final String PERFORMANCE_STAT_ENABLED_PREFIX = \"performanceStatistics.enabled\";\n+\n+    /** Performance statistics writer. */\n+    @Nullable private volatile FilePerformanceStatisticsWriter writer;\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Metastorage with the write access. */\n+    @Nullable private volatile DistributedMetaStorage metastorage;\n+\n+    /** @param ctx Kernal context. */\n+    public PerformaceStatisticsProcessor(GridKernalContext ctx) {\n+        super(ctx);\n+\n+        ctx.internalSubscriptionProcessor().registerDistributedMetastorageListener(\n+            new DistributedMetastorageLifecycleListener() {\n+            @Override public void onReadyForRead(ReadableDistributedMetaStorage metastorage) {\n+                metastorage.listen(PERFORMANCE_STAT_ENABLED_PREFIX::equals, (key, oldVal, newVal) -> {\n+                    // Skip history on local join.\n+                    if (!ctx.discovery().localJoinFuture().isDone())\n+                        return;\n+\n+                    onMetastorageUpdate((boolean)newVal);\n+                });\n+            }\n+\n+            @Override public void onReadyForWrite(DistributedMetaStorage metastorage) {\n+                PerformaceStatisticsProcessor.this.metastorage = metastorage;\n+\n+                try {\n+                    Boolean performanceStatsEnabled = metastorage.read(PERFORMANCE_STAT_ENABLED_PREFIX);\n+\n+                    if (performanceStatsEnabled == null)\n+                        return;\n+\n+                    onMetastorageUpdate(performanceStatsEnabled);\n+                }\n+                catch (IgniteCheckedException e) {\n+                    throw new IgniteException(e);\n+                }\n+            }\n+        });\n+    }\n+\n+    /**\n+     * @param type Operation type.\n+     * @param cacheId Cache id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     */\n+    public void cacheOperation(OperationType type, int cacheId, long startTime, long duration) {\n+        write(writer -> writer.cacheOperation(type, cacheId, startTime, duration));\n+    }\n+\n+    /**\n+     * @param cacheIds Cache IDs.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param commited {@code True} if commited.\n+     */\n+    public void transaction(GridIntList cacheIds, long startTime, long duration, boolean commited) {\n+        write(writer -> writer.transaction(cacheIds, startTime, duration, commited));\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param text Query text in case of SQL query. Cache name in case of SCAN query.\n+     * @param id Query id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param success Success flag.\n+     */\n+    public void query(GridCacheQueryType type, String text, long id, long startTime, long duration, boolean success) {\n+        write(writer -> writer.query(type, text, id, startTime, duration, success));\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param queryNodeId Originating node id.\n+     * @param id Query id.\n+     * @param logicalReads Number of logical reads.\n+     * @param physicalReads Number of physical reads.\n+     */\n+    public void queryReads(GridCacheQueryType type, UUID queryNodeId, long id, long logicalReads, long physicalReads) {\n+        write(writer -> writer.queryReads(type, queryNodeId, id, logicalReads, physicalReads));\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param taskName Task name.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration.\n+     * @param affPartId Affinity partition id.\n+     */\n+    public void task(IgniteUuid sesId, String taskName, long startTime, long duration, int affPartId) {\n+        write(writer -> writer.task(sesId, taskName, startTime, duration, affPartId));\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param queuedTime Time job spent on waiting queue.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Job execution time.\n+     * @param timedOut {@code True} if job is timed out.\n+     */\n+    public void job(IgniteUuid sesId, long queuedTime, long startTime, long duration, boolean timedOut) {\n+        write(writer -> writer.job(sesId, queuedTime, startTime, duration, timedOut));\n+    }\n+\n+    /**\n+     * Starts collecting performance statistics.\n+     *\n+     * @throws IgniteCheckedException If starting failed.\n+     */\n+    public void startCollectStatistics() throws IgniteCheckedException {\n+        A.notNull(metastorage, \"Metastorage not ready. Node not started?\");\n+\n+        if (!allNodesSupports(ctx.discovery().allNodes(), IgniteFeatures.PERFORMANCE_STATISTICS))\n+            throw new IllegalStateException(\"Not all nodes in the cluster support collecting performance statistics.\");\n+\n+        if (ctx.isStopping())\n+            throw new NodeStoppingException(\"Operation has been cancelled (node is stopping)\");\n+\n+        metastorage.write(PERFORMANCE_STAT_ENABLED_PREFIX, true);\n+    }\n+\n+    /**\n+     * Stops collecting performance statistics.\n+     *\n+     * @throws IgniteCheckedException If stopping failed.\n+     */\n+    public void stopCollectStatistics() throws IgniteCheckedException {\n+        A.notNull(metastorage, \"Metastorage not ready. Node not started?\");\n+\n+        if (ctx.isStopping())\n+            throw new NodeStoppingException(\"Operation has been cancelled (node is stopping)\");\n+\n+        metastorage.write(PERFORMANCE_STAT_ENABLED_PREFIX, false);\n+    }\n+\n+    /** @return {@code True} if collecting performance statistics is enabled. */\n+    public boolean enabled() {\n+        return enabled;\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void onKernalStop(boolean cancel) {\n+        if (enabled())\n+            stopWriter();\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void onDisconnected(IgniteFuture<?> reconnectFut) {\n+        if (enabled())\n+            stopWriter();\n+    }\n+\n+    /** Starts or stops collecting statistics on metastorage update. */\n+    private void onMetastorageUpdate(boolean start) {\n+        ctx.closure().runLocalSafe(() -> {\n+            if (start)\n+                startWriter();\n+            else\n+                stopWriter();\n+        });\n+    }\n+\n+    /** Starts performance statistics writer. */\n+    private void startWriter() {\n+        try {\n+            synchronized (this) {\n+                if (enabled)\n+                    return;\n+\n+                writer = new FilePerformanceStatisticsWriter(ctx);\n+\n+                writer.start();\n+\n+                enabled = true;\n+\n+                log.info(\"Performance statistics writer started.\");\n+            }\n+        }\n+        catch (Exception e) {\n+            log.error(\"Failed to start performance statistics writer.\", e);\n+        }\n+    }\n+\n+    /** Stops performance statistics writer. */\n+    private void stopWriter() {\n+        synchronized (this) {\n+            if (!enabled)\n+                return;\n+\n+            enabled = false;\n+\n+            writer.stop();\n+\n+            writer = null;\n+\n+            log.info(\"Performance statistics writer stopped.\");", "originalCommit": "65c083a7045a64ecb1500aada5bc040b29359d20", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzcwMzYxOQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r453703619", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-13T14:46:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzY4NTYxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzY4NjA2Mw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r453686063", "bodyText": "Let's have explicit mux Object for synchronization to avoid contention if some external object will sync of processor.", "author": "nizhikov", "createdAt": "2020-07-13T14:22:02Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/PerformaceStatisticsProcessor.java", "diffHunk": "@@ -0,0 +1,262 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.util.UUID;\n+import java.util.function.Consumer;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteFeatures;\n+import org.apache.ignite.internal.NodeStoppingException;\n+import org.apache.ignite.internal.processors.GridProcessorAdapter;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.processors.metastorage.DistributedMetaStorage;\n+import org.apache.ignite.internal.processors.metastorage.DistributedMetastorageLifecycleListener;\n+import org.apache.ignite.internal.processors.metastorage.ReadableDistributedMetaStorage;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.A;\n+import org.apache.ignite.lang.IgniteFuture;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.jetbrains.annotations.Nullable;\n+\n+import static org.apache.ignite.internal.IgniteFeatures.allNodesSupports;\n+\n+/**\n+ * Performance statistics processor.\n+ * <p>\n+ * Manages collecting performance statistics.\n+ *\n+ * @see FilePerformanceStatisticsWriter\n+ * @see FilePerformanceStatisticsReader\n+ */\n+public class PerformaceStatisticsProcessor extends GridProcessorAdapter {\n+    /** Prefix for performance statistics enabled property name. */\n+    private static final String PERFORMANCE_STAT_ENABLED_PREFIX = \"performanceStatistics.enabled\";\n+\n+    /** Performance statistics writer. */\n+    @Nullable private volatile FilePerformanceStatisticsWriter writer;\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Metastorage with the write access. */\n+    @Nullable private volatile DistributedMetaStorage metastorage;\n+\n+    /** @param ctx Kernal context. */\n+    public PerformaceStatisticsProcessor(GridKernalContext ctx) {\n+        super(ctx);\n+\n+        ctx.internalSubscriptionProcessor().registerDistributedMetastorageListener(\n+            new DistributedMetastorageLifecycleListener() {\n+            @Override public void onReadyForRead(ReadableDistributedMetaStorage metastorage) {\n+                metastorage.listen(PERFORMANCE_STAT_ENABLED_PREFIX::equals, (key, oldVal, newVal) -> {\n+                    // Skip history on local join.\n+                    if (!ctx.discovery().localJoinFuture().isDone())\n+                        return;\n+\n+                    onMetastorageUpdate((boolean)newVal);\n+                });\n+            }\n+\n+            @Override public void onReadyForWrite(DistributedMetaStorage metastorage) {\n+                PerformaceStatisticsProcessor.this.metastorage = metastorage;\n+\n+                try {\n+                    Boolean performanceStatsEnabled = metastorage.read(PERFORMANCE_STAT_ENABLED_PREFIX);\n+\n+                    if (performanceStatsEnabled == null)\n+                        return;\n+\n+                    onMetastorageUpdate(performanceStatsEnabled);\n+                }\n+                catch (IgniteCheckedException e) {\n+                    throw new IgniteException(e);\n+                }\n+            }\n+        });\n+    }\n+\n+    /**\n+     * @param type Operation type.\n+     * @param cacheId Cache id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     */\n+    public void cacheOperation(OperationType type, int cacheId, long startTime, long duration) {\n+        write(writer -> writer.cacheOperation(type, cacheId, startTime, duration));\n+    }\n+\n+    /**\n+     * @param cacheIds Cache IDs.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param commited {@code True} if commited.\n+     */\n+    public void transaction(GridIntList cacheIds, long startTime, long duration, boolean commited) {\n+        write(writer -> writer.transaction(cacheIds, startTime, duration, commited));\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param text Query text in case of SQL query. Cache name in case of SCAN query.\n+     * @param id Query id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param success Success flag.\n+     */\n+    public void query(GridCacheQueryType type, String text, long id, long startTime, long duration, boolean success) {\n+        write(writer -> writer.query(type, text, id, startTime, duration, success));\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param queryNodeId Originating node id.\n+     * @param id Query id.\n+     * @param logicalReads Number of logical reads.\n+     * @param physicalReads Number of physical reads.\n+     */\n+    public void queryReads(GridCacheQueryType type, UUID queryNodeId, long id, long logicalReads, long physicalReads) {\n+        write(writer -> writer.queryReads(type, queryNodeId, id, logicalReads, physicalReads));\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param taskName Task name.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration.\n+     * @param affPartId Affinity partition id.\n+     */\n+    public void task(IgniteUuid sesId, String taskName, long startTime, long duration, int affPartId) {\n+        write(writer -> writer.task(sesId, taskName, startTime, duration, affPartId));\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param queuedTime Time job spent on waiting queue.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Job execution time.\n+     * @param timedOut {@code True} if job is timed out.\n+     */\n+    public void job(IgniteUuid sesId, long queuedTime, long startTime, long duration, boolean timedOut) {\n+        write(writer -> writer.job(sesId, queuedTime, startTime, duration, timedOut));\n+    }\n+\n+    /**\n+     * Starts collecting performance statistics.\n+     *\n+     * @throws IgniteCheckedException If starting failed.\n+     */\n+    public void startCollectStatistics() throws IgniteCheckedException {\n+        A.notNull(metastorage, \"Metastorage not ready. Node not started?\");\n+\n+        if (!allNodesSupports(ctx.discovery().allNodes(), IgniteFeatures.PERFORMANCE_STATISTICS))\n+            throw new IllegalStateException(\"Not all nodes in the cluster support collecting performance statistics.\");\n+\n+        if (ctx.isStopping())\n+            throw new NodeStoppingException(\"Operation has been cancelled (node is stopping)\");\n+\n+        metastorage.write(PERFORMANCE_STAT_ENABLED_PREFIX, true);\n+    }\n+\n+    /**\n+     * Stops collecting performance statistics.\n+     *\n+     * @throws IgniteCheckedException If stopping failed.\n+     */\n+    public void stopCollectStatistics() throws IgniteCheckedException {\n+        A.notNull(metastorage, \"Metastorage not ready. Node not started?\");\n+\n+        if (ctx.isStopping())\n+            throw new NodeStoppingException(\"Operation has been cancelled (node is stopping)\");\n+\n+        metastorage.write(PERFORMANCE_STAT_ENABLED_PREFIX, false);\n+    }\n+\n+    /** @return {@code True} if collecting performance statistics is enabled. */\n+    public boolean enabled() {\n+        return enabled;\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void onKernalStop(boolean cancel) {\n+        if (enabled())\n+            stopWriter();\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void onDisconnected(IgniteFuture<?> reconnectFut) {\n+        if (enabled())\n+            stopWriter();\n+    }\n+\n+    /** Starts or stops collecting statistics on metastorage update. */\n+    private void onMetastorageUpdate(boolean start) {\n+        ctx.closure().runLocalSafe(() -> {\n+            if (start)\n+                startWriter();\n+            else\n+                stopWriter();\n+        });\n+    }\n+\n+    /** Starts performance statistics writer. */\n+    private void startWriter() {\n+        try {\n+            synchronized (this) {\n+                if (enabled)\n+                    return;\n+\n+                writer = new FilePerformanceStatisticsWriter(ctx);\n+\n+                writer.start();\n+\n+                enabled = true;\n+\n+                log.info(\"Performance statistics writer started.\");\n+            }\n+        }\n+        catch (Exception e) {\n+            log.error(\"Failed to start performance statistics writer.\", e);\n+        }\n+    }\n+\n+    /** Stops performance statistics writer. */\n+    private void stopWriter() {\n+        synchronized (this) {", "originalCommit": "65c083a7045a64ecb1500aada5bc040b29359d20", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzcwMzY5NQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r453703695", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-13T14:46:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzY4NjA2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzY5MDU3OA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r453690578", "bodyText": "Other components use _ as a separator and more compact naming such as cp, binary_meta.\nLet's use perf_stat name here.", "author": "nizhikov", "createdAt": "2020-07-13T14:28:29Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,452 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.ClosedByInterruptException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Consumer;\n+import java.util.function.IntSupplier;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.JOB;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY_READS;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TASK;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_COMMIT;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_ROLLBACK;\n+\n+/**\n+ * Performance statistics writer based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";", "originalCommit": "65c083a7045a64ecb1500aada5bc040b29359d20", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzcwMTAyNA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r453701024", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-13T14:42:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzY5MDU3OA=="}], "type": "inlineReview"}, {"oid": "64c6e99d016c4742b3e6ff039df9355961acc0cb", "url": "https://github.com/apache/ignite/commit/64c6e99d016c4742b3e6ff039df9355961acc0cb", "message": "Separate mux + log + renaming", "committedDate": "2020-07-13T14:46:09Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzcyMzk0Nw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r453723947", "bodyText": "we use buffer here but buf in smallBufLogged.\nLet's use buf every where.", "author": "nizhikov", "createdAt": "2020-07-13T15:14:04Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,452 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.ClosedByInterruptException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Consumer;\n+import java.util.function.IntSupplier;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.JOB;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY_READS;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TASK;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_COMMIT;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_ROLLBACK;\n+\n+/**\n+ * Performance statistics writer based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * U.GB;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = (int)(32 * U.MB);\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = (int)(8 * U.MB);\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics file writer worker. */\n+    private final FileWriter fileWriter;\n+\n+    /** Performance statistics file I/O. */\n+    private final FileIO fileIo;\n+\n+    /** File write buffer. */\n+    private final SegmentedRingByteBuffer ringByteBuffer;", "originalCommit": "65c083a7045a64ecb1500aada5bc040b29359d20", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzcyNjMzNQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r453726335", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-13T15:17:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzcyMzk0Nw=="}], "type": "inlineReview"}, {"oid": "3a8ecfddb296c296e2f476b13681b63a66d763d7", "url": "https://github.com/apache/ignite/commit/3a8ecfddb296c296e2f476b13681b63a66d763d7", "message": "Renaming", "committedDate": "2020-07-13T15:17:05Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzc2MTA0OQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r453761049", "bodyText": "This name is not a prefix, it a full name, isnt'it?\nLet's rename this to PERFORMANCE_STAT_KEY", "author": "nizhikov", "createdAt": "2020-07-13T16:05:25Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/PerformaceStatisticsProcessor.java", "diffHunk": "@@ -0,0 +1,262 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.util.UUID;\n+import java.util.function.Consumer;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteFeatures;\n+import org.apache.ignite.internal.NodeStoppingException;\n+import org.apache.ignite.internal.processors.GridProcessorAdapter;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.processors.metastorage.DistributedMetaStorage;\n+import org.apache.ignite.internal.processors.metastorage.DistributedMetastorageLifecycleListener;\n+import org.apache.ignite.internal.processors.metastorage.ReadableDistributedMetaStorage;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.A;\n+import org.apache.ignite.lang.IgniteFuture;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.jetbrains.annotations.Nullable;\n+\n+import static org.apache.ignite.internal.IgniteFeatures.allNodesSupports;\n+\n+/**\n+ * Performance statistics processor.\n+ * <p>\n+ * Manages collecting performance statistics.\n+ *\n+ * @see FilePerformanceStatisticsWriter\n+ * @see FilePerformanceStatisticsReader\n+ */\n+public class PerformaceStatisticsProcessor extends GridProcessorAdapter {\n+    /** Prefix for performance statistics enabled property name. */\n+    private static final String PERFORMANCE_STAT_ENABLED_PREFIX = \"performanceStatistics.enabled\";", "originalCommit": "65c083a7045a64ecb1500aada5bc040b29359d20", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzc3MDgzOA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r453770838", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-13T16:21:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzc2MTA0OQ=="}], "type": "inlineReview"}, {"oid": "af178f633ec8bba7f7c0b41f0d2ecea3c15f3267", "url": "https://github.com/apache/ignite/commit/af178f633ec8bba7f7c0b41f0d2ecea3c15f3267", "message": "Remove enabled. Check for a one writer thread", "committedDate": "2020-07-13T16:09:32Z", "type": "commit"}, {"oid": "444cad8b17a0652225c46ac77c64e28c05e30ece", "url": "https://github.com/apache/ignite/commit/444cad8b17a0652225c46ac77c64e28c05e30ece", "message": "Renaming. perf_stat dir", "committedDate": "2020-07-13T16:13:37Z", "type": "commit"}, {"oid": "4fc84a3a1f6e7d10f6cbdee848d18d194cba1f3f", "url": "https://github.com/apache/ignite/commit/4fc84a3a1f6e7d10f6cbdee848d18d194cba1f3f", "message": "Remove unnecessary vars. Review fixes.", "committedDate": "2020-07-13T16:38:58Z", "type": "commit"}, {"oid": "e32cf4bd518396bb392b011af9396e8d82fad2de", "url": "https://github.com/apache/ignite/commit/e32cf4bd518396bb392b011af9396e8d82fad2de", "message": "Renaming", "committedDate": "2020-07-13T16:40:08Z", "type": "commit"}, {"oid": "e3cda0ecc7aa37a30e135ffec8389b15492b79bd", "url": "https://github.com/apache/ignite/commit/e3cda0ecc7aa37a30e135ffec8389b15492b79bd", "message": "Renaming", "committedDate": "2020-07-13T16:46:49Z", "type": "commit"}, {"oid": "7ca39a3ca03a7d6e8c165fd2593a170d8ec1e44e", "url": "https://github.com/apache/ignite/commit/7ca39a3ca03a7d6e8c165fd2593a170d8ec1e44e", "message": "assert started/stopped. package private writer", "committedDate": "2020-07-13T17:06:49Z", "type": "commit"}, {"oid": "04414a3f69b0fb74f82d694baf98577b58c2e4e2", "url": "https://github.com/apache/ignite/commit/04414a3f69b0fb74f82d694baf98577b58c2e4e2", "message": "Removed string caching. Inline wakeUp", "committedDate": "2020-07-13T17:23:47Z", "type": "commit"}, {"oid": "1fd124f28978f710c8f313dce6ebb92d91b2f7ff", "url": "https://github.com/apache/ignite/commit/1fd124f28978f710c8f313dce6ebb92d91b2f7ff", "message": "Fix thread name", "committedDate": "2020-07-13T18:06:14Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg2MzkzNQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r453863935", "bodyText": "We should introduce an explicit index here.\nOtherwise, any edit in the middle of OperationType will broke deserialization.", "author": "nizhikov", "createdAt": "2020-07-13T18:57:39Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,422 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.ClosedByInterruptException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Consumer;\n+import java.util.function.IntSupplier;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.JOB;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY_READS;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TASK;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_COMMIT;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_ROLLBACK;\n+\n+/**\n+ * Performance statistics writer based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERF_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+class FilePerformanceStatisticsWriter {\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERF_STAT_DIR = \"perf_stat\";\n+\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * U.GB;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = (int)(32 * U.MB);\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = (int)(8 * U.MB);\n+\n+    /** File writer thread name. */\n+    static final String WRITER_THREAD_NAME = \"performance-statistics-writer\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics file I/O. */\n+    private final FileIO fileIo;\n+\n+    /** Performance statistics file writer worker. */\n+    private final FileWriter fileWriter;\n+\n+    /** File writer thread started flag. */\n+    private boolean started;\n+\n+    /** File write buffer. */\n+    private final SegmentedRingByteBuffer ringByteBuf;\n+\n+    /** Count of written to buffer bytes. */\n+    private final AtomicInteger writtenToBuf = new AtomicInteger();\n+\n+    /** {@code True} if the small buffer warning message logged. */\n+    private final AtomicBoolean smallBufLogged = new AtomicBoolean();\n+\n+    /** {@code True} if worker stopped due to maximum file size reached. */\n+    private final AtomicBoolean stopByMaxSize = new AtomicBoolean();\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) throws IgniteCheckedException, IOException {\n+        log = ctx.log(getClass());\n+\n+        File file = statisticsFile(ctx);\n+\n+        U.delete(file);\n+\n+        fileIo = fileIoFactory.create(file);\n+\n+        log.info(\"Performance statistics file created [file=\" + file.getAbsolutePath() + ']');\n+\n+        ringByteBuf = new SegmentedRingByteBuffer(DFLT_BUFFER_SIZE, DFLT_FILE_MAX_SIZE,\n+            SegmentedRingByteBuffer.BufferMode.DIRECT);\n+\n+        fileWriter = new FileWriter(ctx, log);\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public synchronized void start() {\n+        assert !started;\n+\n+        new IgniteThread(fileWriter).start();\n+\n+        started = true;\n+    }\n+\n+    /** Stops collecting performance statistics. */\n+    public synchronized void stop() {\n+        assert started;\n+\n+        // Stop accepting new records.\n+        ringByteBuf.close();\n+\n+        U.awaitForWorkersStop(Collections.singleton(fileWriter), true, log);\n+\n+        // Make sure that all producers released their buffers to safe deallocate memory (in case of worker\n+        // stopped abnormally).\n+        ringByteBuf.poll();\n+\n+        ringByteBuf.free();\n+\n+        U.closeQuiet(fileIo);\n+\n+        started = false;\n+    }\n+\n+    /**\n+     * @param type Operation type.\n+     * @param cacheId Cache id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     */\n+    public void cacheOperation(OperationType type, int cacheId, long startTime, long duration) {\n+        doWrite(type,\n+            () -> 4 + 8 + 8,\n+            buf -> {\n+                buf.putInt(cacheId);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param cacheIds Cache IDs.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param commited {@code True} if commited.\n+     */\n+    public void transaction(GridIntList cacheIds, long startTime, long duration, boolean commited) {\n+        doWrite(commited ? TX_COMMIT : TX_ROLLBACK,\n+            () -> 4 + cacheIds.size() * 4 + 8 + 8,\n+            buf -> {\n+                buf.putInt(cacheIds.size());\n+\n+                GridIntIterator iter = cacheIds.iterator();\n+\n+                while (iter.hasNext())\n+                    buf.putInt(iter.next());\n+\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+            });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param text Query text in case of SQL query. Cache name in case of SCAN query.\n+     * @param id Query id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param success Success flag.\n+     */\n+    public void query(GridCacheQueryType type, String text, long id, long startTime, long duration, boolean success) {\n+        byte[] textBytes = text.getBytes();\n+\n+        doWrite(QUERY,\n+            () -> 1 + 4 + textBytes.length + 4 + 8 + 8 + 8 + 1,\n+            buf -> {\n+                buf.put((byte)type.ordinal());\n+                buf.putInt(textBytes.length);\n+                buf.put(textBytes);\n+                buf.putLong(id);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+                buf.put(success ? (byte)1 : 0);\n+            });\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param queryNodeId Originating node id.\n+     * @param id Query id.\n+     * @param logicalReads Number of logical reads.\n+     * @param physicalReads Number of physical reads.\n+     */\n+    public void queryReads(GridCacheQueryType type, UUID queryNodeId, long id, long logicalReads, long physicalReads) {\n+        doWrite(QUERY_READS,\n+            () -> 1 + 16 + 8 + 8 + 8,\n+            buf -> {\n+                buf.put((byte)type.ordinal());\n+                writeUuid(buf, queryNodeId);\n+                buf.putLong(id);\n+                buf.putLong(logicalReads);\n+                buf.putLong(physicalReads);\n+            });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param taskName Task name.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration.\n+     * @param affPartId Affinity partition id.\n+     */\n+    public void task(IgniteUuid sesId, String taskName, long startTime, long duration, int affPartId) {\n+        byte[] nameBytes = taskName.getBytes();\n+\n+        doWrite(TASK,\n+            () -> 24 + 4 + nameBytes.length + 8 + 8 + 4,\n+            buf -> {\n+                writeIgniteUuid(buf, sesId);\n+                buf.putInt(nameBytes.length);\n+                buf.put(nameBytes);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+                buf.putInt(affPartId);\n+            });\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param queuedTime Time job spent on waiting queue.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Job execution time.\n+     * @param timedOut {@code True} if job is timed out.\n+     */\n+    public void job(IgniteUuid sesId, long queuedTime, long startTime, long duration, boolean timedOut) {\n+        doWrite(JOB,\n+            () -> 24 + 8 + 8 + 8 + 1,\n+            buf -> {\n+                writeIgniteUuid(buf, sesId);\n+                buf.putLong(queuedTime);\n+                buf.putLong(startTime);\n+                buf.putLong(duration);\n+                buf.put(timedOut ? (byte)1 : 0);\n+            });\n+    }\n+\n+    /**\n+     * @param op Operation type.\n+     * @param sizeSupplier Record size supplier.\n+     * @param writer Record writer.\n+     */\n+    private void doWrite(OperationType op, IntSupplier sizeSupplier, Consumer<ByteBuffer> writer) {\n+        int size = sizeSupplier.getAsInt() + /*type*/ 1;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = ringByteBuf.offer(size);\n+\n+        if (seg == null) {\n+            if (smallBufLogged.compareAndSet(false, true)) {\n+                log.warning(\"The performance statistics in-memory buffer size is too small. Some operations \" +\n+                    \"will not be logged.\");\n+            }\n+\n+            return;\n+        }\n+\n+        // Ring buffer closed (writer stopping) or maximum size reached.\n+        if (seg.buffer() == null) {\n+            seg.release();\n+\n+            if (!fileWriter.isCancelled() && stopByMaxSize.compareAndSet(false, true))\n+                log.warning(\"The performance statistics file maximum size is reached.\");\n+\n+            return;\n+        }\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)op.ordinal());", "originalCommit": "1fd124f28978f710c8f313dce6ebb92d91b2f7ff", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg4NjgyOA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r453886828", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-13T19:39:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg2MzkzNQ=="}], "type": "inlineReview"}, {"oid": "b5e78715df3c0aaf1f4bec3bba3fbf6418204228", "url": "https://github.com/apache/ignite/commit/b5e78715df3c0aaf1f4bec3bba3fbf6418204228", "message": "fix fsync", "committedDate": "2020-07-13T19:02:16Z", "type": "commit"}, {"oid": "83f7c1153ecefdc4225c6dfa3fb5b86c535c23d4", "url": "https://github.com/apache/ignite/commit/83f7c1153ecefdc4225c6dfa3fb5b86c535c23d4", "message": "Add index of operations", "committedDate": "2020-07-13T19:38:48Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDE4MDY5Mg==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r454180692", "bodyText": "Nit: We should firstly check read results and after flip the buffer.", "author": "nizhikov", "createdAt": "2020-07-14T08:10:05Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsReader.java", "diffHunk": "@@ -0,0 +1,342 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.FileVisitOption;\n+import java.nio.file.FileVisitResult;\n+import java.nio.file.Path;\n+import java.nio.file.SimpleFileVisitor;\n+import java.nio.file.attribute.BasicFileAttributes;\n+import java.util.Collections;\n+import java.util.EnumSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.GridUnsafe;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.jetbrains.annotations.Nullable;\n+\n+import static java.nio.ByteBuffer.allocateDirect;\n+import static java.nio.ByteOrder.nativeOrder;\n+import static java.nio.file.Files.walkFileTree;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.JOB;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY_READS;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TASK;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_COMMIT;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.cacheOperation;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.transactionOperation;\n+\n+/**\n+ * Walker over the performance statistics file.\n+ *\n+ * @see FilePerformanceStatisticsWriter\n+ */\n+public class FilePerformanceStatisticsReader {\n+    /** File read buffer size. */\n+    private static final int READ_BUFFER_SIZE = (int)(8 * U.MB);\n+\n+    /** Uuid as string pattern. */\n+    private static final String UUID_STR_PATTERN =\n+        \"[a-fA-F0-9]{8}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{12}\";\n+\n+    /** File name pattern. */\n+    private static final Pattern FILE_PATTERN = Pattern.compile(\"^node-(\" + UUID_STR_PATTERN + \").prf$\");\n+\n+    /** IO factory. */\n+    private static final RandomAccessFileIOFactory ioFactory = new RandomAccessFileIOFactory();\n+\n+    /**\n+     * Walks over performance statistics files.\n+     *\n+     * @param filesOrDirs Files or directories.\n+     * @param handlers Handlers to process deserialized operation.\n+     */\n+    public static void read(List<File> filesOrDirs, PerformanceStatisticsHandler... handlers) throws IOException {\n+        List<File> files = resolveFiles(filesOrDirs);\n+\n+        if (files.isEmpty())\n+            return;\n+\n+        for (File file : files)\n+            readFile(file, handlers);\n+    }\n+\n+    /**\n+     * Walks over performance statistics file.\n+     *\n+     * @param file Performance statistics file.\n+     * @param handlers Handlers to process deserialized operation.\n+     */\n+    private static void readFile(File file, PerformanceStatisticsHandler... handlers) throws IOException {\n+        UUID nodeId = checkFileName(file);\n+\n+        ByteBuffer buf = allocateDirect(READ_BUFFER_SIZE).order(nativeOrder());\n+\n+        PerformanceStatisticsDeserializer des = new PerformanceStatisticsDeserializer(nodeId, handlers);\n+\n+        try (FileIO io = ioFactory.create(file)) {\n+            while (true) {\n+                int read = io.read(buf);\n+\n+                buf.flip();\n+\n+                if (read <= 0)", "originalCommit": "1fd124f28978f710c8f313dce6ebb92d91b2f7ff", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDE4OTE2Ng==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r454189166", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-14T08:24:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDE4MDY5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDE4MjA3Mw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r454182073", "bodyText": "We have code to calculate record size both in the writer and in the reader.\nLet's have it in one place - OperationType.", "author": "nizhikov", "createdAt": "2020-07-14T08:12:33Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsReader.java", "diffHunk": "@@ -0,0 +1,342 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.FileVisitOption;\n+import java.nio.file.FileVisitResult;\n+import java.nio.file.Path;\n+import java.nio.file.SimpleFileVisitor;\n+import java.nio.file.attribute.BasicFileAttributes;\n+import java.util.Collections;\n+import java.util.EnumSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.GridUnsafe;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.jetbrains.annotations.Nullable;\n+\n+import static java.nio.ByteBuffer.allocateDirect;\n+import static java.nio.ByteOrder.nativeOrder;\n+import static java.nio.file.Files.walkFileTree;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.JOB;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY_READS;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TASK;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_COMMIT;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.cacheOperation;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.transactionOperation;\n+\n+/**\n+ * Walker over the performance statistics file.\n+ *\n+ * @see FilePerformanceStatisticsWriter\n+ */\n+public class FilePerformanceStatisticsReader {\n+    /** File read buffer size. */\n+    private static final int READ_BUFFER_SIZE = (int)(8 * U.MB);\n+\n+    /** Uuid as string pattern. */\n+    private static final String UUID_STR_PATTERN =\n+        \"[a-fA-F0-9]{8}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{12}\";\n+\n+    /** File name pattern. */\n+    private static final Pattern FILE_PATTERN = Pattern.compile(\"^node-(\" + UUID_STR_PATTERN + \").prf$\");\n+\n+    /** IO factory. */\n+    private static final RandomAccessFileIOFactory ioFactory = new RandomAccessFileIOFactory();\n+\n+    /**\n+     * Walks over performance statistics files.\n+     *\n+     * @param filesOrDirs Files or directories.\n+     * @param handlers Handlers to process deserialized operation.\n+     */\n+    public static void read(List<File> filesOrDirs, PerformanceStatisticsHandler... handlers) throws IOException {\n+        List<File> files = resolveFiles(filesOrDirs);\n+\n+        if (files.isEmpty())\n+            return;\n+\n+        for (File file : files)\n+            readFile(file, handlers);\n+    }\n+\n+    /**\n+     * Walks over performance statistics file.\n+     *\n+     * @param file Performance statistics file.\n+     * @param handlers Handlers to process deserialized operation.\n+     */\n+    private static void readFile(File file, PerformanceStatisticsHandler... handlers) throws IOException {\n+        UUID nodeId = checkFileName(file);\n+\n+        ByteBuffer buf = allocateDirect(READ_BUFFER_SIZE).order(nativeOrder());\n+\n+        PerformanceStatisticsDeserializer des = new PerformanceStatisticsDeserializer(nodeId, handlers);\n+\n+        try (FileIO io = ioFactory.create(file)) {\n+            while (true) {\n+                int read = io.read(buf);\n+\n+                buf.flip();\n+\n+                if (read <= 0)\n+                    break;\n+\n+                while (des.read(buf));\n+\n+                buf.compact();\n+            }\n+        }\n+        finally {\n+            GridUnsafe.cleanDirectBuffer(buf);\n+        }\n+    }\n+\n+    /** Resolves performance statistics files. */\n+    private static List<File> resolveFiles(List<File> filesOrDirs) throws IOException {\n+        if (filesOrDirs == null || filesOrDirs.isEmpty())\n+            return Collections.emptyList();\n+\n+        List<File> files = new LinkedList<>();\n+\n+        for (File file : filesOrDirs) {\n+            if (file.isDirectory()) {\n+                walkFileTree(file.toPath(), EnumSet.noneOf(FileVisitOption.class), 1,\n+                    new SimpleFileVisitor<Path>() {\n+                        @Override public FileVisitResult visitFile(Path path, BasicFileAttributes attrs) {\n+                            if (checkFileName(path.toFile()) != null)\n+                                files.add(path.toFile());\n+\n+                            return FileVisitResult.CONTINUE;\n+                        }\n+                    });\n+\n+                continue;\n+            }\n+\n+            if (checkFileName(file) != null)\n+                files.add(file);\n+        }\n+\n+        return files;\n+    }\n+\n+    /** @return UUID node of file. {@code Null} if this is not a statistics file. */\n+    @Nullable private static UUID checkFileName(File file) {\n+        Matcher matcher = FILE_PATTERN.matcher(file.getName());\n+\n+        if (matcher.matches())\n+            return UUID.fromString(matcher.group(1));\n+\n+        return null;\n+    }\n+\n+    /** Reads {@link UUID} from buffer. */\n+    public static UUID readUuid(ByteBuffer buf) {\n+        return new UUID(buf.getLong(), buf.getLong());\n+    }\n+\n+    /** Reads {@link IgniteUuid} from buffer. */\n+    public static IgniteUuid readIgniteUuid(ByteBuffer buf) {\n+        UUID globalId = new UUID(buf.getLong(), buf.getLong());\n+\n+        return new IgniteUuid(globalId, buf.getLong());\n+    }\n+\n+    /** Performance statistics operations deserializer. */\n+    private static class PerformanceStatisticsDeserializer {\n+        /** Handlers to process deserialized operation. */\n+        private final PerformanceStatisticsHandler[] handlers;\n+\n+        /** Node id. */\n+        private final UUID nodeId;\n+\n+        /** @param handlers Handlers to process deserialized operation. */\n+        PerformanceStatisticsDeserializer(UUID nodeId, PerformanceStatisticsHandler... handlers) {\n+            this.nodeId = nodeId;\n+            this.handlers = handlers;\n+        }\n+\n+        /**\n+         * Tries to deserialize performance statistics operation from buffer and notify handlers.\n+         *\n+         * @param buf Buffer.\n+         * @return {@code True} if operation deserialized and handlers notified. {@code False} if not enough bytes.\n+         */\n+        boolean read(ByteBuffer buf) {\n+            int pos = buf.position();\n+\n+            if (deserialize(buf))\n+                return true;\n+\n+            buf.position(pos);\n+\n+            return false;\n+        }\n+\n+        /**\n+         * @param buf Buffer.\n+         * @return {@code True} if operation deserialized. {@code False} if not enough bytes.\n+         */\n+        private boolean deserialize(ByteBuffer buf) {\n+            if (buf.remaining() < 1)\n+                return false;\n+\n+            byte opTypeByte = buf.get();\n+\n+            OperationType opType = OperationType.fromOrdinal(opTypeByte);\n+\n+            if (cacheOperation(opType)) {\n+                if (buf.remaining() < 4 + 8 + 8)", "originalCommit": "1fd124f28978f710c8f313dce6ebb92d91b2f7ff", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "0bf16fb2ad9f3c74d811195f74f534057ec0e11b", "url": "https://github.com/apache/ignite/commit/0bf16fb2ad9f3c74d811195f74f534057ec0e11b", "message": "Minor fixes", "committedDate": "2020-07-14T08:24:43Z", "type": "commit"}, {"oid": "e57b8e43f4e1e5324d9e334b3800d7decd193618", "url": "https://github.com/apache/ignite/commit/e57b8e43f4e1e5324d9e334b3800d7decd193618", "message": "Minor fixes", "committedDate": "2020-07-14T08:36:26Z", "type": "commit"}, {"oid": "56a39389d004dfa0250441989f38e6cb50b89b7d", "url": "https://github.com/apache/ignite/commit/56a39389d004dfa0250441989f38e6cb50b89b7d", "message": "Cast in the constructor", "committedDate": "2020-07-14T08:48:43Z", "type": "commit"}, {"oid": "80cc53c16e511f6ec65a6d5a34577b0554d3844a", "url": "https://github.com/apache/ignite/commit/80cc53c16e511f6ec65a6d5a34577b0554d3844a", "message": "Record size methods", "committedDate": "2020-07-14T09:56:19Z", "type": "commit"}, {"oid": "cdcee81cb6cd180151f33882ea5b4bb449b66a54", "url": "https://github.com/apache/ignite/commit/cdcee81cb6cd180151f33882ea5b4bb449b66a54", "message": "Refactor reader", "committedDate": "2020-07-14T11:55:17Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDMwNzk0OQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r454307949", "bodyText": "We can use A.notEmpty here.", "author": "nizhikov", "createdAt": "2020-07-14T12:07:36Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsReader.java", "diffHunk": "@@ -0,0 +1,314 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.FileVisitOption;\n+import java.nio.file.FileVisitResult;\n+import java.nio.file.Path;\n+import java.nio.file.SimpleFileVisitor;\n+import java.nio.file.attribute.BasicFileAttributes;\n+import java.util.Collections;\n+import java.util.EnumSet;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.typedef.internal.A;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.jetbrains.annotations.Nullable;\n+\n+import static java.nio.ByteBuffer.allocateDirect;\n+import static java.nio.ByteOrder.nativeOrder;\n+import static java.nio.file.Files.walkFileTree;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.JOB;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.QUERY_READS;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TASK;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.TX_COMMIT;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.cacheOperation;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.cacheRecordSize;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.jobRecordSize;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.queryReadsRecordSize;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.queryRecordSize;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.taskRecordSize;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.transactionOperation;\n+import static org.apache.ignite.internal.processors.performancestatistics.OperationType.transactionRecordSize;\n+\n+/**\n+ * Walker over the performance statistics file.\n+ *\n+ * @see FilePerformanceStatisticsWriter\n+ */\n+public class FilePerformanceStatisticsReader {\n+    /** File read buffer size. */\n+    private static final int READ_BUFFER_SIZE = (int)(8 * U.MB);\n+\n+    /** Uuid as string pattern. */\n+    private static final String UUID_STR_PATTERN =\n+        \"[a-fA-F0-9]{8}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{12}\";\n+\n+    /** File name pattern. */\n+    private static final Pattern FILE_PATTERN = Pattern.compile(\"^node-(\" + UUID_STR_PATTERN + \").prf$\");\n+\n+    /** IO factory. */\n+    private final RandomAccessFileIOFactory ioFactory = new RandomAccessFileIOFactory();\n+\n+    /** Handlers to process deserialized operations. */\n+    private final PerformanceStatisticsHandler[] handlers;\n+\n+    /** @param handlers Handlers to process deserialized operations. */\n+    FilePerformanceStatisticsReader(PerformanceStatisticsHandler... handlers) {\n+        A.ensure(handlers != null, \"At least one handler expected.\");", "originalCommit": "cdcee81cb6cd180151f33882ea5b4bb449b66a54", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDMxMjEzOA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r454312138", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-14T12:15:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDMwNzk0OQ=="}], "type": "inlineReview"}, {"oid": "e56e5556cdbec0b2b338872352eb135cbe5a4f17", "url": "https://github.com/apache/ignite/commit/e56e5556cdbec0b2b338872352eb135cbe5a4f17", "message": "use A.notEmpty", "committedDate": "2020-07-14T12:15:43Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDMyNjk0MQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r454326941", "bodyText": "Let's use PerformanceStatisticsMBean#start here and in the other tests.", "author": "nizhikov", "createdAt": "2020-07-14T12:41:45Z", "path": "modules/core/src/test/java/org/apache/ignite/internal/processors/performancestatistics/AbstractPerformanceStatisticsTest.java", "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.lang.management.ThreadInfo;\n+import java.util.List;\n+import org.apache.ignite.Ignite;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteEx;\n+import org.apache.ignite.internal.util.typedef.G;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.testframework.ListeningTestLogger;\n+import org.apache.ignite.testframework.LogListener;\n+import org.apache.ignite.testframework.junits.GridAbstractTest;\n+import org.apache.ignite.testframework.junits.common.GridCommonAbstractTest;\n+\n+import static org.apache.ignite.internal.processors.performancestatistics.FilePerformanceStatisticsWriter.PERF_STAT_DIR;\n+import static org.apache.ignite.internal.processors.performancestatistics.FilePerformanceStatisticsWriter.WRITER_THREAD_NAME;\n+import static org.apache.ignite.internal.processors.performancestatistics.TestFilePerformanceStatisticsReader.readToLog;\n+import static org.apache.ignite.testframework.GridTestUtils.waitForCondition;\n+\n+/**\n+ * Ignite performance statistics abstract test.\n+ */\n+public abstract class AbstractPerformanceStatisticsTest extends GridCommonAbstractTest {\n+    /** */\n+    public static final long TIMEOUT = 30_000;\n+\n+    /** {@inheritDoc} */\n+    @Override protected void beforeTestsStarted() throws Exception {\n+        super.beforeTestsStarted();\n+\n+        U.delete(U.resolveWorkDirectory(U.defaultWorkDirectory(), PERF_STAT_DIR, false));\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override protected void afterTestsStopped() throws Exception {\n+        super.afterTestsStopped();\n+\n+        stopAllGrids();\n+\n+        U.delete(U.resolveWorkDirectory(U.defaultWorkDirectory(), PERF_STAT_DIR, false));\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    protected static void startCollectStatistics() throws Exception {\n+        List<Ignite> grids = G.allGrids();\n+\n+        assertFalse(grids.isEmpty());\n+\n+        IgniteEx ignite = (IgniteEx)grids.get(0);\n+\n+        ignite.context().performanceStatistics().startCollectStatistics();", "originalCommit": "e56e5556cdbec0b2b338872352eb135cbe5a4f17", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM4NTIzNA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r454385234", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-14T14:10:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDMyNjk0MQ=="}], "type": "inlineReview"}, {"oid": "65c902bfe45c8981d586b2d430753a28aa42076f", "url": "https://github.com/apache/ignite/commit/65c902bfe45c8981d586b2d430753a28aa42076f", "message": "Use handlers in tests", "committedDate": "2020-07-14T14:08:02Z", "type": "commit"}, {"oid": "fd2d08c05ceb4fdab5b923dad0c129081f2a0f51", "url": "https://github.com/apache/ignite/commit/fd2d08c05ceb4fdab5b923dad0c129081f2a0f51", "message": "Minor fixes", "committedDate": "2020-07-14T14:10:19Z", "type": "commit"}, {"oid": "470587263f9bddc8dd52b14cac35fbd1bff7f4d3", "url": "https://github.com/apache/ignite/commit/470587263f9bddc8dd52b14cac35fbd1bff7f4d3", "message": "Fix codestyle", "committedDate": "2020-07-15T07:10:47Z", "type": "commit"}, {"oid": "17b3df8a2acda15ad9353c3d6c75620808e9f4ae", "url": "https://github.com/apache/ignite/commit/17b3df8a2acda15ad9353c3d6c75620808e9f4ae", "message": "Ignite profiling", "committedDate": "2020-04-20T01:29:17Z", "type": "commit"}, {"oid": "10753112844574b9b9aa836eaecf309ad71b4c15", "url": "https://github.com/apache/ignite/commit/10753112844574b9b9aa836eaecf309ad71b4c15", "message": "Fix merge", "committedDate": "2020-04-20T01:35:06Z", "type": "commit"}, {"oid": "a61eca1dd1e69359557cb33ae1c417afc83aca98", "url": "https://github.com/apache/ignite/commit/a61eca1dd1e69359557cb33ae1c417afc83aca98", "message": "Add javadocs.", "committedDate": "2020-04-20T21:07:43Z", "type": "commit"}, {"oid": "6e1cb7602ea8fa7314e02ab077a73fbca5c4d0dc", "url": "https://github.com/apache/ignite/commit/6e1cb7602ea8fa7314e02ab077a73fbca5c4d0dc", "message": "Fix codestyle.", "committedDate": "2020-04-21T12:39:47Z", "type": "commit"}, {"oid": "ff2d64cf7278581ba75c00f044a0f3eb48dd901e", "url": "https://github.com/apache/ignite/commit/ff2d64cf7278581ba75c00f044a0f3eb48dd901e", "message": "Merge branch 'master' into ignite-12666", "committedDate": "2020-04-27T21:28:41Z", "type": "commit"}, {"oid": "df42ab84bd0f9b6e522502df0cc281537aeefb23", "url": "https://github.com/apache/ignite/commit/df42ab84bd0f9b6e522502df0cc281537aeefb23", "message": "Fix codestyle", "committedDate": "2020-04-27T21:35:29Z", "type": "commit"}, {"oid": "546998faf83e0eb64c87cac3b95985ad06ac18d6", "url": "https://github.com/apache/ignite/commit/546998faf83e0eb64c87cac3b95985ad06ac18d6", "message": "the new serializer like wal", "committedDate": "2020-05-02T10:51:57Z", "type": "commit"}, {"oid": "9a081e04e017bec4aeeda1addeed892caedc0ba9", "url": "https://github.com/apache/ignite/commit/9a081e04e017bec4aeeda1addeed892caedc0ba9", "message": "WIP", "committedDate": "2020-05-02T14:03:44Z", "type": "commit"}, {"oid": "efe3bf2d8763d4e7121191139578031b2d596044", "url": "https://github.com/apache/ignite/commit/efe3bf2d8763d4e7121191139578031b2d596044", "message": "WIP", "committedDate": "2020-05-03T00:03:35Z", "type": "commit"}, {"oid": "890167ffd66369a78cbb174833ca8f4ac219625c", "url": "https://github.com/apache/ignite/commit/890167ffd66369a78cbb174833ca8f4ac219625c", "message": "Merge branch 'master' into ignite-12666", "committedDate": "2020-05-03T11:49:43Z", "type": "commit"}, {"oid": "35a39e6d41c2811a67ea249828d6ce93ae587777", "url": "https://github.com/apache/ignite/commit/35a39e6d41c2811a67ea249828d6ce93ae587777", "message": "WIP", "committedDate": "2020-05-14T23:25:39Z", "type": "commit"}, {"oid": "d5aa74cec2b21793e461e514e4cac3dff5eb5bf9", "url": "https://github.com/apache/ignite/commit/d5aa74cec2b21793e461e514e4cac3dff5eb5bf9", "message": "WIP", "committedDate": "2020-05-15T02:31:19Z", "type": "commit"}, {"oid": "20ad83e38b25214e108a8df3f8be3653a81a1b7e", "url": "https://github.com/apache/ignite/commit/20ad83e38b25214e108a8df3f8be3653a81a1b7e", "message": "WIP", "committedDate": "2020-05-15T16:38:23Z", "type": "commit"}, {"oid": "826249e6e529cecfa5ed264d2ce204247418f179", "url": "https://github.com/apache/ignite/commit/826249e6e529cecfa5ed264d2ce204247418f179", "message": "WIP. Add deserializer. One phase report build. Add tests.", "committedDate": "2020-05-21T22:41:46Z", "type": "commit"}, {"oid": "1d32af8616f224f3273db01f650a1c41abf2e2b5", "url": "https://github.com/apache/ignite/commit/1d32af8616f224f3273db01f650a1c41abf2e2b5", "message": "WIP. Revert unnecessary changes.", "committedDate": "2020-05-21T23:21:13Z", "type": "commit"}, {"oid": "807d4df21d79b9937feb93d287b76ae3ee1f3b8c", "url": "https://github.com/apache/ignite/commit/807d4df21d79b9937feb93d287b76ae3ee1f3b8c", "message": "Merge branch 'master' into ignite-12666", "committedDate": "2020-05-21T23:22:06Z", "type": "commit"}, {"oid": "52af08015e6f4d2506433402188a0d14493afae0", "url": "https://github.com/apache/ignite/commit/52af08015e6f4d2506433402188a0d14493afae0", "message": "WIP. Use CDN links", "committedDate": "2020-05-22T15:38:51Z", "type": "commit"}, {"oid": "016492a549e59fd2b13e1b8411bb3f26d715094c", "url": "https://github.com/apache/ignite/commit/016492a549e59fd2b13e1b8411bb3f26d715094c", "message": "WIP. Codestyle", "committedDate": "2020-05-23T19:37:24Z", "type": "commit"}, {"oid": "c50051a11cbb5124b27da13341a98c4e4d334b59", "url": "https://github.com/apache/ignite/commit/c50051a11cbb5124b27da13341a98c4e4d334b59", "message": "WIP. Tests and renaming", "committedDate": "2020-05-26T09:51:56Z", "type": "commit"}, {"oid": "d64b2b5a3ef059200346e9607cc391fb604fa457", "url": "https://github.com/apache/ignite/commit/d64b2b5a3ef059200346e9607cc391fb604fa457", "message": "WIP. UI refactoring. Compact strings.", "committedDate": "2020-05-27T09:11:36Z", "type": "commit"}, {"oid": "c2d1c733e0094d861dc839c31cbbd03161fa9ce1", "url": "https://github.com/apache/ignite/commit/c2d1c733e0094d861dc839c31cbbd03161fa9ce1", "message": "WIP. Fix concurrent start timings.", "committedDate": "2020-05-27T11:17:06Z", "type": "commit"}, {"oid": "138642a417e422a950e1950c32c422d860d66d27", "url": "https://github.com/apache/ignite/commit/138642a417e422a950e1950c32c422d860d66d27", "message": "WIP. Cluster info tab + one data file", "committedDate": "2020-05-28T15:52:58Z", "type": "commit"}, {"oid": "d5643676c04a38401f123618ca6b1193aeafa6bc", "url": "https://github.com/apache/ignite/commit/d5643676c04a38401f123618ca6b1193aeafa6bc", "message": "Fix code style + renaming", "committedDate": "2020-06-03T11:14:04Z", "type": "commit"}, {"oid": "32e4150bb8a11221c23fc2ebd2c4f1bbd97d4987", "url": "https://github.com/apache/ignite/commit/32e4150bb8a11221c23fc2ebd2c4f1bbd97d4987", "message": "Merge branch 'master' into ignite-12666", "committedDate": "2020-06-03T11:15:53Z", "type": "commit"}, {"oid": "0cf6f4c8ffe46a8f3172b0acbb54d13fa929b8ee", "url": "https://github.com/apache/ignite/commit/0cf6f4c8ffe46a8f3172b0acbb54d13fa929b8ee", "message": "Add package info and readme files", "committedDate": "2020-06-03T11:28:28Z", "type": "commit"}, {"oid": "a4b319c0b30ae7fa4f2ca1df5de4731009671bf3", "url": "https://github.com/apache/ignite/commit/a4b319c0b30ae7fa4f2ca1df5de4731009671bf3", "message": "Javadocs fix. Todo fix.", "committedDate": "2020-06-04T06:37:10Z", "type": "commit"}, {"oid": "bfb8a8cfab6b045acc5b26f686c4e4a907dcf5fc", "url": "https://github.com/apache/ignite/commit/bfb8a8cfab6b045acc5b26f686c4e4a907dcf5fc", "message": "Exception fix.", "committedDate": "2020-06-04T06:52:15Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjU0NjQ5NQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r436546495", "bodyText": "Such nested maps are very hard to read, please introduce separate classes for internal maps.", "author": "agoncharuk", "createdAt": "2020-06-08T08:52:51Z", "path": "modules/profiling/src/main/java/org/apache/ignite/internal/profiling/handlers/CacheOperationsHandler.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.profiling.handlers;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.node.ArrayNode;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.UUID;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+\n+import static org.apache.ignite.internal.profiling.ProfilingFilesParser.currentNodeId;\n+import static org.apache.ignite.internal.profiling.util.Utils.MAPPER;\n+import static org.apache.ignite.internal.profiling.util.Utils.createArrayIfAbsent;\n+import static org.apache.ignite.internal.profiling.util.Utils.createObjectIfAbsent;\n+\n+/**\n+ * Builds JSON with aggregated cache operations statistics.\n+ *\n+ * Example:\n+ * <pre>\n+ * {\n+ *    $nodeId : {\n+ *       $cacheId : {\n+ *          $opType : [ [ $startTime, $count] ]\n+ *       }\n+ *    }\n+ * }\n+ * </pre>\n+ */\n+public class CacheOperationsHandler implements IgniteProfilingHandler {\n+    /** Field name of aggregated by caches/nodes values. */\n+    private static final String TOTAL = \"total\";\n+\n+    /** Cache operations statistics: nodeId->cacheId->opType->aggregatedResults. */\n+    private final Map<UUID, Map<Integer, Map<String, Map<Long, Integer>>>> res = new HashMap<>();", "originalCommit": "bfb8a8cfab6b045acc5b26f686c4e4a907dcf5fc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjU1NTQ2Mw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r436555463", "bodyText": "Such calculations are present at least in LogFileProfiling too, need to extract them to a single place to avoid errors.", "author": "agoncharuk", "createdAt": "2020-06-08T09:07:48Z", "path": "modules/profiling/src/main/java/org/apache/ignite/internal/profiling/util/ProfilingDeserializer.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.profiling.util;\n+\n+import java.nio.ByteBuffer;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.profiling.IgniteProfiling;\n+import org.apache.ignite.internal.profiling.IgniteProfiling.CacheOperationType;\n+import org.apache.ignite.internal.profiling.LogFileProfiling;\n+import org.apache.ignite.internal.profiling.LogFileProfiling.OperationType;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.lang.IgniteUuid;\n+\n+import static org.apache.ignite.internal.profiling.LogFileProfiling.readIgniteUuid;\n+import static org.apache.ignite.internal.profiling.LogFileProfiling.readUuid;\n+\n+/**\n+ * Profiling operations deserializer.\n+ *\n+ * @see LogFileProfiling\n+ */\n+public class ProfilingDeserializer implements AutoCloseable {\n+    /** Cached strings by id. */\n+    private final ConcurrentHashMap<Short, String> stringById = new ConcurrentHashMap<>();\n+\n+    /** Handlers to process deserialized operation. */\n+    private final IgniteProfiling[] handlers;\n+\n+    /** @param handlers Handlers to process deserialized operation. */\n+    public ProfilingDeserializer(IgniteProfiling... handlers) {\n+        this.handlers = handlers;\n+    }\n+\n+    /**\n+     * Tries to deserialize profiling operation from buffer.\n+     *\n+     * @param buf Buffer.\n+     * @return {@code True} if operation parsed. {@code False} if not enough bytes.\n+     */\n+    public boolean deserialize(ByteBuffer buf) {\n+        int pos = buf.position();\n+\n+        if (buf.remaining() < 1)\n+            return false;\n+\n+        byte opTypeByte = buf.get();\n+\n+        OperationType opType = OperationType.fromOrdinal(opTypeByte);\n+\n+        switch (opType) {\n+            case CACHE_OPERATION: {\n+                if (buf.remaining() < 1 + 4 + 8 + 8)", "originalCommit": "bfb8a8cfab6b045acc5b26f686c4e4a907dcf5fc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTk5NjE1MQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r439996151", "bodyText": "I put the writer and iterator in one place. See FileProfiling and FileProfilingWalker. Add tests. See AbstractProfilingTest implementations.", "author": "NSAmelchev", "createdAt": "2020-06-15T08:01:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjU1NTQ2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjU1ODAxMw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r436558013", "bodyText": "Need to add a test that validates serializing-deserializing of the operations. There is no need to start Ignite, just an instance of LogFileProfiling writing all possible operations and then an instance of ProfilingDeserializer reading those logged operations.", "author": "agoncharuk", "createdAt": "2020-06-08T09:11:45Z", "path": "modules/profiling/src/main/java/org/apache/ignite/internal/profiling/util/ProfilingDeserializer.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/*", "originalCommit": "bfb8a8cfab6b045acc5b26f686c4e4a907dcf5fc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "e8901889895d1a1d9a6bda1d108452e91661eab8", "url": "https://github.com/apache/ignite/commit/e8901889895d1a1d9a6bda1d108452e91661eab8", "message": "WIP", "committedDate": "2020-06-10T12:18:17Z", "type": "commit"}, {"oid": "9c86c502ff699285b1e0b10176a7e49988bd2edf", "url": "https://github.com/apache/ignite/commit/9c86c502ff699285b1e0b10176a7e49988bd2edf", "message": "WIP", "committedDate": "2020-06-11T08:02:07Z", "type": "commit"}, {"oid": "a7dad1d61fd8f67b947042b1563edf6cc35e5014", "url": "https://github.com/apache/ignite/commit/a7dad1d61fd8f67b947042b1563edf6cc35e5014", "message": "WIP. Remove LT, minor fixes", "committedDate": "2020-06-11T12:53:58Z", "type": "commit"}, {"oid": "605f3b912a02224073d5aace6af6304876159c89", "url": "https://github.com/apache/ignite/commit/605f3b912a02224073d5aace6af6304876159c89", "message": "Fix tests: add checks", "committedDate": "2020-06-15T07:29:54Z", "type": "commit"}, {"oid": "67444c855b316cdfd9f1595b6c667037ec8446ad", "url": "https://github.com/apache/ignite/commit/67444c855b316cdfd9f1595b6c667037ec8446ad", "message": "Add tests. Use full node version.", "committedDate": "2020-06-15T08:30:20Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzUzMjg3Nw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r443532877", "bodyText": "The word 'profiling' exists in each method of this bean. Can we remove it? start, stop, enabled seems less verbose.", "author": "nizhikov", "createdAt": "2020-06-22T12:47:52Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/profiling/IgniteProfilingMBean.java", "diffHunk": "@@ -0,0 +1,54 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.profiling;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.mxbean.MXBeanDescription;\n+import org.apache.ignite.mxbean.MXBeanParameter;\n+\n+/**\n+ * MBean provide access to profiling management.\n+ */\n+@MXBeanDescription(\"MBean provide access to profiling management.\")\n+public interface IgniteProfilingMBean {\n+    /**\n+     * Start profiling in the cluster with default settings.\n+     *\n+     * @see FileProfiling#DFLT_FILE_MAX_SIZE\n+     * @see FileProfiling#DFLT_BUFFER_SIZE\n+     * @see FileProfiling#DFLT_FLUSH_SIZE\n+     */\n+    @MXBeanDescription(\"Start profiling in the cluster.\")\n+    public void startProfiling() throws IgniteCheckedException;", "originalCommit": "67444c855b316cdfd9f1595b6c667037ec8446ad", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAwNjYzNA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446006634", "bodyText": "Fixed.", "author": "NSAmelchev", "createdAt": "2020-06-26T07:09:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzUzMjg3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzU3ODY2Ng==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r443578666", "bodyText": "Why we ignore cancelled operations?\nWe should gather statistics about all operations that user initiate no matter if it succeeds or failed.", "author": "nizhikov", "createdAt": "2020-06-22T13:59:59Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/cache/GridCacheAdapter.java", "diffHunk": "@@ -6794,6 +6899,55 @@ public InvokeAllTimeStatClosure(CacheMetricsImpl metrics, final long start) {\n         }\n     }\n \n+    /** */\n+    private class ProfileClosure<T> implements CI1<IgniteInternalFuture<T>> {\n+        /** */\n+        private static final long serialVersionUID = 0L;\n+\n+        /** Operation type. */\n+        private final CacheOperationType op;\n+\n+        /** Start time in nanoseconds. */\n+        private final long start;\n+\n+        /**\n+         * @param op Operation type.\n+         * @param start Start time in nanoseconds.\n+         */\n+        public ProfileClosure(CacheOperationType op, long start) {\n+            this.op = op;\n+            this.start = start;\n+        }\n+\n+        /** {@inheritDoc} */\n+        @Override public void apply(IgniteInternalFuture<T> fut) {\n+            try {\n+                if (!fut.isCancelled()) {", "originalCommit": "67444c855b316cdfd9f1595b6c667037ec8446ad", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM4NjI4Mg==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r444386282", "bodyText": "Fixed.", "author": "NSAmelchev", "createdAt": "2020-06-23T17:22:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzU3ODY2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzU3ODkyOA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r443578928", "bodyText": "Why do we need fut.get() here?", "author": "nizhikov", "createdAt": "2020-06-22T14:00:18Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/cache/GridCacheAdapter.java", "diffHunk": "@@ -6794,6 +6899,55 @@ public InvokeAllTimeStatClosure(CacheMetricsImpl metrics, final long start) {\n         }\n     }\n \n+    /** */\n+    private class ProfileClosure<T> implements CI1<IgniteInternalFuture<T>> {\n+        /** */\n+        private static final long serialVersionUID = 0L;\n+\n+        /** Operation type. */\n+        private final CacheOperationType op;\n+\n+        /** Start time in nanoseconds. */\n+        private final long start;\n+\n+        /**\n+         * @param op Operation type.\n+         * @param start Start time in nanoseconds.\n+         */\n+        public ProfileClosure(CacheOperationType op, long start) {\n+            this.op = op;\n+            this.start = start;\n+        }\n+\n+        /** {@inheritDoc} */\n+        @Override public void apply(IgniteInternalFuture<T> fut) {\n+            try {\n+                if (!fut.isCancelled()) {\n+                    fut.get();", "originalCommit": "67444c855b316cdfd9f1595b6c667037ec8446ad", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM4NjQ0MA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r444386440", "bodyText": "Removed.", "author": "NSAmelchev", "createdAt": "2020-06-23T17:22:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzU3ODkyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzYwMTIwMA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r443601200", "bodyText": "We should have separate class for each operations so we can eliminate operation variable from ProfileClosure.", "author": "nizhikov", "createdAt": "2020-06-22T14:30:23Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/cache/GridCacheAdapter.java", "diffHunk": "@@ -3324,6 +3418,9 @@ protected void removeAll0(final Collection<? extends K> keys) throws IgniteCheck\n         if (statsEnabled)\n             fut.listen(new UpdateRemoveTimeStatClosure<>(metrics0(), start));\n \n+        if (profilingEnabled)\n+            fut.listen(new ProfileClosure<>(CacheOperationType.REMOVE_ALL, start));", "originalCommit": "67444c855b316cdfd9f1595b6c667037ec8446ad", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzYxNjc0OA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r443616748", "bodyText": "I think we should push down methods startTime and duration from GridCacheFuture to IgniteInternalFuture therefore we can use the single non-static inner class instance to gather statistics both for cache statistics and performance statistics.", "author": "nizhikov", "createdAt": "2020-06-22T14:50:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzYwMTIwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAwNjgwNQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446006805", "bodyText": "We should have separate class for each operations so we can eliminate operation variable from ProfileClosure.\n\nI have used lambda expressions.", "author": "NSAmelchev", "createdAt": "2020-06-26T07:09:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzYwMTIwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzY4NDUwOQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r443684509", "bodyText": "I don't think we need to collect performance statistics about cache start.\nIt a rare operation that should be analyzed via log files.", "author": "nizhikov", "createdAt": "2020-06-22T16:31:00Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/cache/GridCacheProcessor.java", "diffHunk": "@@ -2248,6 +2248,15 @@ private void onCacheStarted(GridCacheContext cacheCtx) throws IgniteCheckedExcep\n                 \", mvcc=\" + cacheCtx.mvccEnabled() + ']');\n         }\n \n+        if (ctx.metric().profilingEnabled()) {", "originalCommit": "67444c855b316cdfd9f1595b6c667037ec8446ad", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAwNjkwOA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446006908", "bodyText": "Excluded.", "author": "NSAmelchev", "createdAt": "2020-06-26T07:09:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzY4NDUwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzY4NjM0Mw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r443686343", "bodyText": "Typo: flag name should be committed or isCommitted", "author": "nizhikov", "createdAt": "2020-06-22T16:33:55Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/cache/transactions/IgniteTxManager.java", "diffHunk": "@@ -3190,6 +3198,23 @@ private void collectInfo() {\n         }\n     }\n \n+    /**\n+     * Profiles transaction.\n+     *\n+     * @param tx Transaction.\n+     * @param commit {@code True} if transaction commited.", "originalCommit": "67444c855b316cdfd9f1595b6c667037ec8446ad", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM4Njc5MQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r444386791", "bodyText": "Fixed.", "author": "NSAmelchev", "createdAt": "2020-06-23T17:23:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzY4NjM0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzY4Nzc0MA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r443687740", "bodyText": "It seems, code that related to performance statistics should be moved to separate Manager.", "author": "nizhikov", "createdAt": "2020-06-22T16:36:15Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/metric/GridMetricManager.java", "diffHunk": "@@ -234,6 +241,9 @@\n     /** Nonheap memory metrics. */\n     private final MemoryUsageMetrics nonHeap;\n \n+    /** Profiling. */\n+    private final FileProfiling profiling;", "originalCommit": "67444c855b316cdfd9f1595b6c667037ec8446ad", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAwNzA0MA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446007040", "bodyText": "I have moved code to the PerformaceStatisticsProcessor", "author": "NSAmelchev", "createdAt": "2020-06-26T07:10:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzY4Nzc0MA=="}], "type": "inlineReview"}, {"oid": "32e8fe68e06b99c36dd6c64c2cc045e3e98b3736", "url": "https://github.com/apache/ignite/commit/32e8fe68e06b99c36dd6c64c2cc045e3e98b3736", "message": "Rename MBean methods", "committedDate": "2020-06-22T18:14:29Z", "type": "commit"}, {"oid": "b718e797dd84185296a66f1c7cafc88483648186", "url": "https://github.com/apache/ignite/commit/b718e797dd84185296a66f1c7cafc88483648186", "message": "Fix typo", "committedDate": "2020-06-22T18:51:03Z", "type": "commit"}, {"oid": "2a2fcc37a9bc8fec136c5720b7112da3fe8c259f", "url": "https://github.com/apache/ignite/commit/2a2fcc37a9bc8fec136c5720b7112da3fe8c259f", "message": "Use lambda in the CacheAdapter", "committedDate": "2020-06-23T10:49:36Z", "type": "commit"}, {"oid": "5ac0dcf8535bde07557a6aa89eddf7a3d025c418", "url": "https://github.com/apache/ignite/commit/5ac0dcf8535bde07557a6aa89eddf7a3d025c418", "message": " Renaming step 1.", "committedDate": "2020-06-23T13:09:00Z", "type": "commit"}, {"oid": "221ed81362a32062b26ac7467eef5d02197eaa85", "url": "https://github.com/apache/ignite/commit/221ed81362a32062b26ac7467eef5d02197eaa85", "message": "Renaming step 2. Remove cacheStart profilingStart", "committedDate": "2020-06-23T14:36:48Z", "type": "commit"}, {"oid": "7db0b02a8d8fec6fc16dedf4dad36f877366999d", "url": "https://github.com/apache/ignite/commit/7db0b02a8d8fec6fc16dedf4dad36f877366999d", "message": "Fix typo", "committedDate": "2020-06-23T15:59:58Z", "type": "commit"}, {"oid": "0329f8d1015dfdcb9a33ac2fd122a9b94a637e53", "url": "https://github.com/apache/ignite/commit/0329f8d1015dfdcb9a33ac2fd122a9b94a637e53", "message": "Move to separate processor", "committedDate": "2020-06-25T22:06:40Z", "type": "commit"}, {"oid": "3e2e2fbcf4a09661e3a7b6e64b919073c62d3f88", "url": "https://github.com/apache/ignite/commit/3e2e2fbcf4a09661e3a7b6e64b919073c62d3f88", "message": "Minor fixes", "committedDate": "2020-06-26T07:06:14Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAxODI5NQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446018295", "bodyText": "Typo: let's use performanceStatsEnabled name here and in all other cases.", "author": "nizhikov", "createdAt": "2020-06-26T07:36:29Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/cache/GridCacheAdapter.java", "diffHunk": "@@ -2588,6 +2630,9 @@ public boolean put(final K key, final V val, final CacheEntryPredicate filter)\n         if (statsEnabled && stored)\n             metrics0().addPutTimeNanos(System.nanoTime() - start);\n \n+        if (performanceStatsEnabled)", "originalCommit": "3e2e2fbcf4a09661e3a7b6e64b919073c62d3f88", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA0NjAzNw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446046037", "bodyText": "Fixed.", "author": "NSAmelchev", "createdAt": "2020-06-26T08:33:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAxODI5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAxOTQzMg==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446019432", "bodyText": "Typo: let's rename this to enabled", "author": "nizhikov", "createdAt": "2020-06-26T07:39:03Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/PerformaceStatisticsProcessor.java", "diffHunk": "@@ -0,0 +1,232 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.Serializable;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteFeatures;\n+import org.apache.ignite.internal.IgniteInternalFuture;\n+import org.apache.ignite.internal.processors.GridProcessorAdapter;\n+import org.apache.ignite.internal.util.distributed.DistributedProcess;\n+import org.apache.ignite.internal.util.future.GridFinishedFuture;\n+import org.apache.ignite.internal.util.future.GridFutureAdapter;\n+import org.apache.ignite.internal.util.typedef.F;\n+import org.apache.ignite.lang.IgniteFuture;\n+import org.apache.ignite.lang.IgniteFutureCancelledException;\n+import org.apache.ignite.spi.discovery.DiscoveryDataBag;\n+\n+import static org.apache.ignite.internal.GridComponent.DiscoveryDataExchangeType.PERFORMANCE_STAT_PROC;\n+import static org.apache.ignite.internal.IgniteFeatures.allNodesSupports;\n+import static org.apache.ignite.internal.util.distributed.DistributedProcess.DistributedProcessType.PERFORMANCE_STATISTICS;\n+\n+/**\n+ * Performance statistics processor.\n+ * <p>\n+ * Manages collecting statistics.\n+ */\n+public class PerformaceStatisticsProcessor extends GridProcessorAdapter {\n+    /** Process to start/stop statistics. */\n+    private final DistributedProcess<Boolean, Boolean> proc;\n+\n+    /** Performance statistics writer. */\n+    private final FilePerformanceStatistics writer;\n+\n+    /** Synchronization mutex for request futures. */\n+    private final Object mux = new Object();\n+\n+    /** Enable/disable statistics request futures. */\n+    private final ConcurrentMap<UUID, GridFutureAdapter<Void>> reqFuts = new ConcurrentHashMap<>();\n+\n+    /** Disconnected flag. */\n+    private volatile boolean disconnected;\n+\n+    /** Stopped flag. */\n+    private volatile boolean stopped;\n+\n+    /** @param ctx Kernal context. */\n+    public PerformaceStatisticsProcessor(GridKernalContext ctx) {\n+        super(ctx);\n+\n+        writer = new FilePerformanceStatistics(ctx);\n+\n+        proc = new DistributedProcess<>(ctx, PERFORMANCE_STATISTICS, start -> {\n+            if (start) {\n+                return ctx.closure().callLocalSafe(() -> {\n+                    if (start)\n+                        writer.start();\n+\n+                    return true;\n+                });\n+            }\n+\n+            return writer.stop().chain(f -> true);\n+        }, (uuid, res, err) -> {\n+            if (!F.isEmpty(err) && statisticsEnabled())\n+                writer.stop();\n+\n+            synchronized (mux) {\n+                GridFutureAdapter<Void> fut = reqFuts.get(uuid);\n+\n+                if (fut != null) {\n+                    if (!F.isEmpty(err))\n+                        fut.onDone(new IgniteException(\"Unable to process request [err=\" + err + ']'));\n+                    else\n+                        fut.onDone();\n+                }\n+            }\n+        });\n+    }\n+\n+    /** @return Performance statistics writer. */\n+    public IgnitePerformanceStatistics writer() {\n+        return writer;\n+    }\n+\n+    /** @return {@code True} if collecting performance statistics is enabled. */\n+    public boolean statisticsEnabled() {", "originalCommit": "3e2e2fbcf4a09661e3a7b6e64b919073c62d3f88", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAyMDk5MA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446020990", "bodyText": "Typo: let's rename it to startCollectStatistics()", "author": "nizhikov", "createdAt": "2020-06-26T07:42:32Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/PerformaceStatisticsProcessor.java", "diffHunk": "@@ -0,0 +1,232 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.Serializable;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteFeatures;\n+import org.apache.ignite.internal.IgniteInternalFuture;\n+import org.apache.ignite.internal.processors.GridProcessorAdapter;\n+import org.apache.ignite.internal.util.distributed.DistributedProcess;\n+import org.apache.ignite.internal.util.future.GridFinishedFuture;\n+import org.apache.ignite.internal.util.future.GridFutureAdapter;\n+import org.apache.ignite.internal.util.typedef.F;\n+import org.apache.ignite.lang.IgniteFuture;\n+import org.apache.ignite.lang.IgniteFutureCancelledException;\n+import org.apache.ignite.spi.discovery.DiscoveryDataBag;\n+\n+import static org.apache.ignite.internal.GridComponent.DiscoveryDataExchangeType.PERFORMANCE_STAT_PROC;\n+import static org.apache.ignite.internal.IgniteFeatures.allNodesSupports;\n+import static org.apache.ignite.internal.util.distributed.DistributedProcess.DistributedProcessType.PERFORMANCE_STATISTICS;\n+\n+/**\n+ * Performance statistics processor.\n+ * <p>\n+ * Manages collecting statistics.\n+ */\n+public class PerformaceStatisticsProcessor extends GridProcessorAdapter {\n+    /** Process to start/stop statistics. */\n+    private final DistributedProcess<Boolean, Boolean> proc;\n+\n+    /** Performance statistics writer. */\n+    private final FilePerformanceStatistics writer;\n+\n+    /** Synchronization mutex for request futures. */\n+    private final Object mux = new Object();\n+\n+    /** Enable/disable statistics request futures. */\n+    private final ConcurrentMap<UUID, GridFutureAdapter<Void>> reqFuts = new ConcurrentHashMap<>();\n+\n+    /** Disconnected flag. */\n+    private volatile boolean disconnected;\n+\n+    /** Stopped flag. */\n+    private volatile boolean stopped;\n+\n+    /** @param ctx Kernal context. */\n+    public PerformaceStatisticsProcessor(GridKernalContext ctx) {\n+        super(ctx);\n+\n+        writer = new FilePerformanceStatistics(ctx);\n+\n+        proc = new DistributedProcess<>(ctx, PERFORMANCE_STATISTICS, start -> {\n+            if (start) {\n+                return ctx.closure().callLocalSafe(() -> {\n+                    if (start)\n+                        writer.start();\n+\n+                    return true;\n+                });\n+            }\n+\n+            return writer.stop().chain(f -> true);\n+        }, (uuid, res, err) -> {\n+            if (!F.isEmpty(err) && statisticsEnabled())\n+                writer.stop();\n+\n+            synchronized (mux) {\n+                GridFutureAdapter<Void> fut = reqFuts.get(uuid);\n+\n+                if (fut != null) {\n+                    if (!F.isEmpty(err))\n+                        fut.onDone(new IgniteException(\"Unable to process request [err=\" + err + ']'));\n+                    else\n+                        fut.onDone();\n+                }\n+            }\n+        });\n+    }\n+\n+    /** @return Performance statistics writer. */\n+    public IgnitePerformanceStatistics writer() {\n+        return writer;\n+    }\n+\n+    /** @return {@code True} if collecting performance statistics is enabled. */\n+    public boolean statisticsEnabled() {\n+        return writer.performanceStatisticsEnabled();\n+    }\n+\n+    /**\n+     * Starts collecting performance statistics.\n+     *\n+     * @return Future to be completed on collecting started.\n+     */\n+    public IgniteInternalFuture<Void> startStatistics() {", "originalCommit": "3e2e2fbcf4a09661e3a7b6e64b919073c62d3f88", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA0NjE5OA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446046198", "bodyText": "Fixed.", "author": "NSAmelchev", "createdAt": "2020-06-26T08:33:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAyMDk5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAyMTEzNQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446021135", "bodyText": "Typo: let's rename it to stopCollectStatistics()", "author": "nizhikov", "createdAt": "2020-06-26T07:42:48Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/PerformaceStatisticsProcessor.java", "diffHunk": "@@ -0,0 +1,232 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.Serializable;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteFeatures;\n+import org.apache.ignite.internal.IgniteInternalFuture;\n+import org.apache.ignite.internal.processors.GridProcessorAdapter;\n+import org.apache.ignite.internal.util.distributed.DistributedProcess;\n+import org.apache.ignite.internal.util.future.GridFinishedFuture;\n+import org.apache.ignite.internal.util.future.GridFutureAdapter;\n+import org.apache.ignite.internal.util.typedef.F;\n+import org.apache.ignite.lang.IgniteFuture;\n+import org.apache.ignite.lang.IgniteFutureCancelledException;\n+import org.apache.ignite.spi.discovery.DiscoveryDataBag;\n+\n+import static org.apache.ignite.internal.GridComponent.DiscoveryDataExchangeType.PERFORMANCE_STAT_PROC;\n+import static org.apache.ignite.internal.IgniteFeatures.allNodesSupports;\n+import static org.apache.ignite.internal.util.distributed.DistributedProcess.DistributedProcessType.PERFORMANCE_STATISTICS;\n+\n+/**\n+ * Performance statistics processor.\n+ * <p>\n+ * Manages collecting statistics.\n+ */\n+public class PerformaceStatisticsProcessor extends GridProcessorAdapter {\n+    /** Process to start/stop statistics. */\n+    private final DistributedProcess<Boolean, Boolean> proc;\n+\n+    /** Performance statistics writer. */\n+    private final FilePerformanceStatistics writer;\n+\n+    /** Synchronization mutex for request futures. */\n+    private final Object mux = new Object();\n+\n+    /** Enable/disable statistics request futures. */\n+    private final ConcurrentMap<UUID, GridFutureAdapter<Void>> reqFuts = new ConcurrentHashMap<>();\n+\n+    /** Disconnected flag. */\n+    private volatile boolean disconnected;\n+\n+    /** Stopped flag. */\n+    private volatile boolean stopped;\n+\n+    /** @param ctx Kernal context. */\n+    public PerformaceStatisticsProcessor(GridKernalContext ctx) {\n+        super(ctx);\n+\n+        writer = new FilePerformanceStatistics(ctx);\n+\n+        proc = new DistributedProcess<>(ctx, PERFORMANCE_STATISTICS, start -> {\n+            if (start) {\n+                return ctx.closure().callLocalSafe(() -> {\n+                    if (start)\n+                        writer.start();\n+\n+                    return true;\n+                });\n+            }\n+\n+            return writer.stop().chain(f -> true);\n+        }, (uuid, res, err) -> {\n+            if (!F.isEmpty(err) && statisticsEnabled())\n+                writer.stop();\n+\n+            synchronized (mux) {\n+                GridFutureAdapter<Void> fut = reqFuts.get(uuid);\n+\n+                if (fut != null) {\n+                    if (!F.isEmpty(err))\n+                        fut.onDone(new IgniteException(\"Unable to process request [err=\" + err + ']'));\n+                    else\n+                        fut.onDone();\n+                }\n+            }\n+        });\n+    }\n+\n+    /** @return Performance statistics writer. */\n+    public IgnitePerformanceStatistics writer() {\n+        return writer;\n+    }\n+\n+    /** @return {@code True} if collecting performance statistics is enabled. */\n+    public boolean statisticsEnabled() {\n+        return writer.performanceStatisticsEnabled();\n+    }\n+\n+    /**\n+     * Starts collecting performance statistics.\n+     *\n+     * @return Future to be completed on collecting started.\n+     */\n+    public IgniteInternalFuture<Void> startStatistics() {\n+        if (!allNodesSupports(ctx.discovery().allNodes(), IgniteFeatures.PERFORMANCE_STATISTICS)) {\n+            return new GridFinishedFuture<>(\n+                new IllegalStateException(\"Not all nodes in the cluster support collecting performance statistics.\"));\n+        }\n+\n+        GridFutureAdapter<Void> fut = new GridFutureAdapter<>();\n+\n+        UUID uuid = UUID.randomUUID();\n+\n+        synchronized (mux) {\n+            if (disconnected || stopped) {\n+                return new GridFinishedFuture<>(\n+                    new IgniteFutureCancelledException(\"Node \" + (stopped ? \"stopped\" : \"disconnected\")));\n+            }\n+\n+            reqFuts.put(uuid, fut);\n+        }\n+\n+        proc.start(uuid, true);\n+\n+        return fut;\n+    }\n+\n+    /**\n+     * Stops collecting performance statistics.\n+     *\n+     * @return Future to be completed on collecting stopped.\n+     */\n+    public IgniteInternalFuture<Void> stopStatistics() {", "originalCommit": "3e2e2fbcf4a09661e3a7b6e64b919073c62d3f88", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA0NjIyMA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446046220", "bodyText": "Fixed.", "author": "NSAmelchev", "createdAt": "2020-06-26T08:33:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAyMTEzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAzNjc0MQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446036741", "bodyText": "Let's encapsulate writer and introduce methods of this interface directly in the processor:\nWe may want to filter out some event later or have several writers, etc.\nThese changes should go directly in the processor and don't bother writer or core code.\n                    ctx.performanceStatistics().task(\n                        ses.getId(),\n                        ses.getTaskName(),\n                        ses.getStartTime(),\n                        U.currentTimeMillis() - ses.getStartTime(),\n                        worker.affPartId());", "author": "nizhikov", "createdAt": "2020-06-26T08:15:28Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/PerformaceStatisticsProcessor.java", "diffHunk": "@@ -0,0 +1,232 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.Serializable;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteFeatures;\n+import org.apache.ignite.internal.IgniteInternalFuture;\n+import org.apache.ignite.internal.processors.GridProcessorAdapter;\n+import org.apache.ignite.internal.util.distributed.DistributedProcess;\n+import org.apache.ignite.internal.util.future.GridFinishedFuture;\n+import org.apache.ignite.internal.util.future.GridFutureAdapter;\n+import org.apache.ignite.internal.util.typedef.F;\n+import org.apache.ignite.lang.IgniteFuture;\n+import org.apache.ignite.lang.IgniteFutureCancelledException;\n+import org.apache.ignite.spi.discovery.DiscoveryDataBag;\n+\n+import static org.apache.ignite.internal.GridComponent.DiscoveryDataExchangeType.PERFORMANCE_STAT_PROC;\n+import static org.apache.ignite.internal.IgniteFeatures.allNodesSupports;\n+import static org.apache.ignite.internal.util.distributed.DistributedProcess.DistributedProcessType.PERFORMANCE_STATISTICS;\n+\n+/**\n+ * Performance statistics processor.\n+ * <p>\n+ * Manages collecting statistics.\n+ */\n+public class PerformaceStatisticsProcessor extends GridProcessorAdapter {\n+    /** Process to start/stop statistics. */\n+    private final DistributedProcess<Boolean, Boolean> proc;\n+\n+    /** Performance statistics writer. */\n+    private final FilePerformanceStatistics writer;\n+\n+    /** Synchronization mutex for request futures. */\n+    private final Object mux = new Object();\n+\n+    /** Enable/disable statistics request futures. */\n+    private final ConcurrentMap<UUID, GridFutureAdapter<Void>> reqFuts = new ConcurrentHashMap<>();\n+\n+    /** Disconnected flag. */\n+    private volatile boolean disconnected;\n+\n+    /** Stopped flag. */\n+    private volatile boolean stopped;\n+\n+    /** @param ctx Kernal context. */\n+    public PerformaceStatisticsProcessor(GridKernalContext ctx) {\n+        super(ctx);\n+\n+        writer = new FilePerformanceStatistics(ctx);\n+\n+        proc = new DistributedProcess<>(ctx, PERFORMANCE_STATISTICS, start -> {\n+            if (start) {\n+                return ctx.closure().callLocalSafe(() -> {\n+                    if (start)\n+                        writer.start();\n+\n+                    return true;\n+                });\n+            }\n+\n+            return writer.stop().chain(f -> true);\n+        }, (uuid, res, err) -> {\n+            if (!F.isEmpty(err) && statisticsEnabled())\n+                writer.stop();\n+\n+            synchronized (mux) {\n+                GridFutureAdapter<Void> fut = reqFuts.get(uuid);\n+\n+                if (fut != null) {\n+                    if (!F.isEmpty(err))\n+                        fut.onDone(new IgniteException(\"Unable to process request [err=\" + err + ']'));\n+                    else\n+                        fut.onDone();\n+                }\n+            }\n+        });\n+    }\n+\n+    /** @return Performance statistics writer. */\n+    public IgnitePerformanceStatistics writer() {", "originalCommit": "3e2e2fbcf4a09661e3a7b6e64b919073c62d3f88", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA0NjM0Mg==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446046342", "bodyText": "Writer encapsulated.", "author": "NSAmelchev", "createdAt": "2020-06-26T08:34:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAzNjc0MQ=="}], "type": "inlineReview"}, {"oid": "bd333453d3723a39cf57a303b445de357b23d98a", "url": "https://github.com/apache/ignite/commit/bd333453d3723a39cf57a303b445de357b23d98a", "message": "Renaming", "committedDate": "2020-06-26T08:28:03Z", "type": "commit"}, {"oid": "058cd7af8f01842c00dbd4241586b305e5a69166", "url": "https://github.com/apache/ignite/commit/058cd7af8f01842c00dbd4241586b305e5a69166", "message": "Writer encapsulate", "committedDate": "2020-06-26T08:33:13Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA2MzUzNQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446063535", "bodyText": "Typo: plese, revert this change", "author": "nizhikov", "createdAt": "2020-06-26T09:08:12Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/metric/GridMetricManager.java", "diffHunk": "@@ -58,8 +58,8 @@\n import org.apache.ignite.spi.metric.HistogramMetric;\n import org.apache.ignite.spi.metric.Metric;\n import org.apache.ignite.spi.metric.MetricExporterSpi;\n-import org.apache.ignite.spi.metric.ReadOnlyMetricRegistry;", "originalCommit": "058cd7af8f01842c00dbd4241586b305e5a69166", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA3NzEzNA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446077134", "bodyText": "Let's rename this to FilePerformanceStatisticsReader", "author": "nizhikov", "createdAt": "2020-06-26T09:35:02Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWalker.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Path;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.processors.performancestatistics.IgnitePerformanceStatistics.CacheOperationType;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.GridUnsafe;\n+import org.apache.ignite.lang.IgniteUuid;\n+\n+import static java.nio.ByteBuffer.allocateDirect;\n+import static java.nio.ByteOrder.nativeOrder;\n+import static org.apache.ignite.internal.processors.performancestatistics.FilePerformanceStatistics.readIgniteUuid;\n+import static org.apache.ignite.internal.processors.performancestatistics.FilePerformanceStatistics.readUuid;\n+\n+/**\n+ * Walker over the performance statistics file.\n+ *\n+ * @see FilePerformanceStatistics\n+ */\n+public class FilePerformanceStatisticsWalker {", "originalCommit": "058cd7af8f01842c00dbd4241586b305e5a69166", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA5Mjc4MQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446092781", "bodyText": "Fixed.", "author": "NSAmelchev", "createdAt": "2020-06-26T10:07:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA3NzEzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA3NzMzMw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446077333", "bodyText": "Let's rename this to read", "author": "nizhikov", "createdAt": "2020-06-26T09:35:29Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWalker.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Path;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.processors.performancestatistics.IgnitePerformanceStatistics.CacheOperationType;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.GridUnsafe;\n+import org.apache.ignite.lang.IgniteUuid;\n+\n+import static java.nio.ByteBuffer.allocateDirect;\n+import static java.nio.ByteOrder.nativeOrder;\n+import static org.apache.ignite.internal.processors.performancestatistics.FilePerformanceStatistics.readIgniteUuid;\n+import static org.apache.ignite.internal.processors.performancestatistics.FilePerformanceStatistics.readUuid;\n+\n+/**\n+ * Walker over the performance statistics file.\n+ *\n+ * @see FilePerformanceStatistics\n+ */\n+public class FilePerformanceStatisticsWalker {\n+    /** File read buffer size. */\n+    private static final int READ_BUFFER_SIZE = 8 * 1024 * 1024;\n+\n+    /** IO factory. */\n+    private static final RandomAccessFileIOFactory ioFactory = new RandomAccessFileIOFactory();\n+\n+    /**\n+     * Walks over performance statistics file.\n+     *\n+     * @param file Performance statistics file.\n+     * @param handlers Handlers to process deserialized operation.\n+     */\n+    public static void walkFile(Path file, IgnitePerformanceStatistics... handlers) throws IOException {", "originalCommit": "058cd7af8f01842c00dbd4241586b305e5a69166", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA5Mjc2MQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446092761", "bodyText": "Fixed.", "author": "NSAmelchev", "createdAt": "2020-06-26T10:06:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA3NzMzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA3ODU4Ng==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446078586", "bodyText": "Let's rewrite it to the while (des.deserialize(buf));", "author": "nizhikov", "createdAt": "2020-06-26T09:38:02Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWalker.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Path;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.processors.performancestatistics.IgnitePerformanceStatistics.CacheOperationType;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.GridUnsafe;\n+import org.apache.ignite.lang.IgniteUuid;\n+\n+import static java.nio.ByteBuffer.allocateDirect;\n+import static java.nio.ByteOrder.nativeOrder;\n+import static org.apache.ignite.internal.processors.performancestatistics.FilePerformanceStatistics.readIgniteUuid;\n+import static org.apache.ignite.internal.processors.performancestatistics.FilePerformanceStatistics.readUuid;\n+\n+/**\n+ * Walker over the performance statistics file.\n+ *\n+ * @see FilePerformanceStatistics\n+ */\n+public class FilePerformanceStatisticsWalker {\n+    /** File read buffer size. */\n+    private static final int READ_BUFFER_SIZE = 8 * 1024 * 1024;\n+\n+    /** IO factory. */\n+    private static final RandomAccessFileIOFactory ioFactory = new RandomAccessFileIOFactory();\n+\n+    /**\n+     * Walks over performance statistics file.\n+     *\n+     * @param file Performance statistics file.\n+     * @param handlers Handlers to process deserialized operation.\n+     */\n+    public static void walkFile(Path file, IgnitePerformanceStatistics... handlers) throws IOException {\n+        ByteBuffer buf = allocateDirect(READ_BUFFER_SIZE).order(nativeOrder());\n+\n+        try (\n+            FileIO io = ioFactory.create(file.toFile());\n+            PerformanceStatisticsDeserializer des = new PerformanceStatisticsDeserializer(handlers)\n+        ) {\n+            while (true) {\n+                int read = io.read(buf);\n+\n+                buf.flip();\n+\n+                if (read <= 0)\n+                    break;\n+\n+                while (true) {", "originalCommit": "058cd7af8f01842c00dbd4241586b305e5a69166", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA5Mjc0Mg==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446092742", "bodyText": "Fixed.", "author": "NSAmelchev", "createdAt": "2020-06-26T10:06:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA3ODU4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA4OTAyMg==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446089022", "bodyText": "We should support the case when file represents a directory", "author": "nizhikov", "createdAt": "2020-06-26T09:59:03Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWalker.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Path;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.processors.performancestatistics.IgnitePerformanceStatistics.CacheOperationType;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.GridUnsafe;\n+import org.apache.ignite.lang.IgniteUuid;\n+\n+import static java.nio.ByteBuffer.allocateDirect;\n+import static java.nio.ByteOrder.nativeOrder;\n+import static org.apache.ignite.internal.processors.performancestatistics.FilePerformanceStatistics.readIgniteUuid;\n+import static org.apache.ignite.internal.processors.performancestatistics.FilePerformanceStatistics.readUuid;\n+\n+/**\n+ * Walker over the performance statistics file.\n+ *\n+ * @see FilePerformanceStatistics\n+ */\n+public class FilePerformanceStatisticsWalker {\n+    /** File read buffer size. */\n+    private static final int READ_BUFFER_SIZE = 8 * 1024 * 1024;\n+\n+    /** IO factory. */\n+    private static final RandomAccessFileIOFactory ioFactory = new RandomAccessFileIOFactory();\n+\n+    /**\n+     * Walks over performance statistics file.\n+     *\n+     * @param file Performance statistics file.", "originalCommit": "058cd7af8f01842c00dbd4241586b305e5a69166", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjExOTk4Mg==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446119982", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-06-26T11:11:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjA4OTAyMg=="}], "type": "inlineReview"}, {"oid": "5d3fa84d04e82a831b48190409aa75fea74794f2", "url": "https://github.com/apache/ignite/commit/5d3fa84d04e82a831b48190409aa75fea74794f2", "message": "Review fixes", "committedDate": "2020-06-26T10:00:30Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEwMTc5Ng==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446101796", "bodyText": "Typo: finally should be on new line.", "author": "nizhikov", "createdAt": "2020-06-26T10:26:51Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/cache/query/GridCacheDistributedQueryManager.java", "diffHunk": "@@ -198,54 +201,74 @@ protected void removeQueryFuture(long reqId) {\n         assert req.mvccSnapshot() != null || !cctx.mvccEnabled() || req.cancel() ||\n             (req.type() == null && !req.fields()) : req; // Last assertion means next page request.\n \n-        if (req.cancel()) {\n-            cancelIds.add(new CancelMessageId(req.id(), sndId));\n+        boolean performanceStatsEnabled = cctx.kernalContext().performanceStatistics().enabled();\n \n-            if (req.fields())\n-                removeFieldsQueryResult(sndId, req.id());\n-            else\n-                removeQueryResult(sndId, req.id());\n-        }\n-        else {\n-            if (!cancelIds.contains(new CancelMessageId(req.id(), sndId))) {\n-                if (!F.eq(req.cacheName(), cctx.name())) {\n-                    GridCacheQueryResponse res = new GridCacheQueryResponse(\n-                        cctx.cacheId(),\n-                        req.id(),\n-                        new IgniteCheckedException(\"Received request for incorrect cache [expected=\" + cctx.name() +\n-                            \", actual=\" + req.cacheName()),\n-                        cctx.deploymentEnabled());\n+        if (performanceStatsEnabled)\n+            IoStatisticsQueryHelper.startGatheringQueryStatistics();\n \n-                    sendQueryResponse(sndId, res, 0);\n-                }\n-                else {\n-                    threads.put(req.id(), Thread.currentThread());\n+        try {\n+            if (req.cancel()) {\n+                cancelIds.add(new CancelMessageId(req.id(), sndId));\n \n-                    try {\n-                        GridCacheQueryInfo info = distributedQueryInfo(sndId, req);\n+                if (req.fields())\n+                    removeFieldsQueryResult(sndId, req.id());\n+                else\n+                    removeQueryResult(sndId, req.id());\n+            }\n+            else {\n+                if (!cancelIds.contains(new CancelMessageId(req.id(), sndId))) {\n+                    if (!F.eq(req.cacheName(), cctx.name())) {\n+                        GridCacheQueryResponse res = new GridCacheQueryResponse(\n+                            cctx.cacheId(),\n+                            req.id(),\n+                            new IgniteCheckedException(\"Received request for incorrect cache [expected=\" + cctx.name() +\n+                                \", actual=\" + req.cacheName()),\n+                            cctx.deploymentEnabled());\n+\n+                        sendQueryResponse(sndId, res, 0);\n+                    }\n+                    else {\n+                        threads.put(req.id(), Thread.currentThread());\n \n-                        if (info == null)\n-                            return;\n+                        try {\n+                            GridCacheQueryInfo info = distributedQueryInfo(sndId, req);\n \n-                        if (req.fields())\n-                            runFieldsQuery(info);\n-                        else\n-                            runQuery(info);\n-                    }\n-                    catch (Throwable e) {\n-                        U.error(log(), \"Failed to run query.\", e);\n+                            if (info == null)\n+                                return;\n+\n+                            if (req.fields())\n+                                runFieldsQuery(info);\n+                            else\n+                                runQuery(info);\n+                        }\n+                        catch (Throwable e) {\n+                            U.error(log(), \"Failed to run query.\", e);\n \n-                        sendQueryResponse(sndId, new GridCacheQueryResponse(cctx.cacheId(), req.id(), e.getCause(),\n-                            cctx.deploymentEnabled()), 0);\n+                            sendQueryResponse(sndId, new GridCacheQueryResponse(cctx.cacheId(), req.id(), e.getCause(),\n+                                cctx.deploymentEnabled()), 0);\n \n-                        if (e instanceof Error)\n-                            throw (Error)e;\n-                    }\n-                    finally {\n-                        threads.remove(req.id());\n+                            if (e instanceof Error)\n+                                throw (Error)e;\n+                        }\n+                        finally {\n+                            threads.remove(req.id());\n+                        }\n                     }\n                 }\n             }\n+        } finally {", "originalCommit": "5d3fa84d04e82a831b48190409aa75fea74794f2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEyMDExMA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446120110", "bodyText": "Fixed.", "author": "NSAmelchev", "createdAt": "2020-06-26T11:11:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEwMTc5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEwOTM4Mg==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446109382", "bodyText": "Typo: this can be rewritten as else if (!cancelIds.contains(new CancelMessageId(req.id(), sndId))) { to reduce one indentation level.", "author": "nizhikov", "createdAt": "2020-06-26T10:45:01Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/cache/query/GridCacheDistributedQueryManager.java", "diffHunk": "@@ -198,54 +201,74 @@ protected void removeQueryFuture(long reqId) {\n         assert req.mvccSnapshot() != null || !cctx.mvccEnabled() || req.cancel() ||\n             (req.type() == null && !req.fields()) : req; // Last assertion means next page request.\n \n-        if (req.cancel()) {\n-            cancelIds.add(new CancelMessageId(req.id(), sndId));\n+        boolean performanceStatsEnabled = cctx.kernalContext().performanceStatistics().enabled();\n \n-            if (req.fields())\n-                removeFieldsQueryResult(sndId, req.id());\n-            else\n-                removeQueryResult(sndId, req.id());\n-        }\n-        else {\n-            if (!cancelIds.contains(new CancelMessageId(req.id(), sndId))) {\n-                if (!F.eq(req.cacheName(), cctx.name())) {\n-                    GridCacheQueryResponse res = new GridCacheQueryResponse(\n-                        cctx.cacheId(),\n-                        req.id(),\n-                        new IgniteCheckedException(\"Received request for incorrect cache [expected=\" + cctx.name() +\n-                            \", actual=\" + req.cacheName()),\n-                        cctx.deploymentEnabled());\n+        if (performanceStatsEnabled)\n+            IoStatisticsQueryHelper.startGatheringQueryStatistics();\n \n-                    sendQueryResponse(sndId, res, 0);\n-                }\n-                else {\n-                    threads.put(req.id(), Thread.currentThread());\n+        try {\n+            if (req.cancel()) {\n+                cancelIds.add(new CancelMessageId(req.id(), sndId));\n \n-                    try {\n-                        GridCacheQueryInfo info = distributedQueryInfo(sndId, req);\n+                if (req.fields())\n+                    removeFieldsQueryResult(sndId, req.id());\n+                else\n+                    removeQueryResult(sndId, req.id());\n+            }\n+            else {", "originalCommit": "5d3fa84d04e82a831b48190409aa75fea74794f2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEyMDAyMw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446120023", "bodyText": "Fixed.", "author": "NSAmelchev", "createdAt": "2020-06-26T11:11:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEwOTM4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjExMzE5MQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446113191", "bodyText": "Why we do this inside if (!worker.isInternal()) {?", "author": "nizhikov", "createdAt": "2020-06-26T10:54:41Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/job/GridJobProcessor.java", "diffHunk": "@@ -2020,6 +2020,14 @@ else if (removeFromActive(jobWorker)) {\n                         rwLock.readUnlock();\n                     }\n                 }\n+\n+                if (ctx.performanceStatistics().enabled()) {", "originalCommit": "5d3fa84d04e82a831b48190409aa75fea74794f2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEyNTAzNw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446125037", "bodyText": "Fixed.", "author": "NSAmelchev", "createdAt": "2020-06-26T11:22:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjExMzE5MQ=="}], "type": "inlineReview"}, {"oid": "4adb5737a6d7627914ae69b81999e7c97541609c", "url": "https://github.com/apache/ignite/commit/4adb5737a6d7627914ae69b81999e7c97541609c", "message": "Multiple files reader", "committedDate": "2020-06-26T11:07:43Z", "type": "commit"}, {"oid": "1f04f08d9553fd8e2a8d249c64c595d15afc15e8", "url": "https://github.com/apache/ignite/commit/1f04f08d9553fd8e2a8d249c64c595d15afc15e8", "message": "Review fixes.", "committedDate": "2020-06-26T11:11:10Z", "type": "commit"}, {"oid": "4e3eb66f7f3b2335cee6533487d27afd3a8739cb", "url": "https://github.com/apache/ignite/commit/4e3eb66f7f3b2335cee6533487d27afd3a8739cb", "message": "Merge branch 'master' into ignite-12666\n\n# Conflicts:\n#\tmodules/core/src/main/java/org/apache/ignite/internal/IgniteFeatures.java", "committedDate": "2020-06-26T11:18:09Z", "type": "commit"}, {"oid": "9e5ac5f2e05611ff990a33730c7dbf91cc5ef3c4", "url": "https://github.com/apache/ignite/commit/9e5ac5f2e05611ff990a33730c7dbf91cc5ef3c4", "message": "Write internal tasks", "committedDate": "2020-06-26T11:22:19Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEzMTUyMQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446131521", "bodyText": "Let's rename this to FilePerformanceStatisticsWriter", "author": "nizhikov", "createdAt": "2020-06-26T11:38:48Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatistics.java", "diffHunk": "@@ -0,0 +1,633 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInternalFuture;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.future.GridFinishedFuture;\n+import org.apache.ignite.internal.util.future.GridFutureAdapter;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatistics implements IgnitePerformanceStatistics {", "originalCommit": "9e5ac5f2e05611ff990a33730c7dbf91cc5ef3c4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0MTQ5Mg==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446141492", "bodyText": "Done", "author": "NSAmelchev", "createdAt": "2020-06-26T12:02:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEzMTUyMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEzNjIxNw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446136217", "bodyText": "This interface should be in org.apache.ignite.mxbean.\nAlso, let's mark all public API with the @IgniteExperimental.", "author": "nizhikov", "createdAt": "2020-06-26T11:50:15Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/IgnitePerformanceStatisticsMBean.java", "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.mxbean.MXBeanDescription;\n+\n+/**\n+ * MBean that provides access to performance statistics management.\n+ */\n+@MXBeanDescription(\"MBean provide access to performance statistics management.\")\n+public interface IgnitePerformanceStatisticsMBean {", "originalCommit": "9e5ac5f2e05611ff990a33730c7dbf91cc5ef3c4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEzNzc2OQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446137769", "bodyText": "Let's renami this to PerformanceStatisticsMBean.", "author": "nizhikov", "createdAt": "2020-06-26T11:53:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEzNjIxNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0MTU0Mw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446141543", "bodyText": "Done", "author": "NSAmelchev", "createdAt": "2020-06-26T12:02:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEzNjIxNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEzNzQ3Mg==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446137472", "bodyText": "Typo: MbeanImpl -> MBeanImpl", "author": "nizhikov", "createdAt": "2020-06-26T11:53:19Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/IgnitePerformanceStatisticsMbeanImpl.java", "diffHunk": "@@ -0,0 +1,49 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.internal.GridKernalContext;\n+\n+/**\n+ * {@link IgnitePerformanceStatisticsMBean} implementation.\n+ */\n+public class IgnitePerformanceStatisticsMbeanImpl implements IgnitePerformanceStatisticsMBean {", "originalCommit": "9e5ac5f2e05611ff990a33730c7dbf91cc5ef3c4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEzODAzOA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446138038", "bodyText": "Let's rename this to PerformanceStatisticsMBeanImpl.", "author": "nizhikov", "createdAt": "2020-06-26T11:54:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEzNzQ3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0MTU5Ng==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r446141596", "bodyText": "Fixed", "author": "NSAmelchev", "createdAt": "2020-06-26T12:02:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEzNzQ3Mg=="}], "type": "inlineReview"}, {"oid": "6ba68bb6e5ea562b5a91db752d7bc4fc441f14e2", "url": "https://github.com/apache/ignite/commit/6ba68bb6e5ea562b5a91db752d7bc4fc441f14e2", "message": "Review fixes + stopping on max file size fix", "committedDate": "2020-06-26T12:01:52Z", "type": "commit"}, {"oid": "5b1ec0bcbf3473670a9227c5e8ba39c58c0c914c", "url": "https://github.com/apache/ignite/commit/5b1ec0bcbf3473670a9227c5e8ba39c58c0c914c", "message": "Review fixes", "committedDate": "2020-06-26T12:11:10Z", "type": "commit"}, {"oid": "5f979b41d84c7751647c3a4582932f5d8ea275eb", "url": "https://github.com/apache/ignite/commit/5f979b41d84c7751647c3a4582932f5d8ea275eb", "message": "Review fixes", "committedDate": "2020-06-26T12:12:17Z", "type": "commit"}, {"oid": "0b4df908ad69b3383dcf03cdd7119f4b04a84d06", "url": "https://github.com/apache/ignite/commit/0b4df908ad69b3383dcf03cdd7119f4b04a84d06", "message": "Fix cancelling req future", "committedDate": "2020-06-26T12:17:40Z", "type": "commit"}, {"oid": "f94020f754d002283a3b7dbb7f8578e54af34582", "url": "https://github.com/apache/ignite/commit/f94020f754d002283a3b7dbb7f8578e54af34582", "message": "Codestyle fixes", "committedDate": "2020-06-26T14:01:03Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzAyNTY4Nw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r447025687", "bodyText": "Let's rename this to PerformanceStatisticsHandler.\nAlso, this is part of the public API, right?\nIf yes, then\n\nit should be located in org.apache.ignite.performancestatistics.\nlet's mark this with the @IgniteExperimental.", "author": "nizhikov", "createdAt": "2020-06-29T14:43:24Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/IgnitePerformanceStatistics.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.util.UUID;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.lang.IgniteUuid;\n+\n+/**\n+ * The interface represents performance statistics operations collection for purposes of troubleshooting and\n+ * performance analysis.\n+ */\n+public interface IgnitePerformanceStatistics {", "originalCommit": "0b4df908ad69b3383dcf03cdd7119f4b04a84d06", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzAzMjM4Mg==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r447032382", "bodyText": "Why do we need DistributedProcess here?\nWhat is the \"process\" here in the first place?\nLet's implement this as 'DistributedMetaStorage' listener.", "author": "nizhikov", "createdAt": "2020-06-29T14:52:26Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/PerformaceStatisticsProcessor.java", "diffHunk": "@@ -0,0 +1,264 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.Serializable;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteFeatures;\n+import org.apache.ignite.internal.IgniteInternalFuture;\n+import org.apache.ignite.internal.processors.GridProcessorAdapter;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.distributed.DistributedProcess;\n+import org.apache.ignite.internal.util.future.GridFinishedFuture;\n+import org.apache.ignite.internal.util.future.GridFutureAdapter;\n+import org.apache.ignite.internal.util.typedef.F;\n+import org.apache.ignite.lang.IgniteFuture;\n+import org.apache.ignite.lang.IgniteFutureCancelledException;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.spi.discovery.DiscoveryDataBag;\n+\n+import static org.apache.ignite.internal.GridComponent.DiscoveryDataExchangeType.PERFORMANCE_STAT_PROC;\n+import static org.apache.ignite.internal.IgniteFeatures.allNodesSupports;\n+import static org.apache.ignite.internal.util.distributed.DistributedProcess.DistributedProcessType.PERFORMANCE_STATISTICS;\n+\n+/**\n+ * Performance statistics processor.\n+ * <p>\n+ * Manages collecting statistics.\n+ */\n+public class PerformaceStatisticsProcessor extends GridProcessorAdapter implements IgnitePerformanceStatistics {\n+    /** Process to start/stop statistics. */\n+    private final DistributedProcess<Boolean, Boolean> proc;\n+\n+    /** Performance statistics writer. */\n+    private final FilePerformanceStatisticsWriter writer;\n+\n+    /** Synchronization mutex for request futures. */\n+    private final Object mux = new Object();\n+\n+    /** Enable/disable statistics request futures. */\n+    private final ConcurrentMap<UUID, GridFutureAdapter<Void>> reqFuts = new ConcurrentHashMap<>();\n+\n+    /** Disconnected flag. */\n+    private volatile boolean disconnected;\n+\n+    /** Stopped flag. */\n+    private volatile boolean stopped;\n+\n+    /** @param ctx Kernal context. */\n+    public PerformaceStatisticsProcessor(GridKernalContext ctx) {\n+        super(ctx);\n+\n+        writer = new FilePerformanceStatisticsWriter(ctx);\n+\n+        proc = new DistributedProcess<>(ctx, PERFORMANCE_STATISTICS, start -> {", "originalCommit": "0b4df908ad69b3383dcf03cdd7119f4b04a84d06", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzA0NzIwNQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r447047205", "bodyText": "We can use DistributedBooleanProperty approach.", "author": "nizhikov", "createdAt": "2020-06-29T15:12:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzAzMjM4Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODg3NzM0OA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r448877348", "bodyText": "I have mplemented this as 'DistributedMetaStorage' listener.", "author": "NSAmelchev", "createdAt": "2020-07-02T09:37:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzAzMjM4Mg=="}], "type": "inlineReview"}, {"oid": "f9c0c32907ae7f4ef428b78d5dfee2321bb2b892", "url": "https://github.com/apache/ignite/commit/f9c0c32907ae7f4ef428b78d5dfee2321bb2b892", "message": "Use metastore + renaming", "committedDate": "2020-06-30T05:39:28Z", "type": "commit"}, {"oid": "7196cbde628798b4af6b1c4c6b5135756cad4c78", "url": "https://github.com/apache/ignite/commit/7196cbde628798b4af6b1c4c6b5135756cad4c78", "message": "Review fixes", "committedDate": "2020-06-30T05:53:19Z", "type": "commit"}, {"oid": "48baa82559a312f716b444acfc20aa46aec03ed3", "url": "https://github.com/apache/ignite/commit/48baa82559a312f716b444acfc20aa46aec03ed3", "message": "Review fixes", "committedDate": "2020-06-30T05:58:07Z", "type": "commit"}, {"oid": "08f8f49a08371437f7083607919e2623647cb491", "url": "https://github.com/apache/ignite/commit/08f8f49a08371437f7083607919e2623647cb491", "message": "Review fixes", "committedDate": "2020-06-30T08:23:48Z", "type": "commit"}, {"oid": "efd562d555f9f6963cd93f441800b2a420c7ba7f", "url": "https://github.com/apache/ignite/commit/efd562d555f9f6963cd93f441800b2a420c7ba7f", "message": "Review fixes", "committedDate": "2020-06-30T08:25:52Z", "type": "commit"}, {"oid": "e7e8511a51577587a8a4a7128fe429a9af281981", "url": "https://github.com/apache/ignite/commit/e7e8511a51577587a8a4a7128fe429a9af281981", "message": "Fix codestyle", "committedDate": "2020-07-02T06:43:27Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODg1MDc3Ng==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r448850776", "bodyText": "AFAIK we don't need package descriptions for internal packages.\nLet's remove this file.", "author": "nizhikov", "createdAt": "2020-07-02T08:53:02Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/package-info.java", "diffHunk": "@@ -0,0 +1,23 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+/**\n+ * <!-- Package description. -->\n+ * Contains classes for Ignite performance statistics.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;", "originalCommit": "e7e8511a51577587a8a4a7128fe429a9af281981", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODg2MzEzNg==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r448863136", "bodyText": "I have added it cause wiki says to add info files despite internal it or no:\nhttps://cwiki.apache.org/confluence/display/IGNITE/How+to+Contribute#HowtoContribute-Creation\nhttps://cwiki.apache.org/confluence/display/IGNITE/How+to+Contribute#HowtoContribute-package-info.java", "author": "NSAmelchev", "createdAt": "2020-07-02T09:13:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODg1MDc3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODg2NTk0MQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r448865941", "bodyText": "We don't have this file for any other internal package.\nSo I think it's OK to remove it here.", "author": "nizhikov", "createdAt": "2020-07-02T09:18:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODg1MDc3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODg3Njg0OQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r448876849", "bodyText": "Ok. Removed.", "author": "NSAmelchev", "createdAt": "2020-07-02T09:36:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODg1MDc3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODg1MTEzNg==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r448851136", "bodyText": "AFAIK we don't need package descriptions for internal packages.\nLet's remove this file.", "author": "nizhikov", "createdAt": "2020-07-02T08:53:42Z", "path": "modules/core/src/test/java/org/apache/ignite/internal/performancestatistics/package-info.java", "diffHunk": "@@ -0,0 +1,23 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+/**\n+ * <!-- Package description. -->\n+ * Ignite performance statistics tests.\n+ */\n+\n+package org.apache.ignite.internal.performancestatistics;", "originalCommit": "e7e8511a51577587a8a4a7128fe429a9af281981", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODg3NjkwNw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r448876907", "bodyText": "Removed.", "author": "NSAmelchev", "createdAt": "2020-07-02T09:36:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODg1MTEzNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODg1NTYzOA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r448855638", "bodyText": "Let's rename this to started", "author": "nizhikov", "createdAt": "2020-07-02T09:00:52Z", "path": "modules/core/src/main/java/org/apache/ignite/mxbean/PerformanceStatisticsMBean.java", "diffHunk": "@@ -0,0 +1,47 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.mxbean;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.internal.processors.performancestatistics.FilePerformanceStatisticsWriter;\n+import org.apache.ignite.lang.IgniteExperimental;\n+\n+/**\n+ * MBean that provides access to performance statistics management.\n+ */\n+@IgniteExperimental\n+@MXBeanDescription(\"MBean provide access to performance statistics management.\")\n+public interface PerformanceStatisticsMBean {\n+    /**\n+     * Start collecting performance statistics in the cluster with default settings.\n+     *\n+     * @see FilePerformanceStatisticsWriter#DFLT_FILE_MAX_SIZE\n+     * @see FilePerformanceStatisticsWriter#DFLT_BUFFER_SIZE\n+     * @see FilePerformanceStatisticsWriter#DFLT_FLUSH_SIZE\n+     */\n+    @MXBeanDescription(\"Start collecting performance statistics in the cluster.\")\n+    public void start() throws IgniteCheckedException;\n+\n+    /** Stop collecting performance statistics in the cluster. */\n+    @MXBeanDescription(\"Stop collecting performance statistics in the cluster.\")\n+    public void stop() throws IgniteCheckedException;\n+\n+    /** @return {@code True} if collecting performance statistics is enabled. */\n+    @MXBeanDescription(\"True if collecting performance statistics is enabled.\")\n+    public boolean enabled();", "originalCommit": "e7e8511a51577587a8a4a7128fe429a9af281981", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODg2ODQ0NA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r448868444", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-02T09:22:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODg1NTYzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODg1NjY5Ng==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r448856696", "bodyText": "Let's rename this to CacheOperation", "author": "nizhikov", "createdAt": "2020-07-02T09:02:36Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/PerformanceStatisticsHandler.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.util.UUID;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.lang.IgniteUuid;\n+\n+/**\n+ * The interface represents performance statistics operations collection for purposes of troubleshooting and\n+ * performance analysis.\n+ */\n+public interface PerformanceStatisticsHandler {\n+    /**\n+     * @param nodeId Node id.\n+     * @param type Operation type.\n+     * @param cacheId Cache id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     */\n+    void cacheOperation(UUID nodeId, CacheOperationType type, int cacheId, long startTime, long duration);\n+\n+    /**\n+     * @param nodeId Node id.\n+     * @param cacheIds Cache IDs.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param commit {@code True} if commited.\n+     */\n+    void transaction(UUID nodeId, GridIntList cacheIds, long startTime, long duration, boolean commit);\n+\n+    /**\n+     * @param nodeId Node id.\n+     * @param type Cache query type.\n+     * @param text Query text in case of SQL query. Cache name in case of SCAN query.\n+     * @param id Query id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param success Success flag.\n+     */\n+    void query(UUID nodeId, GridCacheQueryType type, String text, long id, long startTime, long duration,\n+        boolean success);\n+\n+    /**\n+     * @param nodeId Node id.\n+     * @param type Cache query type.\n+     * @param queryNodeId Originating node id.\n+     * @param id Query id.\n+     * @param logicalReads Number of logical reads.\n+     * @param physicalReads Number of physical reads.\n+     */\n+    void queryReads(UUID nodeId, GridCacheQueryType type, UUID queryNodeId, long id, long logicalReads,\n+        long physicalReads);\n+\n+    /**\n+     * @param nodeId Node id.\n+     * @param sesId Session id.\n+     * @param taskName Task name.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration.\n+     * @param affPartId Affinity partition id.\n+     */\n+    void task(UUID nodeId, IgniteUuid sesId, String taskName, long startTime, long duration, int affPartId);\n+\n+    /**\n+     * @param nodeId Node id.\n+     * @param sesId Session id.\n+     * @param queuedTime Time job spent on waiting queue.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Job execution time.\n+     * @param timedOut {@code True} if job is timed out.\n+     */\n+    void job(UUID nodeId, IgniteUuid sesId, long queuedTime, long startTime, long duration, boolean timedOut);\n+\n+    /** Cache operations types. */\n+    public enum CacheOperationType {", "originalCommit": "e7e8511a51577587a8a4a7128fe429a9af281981", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODg2NDMyOQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r448864329", "bodyText": "Let's make this enum not internal.", "author": "nizhikov", "createdAt": "2020-07-02T09:15:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODg1NjY5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODg2ODQ3Mw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r448868473", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-02T09:22:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODg1NjY5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODg3NjQxMw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r448876413", "bodyText": "Let's make this enum not internal.\nDone.", "author": "NSAmelchev", "createdAt": "2020-07-02T09:36:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODg1NjY5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODg1OTY2Ng==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r448859666", "bodyText": "This flag should be named committed", "author": "nizhikov", "createdAt": "2020-07-02T09:07:40Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/PerformanceStatisticsHandler.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.util.UUID;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.lang.IgniteUuid;\n+\n+/**\n+ * The interface represents performance statistics operations collection for purposes of troubleshooting and\n+ * performance analysis.\n+ */\n+public interface PerformanceStatisticsHandler {\n+    /**\n+     * @param nodeId Node id.\n+     * @param type Operation type.\n+     * @param cacheId Cache id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     */\n+    void cacheOperation(UUID nodeId, CacheOperationType type, int cacheId, long startTime, long duration);\n+\n+    /**\n+     * @param nodeId Node id.\n+     * @param cacheIds Cache IDs.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param commit {@code True} if commited.", "originalCommit": "e7e8511a51577587a8a4a7128fe429a9af281981", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODg2ODQ5MQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r448868491", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-02T09:22:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODg1OTY2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODg2NDY4Nw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r448864687", "bodyText": "Let's make this enum not internal.", "author": "nizhikov", "createdAt": "2020-07-02T09:16:14Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,690 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInternalFuture;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.processors.performancestatistics.PerformanceStatisticsHandler.CacheOperationType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.future.GridFinishedFuture;\n+import org.apache.ignite.internal.util.future.GridFutureAdapter;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * 1024 * 1024 * 1024L;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = 32 * 1024 * 1024;\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = 8 * 1024 * 1024;\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** @return {@code True} if collecting performance statistics enabled. */\n+    public boolean performanceStatisticsEnabled() {\n+        return enabled;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public synchronized void start() {\n+        if (enabled)\n+            return;\n+\n+        FileWriter writer = fileWriter;\n+\n+        // Writer is stopping.\n+        if (writer != null) {\n+            try {\n+                writer.shutdown().get();\n+            }\n+            catch (IgniteCheckedException e) {\n+                throw new IgniteException(\"Failed to wait for previous writer stopping.\", e);\n+            }\n+        }\n+\n+        assert fileWriter == null;\n+\n+        try {\n+            File file = statisticsFile(ctx);\n+\n+            U.delete(file);\n+\n+            FileIO fileIo = fileIoFactory.create(file);\n+\n+            fileIo.position(0);\n+\n+            fileWriter = new FileWriter(ctx, fileIo, DFLT_FILE_MAX_SIZE, DFLT_BUFFER_SIZE, DFLT_FLUSH_SIZE, log);\n+\n+            new IgniteThread(fileWriter).start();\n+\n+            enabled = true;\n+\n+            log.info(\"Performance statistics writer started [file=\" + file.getAbsolutePath() + ']');\n+        }\n+        catch (IOException | IgniteCheckedException e) {\n+            log.error(\"Failed to start performance statistics writer.\", e);\n+\n+            throw new IgniteException(\"Failed to start performance statistics writer.\", e);\n+        }\n+    }\n+\n+    /** Stops collecting performance statistics. */\n+    public IgniteInternalFuture<Void> stop() {\n+        synchronized (this) {\n+            if (!enabled)\n+                return new GridFinishedFuture<>();\n+\n+            enabled = false;\n+        }\n+\n+        log.info(\"Stopping performance statistics writer.\");\n+\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        if (fileWriter != null)\n+            return fileWriter.shutdown();\n+\n+        return new GridFinishedFuture<>();\n+    }\n+\n+    /**\n+     * @param type Operation type.\n+     * @param cacheId Cache id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     */\n+    public void cacheOperation(CacheOperationType type, int cacheId, long startTime, long duration) {\n+        int size = /*type*/ 1 +\n+            /*cacheId*/ 4 +\n+            /*startTime*/ 8 +\n+            /*duration*/ 8;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.CACHE_OPERATION, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)type.ordinal());\n+        buf.putInt(cacheId);\n+        buf.putLong(startTime);\n+        buf.putLong(duration);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * @param cacheIds Cache IDs.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param commit {@code True} if commited.\n+     */\n+    public void transaction(GridIntList cacheIds, long startTime, long duration, boolean commit) {\n+        int size = /*cacheIds*/ 4 + cacheIds.size() * 4 +\n+            /*startTime*/ 8 +\n+            /*duration*/ 8 +\n+            /*commit*/ 1;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.TRANSACTION, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.putInt(cacheIds.size());\n+\n+        GridIntIterator iter = cacheIds.iterator();\n+\n+        while (iter.hasNext())\n+            buf.putInt(iter.next());\n+\n+        buf.putLong(startTime);\n+        buf.putLong(duration);\n+        buf.put(commit ? (byte)1 : 0);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param text Query text in case of SQL query. Cache name in case of SCAN query.\n+     * @param id Query id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param success Success flag.\n+     */\n+    public void query(GridCacheQueryType type, String text, long id, long startTime, long duration, boolean success) {\n+        FileWriter writer = fileWriter;\n+\n+        if (writer == null)\n+            return;\n+\n+        Short strId = writer.stringId(text);\n+\n+        boolean needWriteStr = strId == null;\n+\n+        byte[] strBytes = null;\n+\n+        int size = /*type*/ 1 +\n+            /*compactStringFlag*/ 1 +\n+            /*strId*/ 2 +\n+            /*id*/ 8 +\n+            /*startTime*/ 8 +\n+            /*duration*/ 8 +\n+            /*success*/ 1;\n+\n+        if (needWriteStr) {\n+            strBytes = text.getBytes();\n+\n+            size += /*text*/ 4 + strBytes.length;\n+\n+            strId = writer.generateStringId(text);\n+        }\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.QUERY, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)type.ordinal());\n+        buf.put(needWriteStr ? (byte)1 : 0);\n+        buf.putShort(strId);\n+\n+        if (needWriteStr) {\n+            buf.putInt(strBytes.length);\n+            buf.put(strBytes);\n+        }\n+\n+        buf.putLong(id);\n+        buf.putLong(startTime);\n+        buf.putLong(duration);\n+        buf.put(success ? (byte)1 : 0);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param queryNodeId Originating node id.\n+     * @param id Query id.\n+     * @param logicalReads Number of logical reads.\n+     * @param physicalReads Number of physical reads.\n+     */\n+    public void queryReads(GridCacheQueryType type, UUID queryNodeId, long id, long logicalReads, long physicalReads) {\n+        int size = /*type*/ 1 +\n+            /*queryNodeId*/ 16 +\n+            /*id*/ 8 +\n+            /*logicalReads*/ 8 +\n+            /*physicalReads*/ 8;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.QUERY_READS, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)type.ordinal());\n+        writeUuid(buf, queryNodeId);\n+        buf.putLong(id);\n+        buf.putLong(logicalReads);\n+        buf.putLong(physicalReads);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param taskName Task name.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration.\n+     * @param affPartId Affinity partition id.\n+     */\n+    public void task(IgniteUuid sesId, String taskName, long startTime, long duration, int affPartId) {\n+        FileWriter writer = fileWriter;\n+\n+        if (writer == null)\n+            return;\n+\n+        Short strId = writer.stringId(taskName);\n+\n+        boolean needWriteStr = strId == null;\n+\n+        byte[] strBytes = null;\n+\n+        int size = /*sesId*/ 24 +\n+            /*compactStringFlag*/ 1 +\n+            /*strId*/ 2 +\n+            /*startTime*/ 8 +\n+            /*duration*/ 8 +\n+            /*affPartId*/ 4;\n+\n+        if (needWriteStr) {\n+            strBytes = taskName.getBytes();\n+\n+            size += /*taskName*/ 4 + strBytes.length;\n+\n+            strId = writer.generateStringId(taskName);\n+        }\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.TASK, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        writeIgniteUuid(buf, sesId);\n+        buf.put(needWriteStr ? (byte)1 : 0);\n+        buf.putShort(strId);\n+\n+        if (needWriteStr) {\n+            buf.putInt(strBytes.length);\n+            buf.put(strBytes);\n+        }\n+\n+        buf.putLong(startTime);\n+        buf.putLong(duration);\n+        buf.putInt(affPartId);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param queuedTime Time job spent on waiting queue.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Job execution time.\n+     * @param timedOut {@code True} if job is timed out.\n+     */\n+    public void job(IgniteUuid sesId, long queuedTime, long startTime, long duration, boolean timedOut) {\n+        int size = /*sesId*/ 24 +\n+            /*queuedTime*/ 8 +\n+            /*startTime*/ 8 +\n+            /*duration*/ 8 +\n+            /*timedOut*/ 1;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.JOB, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        writeIgniteUuid(buf, sesId);\n+        buf.putLong(queuedTime);\n+        buf.putLong(startTime);\n+        buf.putLong(duration);\n+        buf.put(timedOut ? (byte)1 : 0);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * Reserves buffer's write segment.\n+     *\n+     * @return Buffer's write segment or {@code null} if not enought space or writer stopping.\n+     */\n+    private SegmentedRingByteBuffer.WriteSegment reserveBuffer(OperationType type, int size) {\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        // Writer stopping.\n+        if (fileWriter == null)\n+            return null;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = fileWriter.writeSegment(size + /*type*/ 1);\n+\n+        if (seg == null) {\n+            fileWriter.logSmallBufferMessage();\n+\n+            return null;\n+        }\n+\n+        // Ring buffer closed (writer stopping) or maximum size reached.\n+        if (seg.buffer() == null) {\n+            seg.release();\n+\n+            if (!fileWriter.isCancelled())\n+                fileWriter.onMaxFileSizeReached();\n+\n+            return null;\n+        }\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)type.ordinal());\n+\n+        return seg;\n+    }\n+\n+    /** @return Performance statistics file. */\n+    public static File statisticsFile(GridKernalContext ctx) throws IgniteCheckedException {\n+        String igniteWorkDir = U.workDirectory(ctx.config().getWorkDirectory(), ctx.config().getIgniteHome());\n+\n+        File fileDir = U.resolveWorkDirectory(igniteWorkDir, PERFORMANCE_STAT_DIR, false);\n+\n+        return new File(fileDir, \"node-\" + ctx.localNodeId() + \".prf\");\n+    }\n+\n+    /** Writes {@link UUID} to buffer. */\n+    public static void writeUuid(ByteBuffer buf, UUID uuid) {\n+        buf.putLong(uuid.getMostSignificantBits());\n+        buf.putLong(uuid.getLeastSignificantBits());\n+    }\n+\n+    /** Reads {@link UUID} from buffer. */\n+    public static UUID readUuid(ByteBuffer buf) {\n+        return new UUID(buf.getLong(), buf.getLong());\n+    }\n+\n+    /** Writes {@link IgniteUuid} to buffer. */\n+    public static void writeIgniteUuid(ByteBuffer buf, IgniteUuid uuid) {\n+        buf.putLong(uuid.globalId().getMostSignificantBits());\n+        buf.putLong(uuid.globalId().getLeastSignificantBits());\n+        buf.putLong(uuid.localId());\n+    }\n+\n+    /** Reads {@link IgniteUuid} from buffer. */\n+    public static IgniteUuid readIgniteUuid(ByteBuffer buf) {\n+        UUID globalId = new UUID(buf.getLong(), buf.getLong());\n+\n+        return new IgniteUuid(globalId, buf.getLong());\n+    }\n+\n+    /** Worker to write to performance statistics file. */\n+    private class FileWriter extends GridWorker {\n+        /** Maximum cached string count. */\n+        private static final short MAX_CACHED_STRING_COUNT = Short.MAX_VALUE;\n+\n+        /** Performance statistics file I/O. */\n+        private final FileIO fileIo;\n+\n+        /** File write buffer. */\n+        private final SegmentedRingByteBuffer ringByteBuffer;\n+\n+        /** Minimal batch size to flush in bytes. */\n+        private final int flushBatchSize;\n+\n+        /** Size of ready for flushing bytes. */\n+        private final AtomicInteger readyForFlushSize = new AtomicInteger();\n+\n+        /** Stop file writer future. */\n+        GridFutureAdapter<Void> stopFut = new GridFutureAdapter<>();\n+\n+        /** Cached strings by id. */\n+        private final ConcurrentHashMap<String, Short> stringIds = new ConcurrentHashMap<>();\n+\n+        /** String id generator. */\n+        private final AtomicInteger idsGen = new AtomicInteger();\n+\n+        /** {@code True} if the small buffer warning message logged. */\n+        private final AtomicBoolean smallBufLogged = new AtomicBoolean();\n+\n+        /** {@code True} if worker stopped due to maximum file size reached. */\n+        private final AtomicBoolean stopByMaxSize = new AtomicBoolean();\n+\n+        /**\n+         * @param ctx Kernal context.\n+         * @param fileIo Performance statistics file I/O.\n+         * @param maxFileSize Maximum file size in bytes.\n+         * @param bufferSize Off heap buffer size in bytes.\n+         * @param flushBatchSize Minimal batch size to flush in bytes.\n+         * @param log Logger.\n+         */\n+        FileWriter(GridKernalContext ctx, FileIO fileIo, long maxFileSize, int bufferSize, int flushBatchSize,\n+            IgniteLogger log) {\n+            super(ctx.igniteInstanceName(), \"performance-statistics-writer%\" + ctx.igniteInstanceName(), log);\n+\n+            this.fileIo = fileIo;\n+            this.flushBatchSize = flushBatchSize;\n+\n+            ringByteBuffer = new SegmentedRingByteBuffer(bufferSize, maxFileSize, BufferMode.DIRECT);\n+\n+            ringByteBuffer.init(0);\n+        }\n+\n+        /** {@inheritDoc} */\n+        @Override protected void body() throws InterruptedException, IgniteInterruptedCheckedException {\n+            while (!isCancelled() && !Thread.interrupted()) {\n+                blockingSectionBegin();\n+\n+                try {\n+                    synchronized (this) {\n+                        while (readyForFlushSize.get() < flushBatchSize && !isCancelled())\n+                            wait();\n+                    }\n+\n+                    flushBuffer();\n+                }\n+                finally {\n+                    blockingSectionEnd();\n+                }\n+            }\n+\n+            fileWriter = null;\n+\n+            ringByteBuffer.close();\n+\n+            // Make sure that all producers released their buffers to safe deallocate memory.\n+            ringByteBuffer.poll();\n+\n+            ringByteBuffer.free();\n+\n+            U.closeQuiet(fileIo);\n+\n+            stringIds.clear();\n+\n+            stopFut.onDone();\n+\n+            log.info(\"Performance statistics writer stopped.\");\n+        }\n+\n+        /** @return Unique per file string identifier. {@code Null} if there is no cached identifier. */\n+        Short stringId(String str) {\n+            return stringIds.get(str);\n+        }\n+\n+        /** @return Generate unique per file string identifier. {@code -1} if max cached limit exceeded. */\n+        short generateStringId(String str) {\n+            if (idsGen.get() > MAX_CACHED_STRING_COUNT)\n+                return -1;\n+\n+            return stringIds.computeIfAbsent(str,\n+                s -> (short)idsGen.updateAndGet(id -> id < MAX_CACHED_STRING_COUNT ? id + 1 : -1));\n+        }\n+\n+        /** @return Write segment.*/\n+        SegmentedRingByteBuffer.WriteSegment writeSegment(int size) {\n+            SegmentedRingByteBuffer.WriteSegment seg = ringByteBuffer.offer(size);\n+\n+            if (seg != null) {\n+                int readySize = readyForFlushSize.addAndGet(size);\n+\n+                if (readySize >= DFLT_FLUSH_SIZE) {\n+                    synchronized (this) {\n+                        notify();\n+                    }\n+                }\n+            }\n+\n+            return seg;\n+        }\n+\n+        /** Flushes to disk available bytes from the ring buffer. */\n+        private void flushBuffer() {\n+            List<SegmentedRingByteBuffer.ReadSegment> segs = ringByteBuffer.poll();\n+\n+            if (segs == null)\n+                return;\n+\n+            try {\n+                for (int i = 0; i < segs.size(); i++) {\n+                    SegmentedRingByteBuffer.ReadSegment seg = segs.get(i);\n+\n+                    try {\n+                        readyForFlushSize.addAndGet(-seg.buffer().remaining());\n+\n+                        fileIo.writeFully(seg.buffer());\n+                    }\n+                    finally {\n+                        seg.release();\n+                    }\n+                }\n+\n+                fileIo.force();\n+            } catch (IOException e) {\n+                log.error(\"Unable to write to file. Performance statistics collecting will be stopped.\", e);\n+\n+                fileWriter.shutdown();\n+\n+                stopStatistics();\n+            }\n+        }\n+\n+        /** Shutted down the worker. */\n+        private IgniteInternalFuture<Void> shutdown() {\n+            isCancelled = true;\n+\n+            synchronized (this) {\n+                notify();\n+            }\n+\n+            return stopFut;\n+        }\n+\n+        /** Logs warning message about small buffer size if not logged yet. */\n+        void logSmallBufferMessage() {\n+            if (smallBufLogged.compareAndSet(false, true)) {\n+                log.warning(\"The performance statistics in-memory buffer size is too small. Some operations \" +\n+                    \"will not be logged.\");\n+            }\n+        }\n+\n+        /** Logs warning message and stops collecting statistics. */\n+        void onMaxFileSizeReached() {\n+            if (stopByMaxSize.compareAndSet(false, true)) {\n+                fileWriter.shutdown();\n+\n+                stopStatistics();\n+\n+                log.warning(\"The performance statistics file maximum size is reached. \" +\n+                    \"Performance statistics collecting will be stopped.\");\n+            }\n+        }\n+\n+        /** Stops collecting statistics. */\n+        void stopStatistics() {\n+            try {\n+                ctx.performanceStatistics().stopCollectStatistics();\n+            }\n+            catch (IgniteCheckedException e) {\n+                log.error(\"Failed to stop performance statistics.\", e);\n+            }\n+        }\n+    }\n+\n+    /** Operation type. */\n+    public enum OperationType {", "originalCommit": "e7e8511a51577587a8a4a7128fe429a9af281981", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODg2ODUwNw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r448868507", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-02T09:22:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODg2NDY4Nw=="}], "type": "inlineReview"}, {"oid": "870ac68912e8142c99bc3a276e0f9a7ca6434abe", "url": "https://github.com/apache/ignite/commit/870ac68912e8142c99bc3a276e0f9a7ca6434abe", "message": "Review fixes", "committedDate": "2020-07-02T09:22:19Z", "type": "commit"}, {"oid": "15dcf55d7542987a0916aaec1f8647c9ac225ac7", "url": "https://github.com/apache/ignite/commit/15dcf55d7542987a0916aaec1f8647c9ac225ac7", "message": "Review fixes", "committedDate": "2020-07-02T09:35:51Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3MTM5OQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r448971399", "bodyText": "Can we rewrite flow a bit to make this code more readable.\nif (fileWriter == null)\n    return new GridFinishedFuture<>();\n\nreturn fileWriter.shutdown();", "author": "nizhikov", "createdAt": "2020-07-02T12:40:35Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,660 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInternalFuture;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.future.GridFinishedFuture;\n+import org.apache.ignite.internal.util.future.GridFutureAdapter;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * 1024 * 1024 * 1024L;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = 32 * 1024 * 1024;\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = 8 * 1024 * 1024;\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** @return {@code True} if collecting performance statistics enabled. */\n+    public boolean performanceStatisticsEnabled() {\n+        return enabled;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public synchronized void start() {\n+        if (enabled)\n+            return;\n+\n+        FileWriter writer = fileWriter;\n+\n+        // Writer is stopping.\n+        if (writer != null) {\n+            try {\n+                writer.shutdown().get();\n+            }\n+            catch (IgniteCheckedException e) {\n+                throw new IgniteException(\"Failed to wait for previous writer stopping.\", e);\n+            }\n+        }\n+\n+        assert fileWriter == null;\n+\n+        try {\n+            File file = statisticsFile(ctx);\n+\n+            U.delete(file);\n+\n+            FileIO fileIo = fileIoFactory.create(file);\n+\n+            fileIo.position(0);\n+\n+            fileWriter = new FileWriter(ctx, fileIo, DFLT_FILE_MAX_SIZE, DFLT_BUFFER_SIZE, DFLT_FLUSH_SIZE, log);\n+\n+            new IgniteThread(fileWriter).start();\n+\n+            enabled = true;\n+\n+            log.info(\"Performance statistics writer started [file=\" + file.getAbsolutePath() + ']');\n+        }\n+        catch (IOException | IgniteCheckedException e) {\n+            log.error(\"Failed to start performance statistics writer.\", e);\n+\n+            throw new IgniteException(\"Failed to start performance statistics writer.\", e);\n+        }\n+    }\n+\n+    /** Stops collecting performance statistics. */\n+    public IgniteInternalFuture<Void> stop() {\n+        synchronized (this) {\n+            if (!enabled)\n+                return new GridFinishedFuture<>();\n+\n+            enabled = false;\n+        }\n+\n+        log.info(\"Stopping performance statistics writer.\");\n+\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        if (fileWriter != null)", "originalCommit": "15dcf55d7542987a0916aaec1f8647c9ac225ac7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk5MDkxNQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r448990915", "bodyText": "Done.", "author": "NSAmelchev", "createdAt": "2020-07-02T13:12:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3MTM5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3MjA0Ng==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r448972046", "bodyText": "The essence of this assert is not clear for me.\nCan you, please, clarify it?", "author": "nizhikov", "createdAt": "2020-07-02T12:41:42Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,660 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInternalFuture;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.future.GridFinishedFuture;\n+import org.apache.ignite.internal.util.future.GridFutureAdapter;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * 1024 * 1024 * 1024L;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = 32 * 1024 * 1024;\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = 8 * 1024 * 1024;\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** @return {@code True} if collecting performance statistics enabled. */\n+    public boolean performanceStatisticsEnabled() {\n+        return enabled;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public synchronized void start() {\n+        if (enabled)\n+            return;\n+\n+        FileWriter writer = fileWriter;\n+\n+        // Writer is stopping.\n+        if (writer != null) {\n+            try {\n+                writer.shutdown().get();\n+            }\n+            catch (IgniteCheckedException e) {\n+                throw new IgniteException(\"Failed to wait for previous writer stopping.\", e);\n+            }\n+        }\n+\n+        assert fileWriter == null;", "originalCommit": "15dcf55d7542987a0916aaec1f8647c9ac225ac7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk5MjY4Mw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r448992683", "bodyText": "This is to make sure that the previous writer is stopped before starting a new one. I have removed it cause it seems unnecessary.", "author": "NSAmelchev", "createdAt": "2020-07-02T13:14:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3MjA0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk4MDM3MA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r448980370", "bodyText": "Why flushBuffer is in blocking section?", "author": "nizhikov", "createdAt": "2020-07-02T12:55:38Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,660 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInternalFuture;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.future.GridFinishedFuture;\n+import org.apache.ignite.internal.util.future.GridFutureAdapter;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * 1024 * 1024 * 1024L;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = 32 * 1024 * 1024;\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = 8 * 1024 * 1024;\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** @return {@code True} if collecting performance statistics enabled. */\n+    public boolean performanceStatisticsEnabled() {\n+        return enabled;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public synchronized void start() {\n+        if (enabled)\n+            return;\n+\n+        FileWriter writer = fileWriter;\n+\n+        // Writer is stopping.\n+        if (writer != null) {\n+            try {\n+                writer.shutdown().get();\n+            }\n+            catch (IgniteCheckedException e) {\n+                throw new IgniteException(\"Failed to wait for previous writer stopping.\", e);\n+            }\n+        }\n+\n+        assert fileWriter == null;\n+\n+        try {\n+            File file = statisticsFile(ctx);\n+\n+            U.delete(file);\n+\n+            FileIO fileIo = fileIoFactory.create(file);\n+\n+            fileIo.position(0);\n+\n+            fileWriter = new FileWriter(ctx, fileIo, DFLT_FILE_MAX_SIZE, DFLT_BUFFER_SIZE, DFLT_FLUSH_SIZE, log);\n+\n+            new IgniteThread(fileWriter).start();\n+\n+            enabled = true;\n+\n+            log.info(\"Performance statistics writer started [file=\" + file.getAbsolutePath() + ']');\n+        }\n+        catch (IOException | IgniteCheckedException e) {\n+            log.error(\"Failed to start performance statistics writer.\", e);\n+\n+            throw new IgniteException(\"Failed to start performance statistics writer.\", e);\n+        }\n+    }\n+\n+    /** Stops collecting performance statistics. */\n+    public IgniteInternalFuture<Void> stop() {\n+        synchronized (this) {\n+            if (!enabled)\n+                return new GridFinishedFuture<>();\n+\n+            enabled = false;\n+        }\n+\n+        log.info(\"Stopping performance statistics writer.\");\n+\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        if (fileWriter != null)\n+            return fileWriter.shutdown();\n+\n+        return new GridFinishedFuture<>();\n+    }\n+\n+    /**\n+     * @param type Operation type.\n+     * @param cacheId Cache id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     */\n+    public void cacheOperation(CacheOperation type, int cacheId, long startTime, long duration) {\n+        int size = /*type*/ 1 +\n+            /*cacheId*/ 4 +\n+            /*startTime*/ 8 +\n+            /*duration*/ 8;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.CACHE_OPERATION, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)type.ordinal());\n+        buf.putInt(cacheId);\n+        buf.putLong(startTime);\n+        buf.putLong(duration);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * @param cacheIds Cache IDs.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param commited {@code True} if commited.\n+     */\n+    public void transaction(GridIntList cacheIds, long startTime, long duration, boolean commited) {\n+        int size = /*cacheIds*/ 4 + cacheIds.size() * 4 +\n+            /*startTime*/ 8 +\n+            /*duration*/ 8 +\n+            /*commit*/ 1;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.TRANSACTION, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.putInt(cacheIds.size());\n+\n+        GridIntIterator iter = cacheIds.iterator();\n+\n+        while (iter.hasNext())\n+            buf.putInt(iter.next());\n+\n+        buf.putLong(startTime);\n+        buf.putLong(duration);\n+        buf.put(commited ? (byte)1 : 0);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param text Query text in case of SQL query. Cache name in case of SCAN query.\n+     * @param id Query id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param success Success flag.\n+     */\n+    public void query(GridCacheQueryType type, String text, long id, long startTime, long duration, boolean success) {\n+        FileWriter writer = fileWriter;\n+\n+        if (writer == null)\n+            return;\n+\n+        Short strId = writer.stringId(text);\n+\n+        boolean needWriteStr = strId == null;\n+\n+        byte[] strBytes = null;\n+\n+        int size = /*type*/ 1 +\n+            /*compactStringFlag*/ 1 +\n+            /*strId*/ 2 +\n+            /*id*/ 8 +\n+            /*startTime*/ 8 +\n+            /*duration*/ 8 +\n+            /*success*/ 1;\n+\n+        if (needWriteStr) {\n+            strBytes = text.getBytes();\n+\n+            size += /*text*/ 4 + strBytes.length;\n+\n+            strId = writer.generateStringId(text);\n+        }\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.QUERY, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)type.ordinal());\n+        buf.put(needWriteStr ? (byte)1 : 0);\n+        buf.putShort(strId);\n+\n+        if (needWriteStr) {\n+            buf.putInt(strBytes.length);\n+            buf.put(strBytes);\n+        }\n+\n+        buf.putLong(id);\n+        buf.putLong(startTime);\n+        buf.putLong(duration);\n+        buf.put(success ? (byte)1 : 0);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param queryNodeId Originating node id.\n+     * @param id Query id.\n+     * @param logicalReads Number of logical reads.\n+     * @param physicalReads Number of physical reads.\n+     */\n+    public void queryReads(GridCacheQueryType type, UUID queryNodeId, long id, long logicalReads, long physicalReads) {\n+        int size = /*type*/ 1 +\n+            /*queryNodeId*/ 16 +\n+            /*id*/ 8 +\n+            /*logicalReads*/ 8 +\n+            /*physicalReads*/ 8;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.QUERY_READS, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)type.ordinal());\n+        writeUuid(buf, queryNodeId);\n+        buf.putLong(id);\n+        buf.putLong(logicalReads);\n+        buf.putLong(physicalReads);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param taskName Task name.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration.\n+     * @param affPartId Affinity partition id.\n+     */\n+    public void task(IgniteUuid sesId, String taskName, long startTime, long duration, int affPartId) {\n+        FileWriter writer = fileWriter;\n+\n+        if (writer == null)\n+            return;\n+\n+        Short strId = writer.stringId(taskName);\n+\n+        boolean needWriteStr = strId == null;\n+\n+        byte[] strBytes = null;\n+\n+        int size = /*sesId*/ 24 +\n+            /*compactStringFlag*/ 1 +\n+            /*strId*/ 2 +\n+            /*startTime*/ 8 +\n+            /*duration*/ 8 +\n+            /*affPartId*/ 4;\n+\n+        if (needWriteStr) {\n+            strBytes = taskName.getBytes();\n+\n+            size += /*taskName*/ 4 + strBytes.length;\n+\n+            strId = writer.generateStringId(taskName);\n+        }\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.TASK, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        writeIgniteUuid(buf, sesId);\n+        buf.put(needWriteStr ? (byte)1 : 0);\n+        buf.putShort(strId);\n+\n+        if (needWriteStr) {\n+            buf.putInt(strBytes.length);\n+            buf.put(strBytes);\n+        }\n+\n+        buf.putLong(startTime);\n+        buf.putLong(duration);\n+        buf.putInt(affPartId);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param queuedTime Time job spent on waiting queue.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Job execution time.\n+     * @param timedOut {@code True} if job is timed out.\n+     */\n+    public void job(IgniteUuid sesId, long queuedTime, long startTime, long duration, boolean timedOut) {\n+        int size = /*sesId*/ 24 +\n+            /*queuedTime*/ 8 +\n+            /*startTime*/ 8 +\n+            /*duration*/ 8 +\n+            /*timedOut*/ 1;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.JOB, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        writeIgniteUuid(buf, sesId);\n+        buf.putLong(queuedTime);\n+        buf.putLong(startTime);\n+        buf.putLong(duration);\n+        buf.put(timedOut ? (byte)1 : 0);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * Reserves buffer's write segment.\n+     *\n+     * @return Buffer's write segment or {@code null} if not enought space or writer stopping.\n+     */\n+    private SegmentedRingByteBuffer.WriteSegment reserveBuffer(OperationType type, int size) {\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        // Writer stopping.\n+        if (fileWriter == null)\n+            return null;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = fileWriter.writeSegment(size + /*type*/ 1);\n+\n+        if (seg == null) {\n+            fileWriter.logSmallBufferMessage();\n+\n+            return null;\n+        }\n+\n+        // Ring buffer closed (writer stopping) or maximum size reached.\n+        if (seg.buffer() == null) {\n+            seg.release();\n+\n+            if (!fileWriter.isCancelled())\n+                fileWriter.onMaxFileSizeReached();\n+\n+            return null;\n+        }\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)type.ordinal());\n+\n+        return seg;\n+    }\n+\n+    /** @return Performance statistics file. */\n+    public static File statisticsFile(GridKernalContext ctx) throws IgniteCheckedException {\n+        String igniteWorkDir = U.workDirectory(ctx.config().getWorkDirectory(), ctx.config().getIgniteHome());\n+\n+        File fileDir = U.resolveWorkDirectory(igniteWorkDir, PERFORMANCE_STAT_DIR, false);\n+\n+        return new File(fileDir, \"node-\" + ctx.localNodeId() + \".prf\");\n+    }\n+\n+    /** Writes {@link UUID} to buffer. */\n+    public static void writeUuid(ByteBuffer buf, UUID uuid) {\n+        buf.putLong(uuid.getMostSignificantBits());\n+        buf.putLong(uuid.getLeastSignificantBits());\n+    }\n+\n+    /** Reads {@link UUID} from buffer. */\n+    public static UUID readUuid(ByteBuffer buf) {\n+        return new UUID(buf.getLong(), buf.getLong());\n+    }\n+\n+    /** Writes {@link IgniteUuid} to buffer. */\n+    public static void writeIgniteUuid(ByteBuffer buf, IgniteUuid uuid) {\n+        buf.putLong(uuid.globalId().getMostSignificantBits());\n+        buf.putLong(uuid.globalId().getLeastSignificantBits());\n+        buf.putLong(uuid.localId());\n+    }\n+\n+    /** Reads {@link IgniteUuid} from buffer. */\n+    public static IgniteUuid readIgniteUuid(ByteBuffer buf) {\n+        UUID globalId = new UUID(buf.getLong(), buf.getLong());\n+\n+        return new IgniteUuid(globalId, buf.getLong());\n+    }\n+\n+    /** Worker to write to performance statistics file. */\n+    private class FileWriter extends GridWorker {\n+        /** Maximum cached string count. */\n+        private static final short MAX_CACHED_STRING_COUNT = Short.MAX_VALUE;\n+\n+        /** Performance statistics file I/O. */\n+        private final FileIO fileIo;\n+\n+        /** File write buffer. */\n+        private final SegmentedRingByteBuffer ringByteBuffer;\n+\n+        /** Minimal batch size to flush in bytes. */\n+        private final int flushBatchSize;\n+\n+        /** Size of ready for flushing bytes. */\n+        private final AtomicInteger readyForFlushSize = new AtomicInteger();\n+\n+        /** Stop file writer future. */\n+        GridFutureAdapter<Void> stopFut = new GridFutureAdapter<>();\n+\n+        /** Cached strings by id. */\n+        private final ConcurrentHashMap<String, Short> stringIds = new ConcurrentHashMap<>();\n+\n+        /** String id generator. */\n+        private final AtomicInteger idsGen = new AtomicInteger();\n+\n+        /** {@code True} if the small buffer warning message logged. */\n+        private final AtomicBoolean smallBufLogged = new AtomicBoolean();\n+\n+        /** {@code True} if worker stopped due to maximum file size reached. */\n+        private final AtomicBoolean stopByMaxSize = new AtomicBoolean();\n+\n+        /**\n+         * @param ctx Kernal context.\n+         * @param fileIo Performance statistics file I/O.\n+         * @param maxFileSize Maximum file size in bytes.\n+         * @param bufferSize Off heap buffer size in bytes.\n+         * @param flushBatchSize Minimal batch size to flush in bytes.\n+         * @param log Logger.\n+         */\n+        FileWriter(GridKernalContext ctx, FileIO fileIo, long maxFileSize, int bufferSize, int flushBatchSize,\n+            IgniteLogger log) {\n+            super(ctx.igniteInstanceName(), \"performance-statistics-writer%\" + ctx.igniteInstanceName(), log);\n+\n+            this.fileIo = fileIo;\n+            this.flushBatchSize = flushBatchSize;\n+\n+            ringByteBuffer = new SegmentedRingByteBuffer(bufferSize, maxFileSize, BufferMode.DIRECT);\n+\n+            ringByteBuffer.init(0);\n+        }\n+\n+        /** {@inheritDoc} */\n+        @Override protected void body() throws InterruptedException, IgniteInterruptedCheckedException {\n+            while (!isCancelled() && !Thread.interrupted()) {\n+                blockingSectionBegin();\n+\n+                try {\n+                    synchronized (this) {\n+                        while (readyForFlushSize.get() < flushBatchSize && !isCancelled())\n+                            wait();\n+                    }\n+\n+                    flushBuffer();", "originalCommit": "15dcf55d7542987a0916aaec1f8647c9ac225ac7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk5MDc4Ng==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r448990786", "bodyText": "I have moved buffer flushing out of the blocking section.", "author": "NSAmelchev", "createdAt": "2020-07-02T13:11:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk4MDM3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk4MjIxMg==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r448982212", "bodyText": "Why do we need to check Thread.interrupted here?", "author": "nizhikov", "createdAt": "2020-07-02T12:58:35Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,660 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInternalFuture;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.future.GridFinishedFuture;\n+import org.apache.ignite.internal.util.future.GridFutureAdapter;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * 1024 * 1024 * 1024L;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = 32 * 1024 * 1024;\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = 8 * 1024 * 1024;\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** @return {@code True} if collecting performance statistics enabled. */\n+    public boolean performanceStatisticsEnabled() {\n+        return enabled;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public synchronized void start() {\n+        if (enabled)\n+            return;\n+\n+        FileWriter writer = fileWriter;\n+\n+        // Writer is stopping.\n+        if (writer != null) {\n+            try {\n+                writer.shutdown().get();\n+            }\n+            catch (IgniteCheckedException e) {\n+                throw new IgniteException(\"Failed to wait for previous writer stopping.\", e);\n+            }\n+        }\n+\n+        assert fileWriter == null;\n+\n+        try {\n+            File file = statisticsFile(ctx);\n+\n+            U.delete(file);\n+\n+            FileIO fileIo = fileIoFactory.create(file);\n+\n+            fileIo.position(0);\n+\n+            fileWriter = new FileWriter(ctx, fileIo, DFLT_FILE_MAX_SIZE, DFLT_BUFFER_SIZE, DFLT_FLUSH_SIZE, log);\n+\n+            new IgniteThread(fileWriter).start();\n+\n+            enabled = true;\n+\n+            log.info(\"Performance statistics writer started [file=\" + file.getAbsolutePath() + ']');\n+        }\n+        catch (IOException | IgniteCheckedException e) {\n+            log.error(\"Failed to start performance statistics writer.\", e);\n+\n+            throw new IgniteException(\"Failed to start performance statistics writer.\", e);\n+        }\n+    }\n+\n+    /** Stops collecting performance statistics. */\n+    public IgniteInternalFuture<Void> stop() {\n+        synchronized (this) {\n+            if (!enabled)\n+                return new GridFinishedFuture<>();\n+\n+            enabled = false;\n+        }\n+\n+        log.info(\"Stopping performance statistics writer.\");\n+\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        if (fileWriter != null)\n+            return fileWriter.shutdown();\n+\n+        return new GridFinishedFuture<>();\n+    }\n+\n+    /**\n+     * @param type Operation type.\n+     * @param cacheId Cache id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     */\n+    public void cacheOperation(CacheOperation type, int cacheId, long startTime, long duration) {\n+        int size = /*type*/ 1 +\n+            /*cacheId*/ 4 +\n+            /*startTime*/ 8 +\n+            /*duration*/ 8;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.CACHE_OPERATION, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)type.ordinal());\n+        buf.putInt(cacheId);\n+        buf.putLong(startTime);\n+        buf.putLong(duration);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * @param cacheIds Cache IDs.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param commited {@code True} if commited.\n+     */\n+    public void transaction(GridIntList cacheIds, long startTime, long duration, boolean commited) {\n+        int size = /*cacheIds*/ 4 + cacheIds.size() * 4 +\n+            /*startTime*/ 8 +\n+            /*duration*/ 8 +\n+            /*commit*/ 1;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.TRANSACTION, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.putInt(cacheIds.size());\n+\n+        GridIntIterator iter = cacheIds.iterator();\n+\n+        while (iter.hasNext())\n+            buf.putInt(iter.next());\n+\n+        buf.putLong(startTime);\n+        buf.putLong(duration);\n+        buf.put(commited ? (byte)1 : 0);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param text Query text in case of SQL query. Cache name in case of SCAN query.\n+     * @param id Query id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param success Success flag.\n+     */\n+    public void query(GridCacheQueryType type, String text, long id, long startTime, long duration, boolean success) {\n+        FileWriter writer = fileWriter;\n+\n+        if (writer == null)\n+            return;\n+\n+        Short strId = writer.stringId(text);\n+\n+        boolean needWriteStr = strId == null;\n+\n+        byte[] strBytes = null;\n+\n+        int size = /*type*/ 1 +\n+            /*compactStringFlag*/ 1 +\n+            /*strId*/ 2 +\n+            /*id*/ 8 +\n+            /*startTime*/ 8 +\n+            /*duration*/ 8 +\n+            /*success*/ 1;\n+\n+        if (needWriteStr) {\n+            strBytes = text.getBytes();\n+\n+            size += /*text*/ 4 + strBytes.length;\n+\n+            strId = writer.generateStringId(text);\n+        }\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.QUERY, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)type.ordinal());\n+        buf.put(needWriteStr ? (byte)1 : 0);\n+        buf.putShort(strId);\n+\n+        if (needWriteStr) {\n+            buf.putInt(strBytes.length);\n+            buf.put(strBytes);\n+        }\n+\n+        buf.putLong(id);\n+        buf.putLong(startTime);\n+        buf.putLong(duration);\n+        buf.put(success ? (byte)1 : 0);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param queryNodeId Originating node id.\n+     * @param id Query id.\n+     * @param logicalReads Number of logical reads.\n+     * @param physicalReads Number of physical reads.\n+     */\n+    public void queryReads(GridCacheQueryType type, UUID queryNodeId, long id, long logicalReads, long physicalReads) {\n+        int size = /*type*/ 1 +\n+            /*queryNodeId*/ 16 +\n+            /*id*/ 8 +\n+            /*logicalReads*/ 8 +\n+            /*physicalReads*/ 8;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.QUERY_READS, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)type.ordinal());\n+        writeUuid(buf, queryNodeId);\n+        buf.putLong(id);\n+        buf.putLong(logicalReads);\n+        buf.putLong(physicalReads);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param taskName Task name.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration.\n+     * @param affPartId Affinity partition id.\n+     */\n+    public void task(IgniteUuid sesId, String taskName, long startTime, long duration, int affPartId) {\n+        FileWriter writer = fileWriter;\n+\n+        if (writer == null)\n+            return;\n+\n+        Short strId = writer.stringId(taskName);\n+\n+        boolean needWriteStr = strId == null;\n+\n+        byte[] strBytes = null;\n+\n+        int size = /*sesId*/ 24 +\n+            /*compactStringFlag*/ 1 +\n+            /*strId*/ 2 +\n+            /*startTime*/ 8 +\n+            /*duration*/ 8 +\n+            /*affPartId*/ 4;\n+\n+        if (needWriteStr) {\n+            strBytes = taskName.getBytes();\n+\n+            size += /*taskName*/ 4 + strBytes.length;\n+\n+            strId = writer.generateStringId(taskName);\n+        }\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.TASK, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        writeIgniteUuid(buf, sesId);\n+        buf.put(needWriteStr ? (byte)1 : 0);\n+        buf.putShort(strId);\n+\n+        if (needWriteStr) {\n+            buf.putInt(strBytes.length);\n+            buf.put(strBytes);\n+        }\n+\n+        buf.putLong(startTime);\n+        buf.putLong(duration);\n+        buf.putInt(affPartId);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param queuedTime Time job spent on waiting queue.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Job execution time.\n+     * @param timedOut {@code True} if job is timed out.\n+     */\n+    public void job(IgniteUuid sesId, long queuedTime, long startTime, long duration, boolean timedOut) {\n+        int size = /*sesId*/ 24 +\n+            /*queuedTime*/ 8 +\n+            /*startTime*/ 8 +\n+            /*duration*/ 8 +\n+            /*timedOut*/ 1;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.JOB, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        writeIgniteUuid(buf, sesId);\n+        buf.putLong(queuedTime);\n+        buf.putLong(startTime);\n+        buf.putLong(duration);\n+        buf.put(timedOut ? (byte)1 : 0);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * Reserves buffer's write segment.\n+     *\n+     * @return Buffer's write segment or {@code null} if not enought space or writer stopping.\n+     */\n+    private SegmentedRingByteBuffer.WriteSegment reserveBuffer(OperationType type, int size) {\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        // Writer stopping.\n+        if (fileWriter == null)\n+            return null;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = fileWriter.writeSegment(size + /*type*/ 1);\n+\n+        if (seg == null) {\n+            fileWriter.logSmallBufferMessage();\n+\n+            return null;\n+        }\n+\n+        // Ring buffer closed (writer stopping) or maximum size reached.\n+        if (seg.buffer() == null) {\n+            seg.release();\n+\n+            if (!fileWriter.isCancelled())\n+                fileWriter.onMaxFileSizeReached();\n+\n+            return null;\n+        }\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)type.ordinal());\n+\n+        return seg;\n+    }\n+\n+    /** @return Performance statistics file. */\n+    public static File statisticsFile(GridKernalContext ctx) throws IgniteCheckedException {\n+        String igniteWorkDir = U.workDirectory(ctx.config().getWorkDirectory(), ctx.config().getIgniteHome());\n+\n+        File fileDir = U.resolveWorkDirectory(igniteWorkDir, PERFORMANCE_STAT_DIR, false);\n+\n+        return new File(fileDir, \"node-\" + ctx.localNodeId() + \".prf\");\n+    }\n+\n+    /** Writes {@link UUID} to buffer. */\n+    public static void writeUuid(ByteBuffer buf, UUID uuid) {\n+        buf.putLong(uuid.getMostSignificantBits());\n+        buf.putLong(uuid.getLeastSignificantBits());\n+    }\n+\n+    /** Reads {@link UUID} from buffer. */\n+    public static UUID readUuid(ByteBuffer buf) {\n+        return new UUID(buf.getLong(), buf.getLong());\n+    }\n+\n+    /** Writes {@link IgniteUuid} to buffer. */\n+    public static void writeIgniteUuid(ByteBuffer buf, IgniteUuid uuid) {\n+        buf.putLong(uuid.globalId().getMostSignificantBits());\n+        buf.putLong(uuid.globalId().getLeastSignificantBits());\n+        buf.putLong(uuid.localId());\n+    }\n+\n+    /** Reads {@link IgniteUuid} from buffer. */\n+    public static IgniteUuid readIgniteUuid(ByteBuffer buf) {\n+        UUID globalId = new UUID(buf.getLong(), buf.getLong());\n+\n+        return new IgniteUuid(globalId, buf.getLong());\n+    }\n+\n+    /** Worker to write to performance statistics file. */\n+    private class FileWriter extends GridWorker {\n+        /** Maximum cached string count. */\n+        private static final short MAX_CACHED_STRING_COUNT = Short.MAX_VALUE;\n+\n+        /** Performance statistics file I/O. */\n+        private final FileIO fileIo;\n+\n+        /** File write buffer. */\n+        private final SegmentedRingByteBuffer ringByteBuffer;\n+\n+        /** Minimal batch size to flush in bytes. */\n+        private final int flushBatchSize;\n+\n+        /** Size of ready for flushing bytes. */\n+        private final AtomicInteger readyForFlushSize = new AtomicInteger();\n+\n+        /** Stop file writer future. */\n+        GridFutureAdapter<Void> stopFut = new GridFutureAdapter<>();\n+\n+        /** Cached strings by id. */\n+        private final ConcurrentHashMap<String, Short> stringIds = new ConcurrentHashMap<>();\n+\n+        /** String id generator. */\n+        private final AtomicInteger idsGen = new AtomicInteger();\n+\n+        /** {@code True} if the small buffer warning message logged. */\n+        private final AtomicBoolean smallBufLogged = new AtomicBoolean();\n+\n+        /** {@code True} if worker stopped due to maximum file size reached. */\n+        private final AtomicBoolean stopByMaxSize = new AtomicBoolean();\n+\n+        /**\n+         * @param ctx Kernal context.\n+         * @param fileIo Performance statistics file I/O.\n+         * @param maxFileSize Maximum file size in bytes.\n+         * @param bufferSize Off heap buffer size in bytes.\n+         * @param flushBatchSize Minimal batch size to flush in bytes.\n+         * @param log Logger.\n+         */\n+        FileWriter(GridKernalContext ctx, FileIO fileIo, long maxFileSize, int bufferSize, int flushBatchSize,\n+            IgniteLogger log) {\n+            super(ctx.igniteInstanceName(), \"performance-statistics-writer%\" + ctx.igniteInstanceName(), log);\n+\n+            this.fileIo = fileIo;\n+            this.flushBatchSize = flushBatchSize;\n+\n+            ringByteBuffer = new SegmentedRingByteBuffer(bufferSize, maxFileSize, BufferMode.DIRECT);\n+\n+            ringByteBuffer.init(0);\n+        }\n+\n+        /** {@inheritDoc} */\n+        @Override protected void body() throws InterruptedException, IgniteInterruptedCheckedException {\n+            while (!isCancelled() && !Thread.interrupted()) {", "originalCommit": "15dcf55d7542987a0916aaec1f8647c9ac225ac7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk4OTUxMQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r448989511", "bodyText": "No need. Removed.", "author": "NSAmelchev", "createdAt": "2020-07-02T13:09:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk4MjIxMg=="}], "type": "inlineReview"}, {"oid": "03c8223d8d0632860148fed785934b08423a6562", "url": "https://github.com/apache/ignite/commit/03c8223d8d0632860148fed785934b08423a6562", "message": "Review fixes", "committedDate": "2020-07-02T13:08:11Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAwODQxMA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449008410", "bodyText": "Can we use the string hash code as an identifier?\nStoring ConcurrentHashMap with the query string will create GC pressure if the user executes many different queries.\nWe can use Set or even BloomFilter implementation to check if some string already seen in the current statistics.", "author": "nizhikov", "createdAt": "2020-07-02T13:38:59Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,660 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInternalFuture;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.future.GridFinishedFuture;\n+import org.apache.ignite.internal.util.future.GridFutureAdapter;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * 1024 * 1024 * 1024L;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = 32 * 1024 * 1024;\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = 8 * 1024 * 1024;\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** @return {@code True} if collecting performance statistics enabled. */\n+    public boolean performanceStatisticsEnabled() {\n+        return enabled;\n+    }\n+\n+    /** Starts collecting performance statistics. */\n+    public synchronized void start() {\n+        if (enabled)\n+            return;\n+\n+        FileWriter writer = fileWriter;\n+\n+        // Writer is stopping.\n+        if (writer != null) {\n+            try {\n+                writer.shutdown().get();\n+            }\n+            catch (IgniteCheckedException e) {\n+                throw new IgniteException(\"Failed to wait for previous writer stopping.\", e);\n+            }\n+        }\n+\n+        assert fileWriter == null;\n+\n+        try {\n+            File file = statisticsFile(ctx);\n+\n+            U.delete(file);\n+\n+            FileIO fileIo = fileIoFactory.create(file);\n+\n+            fileIo.position(0);\n+\n+            fileWriter = new FileWriter(ctx, fileIo, DFLT_FILE_MAX_SIZE, DFLT_BUFFER_SIZE, DFLT_FLUSH_SIZE, log);\n+\n+            new IgniteThread(fileWriter).start();\n+\n+            enabled = true;\n+\n+            log.info(\"Performance statistics writer started [file=\" + file.getAbsolutePath() + ']');\n+        }\n+        catch (IOException | IgniteCheckedException e) {\n+            log.error(\"Failed to start performance statistics writer.\", e);\n+\n+            throw new IgniteException(\"Failed to start performance statistics writer.\", e);\n+        }\n+    }\n+\n+    /** Stops collecting performance statistics. */\n+    public IgniteInternalFuture<Void> stop() {\n+        synchronized (this) {\n+            if (!enabled)\n+                return new GridFinishedFuture<>();\n+\n+            enabled = false;\n+        }\n+\n+        log.info(\"Stopping performance statistics writer.\");\n+\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        if (fileWriter != null)\n+            return fileWriter.shutdown();\n+\n+        return new GridFinishedFuture<>();\n+    }\n+\n+    /**\n+     * @param type Operation type.\n+     * @param cacheId Cache id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     */\n+    public void cacheOperation(CacheOperation type, int cacheId, long startTime, long duration) {\n+        int size = /*type*/ 1 +\n+            /*cacheId*/ 4 +\n+            /*startTime*/ 8 +\n+            /*duration*/ 8;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.CACHE_OPERATION, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)type.ordinal());\n+        buf.putInt(cacheId);\n+        buf.putLong(startTime);\n+        buf.putLong(duration);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * @param cacheIds Cache IDs.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param commited {@code True} if commited.\n+     */\n+    public void transaction(GridIntList cacheIds, long startTime, long duration, boolean commited) {\n+        int size = /*cacheIds*/ 4 + cacheIds.size() * 4 +\n+            /*startTime*/ 8 +\n+            /*duration*/ 8 +\n+            /*commit*/ 1;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.TRANSACTION, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.putInt(cacheIds.size());\n+\n+        GridIntIterator iter = cacheIds.iterator();\n+\n+        while (iter.hasNext())\n+            buf.putInt(iter.next());\n+\n+        buf.putLong(startTime);\n+        buf.putLong(duration);\n+        buf.put(commited ? (byte)1 : 0);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param text Query text in case of SQL query. Cache name in case of SCAN query.\n+     * @param id Query id.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration in nanoseconds.\n+     * @param success Success flag.\n+     */\n+    public void query(GridCacheQueryType type, String text, long id, long startTime, long duration, boolean success) {\n+        FileWriter writer = fileWriter;\n+\n+        if (writer == null)\n+            return;\n+\n+        Short strId = writer.stringId(text);\n+\n+        boolean needWriteStr = strId == null;\n+\n+        byte[] strBytes = null;\n+\n+        int size = /*type*/ 1 +\n+            /*compactStringFlag*/ 1 +\n+            /*strId*/ 2 +\n+            /*id*/ 8 +\n+            /*startTime*/ 8 +\n+            /*duration*/ 8 +\n+            /*success*/ 1;\n+\n+        if (needWriteStr) {\n+            strBytes = text.getBytes();\n+\n+            size += /*text*/ 4 + strBytes.length;\n+\n+            strId = writer.generateStringId(text);\n+        }\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.QUERY, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)type.ordinal());\n+        buf.put(needWriteStr ? (byte)1 : 0);\n+        buf.putShort(strId);\n+\n+        if (needWriteStr) {\n+            buf.putInt(strBytes.length);\n+            buf.put(strBytes);\n+        }\n+\n+        buf.putLong(id);\n+        buf.putLong(startTime);\n+        buf.putLong(duration);\n+        buf.put(success ? (byte)1 : 0);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * @param type Cache query type.\n+     * @param queryNodeId Originating node id.\n+     * @param id Query id.\n+     * @param logicalReads Number of logical reads.\n+     * @param physicalReads Number of physical reads.\n+     */\n+    public void queryReads(GridCacheQueryType type, UUID queryNodeId, long id, long logicalReads, long physicalReads) {\n+        int size = /*type*/ 1 +\n+            /*queryNodeId*/ 16 +\n+            /*id*/ 8 +\n+            /*logicalReads*/ 8 +\n+            /*physicalReads*/ 8;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.QUERY_READS, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)type.ordinal());\n+        writeUuid(buf, queryNodeId);\n+        buf.putLong(id);\n+        buf.putLong(logicalReads);\n+        buf.putLong(physicalReads);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param taskName Task name.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Duration.\n+     * @param affPartId Affinity partition id.\n+     */\n+    public void task(IgniteUuid sesId, String taskName, long startTime, long duration, int affPartId) {\n+        FileWriter writer = fileWriter;\n+\n+        if (writer == null)\n+            return;\n+\n+        Short strId = writer.stringId(taskName);\n+\n+        boolean needWriteStr = strId == null;\n+\n+        byte[] strBytes = null;\n+\n+        int size = /*sesId*/ 24 +\n+            /*compactStringFlag*/ 1 +\n+            /*strId*/ 2 +\n+            /*startTime*/ 8 +\n+            /*duration*/ 8 +\n+            /*affPartId*/ 4;\n+\n+        if (needWriteStr) {\n+            strBytes = taskName.getBytes();\n+\n+            size += /*taskName*/ 4 + strBytes.length;\n+\n+            strId = writer.generateStringId(taskName);\n+        }\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.TASK, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        writeIgniteUuid(buf, sesId);\n+        buf.put(needWriteStr ? (byte)1 : 0);\n+        buf.putShort(strId);\n+\n+        if (needWriteStr) {\n+            buf.putInt(strBytes.length);\n+            buf.put(strBytes);\n+        }\n+\n+        buf.putLong(startTime);\n+        buf.putLong(duration);\n+        buf.putInt(affPartId);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * @param sesId Session id.\n+     * @param queuedTime Time job spent on waiting queue.\n+     * @param startTime Start time in milliseconds.\n+     * @param duration Job execution time.\n+     * @param timedOut {@code True} if job is timed out.\n+     */\n+    public void job(IgniteUuid sesId, long queuedTime, long startTime, long duration, boolean timedOut) {\n+        int size = /*sesId*/ 24 +\n+            /*queuedTime*/ 8 +\n+            /*startTime*/ 8 +\n+            /*duration*/ 8 +\n+            /*timedOut*/ 1;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = reserveBuffer(OperationType.JOB, size);\n+\n+        if (seg == null)\n+            return;\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        writeIgniteUuid(buf, sesId);\n+        buf.putLong(queuedTime);\n+        buf.putLong(startTime);\n+        buf.putLong(duration);\n+        buf.put(timedOut ? (byte)1 : 0);\n+\n+        seg.release();\n+    }\n+\n+    /**\n+     * Reserves buffer's write segment.\n+     *\n+     * @return Buffer's write segment or {@code null} if not enought space or writer stopping.\n+     */\n+    private SegmentedRingByteBuffer.WriteSegment reserveBuffer(OperationType type, int size) {\n+        FileWriter fileWriter = this.fileWriter;\n+\n+        // Writer stopping.\n+        if (fileWriter == null)\n+            return null;\n+\n+        SegmentedRingByteBuffer.WriteSegment seg = fileWriter.writeSegment(size + /*type*/ 1);\n+\n+        if (seg == null) {\n+            fileWriter.logSmallBufferMessage();\n+\n+            return null;\n+        }\n+\n+        // Ring buffer closed (writer stopping) or maximum size reached.\n+        if (seg.buffer() == null) {\n+            seg.release();\n+\n+            if (!fileWriter.isCancelled())\n+                fileWriter.onMaxFileSizeReached();\n+\n+            return null;\n+        }\n+\n+        ByteBuffer buf = seg.buffer();\n+\n+        buf.put((byte)type.ordinal());\n+\n+        return seg;\n+    }\n+\n+    /** @return Performance statistics file. */\n+    public static File statisticsFile(GridKernalContext ctx) throws IgniteCheckedException {\n+        String igniteWorkDir = U.workDirectory(ctx.config().getWorkDirectory(), ctx.config().getIgniteHome());\n+\n+        File fileDir = U.resolveWorkDirectory(igniteWorkDir, PERFORMANCE_STAT_DIR, false);\n+\n+        return new File(fileDir, \"node-\" + ctx.localNodeId() + \".prf\");\n+    }\n+\n+    /** Writes {@link UUID} to buffer. */\n+    public static void writeUuid(ByteBuffer buf, UUID uuid) {\n+        buf.putLong(uuid.getMostSignificantBits());\n+        buf.putLong(uuid.getLeastSignificantBits());\n+    }\n+\n+    /** Reads {@link UUID} from buffer. */\n+    public static UUID readUuid(ByteBuffer buf) {\n+        return new UUID(buf.getLong(), buf.getLong());\n+    }\n+\n+    /** Writes {@link IgniteUuid} to buffer. */\n+    public static void writeIgniteUuid(ByteBuffer buf, IgniteUuid uuid) {\n+        buf.putLong(uuid.globalId().getMostSignificantBits());\n+        buf.putLong(uuid.globalId().getLeastSignificantBits());\n+        buf.putLong(uuid.localId());\n+    }\n+\n+    /** Reads {@link IgniteUuid} from buffer. */\n+    public static IgniteUuid readIgniteUuid(ByteBuffer buf) {\n+        UUID globalId = new UUID(buf.getLong(), buf.getLong());\n+\n+        return new IgniteUuid(globalId, buf.getLong());\n+    }\n+\n+    /** Worker to write to performance statistics file. */\n+    private class FileWriter extends GridWorker {\n+        /** Maximum cached string count. */\n+        private static final short MAX_CACHED_STRING_COUNT = Short.MAX_VALUE;\n+\n+        /** Performance statistics file I/O. */\n+        private final FileIO fileIo;\n+\n+        /** File write buffer. */\n+        private final SegmentedRingByteBuffer ringByteBuffer;\n+\n+        /** Minimal batch size to flush in bytes. */\n+        private final int flushBatchSize;\n+\n+        /** Size of ready for flushing bytes. */\n+        private final AtomicInteger readyForFlushSize = new AtomicInteger();\n+\n+        /** Stop file writer future. */\n+        GridFutureAdapter<Void> stopFut = new GridFutureAdapter<>();\n+\n+        /** Cached strings by id. */\n+        private final ConcurrentHashMap<String, Short> stringIds = new ConcurrentHashMap<>();\n+\n+        /** String id generator. */\n+        private final AtomicInteger idsGen = new AtomicInteger();\n+\n+        /** {@code True} if the small buffer warning message logged. */\n+        private final AtomicBoolean smallBufLogged = new AtomicBoolean();\n+\n+        /** {@code True} if worker stopped due to maximum file size reached. */\n+        private final AtomicBoolean stopByMaxSize = new AtomicBoolean();\n+\n+        /**\n+         * @param ctx Kernal context.\n+         * @param fileIo Performance statistics file I/O.\n+         * @param maxFileSize Maximum file size in bytes.\n+         * @param bufferSize Off heap buffer size in bytes.\n+         * @param flushBatchSize Minimal batch size to flush in bytes.\n+         * @param log Logger.\n+         */\n+        FileWriter(GridKernalContext ctx, FileIO fileIo, long maxFileSize, int bufferSize, int flushBatchSize,\n+            IgniteLogger log) {\n+            super(ctx.igniteInstanceName(), \"performance-statistics-writer%\" + ctx.igniteInstanceName(), log);\n+\n+            this.fileIo = fileIo;\n+            this.flushBatchSize = flushBatchSize;\n+\n+            ringByteBuffer = new SegmentedRingByteBuffer(bufferSize, maxFileSize, BufferMode.DIRECT);\n+\n+            ringByteBuffer.init(0);\n+        }\n+\n+        /** {@inheritDoc} */\n+        @Override protected void body() throws InterruptedException, IgniteInterruptedCheckedException {\n+            while (!isCancelled() && !Thread.interrupted()) {\n+                blockingSectionBegin();\n+\n+                try {\n+                    synchronized (this) {\n+                        while (readyForFlushSize.get() < flushBatchSize && !isCancelled())\n+                            wait();\n+                    }\n+\n+                    flushBuffer();\n+                }\n+                finally {\n+                    blockingSectionEnd();\n+                }\n+            }\n+\n+            fileWriter = null;\n+\n+            ringByteBuffer.close();\n+\n+            // Make sure that all producers released their buffers to safe deallocate memory.\n+            ringByteBuffer.poll();\n+\n+            ringByteBuffer.free();\n+\n+            U.closeQuiet(fileIo);\n+\n+            stringIds.clear();\n+\n+            stopFut.onDone();\n+\n+            log.info(\"Performance statistics writer stopped.\");\n+        }\n+\n+        /** @return Unique per file string identifier. {@code Null} if there is no cached identifier. */\n+        Short stringId(String str) {\n+            return stringIds.get(str);\n+        }\n+\n+        /** @return Generate unique per file string identifier. {@code -1} if max cached limit exceeded. */\n+        short generateStringId(String str) {\n+            if (idsGen.get() > MAX_CACHED_STRING_COUNT)", "originalCommit": "15dcf55d7542987a0916aaec1f8647c9ac225ac7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAzMDc4NQ==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449030785", "bodyText": "I want to avoid collisions. It may lead to wrong results interpretation.\nMAX_CACHED_STRING_COUNT can be decreased to reduce GC pressure.", "author": "NSAmelchev", "createdAt": "2020-07-02T14:11:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAwODQxMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAzMTY2Mw==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449031663", "bodyText": "What collisions do you have in mind? A collision of hash codes of the two strings?", "author": "nizhikov", "createdAt": "2020-07-02T14:12:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAwODQxMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTA2MzE1NA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449063154", "bodyText": "I have implemented with Set of hashcodes", "author": "NSAmelchev", "createdAt": "2020-07-02T14:57:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAwODQxMA=="}], "type": "inlineReview"}, {"oid": "c7873fc3323864aa01a6bc16133676d7be49efa9", "url": "https://github.com/apache/ignite/commit/c7873fc3323864aa01a6bc16133676d7be49efa9", "message": "Review fixes", "committedDate": "2020-07-02T14:51:38Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTEyOTE5MA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449129190", "bodyText": "Let's rename this to enabled.", "author": "nizhikov", "createdAt": "2020-07-02T16:18:11Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/performancestatistics/FilePerformanceStatisticsWriter.java", "diffHunk": "@@ -0,0 +1,643 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.ignite.internal.processors.performancestatistics;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.IgniteInternalFuture;\n+import org.apache.ignite.internal.IgniteInterruptedCheckedException;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIO;\n+import org.apache.ignite.internal.processors.cache.persistence.file.FileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.file.RandomAccessFileIOFactory;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer;\n+import org.apache.ignite.internal.processors.cache.persistence.wal.SegmentedRingByteBuffer.BufferMode;\n+import org.apache.ignite.internal.processors.cache.query.GridCacheQueryType;\n+import org.apache.ignite.internal.util.GridIntIterator;\n+import org.apache.ignite.internal.util.GridIntList;\n+import org.apache.ignite.internal.util.future.GridFinishedFuture;\n+import org.apache.ignite.internal.util.future.GridFutureAdapter;\n+import org.apache.ignite.internal.util.typedef.internal.U;\n+import org.apache.ignite.internal.util.worker.GridWorker;\n+import org.apache.ignite.lang.IgniteUuid;\n+import org.apache.ignite.thread.IgniteThread;\n+import org.jetbrains.annotations.Nullable;\n+\n+/**\n+ * Performance statistics collector based on logging to a file.\n+ * <p>\n+ * Each node collects statistics to a file placed under {@link #PERFORMANCE_STAT_DIR}.\n+ * <p>\n+ * <b>Note:</b> Start again will erase previous performance statistics files.\n+ * <p>\n+ * To iterate over records use {@link FilePerformanceStatisticsReader}.\n+ */\n+public class FilePerformanceStatisticsWriter {\n+    /** Default maximum file size in bytes. Performance statistics will be stopped when the size exceeded. */\n+    public static final long DFLT_FILE_MAX_SIZE = 32 * 1024 * 1024 * 1024L;\n+\n+    /** Default off heap buffer size in bytes. */\n+    public static final int DFLT_BUFFER_SIZE = 32 * 1024 * 1024;\n+\n+    /** Default minimal batch size to flush in bytes. */\n+    public static final int DFLT_FLUSH_SIZE = 8 * 1024 * 1024;\n+\n+    /** Directory to store performance statistics files. Placed under Ignite work directory. */\n+    public static final String PERFORMANCE_STAT_DIR = \"performanceStatistics\";\n+\n+    /** Factory to provide I/O interface. */\n+    private final FileIOFactory fileIoFactory = new RandomAccessFileIOFactory();\n+\n+    /** Performance statistics enabled flag. */\n+    private volatile boolean enabled;\n+\n+    /** Performance statistics file writer worker. */\n+    @Nullable private volatile FileWriter fileWriter;\n+\n+    /** Kernal context. */\n+    private final GridKernalContext ctx;\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** @param ctx Kernal context. */\n+    public FilePerformanceStatisticsWriter(GridKernalContext ctx) {\n+        log = ctx.log(getClass());\n+\n+        this.ctx = ctx;\n+    }\n+\n+    /** @return {@code True} if collecting performance statistics enabled. */\n+    public boolean performanceStatisticsEnabled() {", "originalCommit": "c7873fc3323864aa01a6bc16133676d7be49efa9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTEzODY0MA==", "url": "https://github.com/apache/ignite/pull/7693#discussion_r449138640", "bodyText": "Done", "author": "NSAmelchev", "createdAt": "2020-07-02T16:34:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTEyOTE5MA=="}], "type": "inlineReview"}]}