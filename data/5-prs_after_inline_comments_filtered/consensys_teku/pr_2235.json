{"pr_number": 2235, "pr_title": "Optimize memory:  keep BeaconState view caches via SoftReference", "pr_createdAt": "2020-06-26T17:52:11Z", "pr_url": "https://github.com/ConsenSys/teku/pull/2235", "timeline": [{"oid": "667e218ed9169e324d0c5ab19011bb6f92ac2aa0", "url": "https://github.com/ConsenSys/teku/commit/667e218ed9169e324d0c5ab19011bb6f92ac2aa0", "message": "Clean up ProfilingRun and add a separate method for manual mem testing", "committedDate": "2020-06-26T16:34:36Z", "type": "commit"}, {"oid": "ec9483550d750df34d9f177e74e45deca53a3a63", "url": "https://github.com/ConsenSys/teku/commit/ec9483550d750df34d9f177e74e45deca53a3a63", "message": "Adjust ProfilingRun and add missing dependency", "committedDate": "2020-06-26T17:35:41Z", "type": "commit"}, {"oid": "b7504a14eeeaabb61b70f10ad6521976c7779e82", "url": "https://github.com/ConsenSys/teku/commit/b7504a14eeeaabb61b70f10ad6521976c7779e82", "message": "For topmost BeaconStateImpl view create a soft-reference child view cache to make heap usage more flexible", "committedDate": "2020-06-26T17:37:21Z", "type": "commit"}, {"oid": "3a46a5b99a5cd2070b5398f4b529881b42c6917c", "url": "https://github.com/ConsenSys/teku/commit/3a46a5b99a5cd2070b5398f4b529881b42c6917c", "message": "Apply spotless", "committedDate": "2020-06-26T17:41:09Z", "type": "commit"}, {"oid": "41a2b8e09e8776eb341189446c86a8c6d4d6c13a", "url": "https://github.com/ConsenSys/teku/commit/41a2b8e09e8776eb341189446c86a8c6d4d6c13a", "message": "Resolve erroprone warns", "committedDate": "2020-06-26T18:04:15Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjcwMDg3Mg==", "url": "https://github.com/ConsenSys/teku/pull/2235#discussion_r446700872", "bodyText": "I'm assuming we're ok with multiple threads winding up creating new caches at the same time here?  One of them will just wind up being GC'd again pretty much immediately which is the same behaviour we'd see if a single new SoftReference as created and the GC immediately cleared it out again.", "author": "ajsutton", "createdAt": "2020-06-28T21:33:25Z", "path": "ssz/src/main/java/tech/pegasys/teku/ssz/backing/cache/SoftRefIntCache.java", "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Copyright 2020 ConsenSys AG.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n+ * an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package tech.pegasys.teku.ssz.backing.cache;\n+\n+import java.lang.ref.SoftReference;\n+import java.util.Optional;\n+import java.util.function.Function;\n+import java.util.function.IntFunction;\n+import java.util.function.Supplier;\n+\n+/**\n+ * Keeps the delegate cache in a {@link SoftReference} to allow the cache to be GC'ed if the\n+ * application lacks of heap memory.\n+ *\n+ * <p>On {@link #copy()} or {@link #transfer()} also returns a {@link SoftRefIntCache} instance\n+ */\n+public class SoftRefIntCache<V> implements IntCache<V> {\n+\n+  private final Supplier<IntCache<V>> cacheCtor;\n+  private volatile SoftReference<IntCache<V>> delegate;\n+\n+  private SoftRefIntCache(IntCache<V> initialDelegate, Supplier<IntCache<V>> cacheCtor) {\n+    this.cacheCtor = cacheCtor;\n+    delegate = new SoftReference<>(initialDelegate);\n+  }\n+\n+  public SoftRefIntCache(Supplier<IntCache<V>> cacheCtor) {\n+    this(cacheCtor.get(), cacheCtor);\n+  }\n+\n+  public IntCache<V> getDelegate() {\n+    IntCache<V> cache = delegate.get();\n+    if (cache == null) {\n+      cache = cacheCtor.get();\n+      delegate = new SoftReference<>(cache);\n+    }\n+    return cache;", "originalCommit": "41a2b8e09e8776eb341189446c86a8c6d4d6c13a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjkwMTk4NA==", "url": "https://github.com/ConsenSys/teku/pull/2235#discussion_r446901984", "bodyText": "Yes, concurrent access case that should work fine here. It can lead to an additional cache miss in that case but that trade off seems OK to me.\nI decided to avoid synchronized here as concurrent access would not be the usual case IMHO", "author": "Nashatyrev", "createdAt": "2020-06-29T11:36:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjcwMDg3Mg=="}], "type": "inlineReview"}, {"oid": "a318e3f421db891d2443196b7c4d9133206ac8b6", "url": "https://github.com/ConsenSys/teku/commit/a318e3f421db891d2443196b7c4d9133206ac8b6", "message": "Merge branch 'master' into optimize-mem-state-views", "committedDate": "2020-06-29T11:30:03Z", "type": "commit"}, {"oid": "0cb2cbd21d7da4b421189eca381ba0d6bbddc704", "url": "https://github.com/ConsenSys/teku/commit/0cb2cbd21d7da4b421189eca381ba0d6bbddc704", "message": "Resolve merge conflict", "committedDate": "2020-06-29T12:50:19Z", "type": "commit"}]}