{"pr_number": 7350, "pr_title": "7275 upload auxiliary files", "pr_createdAt": "2020-10-22T19:00:42Z", "pr_url": "https://github.com/IQSS/dataverse/pull/7350", "timeline": [{"oid": "5c2391beb65528675609d499882e41eb56709518", "url": "https://github.com/IQSS/dataverse/commit/5c2391beb65528675609d499882e41eb56709518", "message": "new API method for saving a generic auxiliary file to a data file", "committedDate": "2020-10-13T18:13:25Z", "type": "commit"}, {"oid": "91748b3e395c78b176eab1fd9f66085cfaae36bb", "url": "https://github.com/IQSS/dataverse/commit/91748b3e395c78b176eab1fd9f66085cfaae36bb", "message": "modified framework for the download/GET part of the new aux. metadata API. will post more info tomorrow, about what may still needs to be done there. #7275", "committedDate": "2020-10-19T22:44:09Z", "type": "commit"}, {"oid": "d6ce1d7e5066a6ad2c68f5f6aac6974fa799c1e9", "url": "https://github.com/IQSS/dataverse/commit/d6ce1d7e5066a6ad2c68f5f6aac6974fa799c1e9", "message": "added checksum and contentType to AuxiliaryFile entity", "committedDate": "2020-10-22T18:56:28Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE1MTY0Ng==", "url": "https://github.com/IQSS/dataverse/pull/7350#discussion_r511151646", "bodyText": "storageIO.open called above creates the inputStream for the main file. If it's not going to be used, it needs to be closed (storageIO.getInpputStream().close() - StorageIO doesn't implement Closeable yet/have a close() method - which could be useful someday).", "author": "qqmyers", "createdAt": "2020-10-23T20:56:36Z", "path": "src/main/java/edu/harvard/iq/dataverse/api/DownloadInstanceWriter.java", "diffHunk": "@@ -227,6 +227,18 @@ public void writeTo(DownloadInstance di, Class<?> clazz, Type type, Annotation[]\n                         // (similarly to what the Access API returns when a thumbnail is requested on a text file, etc.)\n                         throw new NotFoundException(\"datafile access error: requested optional service (image scaling, format conversion, etc.) could not be performed on this datafile.\");\n                     }\n+                } else if (di.getAuxiliaryFile() != null) {\n+                    String auxTag = di.getAuxiliaryFile().getFormatTag(); \n+                    String auxVersion = di.getAuxiliaryFile().getFormatVersion();\n+                    if (auxVersion != null) {\n+                        auxTag = auxTag + \"_\" + auxVersion;\n+                    }\n+                    long auxFileSize = di.getAuxiliaryFile().getFileSize();\n+                    InputStreamIO auxStreamIO = new InputStreamIO(storageIO.getAuxFileAsInputStream(auxTag), auxFileSize);\n+                    auxStreamIO.setFileName(storageIO.getFileName() + \".\" + auxTag);\n+                    auxStreamIO.setMimeType(di.getAuxiliaryFile().getContentType());\n+                    storageIO = auxStreamIO;", "originalCommit": "d6ce1d7e5066a6ad2c68f5f6aac6974fa799c1e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjAxMzY2NA==", "url": "https://github.com/IQSS/dataverse/pull/7350#discussion_r512013664", "bodyText": "Thanks, I missed that. Fixed.\nIt's not pretty, what goes on in that DownloadInstance/DownloadInstanceWriter setup, btw. I am opening an issue for cleaning up/simplifying/rewriting it.", "author": "landreev", "createdAt": "2020-10-26T14:42:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE1MTY0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE1NTE0NA==", "url": "https://github.com/IQSS/dataverse/pull/7350#discussion_r511155144", "bodyText": "So far Tika is only used for full-text indexing and content-type detection is done differently for Datafiles. Could/should these both be done the same way? (not necessarily in this PR)", "author": "qqmyers", "createdAt": "2020-10-23T21:05:39Z", "path": "src/main/java/edu/harvard/iq/dataverse/AuxiliaryFileServiceBean.java", "diffHunk": "@@ -0,0 +1,114 @@\n+\n+package edu.harvard.iq.dataverse;\n+\n+import edu.harvard.iq.dataverse.dataaccess.StorageIO;\n+import edu.harvard.iq.dataverse.util.FileUtil;\n+import edu.harvard.iq.dataverse.util.SystemConfig;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.logging.Logger;\n+import javax.ejb.EJB;\n+import javax.ejb.Stateless;\n+import javax.inject.Named;\n+import javax.persistence.EntityManager;\n+import javax.persistence.PersistenceContext;\n+import javax.persistence.Query;\n+import org.apache.tika.Tika;\n+\n+/**\n+ *\n+ * @author ekraffmiller\n+ *  Methods related to the AuxiliaryFile Entity.\n+ */\n+@Stateless\n+@Named\n+public class AuxiliaryFileServiceBean implements java.io.Serializable {\n+   private static final Logger logger = Logger.getLogger(AuxiliaryFileServiceBean.class.getCanonicalName());\n+\n+    @PersistenceContext(unitName = \"VDCNet-ejbPU\")\n+    private EntityManager em;\n+    \n+    @EJB\n+    private SystemConfig systemConfig;\n+    \n+\n+    public AuxiliaryFile find(Object pk) {\n+        return em.find(AuxiliaryFile.class, pk);\n+    }\n+\n+    public AuxiliaryFile save(AuxiliaryFile auxiliaryFile) {\n+        AuxiliaryFile savedFile = em.merge(auxiliaryFile);\n+        return savedFile;\n+\n+    }\n+    \n+    /**\n+     * Save the physical file to storageIO, and save the AuxiliaryFile entity\n+     * to the database.  This should be an all or nothing transaction - if either\n+     * process fails, than nothing will be saved\n+     * @param fileInputStream - auxiliary file data to be saved\n+     * @param dataFile  - the dataFile entity this will be added to\n+     * @param formatTag - type of file being saved\n+     * @param formatVersion - to distinguish between multiple versions of a file\n+     * @param origin - name of the tool/system that created the file\n+     * @param isPublic boolean - is this file available to any user?\n+     * @return success boolean - returns whether the save was successful\n+     */\n+    public boolean processAuxiliaryFile(InputStream fileInputStream, DataFile dataFile, String formatTag, String formatVersion, String origin, boolean isPublic) {\n+    \n+        StorageIO<DataFile> storageIO =null;\n+      \n+        String auxExtension = formatTag + \"_\" + formatVersion;\n+        try {\n+            // Save to storage first.\n+            // If that is successful (does not throw exception),\n+            // then save to db.\n+            // If the db fails for any reason, then rollback\n+            // by removing the auxfile from storage.\n+            storageIO = dataFile.getStorageIO();\n+            AuxiliaryFile auxFile = new AuxiliaryFile();\n+            storageIO.saveInputStreamAsAux(fileInputStream, auxExtension);\n+            auxFile.setChecksum(FileUtil.calculateChecksum(storageIO.getAuxFileAsInputStream(auxExtension), systemConfig.getFileFixityChecksumAlgorithm()));\n+\n+            Tika tika = new Tika();", "originalCommit": "d6ce1d7e5066a6ad2c68f5f6aac6974fa799c1e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE3MTI0MQ==", "url": "https://github.com/IQSS/dataverse/pull/7350#discussion_r515171241", "bodyText": "for Datafiles, JHove is used, which works on a file as opposed to an inputStream.  So to use JHove, I think I would have to save the aux file to a temp location, unless I'm missing something. Is this something we want to do?", "author": "ekraffmiller", "createdAt": "2020-10-30T15:13:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE1NTE0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTIwNzI3Mw==", "url": "https://github.com/IQSS/dataverse/pull/7350#discussion_r515207273", "bodyText": "FWIW: Requiring a temp file for mime detection is a problem for Datafiles too, so it may make sense to use Tika instead of JHOVE there as well. (#6937 would make it possible to get ranges of bytes from S3 to help avoid having to get a whole file).", "author": "qqmyers", "createdAt": "2020-10-30T16:02:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE1NTE0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTIxNzcxMQ==", "url": "https://github.com/IQSS/dataverse/pull/7350#discussion_r515217711", "bodyText": "ok, should we create a separate ticket for changing mime detection to Tika for Datafiles? (Is this something that is usually talked about at dv_tech hour?)", "author": "ekraffmiller", "createdAt": "2020-10-30T16:19:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE1NTE0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODk5MDA0MA==", "url": "https://github.com/IQSS/dataverse/pull/7350#discussion_r518990040", "bodyText": "The method that's used for DataFiles is determineContentType in FileUtil. It would probably be good to use the same code path, instead of using Tika. Or switch it all to Tika, I guess, but that seems daunting to me. Or I guess we could use Tika here for now and work on consistency later. And sure, this is a fine topic for tech hours. \ud83d\ude04", "author": "pdurbin", "createdAt": "2020-11-06T20:31:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE1NTE0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDU4ODA1MQ==", "url": "https://github.com/IQSS/dataverse/pull/7350#discussion_r524588051", "bodyText": "Discussed this during tech hours, we agreed that it would be good to eventually switch from JHove to Tika in other parts of the code for consistency", "author": "ekraffmiller", "createdAt": "2020-11-16T21:13:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE1NTE0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODkyOTY0Mg==", "url": "https://github.com/IQSS/dataverse/pull/7350#discussion_r528929642", "bodyText": "I'm about to approve the PR. There's just one thing I regret not having thought about earlier, when we were having this discussion, above: WHY are we trying to detect mime types at all? As opposed to just making the uploading client supply it, as another parameter?\nWe try to detect mime types on \"normal\" uploaded files - but that's because users upload arbitrary files... This API is for something that's structured; at least in the immediate use case scenario. I.e. that preprocessed summary stats fragment will always be in JSON, the diff. private DDI will always be XML etc. etc. We don't expect any variety there...\nI don't see this as a problem, having this detection code in place. It may come in handy for other cases. And, even if we decide that these aux uploads should, or can supply the mime type as a parameter - we could use this detection as an extra validation step.\nStill, I can't help but feel I should've said \"let's not even worry about it, let's just add a parameter instead\", early on.", "author": "landreev", "createdAt": "2020-11-23T19:01:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE1NTE0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE1NTg5NA==", "url": "https://github.com/IQSS/dataverse/pull/7350#discussion_r511155894", "bodyText": "It's not too hard to wrap the fileInputStream and calculate the has during the original write (versus having to retrieve the file and scan it a second time. (The util.Bag code has examples.)", "author": "qqmyers", "createdAt": "2020-10-23T21:07:40Z", "path": "src/main/java/edu/harvard/iq/dataverse/AuxiliaryFileServiceBean.java", "diffHunk": "@@ -0,0 +1,114 @@\n+\n+package edu.harvard.iq.dataverse;\n+\n+import edu.harvard.iq.dataverse.dataaccess.StorageIO;\n+import edu.harvard.iq.dataverse.util.FileUtil;\n+import edu.harvard.iq.dataverse.util.SystemConfig;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.logging.Logger;\n+import javax.ejb.EJB;\n+import javax.ejb.Stateless;\n+import javax.inject.Named;\n+import javax.persistence.EntityManager;\n+import javax.persistence.PersistenceContext;\n+import javax.persistence.Query;\n+import org.apache.tika.Tika;\n+\n+/**\n+ *\n+ * @author ekraffmiller\n+ *  Methods related to the AuxiliaryFile Entity.\n+ */\n+@Stateless\n+@Named\n+public class AuxiliaryFileServiceBean implements java.io.Serializable {\n+   private static final Logger logger = Logger.getLogger(AuxiliaryFileServiceBean.class.getCanonicalName());\n+\n+    @PersistenceContext(unitName = \"VDCNet-ejbPU\")\n+    private EntityManager em;\n+    \n+    @EJB\n+    private SystemConfig systemConfig;\n+    \n+\n+    public AuxiliaryFile find(Object pk) {\n+        return em.find(AuxiliaryFile.class, pk);\n+    }\n+\n+    public AuxiliaryFile save(AuxiliaryFile auxiliaryFile) {\n+        AuxiliaryFile savedFile = em.merge(auxiliaryFile);\n+        return savedFile;\n+\n+    }\n+    \n+    /**\n+     * Save the physical file to storageIO, and save the AuxiliaryFile entity\n+     * to the database.  This should be an all or nothing transaction - if either\n+     * process fails, than nothing will be saved\n+     * @param fileInputStream - auxiliary file data to be saved\n+     * @param dataFile  - the dataFile entity this will be added to\n+     * @param formatTag - type of file being saved\n+     * @param formatVersion - to distinguish between multiple versions of a file\n+     * @param origin - name of the tool/system that created the file\n+     * @param isPublic boolean - is this file available to any user?\n+     * @return success boolean - returns whether the save was successful\n+     */\n+    public boolean processAuxiliaryFile(InputStream fileInputStream, DataFile dataFile, String formatTag, String formatVersion, String origin, boolean isPublic) {\n+    \n+        StorageIO<DataFile> storageIO =null;\n+      \n+        String auxExtension = formatTag + \"_\" + formatVersion;\n+        try {\n+            // Save to storage first.\n+            // If that is successful (does not throw exception),\n+            // then save to db.\n+            // If the db fails for any reason, then rollback\n+            // by removing the auxfile from storage.\n+            storageIO = dataFile.getStorageIO();\n+            AuxiliaryFile auxFile = new AuxiliaryFile();\n+            storageIO.saveInputStreamAsAux(fileInputStream, auxExtension);\n+            auxFile.setChecksum(FileUtil.calculateChecksum(storageIO.getAuxFileAsInputStream(auxExtension), systemConfig.getFileFixityChecksumAlgorithm()));", "originalCommit": "d6ce1d7e5066a6ad2c68f5f6aac6974fa799c1e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE2OTg0Mw==", "url": "https://github.com/IQSS/dataverse/pull/7350#discussion_r515169843", "bodyText": "Can you explain more what you had it mind? I looked at BagGenerator and BagValidationJob, and can't find an example of this.  I could see how you could combine the logic that reads the stream to calculate the checksum, with the read from stream that happens in StorageIO, but I don't see an example of where that's happening.", "author": "ekraffmiller", "createdAt": "2020-10-30T15:11:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE1NTg5NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE3NTQxMA==", "url": "https://github.com/IQSS/dataverse/pull/7350#discussion_r515175410", "bodyText": "Sorry - it would help if I pointed to the right place. It's actually the archiving commands that do this. E.g. the Google Cloud one. They complicate things with threads, but the basic idea is that you wrap your stream with a java.security.DigestInputStream and, once you've finished reading the bytes, you can get the digest for the algorithm you set from that stream.", "author": "qqmyers", "createdAt": "2020-10-30T15:20:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE1NTg5NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE3OTMwMw==", "url": "https://github.com/IQSS/dataverse/pull/7350#discussion_r515179303", "bodyText": "ok, that makes sense, thank you", "author": "ekraffmiller", "createdAt": "2020-10-30T15:25:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE1NTg5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE1NzkwMg==", "url": "https://github.com/IQSS/dataverse/pull/7350#discussion_r511157902", "bodyText": "FWIW: the normal file add uses a single jsonData param rather than multiple FormDataParams. Not sure if that's intended to be consistent across the API.", "author": "qqmyers", "createdAt": "2020-10-23T21:13:20Z", "path": "src/main/java/edu/harvard/iq/dataverse/api/Access.java", "diffHunk": "@@ -1084,6 +1113,65 @@ private String getWebappImageResource(String imageName) {\n     }\n     */\n     \n+    /**\n+     * \n+     * @param fileId\n+     * @param formatTag\n+     * @param formatVersion\n+     * @param origin\n+     * @param isPublic\n+     * @param fileInputStream\n+     * @param contentDispositionHeader\n+     * @param formDataBodyPart\n+     * @return \n+     */\n+    @Path(\"datafile/{fileId}/metadata/{formatTag}/{formatVersion}\")\n+    @POST\n+    @Consumes(MediaType.MULTIPART_FORM_DATA)\n+\n+    public Response saveAuxiliaryFileWithVersion(@PathParam(\"fileId\") Long fileId,\n+            @PathParam(\"formatTag\") String formatTag,\n+            @PathParam(\"formatVersion\") String formatVersion,\n+            @FormDataParam(\"origin\") String origin,", "originalCommit": "d6ce1d7e5066a6ad2c68f5f6aac6974fa799c1e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIzNzgyNw==", "url": "https://github.com/IQSS/dataverse/pull/7350#discussion_r516237827", "bodyText": "I agree with the desire for consistency, but the parameters listed in Auxiliary files are required, whereas for depositing a Datafile, the jsonData parameter contains only optional params.  So I think it's probably better to keep the Auxiliary API as is so that the required parameters are more obvious.", "author": "ekraffmiller", "createdAt": "2020-11-02T20:33:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE1NzkwMg=="}], "type": "inlineReview"}, {"oid": "1e473163032c742eab609346223455abcdadc13f", "url": "https://github.com/IQSS/dataverse/commit/1e473163032c742eab609346223455abcdadc13f", "message": "Making sure there's no open inputstreams left. (#7275)", "committedDate": "2020-10-26T14:38:42Z", "type": "commit"}, {"oid": "1af5a24dfb45f968e4f9e6e84d0f6f37121b17fa", "url": "https://github.com/IQSS/dataverse/commit/1af5a24dfb45f968e4f9e6e84d0f6f37121b17fa", "message": "Use DigestInputStream so that checksum can be calculated when stream\nis being written to storage", "committedDate": "2020-11-02T21:18:30Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODk5NDYzNg==", "url": "https://github.com/IQSS/dataverse/pull/7350#discussion_r518994636", "bodyText": "This method seems to work file so I'd suggest removing this TODO.", "author": "pdurbin", "createdAt": "2020-11-06T20:41:53Z", "path": "src/main/java/edu/harvard/iq/dataverse/AuxiliaryFileServiceBean.java", "diffHunk": "@@ -0,0 +1,120 @@\n+\n+package edu.harvard.iq.dataverse;\n+\n+import edu.harvard.iq.dataverse.dataaccess.StorageIO;\n+import edu.harvard.iq.dataverse.util.FileUtil;\n+import edu.harvard.iq.dataverse.util.SystemConfig;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.security.DigestInputStream;\n+import java.security.MessageDigest;\n+import java.util.logging.Logger;\n+import javax.ejb.EJB;\n+import javax.ejb.Stateless;\n+import javax.inject.Named;\n+import javax.persistence.EntityManager;\n+import javax.persistence.PersistenceContext;\n+import javax.persistence.Query;\n+import org.apache.tika.Tika;\n+\n+/**\n+ *\n+ * @author ekraffmiller\n+ *  Methods related to the AuxiliaryFile Entity.\n+ */\n+@Stateless\n+@Named\n+public class AuxiliaryFileServiceBean implements java.io.Serializable {\n+   private static final Logger logger = Logger.getLogger(AuxiliaryFileServiceBean.class.getCanonicalName());\n+\n+    @PersistenceContext(unitName = \"VDCNet-ejbPU\")\n+    private EntityManager em;\n+    \n+    @EJB\n+    private SystemConfig systemConfig;\n+    \n+\n+    public AuxiliaryFile find(Object pk) {\n+        return em.find(AuxiliaryFile.class, pk);\n+    }\n+\n+    public AuxiliaryFile save(AuxiliaryFile auxiliaryFile) {\n+        AuxiliaryFile savedFile = em.merge(auxiliaryFile);\n+        return savedFile;\n+\n+    }\n+    \n+    /**\n+     * Save the physical file to storageIO, and save the AuxiliaryFile entity\n+     * to the database.  This should be an all or nothing transaction - if either\n+     * process fails, than nothing will be saved\n+     * @param fileInputStream - auxiliary file data to be saved\n+     * @param dataFile  - the dataFile entity this will be added to\n+     * @param formatTag - type of file being saved\n+     * @param formatVersion - to distinguish between multiple versions of a file\n+     * @param origin - name of the tool/system that created the file\n+     * @param isPublic boolean - is this file available to any user?\n+     * @return success boolean - returns whether the save was successful\n+     */\n+    public boolean processAuxiliaryFile(InputStream fileInputStream, DataFile dataFile, String formatTag, String formatVersion, String origin, boolean isPublic) {\n+    \n+        StorageIO<DataFile> storageIO =null;\n+      \n+        String auxExtension = formatTag + \"_\" + formatVersion;\n+        try {\n+            // Save to storage first.\n+            // If that is successful (does not throw exception),\n+            // then save to db.\n+            // If the db fails for any reason, then rollback\n+            // by removing the auxfile from storage.\n+            storageIO = dataFile.getStorageIO();\n+            AuxiliaryFile auxFile = new AuxiliaryFile();\n+            MessageDigest md = MessageDigest.getInstance(systemConfig.getFileFixityChecksumAlgorithm().toString());\n+            DigestInputStream di \n+                = new DigestInputStream(fileInputStream, md); \n+  \n+            storageIO.saveInputStreamAsAux(fileInputStream, auxExtension);          \n+            auxFile.setChecksum(FileUtil.checksumDigestToString(di.getMessageDigest().digest())    );\n+\n+            Tika tika = new Tika();\n+            auxFile.setContentType(tika.detect(storageIO.getAuxFileAsInputStream(auxExtension)));\n+            auxFile.setFormatTag(formatTag);\n+            auxFile.setFormatVersion(formatVersion);\n+            auxFile.setOrigin(origin);\n+            auxFile.setIsPublic(isPublic);\n+            auxFile.setDataFile(dataFile);         \n+            auxFile.setFileSize(storageIO.getAuxObjectSize(auxExtension));\n+            save(auxFile);\n+        } catch (IOException ioex) {\n+            logger.info(\"IO Exception trying to save auxiliary file: \" + ioex.getMessage());\n+            return false;\n+        } catch (Exception e) {\n+            // If anything fails during database insert, remove file from storage\n+            try {\n+                storageIO.deleteAuxObject(auxExtension);\n+            } catch(IOException ioex) {\n+                    logger.info(\"IO Exception trying remove auxiliary file in exception handler: \" + ioex.getMessage());\n+            return false;\n+            }\n+        }\n+        return true;\n+    }\n+    \n+    // Looks up an auxiliary file by its parent DataFile, the formatTag and version\n+    // TODO: improve as needed. ", "originalCommit": "1af5a24dfb45f968e4f9e6e84d0f6f37121b17fa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODk5NjIwOA==", "url": "https://github.com/IQSS/dataverse/pull/7350#discussion_r518996208", "bodyText": "These methods aren't used. It would be nice to get a listing of aux files based on a data file.", "author": "pdurbin", "createdAt": "2020-11-06T20:45:33Z", "path": "src/main/java/edu/harvard/iq/dataverse/DataFile.java", "diffHunk": "@@ -281,6 +284,14 @@ public String getDuplicateFilename() {\n     public void setDuplicateFilename(String duplicateFilename) {\n         this.duplicateFilename = duplicateFilename;\n     }\n+\n+    public List<AuxiliaryFile> getAuxiliaryFiles() {\n+        return auxiliaryFiles;\n+    }\n+\n+    public void setAuxiliaryFiles(List<AuxiliaryFile> auxiliaryFiles) {\n+        this.auxiliaryFiles = auxiliaryFiles;\n+    }", "originalCommit": "1af5a24dfb45f968e4f9e6e84d0f6f37121b17fa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDU5NTQxNg==", "url": "https://github.com/IQSS/dataverse/pull/7350#discussion_r524595416", "bodyText": "We decided to keep the focus on this ticket to deposit and download APIs, other API calls can be added in the future.", "author": "ekraffmiller", "createdAt": "2020-11-16T21:20:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODk5NjIwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTAwMjc0OA==", "url": "https://github.com/IQSS/dataverse/pull/7350#discussion_r519002748", "bodyText": "Instead of tabularDatafileMetadataPreprocessed maybe this should be called tabularDatafileMetadataAux or something (or something entirely new) to deemphasize the older preprocessed format.", "author": "pdurbin", "createdAt": "2020-11-06T21:00:25Z", "path": "src/main/java/edu/harvard/iq/dataverse/api/Access.java", "diffHunk": "@@ -505,35 +500,69 @@ public String dataVariableMetadataDDI(@PathParam(\"varId\") Long varId, @QueryPara\n     }\n     \n     /*\n-     * \"Preprocessed data\" metadata format:\n-     * (this was previously provided as a \"format conversion\" option of the \n-     * file download form of the access API call)\n+     * GET method for retrieving various auxiliary files associated with \n+     * a tabular datafile.\n      */\n     \n-    @Path(\"datafile/{fileId}/metadata/preprocessed\")\n+    @Path(\"datafile/{fileId}/metadata/{formatTag}/{formatVersion}\")\n     @GET\n-    @Produces({\"text/xml\"})\n     \n-    public DownloadInstance tabularDatafileMetadataPreprocessed(@PathParam(\"fileId\") String fileId, @QueryParam(\"key\") String apiToken, @Context UriInfo uriInfo, @Context HttpHeaders headers, @Context HttpServletResponse response) throws ServiceUnavailableException {\n+    public DownloadInstance tabularDatafileMetadataPreprocessed(@PathParam(\"fileId\") String fileId,", "originalCommit": "1af5a24dfb45f968e4f9e6e84d0f6f37121b17fa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTAwOTQ2NQ==", "url": "https://github.com/IQSS/dataverse/pull/7350#discussion_r519009465", "bodyText": "It seems like only InputStream is used. What are FormDataContentDisposition and FormDataBodyPart for?", "author": "pdurbin", "createdAt": "2020-11-06T21:17:28Z", "path": "src/main/java/edu/harvard/iq/dataverse/api/Access.java", "diffHunk": "@@ -1084,6 +1113,65 @@ private String getWebappImageResource(String imageName) {\n     }\n     */\n     \n+    /**\n+     * \n+     * @param fileId\n+     * @param formatTag\n+     * @param formatVersion\n+     * @param origin\n+     * @param isPublic\n+     * @param fileInputStream\n+     * @param contentDispositionHeader\n+     * @param formDataBodyPart\n+     * @return \n+     */\n+    @Path(\"datafile/{fileId}/metadata/{formatTag}/{formatVersion}\")\n+    @POST\n+    @Consumes(MediaType.MULTIPART_FORM_DATA)\n+\n+    public Response saveAuxiliaryFileWithVersion(@PathParam(\"fileId\") Long fileId,\n+            @PathParam(\"formatTag\") String formatTag,\n+            @PathParam(\"formatVersion\") String formatVersion,\n+            @FormDataParam(\"origin\") String origin,\n+            @FormDataParam(\"isPublic\") boolean isPublic,\n+            @FormDataParam(\"file\") InputStream fileInputStream,\n+            @FormDataParam(\"file\") FormDataContentDisposition contentDispositionHeader,\n+            @FormDataParam(\"file\") final FormDataBodyPart formDataBodyPart\n+    ) {", "originalCommit": "1af5a24dfb45f968e4f9e6e84d0f6f37121b17fa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTAxMDY5Ng==", "url": "https://github.com/IQSS/dataverse/pull/7350#discussion_r519010696", "bodyText": "What if we return the aux file id and the detected content type? If we add AuxiliaryFile to JsonPrinter.java, what would the JSON look like?", "author": "pdurbin", "createdAt": "2020-11-06T21:20:33Z", "path": "src/main/java/edu/harvard/iq/dataverse/api/Access.java", "diffHunk": "@@ -1084,6 +1113,65 @@ private String getWebappImageResource(String imageName) {\n     }\n     */\n     \n+    /**\n+     * \n+     * @param fileId\n+     * @param formatTag\n+     * @param formatVersion\n+     * @param origin\n+     * @param isPublic\n+     * @param fileInputStream\n+     * @param contentDispositionHeader\n+     * @param formDataBodyPart\n+     * @return \n+     */\n+    @Path(\"datafile/{fileId}/metadata/{formatTag}/{formatVersion}\")\n+    @POST\n+    @Consumes(MediaType.MULTIPART_FORM_DATA)\n+\n+    public Response saveAuxiliaryFileWithVersion(@PathParam(\"fileId\") Long fileId,\n+            @PathParam(\"formatTag\") String formatTag,\n+            @PathParam(\"formatVersion\") String formatVersion,\n+            @FormDataParam(\"origin\") String origin,\n+            @FormDataParam(\"isPublic\") boolean isPublic,\n+            @FormDataParam(\"file\") InputStream fileInputStream,\n+            @FormDataParam(\"file\") FormDataContentDisposition contentDispositionHeader,\n+            @FormDataParam(\"file\") final FormDataBodyPart formDataBodyPart\n+    ) {\n+        AuthenticatedUser authenticatedUser;\n+        try {\n+            authenticatedUser = findAuthenticatedUserOrDie();\n+        } catch (WrappedResponse ex) {\n+            return error(FORBIDDEN, \"Authorized users only.\");\n+        }\n+\n+        DataFile dataFile = dataFileService.find(fileId);\n+        if (dataFile == null) {\n+            return error(BAD_REQUEST, \"File not found based on id \" + fileId + \".\");\n+        }\n+        \n+         if (!permissionService.userOn(authenticatedUser, dataFile.getOwner()).has(Permission.EditDataset)) {\n+            return error(FORBIDDEN, \"User not authorized to edit the dataset.\");\n+        }\n+\n+        if (!dataFile.isTabularData()) {\n+            return error(BAD_REQUEST, \"Not a tabular DataFile (db id=\" + fileId + \")\");\n+        }\n+         \n+\n+        boolean saved = auxiliaryFileService.processAuxiliaryFile(fileInputStream, dataFile, formatTag, formatVersion, origin, isPublic);\n+      \n+        if (saved) {\n+            return ok(\"Auxiliary file has been saved.\");", "originalCommit": "1af5a24dfb45f968e4f9e6e84d0f6f37121b17fa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "8098f6ff695e10bd2acf31e6048be2ea788a43ae", "url": "https://github.com/IQSS/dataverse/commit/8098f6ff695e10bd2acf31e6048be2ea788a43ae", "message": "Merge branch 'develop' into 7275-upload-auxliary-files", "committedDate": "2020-11-16T20:28:49Z", "type": "commit"}, {"oid": "c1e03a0e302666585123865116a49eba7ee9d031", "url": "https://github.com/IQSS/dataverse/commit/c1e03a0e302666585123865116a49eba7ee9d031", "message": "Updated deposit API method to return JSon data for saved file", "committedDate": "2020-11-16T23:50:56Z", "type": "commit"}, {"oid": "ee61a381b05e37274484f47d2d4042171aac624e", "url": "https://github.com/IQSS/dataverse/commit/ee61a381b05e37274484f47d2d4042171aac624e", "message": "Merge branch '7275-upload-auxliary-files' of github.com:IQSS/dataverse into 7275-upload-auxliary-files", "committedDate": "2020-11-16T23:52:46Z", "type": "commit"}, {"oid": "11b9db65a453229dee6d5242223433e25fff2259", "url": "https://github.com/IQSS/dataverse/commit/11b9db65a453229dee6d5242223433e25fff2259", "message": "removed unneeded comments", "committedDate": "2020-11-17T00:07:23Z", "type": "commit"}, {"oid": "867ad10a7d99b8db5a7ee92407eb7fd72d9a4759", "url": "https://github.com/IQSS/dataverse/commit/867ad10a7d99b8db5a7ee92407eb7fd72d9a4759", "message": "removed redundant initialization", "committedDate": "2020-11-17T00:08:57Z", "type": "commit"}, {"oid": "6e88b55e6ee62a84def7bb23f7a7526172317eae", "url": "https://github.com/IQSS/dataverse/commit/6e88b55e6ee62a84def7bb23f7a7526172317eae", "message": "added documentation for Auxiliary File APIs", "committedDate": "2020-11-17T18:49:03Z", "type": "commit"}, {"oid": "a2c3f0d9e59b098026278f77053fcd6c61b89bf9", "url": "https://github.com/IQSS/dataverse/commit/a2c3f0d9e59b098026278f77053fcd6c61b89bf9", "message": "doc updates", "committedDate": "2020-11-17T21:56:02Z", "type": "commit"}, {"oid": "36b69df6ebf8a32b72cd524337645df22720c0e5", "url": "https://github.com/IQSS/dataverse/commit/36b69df6ebf8a32b72cd524337645df22720c0e5", "message": "removing :", "committedDate": "2020-11-17T21:58:54Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTczNjQxOA==", "url": "https://github.com/IQSS/dataverse/pull/7350#discussion_r529736418", "bodyText": "This use of created with an id seems to be out of step with all other uses. Notice below that we always return the path to the object just created so it can be further manipulated:\n\nSince this API is experimental, we could just switch it from created to ok (both \"add file\" and \"add prov\" use ok and this code itself used ok until I started asking about returning an id in a JSON response which lead to created being added in c1e03a0) or we could put a proper path in, like created expects. From the test in AccessIT, the file can be downloaded from a path like this:\n.get(\"/api/access/datafile/\" + tabFile1Id + \"/metadata/dpJSON/v1\")", "author": "pdurbin", "createdAt": "2020-11-24T17:04:14Z", "path": "src/main/java/edu/harvard/iq/dataverse/api/Access.java", "diffHunk": "@@ -1084,6 +1113,64 @@ private String getWebappImageResource(String imageName) {\n     }\n     */\n     \n+    /**\n+     * \n+     * @param fileId\n+     * @param formatTag\n+     * @param formatVersion\n+     * @param origin\n+     * @param isPublic\n+     * @param fileInputStream\n+     * @param contentDispositionHeader\n+     * @param formDataBodyPart\n+     * @return \n+     */\n+    @Path(\"datafile/{fileId}/metadata/{formatTag}/{formatVersion}\")\n+    @POST\n+    @Consumes(MediaType.MULTIPART_FORM_DATA)\n+\n+    public Response saveAuxiliaryFileWithVersion(@PathParam(\"fileId\") Long fileId,\n+            @PathParam(\"formatTag\") String formatTag,\n+            @PathParam(\"formatVersion\") String formatVersion,\n+            @FormDataParam(\"origin\") String origin,\n+            @FormDataParam(\"isPublic\") boolean isPublic,\n+            @FormDataParam(\"file\") InputStream fileInputStream\n+          \n+    ) {\n+        AuthenticatedUser authenticatedUser;\n+        try {\n+            authenticatedUser = findAuthenticatedUserOrDie();\n+        } catch (WrappedResponse ex) {\n+            return error(FORBIDDEN, \"Authorized users only.\");\n+        }\n+\n+        DataFile dataFile = dataFileService.find(fileId);\n+        if (dataFile == null) {\n+            return error(BAD_REQUEST, \"File not found based on id \" + fileId + \".\");\n+        }\n+        \n+         if (!permissionService.userOn(authenticatedUser, dataFile.getOwner()).has(Permission.EditDataset)) {\n+            return error(FORBIDDEN, \"User not authorized to edit the dataset.\");\n+        }\n+\n+        if (!dataFile.isTabularData()) {\n+            return error(BAD_REQUEST, \"Not a tabular DataFile (db id=\" + fileId + \")\");\n+        }\n+         \n+\n+        AuxiliaryFile saved = auxiliaryFileService.processAuxiliaryFile(fileInputStream, dataFile, formatTag, formatVersion, origin, isPublic);\n+      \n+        if (saved!=null) {\n+            return created(saved.getId().toString(),JsonPrinter.json(saved));", "originalCommit": "36b69df6ebf8a32b72cd524337645df22720c0e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTgwNDM3OA==", "url": "https://github.com/IQSS/dataverse/pull/7350#discussion_r529804378", "bodyText": "@landreev and I talked this out in Slack and decided to go with switching from created to ok in 471dd25 (which is how this pull request started.", "author": "pdurbin", "createdAt": "2020-11-24T18:51:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTczNjQxOA=="}], "type": "inlineReview"}, {"oid": "471dd25d46c253e158aefe382873599719141786", "url": "https://github.com/IQSS/dataverse/commit/471dd25d46c253e158aefe382873599719141786", "message": "switch from created to ok #7275", "committedDate": "2020-11-24T18:48:18Z", "type": "commit"}, {"oid": "023c5b57763bcb62cd972cb41d8f689dc289975c", "url": "https://github.com/IQSS/dataverse/commit/023c5b57763bcb62cd972cb41d8f689dc289975c", "message": "Merge branch 'develop' into 7275-upload-auxliary-files #7275", "committedDate": "2020-11-24T18:49:12Z", "type": "commit"}, {"oid": "21977d0688e3b3465ce8f5a9db081134bcef95fa", "url": "https://github.com/IQSS/dataverse/commit/21977d0688e3b3465ce8f5a9db081134bcef95fa", "message": "make docs match OK/200 response from add #7275", "committedDate": "2020-11-24T18:53:47Z", "type": "commit"}, {"oid": "103b591015df8292174c934e1fde43beee081f16", "url": "https://github.com/IQSS/dataverse/commit/103b591015df8292174c934e1fde43beee081f16", "message": "adding release notes", "committedDate": "2020-11-30T16:46:16Z", "type": "commit"}, {"oid": "82c5f6699ce3e57f3185107967fdab232244988c", "url": "https://github.com/IQSS/dataverse/commit/82c5f6699ce3e57f3185107967fdab232244988c", "message": "Update aux-file-support.rst\n\nfixed typo in deposit URL", "committedDate": "2020-11-30T21:51:20Z", "type": "commit"}]}