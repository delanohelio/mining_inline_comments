{"pr_number": 6986, "pr_title": "6505 optimize zip downloads", "pr_createdAt": "2020-06-16T13:11:48Z", "pr_url": "https://github.com/IQSS/dataverse/pull/6986", "timeline": [{"oid": "b8d268a1a2a11c22739ce8a5a8aa2457f0d17711", "url": "https://github.com/IQSS/dataverse/commit/b8d268a1a2a11c22739ce8a5a8aa2457f0d17711", "message": "The (very limited) changes that went into the application to accommodate the\nexternal \"custom download\" service. Everything else is done by an outside\nstandalone program (a java program with its own pom file). (#6505)", "committedDate": "2020-05-29T14:50:09Z", "type": "commit"}, {"oid": "8b1765a5ec6cfd30412db7486ea23955d112c7da", "url": "https://github.com/IQSS/dataverse/commit/8b1765a5ec6cfd30412db7486ea23955d112c7da", "message": "components of the standalone zipper (#6505).\nstill working on the documentation, so will need to check it in later.", "committedDate": "2020-05-29T23:33:26Z", "type": "commit"}, {"oid": "e3973d1a90a31295a868223da52e21a5d99290e1", "url": "https://github.com/IQSS/dataverse/commit/e3973d1a90a31295a868223da52e21a5d99290e1", "message": "handling of folders added to the zipper;\nadded some info to the documentation explaining how the zipper does its thing. (#6505)", "committedDate": "2020-06-02T13:42:03Z", "type": "commit"}, {"oid": "ad1787a4b22cbcf5d7ab0f25a9754a2a8fbdb753", "url": "https://github.com/IQSS/dataverse/commit/ad1787a4b22cbcf5d7ab0f25a9754a2a8fbdb753", "message": "cosmetic (#6505)", "committedDate": "2020-06-02T16:46:19Z", "type": "commit"}, {"oid": "1dc597b0fd0d5a83bacd7220619a97fec9bdc9cf", "url": "https://github.com/IQSS/dataverse/commit/1dc597b0fd0d5a83bacd7220619a97fec9bdc9cf", "message": "The modifications allowing the use of the \"custom zipper\" with the API as well.(#6505)", "committedDate": "2020-06-16T13:05:06Z", "type": "commit"}, {"oid": "ddfc88c3ca221bccb7df2a0bdd454fc8d56040ea", "url": "https://github.com/IQSS/dataverse/commit/ddfc88c3ca221bccb7df2a0bdd454fc8d56040ea", "message": "uncommented the line that cleans the request table, on the service executable side. (#6505)", "committedDate": "2020-06-23T01:07:38Z", "type": "commit"}, {"oid": "5402e07eb1afa5370d91c3383089a4341fb57036", "url": "https://github.com/IQSS/dataverse/commit/5402e07eb1afa5370d91c3383089a4341fb57036", "message": "Merge branch 'develop' into 6505-optimize-zip-downloads\n(fixed merge conflicts w/develop - mostly the POST handling added for the /api/access/datafiles/ API)", "committedDate": "2020-06-23T01:28:08Z", "type": "commit"}, {"oid": "aa923ba34ff812091ace1fd56f3dc65822646838", "url": "https://github.com/IQSS/dataverse/commit/aa923ba34ff812091ace1fd56f3dc65822646838", "message": "a release note for the \"zipper tool\". (#6505)", "committedDate": "2020-06-23T02:11:54Z", "type": "commit"}, {"oid": "5d27982b1b4ebd7f56adc349138bd9de3fc22670", "url": "https://github.com/IQSS/dataverse/commit/5d27982b1b4ebd7f56adc349138bd9de3fc22670", "message": "added a section on the zipper service to the \"installation/advanced\" section (#6505)", "committedDate": "2020-06-23T02:34:24Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE1MDk5Mg==", "url": "https://github.com/IQSS/dataverse/pull/6986#discussion_r445150992", "bodyText": "Should this TODO about folders be removed? I see some folder handling below.", "author": "pdurbin", "createdAt": "2020-06-24T20:25:36Z", "path": "scripts/zipdownload/src/main/java/edu/harvard/iq/dataverse/custom/service/download/ZipDownloadService.java", "diffHunk": "@@ -0,0 +1,238 @@\n+/*\n+   Copyright (C) 2005-2012, by the President and Fellows of Harvard College.\n+\n+   Licensed under the Apache License, Version 2.0 (the \"License\");\n+   you may not use this file except in compliance with the License.\n+   You may obtain a copy of the License at\n+\n+         http://www.apache.org/licenses/LICENSE-2.0\n+\n+   Unless required by applicable law or agreed to in writing, software\n+   distributed under the License is distributed on an \"AS IS\" BASIS,\n+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+   See the License for the specific language governing permissions and\n+   limitations under the License.\n+\n+   Dataverse Network - A web application to share, preserve and analyze research data.\n+   Developed at the Institute for Quantitative Social Science, Harvard University.\n+   Version 3.0.\n+*/\n+package edu.harvard.iq.dataverse.custom.service.download;\n+\n+import edu.harvard.iq.dataverse.custom.service.util.DirectAccessUtil;\n+import static edu.harvard.iq.dataverse.custom.service.util.DatabaseAccessUtil.lookupZipJob;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipOutputStream;\n+\n+/**\n+ * Custom (standalone) download service for Dataverse\n+ * \n+ * @author Leonid Andreev\n+ */\n+public class ZipDownloadService { \n+    \n+    private static String jobKey = null;\n+    private List<String[]> jobFiles = null;\n+    private boolean zipOnly = false; \n+    \n+    private DirectAccessUtil directAccessUtil = null; \n+    private ZipOutputStream zipOutputStream = null;\n+\n+    public static void main(String args[]) throws Exception {\n+        \n+        ZipDownloadService zipperService = new ZipDownloadService();\n+        \n+        if (!zipperService.parseArgs(args)) {\n+            zipperService.usage();\n+            return; \n+        }\n+        \n+        zipperService.parseCgiQueryParameters();\n+               \n+        zipperService.execute(jobKey);\n+    }\n+\n+    private static void usage() {\n+        System.out.println(\"\\nUsage:\");\n+        System.out.println(\"  java -jar ZipDownloadService-1.0.0.jar [-ziponly]>\\n\");\n+\n+        System.out.println(\"  supported options:\");\n+        System.out.println(\"   -ziponly = output zip only, no http header/no chunking\");\n+        System.out.println(\"\");\n+\n+    }\n+\n+    // The only option supported at the moment is \"zip only\" - output just the\n+    // compressed stream, skip the HTTP header and chunking.\n+    public boolean parseArgs(String[] args) {\n+\n+        if (args == null || args.length == 0) {\n+            return true; \n+        } else if (args.length == 1) {\n+            if (args[0].equals(\"-ziponly\")) {\n+                this.zipOnly = true;\n+                return true;\n+            }\n+        }\n+        \n+        return false; \n+    }\n+    \n+    // Does not support any parameters, except the job-identifying token key, \n+    // supplied as the entire query string. \n+    public void parseCgiQueryParameters() {\n+        String queryString = System.getenv().get(\"QUERY_STRING\");\n+        if (queryString != null) {\n+            jobKey = queryString; \n+        }\n+    }\n+    \n+    public void print404() {\n+        System.out.println(\"Status: 404 Not Found\\r\");\n+        System.out.println(\"Content-Type: text/html\\r\");\n+        System.out.println(\"\\r\");\n+\n+        System.out.println(\"<h1>404 No such download job!</h1>\");\n+    }\n+    \n+    public void printZipHeader() {\n+        System.out.println(\"Content-disposition: attachment; filename=\\\"dataverse_files.zip\\\"\\r\");\n+        System.out.println(\"Content-Type: application/zip; name=\\\"dataverse_files.zip\\\"\\r\");\n+        System.out.println(\"Transfer-Encoding: chunked\\r\");\n+        System.out.println(\"\\r\");\n+        System.out.flush();\n+    }\n+    \n+    public void execute(String key) {\n+        \n+        jobFiles = lookupZipJob(key); \n+        \n+        if (jobFiles == null || jobFiles.size() == 0) {\n+            this.print404();\n+            System.exit(0);\n+        }\n+        \n+        this.processFiles();\n+    }\n+    \n+    public void processFiles() {\n+        \n+        if (!this.zipOnly) {\n+            this.printZipHeader();\n+        }\n+        \n+        Set<String> zippedFolders = new HashSet<>();\n+       \n+        for (String [] fileEntry : jobFiles) {\n+            String storageLocation = fileEntry[0];\n+            String fileName = fileEntry[1];\n+            \n+            //System.out.println(storageLocation + \":\" + fileName);\n+            \n+            if (this.zipOutputStream == null) {\n+                openZipStream();\n+            }\n+            \n+            if (this.directAccessUtil == null) {\n+                this.directAccessUtil = new DirectAccessUtil();\n+            }\n+            \n+            InputStream inputStream = this.directAccessUtil.openDirectAccess(storageLocation);\n+                \n+            // TODO: folders", "originalCommit": "5d27982b1b4ebd7f56adc349138bd9de3fc22670", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE1MTQ1Mg==", "url": "https://github.com/IQSS/dataverse/pull/6986#discussion_r445151452", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                System.err.println(\"Faile to compress \"+storageLocation);\n          \n          \n            \n                                System.err.println(\"Failed to compress \"+storageLocation);", "author": "pdurbin", "createdAt": "2020-06-24T20:26:26Z", "path": "scripts/zipdownload/src/main/java/edu/harvard/iq/dataverse/custom/service/download/ZipDownloadService.java", "diffHunk": "@@ -0,0 +1,238 @@\n+/*\n+   Copyright (C) 2005-2012, by the President and Fellows of Harvard College.\n+\n+   Licensed under the Apache License, Version 2.0 (the \"License\");\n+   you may not use this file except in compliance with the License.\n+   You may obtain a copy of the License at\n+\n+         http://www.apache.org/licenses/LICENSE-2.0\n+\n+   Unless required by applicable law or agreed to in writing, software\n+   distributed under the License is distributed on an \"AS IS\" BASIS,\n+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+   See the License for the specific language governing permissions and\n+   limitations under the License.\n+\n+   Dataverse Network - A web application to share, preserve and analyze research data.\n+   Developed at the Institute for Quantitative Social Science, Harvard University.\n+   Version 3.0.\n+*/\n+package edu.harvard.iq.dataverse.custom.service.download;\n+\n+import edu.harvard.iq.dataverse.custom.service.util.DirectAccessUtil;\n+import static edu.harvard.iq.dataverse.custom.service.util.DatabaseAccessUtil.lookupZipJob;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipOutputStream;\n+\n+/**\n+ * Custom (standalone) download service for Dataverse\n+ * \n+ * @author Leonid Andreev\n+ */\n+public class ZipDownloadService { \n+    \n+    private static String jobKey = null;\n+    private List<String[]> jobFiles = null;\n+    private boolean zipOnly = false; \n+    \n+    private DirectAccessUtil directAccessUtil = null; \n+    private ZipOutputStream zipOutputStream = null;\n+\n+    public static void main(String args[]) throws Exception {\n+        \n+        ZipDownloadService zipperService = new ZipDownloadService();\n+        \n+        if (!zipperService.parseArgs(args)) {\n+            zipperService.usage();\n+            return; \n+        }\n+        \n+        zipperService.parseCgiQueryParameters();\n+               \n+        zipperService.execute(jobKey);\n+    }\n+\n+    private static void usage() {\n+        System.out.println(\"\\nUsage:\");\n+        System.out.println(\"  java -jar ZipDownloadService-1.0.0.jar [-ziponly]>\\n\");\n+\n+        System.out.println(\"  supported options:\");\n+        System.out.println(\"   -ziponly = output zip only, no http header/no chunking\");\n+        System.out.println(\"\");\n+\n+    }\n+\n+    // The only option supported at the moment is \"zip only\" - output just the\n+    // compressed stream, skip the HTTP header and chunking.\n+    public boolean parseArgs(String[] args) {\n+\n+        if (args == null || args.length == 0) {\n+            return true; \n+        } else if (args.length == 1) {\n+            if (args[0].equals(\"-ziponly\")) {\n+                this.zipOnly = true;\n+                return true;\n+            }\n+        }\n+        \n+        return false; \n+    }\n+    \n+    // Does not support any parameters, except the job-identifying token key, \n+    // supplied as the entire query string. \n+    public void parseCgiQueryParameters() {\n+        String queryString = System.getenv().get(\"QUERY_STRING\");\n+        if (queryString != null) {\n+            jobKey = queryString; \n+        }\n+    }\n+    \n+    public void print404() {\n+        System.out.println(\"Status: 404 Not Found\\r\");\n+        System.out.println(\"Content-Type: text/html\\r\");\n+        System.out.println(\"\\r\");\n+\n+        System.out.println(\"<h1>404 No such download job!</h1>\");\n+    }\n+    \n+    public void printZipHeader() {\n+        System.out.println(\"Content-disposition: attachment; filename=\\\"dataverse_files.zip\\\"\\r\");\n+        System.out.println(\"Content-Type: application/zip; name=\\\"dataverse_files.zip\\\"\\r\");\n+        System.out.println(\"Transfer-Encoding: chunked\\r\");\n+        System.out.println(\"\\r\");\n+        System.out.flush();\n+    }\n+    \n+    public void execute(String key) {\n+        \n+        jobFiles = lookupZipJob(key); \n+        \n+        if (jobFiles == null || jobFiles.size() == 0) {\n+            this.print404();\n+            System.exit(0);\n+        }\n+        \n+        this.processFiles();\n+    }\n+    \n+    public void processFiles() {\n+        \n+        if (!this.zipOnly) {\n+            this.printZipHeader();\n+        }\n+        \n+        Set<String> zippedFolders = new HashSet<>();\n+       \n+        for (String [] fileEntry : jobFiles) {\n+            String storageLocation = fileEntry[0];\n+            String fileName = fileEntry[1];\n+            \n+            //System.out.println(storageLocation + \":\" + fileName);\n+            \n+            if (this.zipOutputStream == null) {\n+                openZipStream();\n+            }\n+            \n+            if (this.directAccessUtil == null) {\n+                this.directAccessUtil = new DirectAccessUtil();\n+            }\n+            \n+            InputStream inputStream = this.directAccessUtil.openDirectAccess(storageLocation);\n+                \n+            // TODO: folders\n+            // TODO: String zipEntryName = checkZipEntryName(fileName);\n+            if (inputStream != null && this.zipOutputStream != null) {\n+                \n+                ZipEntry entry = new ZipEntry(fileName);\n+\n+                byte[] bytes = new byte[2 * 8192];\n+                int read = 0;\n+                long readSize = 0L;\n+\n+                try {\n+                    // Does this file have a folder name? \n+                    if (hasFolder(fileName)) {\n+                        addFolderToZipStream(getFolderName(fileName), zippedFolders);\n+                    }\n+\n+                    this.zipOutputStream.putNextEntry(entry);\n+\n+                    while ((read = inputStream.read(bytes)) != -1) {\n+                        this.zipOutputStream.write(bytes, 0, read);\n+                        readSize += read;\n+                    }\n+                    inputStream.close();\n+                    this.zipOutputStream.closeEntry();\n+\n+                    /*if (fileSize == readSize) {\n+                        //System.out.println(\"Read \"+readSize+\" bytes;\");\n+                    } else {\n+                        throw new IOException(\"Byte size mismatch: expected \" + fileSize + \", read: \" + readSize);\n+                    }*/\n+                } catch (IOException ioex) {\n+                    System.err.println(\"Faile to compress \"+storageLocation);", "originalCommit": "5d27982b1b4ebd7f56adc349138bd9de3fc22670", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE2NzU2NA==", "url": "https://github.com/IQSS/dataverse/pull/6986#discussion_r445167564", "bodyText": "I'm a little confused by how this \"original\" variable always seems to be true. Maybe I'm missing something.", "author": "pdurbin", "createdAt": "2020-06-24T20:57:36Z", "path": "src/main/java/edu/harvard/iq/dataverse/FileDownloadServiceBean.java", "diffHunk": "@@ -90,6 +97,7 @@ public void writeGuestbookAndStartBatchDownload(GuestbookResponse guestbookRespo\n     }\n     \n     public void writeGuestbookAndStartBatchDownload(GuestbookResponse guestbookResponse, Boolean doNotSaveGuestbookRecord){\n+        boolean original = true; ", "originalCommit": "5d27982b1b4ebd7f56adc349138bd9de3fc22670", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjM0OTc2OQ==", "url": "https://github.com/IQSS/dataverse/pull/6986#discussion_r446349769", "bodyText": "You weren't (missing anything).\nFixed.", "author": "landreev", "createdAt": "2020-06-26T18:40:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE2NzU2NA=="}], "type": "inlineReview"}, {"oid": "c99fa60c60993a5921ce261fd3a13babec56a4eb", "url": "https://github.com/IQSS/dataverse/commit/c99fa60c60993a5921ce261fd3a13babec56a4eb", "message": "adding new setting to release notes", "committedDate": "2020-06-24T21:09:59Z", "type": "commit"}, {"oid": "8dfe4c448c87c63e4fa9449eea8de49ab6382441", "url": "https://github.com/IQSS/dataverse/commit/8dfe4c448c87c63e4fa9449eea8de49ab6382441", "message": "Update scripts/zipdownload/README.md\n\nCo-authored-by: Philip Durbin <philip_durbin@harvard.edu>", "committedDate": "2020-06-26T16:07:51Z", "type": "commit"}, {"oid": "46584da7cffb4cd017dae812aa085f2062caedce", "url": "https://github.com/IQSS/dataverse/commit/46584da7cffb4cd017dae812aa085f2062caedce", "message": "Update scripts/zipdownload/src/main/java/edu/harvard/iq/dataverse/custom/service/download/ZipDownloadService.java\n\nCo-authored-by: Philip Durbin <philip_durbin@harvard.edu>", "committedDate": "2020-06-26T16:09:50Z", "type": "commit"}, {"oid": "5aaaff5664c2f610f654e941d0f5318dd1d385f1", "url": "https://github.com/IQSS/dataverse/commit/5aaaff5664c2f610f654e941d0f5318dd1d385f1", "message": "Better/safer handling of database queries (#6505)", "committedDate": "2020-06-26T16:56:59Z", "type": "commit"}, {"oid": "48a56df3b0b23dbf558de4dd1f400ef88cc8a483", "url": "https://github.com/IQSS/dataverse/commit/48a56df3b0b23dbf558de4dd1f400ef88cc8a483", "message": "Merge branch '6505-optimize-zip-downloads' of https://github.com/IQSS/dataverse into 6505-optimize-zip-downloads", "committedDate": "2020-06-26T16:58:00Z", "type": "commit"}, {"oid": "3eb3976192e7bcb5acd32f4d4786a72a04f09b8c", "url": "https://github.com/IQSS/dataverse/commit/3eb3976192e7bcb5acd32f4d4786a72a04f09b8c", "message": "added a line about the Apache configuration to the installation instruction", "committedDate": "2020-06-26T17:04:17Z", "type": "commit"}, {"oid": "1cd8629a26b1acef0941bc7025fd76ebf020c7d2", "url": "https://github.com/IQSS/dataverse/commit/1cd8629a26b1acef0941bc7025fd76ebf020c7d2", "message": "line breaks in the readme (#6505)", "committedDate": "2020-06-26T17:06:47Z", "type": "commit"}, {"oid": "69297fb256fe4e7db1ece6e30a7f2eb5b6a0a8a5", "url": "https://github.com/IQSS/dataverse/commit/69297fb256fe4e7db1ece6e30a7f2eb5b6a0a8a5", "message": "small addition to the guide on installation (#6505)", "committedDate": "2020-06-26T17:19:08Z", "type": "commit"}, {"oid": "6e2e39650f8dfb0774a87cfe2d2a07cc7b80e07b", "url": "https://github.com/IQSS/dataverse/commit/6e2e39650f8dfb0774a87cfe2d2a07cc7b80e07b", "message": "documents the zipper setting. (#6505)", "committedDate": "2020-06-26T17:33:31Z", "type": "commit"}, {"oid": "72394a46edd4c4ef37922fd5f0409ac242a585c3", "url": "https://github.com/IQSS/dataverse/commit/72394a46edd4c4ef37922fd5f0409ac242a585c3", "message": "fixes \"original\" always being true (#6505)", "committedDate": "2020-06-26T17:39:04Z", "type": "commit"}, {"oid": "96c37086ce3f8f66b510cdf95f72bbe994eec127", "url": "https://github.com/IQSS/dataverse/commit/96c37086ce3f8f66b510cdf95f72bbe994eec127", "message": "removed unnecessary repos from pom.xml; a few more words in the advanced guide; #6505", "committedDate": "2020-06-26T18:18:26Z", "type": "commit"}, {"oid": "e01c213d98c802dcb12ebe6ebe6a34abe5f74369", "url": "https://github.com/IQSS/dataverse/commit/e01c213d98c802dcb12ebe6ebe6a34abe5f74369", "message": "Update doc/sphinx-guides/source/installation/advanced.rst\n\nCo-authored-by: Philip Durbin <philip_durbin@harvard.edu>", "committedDate": "2020-06-26T18:22:33Z", "type": "commit"}, {"oid": "9e42aec35af9795ec43aa758a8b988612f3148d1", "url": "https://github.com/IQSS/dataverse/commit/9e42aec35af9795ec43aa758a8b988612f3148d1", "message": "Update scripts/zipdownload/README.md\n\nCo-authored-by: Philip Durbin <philip_durbin@harvard.edu>", "committedDate": "2020-06-26T18:23:52Z", "type": "commit"}, {"oid": "6100ed62d70621b4e453161e125fe15d9b72a106", "url": "https://github.com/IQSS/dataverse/commit/6100ed62d70621b4e453161e125fe15d9b72a106", "message": "style/grammar #6505", "committedDate": "2020-06-26T18:31:25Z", "type": "commit"}, {"oid": "aaaa035bf9411758a32cb2bcafb7fb7038295f0f", "url": "https://github.com/IQSS/dataverse/commit/aaaa035bf9411758a32cb2bcafb7fb7038295f0f", "message": "Update scripts/zipdownload/README.md\n\nCo-authored-by: Philip Durbin <philip_durbin@harvard.edu>", "committedDate": "2020-06-26T18:37:35Z", "type": "commit"}, {"oid": "c5cca50151d3c0a4c93679858e4c8a611cc2fee3", "url": "https://github.com/IQSS/dataverse/commit/c5cca50151d3c0a4c93679858e4c8a611cc2fee3", "message": "Update scripts/zipdownload/README.md\n\nCo-authored-by: Philip Durbin <philip_durbin@harvard.edu>", "committedDate": "2020-06-26T18:39:04Z", "type": "commit"}, {"oid": "1d4b83fb1755b1d0c839298e878c6bddc77cda0f", "url": "https://github.com/IQSS/dataverse/commit/1d4b83fb1755b1d0c839298e878c6bddc77cda0f", "message": "Update scripts/zipdownload/README.md\n\nCo-authored-by: Philip Durbin <philip_durbin@harvard.edu>", "committedDate": "2020-06-26T18:39:38Z", "type": "commit"}, {"oid": "d34eccaccc5411d115fb23ec0605b537d8821205", "url": "https://github.com/IQSS/dataverse/commit/d34eccaccc5411d115fb23ec0605b537d8821205", "message": "typo", "committedDate": "2020-06-26T19:03:00Z", "type": "commit"}, {"oid": "f580a80b5cf84c8eda824dd84d13aa351ee24e1c", "url": "https://github.com/IQSS/dataverse/commit/f580a80b5cf84c8eda824dd84d13aa351ee24e1c", "message": "renamed the flyway script. #6505", "committedDate": "2020-07-08T19:54:46Z", "type": "commit"}, {"oid": "e0e0a4522efadc5afcf2828bf293d80d22915e90", "url": "https://github.com/IQSS/dataverse/commit/e0e0a4522efadc5afcf2828bf293d80d22915e90", "message": "Merge branch 'develop' into 6505-optimize-zip-downloads", "committedDate": "2020-07-08T19:57:00Z", "type": "commit"}, {"oid": "2fcdfac60444b4fc42e8e12bbd087de0ea1fc7eb", "url": "https://github.com/IQSS/dataverse/commit/2fcdfac60444b4fc42e8e12bbd087de0ea1fc7eb", "message": "Merge branch '6505-optimize-zip-downloads' of https://github.com/IQSS/dataverse into 6505-optimize-zip-downloads", "committedDate": "2020-07-08T19:57:50Z", "type": "commit"}, {"oid": "757a1207524275da1874f96858864e68c046c134", "url": "https://github.com/IQSS/dataverse/commit/757a1207524275da1874f96858864e68c046c134", "message": "added support for multiple file stores (#6505)", "committedDate": "2020-07-09T19:45:55Z", "type": "commit"}, {"oid": "7f2bf94579f4afeca5ef9edd499955b04888fdbf", "url": "https://github.com/IQSS/dataverse/commit/7f2bf94579f4afeca5ef9edd499955b04888fdbf", "message": "extra words in the doc #6505", "committedDate": "2020-07-09T20:07:12Z", "type": "commit"}, {"oid": "2553845b3df2c2752b652c2439effd55db9041d8", "url": "https://github.com/IQSS/dataverse/commit/2553845b3df2c2752b652c2439effd55db9041d8", "message": "Fixed the chunking encoding error, that was preventing the download from working in some browsers. (#6505)", "committedDate": "2020-07-14T17:40:12Z", "type": "commit"}]}