{"pr_number": 1132, "pr_title": "(CDAP-17080) Add Data Cacher Plugin", "pr_createdAt": "2020-07-16T18:41:15Z", "pr_url": "https://github.com/cdapio/hydrator-plugins/pull/1132", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAwODU3OQ==", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456008579", "bodyText": "Wrong year", "author": "chtyim", "createdAt": "2020-07-16T19:04:44Z", "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Copyright \u00a9 2016-2019 Cask Data, Inc.", "originalCommit": "125793ea217804652049d3167db2429229fd07fd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEyMzQyMA==", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456123420", "bodyText": "Fixed", "author": "MEseifan", "createdAt": "2020-07-16T22:57:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAwODU3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAwOTgzOA==", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456009838", "bodyText": "A better line breaking:\npublic JavaRDD<StructuredRecord> transform(SparkExecutionPluginContext pluginContext,\n                                           JavaRDD<StructuredRecord> javaRDD) throws Exception {", "author": "chtyim", "createdAt": "2020-07-16T19:07:09Z", "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Copyright \u00a9 2016-2019 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.plugin.spark;\n+\n+import com.google.common.base.Strings;\n+import io.cdap.cdap.api.annotation.Description;\n+import io.cdap.cdap.api.annotation.Macro;\n+import io.cdap.cdap.api.annotation.Name;\n+import io.cdap.cdap.api.annotation.Plugin;\n+import io.cdap.cdap.api.data.format.StructuredRecord;\n+import io.cdap.cdap.api.plugin.PluginConfig;\n+import io.cdap.cdap.etl.api.batch.SparkCompute;\n+import io.cdap.cdap.etl.api.batch.SparkExecutionPluginContext;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.storage.StorageLevel;\n+\n+/**\n+ * SparkCompute that caches a RDD\n+ */\n+@Plugin(type = SparkCompute.PLUGIN_TYPE)\n+@Name(\"DataCacher\")\n+@Description(\"Spark Data Cacher caches any incoming records and outputs them unchanged.\")\n+public class DataCacher extends SparkCompute<StructuredRecord, StructuredRecord> {\n+\n+  private final DataCacherConfig config;\n+\n+  public DataCacher(DataCacherConfig config) {\n+    this.config = config;\n+  }\n+\n+  @Override\n+  public JavaRDD<StructuredRecord> transform(", "originalCommit": "125793ea217804652049d3167db2429229fd07fd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEyNTAzNw==", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456125037", "bodyText": "done", "author": "MEseifan", "createdAt": "2020-07-16T23:01:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAwOTgzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAxMDA4OA==", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456010088", "bodyText": "This should be a validation error that should be checked at deployment time.", "author": "chtyim", "createdAt": "2020-07-16T19:07:34Z", "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Copyright \u00a9 2016-2019 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.plugin.spark;\n+\n+import com.google.common.base.Strings;\n+import io.cdap.cdap.api.annotation.Description;\n+import io.cdap.cdap.api.annotation.Macro;\n+import io.cdap.cdap.api.annotation.Name;\n+import io.cdap.cdap.api.annotation.Plugin;\n+import io.cdap.cdap.api.data.format.StructuredRecord;\n+import io.cdap.cdap.api.plugin.PluginConfig;\n+import io.cdap.cdap.etl.api.batch.SparkCompute;\n+import io.cdap.cdap.etl.api.batch.SparkExecutionPluginContext;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.storage.StorageLevel;\n+\n+/**\n+ * SparkCompute that caches a RDD\n+ */\n+@Plugin(type = SparkCompute.PLUGIN_TYPE)\n+@Name(\"DataCacher\")\n+@Description(\"Spark Data Cacher caches any incoming records and outputs them unchanged.\")\n+public class DataCacher extends SparkCompute<StructuredRecord, StructuredRecord> {\n+\n+  private final DataCacherConfig config;\n+\n+  public DataCacher(DataCacherConfig config) {\n+    this.config = config;\n+  }\n+\n+  @Override\n+  public JavaRDD<StructuredRecord> transform(\n+    SparkExecutionPluginContext sparkExecutionPluginContext, JavaRDD<StructuredRecord> javaRDD)\n+    throws Exception {\n+\n+    StorageLevel storageLevel = config.getStorageLevel();\n+    if (storageLevel == StorageLevel.NONE()) {", "originalCommit": "125793ea217804652049d3167db2429229fd07fd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEyNTQ5NA==", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456125494", "bodyText": "We cant check at deployment time because the spark classes are not available during deployment/validation. I dont think this is a big problem because the plugin uses a dropdown to specify the storage level so the only way the user can pass an incorrect value is using a macro which we cant check during deployment anyway.", "author": "MEseifan", "createdAt": "2020-07-16T23:03:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAxMDA4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEyNjY1Mw==", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456126653", "bodyText": "Maybe check that the string value is in one of the allowed value.", "author": "chtyim", "createdAt": "2020-07-16T23:06:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAxMDA4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEyODMyNg==", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456128326", "bodyText": "Sure, done.", "author": "MEseifan", "createdAt": "2020-07-16T23:12:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAxMDA4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAxMDY1NA==", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456010654", "bodyText": "You can just check for empty string since the config is not optional (i.e. doesn't have @Nullable annotation)", "author": "chtyim", "createdAt": "2020-07-16T19:08:37Z", "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Copyright \u00a9 2016-2019 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.plugin.spark;\n+\n+import com.google.common.base.Strings;\n+import io.cdap.cdap.api.annotation.Description;\n+import io.cdap.cdap.api.annotation.Macro;\n+import io.cdap.cdap.api.annotation.Name;\n+import io.cdap.cdap.api.annotation.Plugin;\n+import io.cdap.cdap.api.data.format.StructuredRecord;\n+import io.cdap.cdap.api.plugin.PluginConfig;\n+import io.cdap.cdap.etl.api.batch.SparkCompute;\n+import io.cdap.cdap.etl.api.batch.SparkExecutionPluginContext;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.storage.StorageLevel;\n+\n+/**\n+ * SparkCompute that caches a RDD\n+ */\n+@Plugin(type = SparkCompute.PLUGIN_TYPE)\n+@Name(\"DataCacher\")\n+@Description(\"Spark Data Cacher caches any incoming records and outputs them unchanged.\")\n+public class DataCacher extends SparkCompute<StructuredRecord, StructuredRecord> {\n+\n+  private final DataCacherConfig config;\n+\n+  public DataCacher(DataCacherConfig config) {\n+    this.config = config;\n+  }\n+\n+  @Override\n+  public JavaRDD<StructuredRecord> transform(\n+    SparkExecutionPluginContext sparkExecutionPluginContext, JavaRDD<StructuredRecord> javaRDD)\n+    throws Exception {\n+\n+    StorageLevel storageLevel = config.getStorageLevel();\n+    if (storageLevel == StorageLevel.NONE()) {\n+      throw new RuntimeException(String.format(\"Invalid storage level '%s'. Please select a valid value\"));\n+    }\n+\n+    javaRDD.persist(storageLevel);\n+    return javaRDD;\n+  }\n+\n+  /**\n+   * Config class for DataCacher.\n+   */\n+  public static class DataCacherConfig extends PluginConfig {\n+\n+    @Name(\"StorageLevel\")\n+    @Description(\"Spark storage level used to cache the data\")\n+    @Macro\n+    private String storageLevel;\n+\n+    StorageLevel getStorageLevel() {\n+      if (Strings.isNullOrEmpty(storageLevel)) {", "originalCommit": "125793ea217804652049d3167db2429229fd07fd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEyNTU3MQ==", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456125571", "bodyText": "Fixed", "author": "MEseifan", "createdAt": "2020-07-16T23:03:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjAxMDY1NA=="}], "type": "inlineReview"}, {"oid": "e33bdd9b738fd2e3141868047a33756fe1065ad8", "url": "https://github.com/cdapio/hydrator-plugins/commit/e33bdd9b738fd2e3141868047a33756fe1065ad8", "message": "Added Data Cacher Plugin", "committedDate": "2020-07-16T19:38:36Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEzODg5NA==", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456138894", "bodyText": "Use a Set\nSet<String> allowed = new HashSet<>(Arrays.asList(\n  \"DISK_ONLY\",\n  \"DISK_ONLY_2\",\n  ...\n));", "author": "chtyim", "createdAt": "2020-07-16T23:45:43Z", "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Copyright \u00a9 2020 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.plugin.spark;\n+\n+import io.cdap.cdap.api.annotation.Description;\n+import io.cdap.cdap.api.annotation.Macro;\n+import io.cdap.cdap.api.annotation.Name;\n+import io.cdap.cdap.api.annotation.Plugin;\n+import io.cdap.cdap.api.data.format.StructuredRecord;\n+import io.cdap.cdap.api.plugin.PluginConfig;\n+import io.cdap.cdap.etl.api.FailureCollector;\n+import io.cdap.cdap.etl.api.PipelineConfigurer;\n+import io.cdap.cdap.etl.api.StageConfigurer;\n+import io.cdap.cdap.etl.api.batch.SparkCompute;\n+import io.cdap.cdap.etl.api.batch.SparkExecutionPluginContext;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.storage.StorageLevel;\n+\n+import java.util.Arrays;\n+\n+/**\n+ * SparkCompute that caches a RDD\n+ */\n+@Plugin(type = SparkCompute.PLUGIN_TYPE)\n+@Name(\"DataCacher\")\n+@Description(\"Spark Data Cacher caches any incoming records and outputs them unchanged.\")\n+public class DataCacher extends SparkCompute<StructuredRecord, StructuredRecord> {\n+\n+  private final DataCacherConfig config;\n+\n+  public DataCacher(DataCacherConfig config) {\n+    this.config = config;\n+  }\n+\n+  @Override\n+  public void configurePipeline(PipelineConfigurer pipelineConfigurer) {\n+    StageConfigurer stageConfigurer = pipelineConfigurer.getStageConfigurer();\n+    stageConfigurer.setOutputSchema(stageConfigurer.getInputSchema());\n+\n+    config.validate(stageConfigurer.getFailureCollector());\n+  }\n+\n+  @Override\n+  public JavaRDD<StructuredRecord> transform(SparkExecutionPluginContext sparkExecutionPluginContext,\n+                                             JavaRDD<StructuredRecord> javaRDD) throws Exception {\n+\n+    StorageLevel storageLevel = StorageLevel.MEMORY_AND_DISK();\n+    if (config.storageLevel.isEmpty()) {\n+      StorageLevel.fromString(config.storageLevel);\n+    }\n+    if (storageLevel == StorageLevel.NONE()) {\n+      throw new RuntimeException(String.format(\"Invalid storage level '%s'. Please select a valid value\"));\n+    }\n+\n+    javaRDD.persist(storageLevel);\n+    return javaRDD;\n+  }\n+\n+  /**\n+   * Config class for DataCacher.\n+   */\n+  public static class DataCacherConfig extends PluginConfig {\n+\n+    private static final String STORAGE_LEVEL = \"storageLevel\";\n+\n+\n+    @Name(STORAGE_LEVEL)\n+    @Description(\"Spark storage level used to cache the data\")\n+    @Macro\n+    private String storageLevel;\n+\n+    public void validate(FailureCollector collector) {\n+      if (containsMacro(STORAGE_LEVEL)) {\n+        return;\n+      }\n+\n+      String[] allowedStrings = {\"DISK_ONLY\", \"DISK_ONLY_2\", \"MEMORY_ONLY\", \"MEMORY_ONLY_2\", \"MEMORY_ONLY_SER\",", "originalCommit": "3043bfbe17a71aafcc1a3e0edbcc1487a10ff6f6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjE0NzM1MQ==", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456147351", "bodyText": "done", "author": "MEseifan", "createdAt": "2020-07-17T00:14:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEzODg5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEzOTA1Mw==", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456139053", "bodyText": "I don't think this check is needed", "author": "chtyim", "createdAt": "2020-07-16T23:46:13Z", "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Copyright \u00a9 2020 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.plugin.spark;\n+\n+import io.cdap.cdap.api.annotation.Description;\n+import io.cdap.cdap.api.annotation.Macro;\n+import io.cdap.cdap.api.annotation.Name;\n+import io.cdap.cdap.api.annotation.Plugin;\n+import io.cdap.cdap.api.data.format.StructuredRecord;\n+import io.cdap.cdap.api.plugin.PluginConfig;\n+import io.cdap.cdap.etl.api.FailureCollector;\n+import io.cdap.cdap.etl.api.PipelineConfigurer;\n+import io.cdap.cdap.etl.api.StageConfigurer;\n+import io.cdap.cdap.etl.api.batch.SparkCompute;\n+import io.cdap.cdap.etl.api.batch.SparkExecutionPluginContext;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.storage.StorageLevel;\n+\n+import java.util.Arrays;\n+\n+/**\n+ * SparkCompute that caches a RDD\n+ */\n+@Plugin(type = SparkCompute.PLUGIN_TYPE)\n+@Name(\"DataCacher\")\n+@Description(\"Spark Data Cacher caches any incoming records and outputs them unchanged.\")\n+public class DataCacher extends SparkCompute<StructuredRecord, StructuredRecord> {\n+\n+  private final DataCacherConfig config;\n+\n+  public DataCacher(DataCacherConfig config) {\n+    this.config = config;\n+  }\n+\n+  @Override\n+  public void configurePipeline(PipelineConfigurer pipelineConfigurer) {\n+    StageConfigurer stageConfigurer = pipelineConfigurer.getStageConfigurer();\n+    stageConfigurer.setOutputSchema(stageConfigurer.getInputSchema());\n+\n+    config.validate(stageConfigurer.getFailureCollector());\n+  }\n+\n+  @Override\n+  public JavaRDD<StructuredRecord> transform(SparkExecutionPluginContext sparkExecutionPluginContext,\n+                                             JavaRDD<StructuredRecord> javaRDD) throws Exception {\n+\n+    StorageLevel storageLevel = StorageLevel.MEMORY_AND_DISK();\n+    if (config.storageLevel.isEmpty()) {\n+      StorageLevel.fromString(config.storageLevel);\n+    }\n+    if (storageLevel == StorageLevel.NONE()) {\n+      throw new RuntimeException(String.format(\"Invalid storage level '%s'. Please select a valid value\"));\n+    }\n+\n+    javaRDD.persist(storageLevel);\n+    return javaRDD;\n+  }\n+\n+  /**\n+   * Config class for DataCacher.\n+   */\n+  public static class DataCacherConfig extends PluginConfig {\n+\n+    private static final String STORAGE_LEVEL = \"storageLevel\";\n+\n+\n+    @Name(STORAGE_LEVEL)\n+    @Description(\"Spark storage level used to cache the data\")\n+    @Macro\n+    private String storageLevel;\n+\n+    public void validate(FailureCollector collector) {\n+      if (containsMacro(STORAGE_LEVEL)) {\n+        return;\n+      }\n+\n+      String[] allowedStrings = {\"DISK_ONLY\", \"DISK_ONLY_2\", \"MEMORY_ONLY\", \"MEMORY_ONLY_2\", \"MEMORY_ONLY_SER\",\n+        \"MEMORY_ONLY_SER_2\", \"MEMORY_AND_DISK\", \"MEMORY_AND_DISK_2\", \"MEMORY_AND_DISK_SER\", \"MEMORY_AND_DISK_SER_2\"};\n+\n+      if (storageLevel.isEmpty()) {", "originalCommit": "3043bfbe17a71aafcc1a3e0edbcc1487a10ff6f6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjE0ODEzNQ==", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456148135", "bodyText": "removed", "author": "MEseifan", "createdAt": "2020-07-17T00:16:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEzOTA1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEzOTQzNQ==", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456139435", "bodyText": "Instead of saying dropdown, it would be better to have the list of allowed values in the suggestive action, since this API can be used in REST API (imagine when someone export and import a pipeline, and due to future version change, some of the value might no longer be valid).", "author": "chtyim", "createdAt": "2020-07-16T23:47:34Z", "path": "spark-plugins/src/main/java/io/cdap/plugin/spark/DataCacher.java", "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Copyright \u00a9 2020 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.plugin.spark;\n+\n+import io.cdap.cdap.api.annotation.Description;\n+import io.cdap.cdap.api.annotation.Macro;\n+import io.cdap.cdap.api.annotation.Name;\n+import io.cdap.cdap.api.annotation.Plugin;\n+import io.cdap.cdap.api.data.format.StructuredRecord;\n+import io.cdap.cdap.api.plugin.PluginConfig;\n+import io.cdap.cdap.etl.api.FailureCollector;\n+import io.cdap.cdap.etl.api.PipelineConfigurer;\n+import io.cdap.cdap.etl.api.StageConfigurer;\n+import io.cdap.cdap.etl.api.batch.SparkCompute;\n+import io.cdap.cdap.etl.api.batch.SparkExecutionPluginContext;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.storage.StorageLevel;\n+\n+import java.util.Arrays;\n+\n+/**\n+ * SparkCompute that caches a RDD\n+ */\n+@Plugin(type = SparkCompute.PLUGIN_TYPE)\n+@Name(\"DataCacher\")\n+@Description(\"Spark Data Cacher caches any incoming records and outputs them unchanged.\")\n+public class DataCacher extends SparkCompute<StructuredRecord, StructuredRecord> {\n+\n+  private final DataCacherConfig config;\n+\n+  public DataCacher(DataCacherConfig config) {\n+    this.config = config;\n+  }\n+\n+  @Override\n+  public void configurePipeline(PipelineConfigurer pipelineConfigurer) {\n+    StageConfigurer stageConfigurer = pipelineConfigurer.getStageConfigurer();\n+    stageConfigurer.setOutputSchema(stageConfigurer.getInputSchema());\n+\n+    config.validate(stageConfigurer.getFailureCollector());\n+  }\n+\n+  @Override\n+  public JavaRDD<StructuredRecord> transform(SparkExecutionPluginContext sparkExecutionPluginContext,\n+                                             JavaRDD<StructuredRecord> javaRDD) throws Exception {\n+\n+    StorageLevel storageLevel = StorageLevel.MEMORY_AND_DISK();\n+    if (config.storageLevel.isEmpty()) {\n+      StorageLevel.fromString(config.storageLevel);\n+    }\n+    if (storageLevel == StorageLevel.NONE()) {\n+      throw new RuntimeException(String.format(\"Invalid storage level '%s'. Please select a valid value\"));\n+    }\n+\n+    javaRDD.persist(storageLevel);\n+    return javaRDD;\n+  }\n+\n+  /**\n+   * Config class for DataCacher.\n+   */\n+  public static class DataCacherConfig extends PluginConfig {\n+\n+    private static final String STORAGE_LEVEL = \"storageLevel\";\n+\n+\n+    @Name(STORAGE_LEVEL)\n+    @Description(\"Spark storage level used to cache the data\")\n+    @Macro\n+    private String storageLevel;\n+\n+    public void validate(FailureCollector collector) {\n+      if (containsMacro(STORAGE_LEVEL)) {\n+        return;\n+      }\n+\n+      String[] allowedStrings = {\"DISK_ONLY\", \"DISK_ONLY_2\", \"MEMORY_ONLY\", \"MEMORY_ONLY_2\", \"MEMORY_ONLY_SER\",\n+        \"MEMORY_ONLY_SER_2\", \"MEMORY_AND_DISK\", \"MEMORY_AND_DISK_2\", \"MEMORY_AND_DISK_SER\", \"MEMORY_AND_DISK_SER_2\"};\n+\n+      if (storageLevel.isEmpty()) {\n+        collector.addFailure(\"Storage level is a required value. \", \"Please select the desired storage level.\")\n+                 .withConfigProperty(STORAGE_LEVEL);\n+      } else if (!Arrays.asList(allowedStrings).contains(storageLevel.toUpperCase())) {\n+        collector\n+          .addFailure(\"Invalid value for Storage Level \", \"Please select one of the valid values from the dropdown.\")", "originalCommit": "3043bfbe17a71aafcc1a3e0edbcc1487a10ff6f6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjE0ODE5NA==", "url": "https://github.com/cdapio/hydrator-plugins/pull/1132#discussion_r456148194", "bodyText": "done", "author": "MEseifan", "createdAt": "2020-07-17T00:16:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEzOTQzNQ=="}], "type": "inlineReview"}, {"oid": "e8d986898f7036d44029100cacab8de04fa1283d", "url": "https://github.com/cdapio/hydrator-plugins/commit/e8d986898f7036d44029100cacab8de04fa1283d", "message": "Added Data Cacher Plugin", "committedDate": "2020-07-17T16:24:34Z", "type": "forcePushed"}, {"oid": "0f6dab41b36f1f53ed799b51d5660d01f8722f36", "url": "https://github.com/cdapio/hydrator-plugins/commit/0f6dab41b36f1f53ed799b51d5660d01f8722f36", "message": "Added Data Cacher Plugin", "committedDate": "2020-07-17T16:29:33Z", "type": "forcePushed"}, {"oid": "19fa031fc4e074939980e2d49bd944a0e02230fa", "url": "https://github.com/cdapio/hydrator-plugins/commit/19fa031fc4e074939980e2d49bd944a0e02230fa", "message": "Added Data Cacher Plugin", "committedDate": "2020-07-21T18:33:22Z", "type": "forcePushed"}, {"oid": "99ce70a6cb6f0dde7e5cd3eb61fcfc20e996860f", "url": "https://github.com/cdapio/hydrator-plugins/commit/99ce70a6cb6f0dde7e5cd3eb61fcfc20e996860f", "message": "Added Data Cacher Plugin", "committedDate": "2020-07-23T16:01:45Z", "type": "commit"}, {"oid": "99ce70a6cb6f0dde7e5cd3eb61fcfc20e996860f", "url": "https://github.com/cdapio/hydrator-plugins/commit/99ce70a6cb6f0dde7e5cd3eb61fcfc20e996860f", "message": "Added Data Cacher Plugin", "committedDate": "2020-07-23T16:01:45Z", "type": "forcePushed"}]}