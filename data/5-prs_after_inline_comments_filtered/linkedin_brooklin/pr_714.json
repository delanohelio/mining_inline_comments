{"pr_number": 714, "pr_title": "Fix producer.close() deadlock by moving actual producer.close() call to separate thread in KafkaProducerWrapper", "pr_createdAt": "2020-05-22T17:05:52Z", "pr_url": "https://github.com/linkedin/brooklin/pull/714", "timeline": [{"oid": "8ddffe91eb0c3d054e1e728c35d850b14b7db39c", "url": "https://github.com/linkedin/brooklin/commit/8ddffe91eb0c3d054e1e728c35d850b14b7db39c", "message": "Fix producer.close() deadlock by moving actual producer.close() call to separate thread in KafkaProducerWrapper", "committedDate": "2020-05-22T16:51:40Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwMjkxNg==", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r430702916", "bodyText": "Why 10 as opposed to a single thread?", "author": "ahmedahamid", "createdAt": "2020-05-26T20:56:14Z", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -98,6 +105,13 @@\n   private final DynamicMetricsManager _dynamicMetricsManager;\n   private final String _metricsNamesPrefix;\n \n+  // A lock used to synchronized access to operations performed on the _kafkaProducer object\n+  private final ReentrantLock _producerLock = new ReentrantLock();\n+\n+  // An executor to spawn threads to close the producer.\n+  private final ExecutorService _producerCloseExecutorService = Executors.newFixedThreadPool(10,", "originalCommit": "8ddffe91eb0c3d054e1e728c35d850b14b7db39c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgxNzM2OA==", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r430817368", "bodyText": "changed to 1", "author": "somandal", "createdAt": "2020-05-27T02:05:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwMjkxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg3NDk1Nw==", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r430874957", "bodyText": "newSingleThreadExecutor is slightly better. To quote the javadocs:\n\nUnlike the otherwise equivalent newFixedThreadPool(1) the returned executor is guaranteed not to be reconfigurable to use additional threads.", "author": "ahmedahamid", "createdAt": "2020-05-27T06:01:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwMjkxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI2ODkzNA==", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r431268934", "bodyText": "done", "author": "somandal", "createdAt": "2020-05-27T16:14:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwMjkxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwNDI1MA==", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r430704250", "bodyText": "Since we're not using any of ReentrantLock's advanced capabilities, I'd recommend just defining an Object and locking it using synchronized blocks; they're easier to read, do not require try/finally blocks, do not require separate lock/unlock statements, the lock/unlock are lexically defined with a block scope, are also reentrant, and are generally simpler.", "author": "ahmedahamid", "createdAt": "2020-05-26T20:58:50Z", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -98,6 +105,13 @@\n   private final DynamicMetricsManager _dynamicMetricsManager;\n   private final String _metricsNamesPrefix;\n \n+  // A lock used to synchronized access to operations performed on the _kafkaProducer object\n+  private final ReentrantLock _producerLock = new ReentrantLock();", "originalCommit": "8ddffe91eb0c3d054e1e728c35d850b14b7db39c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgxNzM0NQ==", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r430817345", "bodyText": "done", "author": "somandal", "createdAt": "2020-05-27T02:05:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwNDI1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwNTg4NQ==", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r430705885", "bodyText": "Do you think it would be better to move this javadoc inside the method? It's slightly confusing now since it could be misinterpreted to mean a lock has to be acquired before this method is called.", "author": "ahmedahamid", "createdAt": "2020-05-26T21:02:09Z", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -163,22 +177,27 @@ int getTasksSize() {\n   }\n \n   /**\n-   * Must be synchronized to avoid creating duplicate producers when multiple concurrent\n+   * Must be protected by a lock to avoid creating duplicate producers when multiple concurrent\n    * sends are in-flight and _kafkaProducer has been set to null as a result of previous\n    * producer exception.\n    */", "originalCommit": "8ddffe91eb0c3d054e1e728c35d850b14b7db39c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgxNzQwNg==", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r430817406", "bodyText": "done", "author": "somandal", "createdAt": "2020-05-27T02:05:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwNTg4NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwOTA4Nw==", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r430709087", "bodyText": "If it may be come in handy during debugging and isn't produced too frequently, it may not be such a bad idea to turn the two debug logs within this block to info instead. I don't have as much experience as you do with these logs though.", "author": "ahmedahamid", "createdAt": "2020-05-26T21:09:04Z", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -221,61 +240,87 @@ void send(DatastreamTask task, ProducerRecord<K, V> producerRecord, Callback onC\n         }\n         // Set a max_send_attempts for KafkaException as it may be non-recoverable\n         if (numberOfAttempt > MAX_SEND_ATTEMPTS || ((cause instanceof Error || cause instanceof RuntimeException))) {\n-          _log.error(\"Send failed for partition {} with a non retriable exception\", producerRecord.partition(), e);\n+          _log.error(String.format(\"Send failed for partition %d with a non-retriable exception\",\n+              producerRecord.partition()), e);\n           throw generateSendFailure(e);\n         } else {\n-          _log.warn(\"Send failed for partition {} with retriable exception, retry {} out of {} in {} ms.\",\n-              producerRecord.partition(), numberOfAttempt, MAX_SEND_ATTEMPTS, _sendFailureRetryWaitTimeMs, e);\n+          _log.warn(String.format(\n+              \"Send failed for partition %d with a retriable exception, retry %d out of %d in %d ms.\",\n+              producerRecord.partition(), numberOfAttempt, MAX_SEND_ATTEMPTS, _sendFailureRetryWaitTimeMs), e);\n           Thread.sleep(_sendFailureRetryWaitTimeMs);\n         }\n       } catch (Exception e) {\n-        _log.error(\"Send failed for partition {} with an exception\", producerRecord.partition(), e);\n+        _log.error(String.format(\"Send failed for partition %d with an exception\", producerRecord.partition()), e);\n         throw generateSendFailure(e);\n       }\n     }\n   }\n \n-  private synchronized void shutdownProducer() {\n-    Producer<K, V> producer = _kafkaProducer;\n-    // Nullify first to prevent subsequent send() to use\n-    // the current producer which is being shutdown.\n-    _kafkaProducer = null;\n+  @VisibleForTesting\n+  void shutdownProducer() {\n+    Producer<K, V> producer;\n+    _producerLock.lock();\n+    try {\n+      producer = _kafkaProducer;\n+      // Nullify first to prevent subsequent send() to use\n+      // the current producer which is being shutdown.\n+      _kafkaProducer = null;\n+    } finally {\n+      _producerLock.unlock();\n+    }\n+\n+    // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n+    // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n+    // thread\n     if (producer != null) {\n-      producer.close(TIME_OUT, TimeUnit.MILLISECONDS);\n-      NUM_PRODUCERS.decrementAndGet();\n+      _producerCloseExecutorService.submit(() -> {\n+        _log.debug(\"KafkaProducerWrapper: Closing the Kafka Producer\");", "originalCommit": "8ddffe91eb0c3d054e1e728c35d850b14b7db39c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgxNzQzMg==", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r430817432", "bodyText": "done", "author": "somandal", "createdAt": "2020-05-27T02:06:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwOTA4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDc2MTE4Mg==", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r430761182", "bodyText": "Please, feel free to ignore this comment.\nI generally dislike polling in tests for several reasons. I'll just mention the most relevant ones here:\n\nIt's a source of flakiness (I know you used a timeout of 10s for that reason)\nWhen we do verifyClose(0), count == numExpected will return true immediately, a racey behavior that does not affect this test because it has a subsequent assertion that verifies shutdownProducer() itself hasn't been called.\nAssert.assertEquals(_numShutdownProducerCalls, numExpected)\nbut this begs the question: do we have to assert on _mockProducer.produce() in the first place?", "author": "ahmedahamid", "createdAt": "2020-05-26T23:26:08Z", "path": "datastream-kafka/src/test/java/com/linkedin/datastream/kafka/TestKafkaProducerWrapper.java", "diffHunk": "@@ -141,8 +153,17 @@ void verifyFlush(int numExpected) {\n       verify(_mockProducer, times(numExpected)).flush();\n     }\n \n-    void verifyClose(int numExpected) {\n+    void verifyClose(int numExpected) throws NoSuchMethodException {\n+      // Producer close is invoked in a separate thread. Must wait for the thread to get scheduled and call close\n+      Method method = Producer.class.getMethod(\"close\", long.class, TimeUnit.class);\n+      PollUtils.poll(() -> {\n+        Collection<Invocation> invocations = mockingDetails(_mockProducer).getInvocations();\n+        long count = invocations.stream().filter(invocation -> invocation.getMethod().equals(method)).count();\n+        return count == numExpected;\n+      }, 1000, 10000);\n       verify(_mockProducer, times(numExpected)).close(anyLong(), any(TimeUnit.class));", "originalCommit": "8ddffe91eb0c3d054e1e728c35d850b14b7db39c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgxNzU3MA==", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r430817570", "bodyText": "As discussed offline, it does make sense to leave this as is since we want to test both that shutdownProducer is called and that mockProducer's close() is called.", "author": "somandal", "createdAt": "2020-05-27T02:06:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDc2MTE4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDc2MjQ4MA==", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r430762480", "bodyText": "Unlike the other two verify*() methods, this one resets its call count (_numShutdownProducerCalls). This is a little confusing because the call counts passed to the other methods in testFlushInterrupt() are all cumulative.", "author": "ahmedahamid", "createdAt": "2020-05-26T23:30:29Z", "path": "datastream-kafka/src/test/java/com/linkedin/datastream/kafka/TestKafkaProducerWrapper.java", "diffHunk": "@@ -141,8 +153,17 @@ void verifyFlush(int numExpected) {\n       verify(_mockProducer, times(numExpected)).flush();\n     }\n \n-    void verifyClose(int numExpected) {\n+    void verifyClose(int numExpected) throws NoSuchMethodException {\n+      // Producer close is invoked in a separate thread. Must wait for the thread to get scheduled and call close\n+      Method method = Producer.class.getMethod(\"close\", long.class, TimeUnit.class);\n+      PollUtils.poll(() -> {\n+        Collection<Invocation> invocations = mockingDetails(_mockProducer).getInvocations();\n+        long count = invocations.stream().filter(invocation -> invocation.getMethod().equals(method)).count();\n+        return count == numExpected;\n+      }, 1000, 10000);\n       verify(_mockProducer, times(numExpected)).close(anyLong(), any(TimeUnit.class));\n+      Assert.assertEquals(_numShutdownProducerCalls, numExpected);\n+      _numShutdownProducerCalls = 0;", "originalCommit": "8ddffe91eb0c3d054e1e728c35d850b14b7db39c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgxNzY2Mw==", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r430817663", "bodyText": "As discussed offline, leaving this as is since mockProducers can be created and removed during the test", "author": "somandal", "createdAt": "2020-05-27T02:07:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDc2MjQ4MA=="}], "type": "inlineReview"}, {"oid": "97871962ca674d17fb8dfe3a103148d494c00c70", "url": "https://github.com/linkedin/brooklin/commit/97871962ca674d17fb8dfe3a103148d494c00c70", "message": "Address review comments", "committedDate": "2020-05-27T02:05:17Z", "type": "commit"}, {"oid": "9903637456ba0d3dd4ccdcbaa2063dd63c944485", "url": "https://github.com/linkedin/brooklin/commit/9903637456ba0d3dd4ccdcbaa2063dd63c944485", "message": "Use single thread executor", "committedDate": "2020-05-27T16:13:53Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjU2MDU5MQ==", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r432560591", "bodyText": "nit: not sure why this method called generateSendFailure. Should this be renamed to handleSendFailure?", "author": "DEEPTHIKORAT", "createdAt": "2020-05-29T15:24:05Z", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -221,47 +234,63 @@ void send(DatastreamTask task, ProducerRecord<K, V> producerRecord, Callback onC\n         }\n         // Set a max_send_attempts for KafkaException as it may be non-recoverable\n         if (numberOfAttempt > MAX_SEND_ATTEMPTS || ((cause instanceof Error || cause instanceof RuntimeException))) {\n-          _log.error(\"Send failed for partition {} with a non retriable exception\", producerRecord.partition(), e);\n+          _log.error(String.format(\"Send failed for partition %d with a non-retriable exception\",\n+              producerRecord.partition()), e);\n           throw generateSendFailure(e);\n         } else {\n-          _log.warn(\"Send failed for partition {} with retriable exception, retry {} out of {} in {} ms.\",\n-              producerRecord.partition(), numberOfAttempt, MAX_SEND_ATTEMPTS, _sendFailureRetryWaitTimeMs, e);\n+          _log.warn(String.format(\n+              \"Send failed for partition %d with a retriable exception, retry %d out of %d in %d ms.\",\n+              producerRecord.partition(), numberOfAttempt, MAX_SEND_ATTEMPTS, _sendFailureRetryWaitTimeMs), e);\n           Thread.sleep(_sendFailureRetryWaitTimeMs);\n         }\n       } catch (Exception e) {\n-        _log.error(\"Send failed for partition {} with an exception\", producerRecord.partition(), e);\n+        _log.error(String.format(\"Send failed for partition %d with an exception\", producerRecord.partition()), e);\n         throw generateSendFailure(e);\n       }\n     }\n   }\n \n-  private synchronized void shutdownProducer() {\n-    Producer<K, V> producer = _kafkaProducer;\n-    // Nullify first to prevent subsequent send() to use\n-    // the current producer which is being shutdown.\n-    _kafkaProducer = null;\n+  @VisibleForTesting\n+  void shutdownProducer() {\n+    Producer<K, V> producer;\n+    synchronized (_producerLock) {\n+      producer = _kafkaProducer;\n+      // Nullify first to prevent subsequent send() to use\n+      // the current producer which is being shutdown.\n+      _kafkaProducer = null;\n+    }\n+\n+    // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n+    // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n+    // thread\n     if (producer != null) {\n-      producer.close(TIME_OUT, TimeUnit.MILLISECONDS);\n-      NUM_PRODUCERS.decrementAndGet();\n+      _producerCloseExecutorService.submit(() -> {\n+        _log.info(\"KafkaProducerWrapper: Closing the Kafka Producer\");\n+        producer.close(TIME_OUT, TimeUnit.MILLISECONDS);\n+        NUM_PRODUCERS.decrementAndGet();\n+        _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+      });\n     }\n   }\n \n   private DatastreamRuntimeException generateSendFailure(Exception exception) {", "originalCommit": "9903637456ba0d3dd4ccdcbaa2063dd63c944485", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY1MTcyMg==", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r432651722", "bodyText": "Went back and forth in my head on this. throws handleSendFailure looks very weird to me. So leaving this as is.", "author": "somandal", "createdAt": "2020-05-29T18:05:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjU2MDU5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYzNzcwMQ==", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r432637701", "bodyText": "nit: A lock used to \"synchronize\" access to", "author": "DEEPTHIKORAT", "createdAt": "2020-05-29T17:37:30Z", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -98,6 +104,13 @@\n   private final DynamicMetricsManager _dynamicMetricsManager;\n   private final String _metricsNamesPrefix;\n \n+  // A lock used to synchronized access to operations performed on the _kafkaProducer object", "originalCommit": "9903637456ba0d3dd4ccdcbaa2063dd63c944485", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY1MDY2OA==", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r432650668", "bodyText": "done", "author": "somandal", "createdAt": "2020-05-29T18:02:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYzNzcwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYzODc5Ng==", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r432638796", "bodyText": "I am guessing we can now use setName API instead without the %d format since you changed to singleThreadExecutor?", "author": "DEEPTHIKORAT", "createdAt": "2020-05-29T17:39:44Z", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -98,6 +104,13 @@\n   private final DynamicMetricsManager _dynamicMetricsManager;\n   private final String _metricsNamesPrefix;\n \n+  // A lock used to synchronized access to operations performed on the _kafkaProducer object\n+  private final Object _producerLock = new Object();\n+\n+  // An executor to spawn threads to close the producer.\n+  private final ExecutorService _producerCloseExecutorService = Executors.newSingleThreadExecutor(\n+      new ThreadFactoryBuilder().setNameFormat(\"KafkaProducerWrapperClose-%d\").build());", "originalCommit": "9903637456ba0d3dd4ccdcbaa2063dd63c944485", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY1MTQ1OA==", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r432651458", "bodyText": "as discussed, there is no setName API for the  ThreadFactoryBuilder,  so leaving this as is.", "author": "somandal", "createdAt": "2020-05-29T18:04:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYzODc5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYzOTUyMA==", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r432639520", "bodyText": "nit: Should we use StringUtils ?", "author": "DEEPTHIKORAT", "createdAt": "2020-05-29T17:40:59Z", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -117,7 +130,7 @@\n \n     _clientId = transportProviderProperties.getProperty(ProducerConfig.CLIENT_ID_CONFIG);\n     if (_clientId == null || _clientId.isEmpty()) {", "originalCommit": "9903637456ba0d3dd4ccdcbaa2063dd63c944485", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY1MTQ5OA==", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r432651498", "bodyText": "done", "author": "somandal", "createdAt": "2020-05-29T18:04:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYzOTUyMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY0NTI1Ng==", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r432645256", "bodyText": "nit: should this read: \"send failed with a non-transient exception. Shutting down producer\" to match what is being done in the method.", "author": "DEEPTHIKORAT", "createdAt": "2020-05-29T17:52:05Z", "path": "datastream-kafka/src/main/java/com/linkedin/datastream/kafka/KafkaProducerWrapper.java", "diffHunk": "@@ -221,47 +234,63 @@ void send(DatastreamTask task, ProducerRecord<K, V> producerRecord, Callback onC\n         }\n         // Set a max_send_attempts for KafkaException as it may be non-recoverable\n         if (numberOfAttempt > MAX_SEND_ATTEMPTS || ((cause instanceof Error || cause instanceof RuntimeException))) {\n-          _log.error(\"Send failed for partition {} with a non retriable exception\", producerRecord.partition(), e);\n+          _log.error(String.format(\"Send failed for partition %d with a non-retriable exception\",\n+              producerRecord.partition()), e);\n           throw generateSendFailure(e);\n         } else {\n-          _log.warn(\"Send failed for partition {} with retriable exception, retry {} out of {} in {} ms.\",\n-              producerRecord.partition(), numberOfAttempt, MAX_SEND_ATTEMPTS, _sendFailureRetryWaitTimeMs, e);\n+          _log.warn(String.format(\n+              \"Send failed for partition %d with a retriable exception, retry %d out of %d in %d ms.\",\n+              producerRecord.partition(), numberOfAttempt, MAX_SEND_ATTEMPTS, _sendFailureRetryWaitTimeMs), e);\n           Thread.sleep(_sendFailureRetryWaitTimeMs);\n         }\n       } catch (Exception e) {\n-        _log.error(\"Send failed for partition {} with an exception\", producerRecord.partition(), e);\n+        _log.error(String.format(\"Send failed for partition %d with an exception\", producerRecord.partition()), e);\n         throw generateSendFailure(e);\n       }\n     }\n   }\n \n-  private synchronized void shutdownProducer() {\n-    Producer<K, V> producer = _kafkaProducer;\n-    // Nullify first to prevent subsequent send() to use\n-    // the current producer which is being shutdown.\n-    _kafkaProducer = null;\n+  @VisibleForTesting\n+  void shutdownProducer() {\n+    Producer<K, V> producer;\n+    synchronized (_producerLock) {\n+      producer = _kafkaProducer;\n+      // Nullify first to prevent subsequent send() to use\n+      // the current producer which is being shutdown.\n+      _kafkaProducer = null;\n+    }\n+\n+    // This may be called from the send callback. The callbacks are called from the sender thread, and must complete\n+    // quickly to avoid delaying/blocking the sender thread. Thus schedule the actual producer.close() on a separate\n+    // thread\n     if (producer != null) {\n-      producer.close(TIME_OUT, TimeUnit.MILLISECONDS);\n-      NUM_PRODUCERS.decrementAndGet();\n+      _producerCloseExecutorService.submit(() -> {\n+        _log.info(\"KafkaProducerWrapper: Closing the Kafka Producer\");\n+        producer.close(TIME_OUT, TimeUnit.MILLISECONDS);\n+        NUM_PRODUCERS.decrementAndGet();\n+        _log.info(\"KafkaProducerWrapper: Kafka Producer is closed\");\n+      });\n     }\n   }\n \n   private DatastreamRuntimeException generateSendFailure(Exception exception) {\n     _dynamicMetricsManager.createOrUpdateMeter(_metricsNamesPrefix, AGGREGATE, PRODUCER_ERROR, 1);\n     if (exception instanceof IllegalStateException) {\n-      _log.warn(\"sent failure transiently, exception: \", exception);\n+      _log.warn(\"send failed transiently with exception: \", exception);\n       return new DatastreamTransientException(exception);\n     } else {\n-      _log.warn(\"sent failure, restart producer, exception: \", exception);\n+      _log.warn(\"send failed, restart producer, exception: \", exception);", "originalCommit": "9903637456ba0d3dd4ccdcbaa2063dd63c944485", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY1MjM3Nw==", "url": "https://github.com/linkedin/brooklin/pull/714#discussion_r432652377", "bodyText": "done", "author": "somandal", "createdAt": "2020-05-29T18:06:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY0NTI1Ng=="}], "type": "inlineReview"}, {"oid": "b7798009d8744c782dbce1997c308b4103d07d29", "url": "https://github.com/linkedin/brooklin/commit/b7798009d8744c782dbce1997c308b4103d07d29", "message": "Address review comments", "committedDate": "2020-05-29T18:08:05Z", "type": "commit"}]}