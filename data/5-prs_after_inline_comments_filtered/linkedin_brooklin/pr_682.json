{"pr_number": 682, "pr_title": "Add synchronization around runningTasks map in AbstractKafkaConnector", "pr_createdAt": "2020-02-08T06:48:08Z", "pr_url": "https://github.com/linkedin/brooklin/pull/682", "timeline": [{"oid": "44be7539c9fd406ccfb851ed0ea6243a8f5a211c", "url": "https://github.com/linkedin/brooklin/commit/44be7539c9fd406ccfb851ed0ea6243a8f5a211c", "message": "Add synchronization around runningTasks map in AbstractKafkaConnector", "committedDate": "2020-02-08T06:45:12Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjcxMDE3Mw==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r376710173", "bodyText": "nit: it's preferable to use Map<K, V> for type declaration since it gives us the freedom to change the concrete type later should we need to.\nIt would be nice to have a comment here documenting that access to this map must be synchronized because it is accessed by multiple concurrent threads.", "author": "ahmedahamid", "createdAt": "2020-02-08T13:29:32Z", "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaConnector.java", "diffHunk": "@@ -76,13 +75,10 @@\n   protected final KafkaBasedConnectorConfig _config;\n   protected final GroupIdConstructor _groupIdConstructor;\n   protected final String _clusterName;\n-  protected final ConcurrentHashMap<DatastreamTask, AbstractKafkaBasedConnectorTask> _runningTasks =\n-      new ConcurrentHashMap<>();\n \n   private final Logger _logger;\n   private final AtomicInteger _threadCounter = new AtomicInteger(0);\n-  private final ConcurrentHashMap<DatastreamTask, Thread> _taskThreads = new ConcurrentHashMap<>();\n-\n+  private final HashMap<DatastreamTask, ConnectorTaskEntry> _runningTasks = new HashMap<>();", "originalCommit": "44be7539c9fd406ccfb851ed0ea6243a8f5a211c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjczNzc4OA==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r376737788", "bodyText": "done", "author": "somandal", "createdAt": "2020-02-08T22:10:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjcxMDE3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjcxMjU2NQ==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r376712565", "bodyText": "I don't think we need to instantiate a new ConnectorTaskEntry here (it's immutable; kafkaBasedConnectorTask mutates its internal state and thread does not change). We can use connectorTaskEntry instead.\nUnrelated to your change: despite the comment on line 137, I still found it confusing that the code indexes into _runningTasks using task then puts the same task back into the map. Turns out the reason is that DatastreamTaskImpl.hashCode() is only computed based on the following properties:\n  @Override\n  public int hashCode() {\n    return Objects.hash(_connectorType, _id, _taskPrefix, _partitions, _partitionsV2);\n  }\nThis implies that two tasks with the same _connectorType, _id, _taskPrefix, _partitions, _partitionsV2 will hash to the same slot in _runningTasks even if their dependencies are different for example, which makes it necessary to do that confusing replacement because getting a non-null value from   _runningTasks.get(task) does not necessarily imply that task is identical to the one in the map. I think this is worth a comment explaining that the reason behind that seemingly unnecessary replacement is that the identity of the datastream task is only determined based on a subset of its properties.\nAlso unrelated to your change but a consequence of the previous point: do you know if it is actually sound to not spawn a new connector task for a newly assigned datastream task that has different dependencies?", "author": "ahmedahamid", "createdAt": "2020-02-08T14:20:15Z", "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaConnector.java", "diffHunk": "@@ -124,25 +120,27 @@ public AbstractKafkaConnector(String connectorName, Properties config, GroupIdCo\n   public synchronized void onAssignmentChange(List<DatastreamTask> tasks) {\n     _logger.info(\"onAssignmentChange called with tasks {}\", tasks);\n \n-    HashSet<DatastreamTask> toCancel = new HashSet<>(_runningTasks.keySet());\n-    toCancel.removeAll(tasks);\n-\n-    for (DatastreamTask task : toCancel) {\n-      AbstractKafkaBasedConnectorTask connectorTask = _runningTasks.remove(task);\n-      connectorTask.stop();\n-      _taskThreads.remove(task);\n-    }\n+    synchronized (_runningTasks) {\n+      HashSet<DatastreamTask> toCancel = new HashSet<>(_runningTasks.keySet());\n+      toCancel.removeAll(tasks);\n \n-    for (DatastreamTask task : tasks) {\n-      AbstractKafkaBasedConnectorTask kafkaBasedConnectorTask = _runningTasks.get(task);\n-      if (kafkaBasedConnectorTask != null) {\n-        kafkaBasedConnectorTask.checkForUpdateTask(task);\n-        // make sure to replace the DatastreamTask with most up to date info\n-        _runningTasks.put(task, kafkaBasedConnectorTask);\n-        continue; // already running\n+      for (DatastreamTask task : toCancel) {\n+        ConnectorTaskEntry connectorTaskEntry = _runningTasks.remove(task);\n+        connectorTaskEntry.getConnectorTask().stop();\n       }\n \n-      createKafkaConnectorTask(task);\n+      for (DatastreamTask task : tasks) {\n+        ConnectorTaskEntry connectorTaskEntry = _runningTasks.get(task);\n+        if (connectorTaskEntry != null) {\n+          AbstractKafkaBasedConnectorTask kafkaBasedConnectorTask = connectorTaskEntry.getConnectorTask();\n+          kafkaBasedConnectorTask.checkForUpdateTask(task);\n+          // make sure to replace the DatastreamTask with most up to date info\n+          _runningTasks.put(task, new ConnectorTaskEntry(kafkaBasedConnectorTask, connectorTaskEntry.getThread()));", "originalCommit": "44be7539c9fd406ccfb851ed0ea6243a8f5a211c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjczODcxMQ==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r376738711", "bodyText": "let's discuss this in person, I'm a little confused.", "author": "somandal", "createdAt": "2020-02-08T22:31:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjcxMjU2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzI3NTI4Nw==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r377275287", "bodyText": "For (3): Dependencies are not a worry at the moment. Only partition-managed datastreams use dependencies, and when a new task is created which has a list of dependencies, the taskPrefix of the new task is always different. This may become a concern in the future we change the semantics of this, where tasks having the same task prefix can have different dependencies.", "author": "somandal", "createdAt": "2020-02-10T19:40:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjcxMjU2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjcyNzcwMg==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r376727702", "bodyText": "It would be nice to have a comment explaining why we're not using/calling stopTask() here.", "author": "ahmedahamid", "createdAt": "2020-02-08T19:06:49Z", "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaConnector.java", "diffHunk": "@@ -124,25 +120,27 @@ public AbstractKafkaConnector(String connectorName, Properties config, GroupIdCo\n   public synchronized void onAssignmentChange(List<DatastreamTask> tasks) {\n     _logger.info(\"onAssignmentChange called with tasks {}\", tasks);\n \n-    HashSet<DatastreamTask> toCancel = new HashSet<>(_runningTasks.keySet());\n-    toCancel.removeAll(tasks);\n-\n-    for (DatastreamTask task : toCancel) {\n-      AbstractKafkaBasedConnectorTask connectorTask = _runningTasks.remove(task);\n-      connectorTask.stop();\n-      _taskThreads.remove(task);\n-    }\n+    synchronized (_runningTasks) {\n+      HashSet<DatastreamTask> toCancel = new HashSet<>(_runningTasks.keySet());\n+      toCancel.removeAll(tasks);\n \n-    for (DatastreamTask task : tasks) {\n-      AbstractKafkaBasedConnectorTask kafkaBasedConnectorTask = _runningTasks.get(task);\n-      if (kafkaBasedConnectorTask != null) {\n-        kafkaBasedConnectorTask.checkForUpdateTask(task);\n-        // make sure to replace the DatastreamTask with most up to date info\n-        _runningTasks.put(task, kafkaBasedConnectorTask);\n-        continue; // already running\n+      for (DatastreamTask task : toCancel) {\n+        ConnectorTaskEntry connectorTaskEntry = _runningTasks.remove(task);\n+        connectorTaskEntry.getConnectorTask().stop();", "originalCommit": "44be7539c9fd406ccfb851ed0ea6243a8f5a211c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjczNzc5OA==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r376737798", "bodyText": "done", "author": "somandal", "createdAt": "2020-02-08T22:11:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjcyNzcwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Njc0NjQ0Ng==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r376746446", "bodyText": "Awesome \ud83d\udc4c Thank you", "author": "ahmedahamid", "createdAt": "2020-02-09T01:08:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjcyNzcwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjcyODAwMQ==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r376728001", "bodyText": "Please, consider inverting the logic of this method (e.g. isDead/Stopped/BrokenTask()).\nIf you like this suggestion, it may also be a good idea to change the name of restartTasksIfNotRunning() to restartDead/Stopped/BrokenTasks().", "author": "ahmedahamid", "createdAt": "2020-02-08T19:13:17Z", "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaConnector.java", "diffHunk": "@@ -189,36 +182,59 @@ public void start(CheckpointProvider checkpointProvider) {\n   }\n \n   /**\n-   * If the {@link AbstractKafkaBasedConnectorTask} corresponding to the {@link DatastreamTask} is not running, Restart it.\n-   * @param task Datastream task which needs to checked and restarted if it is not running.\n+   * Check the health of all {@link AbstractKafkaBasedConnectorTask} corresponding to the DatastreamTasks.\n+   * If any of them are not running or not healthy, Restart them.\n    */\n-  protected void restartIfNotRunning(DatastreamTask task) {\n-    if (!isTaskRunning(task)) {\n-      _logger.warn(\"Detected that the kafka connector task is not running for datastream task {}. Restarting it\", task);\n-      boolean stopped = stopTask(task);\n-      if (stopped) {\n-        createKafkaConnectorTask(task);\n-      } else {\n-        _logger.error(\"Datastream task {} could not be stopped.\", task);\n+  protected void restartTasksIfNotRunning() {\n+    synchronized (_runningTasks) {\n+      if (_runningTasks.isEmpty()) {\n+        _logger.info(\"connector received no datastreams tasks yet.\");\n+        return;\n       }\n+\n+      _logger.info(\"Checking the status of {} running connector tasks.\", _runningTasks.size());\n+\n+      Set<DatastreamTask> deadDatastreamTasks = new HashSet<>();\n+      _runningTasks.keySet().forEach((datastreamTask) -> {\n+        if (!isTaskRunning(datastreamTask)) {", "originalCommit": "44be7539c9fd406ccfb851ed0ea6243a8f5a211c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjczODYxMA==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r376738610", "bodyText": "done", "author": "somandal", "createdAt": "2020-02-08T22:29:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjcyODAwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjcyODE0Ng==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r376728146", "bodyText": "not your fault nit: please change the type of toCancel to Set<DatastreamTask>", "author": "ahmedahamid", "createdAt": "2020-02-08T19:15:44Z", "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaConnector.java", "diffHunk": "@@ -124,25 +120,27 @@ public AbstractKafkaConnector(String connectorName, Properties config, GroupIdCo\n   public synchronized void onAssignmentChange(List<DatastreamTask> tasks) {\n     _logger.info(\"onAssignmentChange called with tasks {}\", tasks);\n \n-    HashSet<DatastreamTask> toCancel = new HashSet<>(_runningTasks.keySet());\n-    toCancel.removeAll(tasks);\n-\n-    for (DatastreamTask task : toCancel) {\n-      AbstractKafkaBasedConnectorTask connectorTask = _runningTasks.remove(task);\n-      connectorTask.stop();\n-      _taskThreads.remove(task);\n-    }\n+    synchronized (_runningTasks) {\n+      HashSet<DatastreamTask> toCancel = new HashSet<>(_runningTasks.keySet());", "originalCommit": "44be7539c9fd406ccfb851ed0ea6243a8f5a211c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjczNzc5NQ==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r376737795", "bodyText": "done", "author": "somandal", "createdAt": "2020-02-08T22:11:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjcyODE0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjcyOTcwMw==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r376729703", "bodyText": "I think this can be simplified to by adding a map() before filter():\n          .map(ConnectorTaskEntry::getConnectorTask)\n          .filter(task -> task.hasDatastream(streamName))\n          .map(task -> task.getKafkaDatastreamStatesResponse())", "author": "ahmedahamid", "createdAt": "2020-02-08T19:43:27Z", "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaConnector.java", "diffHunk": "@@ -374,11 +393,14 @@ public String process(String query) {\n    * Collect stats from every running task and join them into single response\n    */\n   private Optional<KafkaDatastreamStatesResponse> getDatastreamStatesResponse(String streamName) {\n-    List<KafkaDatastreamStatesResponse> responses = _runningTasks.values()\n-        .stream()\n-        .filter(task -> task.hasDatastream(streamName))\n-        .map(AbstractKafkaBasedConnectorTask::getKafkaDatastreamStatesResponse)\n-        .collect(Collectors.toList());\n+    List<KafkaDatastreamStatesResponse> responses;\n+    synchronized (_runningTasks) {\n+      responses = _runningTasks.values()\n+          .stream()\n+          .filter(connectorTaskEntry -> connectorTaskEntry.getConnectorTask().hasDatastream(streamName))\n+          .map(connectorTaskEntry -> connectorTaskEntry.getConnectorTask().getKafkaDatastreamStatesResponse())", "originalCommit": "44be7539c9fd406ccfb851ed0ea6243a8f5a211c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjczODc3OA==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r376738778", "bodyText": "done", "author": "somandal", "createdAt": "2020-02-08T22:33:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjcyOTcwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjcyOTczMg==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r376729732", "bodyText": "nit: please rename to connectorTask", "author": "ahmedahamid", "createdAt": "2020-02-08T19:44:10Z", "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaConnector.java", "diffHunk": "@@ -229,30 +245,33 @@ private boolean stopTask(DatastreamTask datastreamTask) {\n \n   /**\n    * Check if the {@link AbstractKafkaBasedConnectorTask} corresponding to the {@link DatastreamTask} is running.\n+   * The _runningTasks must be locked before calling this method\n    * @param datastreamTask Datastream task that needs to be checked whether it is running.\n    * @return true if it is running, false if it is not.\n    */\n   protected boolean isTaskRunning(DatastreamTask datastreamTask) {\n-    Thread taskThread = _taskThreads.get(datastreamTask);\n-    AbstractKafkaBasedConnectorTask kafkaTask = _runningTasks.get(datastreamTask);\n+    ConnectorTaskEntry connectorTaskEntry = _runningTasks.get(datastreamTask);\n+    Thread taskThread = connectorTaskEntry.getThread();\n+    AbstractKafkaBasedConnectorTask kafkaTask = connectorTaskEntry.getConnectorTask();", "originalCommit": "44be7539c9fd406ccfb851ed0ea6243a8f5a211c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjczODY2OQ==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r376738669", "bodyText": "done", "author": "somandal", "createdAt": "2020-02-08T22:31:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjcyOTczMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjcyOTc1Mg==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r376729752", "bodyText": "Not your fault because the pattern I'm about to criticize existed in this class before this PR. Here's a couple of places where I find the code doing things in a somewhat roundabout way:\n// case #1\n// We're choosing to iterate over keys ...\n_runningTasks.keySet().forEach((datastreamTask) -> { \n       // ... but isTaskRunning() indexes into _runningTasks to retrieve \n       // the value. Why not iterate over keys and values here and pass \n       // the value (ConnectorTaskEntry) directly to isTaskRunning() instead?\n        if (!isTaskRunning(datastreamTask) {\n        }\n)\n\n// case #2\n// We're choosing to iterate over keys, but we're passing every key to \n// stopTask() so it can index into _runningTasks (again?) to retrieve \n// the value. Why not iterate over the values passing each to stopTask()\n// instead?\n_runningTasks.keySet().forEach(this::stopTask);", "author": "ahmedahamid", "createdAt": "2020-02-08T19:44:49Z", "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaConnector.java", "diffHunk": "@@ -189,36 +182,59 @@ public void start(CheckpointProvider checkpointProvider) {\n   }\n \n   /**\n-   * If the {@link AbstractKafkaBasedConnectorTask} corresponding to the {@link DatastreamTask} is not running, Restart it.\n-   * @param task Datastream task which needs to checked and restarted if it is not running.\n+   * Check the health of all {@link AbstractKafkaBasedConnectorTask} corresponding to the DatastreamTasks.\n+   * If any of them are not running or not healthy, Restart them.\n    */\n-  protected void restartIfNotRunning(DatastreamTask task) {\n-    if (!isTaskRunning(task)) {\n-      _logger.warn(\"Detected that the kafka connector task is not running for datastream task {}. Restarting it\", task);\n-      boolean stopped = stopTask(task);\n-      if (stopped) {\n-        createKafkaConnectorTask(task);\n-      } else {\n-        _logger.error(\"Datastream task {} could not be stopped.\", task);\n+  protected void restartTasksIfNotRunning() {\n+    synchronized (_runningTasks) {\n+      if (_runningTasks.isEmpty()) {\n+        _logger.info(\"connector received no datastreams tasks yet.\");\n+        return;\n       }\n+\n+      _logger.info(\"Checking the status of {} running connector tasks.\", _runningTasks.size());\n+\n+      Set<DatastreamTask> deadDatastreamTasks = new HashSet<>();\n+      _runningTasks.keySet().forEach((datastreamTask) -> {\n+        if (!isTaskRunning(datastreamTask)) {", "originalCommit": "44be7539c9fd406ccfb851ed0ea6243a8f5a211c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjczODYzOA==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r376738638", "bodyText": "done - I was debating about this too, and then decided I'd make this change as part of the next change to force cancel task in a separate thread during onAssignmentChange(). Easy enough to do it as part of this change itself though.", "author": "somandal", "createdAt": "2020-02-08T22:30:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjcyOTc1Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Njc0NzEyMA==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r376747120", "bodyText": "Thank you", "author": "ahmedahamid", "createdAt": "2020-02-09T01:27:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjcyOTc1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjczMTU3Ng==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r376731576", "bodyText": "Not your fault: I wonder if returning true is sound in case we interrupt the thread (line 236); how do we know if the code in that thread actually complied? What if it ignored our interruption altogether (especially since this is a base class managing a base/abstract task \u2014 the behaviors of different extenders may vary). Returning true before making sure the task stopped means we can be spawning a new connector task for datastreamTask in restartTasksIfNotRunning(), one that would be running simultaneously with the broken/rogue task that ignored interruption.\nWould it be better if we did return stopped  || kafkaTask.awaitStop(0, TimeUnit.MILLISECONDS) instead?", "author": "ahmedahamid", "createdAt": "2020-02-08T20:16:03Z", "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaConnector.java", "diffHunk": "@@ -189,36 +182,59 @@ public void start(CheckpointProvider checkpointProvider) {\n   }\n \n   /**\n-   * If the {@link AbstractKafkaBasedConnectorTask} corresponding to the {@link DatastreamTask} is not running, Restart it.\n-   * @param task Datastream task which needs to checked and restarted if it is not running.\n+   * Check the health of all {@link AbstractKafkaBasedConnectorTask} corresponding to the DatastreamTasks.\n+   * If any of them are not running or not healthy, Restart them.\n    */\n-  protected void restartIfNotRunning(DatastreamTask task) {\n-    if (!isTaskRunning(task)) {\n-      _logger.warn(\"Detected that the kafka connector task is not running for datastream task {}. Restarting it\", task);\n-      boolean stopped = stopTask(task);\n-      if (stopped) {\n-        createKafkaConnectorTask(task);\n-      } else {\n-        _logger.error(\"Datastream task {} could not be stopped.\", task);\n+  protected void restartTasksIfNotRunning() {\n+    synchronized (_runningTasks) {\n+      if (_runningTasks.isEmpty()) {\n+        _logger.info(\"connector received no datastreams tasks yet.\");\n+        return;\n       }\n+\n+      _logger.info(\"Checking the status of {} running connector tasks.\", _runningTasks.size());\n+\n+      Set<DatastreamTask> deadDatastreamTasks = new HashSet<>();\n+      _runningTasks.keySet().forEach((datastreamTask) -> {\n+        if (!isTaskRunning(datastreamTask)) {\n+          _logger.warn(\"Detected that the kafka connector task is not running for datastream task {}. Restarting it\",\n+              datastreamTask);\n+          boolean stopped = stopTask(datastreamTask);\n+          if (stopped) {\n+            deadDatastreamTasks.add(datastreamTask);\n+          } else {\n+            _logger.error(\"Datastream task {} could not be stopped.\", datastreamTask);\n+          }\n+        } else {\n+          _logger.info(\"Connector task for datastream task {} is healthy\", datastreamTask);\n+        }\n+      });\n+\n+      deadDatastreamTasks.forEach(datastreamTask -> {\n+        _logger.warn(\"Creating a new connector task for the datastream task {}\", datastreamTask);\n+        _runningTasks.remove(datastreamTask);\n+        createKafkaConnectorTask(datastreamTask);\n+      });\n     }\n   }\n \n   /**\n    * Stop the datastream task and wait for it to stop. If it has not stopped within a timeout, interrupt the thread.\n+   * The _runningTasks must be locked before calling this method\n+   * @param datastreamTask Datastream task that needs to stopped.\n+   * @return true if it was successfully stopped, false if it was not.\n    */\n   private boolean stopTask(DatastreamTask datastreamTask) {\n     try {\n-      AbstractKafkaBasedConnectorTask kafkaTask = _runningTasks.get(datastreamTask);\n+      ConnectorTaskEntry connectorTaskEntry = _runningTasks.get(datastreamTask);\n+      AbstractKafkaBasedConnectorTask kafkaTask = connectorTaskEntry.getConnectorTask();\n       kafkaTask.stop();\n       boolean stopped = kafkaTask.awaitStop(CANCEL_TASK_TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n       if (!stopped) {\n         _logger.warn(\"Task {} took longer than {} ms to stop. Interrupting the thread.\", datastreamTask,\n             CANCEL_TASK_TIMEOUT.toMillis());\n-        _taskThreads.get(datastreamTask).interrupt();\n+        connectorTaskEntry.getThread().interrupt();\n       }\n-      _runningTasks.remove(datastreamTask);\n-      _taskThreads.remove(datastreamTask);\n       return true;", "originalCommit": "44be7539c9fd406ccfb851ed0ea6243a8f5a211c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjczODY4Ng==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r376738686", "bodyText": "let's discuss this in person - basically what are the repercussions if we race with when the thread gets interrupted and the countdown latch reflects the fact,  and when we check the status? What if it does get interrupted and we miss this?", "author": "somandal", "createdAt": "2020-02-08T22:31:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjczMTU3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Njc0ODcwNw==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r376748707", "bodyText": "Good point. The interrupted thread is most certainly not going to react so quickly.\nPerhaps we can return awaitStop() after interruption (prolly with a shorter timeout than CANCEL_TASK_TIMEOUT though), or maybe we can return false after interruption so that restartDeadTasks() keeps the task around until the next health-check. Bottom line is: I like the idea of seeing a flow of warning logs about rogue tasks until they comply rather than allowing them to linger around in a faulty state for unknown durations.\nTwo important questions beg themselves though:\n\nIs it okay if we keep trying to stop a rogue task first before spawning a new one?\nConversely, is it okay to spawn a new task in the presence of an incompliant rogue one?\n\nLet's discuss this in person, I agree.", "author": "ahmedahamid", "createdAt": "2020-02-09T02:10:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjczMTU3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzMwOTgyMg==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r377309822", "bodyText": "We have decided to awaitStop() for a shorter period of time after interrupting, and adding a warning log indicating that the task may not have stopped. In the future if we see these often, we will add a metric to track this.", "author": "somandal", "createdAt": "2020-02-10T20:53:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjczMTU3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjczMTcwNQ==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r376731705", "bodyText": "nit: please rename to connectorTask", "author": "ahmedahamid", "createdAt": "2020-02-08T20:18:15Z", "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaConnector.java", "diffHunk": "@@ -189,36 +182,59 @@ public void start(CheckpointProvider checkpointProvider) {\n   }\n \n   /**\n-   * If the {@link AbstractKafkaBasedConnectorTask} corresponding to the {@link DatastreamTask} is not running, Restart it.\n-   * @param task Datastream task which needs to checked and restarted if it is not running.\n+   * Check the health of all {@link AbstractKafkaBasedConnectorTask} corresponding to the DatastreamTasks.\n+   * If any of them are not running or not healthy, Restart them.\n    */\n-  protected void restartIfNotRunning(DatastreamTask task) {\n-    if (!isTaskRunning(task)) {\n-      _logger.warn(\"Detected that the kafka connector task is not running for datastream task {}. Restarting it\", task);\n-      boolean stopped = stopTask(task);\n-      if (stopped) {\n-        createKafkaConnectorTask(task);\n-      } else {\n-        _logger.error(\"Datastream task {} could not be stopped.\", task);\n+  protected void restartTasksIfNotRunning() {\n+    synchronized (_runningTasks) {\n+      if (_runningTasks.isEmpty()) {\n+        _logger.info(\"connector received no datastreams tasks yet.\");\n+        return;\n       }\n+\n+      _logger.info(\"Checking the status of {} running connector tasks.\", _runningTasks.size());\n+\n+      Set<DatastreamTask> deadDatastreamTasks = new HashSet<>();\n+      _runningTasks.keySet().forEach((datastreamTask) -> {\n+        if (!isTaskRunning(datastreamTask)) {\n+          _logger.warn(\"Detected that the kafka connector task is not running for datastream task {}. Restarting it\",\n+              datastreamTask);\n+          boolean stopped = stopTask(datastreamTask);\n+          if (stopped) {\n+            deadDatastreamTasks.add(datastreamTask);\n+          } else {\n+            _logger.error(\"Datastream task {} could not be stopped.\", datastreamTask);\n+          }\n+        } else {\n+          _logger.info(\"Connector task for datastream task {} is healthy\", datastreamTask);\n+        }\n+      });\n+\n+      deadDatastreamTasks.forEach(datastreamTask -> {\n+        _logger.warn(\"Creating a new connector task for the datastream task {}\", datastreamTask);\n+        _runningTasks.remove(datastreamTask);\n+        createKafkaConnectorTask(datastreamTask);\n+      });\n     }\n   }\n \n   /**\n    * Stop the datastream task and wait for it to stop. If it has not stopped within a timeout, interrupt the thread.\n+   * The _runningTasks must be locked before calling this method\n+   * @param datastreamTask Datastream task that needs to stopped.\n+   * @return true if it was successfully stopped, false if it was not.\n    */\n   private boolean stopTask(DatastreamTask datastreamTask) {\n     try {\n-      AbstractKafkaBasedConnectorTask kafkaTask = _runningTasks.get(datastreamTask);\n+      ConnectorTaskEntry connectorTaskEntry = _runningTasks.get(datastreamTask);\n+      AbstractKafkaBasedConnectorTask kafkaTask = connectorTaskEntry.getConnectorTask();", "originalCommit": "44be7539c9fd406ccfb851ed0ea6243a8f5a211c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjczODUzMA==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r376738530", "bodyText": "done", "author": "somandal", "createdAt": "2020-02-08T22:27:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjczMTcwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjczMjA2Mw==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r376732063", "bodyText": "Not your fault nit: please reword to make a distinction between datastream tasks (passive data objects) and connector tasks (datastream task processors), e.g. Connector task for datastream task {} could not be stopped.\nThe rationale is that other log messages in this method are correctly worded to distinguish between datastream tasks and connector tasks (e.g. connector task is not running for datastream task, Connector task for datastream task {} is healthy, and Creating a new connector task for the datastream task {}).", "author": "ahmedahamid", "createdAt": "2020-02-08T20:24:57Z", "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaConnector.java", "diffHunk": "@@ -189,36 +182,59 @@ public void start(CheckpointProvider checkpointProvider) {\n   }\n \n   /**\n-   * If the {@link AbstractKafkaBasedConnectorTask} corresponding to the {@link DatastreamTask} is not running, Restart it.\n-   * @param task Datastream task which needs to checked and restarted if it is not running.\n+   * Check the health of all {@link AbstractKafkaBasedConnectorTask} corresponding to the DatastreamTasks.\n+   * If any of them are not running or not healthy, Restart them.\n    */\n-  protected void restartIfNotRunning(DatastreamTask task) {\n-    if (!isTaskRunning(task)) {\n-      _logger.warn(\"Detected that the kafka connector task is not running for datastream task {}. Restarting it\", task);\n-      boolean stopped = stopTask(task);\n-      if (stopped) {\n-        createKafkaConnectorTask(task);\n-      } else {\n-        _logger.error(\"Datastream task {} could not be stopped.\", task);\n+  protected void restartTasksIfNotRunning() {\n+    synchronized (_runningTasks) {\n+      if (_runningTasks.isEmpty()) {\n+        _logger.info(\"connector received no datastreams tasks yet.\");\n+        return;\n       }\n+\n+      _logger.info(\"Checking the status of {} running connector tasks.\", _runningTasks.size());\n+\n+      Set<DatastreamTask> deadDatastreamTasks = new HashSet<>();\n+      _runningTasks.keySet().forEach((datastreamTask) -> {\n+        if (!isTaskRunning(datastreamTask)) {\n+          _logger.warn(\"Detected that the kafka connector task is not running for datastream task {}. Restarting it\",\n+              datastreamTask);\n+          boolean stopped = stopTask(datastreamTask);\n+          if (stopped) {\n+            deadDatastreamTasks.add(datastreamTask);\n+          } else {\n+            _logger.error(\"Datastream task {} could not be stopped.\", datastreamTask);", "originalCommit": "44be7539c9fd406ccfb851ed0ea6243a8f5a211c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjczODY2NQ==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r376738665", "bodyText": "done", "author": "somandal", "createdAt": "2020-02-08T22:30:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjczMjA2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjczMzIzMA==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r376733230", "bodyText": "Thank you for documenting this wherever necessary.\nHere's a suggestion: why don't we lock _runningTasks here (and in every method that has a similar comment) instead? Synchronized blocks are reentrant [url]; a thread locking _runningTask in, say restartTasksIfNotRunning(), would still be able to acquire a lock on it in this method.\nAn even better suggestion IMO: why not have createKafkaConnectorTask() return the ConnectorTaskEntry it instantiates instead? This way, it won't even need to access _runningTask, and call-sites already holding the lock (i.e. in onAssignmentChange() and restartTasksIfNotRunning()) can freely edit _runningTask themselves. The same thing applies to all the other methods that have a similar comment about locking _runningTasks:\n\nstopTask() has no real need to access/lock _runningTasks; we can pass it a ConnectorTaskEntry instead. The callers of stopTask() already lock _runningTasks\nisTaskRunning() can similarly be given a ConnectorTaskEntry instead", "author": "ahmedahamid", "createdAt": "2020-02-08T20:44:01Z", "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaConnector.java", "diffHunk": "@@ -160,25 +158,20 @@ public Thread createTaskThread(AbstractKafkaBasedConnectorTask task) {\n     return t;\n   }\n \n+  // The _runningTasks must be locked before calling this method", "originalCommit": "44be7539c9fd406ccfb851ed0ea6243a8f5a211c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjczODU5NQ==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r376738595", "bodyText": "done - I was debating about this too, and then decided I'd make this change as part of the next change to force cancel task in a separate thread during onAssignmentChange(). Easy enough to do it as part of this change itself though.\nI decided to remove the need of _runningTasks in these functions rather than making them have synchronized blocks too.", "author": "somandal", "createdAt": "2020-02-08T22:29:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjczMzIzMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Njc0NzE0Nw==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r376747147", "bodyText": "Awesome. Thank you.", "author": "ahmedahamid", "createdAt": "2020-02-09T01:28:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjczMzIzMA=="}], "type": "inlineReview"}, {"oid": "dfd320e0c4c9363b9455ffb89fc8cc36bccdf1e5", "url": "https://github.com/linkedin/brooklin/commit/dfd320e0c4c9363b9455ffb89fc8cc36bccdf1e5", "message": "Address review comments", "committedDate": "2020-02-08T22:44:43Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Njc0NjkxOA==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r376746918", "bodyText": "Stale javadoc", "author": "ahmedahamid", "createdAt": "2020-02-09T01:21:59Z", "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaConnector.java", "diffHunk": "@@ -189,70 +185,95 @@ public void start(CheckpointProvider checkpointProvider) {\n   }\n \n   /**\n-   * If the {@link AbstractKafkaBasedConnectorTask} corresponding to the {@link DatastreamTask} is not running, Restart it.\n-   * @param task Datastream task which needs to checked and restarted if it is not running.\n+   * Check the health of all {@link AbstractKafkaBasedConnectorTask} corresponding to the DatastreamTasks.\n+   * If any of them are not running or not healthy, Restart them.\n    */\n-  protected void restartIfNotRunning(DatastreamTask task) {\n-    if (!isTaskRunning(task)) {\n-      _logger.warn(\"Detected that the kafka connector task is not running for datastream task {}. Restarting it\", task);\n-      boolean stopped = stopTask(task);\n-      if (stopped) {\n-        createKafkaConnectorTask(task);\n-      } else {\n-        _logger.error(\"Datastream task {} could not be stopped.\", task);\n+  protected void restartDeadTasks() {\n+    synchronized (_runningTasks) {\n+      if (_runningTasks.isEmpty()) {\n+        _logger.info(\"Connector received no datastreams tasks yet.\");\n+        return;\n       }\n+\n+      _logger.info(\"Checking the status of {} running connector tasks.\", _runningTasks.size());\n+\n+      Set<DatastreamTask> deadDatastreamTasks = new HashSet<>();\n+      _runningTasks.forEach((datastreamTask, connectorTaskEntry) -> {\n+        if (isTaskDead(connectorTaskEntry)) {\n+          _logger.warn(\"Detected that the kafka connector task is not running for datastream task {}. Restarting it\",\n+              datastreamTask);\n+          boolean stopped = stopTask(datastreamTask, connectorTaskEntry);\n+          if (stopped) {\n+            deadDatastreamTasks.add(datastreamTask);\n+          } else {\n+            _logger.error(\"Connector task for datastream task {} could not be stopped.\", datastreamTask);\n+          }\n+        } else {\n+          _logger.info(\"Connector task for datastream task {} is healthy\", datastreamTask);\n+        }\n+      });\n+\n+      deadDatastreamTasks.forEach(datastreamTask -> {\n+        _logger.warn(\"Creating a new connector task for the datastream task {}\", datastreamTask);\n+        _runningTasks.remove(datastreamTask);\n+        _runningTasks.put(datastreamTask, createKafkaConnectorTask(datastreamTask));\n+      });\n     }\n   }\n \n   /**\n    * Stop the datastream task and wait for it to stop. If it has not stopped within a timeout, interrupt the thread.\n+   * @param datastreamTask Datastream task that needs to stopped.\n+   * @param connectorTaskEntry connectorTaskEntry corresponding to the datastream task.\n+   * @return true if it was successfully stopped, false if it was not.\n    */\n-  private boolean stopTask(DatastreamTask datastreamTask) {\n+  private boolean stopTask(DatastreamTask datastreamTask, ConnectorTaskEntry connectorTaskEntry) {\n     try {\n-      AbstractKafkaBasedConnectorTask kafkaTask = _runningTasks.get(datastreamTask);\n-      kafkaTask.stop();\n-      boolean stopped = kafkaTask.awaitStop(CANCEL_TASK_TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+      AbstractKafkaBasedConnectorTask connectorTask = connectorTaskEntry.getConnectorTask();\n+      connectorTask.stop();\n+      boolean stopped = connectorTask.awaitStop(CANCEL_TASK_TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n       if (!stopped) {\n-        _logger.warn(\"Task {} took longer than {} ms to stop. Interrupting the thread.\", datastreamTask,\n-            CANCEL_TASK_TIMEOUT.toMillis());\n-        _taskThreads.get(datastreamTask).interrupt();\n+        _logger.warn(\"Connector task for datastream task {} took longer than {} ms to stop. Interrupting the thread.\",\n+            datastreamTask, CANCEL_TASK_TIMEOUT.toMillis());\n+        connectorTaskEntry.getThread().interrupt();\n       }\n-      _runningTasks.remove(datastreamTask);\n-      _taskThreads.remove(datastreamTask);\n       return true;\n     } catch (InterruptedException e) {\n-      _logger.warn(String.format(\"Caught exception while trying to stop the datastream task %s\", datastreamTask), e);\n+      _logger.warn(String.format(\"Caught exception while trying to stop the connector task for datastream task %s\",\n+          datastreamTask), e);\n     }\n \n     return false;\n   }\n \n   /**\n-   * Check if the {@link AbstractKafkaBasedConnectorTask} corresponding to the {@link DatastreamTask} is running.\n-   * @param datastreamTask Datastream task that needs to be checked whether it is running.\n-   * @return true if it is running, false if it is not.\n+   * Check if the {@link AbstractKafkaBasedConnectorTask} corresponding to the {@link DatastreamTask} is dead.", "originalCommit": "dfd320e0c4c9363b9455ffb89fc8cc36bccdf1e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Njc1MDA1NA==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r376750054", "bodyText": "done", "author": "somandal", "createdAt": "2020-02-09T02:46:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Njc0NjkxOA=="}], "type": "inlineReview"}, {"oid": "9a2eb6607ef061746da5d3e28abdc6e2825dc730", "url": "https://github.com/linkedin/brooklin/commit/9a2eb6607ef061746da5d3e28abdc6e2825dc730", "message": "Remove stale comment", "committedDate": "2020-02-09T02:46:00Z", "type": "commit"}, {"oid": "8cd232d1ffd68b2b72e7556978b37a828260d64c", "url": "https://github.com/linkedin/brooklin/commit/8cd232d1ffd68b2b72e7556978b37a828260d64c", "message": "Address review comments", "committedDate": "2020-02-10T21:03:23Z", "type": "commit"}, {"oid": "2841cb3317d1ae6f8fc6c30228c3991786da14b7", "url": "https://github.com/linkedin/brooklin/commit/2841cb3317d1ae6f8fc6c30228c3991786da14b7", "message": "Add comment about why we check for interrupted threads on stop path", "committedDate": "2020-02-10T23:16:27Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzM4Nzk0Mw==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r377387943", "bodyText": "DatastreamTaskImpl.hashCode() and DatastreamTaskImpl.equals() considers same fields to determine the uniqueness of the key. So, in this \"put\", it will consider the new key same as existing key and will only replace the value and not update the key.", "author": "vmaheshw", "createdAt": "2020-02-10T23:59:01Z", "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaConnector.java", "diffHunk": "@@ -124,25 +122,32 @@ public AbstractKafkaConnector(String connectorName, Properties config, GroupIdCo\n   public synchronized void onAssignmentChange(List<DatastreamTask> tasks) {\n     _logger.info(\"onAssignmentChange called with tasks {}\", tasks);\n \n-    HashSet<DatastreamTask> toCancel = new HashSet<>(_runningTasks.keySet());\n-    toCancel.removeAll(tasks);\n-\n-    for (DatastreamTask task : toCancel) {\n-      AbstractKafkaBasedConnectorTask connectorTask = _runningTasks.remove(task);\n-      connectorTask.stop();\n-      _taskThreads.remove(task);\n-    }\n+    synchronized (_runningTasks) {\n+      Set<DatastreamTask> toCancel = new HashSet<>(_runningTasks.keySet());\n+      toCancel.removeAll(tasks);\n \n-    for (DatastreamTask task : tasks) {\n-      AbstractKafkaBasedConnectorTask kafkaBasedConnectorTask = _runningTasks.get(task);\n-      if (kafkaBasedConnectorTask != null) {\n-        kafkaBasedConnectorTask.checkForUpdateTask(task);\n-        // make sure to replace the DatastreamTask with most up to date info\n-        _runningTasks.put(task, kafkaBasedConnectorTask);\n-        continue; // already running\n+      for (DatastreamTask task : toCancel) {\n+        ConnectorTaskEntry connectorTaskEntry = _runningTasks.remove(task);\n+        // Stopping the connectorTask. This only marks the connector task as shutdown and does not actually wait for\n+        // the connector task to stop. onAssignmentChange() must be completed quickly, otherwise the Coordinator\n+        // kills the assignment threads.\n+        connectorTaskEntry.getConnectorTask().stop();\n       }\n \n-      createKafkaConnectorTask(task);\n+      for (DatastreamTask task : tasks) {\n+        ConnectorTaskEntry connectorTaskEntry = _runningTasks.get(task);\n+        if (connectorTaskEntry != null) {\n+          AbstractKafkaBasedConnectorTask kafkaBasedConnectorTask = connectorTaskEntry.getConnectorTask();\n+          kafkaBasedConnectorTask.checkForUpdateTask(task);\n+          // Make sure to replace the DatastreamTask with most up to date info\n+          // This is necessary because DatastreamTaskImpl.hashCode() does not take into account all the\n+          // fields/properties of the DatastreamTask (e.g. dependencies).", "originalCommit": "2841cb3317d1ae6f8fc6c30228c3991786da14b7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzQwMjgzNA==", "url": "https://github.com/linkedin/brooklin/pull/682#discussion_r377402834", "bodyText": "Great catch. So, HashMap won't effectively replace the key unless we remove the task then put it back again, right?", "author": "ahmedahamid", "createdAt": "2020-02-11T00:53:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzM4Nzk0Mw=="}], "type": "inlineReview"}]}