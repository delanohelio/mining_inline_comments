{"pr_number": 36, "pr_title": "Various op-related changes", "pr_createdAt": "2020-03-28T23:59:46Z", "pr_url": "https://github.com/tensorflow/java/pull/36", "timeline": [{"oid": "9dffbd06c7a9a352b523add2239b032deaf1ac29", "url": "https://github.com/tensorflow/java/commit/9dffbd06c7a9a352b523add2239b032deaf1ac29", "message": "Rollback operator 'val' to 'constant'", "committedDate": "2020-03-27T02:06:51Z", "type": "commit"}, {"oid": "2cdccbca0f81d1384cdf9f08534d83412f4af2d0", "url": "https://github.com/tensorflow/java/commit/2cdccbca0f81d1384cdf9f08534d83412f4af2d0", "message": "Rename 'PrimitiveOp' to 'RawOp'", "committedDate": "2020-03-28T22:00:10Z", "type": "commit"}, {"oid": "13cdae07119869df0fd77d0b91b259465ae87313", "url": "https://github.com/tensorflow/java/commit/13cdae07119869df0fd77d0b91b259465ae87313", "message": "Execute graph initializers in a single call", "committedDate": "2020-03-29T15:44:26Z", "type": "commit"}, {"oid": "13cdae07119869df0fd77d0b91b259465ae87313", "url": "https://github.com/tensorflow/java/commit/13cdae07119869df0fd77d0b91b259465ae87313", "message": "Execute graph initializers in a single call", "committedDate": "2020-03-29T15:44:26Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTgyMDU2MA==", "url": "https://github.com/tensorflow/java/pull/36#discussion_r399820560", "bodyText": "Nice!", "author": "dhruvrajan", "createdAt": "2020-03-29T16:26:39Z", "path": "tensorflow-core/tensorflow-core-api/src/main/java/org/tensorflow/Graph.java", "diffHunk": "@@ -183,17 +180,10 @@ public synchronized void addInitializer(Op initializer) {\n   }\n \n   /**\n-   * Returns an op which initializers all the variables.\n-   * @return The initializer operation.\n+   * Returns all initializers added to the graph via {@link #addInitializer(Op)}\n    */\n-  public NoOp variablesInitializer() {\n-    return variablesInitializer(DEFAULT_INIT_NAME);\n-  }\n-\n-  public NoOp variablesInitializer(String name) {\n-    Scope scope = new Scope(this);\n-    scope = scope.withName(name).withControlDependencies(initializers);\n-    return NoOp.create(scope);\n+  public List<Op> initializers() {\n+    return Collections.unmodifiableList(initializers);", "originalCommit": "13cdae07119869df0fd77d0b91b259465ae87313", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "98fb67b811249889d22d5dd47917206c0969bae5", "url": "https://github.com/tensorflow/java/commit/98fb67b811249889d22d5dd47917206c0969bae5", "message": "Add an Op as a target", "committedDate": "2020-03-29T21:08:29Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg3MDk4NA==", "url": "https://github.com/tensorflow/java/pull/36#discussion_r399870984", "bodyText": "Thanks for these changes Karl, I think these will be super helpful! Quick thought:\nSince the new Init class is a RawOp, do we gain anything by adding the runInit method, as opposed to running the RawOp in the normal fashion:\nsession.runner().addTarget(initOp).run()\n\nWe could even add additional run methods to Session that accept single Op/Operand/etc. arguments, and have them automatically added as targets, to achieve syntax like\nsession.run(initOp)\nTensorFlow Python (pre 2.0) has a standard syntax for the variable initializers (for both global and local variables)\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n \n    ...\n\nMaybe we could modify the Java API to match? It may not yet be on our roadmap to distinguish between global (shared across processes) variables and local (per-process) variables, but we could perhaps try for something like:\ntry (Graph graph = new Graph()) {\n  Ops tf = Ops.create(graph);\n\n  ...\n\n  try (Session session = new Session(graph)) {\n    session.addTarget(tf.variablesInitializer()).run(); // or session.run(tf.variablesInitializer)\n\n    ...\n\n  }\n}\n\ntf.variablesInitializer() can call Graph.initializers() that you added below. To make it even simpler, we could automatically add the Assign op to a graph when tf.variable is called with an initial value, so users don't need to keep track of adding each initialization to the initializers list.\nThe global vs. local variable distinction may be something we want to add later on though...\nWhat do you think?", "author": "dhruvrajan", "createdAt": "2020-03-29T23:37:17Z", "path": "tensorflow-core/tensorflow-core-api/src/main/java/org/tensorflow/Session.java", "diffHunk": "@@ -432,6 +434,106 @@ public Runner runner() {\n     return new Runner();\n   }\n \n+  /**\n+   * Run all graph initializers.\n+   *\n+   * <p>Initializers must be executed once before running the graph in a training\n+   * loop using a session {@link Runner}.</p>\n+   *\n+   * <p>This method invokes {@link #runInit(String)} using the default name for the init\n+   * operation, which is {@link Init#DEFAULT_NAME}. For example:</p>\n+   * <pre>{@code\n+   * try (Graph g = new Graph()) {\n+   *   Ops tf = Ops.create(g);\n+   *\n+   *   Variable<TInt32> x = tf.variable(tf.constant(10));\n+   *   Variable<TInt32> y = tf.variable(tf.constant(20));\n+   *   Add<TInt32> z = tf.math.add(x, y);\n+   *   tf.init();\n+   *\n+   *   try (Session s = new Session(g)) {\n+   *     s.runInit();\n+   *\n+   *     try (Tensor<TInt32> t = s.runner().fetch(z).run().get(0).expect(TInt32.DTYPE)) {\n+   *       assertEquals(30, t.data().getInt());\n+   *     }\n+   *   }\n+   * }\n+   * }</pre>\n+   */\n+  public void runInit() {\n+    runInit(Init.DEFAULT_NAME);\n+  }\n+\n+  /**\n+   * Run all graph initializers grouped under the {@code initOpName} operation.\n+   *\n+   * <p>Initializers must be executed once before running the graph in a training loop using a\n+   * session {@link Runner}.</p>\n+   *\n+   * <p>The {@code initOpName} is the name of a single operation already added to the\n+   * graph that executes all graph initializers at once. For example:</p>\n+   * <pre>{@code\n+   * try (Graph g = new Graph()) {\n+   *   Ops tf = Ops.create(g);\n+   *\n+   *   Variable<TInt32> x = tf.variable(tf.constant(10));\n+   *   Variable<TInt32> y = tf.variable(tf.constant(20));\n+   *   Add<TInt32> z = tf.math.add(x, y);\n+   *   tf.withName(\"initialize\").init();\n+   *\n+   *   try (Session s = new Session(g)) {\n+   *     s.runInit(\"initialize\");\n+   *\n+   *     try (Tensor<TInt32> t = s.runner().fetch(z).run().get(0).expect(TInt32.DTYPE)) {\n+   *       assertEquals(30, t.data().getInt());\n+   *     }\n+   *   }\n+   * }\n+   * }</pre>\n+   *\n+   * @param initOpName name of the initializer operation.\n+   */\n+  public void runInit(String initOpName) {\n+    Operation operation = graph.operation(initOpName);\n+    if (operation == null) {\n+      throw new IllegalArgumentException(\"Initializer operation named '\"\n+          + initOpName + \"' cannot be found in the graph\");\n+    }\n+    runner().addTarget(operation).run();\n+  }\n+\n+  /**\n+   * Run all graph initializers registered by the given {@code init} op.\n+   *\n+   * <p>Initializers must be executed once before running the graph in a training\n+   * loop using a session {@link Runner}.</p>\n+   *\n+   * <p>This method can be used if the graph is being built by the same program running the session.\n+   * For example:</p>\n+   * <pre>{@code\n+   * try (Graph g = new Graph()) {\n+   *   Ops tf = Ops.create(g);\n+   *\n+   *   Variable<TInt32> x = tf.variable(tf.constant(10));\n+   *   Variable<TInt32> y = tf.variable(tf.constant(20));\n+   *   Add<TInt32> z = tf.math.add(x, y);\n+   *   Init init = tf.withName(\"initialize\").init();\n+   *\n+   *   try (Session s = new Session(g)) {\n+   *     s.runInit(init);\n+   *\n+   *     try (Tensor<TInt32> t = s.runner().fetch(z).run().get(0).expect(TInt32.DTYPE)) {\n+   *       assertEquals(30, t.data().getInt());\n+   *     }\n+   *   }\n+   * }\n+   * }</pre>\n+   */\n+  public void runInit(Init initOp) {", "originalCommit": "13cdae07119869df0fd77d0b91b259465ae87313", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDU1NzQ5MA==", "url": "https://github.com/tensorflow/java/pull/36#discussion_r400557490", "bodyText": "Thanks @dhruvrajan ,\n\nWe could even add additional run methods to Session that accept single Op/Operand/etc. arguments\n\nYes, I thought of having a session.run(Op) as well, I thought that by typing it we kind of \"guide\" the user to use it only for running initializers but I agree we can relax this a bit.\n\ntf.variablesInitializer() can call Graph.initializers() that you added below.\n\nThe tf.variableInitializers() sounds pretty much like the tf.init(), no? But the problem that arise and that @Craigacp mentioned to me before is when you load a graph from disk, your graph won't have any initializers so you can't build that op at runtime, you need to find it in the graph.\nThat is why the tf.init() is always called before running the session. It's kind of annoying, I agree, to always remember calling this method before freezing the graph, I don't know how we can make it more obvious... I can also revert to what Adam did before, where we could retrieve the init op from the Graph instead of Ops (i.e. we would do something like session.run(graph.variableInitializers())). At least that simple run method would be a simple improvement.\n\nTo make it even simpler, we could automatically add the Assign op to a graph when tf.variable\n\nThis is already supported! Check here", "author": "karllessard", "createdAt": "2020-03-30T23:37:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg3MDk4NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTE2NTEyOA==", "url": "https://github.com/tensorflow/java/pull/36#discussion_r401165128", "bodyText": "This is already supported! Check here\n\nAh thanks for pointing that out, awesome!\n\nwhen you load a graph from disk, your graph won't have any initializers so you can't build that op at runtime, you need to find it in the graph.\n\nHmm this is interesting! If you load a graph from disk, why won't the graph have any initializers? (It may have init ops in the graph, I guess, but they wouldn't be mapped to the initializers list we maintain in Java?). In this case, could we just create an Init Op that does nothing?\n\nThat is why the tf.init() is always called before running the session.\n\nTo clarify, must the Init op be created before a session is created, or just run before the first session.run? If it is the latter, we can have:\ntry (Session session = new Session(graph)) {\n  session.run(tf.init()); // maybe rename to variablesInitializer() for consistency?\n}\n\nBrainstorming other ways to keep the syntax consistent with Python, I had a couple ideas, eager to know your thoughts @karllessard:\n\nIf it really needs to go before Session.create, add the Init creation (tf.init()) call as the first step of Session.create() or a tf.session() factory method.\n\nI can't think of a case where we would not want this Op to be added to the graph; this could also eliminate the need for the user to call tf.init()?\n\nAs in TensorFlow Python keep track of individual variable initial_values and initializer ops as fields within the Variable class.\n\nThus instead of keeping track of a list of initializer ops on the graph, we only keep track of variables. We can extract the initializers by mapping over the variables. (See: global_variables, global_variables_initializer)\nThen we get syntax and functionality super close to standard TF (I think, quite desirable)\ntry (Session session = tf.session()) { // automatically runs tf.init()\n    session.run(tf.variablesInitializer());\n}\n\nThanks for the detailed discussion! \ud83d\ude03", "author": "dhruvrajan", "createdAt": "2020-03-31T19:36:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg3MDk4NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTIyNDQwMQ==", "url": "https://github.com/tensorflow/java/pull/36#discussion_r401224401", "bodyText": "The loaded graph does have initializers but the Java code doesn't know about them. We could consider crawling the graph and giving initializers a privileged name to rebuild it, but we'd need to sync this up with everything in the tf ecosystem which emits GraphDef, as otherwise it have unintended consequences when loading graphs created by other language TF implementations.\nThe Python global_variables_initializer needs to be created in the same way that tf.init does at the moment, what's in this PR is pretty close to how TF 1 in python does it.", "author": "Craigacp", "createdAt": "2020-03-31T21:24:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg3MDk4NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTg5NzQ4OA==", "url": "https://github.com/tensorflow/java/pull/36#discussion_r401897488", "bodyText": "My concern of naming it variableInitializers instead of just init is that I think there might be other op that must be called prior to run a session that variable assign.\nFor instance, in this old example I had to run the createSummaryFileWriter as well.\nSo maybe that name is not \"right\" in Python as well but they kept if for backward compatibility. Or the have more than one op ran before a session starts.\nNow for calling tf.init() implicitly at session creation or explicitly... I don't have the answer right now, to be honest, it is a tough call that requires more thinking. If @Craigacp says right that the actual behaviour mimics what is done in Python, then I would be comfortable to merge it as is and maybe find other ways to improve it later?", "author": "karllessard", "createdAt": "2020-04-01T20:43:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg3MDk4NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAzMjc2Mg==", "url": "https://github.com/tensorflow/java/pull/36#discussion_r402032762", "bodyText": "Yup I agree; good idea to merge this, and update things reactively in the future.\nFor now, then, the two main things I see that will be different between the current implementation and the Python implementation are:\n\n\nIn Java, we must call tf.init() before creating a session; in Python, the equivalent function can be called after a session is created.\n\n\nIn Java, we explicitly keep track of initializers within the Graph object. In Python, initializers are held by Variable objects, and retrieved when needed.\n\n\nLet's just keep these differences in mind and see if anything related comes up in the future!", "author": "dhruvrajan", "createdAt": "2020-04-02T03:32:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg3MDk4NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjI5MDU0Mg==", "url": "https://github.com/tensorflow/java/pull/36#discussion_r402290542", "bodyText": "Thinking of it, for point 1., I\u2019m gonna test again, maybe it\u2019s ok to add an op to a graph after a session is created, so you can simply call session.run(tf.init()) if the graph is built in the same process as the session runner.", "author": "karllessard", "createdAt": "2020-04-02T12:55:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg3MDk4NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjcwMjc3Mg==", "url": "https://github.com/tensorflow/java/pull/36#discussion_r402702772", "bodyText": "Yep, looks like this works too!", "author": "karllessard", "createdAt": "2020-04-03T02:32:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg3MDk4NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk2ODgyMw==", "url": "https://github.com/tensorflow/java/pull/36#discussion_r400968823", "bodyText": "Can we check the type of the operation too? If the user creates something that doesn't use the init mechanism but does have the name it might be nice to have some kind of warning.", "author": "Craigacp", "createdAt": "2020-03-31T14:41:25Z", "path": "tensorflow-core/tensorflow-core-api/src/main/java/org/tensorflow/Session.java", "diffHunk": "@@ -432,6 +434,106 @@ public Runner runner() {\n     return new Runner();\n   }\n \n+  /**\n+   * Run all graph initializers.\n+   *\n+   * <p>Initializers must be executed once before running the graph in a training\n+   * loop using a session {@link Runner}.</p>\n+   *\n+   * <p>This method invokes {@link #runInit(String)} using the default name for the init\n+   * operation, which is {@link Init#DEFAULT_NAME}. For example:</p>\n+   * <pre>{@code\n+   * try (Graph g = new Graph()) {\n+   *   Ops tf = Ops.create(g);\n+   *\n+   *   Variable<TInt32> x = tf.variable(tf.constant(10));\n+   *   Variable<TInt32> y = tf.variable(tf.constant(20));\n+   *   Add<TInt32> z = tf.math.add(x, y);\n+   *   tf.init();\n+   *\n+   *   try (Session s = new Session(g)) {\n+   *     s.runInit();\n+   *\n+   *     try (Tensor<TInt32> t = s.runner().fetch(z).run().get(0).expect(TInt32.DTYPE)) {\n+   *       assertEquals(30, t.data().getInt());\n+   *     }\n+   *   }\n+   * }\n+   * }</pre>\n+   */\n+  public void runInit() {\n+    runInit(Init.DEFAULT_NAME);\n+  }\n+\n+  /**\n+   * Run all graph initializers grouped under the {@code initOpName} operation.\n+   *\n+   * <p>Initializers must be executed once before running the graph in a training loop using a\n+   * session {@link Runner}.</p>\n+   *\n+   * <p>The {@code initOpName} is the name of a single operation already added to the\n+   * graph that executes all graph initializers at once. For example:</p>\n+   * <pre>{@code\n+   * try (Graph g = new Graph()) {\n+   *   Ops tf = Ops.create(g);\n+   *\n+   *   Variable<TInt32> x = tf.variable(tf.constant(10));\n+   *   Variable<TInt32> y = tf.variable(tf.constant(20));\n+   *   Add<TInt32> z = tf.math.add(x, y);\n+   *   tf.withName(\"initialize\").init();\n+   *\n+   *   try (Session s = new Session(g)) {\n+   *     s.runInit(\"initialize\");\n+   *\n+   *     try (Tensor<TInt32> t = s.runner().fetch(z).run().get(0).expect(TInt32.DTYPE)) {\n+   *       assertEquals(30, t.data().getInt());\n+   *     }\n+   *   }\n+   * }\n+   * }</pre>\n+   *\n+   * @param initOpName name of the initializer operation.\n+   */\n+  public void runInit(String initOpName) {\n+    Operation operation = graph.operation(initOpName);\n+    if (operation == null) {", "originalCommit": "13cdae07119869df0fd77d0b91b259465ae87313", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk3MDQ4MA==", "url": "https://github.com/tensorflow/java/pull/36#discussion_r400970480", "bodyText": "That said, it might be an interop issue with graphs created in other TF languages if it warns every time you run a graph created in Python.", "author": "Craigacp", "createdAt": "2020-03-31T14:43:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk2ODgyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTg5ODM1OQ==", "url": "https://github.com/tensorflow/java/pull/36#discussion_r401898359", "bodyText": "@dhruvrajan suggestion is to relax a bit the constraint here and to rename runInit to run, which accepts any type of operation. I'm ok with this too, what do you think?", "author": "karllessard", "createdAt": "2020-04-01T20:45:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk2ODgyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjQ1MjkzNw==", "url": "https://github.com/tensorflow/java/pull/36#discussion_r402452937", "bodyText": "Fine by me. It's essentially just addTarget(String).run() then though?", "author": "Craigacp", "createdAt": "2020-04-02T16:37:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk2ODgyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjYwNjI0MA==", "url": "https://github.com/tensorflow/java/pull/36#discussion_r402606240", "bodyText": "a short cut to session.runner().addTarget(name).run(), yes.", "author": "karllessard", "createdAt": "2020-04-02T21:27:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk2ODgyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzAzNjAxMg==", "url": "https://github.com/tensorflow/java/pull/36#discussion_r403036012", "bodyText": "Given this exists, should we add a convenience method for session.runner().fetch(name).run()? Also the exception still mentions an initializer operation, but this isn't required anymore.", "author": "Craigacp", "createdAt": "2020-04-03T14:14:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk2ODgyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzEzNDI2Ng==", "url": "https://github.com/tensorflow/java/pull/36#discussion_r403134266", "bodyText": "I guess we could. But fetching is more tricky because you need to make sure to release the returned tensor, a behaviour I would like us to review as a whole at some point, wdyt?\nIf you are ok with this, then I'll update the exception message (thanks for catching this) and merge this PR now.", "author": "karllessard", "createdAt": "2020-04-03T16:38:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk2ODgyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzI0MzMwMQ==", "url": "https://github.com/tensorflow/java/pull/36#discussion_r403243301", "bodyText": "I agree it's more complex, but it seems weird to me to have one without the other. Either way we can deal with it later.", "author": "Craigacp", "createdAt": "2020-04-03T18:53:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDk2ODgyMw=="}], "type": "inlineReview"}, {"oid": "0f48e827e03bbd04bbd3b365c44906b94eee6c2c", "url": "https://github.com/tensorflow/java/commit/0f48e827e03bbd04bbd3b365c44906b94eee6c2c", "message": "Run any single op from session", "committedDate": "2020-04-03T03:58:20Z", "type": "commit"}, {"oid": "8be3139d9138b7e484bf4e536ddee5f00dbb9fa9", "url": "https://github.com/tensorflow/java/commit/8be3139d9138b7e484bf4e536ddee5f00dbb9fa9", "message": "Remove traces", "committedDate": "2020-04-03T03:58:39Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzA4Mzc2Ng==", "url": "https://github.com/tensorflow/java/pull/36#discussion_r403083766", "bodyText": "This looks awesome!", "author": "dhruvrajan", "createdAt": "2020-04-03T15:24:13Z", "path": "tensorflow-core/tensorflow-core-api/src/test/java/org/tensorflow/SessionTest.java", "diffHunk": "@@ -173,31 +172,9 @@ public void runInit() {\n       tf.initAdd(tf.assign(var1, tf.constant(10)));\n       Variable<TInt32> var2 = tf.variable(tf.constant(20));\n       Add<TInt32> add = tf.math.add(var1, var2);\n-      tf.init();\n \n       try (Session s = new Session(g)) {\n-        s.runInit();\n-\n-        try (Tensor<TInt32> t = s.runner().fetch(add).run().get(0).expect(TInt32.DTYPE)) {\n-          assertEquals(30, t.data().getInt());\n-        }\n-      }\n-    }\n-  }\n-\n-  @Test\n-  public void runInitByVar() {\n-    try (Graph g = new Graph()) {\n-      Ops tf = Ops.create(g);\n-\n-      Variable<TInt32> var1 = tf.variable(Shape.scalar(), TInt32.DTYPE);\n-      tf.initAdd(tf.assign(var1, tf.constant(10)));\n-      Variable<TInt32> var2 = tf.variable(tf.constant(20));\n-      Add<TInt32> add = tf.math.add(var1, var2);\n-      Init init = tf.withName(\"initialize\").init();\n-\n-      try (Session s = new Session(g)) {\n-        s.runInit(init);\n+        s.run(tf.init());", "originalCommit": "0f48e827e03bbd04bbd3b365c44906b94eee6c2c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "27e27f0ee77a8f38b0c0cbd70db98e7165311c90", "url": "https://github.com/tensorflow/java/commit/27e27f0ee77a8f38b0c0cbd70db98e7165311c90", "message": "Update exception message", "committedDate": "2020-04-03T16:40:17Z", "type": "commit"}]}