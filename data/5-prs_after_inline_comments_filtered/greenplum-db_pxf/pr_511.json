{"pr_number": 511, "pr_title": "pxf-hive: properly escape strings in complex data types", "pr_createdAt": "2020-12-03T23:02:55Z", "pr_url": "https://github.com/greenplum-db/pxf/pull/511", "timeline": [{"oid": "d17b1e4ece7d579ac7cb9557beeff6e208c389f8", "url": "https://github.com/greenplum-db/pxf/commit/d17b1e4ece7d579ac7cb9557beeff6e208c389f8", "message": "pxf-hive: properly escape strings in complext data types\n\nCo-authored-by: Bradford D. Boyle <bradfordb@vmware.com>\nCo-authored-by: Ashuka Xue <axue@vmware.com>", "committedDate": "2020-12-07T22:04:07Z", "type": "forcePushed"}, {"oid": "b0b86c3b40798334cd3a6fc4afabddba4356840a", "url": "https://github.com/greenplum-db/pxf/commit/b0b86c3b40798334cd3a6fc4afabddba4356840a", "message": "pxf-hive: add unit tests for HiveResolver\n\nCo-authored-by: Bradford D. Boyle <bradfordb@vmware.com>\nCo-authored-by: Ashuka Xue <axue@vmware.com>", "committedDate": "2020-12-18T00:40:41Z", "type": "forcePushed"}, {"oid": "d7267b6436f6c6f95222438f6eba35f72b21bb6d", "url": "https://github.com/greenplum-db/pxf/commit/d7267b6436f6c6f95222438f6eba35f72b21bb6d", "message": "pxf-hive: properly escape strings in complex data types\n\nCo-authored-by: Bradford D. Boyle <bradfordb@vmware.com>\nCo-authored-by: Ashuka Xue <axue@vmware.com>", "committedDate": "2020-12-18T00:42:16Z", "type": "commit"}, {"oid": "50dbf772c3b9c1f0783651af60c11b95a17235f5", "url": "https://github.com/greenplum-db/pxf/commit/50dbf772c3b9c1f0783651af60c11b95a17235f5", "message": "pxf-hive: add unit tests for HiveResolver\n\nCo-authored-by: Bradford D. Boyle <bradfordb@vmware.com>\nCo-authored-by: Ashuka Xue <axue@vmware.com>", "committedDate": "2020-12-18T00:42:26Z", "type": "commit"}, {"oid": "50dbf772c3b9c1f0783651af60c11b95a17235f5", "url": "https://github.com/greenplum-db/pxf/commit/50dbf772c3b9c1f0783651af60c11b95a17235f5", "message": "pxf-hive: add unit tests for HiveResolver\n\nCo-authored-by: Bradford D. Boyle <bradfordb@vmware.com>\nCo-authored-by: Ashuka Xue <axue@vmware.com>", "committedDate": "2020-12-18T00:42:26Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyMTIzNA==", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r545521234", "bodyText": "so what will happen when val is null and toFlatten == true ? It will NPE on val.toString(). What should be the expected result ? We also need a unit test for this.", "author": "denalex", "createdAt": "2020-12-18T01:51:20Z", "path": "server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java", "diffHunk": "@@ -611,8 +612,8 @@ private void resolvePrimitive(Object o, PrimitiveObjectInspector oi,\n             case STRING: {\n                 val = (o != null) ? ((StringObjectInspector) oi).getPrimitiveJavaObject(o)\n                         : null;\n-                addOneFieldToRecord(record, DataType.TEXT,\n-                        toFlatten ? String.format(\"\\\"%s\\\"\", val) : val);\n+                val = toFlatten ? String.format(\"\\\"%s\\\"\", StringEscapeUtils.escapeJava(val.toString())) : val;", "originalCommit": "50dbf772c3b9c1f0783651af60c11b95a17235f5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTYyMDQxOA==", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r551620418", "bodyText": "We added an additional conditional as well as an automation test for the null case.", "author": "ashuka24", "createdAt": "2021-01-04T23:04:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyMTIzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyMTQyMQ==", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r545521421", "bodyText": "so \\u0002 is a separator of data within the struct value ?", "author": "denalex", "createdAt": "2020-12-18T01:52:04Z", "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "diffHunk": "@@ -0,0 +1,165 @@\n+package org.greenplum.pxf.plugins.hive;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.io.ArrayWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.io.Writable;\n+import org.greenplum.pxf.api.io.DataType;\n+import org.greenplum.pxf.api.model.RequestContext;\n+import org.greenplum.pxf.api.OneField;\n+import org.greenplum.pxf.api.OneRow;\n+import org.greenplum.pxf.api.utilities.ColumnDescriptor;\n+import org.greenplum.pxf.plugins.hive.utilities.HiveUtilities;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.core.Is.is;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class HiveResolverTest {\n+\n+    @Mock\n+    HiveUtilities mockHiveUtilities;\n+\n+    private static final String SERDE_CLASS_NAME = \"org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe\";\n+    private static final String COL_NAMES_SIMPLE = \"name,amt\";\n+    private static final String COL_TYPES_SIMPLE = \"string:double\";\n+\n+    private static final String SERDE_CLASS_NAME_STRUCT = \"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\";\n+    private static final String COL_NAMES_STRUCT = \"address\";\n+    private static final String COL_TYPES_STRUCT = \"struct<street:string,zipcode:bigint>\";\n+    private static final String COL_NAMES_NESTED_STRUCT = \"address\";\n+    private static final String COL_TYPES_NESTED_STRUCT = \"struct<line1:struct<number:bigint,street_name:string>,line2:struct<city:string,zipcode:bigint>>\";\n+    Configuration configuration;\n+    Properties properties;\n+    List<ColumnDescriptor> columnDescriptors;\n+    private HiveResolver resolver;\n+    RequestContext context;\n+    List<Integer> hiveIndexes;\n+\n+    @BeforeEach\n+    public void setup() {\n+        properties = new Properties();\n+        configuration = new Configuration();\n+        columnDescriptors = new ArrayList<>();\n+        context = new RequestContext();\n+        // metadata usually set in accessor\n+        hiveIndexes = Arrays.asList(0, 1);\n+    }\n+\n+    @Test\n+    public void testSimpleString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"plain string\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"plain string\\u00011000\"));\n+    }\n+\n+    @Test\n+    public void testSpecialCharString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"a really \\\"fancy\\\" string? *wink*\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"a really \\\"fancy\\\" string? *wink*\\u00011000\"));\n+    }\n+\n+    @Test\n+    public void testStructSimpleString() throws Exception {\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_STRUCT);\n+        columnDescriptors.add(new ColumnDescriptor(\"address\", DataType.TEXT.getOID(), 3, \"struct\", null));\n+\n+        OneRow row = new OneRow(0, new Text(\"plain string\\u00021001\"));", "originalCommit": "50dbf772c3b9c1f0783651af60c11b95a17235f5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTYyMTI2NQ==", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r551621265", "bodyText": "Yes, I found this value by debugging a live session containing a nested struct. Further nesting would result in larger numbers, ex: \\u0003 signifies a separation of data nested further down the struct.", "author": "ashuka24", "createdAt": "2021-01-04T23:06:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyMTQyMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyMTU5Mg==", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r545521592", "bodyText": "Why do we need to escape the string using java rules? can we add a comment why we are doing this?", "author": "frankgh", "createdAt": "2020-12-18T01:52:38Z", "path": "server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java", "diffHunk": "@@ -611,8 +612,8 @@ private void resolvePrimitive(Object o, PrimitiveObjectInspector oi,\n             case STRING: {\n                 val = (o != null) ? ((StringObjectInspector) oi).getPrimitiveJavaObject(o)\n                         : null;\n-                addOneFieldToRecord(record, DataType.TEXT,\n-                        toFlatten ? String.format(\"\\\"%s\\\"\", val) : val);\n+                val = toFlatten ? String.format(\"\\\"%s\\\"\", StringEscapeUtils.escapeJava(val.toString())) : val;", "originalCommit": "50dbf772c3b9c1f0783651af60c11b95a17235f5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyMjEzMQ==", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r545522131", "bodyText": "\ud83d\udc4d  +1 for adding this class", "author": "frankgh", "createdAt": "2020-12-18T01:54:31Z", "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "diffHunk": "@@ -0,0 +1,165 @@\n+package org.greenplum.pxf.plugins.hive;", "originalCommit": "50dbf772c3b9c1f0783651af60c11b95a17235f5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyMzMwNw==", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r545523307", "bodyText": "i don't think it matters , but just to make it accurate, can we change the indexes here:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n          \n          \n            \n                    columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n          \n          \n            \n                    columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 0, \"text\", null));\n          \n          \n            \n                    columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 1, \"float8\", null));", "author": "frankgh", "createdAt": "2020-12-18T01:58:23Z", "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "diffHunk": "@@ -0,0 +1,165 @@\n+package org.greenplum.pxf.plugins.hive;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.io.ArrayWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.io.Writable;\n+import org.greenplum.pxf.api.io.DataType;\n+import org.greenplum.pxf.api.model.RequestContext;\n+import org.greenplum.pxf.api.OneField;\n+import org.greenplum.pxf.api.OneRow;\n+import org.greenplum.pxf.api.utilities.ColumnDescriptor;\n+import org.greenplum.pxf.plugins.hive.utilities.HiveUtilities;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.core.Is.is;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class HiveResolverTest {\n+\n+    @Mock\n+    HiveUtilities mockHiveUtilities;\n+\n+    private static final String SERDE_CLASS_NAME = \"org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe\";\n+    private static final String COL_NAMES_SIMPLE = \"name,amt\";\n+    private static final String COL_TYPES_SIMPLE = \"string:double\";\n+\n+    private static final String SERDE_CLASS_NAME_STRUCT = \"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\";\n+    private static final String COL_NAMES_STRUCT = \"address\";\n+    private static final String COL_TYPES_STRUCT = \"struct<street:string,zipcode:bigint>\";\n+    private static final String COL_NAMES_NESTED_STRUCT = \"address\";\n+    private static final String COL_TYPES_NESTED_STRUCT = \"struct<line1:struct<number:bigint,street_name:string>,line2:struct<city:string,zipcode:bigint>>\";\n+    Configuration configuration;\n+    Properties properties;\n+    List<ColumnDescriptor> columnDescriptors;\n+    private HiveResolver resolver;\n+    RequestContext context;\n+    List<Integer> hiveIndexes;\n+\n+    @BeforeEach\n+    public void setup() {\n+        properties = new Properties();\n+        configuration = new Configuration();\n+        columnDescriptors = new ArrayList<>();\n+        context = new RequestContext();\n+        // metadata usually set in accessor\n+        hiveIndexes = Arrays.asList(0, 1);\n+    }\n+\n+    @Test\n+    public void testSimpleString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));", "originalCommit": "50dbf772c3b9c1f0783651af60c11b95a17235f5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyMzYzMg==", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r545523632", "bodyText": "can we remove the comment?\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n          \n          \n            \n                    context.setMetadata(new HiveMetadata(properties, null, hiveIndexes));", "author": "frankgh", "createdAt": "2020-12-18T01:59:31Z", "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "diffHunk": "@@ -0,0 +1,165 @@\n+package org.greenplum.pxf.plugins.hive;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.io.ArrayWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.io.Writable;\n+import org.greenplum.pxf.api.io.DataType;\n+import org.greenplum.pxf.api.model.RequestContext;\n+import org.greenplum.pxf.api.OneField;\n+import org.greenplum.pxf.api.OneRow;\n+import org.greenplum.pxf.api.utilities.ColumnDescriptor;\n+import org.greenplum.pxf.plugins.hive.utilities.HiveUtilities;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.core.Is.is;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class HiveResolverTest {\n+\n+    @Mock\n+    HiveUtilities mockHiveUtilities;\n+\n+    private static final String SERDE_CLASS_NAME = \"org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe\";\n+    private static final String COL_NAMES_SIMPLE = \"name,amt\";\n+    private static final String COL_TYPES_SIMPLE = \"string:double\";\n+\n+    private static final String SERDE_CLASS_NAME_STRUCT = \"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\";\n+    private static final String COL_NAMES_STRUCT = \"address\";\n+    private static final String COL_TYPES_STRUCT = \"struct<street:string,zipcode:bigint>\";\n+    private static final String COL_NAMES_NESTED_STRUCT = \"address\";\n+    private static final String COL_TYPES_NESTED_STRUCT = \"struct<line1:struct<number:bigint,street_name:string>,line2:struct<city:string,zipcode:bigint>>\";\n+    Configuration configuration;\n+    Properties properties;\n+    List<ColumnDescriptor> columnDescriptors;\n+    private HiveResolver resolver;\n+    RequestContext context;\n+    List<Integer> hiveIndexes;\n+\n+    @BeforeEach\n+    public void setup() {\n+        properties = new Properties();\n+        configuration = new Configuration();\n+        columnDescriptors = new ArrayList<>();\n+        context = new RequestContext();\n+        // metadata usually set in accessor\n+        hiveIndexes = Arrays.asList(0, 1);\n+    }\n+\n+    @Test\n+    public void testSimpleString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"plain string\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));", "originalCommit": "50dbf772c3b9c1f0783651af60c11b95a17235f5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTYxNjIzMw==", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r551616233", "bodyText": "I have the comment there for clarity. It is mostly to show that HiveMetadata requires a list of HivePartitions, but for these test cases this list is not necessary.", "author": "ashuka24", "createdAt": "2021-01-04T22:52:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyMzYzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyMzkxNQ==", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r545523915", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    assertThat(output.get(0).toString(), is(\"plain string\\u00011000\"));\n          \n          \n            \n                    assertThat(output.get(0).toString()).isEqualTo(\"plain string\\u00011000\"));", "author": "frankgh", "createdAt": "2020-12-18T02:00:26Z", "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "diffHunk": "@@ -0,0 +1,165 @@\n+package org.greenplum.pxf.plugins.hive;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.io.ArrayWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.io.Writable;\n+import org.greenplum.pxf.api.io.DataType;\n+import org.greenplum.pxf.api.model.RequestContext;\n+import org.greenplum.pxf.api.OneField;\n+import org.greenplum.pxf.api.OneRow;\n+import org.greenplum.pxf.api.utilities.ColumnDescriptor;\n+import org.greenplum.pxf.plugins.hive.utilities.HiveUtilities;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.core.Is.is;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class HiveResolverTest {\n+\n+    @Mock\n+    HiveUtilities mockHiveUtilities;\n+\n+    private static final String SERDE_CLASS_NAME = \"org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe\";\n+    private static final String COL_NAMES_SIMPLE = \"name,amt\";\n+    private static final String COL_TYPES_SIMPLE = \"string:double\";\n+\n+    private static final String SERDE_CLASS_NAME_STRUCT = \"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\";\n+    private static final String COL_NAMES_STRUCT = \"address\";\n+    private static final String COL_TYPES_STRUCT = \"struct<street:string,zipcode:bigint>\";\n+    private static final String COL_NAMES_NESTED_STRUCT = \"address\";\n+    private static final String COL_TYPES_NESTED_STRUCT = \"struct<line1:struct<number:bigint,street_name:string>,line2:struct<city:string,zipcode:bigint>>\";\n+    Configuration configuration;\n+    Properties properties;\n+    List<ColumnDescriptor> columnDescriptors;\n+    private HiveResolver resolver;\n+    RequestContext context;\n+    List<Integer> hiveIndexes;\n+\n+    @BeforeEach\n+    public void setup() {\n+        properties = new Properties();\n+        configuration = new Configuration();\n+        columnDescriptors = new ArrayList<>();\n+        context = new RequestContext();\n+        // metadata usually set in accessor\n+        hiveIndexes = Arrays.asList(0, 1);\n+    }\n+\n+    @Test\n+    public void testSimpleString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"plain string\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"plain string\\u00011000\"));", "originalCommit": "50dbf772c3b9c1f0783651af60c11b95a17235f5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyNDE0MQ==", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r545524141", "bodyText": "aren't we expecting two OneFields since we have two columns?", "author": "frankgh", "createdAt": "2020-12-18T02:01:21Z", "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "diffHunk": "@@ -0,0 +1,165 @@\n+package org.greenplum.pxf.plugins.hive;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.io.ArrayWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.io.Writable;\n+import org.greenplum.pxf.api.io.DataType;\n+import org.greenplum.pxf.api.model.RequestContext;\n+import org.greenplum.pxf.api.OneField;\n+import org.greenplum.pxf.api.OneRow;\n+import org.greenplum.pxf.api.utilities.ColumnDescriptor;\n+import org.greenplum.pxf.plugins.hive.utilities.HiveUtilities;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.core.Is.is;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class HiveResolverTest {\n+\n+    @Mock\n+    HiveUtilities mockHiveUtilities;\n+\n+    private static final String SERDE_CLASS_NAME = \"org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe\";\n+    private static final String COL_NAMES_SIMPLE = \"name,amt\";\n+    private static final String COL_TYPES_SIMPLE = \"string:double\";\n+\n+    private static final String SERDE_CLASS_NAME_STRUCT = \"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\";\n+    private static final String COL_NAMES_STRUCT = \"address\";\n+    private static final String COL_TYPES_STRUCT = \"struct<street:string,zipcode:bigint>\";\n+    private static final String COL_NAMES_NESTED_STRUCT = \"address\";\n+    private static final String COL_TYPES_NESTED_STRUCT = \"struct<line1:struct<number:bigint,street_name:string>,line2:struct<city:string,zipcode:bigint>>\";\n+    Configuration configuration;\n+    Properties properties;\n+    List<ColumnDescriptor> columnDescriptors;\n+    private HiveResolver resolver;\n+    RequestContext context;\n+    List<Integer> hiveIndexes;\n+\n+    @BeforeEach\n+    public void setup() {\n+        properties = new Properties();\n+        configuration = new Configuration();\n+        columnDescriptors = new ArrayList<>();\n+        context = new RequestContext();\n+        // metadata usually set in accessor\n+        hiveIndexes = Arrays.asList(0, 1);\n+    }\n+\n+    @Test\n+    public void testSimpleString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"plain string\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);", "originalCommit": "50dbf772c3b9c1f0783651af60c11b95a17235f5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyNDQxMA==", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r545524410", "bodyText": "same comment as above?", "author": "frankgh", "createdAt": "2020-12-18T02:02:17Z", "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "diffHunk": "@@ -0,0 +1,165 @@\n+package org.greenplum.pxf.plugins.hive;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.io.ArrayWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.io.Writable;\n+import org.greenplum.pxf.api.io.DataType;\n+import org.greenplum.pxf.api.model.RequestContext;\n+import org.greenplum.pxf.api.OneField;\n+import org.greenplum.pxf.api.OneRow;\n+import org.greenplum.pxf.api.utilities.ColumnDescriptor;\n+import org.greenplum.pxf.plugins.hive.utilities.HiveUtilities;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.core.Is.is;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class HiveResolverTest {\n+\n+    @Mock\n+    HiveUtilities mockHiveUtilities;\n+\n+    private static final String SERDE_CLASS_NAME = \"org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe\";\n+    private static final String COL_NAMES_SIMPLE = \"name,amt\";\n+    private static final String COL_TYPES_SIMPLE = \"string:double\";\n+\n+    private static final String SERDE_CLASS_NAME_STRUCT = \"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\";\n+    private static final String COL_NAMES_STRUCT = \"address\";\n+    private static final String COL_TYPES_STRUCT = \"struct<street:string,zipcode:bigint>\";\n+    private static final String COL_NAMES_NESTED_STRUCT = \"address\";\n+    private static final String COL_TYPES_NESTED_STRUCT = \"struct<line1:struct<number:bigint,street_name:string>,line2:struct<city:string,zipcode:bigint>>\";\n+    Configuration configuration;\n+    Properties properties;\n+    List<ColumnDescriptor> columnDescriptors;\n+    private HiveResolver resolver;\n+    RequestContext context;\n+    List<Integer> hiveIndexes;\n+\n+    @BeforeEach\n+    public void setup() {\n+        properties = new Properties();\n+        configuration = new Configuration();\n+        columnDescriptors = new ArrayList<>();\n+        context = new RequestContext();\n+        // metadata usually set in accessor\n+        hiveIndexes = Arrays.asList(0, 1);\n+    }\n+\n+    @Test\n+    public void testSimpleString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"plain string\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"plain string\\u00011000\"));\n+    }\n+\n+    @Test\n+    public void testSpecialCharString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));", "originalCommit": "50dbf772c3b9c1f0783651af60c11b95a17235f5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyNDgxOQ==", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r545524819", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    assertThat(output.get(0).toString(), is(\"a really \\\"fancy\\\" string? *wink*\\u00011000\"));\n          \n          \n            \n                    assertThat(output.get(0).toString()).isEqualTo(\"a really \\\"fancy\\\" string? *wink*\\u00011000\"));", "author": "frankgh", "createdAt": "2020-12-18T02:03:39Z", "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "diffHunk": "@@ -0,0 +1,165 @@\n+package org.greenplum.pxf.plugins.hive;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.io.ArrayWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.io.Writable;\n+import org.greenplum.pxf.api.io.DataType;\n+import org.greenplum.pxf.api.model.RequestContext;\n+import org.greenplum.pxf.api.OneField;\n+import org.greenplum.pxf.api.OneRow;\n+import org.greenplum.pxf.api.utilities.ColumnDescriptor;\n+import org.greenplum.pxf.plugins.hive.utilities.HiveUtilities;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.core.Is.is;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class HiveResolverTest {\n+\n+    @Mock\n+    HiveUtilities mockHiveUtilities;\n+\n+    private static final String SERDE_CLASS_NAME = \"org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe\";\n+    private static final String COL_NAMES_SIMPLE = \"name,amt\";\n+    private static final String COL_TYPES_SIMPLE = \"string:double\";\n+\n+    private static final String SERDE_CLASS_NAME_STRUCT = \"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\";\n+    private static final String COL_NAMES_STRUCT = \"address\";\n+    private static final String COL_TYPES_STRUCT = \"struct<street:string,zipcode:bigint>\";\n+    private static final String COL_NAMES_NESTED_STRUCT = \"address\";\n+    private static final String COL_TYPES_NESTED_STRUCT = \"struct<line1:struct<number:bigint,street_name:string>,line2:struct<city:string,zipcode:bigint>>\";\n+    Configuration configuration;\n+    Properties properties;\n+    List<ColumnDescriptor> columnDescriptors;\n+    private HiveResolver resolver;\n+    RequestContext context;\n+    List<Integer> hiveIndexes;\n+\n+    @BeforeEach\n+    public void setup() {\n+        properties = new Properties();\n+        configuration = new Configuration();\n+        columnDescriptors = new ArrayList<>();\n+        context = new RequestContext();\n+        // metadata usually set in accessor\n+        hiveIndexes = Arrays.asList(0, 1);\n+    }\n+\n+    @Test\n+    public void testSimpleString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"plain string\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"plain string\\u00011000\"));\n+    }\n+\n+    @Test\n+    public void testSpecialCharString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"a really \\\"fancy\\\" string? *wink*\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"a really \\\"fancy\\\" string? *wink*\\u00011000\"));", "originalCommit": "50dbf772c3b9c1f0783651af60c11b95a17235f5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyNTAwOA==", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r545525008", "bodyText": "again, here shouldn't we expect two OneFields in the resulting list?", "author": "frankgh", "createdAt": "2020-12-18T02:04:13Z", "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "diffHunk": "@@ -0,0 +1,165 @@\n+package org.greenplum.pxf.plugins.hive;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.io.ArrayWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.io.Writable;\n+import org.greenplum.pxf.api.io.DataType;\n+import org.greenplum.pxf.api.model.RequestContext;\n+import org.greenplum.pxf.api.OneField;\n+import org.greenplum.pxf.api.OneRow;\n+import org.greenplum.pxf.api.utilities.ColumnDescriptor;\n+import org.greenplum.pxf.plugins.hive.utilities.HiveUtilities;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.core.Is.is;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class HiveResolverTest {\n+\n+    @Mock\n+    HiveUtilities mockHiveUtilities;\n+\n+    private static final String SERDE_CLASS_NAME = \"org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe\";\n+    private static final String COL_NAMES_SIMPLE = \"name,amt\";\n+    private static final String COL_TYPES_SIMPLE = \"string:double\";\n+\n+    private static final String SERDE_CLASS_NAME_STRUCT = \"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\";\n+    private static final String COL_NAMES_STRUCT = \"address\";\n+    private static final String COL_TYPES_STRUCT = \"struct<street:string,zipcode:bigint>\";\n+    private static final String COL_NAMES_NESTED_STRUCT = \"address\";\n+    private static final String COL_TYPES_NESTED_STRUCT = \"struct<line1:struct<number:bigint,street_name:string>,line2:struct<city:string,zipcode:bigint>>\";\n+    Configuration configuration;\n+    Properties properties;\n+    List<ColumnDescriptor> columnDescriptors;\n+    private HiveResolver resolver;\n+    RequestContext context;\n+    List<Integer> hiveIndexes;\n+\n+    @BeforeEach\n+    public void setup() {\n+        properties = new Properties();\n+        configuration = new Configuration();\n+        columnDescriptors = new ArrayList<>();\n+        context = new RequestContext();\n+        // metadata usually set in accessor\n+        hiveIndexes = Arrays.asList(0, 1);\n+    }\n+\n+    @Test\n+    public void testSimpleString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"plain string\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"plain string\\u00011000\"));\n+    }\n+\n+    @Test\n+    public void testSpecialCharString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"a really \\\"fancy\\\" string? *wink*\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);", "originalCommit": "50dbf772c3b9c1f0783651af60c11b95a17235f5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyNTg3OQ==", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r545525879", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    columnDescriptors.add(new ColumnDescriptor(\"address\", DataType.TEXT.getOID(), 3, \"struct\", null));\n          \n          \n            \n                    columnDescriptors.add(new ColumnDescriptor(\"address\", DataType.TEXT.getOID(), 0, \"struct\", null));", "author": "frankgh", "createdAt": "2020-12-18T02:07:00Z", "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "diffHunk": "@@ -0,0 +1,165 @@\n+package org.greenplum.pxf.plugins.hive;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.io.ArrayWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.io.Writable;\n+import org.greenplum.pxf.api.io.DataType;\n+import org.greenplum.pxf.api.model.RequestContext;\n+import org.greenplum.pxf.api.OneField;\n+import org.greenplum.pxf.api.OneRow;\n+import org.greenplum.pxf.api.utilities.ColumnDescriptor;\n+import org.greenplum.pxf.plugins.hive.utilities.HiveUtilities;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.core.Is.is;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class HiveResolverTest {\n+\n+    @Mock\n+    HiveUtilities mockHiveUtilities;\n+\n+    private static final String SERDE_CLASS_NAME = \"org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe\";\n+    private static final String COL_NAMES_SIMPLE = \"name,amt\";\n+    private static final String COL_TYPES_SIMPLE = \"string:double\";\n+\n+    private static final String SERDE_CLASS_NAME_STRUCT = \"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\";\n+    private static final String COL_NAMES_STRUCT = \"address\";\n+    private static final String COL_TYPES_STRUCT = \"struct<street:string,zipcode:bigint>\";\n+    private static final String COL_NAMES_NESTED_STRUCT = \"address\";\n+    private static final String COL_TYPES_NESTED_STRUCT = \"struct<line1:struct<number:bigint,street_name:string>,line2:struct<city:string,zipcode:bigint>>\";\n+    Configuration configuration;\n+    Properties properties;\n+    List<ColumnDescriptor> columnDescriptors;\n+    private HiveResolver resolver;\n+    RequestContext context;\n+    List<Integer> hiveIndexes;\n+\n+    @BeforeEach\n+    public void setup() {\n+        properties = new Properties();\n+        configuration = new Configuration();\n+        columnDescriptors = new ArrayList<>();\n+        context = new RequestContext();\n+        // metadata usually set in accessor\n+        hiveIndexes = Arrays.asList(0, 1);\n+    }\n+\n+    @Test\n+    public void testSimpleString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"plain string\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"plain string\\u00011000\"));\n+    }\n+\n+    @Test\n+    public void testSpecialCharString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"a really \\\"fancy\\\" string? *wink*\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"a really \\\"fancy\\\" string? *wink*\\u00011000\"));\n+    }\n+\n+    @Test\n+    public void testStructSimpleString() throws Exception {\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_STRUCT);\n+        columnDescriptors.add(new ColumnDescriptor(\"address\", DataType.TEXT.getOID(), 3, \"struct\", null));", "originalCommit": "50dbf772c3b9c1f0783651af60c11b95a17235f5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyNjE0OA==", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r545526148", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    assertThat(output.get(0).toString(), is(\"{\\\"street\\\":\\\"plain string\\\",\\\"zipcode\\\":1001}\"));\n          \n          \n            \n                    assertThat(output.get(0).toString()).isEqualTo(\"{\\\"street\\\":\\\"plain string\\\",\\\"zipcode\\\":1001}\"));", "author": "frankgh", "createdAt": "2020-12-18T02:07:46Z", "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "diffHunk": "@@ -0,0 +1,165 @@\n+package org.greenplum.pxf.plugins.hive;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.io.ArrayWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.io.Writable;\n+import org.greenplum.pxf.api.io.DataType;\n+import org.greenplum.pxf.api.model.RequestContext;\n+import org.greenplum.pxf.api.OneField;\n+import org.greenplum.pxf.api.OneRow;\n+import org.greenplum.pxf.api.utilities.ColumnDescriptor;\n+import org.greenplum.pxf.plugins.hive.utilities.HiveUtilities;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.core.Is.is;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class HiveResolverTest {\n+\n+    @Mock\n+    HiveUtilities mockHiveUtilities;\n+\n+    private static final String SERDE_CLASS_NAME = \"org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe\";\n+    private static final String COL_NAMES_SIMPLE = \"name,amt\";\n+    private static final String COL_TYPES_SIMPLE = \"string:double\";\n+\n+    private static final String SERDE_CLASS_NAME_STRUCT = \"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\";\n+    private static final String COL_NAMES_STRUCT = \"address\";\n+    private static final String COL_TYPES_STRUCT = \"struct<street:string,zipcode:bigint>\";\n+    private static final String COL_NAMES_NESTED_STRUCT = \"address\";\n+    private static final String COL_TYPES_NESTED_STRUCT = \"struct<line1:struct<number:bigint,street_name:string>,line2:struct<city:string,zipcode:bigint>>\";\n+    Configuration configuration;\n+    Properties properties;\n+    List<ColumnDescriptor> columnDescriptors;\n+    private HiveResolver resolver;\n+    RequestContext context;\n+    List<Integer> hiveIndexes;\n+\n+    @BeforeEach\n+    public void setup() {\n+        properties = new Properties();\n+        configuration = new Configuration();\n+        columnDescriptors = new ArrayList<>();\n+        context = new RequestContext();\n+        // metadata usually set in accessor\n+        hiveIndexes = Arrays.asList(0, 1);\n+    }\n+\n+    @Test\n+    public void testSimpleString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"plain string\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"plain string\\u00011000\"));\n+    }\n+\n+    @Test\n+    public void testSpecialCharString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"a really \\\"fancy\\\" string? *wink*\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"a really \\\"fancy\\\" string? *wink*\\u00011000\"));\n+    }\n+\n+    @Test\n+    public void testStructSimpleString() throws Exception {\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_STRUCT);\n+        columnDescriptors.add(new ColumnDescriptor(\"address\", DataType.TEXT.getOID(), 3, \"struct\", null));\n+\n+        OneRow row = new OneRow(0, new Text(\"plain string\\u00021001\"));\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"{\\\"street\\\":\\\"plain string\\\",\\\"zipcode\\\":1001}\"));", "originalCommit": "50dbf772c3b9c1f0783651af60c11b95a17235f5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyNjcxMg==", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r545526712", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    assertThat(output.get(0).toString(), is(\"{\\\"street\\\":\\\"a really \\\\\\\"fancy\\\\\\\" string\\\",\\\"zipcode\\\":1001}\"));\n          \n          \n            \n                    assertThat(output.get(0).toString()).isEqualTo(\"{\\\"street\\\":\\\"a really \\\\\\\"fancy\\\\\\\" string\\\",\\\"zipcode\\\":1001}\"));", "author": "frankgh", "createdAt": "2020-12-18T02:09:28Z", "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "diffHunk": "@@ -0,0 +1,165 @@\n+package org.greenplum.pxf.plugins.hive;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.io.ArrayWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.io.Writable;\n+import org.greenplum.pxf.api.io.DataType;\n+import org.greenplum.pxf.api.model.RequestContext;\n+import org.greenplum.pxf.api.OneField;\n+import org.greenplum.pxf.api.OneRow;\n+import org.greenplum.pxf.api.utilities.ColumnDescriptor;\n+import org.greenplum.pxf.plugins.hive.utilities.HiveUtilities;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.core.Is.is;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class HiveResolverTest {\n+\n+    @Mock\n+    HiveUtilities mockHiveUtilities;\n+\n+    private static final String SERDE_CLASS_NAME = \"org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe\";\n+    private static final String COL_NAMES_SIMPLE = \"name,amt\";\n+    private static final String COL_TYPES_SIMPLE = \"string:double\";\n+\n+    private static final String SERDE_CLASS_NAME_STRUCT = \"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\";\n+    private static final String COL_NAMES_STRUCT = \"address\";\n+    private static final String COL_TYPES_STRUCT = \"struct<street:string,zipcode:bigint>\";\n+    private static final String COL_NAMES_NESTED_STRUCT = \"address\";\n+    private static final String COL_TYPES_NESTED_STRUCT = \"struct<line1:struct<number:bigint,street_name:string>,line2:struct<city:string,zipcode:bigint>>\";\n+    Configuration configuration;\n+    Properties properties;\n+    List<ColumnDescriptor> columnDescriptors;\n+    private HiveResolver resolver;\n+    RequestContext context;\n+    List<Integer> hiveIndexes;\n+\n+    @BeforeEach\n+    public void setup() {\n+        properties = new Properties();\n+        configuration = new Configuration();\n+        columnDescriptors = new ArrayList<>();\n+        context = new RequestContext();\n+        // metadata usually set in accessor\n+        hiveIndexes = Arrays.asList(0, 1);\n+    }\n+\n+    @Test\n+    public void testSimpleString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"plain string\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"plain string\\u00011000\"));\n+    }\n+\n+    @Test\n+    public void testSpecialCharString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"a really \\\"fancy\\\" string? *wink*\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"a really \\\"fancy\\\" string? *wink*\\u00011000\"));\n+    }\n+\n+    @Test\n+    public void testStructSimpleString() throws Exception {\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_STRUCT);\n+        columnDescriptors.add(new ColumnDescriptor(\"address\", DataType.TEXT.getOID(), 3, \"struct\", null));\n+\n+        OneRow row = new OneRow(0, new Text(\"plain string\\u00021001\"));\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"{\\\"street\\\":\\\"plain string\\\",\\\"zipcode\\\":1001}\"));\n+    }\n+\n+    @Test\n+    public void testStructSpecialCharString() throws Exception {\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_STRUCT);\n+        columnDescriptors.add(new ColumnDescriptor(\"address\", DataType.TEXT.getOID(), 3, \"struct\", null));\n+\n+        OneRow row = new OneRow(0, new Text(\"a really \\\"fancy\\\" string\\u00021001\"));\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"{\\\"street\\\":\\\"a really \\\\\\\"fancy\\\\\\\" string\\\",\\\"zipcode\\\":1001}\"));", "originalCommit": "50dbf772c3b9c1f0783651af60c11b95a17235f5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUyNzAwNQ==", "url": "https://github.com/greenplum-db/pxf/pull/511#discussion_r545527005", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    assertThat(output.get(0).toString(), is(\"{\\\"line1\\\":{\\\"number\\\":1000,\\\"street_name\\\":\\\"a really \\\\\\\"fancy\\\\\\\" string\\\"},\\\"line2\\\":{\\\"city\\\":\\\"plain string\\\",\\\"zipcode\\\":1001}}\"));\n          \n          \n            \n                    assertThat(output.get(0).toString()).isEqualTo(\"{\\\"line1\\\":{\\\"number\\\":1000,\\\"street_name\\\":\\\"a really \\\\\\\"fancy\\\\\\\" string\\\"},\\\"line2\\\":{\\\"city\\\":\\\"plain string\\\",\\\"zipcode\\\":1001}}\"));", "author": "frankgh", "createdAt": "2020-12-18T02:10:31Z", "path": "server/pxf-hive/src/test/java/org/greenplum/pxf/plugins/hive/HiveResolverTest.java", "diffHunk": "@@ -0,0 +1,165 @@\n+package org.greenplum.pxf.plugins.hive;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.io.ArrayWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.io.Writable;\n+import org.greenplum.pxf.api.io.DataType;\n+import org.greenplum.pxf.api.model.RequestContext;\n+import org.greenplum.pxf.api.OneField;\n+import org.greenplum.pxf.api.OneRow;\n+import org.greenplum.pxf.api.utilities.ColumnDescriptor;\n+import org.greenplum.pxf.plugins.hive.utilities.HiveUtilities;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.core.Is.is;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class HiveResolverTest {\n+\n+    @Mock\n+    HiveUtilities mockHiveUtilities;\n+\n+    private static final String SERDE_CLASS_NAME = \"org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe\";\n+    private static final String COL_NAMES_SIMPLE = \"name,amt\";\n+    private static final String COL_TYPES_SIMPLE = \"string:double\";\n+\n+    private static final String SERDE_CLASS_NAME_STRUCT = \"org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\";\n+    private static final String COL_NAMES_STRUCT = \"address\";\n+    private static final String COL_TYPES_STRUCT = \"struct<street:string,zipcode:bigint>\";\n+    private static final String COL_NAMES_NESTED_STRUCT = \"address\";\n+    private static final String COL_TYPES_NESTED_STRUCT = \"struct<line1:struct<number:bigint,street_name:string>,line2:struct<city:string,zipcode:bigint>>\";\n+    Configuration configuration;\n+    Properties properties;\n+    List<ColumnDescriptor> columnDescriptors;\n+    private HiveResolver resolver;\n+    RequestContext context;\n+    List<Integer> hiveIndexes;\n+\n+    @BeforeEach\n+    public void setup() {\n+        properties = new Properties();\n+        configuration = new Configuration();\n+        columnDescriptors = new ArrayList<>();\n+        context = new RequestContext();\n+        // metadata usually set in accessor\n+        hiveIndexes = Arrays.asList(0, 1);\n+    }\n+\n+    @Test\n+    public void testSimpleString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"plain string\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"plain string\\u00011000\"));\n+    }\n+\n+    @Test\n+    public void testSpecialCharString() throws Exception {\n+\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_SIMPLE);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_SIMPLE);\n+        columnDescriptors.add(new ColumnDescriptor(\"name\", DataType.TEXT.getOID(), 1, \"text\", null));\n+        columnDescriptors.add(new ColumnDescriptor(\"amt\", DataType.FLOAT8.getOID(), 3, \"float8\", null));\n+\n+        ArrayWritable aw = new ArrayWritable(Text.class, new Writable[]{new Text(\"a really \\\"fancy\\\" string? *wink*\\u00011000\")});\n+        OneRow row = new OneRow(aw);\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"a really \\\"fancy\\\" string? *wink*\\u00011000\"));\n+    }\n+\n+    @Test\n+    public void testStructSimpleString() throws Exception {\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_STRUCT);\n+        columnDescriptors.add(new ColumnDescriptor(\"address\", DataType.TEXT.getOID(), 3, \"struct\", null));\n+\n+        OneRow row = new OneRow(0, new Text(\"plain string\\u00021001\"));\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"{\\\"street\\\":\\\"plain string\\\",\\\"zipcode\\\":1001}\"));\n+    }\n+\n+    @Test\n+    public void testStructSpecialCharString() throws Exception {\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_STRUCT);\n+        columnDescriptors.add(new ColumnDescriptor(\"address\", DataType.TEXT.getOID(), 3, \"struct\", null));\n+\n+        OneRow row = new OneRow(0, new Text(\"a really \\\"fancy\\\" string\\u00021001\"));\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"{\\\"street\\\":\\\"a really \\\\\\\"fancy\\\\\\\" string\\\",\\\"zipcode\\\":1001}\"));\n+    }\n+\n+    @Test\n+    public void testNestedStruct() throws Exception {\n+        properties.put(\"serialization.lib\", SERDE_CLASS_NAME_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMNS, COL_NAMES_NESTED_STRUCT);\n+        properties.put(serdeConstants.LIST_COLUMN_TYPES, COL_TYPES_NESTED_STRUCT);\n+        columnDescriptors.add(new ColumnDescriptor(\"address\", DataType.TEXT.getOID(), 3, \"struct\", null));\n+\n+        OneRow row = new OneRow(0, new Text(\"1000\\u0003a really \\\"fancy\\\" string\\u0002plain string\\u00031001\"));\n+\n+        context.setConfiguration(configuration);\n+        context.setMetadata(new HiveMetadata(properties, null /*List<HivePartition>*/, hiveIndexes));\n+        context.setTupleDescription(columnDescriptors);\n+        resolver = new HiveResolver(mockHiveUtilities);\n+        resolver.setRequestContext(context);\n+        resolver.afterPropertiesSet();\n+        List<OneField> output = resolver.getFields(row);\n+\n+        assertThat(output.get(0).toString(), is(\"{\\\"line1\\\":{\\\"number\\\":1000,\\\"street_name\\\":\\\"a really \\\\\\\"fancy\\\\\\\" string\\\"},\\\"line2\\\":{\\\"city\\\":\\\"plain string\\\",\\\"zipcode\\\":1001}}\"));", "originalCommit": "50dbf772c3b9c1f0783651af60c11b95a17235f5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "ff67c28432eb38e02d893712281cdf8e21c46e22", "url": "https://github.com/greenplum-db/pxf/commit/ff67c28432eb38e02d893712281cdf8e21c46e22", "message": "pxf-hive: handle null cases in complex types in HiveResolver\n\nCo-authored-by: Ashuka Xue <axue@vmware.com>\nCo-authored-by: Francisco Guerrero <fguerrero@vmware.com>", "committedDate": "2021-01-04T22:24:53Z", "type": "commit"}, {"oid": "d0775d2ccfa26c6efc527efe1070dc3417039ba1", "url": "https://github.com/greenplum-db/pxf/commit/d0775d2ccfa26c6efc527efe1070dc3417039ba1", "message": "pxf-hive: Add integration test for nested struct\n\nCo-authored-by: Ashuka Xue <axue@vmware.com>\nCo-authored-by: Francisco Guerrero <fguerrero@vmware.com>", "committedDate": "2021-01-04T23:10:41Z", "type": "commit"}, {"oid": "3cfc82f850d32d626c08d7952f19aac2d3d70ff1", "url": "https://github.com/greenplum-db/pxf/commit/3cfc82f850d32d626c08d7952f19aac2d3d70ff1", "message": "pxf-hive: Update unit tests\n\nCo-authored-by: Ashuka Xue <axue@vmware.com>\nCo-authored-by: Francisco Guerrero <fguerrero@vmware.com>", "committedDate": "2021-01-04T23:10:52Z", "type": "commit"}, {"oid": "baa70eadf71f04097d355043a04c98e47aac8d57", "url": "https://github.com/greenplum-db/pxf/commit/baa70eadf71f04097d355043a04c98e47aac8d57", "message": "Address PR Feedback", "committedDate": "2021-01-04T23:10:52Z", "type": "commit"}, {"oid": "baa70eadf71f04097d355043a04c98e47aac8d57", "url": "https://github.com/greenplum-db/pxf/commit/baa70eadf71f04097d355043a04c98e47aac8d57", "message": "Address PR Feedback", "committedDate": "2021-01-04T23:10:52Z", "type": "forcePushed"}, {"oid": "fb7c7e54a19ce4f9814f8d4c775fb7d79c4ace17", "url": "https://github.com/greenplum-db/pxf/commit/fb7c7e54a19ce4f9814f8d4c775fb7d79c4ace17", "message": "fixup! Address PR Feedback", "committedDate": "2021-01-12T00:57:06Z", "type": "commit"}]}