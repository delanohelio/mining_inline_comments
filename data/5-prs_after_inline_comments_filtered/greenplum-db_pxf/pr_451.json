{"pr_number": 451, "pr_title": "Support dropping columns in PXF external tables", "pr_createdAt": "2020-09-15T15:39:15Z", "pr_url": "https://github.com/greenplum-db/pxf/pull/451", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDU4NjY3MQ==", "url": "https://github.com/greenplum-db/pxf/pull/451#discussion_r490586671", "bodyText": "why do you need sleep?", "author": "ashuka24", "createdAt": "2020-09-17T22:01:27Z", "path": "automation/src/test/java/org/greenplum/pxf/automation/features/general/AlterTableTest.java", "diffHunk": "@@ -0,0 +1,190 @@\n+package org.greenplum.pxf.automation.features.general;\n+\n+import org.greenplum.pxf.automation.features.BaseFeature;\n+import org.greenplum.pxf.automation.structures.tables.basic.Table;\n+import org.greenplum.pxf.automation.structures.tables.pxf.ReadableExternalTable;\n+import org.greenplum.pxf.automation.structures.tables.pxf.WritableExternalTable;\n+import org.greenplum.pxf.automation.structures.tables.utils.TableFactory;\n+import org.greenplum.pxf.automation.utils.system.ProtocolEnum;\n+import org.greenplum.pxf.automation.utils.system.ProtocolUtils;\n+import org.testng.annotations.Test;\n+\n+import java.util.List;\n+\n+import static java.lang.Thread.sleep;", "originalCommit": "904003217a18f82003afbc540c1c01398c5bce5c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYwMzgwOA==", "url": "https://github.com/greenplum-db/pxf/pull/451#discussion_r490603808", "bodyText": "good catch, the imports need cleaning", "author": "frankgh", "createdAt": "2020-09-17T22:47:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDU4NjY3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDU4NzIzMw==", "url": "https://github.com/greenplum-db/pxf/pull/451#discussion_r490587233", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                 * Attempt to query data on a table that has a column that does not exist.\n          \n          \n            \n                 * Attempt to query data on a table with column that does not exist.", "author": "ashuka24", "createdAt": "2020-09-17T22:02:55Z", "path": "automation/src/test/java/org/greenplum/pxf/automation/features/general/AlterTableTest.java", "diffHunk": "@@ -0,0 +1,190 @@\n+package org.greenplum.pxf.automation.features.general;\n+\n+import org.greenplum.pxf.automation.features.BaseFeature;\n+import org.greenplum.pxf.automation.structures.tables.basic.Table;\n+import org.greenplum.pxf.automation.structures.tables.pxf.ReadableExternalTable;\n+import org.greenplum.pxf.automation.structures.tables.pxf.WritableExternalTable;\n+import org.greenplum.pxf.automation.structures.tables.utils.TableFactory;\n+import org.greenplum.pxf.automation.utils.system.ProtocolEnum;\n+import org.greenplum.pxf.automation.utils.system.ProtocolUtils;\n+import org.testng.annotations.Test;\n+\n+import java.util.List;\n+\n+import static java.lang.Thread.sleep;\n+\n+public class AlterTableTest extends BaseFeature {\n+\n+    private static final String AVRO_TYPES_FILE_NAME = \"supported_primitive_types\";\n+    private static final String FILE_SCHEME = \"file://\";\n+    private static final String PXF_ALTER_AVRO_TABLE = \"pxf_alter_avro_table\";\n+    private static final String PXF_ALTER_CSV_TABLE = \"pxf_alter_csv_table\";\n+    private static final String PXF_PARQUET_TABLE_SOURCE = \"pxf_alter_parquet_primitive_types\";\n+    private static final String PXF_ALTER_PARQUET_TABLE = \"pxf_alter_parquet_table\";\n+    private static final String PXF_ALTER_WRITE_PARQUET_TABLE = \"pxf_alter_write_parquet_table\";\n+    private static final String PARQUET_PRIMITIVE_TYPES = \"parquet_primitive_types\";\n+    private static final String PARQUET_WRITE_PRIMITIVES = \"parquet_write_primitives\";\n+    private static final String SUFFIX_JSON = \".json\";\n+    private static final String SUFFIX_AVRO = \".avro\";\n+    private static final String SUFFIX_AVSC = \".avsc\";\n+\n+    private static final String[] PARQUET_TABLE_COLUMNS = new String[]{\n+            \"s1    TEXT\",\n+            \"s2    TEXT\",\n+            \"n1    INTEGER\",\n+            \"d1    DOUBLE PRECISION\",\n+            \"dc1   NUMERIC\",\n+            \"tm    TIMESTAMP\",\n+            \"f     REAL\",\n+            \"bg    BIGINT\",\n+            \"b     BOOLEAN\",\n+            \"tn    SMALLINT\",\n+            \"vc1   VARCHAR(5)\",\n+            \"sml   SMALLINT\",\n+            \"c1    CHAR(3)\",\n+            \"bin   BYTEA\"\n+    };\n+\n+    private static final String[] PARQUET_TABLE_SUBSET_COLUMNS = new String[]{\n+            \"s1    TEXT\",\n+            \"s2    TEXT\",\n+            \"n1    INTEGER\",\n+            \"d1    DOUBLE PRECISION\",\n+            \"dc1   NUMERIC\",\n+            \"f     REAL\",\n+            \"bg    BIGINT\",\n+            \"b     BOOLEAN\",\n+            \"tn    SMALLINT\",\n+            \"vc1   VARCHAR(5)\",\n+            \"sml   SMALLINT\",\n+            \"c1    CHAR(3)\"\n+    };\n+\n+    private String hdfsPath;\n+\n+    @Override\n+    public void beforeClass() throws Exception {\n+        // path for storing data on HDFS (for processing by PXF)\n+        hdfsPath = hdfs.getWorkingDirectory() + \"/alter-tests\";\n+\n+        String resourcePath = localDataResourcesFolder + \"/parquet/\";\n+        hdfs.copyFromLocal(resourcePath + PARQUET_PRIMITIVE_TYPES, hdfsPath + \"/parquet/\" + PARQUET_PRIMITIVE_TYPES);\n+\n+        // Create Data and write it to HDFS\n+        Table dataTable = getSmallData();\n+        hdfs.writeTableToFile(hdfsPath + \"/csv/\" + fileName, dataTable, \",\");\n+\n+        // Avro\n+        // location of schema and data files\n+        String absolutePath = getClass().getClassLoader().getResource(\"data\").getPath();\n+        resourcePath = absolutePath + \"/avro/\";\n+        hdfs.writeAvroFileFromJson(hdfsPath + \"/avro/\" + AVRO_TYPES_FILE_NAME + SUFFIX_AVRO,\n+                FILE_SCHEME + resourcePath + AVRO_TYPES_FILE_NAME + SUFFIX_AVSC,\n+                FILE_SCHEME + resourcePath + AVRO_TYPES_FILE_NAME + SUFFIX_JSON, null);\n+    }\n+\n+    /**\n+     * Query data on a table, then drops column(s), then queries again.\n+     * Finally, the test adds back one of the dropped columns to the table,\n+     * and a new query is performed. The query uses parquet which supports\n+     * column projection, and uses the pxfwritable_import formatter.\n+     *\n+     * @throws Exception when the test execution fails\n+     */\n+    @Test(groups = {\"features\", \"gpdb\", \"security\"})\n+    public void dropAndAddColumnsPxfWritableImportWithColumnProjectionSupport() throws Exception {\n+\n+        exTable = new ReadableExternalTable(PXF_ALTER_PARQUET_TABLE,\n+                PARQUET_TABLE_COLUMNS, hdfsPath + \"/parquet/\" + PARQUET_PRIMITIVE_TYPES, \"custom\");\n+        exTable.setHost(pxfHost);\n+        exTable.setPort(pxfPort);\n+        exTable.setFormatter(\"pxfwritable_import\");\n+        exTable.setProfile(ProtocolUtils.getProtocol().value() + \":parquet\");\n+\n+        gpdb.createTableAndVerify(exTable);\n+\n+        runTincTest(\"pxf.features.general.alter.pxfwritable_import.with_column_projection.runTest\");\n+    }\n+\n+    @Test(groups = {\"features\", \"gpdb\", \"security\"})\n+    public void dropColumnsPxfWritableExport() throws Exception {\n+\n+        // Create source table\n+        exTable = new ReadableExternalTable(PXF_PARQUET_TABLE_SOURCE,\n+                PARQUET_TABLE_COLUMNS, hdfsPath + \"/parquet/\" + PARQUET_PRIMITIVE_TYPES, \"custom\");\n+        exTable.setHost(pxfHost);\n+        exTable.setPort(pxfPort);\n+        exTable.setFormatter(\"pxfwritable_import\");\n+        exTable.setProfile(ProtocolUtils.getProtocol().value() + \":parquet\");\n+        gpdb.createTableAndVerify(exTable);\n+\n+        // Create writable table\n+        exTable = new WritableExternalTable(PXF_ALTER_WRITE_PARQUET_TABLE,\n+                PARQUET_TABLE_COLUMNS, hdfsPath + \"/parquet-write/\" + PARQUET_WRITE_PRIMITIVES, \"custom\");\n+        exTable.setHost(pxfHost);\n+        exTable.setPort(pxfPort);\n+        exTable.setFormatter(\"pxfwritable_export\");\n+        exTable.setProfile(ProtocolUtils.getProtocol().value() + \":parquet\");\n+        gpdb.createTableAndVerify(exTable);\n+\n+        // Create validation table\n+        exTable = new ReadableExternalTable(PXF_ALTER_WRITE_PARQUET_TABLE + \"_r\",\n+                PARQUET_TABLE_SUBSET_COLUMNS, hdfsPath + \"/parquet-write/\" + PARQUET_WRITE_PRIMITIVES, \"custom\");\n+        exTable.setHost(pxfHost);\n+        exTable.setPort(pxfPort);\n+        exTable.setFormatter(\"pxfwritable_import\");\n+        exTable.setProfile(ProtocolUtils.getProtocol().value() + \":parquet\");\n+        gpdb.createTableAndVerify(exTable);\n+\n+        runTincTest(\"pxf.features.general.alter.pxfwritable_export.parquet.runTest\");\n+    }\n+\n+    @Test(groups = {\"features\", \"gpdb\", \"security\"})\n+    public void dropAndAddColumnsPxfWritableImportWithoutColumnProjectionSupport() throws Exception {\n+        // default external table with common settings\n+        exTable = new ReadableExternalTable(PXF_ALTER_AVRO_TABLE, new String[]{\n+                \"type_int int\",\n+                \"type_double float8\",\n+                \"type_string text\",\n+                \"type_float real\",\n+                \"col_does_not_exist text\",\n+                \"type_long bigint\",\n+                \"type_bytes bytea\",\n+                \"type_boolean bool\"}, hdfsPath + \"/avro/\" + AVRO_TYPES_FILE_NAME + SUFFIX_AVRO, \"custom\");\n+        exTable.setHost(pxfHost);\n+        exTable.setPort(pxfPort);\n+        exTable.setFormatter(\"pxfwritable_import\");\n+        exTable.setProfile(ProtocolUtils.getProtocol().value() + \":avro\");\n+\n+        gpdb.createTableAndVerify(exTable);\n+\n+        // Verify results\n+        runTincTest(\"pxf.features.general.alter.pxfwritable_import.without_column_projection.runTest\");\n+    }\n+\n+    /**\n+     * Attempt to query data on a table that has a column that does not exist.", "originalCommit": "904003217a18f82003afbc540c1c01398c5bce5c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDU4ODU3OA==", "url": "https://github.com/greenplum-db/pxf/pull/451#discussion_r490588578", "bodyText": "or maybe\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                 * Attempt to query data on a table that has a column that does not exist.\n          \n          \n            \n                 * Attempt to query data on a column from a table where the column does not exist.", "author": "ashuka24", "createdAt": "2020-09-17T22:06:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDU4NzIzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDU4NzczMA==", "url": "https://github.com/greenplum-db/pxf/pull/451#discussion_r490587730", "bodyText": "could you please clarify this? if it tries to query data on a non-existent column, then what exactly is being dropped?", "author": "ashuka24", "createdAt": "2020-09-17T22:04:08Z", "path": "automation/src/test/java/org/greenplum/pxf/automation/features/general/AlterTableTest.java", "diffHunk": "@@ -0,0 +1,190 @@\n+package org.greenplum.pxf.automation.features.general;\n+\n+import org.greenplum.pxf.automation.features.BaseFeature;\n+import org.greenplum.pxf.automation.structures.tables.basic.Table;\n+import org.greenplum.pxf.automation.structures.tables.pxf.ReadableExternalTable;\n+import org.greenplum.pxf.automation.structures.tables.pxf.WritableExternalTable;\n+import org.greenplum.pxf.automation.structures.tables.utils.TableFactory;\n+import org.greenplum.pxf.automation.utils.system.ProtocolEnum;\n+import org.greenplum.pxf.automation.utils.system.ProtocolUtils;\n+import org.testng.annotations.Test;\n+\n+import java.util.List;\n+\n+import static java.lang.Thread.sleep;\n+\n+public class AlterTableTest extends BaseFeature {\n+\n+    private static final String AVRO_TYPES_FILE_NAME = \"supported_primitive_types\";\n+    private static final String FILE_SCHEME = \"file://\";\n+    private static final String PXF_ALTER_AVRO_TABLE = \"pxf_alter_avro_table\";\n+    private static final String PXF_ALTER_CSV_TABLE = \"pxf_alter_csv_table\";\n+    private static final String PXF_PARQUET_TABLE_SOURCE = \"pxf_alter_parquet_primitive_types\";\n+    private static final String PXF_ALTER_PARQUET_TABLE = \"pxf_alter_parquet_table\";\n+    private static final String PXF_ALTER_WRITE_PARQUET_TABLE = \"pxf_alter_write_parquet_table\";\n+    private static final String PARQUET_PRIMITIVE_TYPES = \"parquet_primitive_types\";\n+    private static final String PARQUET_WRITE_PRIMITIVES = \"parquet_write_primitives\";\n+    private static final String SUFFIX_JSON = \".json\";\n+    private static final String SUFFIX_AVRO = \".avro\";\n+    private static final String SUFFIX_AVSC = \".avsc\";\n+\n+    private static final String[] PARQUET_TABLE_COLUMNS = new String[]{\n+            \"s1    TEXT\",\n+            \"s2    TEXT\",\n+            \"n1    INTEGER\",\n+            \"d1    DOUBLE PRECISION\",\n+            \"dc1   NUMERIC\",\n+            \"tm    TIMESTAMP\",\n+            \"f     REAL\",\n+            \"bg    BIGINT\",\n+            \"b     BOOLEAN\",\n+            \"tn    SMALLINT\",\n+            \"vc1   VARCHAR(5)\",\n+            \"sml   SMALLINT\",\n+            \"c1    CHAR(3)\",\n+            \"bin   BYTEA\"\n+    };\n+\n+    private static final String[] PARQUET_TABLE_SUBSET_COLUMNS = new String[]{\n+            \"s1    TEXT\",\n+            \"s2    TEXT\",\n+            \"n1    INTEGER\",\n+            \"d1    DOUBLE PRECISION\",\n+            \"dc1   NUMERIC\",\n+            \"f     REAL\",\n+            \"bg    BIGINT\",\n+            \"b     BOOLEAN\",\n+            \"tn    SMALLINT\",\n+            \"vc1   VARCHAR(5)\",\n+            \"sml   SMALLINT\",\n+            \"c1    CHAR(3)\"\n+    };\n+\n+    private String hdfsPath;\n+\n+    @Override\n+    public void beforeClass() throws Exception {\n+        // path for storing data on HDFS (for processing by PXF)\n+        hdfsPath = hdfs.getWorkingDirectory() + \"/alter-tests\";\n+\n+        String resourcePath = localDataResourcesFolder + \"/parquet/\";\n+        hdfs.copyFromLocal(resourcePath + PARQUET_PRIMITIVE_TYPES, hdfsPath + \"/parquet/\" + PARQUET_PRIMITIVE_TYPES);\n+\n+        // Create Data and write it to HDFS\n+        Table dataTable = getSmallData();\n+        hdfs.writeTableToFile(hdfsPath + \"/csv/\" + fileName, dataTable, \",\");\n+\n+        // Avro\n+        // location of schema and data files\n+        String absolutePath = getClass().getClassLoader().getResource(\"data\").getPath();\n+        resourcePath = absolutePath + \"/avro/\";\n+        hdfs.writeAvroFileFromJson(hdfsPath + \"/avro/\" + AVRO_TYPES_FILE_NAME + SUFFIX_AVRO,\n+                FILE_SCHEME + resourcePath + AVRO_TYPES_FILE_NAME + SUFFIX_AVSC,\n+                FILE_SCHEME + resourcePath + AVRO_TYPES_FILE_NAME + SUFFIX_JSON, null);\n+    }\n+\n+    /**\n+     * Query data on a table, then drops column(s), then queries again.\n+     * Finally, the test adds back one of the dropped columns to the table,\n+     * and a new query is performed. The query uses parquet which supports\n+     * column projection, and uses the pxfwritable_import formatter.\n+     *\n+     * @throws Exception when the test execution fails\n+     */\n+    @Test(groups = {\"features\", \"gpdb\", \"security\"})\n+    public void dropAndAddColumnsPxfWritableImportWithColumnProjectionSupport() throws Exception {\n+\n+        exTable = new ReadableExternalTable(PXF_ALTER_PARQUET_TABLE,\n+                PARQUET_TABLE_COLUMNS, hdfsPath + \"/parquet/\" + PARQUET_PRIMITIVE_TYPES, \"custom\");\n+        exTable.setHost(pxfHost);\n+        exTable.setPort(pxfPort);\n+        exTable.setFormatter(\"pxfwritable_import\");\n+        exTable.setProfile(ProtocolUtils.getProtocol().value() + \":parquet\");\n+\n+        gpdb.createTableAndVerify(exTable);\n+\n+        runTincTest(\"pxf.features.general.alter.pxfwritable_import.with_column_projection.runTest\");\n+    }\n+\n+    @Test(groups = {\"features\", \"gpdb\", \"security\"})\n+    public void dropColumnsPxfWritableExport() throws Exception {\n+\n+        // Create source table\n+        exTable = new ReadableExternalTable(PXF_PARQUET_TABLE_SOURCE,\n+                PARQUET_TABLE_COLUMNS, hdfsPath + \"/parquet/\" + PARQUET_PRIMITIVE_TYPES, \"custom\");\n+        exTable.setHost(pxfHost);\n+        exTable.setPort(pxfPort);\n+        exTable.setFormatter(\"pxfwritable_import\");\n+        exTable.setProfile(ProtocolUtils.getProtocol().value() + \":parquet\");\n+        gpdb.createTableAndVerify(exTable);\n+\n+        // Create writable table\n+        exTable = new WritableExternalTable(PXF_ALTER_WRITE_PARQUET_TABLE,\n+                PARQUET_TABLE_COLUMNS, hdfsPath + \"/parquet-write/\" + PARQUET_WRITE_PRIMITIVES, \"custom\");\n+        exTable.setHost(pxfHost);\n+        exTable.setPort(pxfPort);\n+        exTable.setFormatter(\"pxfwritable_export\");\n+        exTable.setProfile(ProtocolUtils.getProtocol().value() + \":parquet\");\n+        gpdb.createTableAndVerify(exTable);\n+\n+        // Create validation table\n+        exTable = new ReadableExternalTable(PXF_ALTER_WRITE_PARQUET_TABLE + \"_r\",\n+                PARQUET_TABLE_SUBSET_COLUMNS, hdfsPath + \"/parquet-write/\" + PARQUET_WRITE_PRIMITIVES, \"custom\");\n+        exTable.setHost(pxfHost);\n+        exTable.setPort(pxfPort);\n+        exTable.setFormatter(\"pxfwritable_import\");\n+        exTable.setProfile(ProtocolUtils.getProtocol().value() + \":parquet\");\n+        gpdb.createTableAndVerify(exTable);\n+\n+        runTincTest(\"pxf.features.general.alter.pxfwritable_export.parquet.runTest\");\n+    }\n+\n+    @Test(groups = {\"features\", \"gpdb\", \"security\"})\n+    public void dropAndAddColumnsPxfWritableImportWithoutColumnProjectionSupport() throws Exception {\n+        // default external table with common settings\n+        exTable = new ReadableExternalTable(PXF_ALTER_AVRO_TABLE, new String[]{\n+                \"type_int int\",\n+                \"type_double float8\",\n+                \"type_string text\",\n+                \"type_float real\",\n+                \"col_does_not_exist text\",\n+                \"type_long bigint\",\n+                \"type_bytes bytea\",\n+                \"type_boolean bool\"}, hdfsPath + \"/avro/\" + AVRO_TYPES_FILE_NAME + SUFFIX_AVRO, \"custom\");\n+        exTable.setHost(pxfHost);\n+        exTable.setPort(pxfPort);\n+        exTable.setFormatter(\"pxfwritable_import\");\n+        exTable.setProfile(ProtocolUtils.getProtocol().value() + \":avro\");\n+\n+        gpdb.createTableAndVerify(exTable);\n+\n+        // Verify results\n+        runTincTest(\"pxf.features.general.alter.pxfwritable_import.without_column_projection.runTest\");\n+    }\n+\n+    /**\n+     * Attempt to query data on a table that has a column that does not exist.\n+     * It then drops the column and performs the query successfully.", "originalCommit": "904003217a18f82003afbc540c1c01398c5bce5c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYwNTA0NA==", "url": "https://github.com/greenplum-db/pxf/pull/451#discussion_r490605044", "bodyText": "done, hopefully it makes more sense now.", "author": "frankgh", "createdAt": "2020-09-17T22:51:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDU4NzczMA=="}], "type": "inlineReview"}, {"oid": "c83c8630b623b13e5934cc1f0eb97dd8f07c4dac", "url": "https://github.com/greenplum-db/pxf/commit/c83c8630b623b13e5934cc1f0eb97dd8f07c4dac", "message": "Support dropping columns in PXF readable external tables\n\nPXF does not support dropping columns from readable external tables.\nThis commit adds support for dropping columns, especially when the\nformat is CUSTOM and the formatter is `pxfwritable_import`. This also\napplies for TEXT/CSV format, but the complexity lies in the\n`pxfwritable_import` formatter. Add automation tests for altering PXF\nreadable external tables.", "committedDate": "2020-09-23T00:30:30Z", "type": "commit"}, {"oid": "ba4105151e844d016383f0968ad7ae556b3a6e16", "url": "https://github.com/greenplum-db/pxf/commit/ba4105151e844d016383f0968ad7ae556b3a6e16", "message": "Support dropping columns in PXF writable external tables\n\nPXF does not support dropping columns from writable external tables.\nThis commit adds support for dropping columns in PXF writable external\ntables. The complexity of the implementation lies in the\n`pxfwritable_export` formatter. Add automation tests for altering PXF\nwritable external tables.", "committedDate": "2020-09-23T00:30:37Z", "type": "commit"}, {"oid": "ba4105151e844d016383f0968ad7ae556b3a6e16", "url": "https://github.com/greenplum-db/pxf/commit/ba4105151e844d016383f0968ad7ae556b3a6e16", "message": "Support dropping columns in PXF writable external tables\n\nPXF does not support dropping columns from writable external tables.\nThis commit adds support for dropping columns in PXF writable external\ntables. The complexity of the implementation lies in the\n`pxfwritable_export` formatter. Add automation tests for altering PXF\nwritable external tables.", "committedDate": "2020-09-23T00:30:37Z", "type": "forcePushed"}]}