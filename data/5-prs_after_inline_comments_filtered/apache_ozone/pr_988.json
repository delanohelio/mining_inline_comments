{"pr_number": 988, "pr_title": "HDDS-3681. Recon: Add support to store file size counts in each volum\u2026", "pr_createdAt": "2020-05-28T22:29:40Z", "pr_url": "https://github.com/apache/ozone/pull/988", "timeline": [{"oid": "c9bf97bea0e8ddb7292abc1ded33d90af525e30c", "url": "https://github.com/apache/ozone/commit/c9bf97bea0e8ddb7292abc1ded33d90af525e30c", "message": "HDDS-3681. Recon: Add support to store file size counts in each volume/bucket", "committedDate": "2020-05-28T22:26:04Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYxMDA2Ng==", "url": "https://github.com/apache/ozone/pull/988#discussion_r432610066", "bodyText": "Do we know if 64 is the actual volume & bucket name length limit as enforced by OM? If not, we have to change this to handle longer lengths.", "author": "avijayanhwx", "createdAt": "2020-05-29T16:49:20Z", "path": "hadoop-ozone/recon-codegen/src/main/java/org/hadoop/ozone/recon/schema/UtilizationSchemaDefinition.java", "diffHunk": "@@ -83,11 +86,17 @@ private void createClusterGrowthTable(Connection conn) {\n   }\n \n   private void createFileSizeCountTable(Connection conn) {\n-    DSL.using(conn).createTableIfNotExists(FILE_COUNT_BY_SIZE_TABLE_NAME)\n+    dslContext.createTableIfNotExists(FILE_COUNT_BY_SIZE_TABLE_NAME)\n+        .column(\"volume\", SQLDataType.VARCHAR(64))", "originalCommit": "c9bf97bea0e8ddb7292abc1ded33d90af525e30c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY3MDc5Nw==", "url": "https://github.com/apache/ozone/pull/988#discussion_r432670797", "bodyText": "Yes, verified that the max character limit of volume name and bucket name is 63 characters.", "author": "vivekratnavel", "createdAt": "2020-05-29T18:44:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYxMDA2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYxODgwOA==", "url": "https://github.com/apache/ozone/pull/988#discussion_r432618808", "bodyText": "Good test to see how much we can handle!", "author": "avijayanhwx", "createdAt": "2020-05-29T17:02:31Z", "path": "hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/tasks/TestFileSizeCountTask.java", "diffHunk": "@@ -206,10 +216,189 @@ public void testProcess() {\n         Arrays.asList(updateEvent, putEvent, deleteEvent));\n     fileSizeCountTask.process(omUpdateEventBatch);\n \n-    upperBoundCount = fileSizeCountTask.getUpperBoundCount();\n-    assertEquals(1, upperBoundCount[0]); // newKey\n-    assertEquals(0, upperBoundCount[1]); // deletedKey\n-    assertEquals(0, upperBoundCount[4]); // updatedKey old\n-    assertEquals(1, upperBoundCount[6]); // updatedKey new\n+    assertEquals(4, fileCountBySizeDao.count());\n+    recordToFind.value3(1024L);\n+    assertEquals(1, fileCountBySizeDao.findById(recordToFind)\n+        .getCount().longValue());\n+    recordToFind.value3(2048L);\n+    assertEquals(0, fileCountBySizeDao.findById(recordToFind)\n+        .getCount().longValue());\n+    recordToFind.value3(16384L);\n+    assertEquals(0, fileCountBySizeDao.findById(recordToFind)\n+        .getCount().longValue());\n+    recordToFind.value3(65536L);\n+    assertEquals(1, fileCountBySizeDao.findById(recordToFind)\n+        .getCount().longValue());\n+  }\n+\n+  @Test\n+  public void testReprocessAtScale() throws IOException {", "originalCommit": "c9bf97bea0e8ddb7292abc1ded33d90af525e30c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYyMDc4Mw==", "url": "https://github.com/apache/ozone/pull/988#discussion_r432620783", "bodyText": "Since we don't read everything from the DB at init time, 'fileSizeCountMap' can be a local variable created inside the 'process' and 'reprocess' methods.", "author": "avijayanhwx", "createdAt": "2020-05-29T17:06:16Z", "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/tasks/FileSizeCountTask.java", "diffHunk": "@@ -49,33 +52,28 @@\n   private static final Logger LOG =\n       LoggerFactory.getLogger(FileSizeCountTask.class);\n \n-  private int maxBinSize = -1;\n-  private long maxFileSizeUpperBound = 1125899906842624L; // 1 PB\n-  private long[] upperBoundCount;\n-  private long oneKb = 1024L;\n+  // 1125899906842624L = 1PB\n+  private static final long MAX_FILE_SIZE_UPPER_BOUND = 1125899906842624L;\n   private FileCountBySizeDao fileCountBySizeDao;\n+  // Map to store file counts in each <volume,bucket,fileSizeUpperBound>\n+  private Map<FileSizeCountKey, Long> fileSizeCountMap;", "originalCommit": "c9bf97bea0e8ddb7292abc1ded33d90af525e30c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjc1NDMxNQ==", "url": "https://github.com/apache/ozone/pull/988#discussion_r432754315", "bodyText": "Moving it to local variable would then require writeCountsToDB, handlePutKeyEvent and handleDeleteKeyEvent methods to take Map<FileSizeCountKey, Long> fileSizeCountMap as another argument. Currently, initializing this map in reprocess and process is just enough since both methods will never be called at the same time.", "author": "vivekratnavel", "createdAt": "2020-05-29T21:47:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYyMDc4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzA2MDA3Nw==", "url": "https://github.com/apache/ozone/pull/988#discussion_r433060077", "bodyText": "IMO, it is OK to have the handleDeleteKeyEvent & handlePutKeyEvent and writeCountsToDB to take the map as a parameter. They are meant to be stateless helper methods that act on the input given to them. In the current implementation, there is an assumption that the task's implementation makes of the higher level caller, which may not be true in the future.", "author": "avijayanhwx", "createdAt": "2020-06-01T06:18:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYyMDc4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYyMzkzMw==", "url": "https://github.com/apache/ozone/pull/988#discussion_r432623933", "bodyText": "Can we add an endpoint for getFileCounts(volume, bucket, fileSize(Default = null)) here?", "author": "avijayanhwx", "createdAt": "2020-05-29T17:11:00Z", "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/UtilizationEndpoint.java", "diffHunk": "@@ -34,7 +34,7 @@\n  */\n @Path(\"/utilization\")\n @Produces(MediaType.APPLICATION_JSON)\n-public class UtilizationService {\n+public class UtilizationEndpoint {", "originalCommit": "c9bf97bea0e8ddb7292abc1ded33d90af525e30c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "e550e172c9d40154e47208a553a8825bce0d6ba0", "url": "https://github.com/apache/ozone/commit/e550e172c9d40154e47208a553a8825bce0d6ba0", "message": "support query params for filecounts endpoint", "committedDate": "2020-05-29T22:31:48Z", "type": "commit"}, {"oid": "7a7079b74387383106b3cde1800acda1801f8862", "url": "https://github.com/apache/ozone/commit/7a7079b74387383106b3cde1800acda1801f8862", "message": "Empty commit to retrigger CI checks.", "committedDate": "2020-06-01T17:38:28Z", "type": "commit"}, {"oid": "6f696119a195501f3a422efa1053f6e9f3d10b09", "url": "https://github.com/apache/ozone/commit/6f696119a195501f3a422efa1053f6e9f3d10b09", "message": "Fix review comments.", "committedDate": "2020-06-01T19:42:50Z", "type": "commit"}, {"oid": "c9a9f641a988345b91752a3f389370d0e6c4dc03", "url": "https://github.com/apache/ozone/commit/c9a9f641a988345b91752a3f389370d0e6c4dc03", "message": "Merge remote-tracking branch 'apache/master' into HDDS-3681", "committedDate": "2020-06-02T19:15:39Z", "type": "commit"}]}