{"pr_number": 1613, "pr_title": "HDDS-4480. Implement OM Prepare Request/Response.", "pr_createdAt": "2020-11-23T23:43:25Z", "pr_url": "https://github.com/apache/ozone/pull/1613", "timeline": [{"oid": "f8e1ddd65939ff9524eaddc5a430408ab9358577", "url": "https://github.com/apache/ozone/commit/f8e1ddd65939ff9524eaddc5a430408ab9358577", "message": "Outline new request class", "committedDate": "2020-11-17T13:44:32Z", "type": "commit"}, {"oid": "4709e9fe046bdf9d1515126cdee014e4792dc4e3", "url": "https://github.com/apache/ozone/commit/4709e9fe046bdf9d1515126cdee014e4792dc4e3", "message": "Fix typo in proto definitions", "committedDate": "2020-11-17T14:05:18Z", "type": "commit"}, {"oid": "f6206b50d04fe35859d8e9f5a5ba94d373db8f04", "url": "https://github.com/apache/ozone/commit/f6206b50d04fe35859d8e9f5a5ba94d373db8f04", "message": "Add Response class for prepare for upgrade", "committedDate": "2020-11-17T14:05:35Z", "type": "commit"}, {"oid": "a24420f13d89ea16af8943f0faa1391690d9b998", "url": "https://github.com/apache/ozone/commit/a24420f13d89ea16af8943f0faa1391690d9b998", "message": "Get RatisUpgradeUtils changes from original prepare upgrade feature", "committedDate": "2020-11-18T18:17:32Z", "type": "commit"}, {"oid": "cfa75ee02770203130c40f842ac727957e868260", "url": "https://github.com/apache/ozone/commit/cfa75ee02770203130c40f842ac727957e868260", "message": "Switch ratis snapshot to newer version", "committedDate": "2020-11-18T18:43:51Z", "type": "commit"}, {"oid": "4c177fa3fa8e51b16094aa8194d961abdea5668f", "url": "https://github.com/apache/ozone/commit/4c177fa3fa8e51b16094aa8194d961abdea5668f", "message": "Remove --prepareForUpgrade startup flag\n\nOM now has prepared state internally that is not set on startup.\nA similar startup flag can be re-introduced when the --upgrade mode is implemented to take the OMs out of prepare with the new bits.", "committedDate": "2020-11-18T21:21:28Z", "type": "commit"}, {"oid": "9a5f333c6156818d02e2230accefd4c2779afe71", "url": "https://github.com/apache/ozone/commit/9a5f333c6156818d02e2230accefd4c2779afe71", "message": "Call new OM Prepare method to do purge and snapshot", "committedDate": "2020-11-18T21:58:19Z", "type": "commit"}, {"oid": "6b26a6c9c9db1e757eb02d49915a45cfc02db173", "url": "https://github.com/apache/ozone/commit/6b26a6c9c9db1e757eb02d49915a45cfc02db173", "message": "Remove requestAllowed method from OzoneManager\n\nThis can be added when preAppend changes are handled", "committedDate": "2020-11-18T22:00:00Z", "type": "commit"}, {"oid": "3a16d5f8dfe75df8e7e0800c4e3046cc4f974a87", "url": "https://github.com/apache/ozone/commit/3a16d5f8dfe75df8e7e0800c4e3046cc4f974a87", "message": "Fix typo in proto imports and declaration", "committedDate": "2020-11-19T16:46:26Z", "type": "commit"}, {"oid": "0b644600c7ce2efbe2e06ed42873c9dad6d827e6", "url": "https://github.com/apache/ozone/commit/0b644600c7ce2efbe2e06ed42873c9dad6d827e6", "message": "Update files to use new Ratis APIs after snapshot update", "committedDate": "2020-11-19T16:46:38Z", "type": "commit"}, {"oid": "e1bfa8e162c80c60d464f2b822a57c3c6643ef48", "url": "https://github.com/apache/ozone/commit/e1bfa8e162c80c60d464f2b822a57c3c6643ef48", "message": "Add missed Ratis upgrade fixes", "committedDate": "2020-11-19T19:58:28Z", "type": "commit"}, {"oid": "cefdb08c0a08a1971cf0400f21cd27818b3f8f6f", "url": "https://github.com/apache/ozone/commit/cefdb08c0a08a1971cf0400f21cd27818b3f8f6f", "message": "Add original prepare integration test\n\nMight be discarded for the one Aravindan already created.", "committedDate": "2020-11-19T21:52:18Z", "type": "commit"}, {"oid": "cfb578d69d33df396ad87deb0db7023b39367bb1", "url": "https://github.com/apache/ozone/commit/cfb578d69d33df396ad87deb0db7023b39367bb1", "message": "Add Prepare Response to proto", "committedDate": "2020-11-19T23:29:49Z", "type": "commit"}, {"oid": "6cf0cef13f68a960ca277cace073106a139145b5", "url": "https://github.com/apache/ozone/commit/6cf0cef13f68a960ca277cace073106a139145b5", "message": "Fix typo in comments", "committedDate": "2020-11-19T23:30:52Z", "type": "commit"}, {"oid": "99c9de139ef20b6e54c529ebe045ac1517c13822", "url": "https://github.com/apache/ozone/commit/99c9de139ef20b6e54c529ebe045ac1517c13822", "message": "Fix typo in response builder", "committedDate": "2020-11-19T23:32:09Z", "type": "commit"}, {"oid": "2433bddec9e9d83a0f8f2d0118bb901c54f299b0", "url": "https://github.com/apache/ozone/commit/2433bddec9e9d83a0f8f2d0118bb901c54f299b0", "message": "Initial draft of tests\n\nUnit test is minimal but passing.\nIntegration test still needs work.", "committedDate": "2020-11-19T23:32:21Z", "type": "commit"}, {"oid": "348eae2536368be69092d4d6ac18aa09dbcfa2a9", "url": "https://github.com/apache/ozone/commit/348eae2536368be69092d4d6ac18aa09dbcfa2a9", "message": "Add more robust (but failing) mini ozone cluster test", "committedDate": "2020-11-20T16:03:03Z", "type": "commit"}, {"oid": "ea88dfccd6282c83d2e3482ce6e9edc7974f0be3", "url": "https://github.com/apache/ozone/commit/ea88dfccd6282c83d2e3482ce6e9edc7974f0be3", "message": "Add (failing) test for calling prepare directly on OM with data", "committedDate": "2020-11-20T16:55:23Z", "type": "commit"}, {"oid": "454fa8dbd81607304f3dddfe77e0241880b54e3e", "url": "https://github.com/apache/ozone/commit/454fa8dbd81607304f3dddfe77e0241880b54e3e", "message": "Add passing test for prepare of one OM with no ratis transactions", "committedDate": "2020-11-20T19:13:43Z", "type": "commit"}, {"oid": "78eab948d23a26515d8fe93779ba62f52e55b565", "url": "https://github.com/apache/ozone/commit/78eab948d23a26515d8fe93779ba62f52e55b565", "message": "Fix NPE when preparing without transactions, and move prepare flag to correct place", "committedDate": "2020-11-20T20:32:47Z", "type": "commit"}, {"oid": "5eef0fdf8f175f37e57f248e498604b66d6baed4", "url": "https://github.com/apache/ozone/commit/5eef0fdf8f175f37e57f248e498604b66d6baed4", "message": "Remove todo comment", "committedDate": "2020-11-20T20:33:22Z", "type": "commit"}, {"oid": "1b6332c5750df9fba6ca78e2646ac5e0de3468b6", "url": "https://github.com/apache/ozone/commit/1b6332c5750df9fba6ca78e2646ac5e0de3468b6", "message": "Fix bug in s3 table cleanup (not introduced by this change)", "committedDate": "2020-11-20T23:16:01Z", "type": "commit"}, {"oid": "7ec4316998a5dae8bca8fdf17796f68f9dbe76e1", "url": "https://github.com/apache/ozone/commit/7ec4316998a5dae8bca8fdf17796f68f9dbe76e1", "message": "Add comment explaining logic in snapshot and sync logs method", "committedDate": "2020-11-20T23:17:08Z", "type": "commit"}, {"oid": "57559e07901e2a934428d5687e446fb59c206909", "url": "https://github.com/apache/ozone/commit/57559e07901e2a934428d5687e446fb59c206909", "message": "Passing Ratis integration test for prepare\n\nStill need to clean up OzoneManager", "committedDate": "2020-11-20T23:18:16Z", "type": "commit"}, {"oid": "4a6a861a8afa8097f4cbb35b16cd7af5340c16fb", "url": "https://github.com/apache/ozone/commit/4a6a861a8afa8097f4cbb35b16cd7af5340c16fb", "message": "Add imports to make code more readable", "committedDate": "2020-11-23T22:48:11Z", "type": "commit"}, {"oid": "88b45db1b2b02be3a92f2412d325c4b880a5e55f", "url": "https://github.com/apache/ozone/commit/88b45db1b2b02be3a92f2412d325c4b880a5e55f", "message": "Fix old class header", "committedDate": "2020-11-23T22:48:33Z", "type": "commit"}, {"oid": "24b3497124b310d640fec70100f6c19f2f466431", "url": "https://github.com/apache/ozone/commit/24b3497124b310d640fec70100f6c19f2f466431", "message": "Add wait for double buffer flush in prepare request, and more robust testing\n\nThe complex test case with a downed OM is still failing due to issues with mini ozone cluster.", "committedDate": "2020-11-23T22:54:39Z", "type": "commit"}, {"oid": "2ce04cc781ccfeee73419ebf730c117d18c926e0", "url": "https://github.com/apache/ozone/commit/2ce04cc781ccfeee73419ebf730c117d18c926e0", "message": "Comment out failing test and update comments", "committedDate": "2020-11-23T23:00:05Z", "type": "commit"}, {"oid": "212c03bd4189add41a6d6811c0ad076d863e41cf", "url": "https://github.com/apache/ozone/commit/212c03bd4189add41a6d6811c0ad076d863e41cf", "message": "Rename old uses of PrepareForUpgrade to Prepare", "committedDate": "2020-11-23T23:21:51Z", "type": "commit"}, {"oid": "7ed9ec08503c3804d04e64e9b18ec911bc99c413", "url": "https://github.com/apache/ozone/commit/7ed9ec08503c3804d04e64e9b18ec911bc99c413", "message": "Fix some checkstyle violations", "committedDate": "2020-11-23T23:26:14Z", "type": "commit"}, {"oid": "a3bdb40ea4f08e1e6dd373b61c86ea66560a642c", "url": "https://github.com/apache/ozone/commit/a3bdb40ea4f08e1e6dd373b61c86ea66560a642c", "message": "Fix checkstyle violations and remove unused OM code from older iteration", "committedDate": "2020-11-23T23:32:29Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTYwNDE2Nw==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r529604167", "bodyText": "Transaction entry added in double buffer is async flushed to db. Shall we pass transactionLogIndex to double check and make sure previous txns be applied.  I mean we would better to double check and ensure that snapshot index equals current prepare transactionLogIndex.", "author": "linyiqun", "createdAt": "2020-11-24T14:51:57Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,108 @@\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.hdds.ratis.RatisUpgradeUtils;\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final long DOUBLE_BUFFER_FLUSH_TIMEOUT_SECONDS = 5 * 60;\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final long DOUBLE_BUFFER_FLUSH_CHECK_SECONDS = 1;\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareForUpgradeResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      OzoneManagerStateMachine omStateMachine =\n+          omRatisServer.getOmStateMachine();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      RatisUpgradeUtils.waitForAllTxnsApplied(omStateMachine, serverImpl,\n+          DOUBLE_BUFFER_FLUSH_TIMEOUT_SECONDS,\n+          DOUBLE_BUFFER_FLUSH_CHECK_SECONDS);", "originalCommit": "a3bdb40ea4f08e1e6dd373b61c86ea66560a642c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDYwMjEwMw==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r530602103", "bodyText": "Yes Yiqun, you are right. This was an early draft of the feature. Please see the new code and let me know if this resolves your concern.", "author": "errose28", "createdAt": "2020-11-25T19:34:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTYwNDE2Nw=="}], "type": "inlineReview"}, {"oid": "f259f39cb483cf2bb9e955d8c9a317fde0d89914", "url": "https://github.com/apache/ozone/commit/f259f39cb483cf2bb9e955d8c9a317fde0d89914", "message": "Merge branch 'HDDS-3698-upgrade' into HDDS-4480\n\n* HDDS-3698-upgrade: (46 commits)\n  HDDS-4468. Fix Goofys listBucket large than 1000 objects will stuck forever (#1595)\n  HDDS-4417. Simplify Ozone client code with configuration object -- addendum (#1581)\n  HDDS-4476. Improve the ZH translation of the HA.md in doc. (#1597)\n  HDDS-4432. Update Ratis version to latest snapshot. (#1586)\n  HDDS-4488. Open RocksDB read only when loading containers at Datanode startup (#1605)\n  HDDS-4478. Large deletedKeyset slows down OM via listStatus. (#1598)\n  HDDS-4452. findbugs.sh couldn't be executed after a full build (#1576)\n  HDDS-4427. Avoid ContainerCache in ContainerReader at Datanode startup (#1549)\n  HDDS-4448. Duplicate refreshPipeline in listStatus (#1569)\n  HDDS-4450. Cannot run ozone if HADOOP_HOME points to Hadoop install (#1572)\n  HDDS-4346.Ozone specific Trash Policy (#1535)\n  HDDS-4426. SCM should create transactions using all blocks received from OM (#1561)\n  HDDS-4399. Safe mode rule for piplelines should only consider open pipelines. (#1526)\n  HDDS-4367. Configuration for deletion service intervals should be different for OM, SCM and datanodes (#1573)\n  HDDS-4462. Add --frozen-lockfile to pnpm install to prevent ozone-recon-web/pnpm-lock.yaml from being updated automatically (#1589)\n  HDDS-4082. Create ZH translation of HA.md in doc. (#1591)\n  HDDS-4464. Upgrade httpclient version due to CVE-2020-13956. (#1590)\n  HDDS-4467. Acceptance test fails due to new Hadoop 3 image (#1594)\n  HDDS-4466. Update url in .asf.yaml to use TLP project (#1592)\n  HDDS-4458. Fix Max Transaction ID value in OM. (#1585)\n  ...", "committedDate": "2020-11-24T15:16:35Z", "type": "commit"}, {"oid": "30c405dd3089aa470d2f99544bc422f101ad1851", "url": "https://github.com/apache/ozone/commit/30c405dd3089aa470d2f99544bc422f101ad1851", "message": "Fix build errors, and clean up code formatting", "committedDate": "2020-11-24T16:07:14Z", "type": "commit"}, {"oid": "a4247f166fecfa584210fd3ea0b523c96f6ddede", "url": "https://github.com/apache/ozone/commit/a4247f166fecfa584210fd3ea0b523c96f6ddede", "message": "Add fully remove s3 table and add unit test", "committedDate": "2020-11-24T17:01:03Z", "type": "commit"}, {"oid": "8f9e80848087f25d1b72206f55ce4ed1bf70347f", "url": "https://github.com/apache/ozone/commit/8f9e80848087f25d1b72206f55ce4ed1bf70347f", "message": "Fix rat violation", "committedDate": "2020-11-24T17:04:40Z", "type": "commit"}, {"oid": "ad28431d6577868a9c84dd157d44090b18a389ed", "url": "https://github.com/apache/ozone/commit/ad28431d6577868a9c84dd157d44090b18a389ed", "message": "Fix double buffer wait and take snapshot outside of request's applyTxn", "committedDate": "2020-11-24T21:35:22Z", "type": "commit"}, {"oid": "90a3457e936457e8173b7e8f63a161eb12b52af0", "url": "https://github.com/apache/ozone/commit/90a3457e936457e8173b7e8f63a161eb12b52af0", "message": "Move all prepare logic back inside the prepare request\n\nAlso move the snapshot method out of RatisUpgradeUtils, meaning it is no longer used.", "committedDate": "2020-11-25T17:09:14Z", "type": "commit"}, {"oid": "28c2690879e9a9aaaa148c9e119d0203bb61c1d0", "url": "https://github.com/apache/ozone/commit/28c2690879e9a9aaaa148c9e119d0203bb61c1d0", "message": "Minor readability change", "committedDate": "2020-11-25T18:58:37Z", "type": "commit"}, {"oid": "d69fdea088d883e0f2b78b2c8f9fa66d2d7aa849", "url": "https://github.com/apache/ozone/commit/d69fdea088d883e0f2b78b2c8f9fa66d2d7aa849", "message": "Fix failures in tests with all 3 OMs up", "committedDate": "2020-11-25T18:59:52Z", "type": "commit"}, {"oid": "ff15f3e4e67ae79a60e23bc8f8624631dc4ab6d0", "url": "https://github.com/apache/ozone/commit/ff15f3e4e67ae79a60e23bc8f8624631dc4ab6d0", "message": "Remove unit test for prepare request\n\nBecause prepare request needs Ratis, we can only test it with integration tests and mini ozone cluster.", "committedDate": "2020-11-25T19:01:19Z", "type": "commit"}, {"oid": "3a6a9d2c22d25e757d80028288a39cb11e048668", "url": "https://github.com/apache/ozone/commit/3a6a9d2c22d25e757d80028288a39cb11e048668", "message": "Fix checkstyle violation", "committedDate": "2020-11-25T19:07:33Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDYzNTQ1NQ==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r530635455", "bodyText": "We need to have the RPC server running even in \"Prepared\" state. This if condition can be removed.", "author": "avijayanhwx", "createdAt": "2020-11-25T20:48:36Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "diffHunk": "@@ -1239,7 +1208,7 @@ public void start() throws IOException {\n       LOG.error(\"OM HttpServer failed to start.\", ex);\n     }\n \n-    if (!prepareForUpgrade) {\n+    if (!isPrepared) {", "originalCommit": "3a6a9d2c22d25e757d80028288a39cb11e048668", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDYzODQ2Ng==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r530638466", "bodyText": "3 second timeout maybe a bit aggressive. Can we increase it to 30seconds?", "author": "avijayanhwx", "createdAt": "2020-11-25T20:56:11Z", "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOzoneManagerPrepare.java", "diffHunk": "@@ -0,0 +1,288 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om;\n+\n+import static java.nio.charset.StandardCharsets.UTF_8;\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+\n+import java.io.File;\n+import java.nio.file.Paths;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.UUID;\n+\n+import org.apache.hadoop.hdds.client.ReplicationFactor;\n+import org.apache.hadoop.hdds.client.ReplicationType;\n+import org.apache.hadoop.ozone.MiniOzoneHAClusterImpl;\n+import org.apache.hadoop.ozone.client.ObjectStore;\n+import org.apache.hadoop.ozone.client.OzoneClient;\n+import org.apache.hadoop.ozone.client.OzoneClientFactory;\n+import org.apache.hadoop.ozone.client.OzoneVolume;\n+import org.apache.hadoop.ozone.client.io.OzoneOutputStream;\n+import org.apache.hadoop.ozone.container.ContainerTestHelper;\n+import org.apache.hadoop.ozone.container.TestHelper;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareRequest;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * Test OM prepare against actual mini cluster.\n+ */\n+public class TestOzoneManagerPrepare extends TestOzoneManagerHA {\n+\n+  private final String keyPrefix = \"key\";\n+\n+  /**\n+   * Calls prepare on all OMs when they have no transaction information.\n+   * Checks that they are brought into prepare mode successfully.\n+   */\n+  @Test\n+  public void testPrepareWithoutTransactions() throws Exception {\n+    MiniOzoneHAClusterImpl cluster = getCluster();\n+    OzoneManager leader = cluster.getOMLeader();\n+    OMResponse omResponse =\n+        leader.getOmRatisServer().submitRequest(buildPrepareRequest());\n+    // Get the log index of the prepare request.\n+    long prepareRequestLogIndex =\n+        omResponse.getPrepareResponse().getTxnID();\n+\n+    // Prepare response processing is included in the snapshot,\n+    // giving index of 1.\n+    Assert.assertEquals(1, prepareRequestLogIndex);\n+    for (OzoneManager om: cluster.getOzoneManagersList()) {\n+      // Leader should be prepared as soon as it returns response.\n+      if (om == leader) {\n+        checkPrepared(om, prepareRequestLogIndex);\n+      } else {\n+        waitAndCheckPrepared(om, prepareRequestLogIndex);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Writes data to the cluster via the leader OM, and then prepares it.\n+   * Checks that every OM is prepared successfully.\n+   */\n+  @Test\n+  public void testPrepareWithTransactions() throws Exception {\n+    MiniOzoneHAClusterImpl cluster = getCluster();\n+    OzoneClient ozClient = OzoneClientFactory.getRpcClient(getConf());\n+\n+    String volumeName = UUID.randomUUID().toString();\n+    String bucketName = UUID.randomUUID().toString();\n+    ObjectStore store = ozClient.getObjectStore();\n+\n+    store.createVolume(volumeName);\n+    OzoneVolume volume = store.getVolume(volumeName);\n+    volume.createBucket(bucketName);\n+\n+    Set<String> writtenKeys = new HashSet<>();\n+    for (int i = 1; i <= 10; i++) {\n+      String keyName = keyPrefix + i;\n+      writeTestData(store, volumeName, bucketName, keyName);\n+      writtenKeys.add(keyName);\n+    }\n+\n+    OzoneManager leader = cluster.getOMLeader();\n+    OMResponse omResponse =\n+        leader.getOmRatisServer().submitRequest(buildPrepareRequest());\n+    // Get the log index of the prepare request.\n+    long prepareRequestLogIndex =\n+        omResponse.getPrepareResponse().getTxnID();\n+\n+    // Make sure all OMs are prepared and all OMs still have their data.\n+    for (OzoneManager om: cluster.getOzoneManagersList()) {\n+      // Leader should be prepared as soon as it returns response.\n+      if (om == leader) {\n+        checkPrepared(om, prepareRequestLogIndex);\n+      } else {\n+        waitAndCheckPrepared(om, prepareRequestLogIndex);\n+      }\n+\n+      List<OmKeyInfo> keys = om.getMetadataManager().listKeys(volumeName,\n+          bucketName, null, keyPrefix, 100);\n+\n+      Assert.assertEquals(writtenKeys.size(), keys.size());\n+      for (OmKeyInfo keyInfo: keys) {\n+        Assert.assertTrue(writtenKeys.contains(keyInfo.getKeyName()));\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Writes data to the cluster.\n+   * Shuts down one OM.\n+   * Writes more data to the cluster.\n+   * Submits prepare as ratis request.\n+   * Checks that two live OMs are prepared.\n+   * Revives the third OM\n+   * Checks that third OM received all transactions and is prepared.\n+   * @throws Exception\n+   */\n+  // TODO: Fix this test so it passes.\n+  // @Test\n+  public void testPrepareDownedOM() throws Exception {\n+    // Index of the OM that will be shut down during this test.\n+    final int shutdownOMIndex = 2;\n+\n+    MiniOzoneHAClusterImpl cluster = getCluster();\n+    OzoneClient ozClient = OzoneClientFactory.getRpcClient(getConf());\n+\n+    String volumeName = UUID.randomUUID().toString();\n+    String bucketName = UUID.randomUUID().toString();\n+    ObjectStore store = ozClient.getObjectStore();\n+\n+    // Create keys with all 3 OMs up.\n+    store.createVolume(volumeName);\n+    OzoneVolume volume = store.getVolume(volumeName);\n+    volume.createBucket(bucketName);\n+\n+    Set<String> writtenKeys = new HashSet<>();\n+    for (int i = 1; i <= 50; i++) {\n+      String keyName = keyPrefix + i;\n+      writeTestData(store, volumeName, bucketName, keyName);\n+      writtenKeys.add(keyName);\n+    }\n+\n+    // Shut down one OM.\n+    cluster.stopOzoneManager(shutdownOMIndex);\n+    OzoneManager downedOM = cluster.getOzoneManager(shutdownOMIndex);\n+    Assert.assertFalse(downedOM.isRunning());\n+\n+    // Write keys with the remaining OMs up.\n+    for (int i = 51; i <= 100; i++) {\n+      String keyName = keyPrefix + i;\n+      writeTestData(store, volumeName, bucketName, keyName);\n+      writtenKeys.add(keyName);\n+    }\n+\n+    // Submit prepare request via Ratis.\n+    OzoneManager leaderOM = cluster.getOMLeader();\n+    long prepareIndex =\n+        leaderOM.getOmRatisServer().submitRequest(buildPrepareRequest())\n+            .getPrepareResponse()\n+            .getTxnID();\n+\n+    // Check that the two live OMs are prepared.\n+    for (OzoneManager om: cluster.getOzoneManagersList()) {\n+      if (om == leaderOM) {\n+        // Leader should have been prepared after we got the response.\n+        checkPrepared(om, prepareIndex);\n+      } else if (om != downedOM) {\n+        // Follower may still be applying transactions.\n+        waitAndCheckPrepared(om, prepareIndex);\n+      }\n+    }\n+\n+    // Restart the downed OM and wait for it to catch up.\n+    // Since prepare was the last Ratis transaction, it should have all data\n+    // it missed once it receives the prepare transaction.\n+    cluster.restartOzoneManager(downedOM, true);\n+    // Wait for other OMs to catch this one up on transactions.\n+    LambdaTestUtils.await(3000, 1000,", "originalCommit": "3a6a9d2c22d25e757d80028288a39cb11e048668", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDY5NjE4OQ==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r530696189", "bodyText": "Sure, done.", "author": "errose28", "createdAt": "2020-11-25T23:44:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDYzODQ2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDYzOTUxNg==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r530639516", "bodyText": "Let's add a logFilesPresentInRatisPeer 'true' assert here so that we start from an 'expected' state and also to make sure that there are no bugs in that method itself :).", "author": "avijayanhwx", "createdAt": "2020-11-25T20:58:48Z", "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOzoneManagerPrepare.java", "diffHunk": "@@ -0,0 +1,288 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om;\n+\n+import static java.nio.charset.StandardCharsets.UTF_8;\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+\n+import java.io.File;\n+import java.nio.file.Paths;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.UUID;\n+\n+import org.apache.hadoop.hdds.client.ReplicationFactor;\n+import org.apache.hadoop.hdds.client.ReplicationType;\n+import org.apache.hadoop.ozone.MiniOzoneHAClusterImpl;\n+import org.apache.hadoop.ozone.client.ObjectStore;\n+import org.apache.hadoop.ozone.client.OzoneClient;\n+import org.apache.hadoop.ozone.client.OzoneClientFactory;\n+import org.apache.hadoop.ozone.client.OzoneVolume;\n+import org.apache.hadoop.ozone.client.io.OzoneOutputStream;\n+import org.apache.hadoop.ozone.container.ContainerTestHelper;\n+import org.apache.hadoop.ozone.container.TestHelper;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareRequest;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * Test OM prepare against actual mini cluster.\n+ */\n+public class TestOzoneManagerPrepare extends TestOzoneManagerHA {\n+\n+  private final String keyPrefix = \"key\";\n+\n+  /**\n+   * Calls prepare on all OMs when they have no transaction information.\n+   * Checks that they are brought into prepare mode successfully.\n+   */\n+  @Test\n+  public void testPrepareWithoutTransactions() throws Exception {\n+    MiniOzoneHAClusterImpl cluster = getCluster();\n+    OzoneManager leader = cluster.getOMLeader();\n+    OMResponse omResponse =\n+        leader.getOmRatisServer().submitRequest(buildPrepareRequest());\n+    // Get the log index of the prepare request.\n+    long prepareRequestLogIndex =\n+        omResponse.getPrepareResponse().getTxnID();\n+\n+    // Prepare response processing is included in the snapshot,\n+    // giving index of 1.\n+    Assert.assertEquals(1, prepareRequestLogIndex);\n+    for (OzoneManager om: cluster.getOzoneManagersList()) {\n+      // Leader should be prepared as soon as it returns response.\n+      if (om == leader) {\n+        checkPrepared(om, prepareRequestLogIndex);\n+      } else {\n+        waitAndCheckPrepared(om, prepareRequestLogIndex);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Writes data to the cluster via the leader OM, and then prepares it.\n+   * Checks that every OM is prepared successfully.\n+   */\n+  @Test\n+  public void testPrepareWithTransactions() throws Exception {\n+    MiniOzoneHAClusterImpl cluster = getCluster();\n+    OzoneClient ozClient = OzoneClientFactory.getRpcClient(getConf());\n+\n+    String volumeName = UUID.randomUUID().toString();\n+    String bucketName = UUID.randomUUID().toString();\n+    ObjectStore store = ozClient.getObjectStore();\n+\n+    store.createVolume(volumeName);\n+    OzoneVolume volume = store.getVolume(volumeName);\n+    volume.createBucket(bucketName);\n+\n+    Set<String> writtenKeys = new HashSet<>();\n+    for (int i = 1; i <= 10; i++) {\n+      String keyName = keyPrefix + i;\n+      writeTestData(store, volumeName, bucketName, keyName);\n+      writtenKeys.add(keyName);\n+    }\n+\n+    OzoneManager leader = cluster.getOMLeader();\n+    OMResponse omResponse =\n+        leader.getOmRatisServer().submitRequest(buildPrepareRequest());\n+    // Get the log index of the prepare request.\n+    long prepareRequestLogIndex =\n+        omResponse.getPrepareResponse().getTxnID();\n+\n+    // Make sure all OMs are prepared and all OMs still have their data.\n+    for (OzoneManager om: cluster.getOzoneManagersList()) {\n+      // Leader should be prepared as soon as it returns response.\n+      if (om == leader) {\n+        checkPrepared(om, prepareRequestLogIndex);\n+      } else {\n+        waitAndCheckPrepared(om, prepareRequestLogIndex);\n+      }\n+\n+      List<OmKeyInfo> keys = om.getMetadataManager().listKeys(volumeName,\n+          bucketName, null, keyPrefix, 100);\n+\n+      Assert.assertEquals(writtenKeys.size(), keys.size());\n+      for (OmKeyInfo keyInfo: keys) {\n+        Assert.assertTrue(writtenKeys.contains(keyInfo.getKeyName()));\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Writes data to the cluster.\n+   * Shuts down one OM.\n+   * Writes more data to the cluster.\n+   * Submits prepare as ratis request.\n+   * Checks that two live OMs are prepared.\n+   * Revives the third OM\n+   * Checks that third OM received all transactions and is prepared.\n+   * @throws Exception\n+   */\n+  // TODO: Fix this test so it passes.\n+  // @Test\n+  public void testPrepareDownedOM() throws Exception {\n+    // Index of the OM that will be shut down during this test.\n+    final int shutdownOMIndex = 2;\n+\n+    MiniOzoneHAClusterImpl cluster = getCluster();\n+    OzoneClient ozClient = OzoneClientFactory.getRpcClient(getConf());\n+\n+    String volumeName = UUID.randomUUID().toString();\n+    String bucketName = UUID.randomUUID().toString();\n+    ObjectStore store = ozClient.getObjectStore();\n+\n+    // Create keys with all 3 OMs up.\n+    store.createVolume(volumeName);\n+    OzoneVolume volume = store.getVolume(volumeName);\n+    volume.createBucket(bucketName);\n+\n+    Set<String> writtenKeys = new HashSet<>();\n+    for (int i = 1; i <= 50; i++) {\n+      String keyName = keyPrefix + i;\n+      writeTestData(store, volumeName, bucketName, keyName);\n+      writtenKeys.add(keyName);\n+    }\n+\n+    // Shut down one OM.\n+    cluster.stopOzoneManager(shutdownOMIndex);\n+    OzoneManager downedOM = cluster.getOzoneManager(shutdownOMIndex);\n+    Assert.assertFalse(downedOM.isRunning());\n+\n+    // Write keys with the remaining OMs up.\n+    for (int i = 51; i <= 100; i++) {\n+      String keyName = keyPrefix + i;\n+      writeTestData(store, volumeName, bucketName, keyName);\n+      writtenKeys.add(keyName);\n+    }\n+", "originalCommit": "3a6a9d2c22d25e757d80028288a39cb11e048668", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDY5NjM4Nw==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r530696387", "bodyText": "Added this check on all OMs in both the tests that have transactions (even though one is commented out and does not run).", "author": "errose28", "createdAt": "2020-11-25T23:45:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDYzOTUxNg=="}], "type": "inlineReview"}, {"oid": "fd4fe4f43eee2a9d261e72b397bd5cedbcc827f6", "url": "https://github.com/apache/ozone/commit/fd4fe4f43eee2a9d261e72b397bd5cedbcc827f6", "message": "Add fixes from code review\n\nIncrease test timeout to 30 seconds.\nAssert logs are present before prepare in tests.\nLeave RPC server running in prepared state.", "committedDate": "2020-11-25T23:42:09Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjE1OTQzNg==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r532159436", "bodyText": "Not a comment for this PR, another TODO thing I am thinking: After this prepare request be executed, OM should  reject subsequent requests immediately, how do we implement this? Exit OM and use upgrade flag to restart OM?", "author": "linyiqun", "createdAt": "2020-11-29T05:43:03Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,196 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      takeSnapshotAndPurgeLogs(serverImpl);\n+\n+      // TODO: Create marker file with txn index.\n+", "originalCommit": "fd4fe4f43eee2a9d261e72b397bd5cedbcc827f6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjY4MjUyOA==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r532682528", "bodyText": "Subsequent requests will be rejected by the leader using a gate in the preAppend step. This will will be done in another Jira. See HDDS-4470 for the design document and flow diagram of the overall prepare approach. This also documents how the upgrade startup flag or cancel prepare request (to be implemented in following Jiras) can be used to take the OM out of prepare mode.", "author": "errose28", "createdAt": "2020-11-30T15:29:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjE1OTQzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAzMjYxOA==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533032618", "bodyText": "Okay, will have a look for this. Thanks, @errose28 .", "author": "linyiqun", "createdAt": "2020-12-01T02:30:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjE1OTQzNg=="}], "type": "inlineReview"}, {"oid": "0c82642283718163a8a31853c64e8e0798c48271", "url": "https://github.com/apache/ozone/commit/0c82642283718163a8a31853c64e8e0798c48271", "message": "Fix checkstyle violation", "committedDate": "2020-11-30T15:40:17Z", "type": "commit"}, {"oid": "3de786e23c6778a7b265ab5b421a2ad11eaf40d3", "url": "https://github.com/apache/ozone/commit/3de786e23c6778a7b265ab5b421a2ad11eaf40d3", "message": "Retrigger CI", "committedDate": "2020-11-30T22:14:29Z", "type": "commit"}, {"oid": "ced3350e8caec9bd9ce7224a1319b954407a5026", "url": "https://github.com/apache/ozone/commit/ced3350e8caec9bd9ce7224a1319b954407a5026", "message": "Merge branch 'HDDS-3698-upgrade' into HDDS-4480\n\n* HDDS-3698-upgrade:\n  HDDS-4429. Create unit test for SimpleContainerDownloader. (#1551)\n  HDDS-4461. Reuse compiled binaries in acceptance test (#1588)\n  HDDS-4511: Avoiding StaleNodeHandler to take effect in TestDeleteWithSlowFollower. (#1625)\n  HDDS-4510. SCM can avoid creating RetriableDatanodeEventWatcher for deletion command ACK (#1626)\n  HDDS-3363. Intermittent failure in testContainerImportExport (#1618)\n  HDDS-4370. Datanode deletion service can avoid storing deleted blocks. (#1620)\n  HDDS-4512. Remove unused netty3 transitive dependency (#1627)\n  HDDS-4481. With HA OM can send deletion blocks to SCM multiple times. (#1608)\n  HDDS-4487. SCM can avoid using RETRIABLE_DATANODE_COMMAND for datanode deletion commands. (#1621)\n  HDDS-4471. GrpcOutputStream length can overflow (#1617)\n  HDDS-4308. Fix issue with quota update (#1489)\n  HDDS-4392. [DOC] Add Recon architecture to docs (#1602)\n  HDDS-4501. Reload OM State fail should terminate OM for any exceptions. (#1622)\n  HDDS-4492. CLI flag --quota should default to 'spaceQuota' to preserve backward compatibility. (#1609)\n  HDDS-3689. Add various profiles to MiniOzoneChaosCluster to run different modes. (#1420)\n  HDDS-4497. Recon File Size Count task throws SQL Exception. (#1612)", "committedDate": "2020-11-30T23:08:16Z", "type": "commit"}, {"oid": "e3a5a8919c6205ed438f36292b4ece78fdce3f25", "url": "https://github.com/apache/ozone/commit/e3a5a8919c6205ed438f36292b4ece78fdce3f25", "message": "Add accidentally deleted RPC server start call in OM", "committedDate": "2020-12-01T15:29:11Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYyOTIwMw==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533629203", "bodyText": "Minor nit: Why isn't this externally configurable? Since we throw an IOException after waiting. For non-rolling upgrades probably unnecessary hence a minor nit.", "author": "swagle", "createdAt": "2020-12-01T18:26:18Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,196 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =", "originalCommit": "e3a5a8919c6205ed438f36292b4ece78fdce3f25", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY5MzYxMA==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533693610", "bodyText": "I can make this an external config if we think it is necessary. @avijayanhwx any thoughts here?", "author": "errose28", "createdAt": "2020-12-01T20:15:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYyOTIwMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzcwNTM3OQ==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533705379", "bodyText": "We can add this as a passed in client side param, rather than an OM config. Something like\nozone admin om --prepare --wait-for-flush=2m\nThis will be added in subsequent JIRAs.", "author": "avijayanhwx", "createdAt": "2020-12-01T20:36:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYyOTIwMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzcwNzc3MQ==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533707771", "bodyText": "Actually @avijayanhwx suggested offline we should probably make this a client side param later. Something like ozone om prepare --waitFor=1m.", "author": "errose28", "createdAt": "2020-12-01T20:41:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYyOTIwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYzMTQyNg==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533631426", "bodyText": "Minor nit: unused local references", "author": "swagle", "createdAt": "2020-12-01T18:29:53Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,196 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();", "originalCommit": "e3a5a8919c6205ed438f36292b4ece78fdce3f25", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY5NTYwNA==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533695604", "bodyText": "Which reference is unused, omRatisServer? It is used in the following two lines to construct the RaftServerImpl.", "author": "errose28", "createdAt": "2020-12-01T20:19:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYzMTQyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY5NzMyOQ==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533697329", "bodyText": "server and serverImpl do not seem to be used, only a code readability comment, it makes the method more concise, can be inline with usage", "author": "swagle", "createdAt": "2020-12-01T20:22:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYzMTQyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzcwNjA4MA==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533706080", "bodyText": "server is used to obtain serverImpl, which is passed to takeSnapshotAndPurgeLogs. I could collapse it, not sure if its more readable. It would look like this:\ntakeSnapshotAndPurgeLogs(((RaftServerProxy) omRatisServer.getServer())\n          .getImpl(omRatisServer.getRaftGroup().getGroupId()));", "author": "errose28", "createdAt": "2020-12-01T20:38:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYzMTQyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzgyMzE0NQ==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533823145", "bodyText": "Since typecasting is involved, lets leave this the way it is. It is more of a personal choice. Since the reference is utilized only once, I think it make sense to eliminate the reference, probably an interesting discussion for some other time :) Marking this as resolved.", "author": "swagle", "createdAt": "2020-12-02T00:56:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYzMTQyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYzNDcwNQ==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533634705", "bodyText": "Can we add a comment here: What is the recovery step from this? If the snapshot index does not match will subsequent prepare ever succeed? cc: @avijayanhwx", "author": "swagle", "createdAt": "2020-12-01T18:35:24Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,196 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      takeSnapshotAndPurgeLogs(serverImpl);\n+\n+      // TODO: Create marker file with txn index.\n+\n+      LOG.info(\"OM prepared at log index {}. Returning response {}\",\n+          ozoneManager.getRatisSnapshotIndex(), omResponse);\n+    } catch (IOException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, e));\n+    } catch (InterruptedException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, new OMException(e,\n+              OMException.ResultCodes.INTERNAL_ERROR)));\n+    }\n+\n+    return response;\n+  }\n+\n+  private static void waitForDoubleBufferFlush(\n+      OzoneManager ozoneManager, long txnLogIndex)\n+      throws InterruptedException, IOException {\n+\n+    long endTime = System.currentTimeMillis() +\n+        DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis();\n+    boolean success = false;\n+\n+    while (!success && System.currentTimeMillis() < endTime) {\n+      // If no transactions have been persisted to the DB, transaction info\n+      // will be null, not zero, causing a null pointer exception within\n+      // ozoneManager#getRatisSnaphotIndex.\n+      // Get the transaction directly instead.\n+      OMTransactionInfo txnInfo = ozoneManager.getMetadataManager()\n+          .getTransactionInfoTable().get(TRANSACTION_INFO_KEY);\n+      if (txnInfo == null) {\n+        success = (txnLogIndex == 0);\n+      } else {\n+        success = (txnInfo.getTransactionIndex() == txnLogIndex);\n+      }\n+\n+      Thread.sleep(DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL.toMillis());\n+    }\n+\n+    if (!success) {\n+      throw new IOException(String.format(\"After waiting for %d seconds, \" +\n+              \"State Machine has not applied  all the transactions.\",\n+          DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis() * 1000));\n+    }\n+  }\n+\n+  /**\n+   * Take a snapshot of the state machine at the last index, and purge ALL logs.\n+   * @param impl RaftServerImpl instance\n+   * @throws IOException on Error.\n+   */\n+  public static long takeSnapshotAndPurgeLogs(RaftServerImpl impl)\n+      throws IOException {\n+\n+    StateMachine stateMachine = impl.getStateMachine();\n+    long snapshotIndex = stateMachine.takeSnapshot();\n+    if (snapshotIndex != stateMachine.getLastAppliedTermIndex().getIndex()) {\n+      throw new IOException(\"Index from Snapshot does not match last applied \" +", "originalCommit": "e3a5a8919c6205ed438f36292b4ece78fdce3f25", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY5NTk2MQ==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533695961", "bodyText": "If this fails, prepare will fail and an error response will be sent back to the client. I will add a comment to address this.", "author": "errose28", "createdAt": "2020-12-01T20:19:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYzNDcwNQ=="}], "type": "inlineReview"}, {"oid": "5185112d1fd1f7666aa808500ddb0c8aae0374e1", "url": "https://github.com/apache/ozone/commit/5185112d1fd1f7666aa808500ddb0c8aae0374e1", "message": "Update ratis request to use new API", "committedDate": "2020-12-01T20:09:51Z", "type": "commit"}, {"oid": "ed1f492185a7f67d13c9e701739c751730252063", "url": "https://github.com/apache/ozone/commit/ed1f492185a7f67d13c9e701739c751730252063", "message": "Add comments about failure cases", "committedDate": "2020-12-01T20:26:27Z", "type": "commit"}, {"oid": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728", "url": "https://github.com/apache/ozone/commit/4a149d9a87caa02fbdcc2440b986b8bfa72d5728", "message": "Fix checkstyle violations", "committedDate": "2020-12-01T21:23:57Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc3MjkzNg==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533772936", "bodyText": "I believe there is a chance of snapshotIndex != lastAppliedTermIndex.\nBecause once doubleBuffer flush completes, it calls updateLastAppliedIndex from DoubleBuffer flush thread, to update lastAppliedIndex, but if doubleBuffer flush thread has not completed updateLastAppliedIndex updating, then this might not be equal.\nThere is very little chance to happen, as there is takeSnapshot which flush to DB, as updateLastAppliedIndex is inmemory map update.\nSo, to be safer side check lastAppliedTermIndex is the same as the TransactionInfo table lastAppliedIndex in the waitForDoubleBufferFlush method.", "author": "bharatviswa504", "createdAt": "2020-12-01T22:46:13Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      takeSnapshotAndPurgeLogs(((RaftServerProxy) omRatisServer.getServer())\n+          .getImpl(omRatisServer.getRaftGroup().getGroupId()));\n+\n+      // TODO: Create marker file with txn index.\n+\n+      LOG.info(\"OM prepared at log index {}. Returning response {}\",\n+          ozoneManager.getRatisSnapshotIndex(), omResponse);\n+    } catch (IOException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, e));\n+    } catch (InterruptedException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, new OMException(e,\n+              OMException.ResultCodes.INTERNAL_ERROR)));\n+    }\n+\n+    return response;\n+  }\n+\n+  private static void waitForDoubleBufferFlush(\n+      OzoneManager ozoneManager, long txnLogIndex)\n+      throws InterruptedException, IOException {\n+\n+    long endTime = System.currentTimeMillis() +\n+        DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis();\n+    boolean success = false;\n+\n+    while (!success && System.currentTimeMillis() < endTime) {\n+      // If no transactions have been persisted to the DB, transaction info\n+      // will be null, not zero, causing a null pointer exception within\n+      // ozoneManager#getRatisSnaphotIndex.\n+      // Get the transaction directly instead.\n+      OMTransactionInfo txnInfo = ozoneManager.getMetadataManager()\n+          .getTransactionInfoTable().get(TRANSACTION_INFO_KEY);\n+      if (txnInfo == null) {\n+        success = (txnLogIndex == 0);\n+      } else {\n+        success = (txnInfo.getTransactionIndex() == txnLogIndex);\n+      }\n+\n+      Thread.sleep(DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL.toMillis());\n+    }\n+\n+    // If the timeout waiting for all transactions to reach the state machine\n+    // is exceeded, the exception is propagated, resulting in an error response\n+    // to the client. They can retry the prepare request.\n+    if (!success) {\n+      throw new IOException(String.format(\"After waiting for %d seconds, \" +\n+              \"State Machine has not applied  all the transactions.\",\n+          DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis() * 1000));\n+    }\n+  }\n+\n+  /**\n+   * Take a snapshot of the state machine at the last index, and purge ALL logs.\n+   * @param impl RaftServerImpl instance\n+   * @throws IOException on Error.\n+   */\n+  public static long takeSnapshotAndPurgeLogs(RaftServerImpl impl)\n+      throws IOException {\n+\n+    StateMachine stateMachine = impl.getStateMachine();\n+    long snapshotIndex = stateMachine.takeSnapshot();\n+\n+    // If the snapshot indices from Ratis and the state machine do not match,\n+    // the exception is propagated, resulting in an error response to the\n+    // client. They can retry the prepare request.\n+    if (snapshotIndex != stateMachine.getLastAppliedTermIndex().getIndex()) {", "originalCommit": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDQ2NzkyMA==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r534467920", "bodyText": "The comment I put above this check is actually incorrect. This check is redundant since it is checking Ratis's in memory snapshot index against itself. It does not touch the transaction info table in the DB. I will remove this check.\n\ncheck lastAppliedTermIndex is the same as the TransactionInfo table lastAppliedIndex in the waitForDoubleBufferFlush method\n\nI believe the check we have in the waitForDoubleBufferFlush method provides the same guarantee. Let me know if there is any added benefit to putting this check there as well.", "author": "errose28", "createdAt": "2020-12-02T20:42:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc3MjkzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTcwNzYzMA==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r535707630", "bodyText": "I understand the issue now, sorry for the confusion about the original code. It looks like this did surface on the most recent CI integration test run. If I understand correctly, we should be waiting for both the lastAppliedIndex (Ratis's view) and the transaction index in the DB to update to the prepare request's index. There is no guarantee whether one or the other is updated first.", "author": "errose28", "createdAt": "2020-12-03T22:57:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc3MjkzNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc3OTk3OA==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533779978", "bodyText": "Minor: We can pass the serverImpl which we got in L106 to takeSnapshotAndPurgeLogs", "author": "bharatviswa504", "createdAt": "2020-12-01T23:01:03Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      takeSnapshotAndPurgeLogs(((RaftServerProxy) omRatisServer.getServer())", "originalCommit": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDQ2ODAxNA==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r534468014", "bodyText": "Will do", "author": "errose28", "createdAt": "2020-12-02T20:42:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc3OTk3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc4MTcwMA==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533781700", "bodyText": "Why we need to return success in this case, because when PrepareRequest is added to double-buffer that mean double-buffer will flush the transaction of PrepareRequest to DB, even if there is no request to OM at all.\nAnd also not understood the reason for the null pointer exception part", "author": "bharatviswa504", "createdAt": "2020-12-01T23:05:03Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      takeSnapshotAndPurgeLogs(((RaftServerProxy) omRatisServer.getServer())\n+          .getImpl(omRatisServer.getRaftGroup().getGroupId()));\n+\n+      // TODO: Create marker file with txn index.\n+\n+      LOG.info(\"OM prepared at log index {}. Returning response {}\",\n+          ozoneManager.getRatisSnapshotIndex(), omResponse);\n+    } catch (IOException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, e));\n+    } catch (InterruptedException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, new OMException(e,\n+              OMException.ResultCodes.INTERNAL_ERROR)));\n+    }\n+\n+    return response;\n+  }\n+\n+  private static void waitForDoubleBufferFlush(\n+      OzoneManager ozoneManager, long txnLogIndex)\n+      throws InterruptedException, IOException {\n+\n+    long endTime = System.currentTimeMillis() +\n+        DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis();\n+    boolean success = false;\n+\n+    while (!success && System.currentTimeMillis() < endTime) {\n+      // If no transactions have been persisted to the DB, transaction info\n+      // will be null, not zero, causing a null pointer exception within\n+      // ozoneManager#getRatisSnaphotIndex.\n+      // Get the transaction directly instead.\n+      OMTransactionInfo txnInfo = ozoneManager.getMetadataManager()\n+          .getTransactionInfoTable().get(TRANSACTION_INFO_KEY);\n+      if (txnInfo == null) {\n+        success = (txnLogIndex == 0);", "originalCommit": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDQ2OTYzNQ==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r534469635", "bodyText": "This left over from an earlier implementation where the prepare request was not part of the snapshot and the passed txnLogIndex could be 0 if prepare was the first request. Now that we add the response to the double buffer before calling this method, this logic is more of an extra step for completeness so passing 0 as txnLogIndex does not yield incorrect behavior, even though we are not doing that right now. I will tweak this to be more apparent.\nEven if we add the response to the double buffer before calling this method, it may not (and usually does not) make it to the DB by the first check, meaning a get on the TRANSACTION_INFO_KEY will return null and should be handled anyways.", "author": "errose28", "createdAt": "2020-12-02T20:45:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc4MTcwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc4NjYyOQ==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533786629", "bodyText": "Question: According to design flow, in preAppend we set the prepare flag to true so that no new transactions will be accepted. In which scenario will we have logs more than snapshotIndex and if we purge them those requests will not receive any response from OM leader and timed out?", "author": "bharatviswa504", "createdAt": "2020-12-01T23:15:51Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      takeSnapshotAndPurgeLogs(((RaftServerProxy) omRatisServer.getServer())\n+          .getImpl(omRatisServer.getRaftGroup().getGroupId()));\n+\n+      // TODO: Create marker file with txn index.\n+\n+      LOG.info(\"OM prepared at log index {}. Returning response {}\",\n+          ozoneManager.getRatisSnapshotIndex(), omResponse);\n+    } catch (IOException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, e));\n+    } catch (InterruptedException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, new OMException(e,\n+              OMException.ResultCodes.INTERNAL_ERROR)));\n+    }\n+\n+    return response;\n+  }\n+\n+  private static void waitForDoubleBufferFlush(\n+      OzoneManager ozoneManager, long txnLogIndex)\n+      throws InterruptedException, IOException {\n+\n+    long endTime = System.currentTimeMillis() +\n+        DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis();\n+    boolean success = false;\n+\n+    while (!success && System.currentTimeMillis() < endTime) {\n+      // If no transactions have been persisted to the DB, transaction info\n+      // will be null, not zero, causing a null pointer exception within\n+      // ozoneManager#getRatisSnaphotIndex.\n+      // Get the transaction directly instead.\n+      OMTransactionInfo txnInfo = ozoneManager.getMetadataManager()\n+          .getTransactionInfoTable().get(TRANSACTION_INFO_KEY);\n+      if (txnInfo == null) {\n+        success = (txnLogIndex == 0);\n+      } else {\n+        success = (txnInfo.getTransactionIndex() == txnLogIndex);\n+      }\n+\n+      Thread.sleep(DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL.toMillis());\n+    }\n+\n+    // If the timeout waiting for all transactions to reach the state machine\n+    // is exceeded, the exception is propagated, resulting in an error response\n+    // to the client. They can retry the prepare request.\n+    if (!success) {\n+      throw new IOException(String.format(\"After waiting for %d seconds, \" +\n+              \"State Machine has not applied  all the transactions.\",\n+          DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis() * 1000));\n+    }\n+  }\n+\n+  /**\n+   * Take a snapshot of the state machine at the last index, and purge ALL logs.\n+   * @param impl RaftServerImpl instance\n+   * @throws IOException on Error.\n+   */\n+  public static long takeSnapshotAndPurgeLogs(RaftServerImpl impl)\n+      throws IOException {\n+\n+    StateMachine stateMachine = impl.getStateMachine();\n+    long snapshotIndex = stateMachine.takeSnapshot();\n+\n+    // If the snapshot indices from Ratis and the state machine do not match,\n+    // the exception is propagated, resulting in an error response to the\n+    // client. They can retry the prepare request.\n+    if (snapshotIndex != stateMachine.getLastAppliedTermIndex().getIndex()) {\n+      throw new IOException(\"Index from Snapshot does not match last applied \" +\n+          \"Index\");\n+    }\n+\n+    RaftLog raftLog = impl.getState().getLog();\n+    // In order to get rid of all logs, make sure we also account for\n+    // intermediate Ratis entries that do not pertain to OM.\n+    long lastIndex = Math.max(snapshotIndex,", "originalCommit": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDQ3Njg5Ng==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r534476896", "bodyText": "This was originally done defensively against meta transactions that Ratis may put in the log, which are not related to OM activities. @avijayanhwx and I are unable to reproduce earlier errors we thought we saw related to this, so we will remove this max statement and just use snapshotIndex. If an error surfaces later under more robust prepare and upgrade testing, we will re-address this issue, but for now we can remove it to avoid unintended side effects this might cause.", "author": "errose28", "createdAt": "2020-12-02T20:58:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc4NjYyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc4NjgxNg==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533786816", "bodyText": "Why cleanupAll is true in this case, as this has not touched any DB, so it can be false right?", "author": "bharatviswa504", "createdAt": "2020-12-01T23:16:22Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/response/upgrade/OMPrepareResponse.java", "diffHunk": "@@ -0,0 +1,44 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.response.upgrade;\n+\n+import org.apache.hadoop.hdds.utils.db.BatchOperation;\n+import org.apache.hadoop.ozone.om.OMMetadataManager;\n+import org.apache.hadoop.ozone.om.response.CleanupTableInfo;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos;\n+\n+import java.io.IOException;\n+\n+/**\n+ * Response for prepare request.\n+ */\n+@CleanupTableInfo(cleanupAll = true)", "originalCommit": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDQ3MDE0MQ==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r534470141", "bodyText": "Yes, we can actually just set this to false.", "author": "errose28", "createdAt": "2020-12-02T20:46:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc4NjgxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc4OTA0NA==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533789044", "bodyText": "In design flow, the prepare flag is set in preAppend will that be handled in a seperate Jira?", "author": "bharatviswa504", "createdAt": "2020-12-01T23:21:42Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(", "originalCommit": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzg0MDYwMQ==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533840601", "bodyText": "Yes, in follow up JIRAs, the 'Prepared' OM state maintenance and the gate for stopping other requests will be added.", "author": "avijayanhwx", "createdAt": "2020-12-02T01:45:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc4OTA0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzgxMjY3Mg==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533812672", "bodyText": "Is this failing test that needs more changes?", "author": "bharatviswa504", "createdAt": "2020-12-02T00:27:09Z", "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOzoneManagerPrepare.java", "diffHunk": "@@ -0,0 +1,326 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om;\n+\n+import static java.nio.charset.StandardCharsets.UTF_8;\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+\n+import java.io.File;\n+import java.nio.file.Paths;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.UUID;\n+\n+import org.apache.hadoop.hdds.client.ReplicationFactor;\n+import org.apache.hadoop.hdds.client.ReplicationType;\n+import org.apache.hadoop.ozone.MiniOzoneHAClusterImpl;\n+import org.apache.hadoop.ozone.client.ObjectStore;\n+import org.apache.hadoop.ozone.client.OzoneClient;\n+import org.apache.hadoop.ozone.client.OzoneClientFactory;\n+import org.apache.hadoop.ozone.client.OzoneVolume;\n+import org.apache.hadoop.ozone.client.io.OzoneOutputStream;\n+import org.apache.hadoop.ozone.container.ContainerTestHelper;\n+import org.apache.hadoop.ozone.container.TestHelper;\n+import org.apache.hadoop.ozone.om.helpers.OMRatisHelper;\n+import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareRequest;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+import org.apache.ratis.protocol.ClientId;\n+import org.apache.ratis.protocol.Message;\n+import org.apache.ratis.protocol.RaftClientRequest;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * Test OM prepare against actual mini cluster.\n+ */\n+public class TestOzoneManagerPrepare extends TestOzoneManagerHA {\n+\n+  private final String keyPrefix = \"key\";\n+  private final int timeoutMillis = 30000;\n+\n+  /**\n+   * Calls prepare on all OMs when they have no transaction information.\n+   * Checks that they are brought into prepare mode successfully.\n+   */\n+  @Test\n+  public void testPrepareWithoutTransactions() throws Exception {\n+    MiniOzoneHAClusterImpl cluster = getCluster();\n+    OzoneManager leader = cluster.getOMLeader();\n+    OMResponse omResponse = submitPrepareRequest(leader.getOmRatisServer());\n+    // Get the log index of the prepare request.\n+    long prepareRequestLogIndex =\n+        omResponse.getPrepareResponse().getTxnID();\n+\n+    // Prepare response processing is included in the snapshot,\n+    // giving index of 1.\n+    Assert.assertEquals(1, prepareRequestLogIndex);\n+    for (OzoneManager om: cluster.getOzoneManagersList()) {\n+      // Leader should be prepared as soon as it returns response.\n+      if (om == leader) {\n+        checkPrepared(om, prepareRequestLogIndex);\n+      } else {\n+        waitAndCheckPrepared(om, prepareRequestLogIndex);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Writes data to the cluster via the leader OM, and then prepares it.\n+   * Checks that every OM is prepared successfully.\n+   */\n+  @Test\n+  public void testPrepareWithTransactions() throws Exception {\n+    MiniOzoneHAClusterImpl cluster = getCluster();\n+    OzoneClient ozClient = OzoneClientFactory.getRpcClient(getConf());\n+\n+    String volumeName = UUID.randomUUID().toString();\n+    String bucketName = UUID.randomUUID().toString();\n+    ObjectStore store = ozClient.getObjectStore();\n+\n+    store.createVolume(volumeName);\n+    OzoneVolume volume = store.getVolume(volumeName);\n+    volume.createBucket(bucketName);\n+\n+    Set<String> writtenKeys = new HashSet<>();\n+    for (int i = 1; i <= 10; i++) {\n+      String keyName = keyPrefix + i;\n+      writeTestData(store, volumeName, bucketName, keyName);\n+      writtenKeys.add(keyName);\n+    }\n+\n+    // Make sure all OMs have logs from writing data, so we can check that\n+    // they are purged after prepare.\n+    for (OzoneManager om: cluster.getOzoneManagersList()) {\n+      LambdaTestUtils.await(timeoutMillis, 1000,\n+          () -> logFilesPresentInRatisPeer(om));\n+    }\n+\n+    OzoneManager leader = cluster.getOMLeader();\n+    OMResponse omResponse = submitPrepareRequest(leader.getOmRatisServer());\n+    // Get the log index of the prepare request.\n+    long prepareRequestLogIndex =\n+        omResponse.getPrepareResponse().getTxnID();\n+\n+    // Make sure all OMs are prepared and all OMs still have their data.\n+    for (OzoneManager om: cluster.getOzoneManagersList()) {\n+      // Leader should be prepared as soon as it returns response.\n+      if (om == leader) {\n+        checkPrepared(om, prepareRequestLogIndex);\n+      } else {\n+        waitAndCheckPrepared(om, prepareRequestLogIndex);\n+      }\n+\n+      List<OmKeyInfo> keys = om.getMetadataManager().listKeys(volumeName,\n+          bucketName, null, keyPrefix, 100);\n+\n+      Assert.assertEquals(writtenKeys.size(), keys.size());\n+      for (OmKeyInfo keyInfo: keys) {\n+        Assert.assertTrue(writtenKeys.contains(keyInfo.getKeyName()));\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Writes data to the cluster.\n+   * Shuts down one OM.\n+   * Writes more data to the cluster.\n+   * Submits prepare as ratis request.\n+   * Checks that two live OMs are prepared.\n+   * Revives the third OM\n+   * Checks that third OM received all transactions and is prepared.\n+   * @throws Exception\n+   */", "originalCommit": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDQ3MjEzMg==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r534472132", "bodyText": "I could not get this test to work without client side changes. Once those are implemented by @avijayanhwx, we will use them to implement more robust integration tests with failures. This is left here for reference to come back to.", "author": "errose28", "createdAt": "2020-12-02T20:50:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzgxMjY3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzgxMzYyNA==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533813624", "bodyText": "Offline discussion with @avijayanhwx this part of logic will be revisited in next jiras, if another PrepareUpgrade request is let in, we cleanup logIndexes greater than snapshotIndex and also syncWithSnapshot does not close when end logIndex is greater than snapshotIndex, so that might be left out.", "author": "bharatviswa504", "createdAt": "2020-12-02T00:29:46Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.ozone.om.request.upgrade;\n+\n+import org.apache.hadoop.ozone.om.OzoneManager;\n+import org.apache.hadoop.ozone.om.exceptions.OMException;\n+import org.apache.hadoop.ozone.om.ratis.OMTransactionInfo;\n+import org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer;\n+import org.apache.hadoop.ozone.om.ratis.utils.OzoneManagerDoubleBufferHelper;\n+import org.apache.hadoop.ozone.om.request.OMClientRequest;\n+import org.apache.hadoop.ozone.om.request.util.OmResponseUtil;\n+import org.apache.hadoop.ozone.om.response.OMClientResponse;\n+import org.apache.hadoop.ozone.om.response.upgrade.OMPrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.PrepareResponse;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMRequest;\n+import org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.OMResponse;\n+\n+import static org.apache.hadoop.ozone.OzoneConsts.TRANSACTION_INFO_KEY;\n+import static org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos.Type;\n+\n+import org.apache.ratis.server.impl.RaftServerImpl;\n+import org.apache.ratis.server.impl.RaftServerProxy;\n+import org.apache.ratis.server.raftlog.RaftLog;\n+import org.apache.ratis.statemachine.StateMachine;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.temporal.ChronoUnit;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * OM Request used to flush all transactions to disk, take a DB snapshot, and\n+ * purge the logs, leaving Ratis in a clean state without unapplied log\n+ * entries. This prepares the OM for upgrades/downgrades so that no request\n+ * in the log is applied to the database in the old version of the code in one\n+ * OM, and the new version of the code on another OM.\n+ */\n+public class OMPrepareRequest extends OMClientRequest {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(OMPrepareRequest.class);\n+\n+  // Allow double buffer this many seconds to flush all transactions before\n+  // returning an error to the caller.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_TIMEOUT =\n+      Duration.of(5, ChronoUnit.MINUTES);\n+  // Time between checks to see if double buffer finished flushing.\n+  private static final Duration DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL =\n+      Duration.of(1, ChronoUnit.SECONDS);\n+\n+  public OMPrepareRequest(OMRequest omRequest) {\n+    super(omRequest);\n+  }\n+\n+  @Override\n+  public OMClientResponse validateAndUpdateCache(\n+      OzoneManager ozoneManager, long transactionLogIndex,\n+      OzoneManagerDoubleBufferHelper ozoneManagerDoubleBufferHelper) {\n+\n+    LOG.info(\"Received prepare request with log index {}\", transactionLogIndex);\n+\n+    OMResponse.Builder responseBuilder =\n+        OmResponseUtil.getOMResponseBuilder(getOmRequest());\n+    responseBuilder.setCmdType(Type.Prepare);\n+    OMClientResponse response = null;\n+\n+    try {\n+      // Create response.\n+      PrepareResponse omResponse = PrepareResponse.newBuilder()\n+              .setTxnID(transactionLogIndex)\n+              .build();\n+      responseBuilder.setPrepareResponse(omResponse);\n+      response = new OMPrepareResponse(responseBuilder.build());\n+\n+      // Add response to double buffer before clearing logs.\n+      // This guarantees the log index of this request will be the same as\n+      // the snapshot index in the prepared state.\n+      ozoneManagerDoubleBufferHelper.add(response, transactionLogIndex);\n+\n+      // Wait for outstanding double buffer entries to flush to disk,\n+      // so they will not be purged from the log before being persisted to\n+      // the DB.\n+      // Since the response for this request was added to the double buffer\n+      // already, once this index reaches the state machine, we know all\n+      // transactions have been flushed.\n+      waitForDoubleBufferFlush(ozoneManager, transactionLogIndex);\n+\n+      OzoneManagerRatisServer omRatisServer = ozoneManager.getOmRatisServer();\n+      RaftServerProxy server = (RaftServerProxy) omRatisServer.getServer();\n+      RaftServerImpl serverImpl =\n+          server.getImpl(omRatisServer.getRaftGroup().getGroupId());\n+\n+      takeSnapshotAndPurgeLogs(((RaftServerProxy) omRatisServer.getServer())\n+          .getImpl(omRatisServer.getRaftGroup().getGroupId()));\n+\n+      // TODO: Create marker file with txn index.\n+\n+      LOG.info(\"OM prepared at log index {}. Returning response {}\",\n+          ozoneManager.getRatisSnapshotIndex(), omResponse);\n+    } catch (IOException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, e));\n+    } catch (InterruptedException e) {\n+      response = new OMPrepareResponse(\n+          createErrorOMResponse(responseBuilder, new OMException(e,\n+              OMException.ResultCodes.INTERNAL_ERROR)));\n+    }\n+\n+    return response;\n+  }\n+\n+  private static void waitForDoubleBufferFlush(\n+      OzoneManager ozoneManager, long txnLogIndex)\n+      throws InterruptedException, IOException {\n+\n+    long endTime = System.currentTimeMillis() +\n+        DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis();\n+    boolean success = false;\n+\n+    while (!success && System.currentTimeMillis() < endTime) {\n+      // If no transactions have been persisted to the DB, transaction info\n+      // will be null, not zero, causing a null pointer exception within\n+      // ozoneManager#getRatisSnaphotIndex.\n+      // Get the transaction directly instead.\n+      OMTransactionInfo txnInfo = ozoneManager.getMetadataManager()\n+          .getTransactionInfoTable().get(TRANSACTION_INFO_KEY);\n+      if (txnInfo == null) {\n+        success = (txnLogIndex == 0);\n+      } else {\n+        success = (txnInfo.getTransactionIndex() == txnLogIndex);\n+      }\n+\n+      Thread.sleep(DOUBLE_BUFFER_FLUSH_CHECK_INTERVAL.toMillis());\n+    }\n+\n+    // If the timeout waiting for all transactions to reach the state machine\n+    // is exceeded, the exception is propagated, resulting in an error response\n+    // to the client. They can retry the prepare request.\n+    if (!success) {\n+      throw new IOException(String.format(\"After waiting for %d seconds, \" +\n+              \"State Machine has not applied  all the transactions.\",\n+          DOUBLE_BUFFER_FLUSH_TIMEOUT.toMillis() * 1000));\n+    }\n+  }\n+\n+  /**\n+   * Take a snapshot of the state machine at the last index, and purge ALL logs.\n+   * @param impl RaftServerImpl instance\n+   * @throws IOException on Error.\n+   */\n+  public static long takeSnapshotAndPurgeLogs(RaftServerImpl impl)\n+      throws IOException {\n+\n+    StateMachine stateMachine = impl.getStateMachine();\n+    long snapshotIndex = stateMachine.takeSnapshot();\n+\n+    // If the snapshot indices from Ratis and the state machine do not match,", "originalCommit": "4a149d9a87caa02fbdcc2440b986b8bfa72d5728", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzg0MTAyNQ==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r533841025", "bodyText": "Yes, +1.", "author": "avijayanhwx", "createdAt": "2020-12-02T01:46:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzgxMzYyNA=="}], "type": "inlineReview"}, {"oid": "6ddb371f5dc5647601d627ca8846e5438d728523", "url": "https://github.com/apache/ozone/commit/6ddb371f5dc5647601d627ca8846e5438d728523", "message": "Update checks in snapshot and purge step", "committedDate": "2020-12-02T20:35:20Z", "type": "commit"}, {"oid": "626120ce3011b4238a430789833ecfbb4fab7960", "url": "https://github.com/apache/ozone/commit/626120ce3011b4238a430789833ecfbb4fab7960", "message": "Remove cleanupTables = all marking from prepare response\n\nIt does not touch any tables.", "committedDate": "2020-12-02T21:33:51Z", "type": "commit"}, {"oid": "bb09232c91b1f8fca27db28116917a6cb27fe33e", "url": "https://github.com/apache/ozone/commit/bb09232c91b1f8fca27db28116917a6cb27fe33e", "message": "Readability improvements for waitForDoubleBufferFlush method", "committedDate": "2020-12-02T21:34:47Z", "type": "commit"}, {"oid": "8d12a4e1e87a59b203db63b9c9f0f8ee6c430d43", "url": "https://github.com/apache/ozone/commit/8d12a4e1e87a59b203db63b9c9f0f8ee6c430d43", "message": "Fix checkstyle violation", "committedDate": "2020-12-02T23:08:53Z", "type": "commit"}, {"oid": "464c15edc8c9f8e7c521edab6f29bbc3c13b52da", "url": "https://github.com/apache/ozone/commit/464c15edc8c9f8e7c521edab6f29bbc3c13b52da", "message": "Allow OMPrepareResponse to have no cleanup tables in unit test", "committedDate": "2020-12-03T17:18:09Z", "type": "commit"}, {"oid": "7a3ad7259f026832e0b4f35f7ab028ed7ce70fbf", "url": "https://github.com/apache/ozone/commit/7a3ad7259f026832e0b4f35f7ab028ed7ce70fbf", "message": "Wait on both ratis index and DB index, and don't terminate OM on failed prepare", "committedDate": "2020-12-04T16:52:22Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzMjkzNQ==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r536432935", "bodyText": "Right now adding this logic might have issue, as there is no safeguard logic to not allow further requests after PUR.", "author": "bharatviswa504", "createdAt": "2020-12-04T22:57:31Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -166,36 +166,29 @@ private static void waitForDoubleBufferFlush(\n    */\n   public static long takeSnapshotAndPurgeLogs(RaftServerImpl impl)\n       throws IOException {\n-\n     StateMachine stateMachine = impl.getStateMachine();\n     long snapshotIndex = stateMachine.takeSnapshot();\n+    RaftLog raftLog = impl.getState().getLog();\n+    long raftLogIndex = raftLog.getLastEntryTermIndex().getIndex();\n \n-    // If the snapshot indices from Ratis and the state machine do not match,\n-    // the exception is propagated, resulting in an error response to the\n-    // client. They can retry the prepare request.\n-    if (snapshotIndex != stateMachine.getLastAppliedTermIndex().getIndex()) {\n-      throw new IOException(\"Index from Snapshot does not match last applied \" +\n-          \"Index\");\n+    if (snapshotIndex != raftLogIndex) {", "originalCommit": "6ddb371f5dc5647601d627ca8846e5438d728523", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0MjM3MQ==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r536442371", "bodyText": "@bharatviswa504 That will be the next work item in the prepare OM feature.", "author": "avijayanhwx", "createdAt": "2020-12-04T23:25:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzMjkzNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0MjUwMw==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r536442503", "bodyText": "Right. The gate to stop further write transactions will be added in a later Jira. This is added in anticipation of that feature. Current testing acknowledges that the gate does not exist by not submitting requests after prepare.  Basically this whole pull request will have issues under a real use case without the gate, which is why this is part of a larger feature off of the master branch.", "author": "errose28", "createdAt": "2020-12-04T23:26:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzMjkzNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0MzYxMg==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r536443612", "bodyText": "Makes sense, thanks for the clear explanation.", "author": "bharatviswa504", "createdAt": "2020-12-04T23:29:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzMjkzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzMzcyOQ==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r536433729", "bodyText": "When PUR is flushed, in DB of transactionInfo table still it is null means something wrong right?", "author": "bharatviswa504", "createdAt": "2020-12-04T22:59:53Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/upgrade/OMPrepareRequest.java", "diffHunk": "@@ -137,16 +137,21 @@ private static void waitForDoubleBufferFlush(\n       // If no transactions have been persisted to the DB, transaction info\n       // will be null, not zero, causing a null pointer exception within\n       // ozoneManager#getRatisSnaphotIndex.\n-      // Get the transaction directly instead.\n-      OMTransactionInfo txnInfo = ozoneManager.getMetadataManager()\n+      // Get the transaction directly instead to handle the case when it is\n+      // null.\n+      OMTransactionInfo dbTxnInfo = ozoneManager.getMetadataManager()\n           .getTransactionInfoTable().get(TRANSACTION_INFO_KEY);\n-      if (txnInfo == null) {\n-        success = (txnLogIndex == 0);\n+      if (dbTxnInfo == null) {\n+        // If there are no transactions in the DB, we are prepared to log", "originalCommit": "bb09232c91b1f8fca27db28116917a6cb27fe33e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0MDI0NA==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r536440244", "bodyText": "Yes, when it is flushed. But this is the method that is waiting for the flush. The flush has not necessarily completed by the first run of this loop. It is possible that when prepare is the first transaction to the DB, this method call happens before its flush completes, and on the first (few) iterations of the loop, the transaction info table is empty and dbTxnInfo will be null. Once the flush completes, dbTxnInfo will no longer be null on later loop iterations.", "author": "errose28", "createdAt": "2020-12-04T23:18:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzMzcyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0MzQ0NQ==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r536443445", "bodyText": "Ohh misread the condition indexToWaitFor==0, indexTowaitFor will never be zero, so in case when doubleBuffer flush fails to flush this condition is not met. Is my understanding correct?", "author": "bharatviswa504", "createdAt": "2020-12-04T23:29:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzMzcyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0NDI1NQ==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r536444255", "bodyText": "Or simply here, we can have if dbTxnInfo success=false right?", "author": "bharatviswa504", "createdAt": "2020-12-04T23:31:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzMzcyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0OTY1OA==", "url": "https://github.com/apache/ozone/pull/1613#discussion_r536449658", "bodyText": "Right, the condition should never be met. Because of that, we could just set success = false when the dbTxnInfo is null, but since we have to do the null check anyways, I figured it was better to add a line to handle the case correctly, even if it should never arise.", "author": "errose28", "createdAt": "2020-12-04T23:50:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzMzcyOQ=="}], "type": "inlineReview"}]}