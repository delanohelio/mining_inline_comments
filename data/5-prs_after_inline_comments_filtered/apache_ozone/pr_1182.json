{"pr_number": 1182, "pr_title": "HDDS-3926. OM Token Identifier table should use in-house serialization.", "pr_createdAt": "2020-07-09T08:16:00Z", "pr_url": "https://github.com/apache/ozone/pull/1182", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjY0MjkyNw==", "url": "https://github.com/apache/ozone/pull/1182#discussion_r452642927", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              public byte[] toUniqueSerilizedKey() {\n          \n          \n            \n              public byte[] toUniqueSerializedKey() {", "author": "adoroszlai", "createdAt": "2020-07-10T06:17:01Z", "path": "hadoop-ozone/common/src/main/java/org/apache/hadoop/ozone/security/OzoneTokenIdentifier.java", "diffHunk": "@@ -77,6 +79,119 @@ public Text getKind() {\n     return KIND_NAME;\n   }\n \n+  /** Instead of relying on proto serialization, this\n+   *  provides  explicit serialization for OzoneTokenIdentifier.\n+   * @return byte[]\n+   */\n+  public byte[] toUniqueSerilizedKey() {", "originalCommit": "edd6079730477978713e3bcdd46c31c61ca3fbff", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEzNDgwMg==", "url": "https://github.com/apache/ozone/pull/1182#discussion_r453134802", "bodyText": "done", "author": "prashantpogde", "createdAt": "2020-07-11T00:57:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjY0MjkyNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjY0Mjk4NQ==", "url": "https://github.com/apache/ozone/pull/1182#discussion_r452642985", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              public static OzoneTokenIdentifier fromUniqueSerilizedKey(byte[] rawData) {\n          \n          \n            \n              public static OzoneTokenIdentifier fromUniqueSerializedKey(byte[] rawData) {", "author": "adoroszlai", "createdAt": "2020-07-10T06:17:15Z", "path": "hadoop-ozone/common/src/main/java/org/apache/hadoop/ozone/security/OzoneTokenIdentifier.java", "diffHunk": "@@ -77,6 +79,119 @@ public Text getKind() {\n     return KIND_NAME;\n   }\n \n+  /** Instead of relying on proto serialization, this\n+   *  provides  explicit serialization for OzoneTokenIdentifier.\n+   * @return byte[]\n+   */\n+  public byte[] toUniqueSerilizedKey() {\n+    ByteBuffer result =\n+        ByteBuffer.allocate(4096);\n+    result.order(ByteOrder.BIG_ENDIAN);\n+    try {\n+      result.putLong(getIssueDate());\n+      result.putInt(getMasterKeyId());\n+      result.putInt(getSequenceNumber());\n+\n+      result.putLong(getMaxDate());\n+\n+      result.putInt(getOwner().toString().length());\n+      result.put(getOwner().toString().getBytes());\n+\n+      result.putInt(getRealUser().toString().length());\n+      result.put(getRealUser().toString().getBytes());\n+\n+      result.putInt(getRenewer().toString().length());\n+      result.put(getRenewer().toString().getBytes());\n+\n+      result.putInt(getTokenType().getNumber());\n+      // Set s3 specific fields.\n+      if (getTokenType().equals(S3AUTHINFO)) {\n+        result.putInt(getAwsAccessId().length());\n+        result.put(getAwsAccessId().getBytes());\n+\n+        result.putInt(getSignature().length());\n+        result.put(getSignature().getBytes());\n+\n+        result.putInt(getStrToSign().length());\n+        result.put(getStrToSign().getBytes());\n+      } else {\n+        result.putInt(getOmCertSerialId().length());\n+        result.put(getOmCertSerialId().getBytes());\n+        if (getOmServiceId() != null) {\n+          result.putInt(getOmServiceId().length());\n+          result.put(getOmServiceId().getBytes());\n+        } else {\n+          result.putInt(0);\n+        }\n+      }\n+    } catch (IndexOutOfBoundsException e) {\n+      throw new IllegalArgumentException(\n+          \"Can't encode the the raw data \", e);\n+    }\n+    return result.array();\n+  }\n+\n+  /** Instead of relying on proto deserialization, this\n+   *  provides  explicit deserialization for OzoneTokenIdentifier.\n+   * @return byte[]\n+   */\n+  public static OzoneTokenIdentifier fromUniqueSerilizedKey(byte[] rawData) {", "originalCommit": "edd6079730477978713e3bcdd46c31c61ca3fbff", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEzNDgzMg==", "url": "https://github.com/apache/ozone/pull/1182#discussion_r453134832", "bodyText": "done", "author": "prashantpogde", "createdAt": "2020-07-11T00:57:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjY0Mjk4NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjY0MzY5Mg==", "url": "https://github.com/apache/ozone/pull/1182#discussion_r452643692", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                return object.toUniqueSerilizedKey();\n          \n          \n            \n                return object.toUniqueSerializedKey();", "author": "adoroszlai", "createdAt": "2020-07-10T06:19:41Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/codec/TokenIdentifierCodec.java", "diffHunk": "@@ -33,7 +33,7 @@\n   public byte[] toPersistedFormat(OzoneTokenIdentifier object) {\n     Preconditions\n         .checkNotNull(object, \"Null object can't be converted to byte array.\");\n-    return object.getBytes();\n+    return object.toUniqueSerilizedKey();", "originalCommit": "edd6079730477978713e3bcdd46c31c61ca3fbff", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEzNDg4Ng==", "url": "https://github.com/apache/ozone/pull/1182#discussion_r453134886", "bodyText": "done", "author": "prashantpogde", "createdAt": "2020-07-11T00:57:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjY0MzY5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjY0MzczNg==", "url": "https://github.com/apache/ozone/pull/1182#discussion_r452643736", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  return OzoneTokenIdentifier.fromUniqueSerilizedKey(rawData);\n          \n          \n            \n                  return OzoneTokenIdentifier.fromUniqueSerializedKey(rawData);", "author": "adoroszlai", "createdAt": "2020-07-10T06:19:50Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/codec/TokenIdentifierCodec.java", "diffHunk": "@@ -42,8 +42,8 @@ public OzoneTokenIdentifier fromPersistedFormat(byte[] rawData)\n     Preconditions.checkNotNull(rawData,\n         \"Null byte array can't converted to real object.\");\n     try {\n-      return OzoneTokenIdentifier.readProtoBuf(rawData);\n-    } catch (InvalidProtocolBufferException e) {\n+      return OzoneTokenIdentifier.fromUniqueSerilizedKey(rawData);", "originalCommit": "edd6079730477978713e3bcdd46c31c61ca3fbff", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEzNDkwNg==", "url": "https://github.com/apache/ozone/pull/1182#discussion_r453134906", "bodyText": "done", "author": "prashantpogde", "createdAt": "2020-07-11T00:58:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjY0MzczNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjcyNDQ3MA==", "url": "https://github.com/apache/ozone/pull/1182#discussion_r452724470", "bodyText": "Findbugs:\nH I Dm: Found reliance on default encoding in org.apache.hadoop.ozone.security.OzoneTokenIdentifier.toUniqueSerilizedKey(): String.getBytes()  At OzoneTokenIdentifier.java:[line 98]", "author": "adoroszlai", "createdAt": "2020-07-10T09:13:48Z", "path": "hadoop-ozone/common/src/main/java/org/apache/hadoop/ozone/security/OzoneTokenIdentifier.java", "diffHunk": "@@ -77,6 +79,119 @@ public Text getKind() {\n     return KIND_NAME;\n   }\n \n+  /** Instead of relying on proto serialization, this\n+   *  provides  explicit serialization for OzoneTokenIdentifier.\n+   * @return byte[]\n+   */\n+  public byte[] toUniqueSerilizedKey() {\n+    ByteBuffer result =\n+        ByteBuffer.allocate(4096);\n+    result.order(ByteOrder.BIG_ENDIAN);\n+    try {\n+      result.putLong(getIssueDate());\n+      result.putInt(getMasterKeyId());\n+      result.putInt(getSequenceNumber());\n+\n+      result.putLong(getMaxDate());\n+\n+      result.putInt(getOwner().toString().length());\n+      result.put(getOwner().toString().getBytes());", "originalCommit": "edd6079730477978713e3bcdd46c31c61ca3fbff", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEzNDkyNA==", "url": "https://github.com/apache/ozone/pull/1182#discussion_r453134924", "bodyText": "done", "author": "prashantpogde", "createdAt": "2020-07-11T00:58:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjcyNDQ3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjcyNDYwNA==", "url": "https://github.com/apache/ozone/pull/1182#discussion_r452724604", "bodyText": "Findbugs:\nH I Dm: Found reliance on default encoding in org.apache.hadoop.ozone.security.OzoneTokenIdentifier.fromUniqueSerilizedKey(byte[]): new String(byte[])  At OzoneTokenIdentifier.java:[line 169]", "author": "adoroszlai", "createdAt": "2020-07-10T09:14:07Z", "path": "hadoop-ozone/common/src/main/java/org/apache/hadoop/ozone/security/OzoneTokenIdentifier.java", "diffHunk": "@@ -77,6 +79,119 @@ public Text getKind() {\n     return KIND_NAME;\n   }\n \n+  /** Instead of relying on proto serialization, this\n+   *  provides  explicit serialization for OzoneTokenIdentifier.\n+   * @return byte[]\n+   */\n+  public byte[] toUniqueSerilizedKey() {\n+    ByteBuffer result =\n+        ByteBuffer.allocate(4096);\n+    result.order(ByteOrder.BIG_ENDIAN);\n+    try {\n+      result.putLong(getIssueDate());\n+      result.putInt(getMasterKeyId());\n+      result.putInt(getSequenceNumber());\n+\n+      result.putLong(getMaxDate());\n+\n+      result.putInt(getOwner().toString().length());\n+      result.put(getOwner().toString().getBytes());\n+\n+      result.putInt(getRealUser().toString().length());\n+      result.put(getRealUser().toString().getBytes());\n+\n+      result.putInt(getRenewer().toString().length());\n+      result.put(getRenewer().toString().getBytes());\n+\n+      result.putInt(getTokenType().getNumber());\n+      // Set s3 specific fields.\n+      if (getTokenType().equals(S3AUTHINFO)) {\n+        result.putInt(getAwsAccessId().length());\n+        result.put(getAwsAccessId().getBytes());\n+\n+        result.putInt(getSignature().length());\n+        result.put(getSignature().getBytes());\n+\n+        result.putInt(getStrToSign().length());\n+        result.put(getStrToSign().getBytes());\n+      } else {\n+        result.putInt(getOmCertSerialId().length());\n+        result.put(getOmCertSerialId().getBytes());\n+        if (getOmServiceId() != null) {\n+          result.putInt(getOmServiceId().length());\n+          result.put(getOmServiceId().getBytes());\n+        } else {\n+          result.putInt(0);\n+        }\n+      }\n+    } catch (IndexOutOfBoundsException e) {\n+      throw new IllegalArgumentException(\n+          \"Can't encode the the raw data \", e);\n+    }\n+    return result.array();\n+  }\n+\n+  /** Instead of relying on proto deserialization, this\n+   *  provides  explicit deserialization for OzoneTokenIdentifier.\n+   * @return byte[]\n+   */\n+  public static OzoneTokenIdentifier fromUniqueSerilizedKey(byte[] rawData) {\n+    OzoneTokenIdentifier result = newInstance();\n+    ByteBuffer inbuf = ByteBuffer.wrap(rawData);\n+    inbuf.order(ByteOrder.BIG_ENDIAN);\n+    result.setIssueDate(inbuf.getLong());\n+    result.setMasterKeyId(inbuf.getInt());\n+    result.setSequenceNumber(inbuf.getInt());\n+\n+    result.setMaxDate(inbuf.getLong());\n+\n+    int strsize = 0;\n+    strsize = inbuf.getInt();\n+    byte[] ownerBytes = new byte[strsize];\n+    inbuf.get(ownerBytes);\n+    result.setOwner(new Text(ownerBytes));\n+\n+    strsize = inbuf.getInt();\n+    byte[] ruserBytes = new byte[strsize];\n+    inbuf.get(ruserBytes);\n+    result.setRealUser(new Text(ruserBytes));\n+\n+    strsize = inbuf.getInt();\n+    byte[] renewerBytes = new byte[strsize];\n+    inbuf.get(renewerBytes);\n+    result.setRenewer(new Text(renewerBytes));\n+\n+    // Set s3 specific fields.\n+    if (inbuf.getInt() == S3AUTHINFO.getNumber()) {\n+      strsize = inbuf.getInt();\n+      byte[] awsAccessIdBytes = new byte[strsize];\n+      inbuf.get(awsAccessIdBytes);\n+      result.setAwsAccessId(new String(awsAccessIdBytes));", "originalCommit": "edd6079730477978713e3bcdd46c31c61ca3fbff", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEzNDk0Mw==", "url": "https://github.com/apache/ozone/pull/1182#discussion_r453134943", "bodyText": "done", "author": "prashantpogde", "createdAt": "2020-07-11T00:58:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjcyNDYwNA=="}], "type": "inlineReview"}, {"oid": "e644a17a8b18115327cab0585c940d6566374cd7", "url": "https://github.com/apache/ozone/commit/e644a17a8b18115327cab0585c940d6566374cd7", "message": "HDDS-3926. OM Token Identifier table should use in-house serialization.", "committedDate": "2020-07-11T00:55:02Z", "type": "commit"}, {"oid": "e644a17a8b18115327cab0585c940d6566374cd7", "url": "https://github.com/apache/ozone/commit/e644a17a8b18115327cab0585c940d6566374cd7", "message": "HDDS-3926. OM Token Identifier table should use in-house serialization.", "committedDate": "2020-07-11T00:55:02Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQxNjA2Ng==", "url": "https://github.com/apache/ozone/pull/1182#discussion_r453416066", "bodyText": "I see there is StrToSign if it's S3 auth. I 'm curious about how big this StrToSign can be? And whether 4096 bytes can hold all these.", "author": "ChenSammi", "createdAt": "2020-07-13T03:28:59Z", "path": "hadoop-ozone/common/src/main/java/org/apache/hadoop/ozone/security/OzoneTokenIdentifier.java", "diffHunk": "@@ -77,6 +80,122 @@ public Text getKind() {\n     return KIND_NAME;\n   }\n \n+  /** Instead of relying on proto serialization, this\n+   *  provides  explicit serialization for OzoneTokenIdentifier.\n+   * @return byte[]\n+   */\n+  public byte[] toUniqueSerializedKey() {\n+    ByteBuffer result =\n+        ByteBuffer.allocate(4096);", "originalCommit": "e644a17a8b18115327cab0585c940d6566374cd7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgyOTIxNg==", "url": "https://github.com/apache/ozone/pull/1182#discussion_r453829216", "bodyText": "I see there is StrToSign if it's S3 auth. I 'm curious about how big this StrToSign can be? And whether 4096 bytes can hold all these.\n\nIt should not be too big and not cause overflow.\nhttps://docs.aws.amazon.com/general/latest/gr/sigv4-create-string-to-sign.html\nI saw something similar in other places too e.g.\norg/apache/hadoop/security/token/TokenIdentifier.class with 4096 bytes limit.", "author": "prashantpogde", "createdAt": "2020-07-13T17:57:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQxNjA2Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDY1OTg2Mg==", "url": "https://github.com/apache/ozone/pull/1182#discussion_r454659862", "bodyText": "This issue is no longer valid in the newer version of the patch. cc @ChenSammi.", "author": "avijayanhwx", "createdAt": "2020-07-14T21:36:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQxNjA2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDAwOTY5MQ==", "url": "https://github.com/apache/ozone/pull/1182#discussion_r454009691", "bodyText": "Thanks @prashantpogde for working on this. The patch LGTM overall. Have a few questions:\nHave you consider leverage the readFields from parent class to handle the basic non-protoc serialization which seems to be much simpler.\npublic byte[] toUniqueSerializedKey() throws IOException {\n    DataOutputBuffer buf = new DataOutputBuffer();\n    super.write(buf);\n    WritableUtils.writeEnum(buf, getTokenType());\n    // Set s3 specific fields.\n    if (getTokenType().equals(S3AUTHINFO)) {\n      WritableUtils.writeString(buf, getAwsAccessId());\n      WritableUtils.writeString(buf, getSignature());\n      WritableUtils.writeString(buf, getStrToSign());\n    } else {\n      WritableUtils.writeString(buf, getOmCertSerialId());\n    }\n    return buf.getData();\n  }", "author": "xiaoyuyao", "createdAt": "2020-07-13T23:39:18Z", "path": "hadoop-ozone/common/src/main/java/org/apache/hadoop/ozone/security/OzoneTokenIdentifier.java", "diffHunk": "@@ -77,6 +80,122 @@ public Text getKind() {\n     return KIND_NAME;\n   }\n \n+  /** Instead of relying on proto serialization, this\n+   *  provides  explicit serialization for OzoneTokenIdentifier.\n+   * @return byte[]\n+   */\n+  public byte[] toUniqueSerializedKey() {\n+    ByteBuffer result =", "originalCommit": "e644a17a8b18115327cab0585c940d6566374cd7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDEwNjU5Mg==", "url": "https://github.com/apache/ozone/pull/1182#discussion_r454106592", "bodyText": "didn't try this. This looks simpler. Let me try this.", "author": "prashantpogde", "createdAt": "2020-07-14T05:16:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDAwOTY5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDEwNjkwMQ==", "url": "https://github.com/apache/ozone/pull/1182#discussion_r454106901", "bodyText": "I wanted to do explicit serialization. But this also looks safe serialization.", "author": "prashantpogde", "createdAt": "2020-07-14T05:17:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDAwOTY5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDAxMTE3OQ==", "url": "https://github.com/apache/ozone/pull/1182#discussion_r454011179", "bodyText": "NIT: The Text class is a UTF-8 bytes + length wrapper class. You can use getLength()/getBytes() without toString() conversion. Same apply to owner, realuser and renewer.", "author": "xiaoyuyao", "createdAt": "2020-07-13T23:41:52Z", "path": "hadoop-ozone/common/src/main/java/org/apache/hadoop/ozone/security/OzoneTokenIdentifier.java", "diffHunk": "@@ -77,6 +80,122 @@ public Text getKind() {\n     return KIND_NAME;\n   }\n \n+  /** Instead of relying on proto serialization, this\n+   *  provides  explicit serialization for OzoneTokenIdentifier.\n+   * @return byte[]\n+   */\n+  public byte[] toUniqueSerializedKey() {\n+    ByteBuffer result =\n+        ByteBuffer.allocate(4096);\n+    result.order(ByteOrder.BIG_ENDIAN);\n+    try {\n+      result.putLong(getIssueDate());\n+      result.putInt(getMasterKeyId());\n+      result.putInt(getSequenceNumber());\n+\n+      result.putLong(getMaxDate());\n+\n+      result.putInt(getOwner().toString().length());", "originalCommit": "e644a17a8b18115327cab0585c940d6566374cd7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDEwNzAzMg==", "url": "https://github.com/apache/ozone/pull/1182#discussion_r454107032", "bodyText": "this will change after I use super.write()", "author": "prashantpogde", "createdAt": "2020-07-14T05:18:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDAxMTE3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDAxMTc5MQ==", "url": "https://github.com/apache/ozone/pull/1182#discussion_r454011791", "bodyText": "We could simplify the code by leveraging the readFields from parent class to deserialize non-protoc token id.", "author": "xiaoyuyao", "createdAt": "2020-07-13T23:43:35Z", "path": "hadoop-ozone/common/src/main/java/org/apache/hadoop/ozone/security/OzoneTokenIdentifier.java", "diffHunk": "@@ -77,6 +80,122 @@ public Text getKind() {\n     return KIND_NAME;\n   }\n \n+  /** Instead of relying on proto serialization, this\n+   *  provides  explicit serialization for OzoneTokenIdentifier.\n+   * @return byte[]\n+   */\n+  public byte[] toUniqueSerializedKey() {\n+    ByteBuffer result =\n+        ByteBuffer.allocate(4096);\n+    result.order(ByteOrder.BIG_ENDIAN);\n+    try {\n+      result.putLong(getIssueDate());\n+      result.putInt(getMasterKeyId());\n+      result.putInt(getSequenceNumber());\n+\n+      result.putLong(getMaxDate());\n+\n+      result.putInt(getOwner().toString().length());\n+      result.put(getOwner().toString().getBytes(StandardCharsets.UTF_8));\n+\n+      result.putInt(getRealUser().toString().length());\n+      result.put(getRealUser().toString().getBytes(StandardCharsets.UTF_8));\n+\n+      result.putInt(getRenewer().toString().length());\n+      result.put(getRenewer().toString().getBytes(StandardCharsets.UTF_8));\n+\n+      result.putInt(getTokenType().getNumber());\n+      // Set s3 specific fields.\n+      if (getTokenType().equals(S3AUTHINFO)) {\n+        result.putInt(getAwsAccessId().length());\n+        result.put(getAwsAccessId().getBytes(StandardCharsets.UTF_8));\n+\n+        result.putInt(getSignature().length());\n+        result.put(getSignature().getBytes(StandardCharsets.UTF_8));\n+\n+        result.putInt(getStrToSign().length());\n+        result.put(getStrToSign().getBytes(StandardCharsets.UTF_8));\n+      } else {\n+        result.putInt(getOmCertSerialId().length());\n+        result.put(getOmCertSerialId().getBytes(StandardCharsets.UTF_8));\n+        if (getOmServiceId() != null) {\n+          result.putInt(getOmServiceId().length());\n+          result.put(getOmServiceId().getBytes(StandardCharsets.UTF_8));\n+        } else {\n+          result.putInt(0);\n+        }\n+      }\n+    } catch (IndexOutOfBoundsException e) {\n+      throw new IllegalArgumentException(\n+          \"Can't encode the the raw data \", e);\n+    }\n+    return result.array();\n+  }\n+\n+  /** Instead of relying on proto deserialization, this\n+   *  provides  explicit deserialization for OzoneTokenIdentifier.\n+   * @return byte[]\n+   */\n+  public static OzoneTokenIdentifier fromUniqueSerializedKey(byte[] rawData) {\n+    OzoneTokenIdentifier result = newInstance();", "originalCommit": "e644a17a8b18115327cab0585c940d6566374cd7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDEwNzE4NQ==", "url": "https://github.com/apache/ozone/pull/1182#discussion_r454107185", "bodyText": "Earlier I wanted to do explicit serialization, but your suggestion looks simpler. I will try this.", "author": "prashantpogde", "createdAt": "2020-07-14T05:18:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDAxMTc5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDE2NTM5Ng==", "url": "https://github.com/apache/ozone/pull/1182#discussion_r454165396", "bodyText": "I have uploaded the changes as suggested by @xiaoyuyao Please take a look..", "author": "prashantpogde", "createdAt": "2020-07-14T07:41:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDAxMTc5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDIwNDI5Ng==", "url": "https://github.com/apache/ozone/pull/1182#discussion_r454204296", "bodyText": "One failure in coverage check looks unreleted.", "author": "prashantpogde", "createdAt": "2020-07-14T08:51:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDAxMTc5MQ=="}], "type": "inlineReview"}, {"oid": "ba3da0e52b99ce26d8475ee815144c6a1921519d", "url": "https://github.com/apache/ozone/commit/ba3da0e52b99ce26d8475ee815144c6a1921519d", "message": "HDDS-3926. OM Token Identifier: Serialization changes after code review.", "committedDate": "2020-07-14T07:04:13Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ3NDI1NQ==", "url": "https://github.com/apache/ozone/pull/1182#discussion_r454474255", "bodyText": "Thanks @prashantpogde  for the update. LGTM overall. Only one question: the null check on line100 should be removed. WritableUtils.writeString will write len=-1 for null and the WritableUtils.readString will populate null back during de-serialization. This way, we will have matched deserialization code on the code in line129-130.\n+1 after that being fixed.", "author": "xiaoyuyao", "createdAt": "2020-07-14T16:12:59Z", "path": "hadoop-ozone/common/src/main/java/org/apache/hadoop/ozone/security/OzoneTokenIdentifier.java", "diffHunk": "@@ -77,6 +81,57 @@ public Text getKind() {\n     return KIND_NAME;\n   }\n \n+  /** Instead of relying on proto serialization, this\n+   *  provides  explicit serialization for OzoneTokenIdentifier.\n+   * @return byte[]\n+   */\n+  public byte[] toUniqueSerializedKey() {\n+    DataOutputBuffer buf = new DataOutputBuffer();\n+    try {\n+      super.write(buf);\n+      WritableUtils.writeVInt(buf, getTokenType().getNumber());\n+      // Set s3 specific fields.\n+      if (getTokenType().equals(S3AUTHINFO)) {\n+        WritableUtils.writeString(buf, getAwsAccessId());\n+        WritableUtils.writeString(buf, getSignature());\n+        WritableUtils.writeString(buf, getStrToSign());\n+      } else {\n+        WritableUtils.writeString(buf, getOmCertSerialId());\n+        if (getOmServiceId() != null) {", "originalCommit": "45030d9f654d6ec60fb7d71e2a7906e154dcc89c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "a164a675f953579b7226e298a829f15ff1bfc87e", "url": "https://github.com/apache/ozone/commit/a164a675f953579b7226e298a829f15ff1bfc87e", "message": "HDDS-3926. Part3: OM Token Identifier: Serialization changes after code review.", "committedDate": "2020-07-14T16:33:51Z", "type": "commit"}, {"oid": "a164a675f953579b7226e298a829f15ff1bfc87e", "url": "https://github.com/apache/ozone/commit/a164a675f953579b7226e298a829f15ff1bfc87e", "message": "HDDS-3926. Part3: OM Token Identifier: Serialization changes after code review.", "committedDate": "2020-07-14T16:33:51Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTUxOTE5Nw==", "url": "https://github.com/apache/ozone/pull/1182#discussion_r455519197", "bodyText": "We should catch IOException here and fall back to reading the old format to avoid OM failures to load tokens in old format upon upgrade/restart. We can rewrite the loaded token with the new format like HDDS-3925 upon hitting tokens in old format to avoid future fallbacks. But I'm OK without it given old tokens in old format will be expired in 7 days anyway (unlike the pipeline id) and the new tokens will be written in new format.\nI also suggest we add a unit test like below that can repro the loading failure cases in TestOzoneTokenIdentifier.java.\n  @Test\n  public void testTokenPersistence() throws IOException {\n    OzoneTokenIdentifier idWrite = getIdentifierInst();\n    idWrite.setOmServiceId(\"defaultServiceId\");\n\n    byte[] oldIdBytes = idWrite.getBytes();\n    TokenIdentifierCodec idCodec = new TokenIdentifierCodec();\n\n    OzoneTokenIdentifier idRead = null;\n    try {\n      idRead =  idCodec.fromPersistedFormat(oldIdBytes);\n    } catch (IOException ex) {\n      Assert.fail(\"Should not fail to load old token format\");\n    }\n    Assert.assertEquals(\"Deserialize Serialized Token should equal.\",\n        idWrite, idRead);\n  }", "author": "xiaoyuyao", "createdAt": "2020-07-16T05:31:20Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/codec/TokenIdentifierCodec.java", "diffHunk": "@@ -42,8 +42,9 @@ public OzoneTokenIdentifier fromPersistedFormat(byte[] rawData)\n     Preconditions.checkNotNull(rawData,\n         \"Null byte array can't converted to real object.\");\n     try {\n-      return OzoneTokenIdentifier.readProtoBuf(rawData);\n-    } catch (InvalidProtocolBufferException e) {\n+      OzoneTokenIdentifier object = OzoneTokenIdentifier.newInstance();\n+      return object.fromUniqueSerializedKey(rawData);\n+    } catch (BufferUnderflowException e) {", "originalCommit": "a164a675f953579b7226e298a829f15ff1bfc87e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTk3NDk2NQ==", "url": "https://github.com/apache/ozone/pull/1182#discussion_r455974965", "bodyText": "done", "author": "prashantpogde", "createdAt": "2020-07-16T18:05:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTUxOTE5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTUxOTg0MA==", "url": "https://github.com/apache/ozone/pull/1182#discussion_r455519840", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                } catch (BufferUnderflowException e) {\n          \n          \n            \n                } catch (IOException ex) {\n          \n          \n            \n                  return OzoneTokenIdentifier.readProtoBuf(rawData);\n          \n          \n            \n                } catch (BufferUnderflowException e) {", "author": "xiaoyuyao", "createdAt": "2020-07-16T05:33:42Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/codec/TokenIdentifierCodec.java", "diffHunk": "@@ -42,8 +42,9 @@ public OzoneTokenIdentifier fromPersistedFormat(byte[] rawData)\n     Preconditions.checkNotNull(rawData,\n         \"Null byte array can't converted to real object.\");\n     try {\n-      return OzoneTokenIdentifier.readProtoBuf(rawData);\n-    } catch (InvalidProtocolBufferException e) {\n+      OzoneTokenIdentifier object = OzoneTokenIdentifier.newInstance();\n+      return object.fromUniqueSerializedKey(rawData);\n+    } catch (BufferUnderflowException e) {", "originalCommit": "a164a675f953579b7226e298a829f15ff1bfc87e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTk3NTAzMQ==", "url": "https://github.com/apache/ozone/pull/1182#discussion_r455975031", "bodyText": "done", "author": "prashantpogde", "createdAt": "2020-07-16T18:06:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTUxOTg0MA=="}], "type": "inlineReview"}, {"oid": "cd999130a8485f07f852da6da947798117439913", "url": "https://github.com/apache/ozone/commit/cd999130a8485f07f852da6da947798117439913", "message": "HDDS-3926. Part4: OM Token Identifier: Serialization changes after code review.", "committedDate": "2020-07-16T18:03:54Z", "type": "commit"}]}