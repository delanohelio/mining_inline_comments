{"pr_number": 503, "pr_title": "HDDS-2850. Handle Create container use case in Recon.", "pr_createdAt": "2020-01-29T19:07:24Z", "pr_url": "https://github.com/apache/ozone/pull/503", "timeline": [{"oid": "9e5121f94ab6e6a923a059a8aef5116f06ef4746", "url": "https://github.com/apache/ozone/commit/9e5121f94ab6e6a923a059a8aef5116f06ef4746", "message": "HDDS-2850. Handle Create container use case in Recon.", "committedDate": "2020-01-29T19:03:57Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjcyMzQxOA==", "url": "https://github.com/apache/ozone/pull/503#discussion_r372723418", "bodyText": "This should likely be filed as separate Jira, but why is this not a ReadWriteLock?", "author": "swagle", "createdAt": "2020-01-30T01:44:46Z", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/SCMContainerManager.java", "diffHunk": "@@ -194,6 +194,18 @@ public ContainerInfo getContainer(final ContainerID containerID)\n     return containerStateManager.getContainer(containerID);\n   }\n \n+  @Override\n+  public boolean exists(ContainerID containerID) {\n+    lock.lock();", "originalCommit": "9e5121f94ab6e6a923a059a8aef5116f06ef4746", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mjc4NDgxMg==", "url": "https://github.com/apache/ozone/pull/503#discussion_r372784812", "bodyText": "Not sure. SCM ContainerManager has had a Reentrant lock from the first. I will investigate why it is not a RW lock, and create a new JIRA for this.", "author": "avijayanhwx", "createdAt": "2020-01-30T06:59:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjcyMzQxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjcyNTI5Mg==", "url": "https://github.com/apache/ozone/pull/503#discussion_r372725292", "bodyText": "Minor: instead of getUuid() let toString method of DatanodeDetails determine what is printed.", "author": "swagle", "createdAt": "2020-01-30T01:53:46Z", "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/scm/ReconIncrementalContainerReportHandler.java", "diffHunk": "@@ -0,0 +1,108 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon.scm;\n+\n+import java.io.IOException;\n+\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos.ContainerReplicaProto;\n+import org.apache.hadoop.hdds.scm.container.ContainerID;\n+import org.apache.hadoop.hdds.scm.container.ContainerManager;\n+import org.apache.hadoop.hdds.scm.container.ContainerNotFoundException;\n+import org.apache.hadoop.hdds.scm.container.IncrementalContainerReportHandler;\n+import org.apache.hadoop.hdds.scm.container.common.helpers.ContainerWithPipeline;\n+import org.apache.hadoop.hdds.scm.node.NodeManager;\n+import org.apache.hadoop.hdds.scm.node.states.NodeNotFoundException;\n+import org.apache.hadoop.hdds.scm.server.SCMDatanodeHeartbeatDispatcher.IncrementalContainerReportFromDatanode;\n+import org.apache.hadoop.hdds.server.events.EventPublisher;\n+import org.apache.hadoop.ozone.recon.spi.StorageContainerServiceProvider;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Recon ICR handler.\n+ */\n+public class ReconIncrementalContainerReportHandler\n+    extends IncrementalContainerReportHandler {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(\n+      ReconIncrementalContainerReportHandler.class);\n+\n+  private StorageContainerServiceProvider scmClient;\n+\n+  public ReconIncrementalContainerReportHandler(NodeManager nodeManager,\n+      ContainerManager containerManager,\n+      StorageContainerServiceProvider scmClient) {\n+    super(nodeManager, containerManager);\n+    this.scmClient = scmClient;\n+  }\n+\n+  @Override\n+  public void onMessage(final IncrementalContainerReportFromDatanode report,\n+                        final EventPublisher publisher) {\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Processing incremental container report from data node {}\",\n+          report.getDatanodeDetails().getUuid());", "originalCommit": "9e5121f94ab6e6a923a059a8aef5116f06ef4746", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mjc4NTE4MQ==", "url": "https://github.com/apache/ozone/pull/503#discussion_r372785181", "bodyText": "Thanks for the suggestion, fixed!", "author": "avijayanhwx", "createdAt": "2020-01-30T07:00:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjcyNTI5Mg=="}], "type": "inlineReview"}, {"oid": "7c99a43c432cad15a173f13e5e99a3ddf6105f77", "url": "https://github.com/apache/ozone/commit/7c99a43c432cad15a173f13e5e99a3ddf6105f77", "message": "HDDS-2850. Address review comment.", "committedDate": "2020-01-30T07:00:11Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzEyNzA1OQ==", "url": "https://github.com/apache/ozone/pull/503#discussion_r373127059", "bodyText": "Nit: can be simplified to\ngetContainerManager().notifyContainerReportProcessing(false, success);", "author": "adoroszlai", "createdAt": "2020-01-30T18:47:18Z", "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/scm/ReconIncrementalContainerReportHandler.java", "diffHunk": "@@ -0,0 +1,108 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon.scm;\n+\n+import java.io.IOException;\n+\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos.ContainerReplicaProto;\n+import org.apache.hadoop.hdds.scm.container.ContainerID;\n+import org.apache.hadoop.hdds.scm.container.ContainerManager;\n+import org.apache.hadoop.hdds.scm.container.ContainerNotFoundException;\n+import org.apache.hadoop.hdds.scm.container.IncrementalContainerReportHandler;\n+import org.apache.hadoop.hdds.scm.container.common.helpers.ContainerWithPipeline;\n+import org.apache.hadoop.hdds.scm.node.NodeManager;\n+import org.apache.hadoop.hdds.scm.node.states.NodeNotFoundException;\n+import org.apache.hadoop.hdds.scm.server.SCMDatanodeHeartbeatDispatcher.IncrementalContainerReportFromDatanode;\n+import org.apache.hadoop.hdds.server.events.EventPublisher;\n+import org.apache.hadoop.ozone.recon.spi.StorageContainerServiceProvider;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Recon ICR handler.\n+ */\n+public class ReconIncrementalContainerReportHandler\n+    extends IncrementalContainerReportHandler {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(\n+      ReconIncrementalContainerReportHandler.class);\n+\n+  private StorageContainerServiceProvider scmClient;\n+\n+  public ReconIncrementalContainerReportHandler(NodeManager nodeManager,\n+      ContainerManager containerManager,\n+      StorageContainerServiceProvider scmClient) {\n+    super(nodeManager, containerManager);\n+    this.scmClient = scmClient;\n+  }\n+\n+  @Override\n+  public void onMessage(final IncrementalContainerReportFromDatanode report,\n+                        final EventPublisher publisher) {\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Processing incremental container report from data node {}\",\n+          report.getDatanodeDetails());\n+    }\n+\n+    ReconContainerManager containerManager =\n+        (ReconContainerManager) getContainerManager();\n+    boolean success = true;\n+    for (ContainerReplicaProto replicaProto :\n+        report.getReport().getReportList()) {\n+      try {\n+        final DatanodeDetails dd = report.getDatanodeDetails();\n+        final ContainerID id = ContainerID.valueof(\n+            replicaProto.getContainerID());\n+        if (!getContainerManager().exists(id)) {\n+          LOG.info(\"New container {} got from {}.\", id,\n+              report.getDatanodeDetails());\n+          try {\n+            ContainerWithPipeline containerWithPipeline =\n+                scmClient.getContainerWithPipeline(id.getId());\n+            containerManager.addNewContainer(id.getId(), containerWithPipeline);\n+          } catch (IOException ioEx) {\n+            LOG.error(\"Exception while getting new container info from SCM\",\n+                ioEx);\n+            return;\n+          }\n+        }\n+        getNodeManager().addContainer(dd, id);\n+        processContainerReplica(dd, replicaProto);\n+      } catch (ContainerNotFoundException e) {\n+        success = false;\n+        LOG.warn(\"Container {} not found!\", replicaProto.getContainerID());\n+      } catch (NodeNotFoundException ex) {\n+        success = false;\n+        LOG.error(\"Received ICR from unknown datanode {} {}\",\n+            report.getDatanodeDetails(), ex);\n+      } catch (IOException e) {\n+        success = false;\n+        LOG.error(\"Exception while processing ICR for container {}\",\n+            replicaProto.getContainerID());\n+      }\n+    }\n+\n+    if (success) {\n+      getContainerManager().notifyContainerReportProcessing(false, true);\n+    } else {\n+      getContainerManager().notifyContainerReportProcessing(false, false);\n+    }", "originalCommit": "7c99a43c432cad15a173f13e5e99a3ddf6105f77", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzE1MTU2NQ==", "url": "https://github.com/apache/ozone/pull/503#discussion_r373151565", "bodyText": "Fixed.", "author": "avijayanhwx", "createdAt": "2020-01-30T19:35:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzEyNzA1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzE1NDQyMA==", "url": "https://github.com/apache/ozone/pull/503#discussion_r373154420", "bodyText": "This code was just copied from SCM's IncrementalContainerReportHandler. FYI -> apache/hadoop#1541 (comment)", "author": "avijayanhwx", "createdAt": "2020-01-30T19:40:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzEyNzA1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzEzMDgzOA==", "url": "https://github.com/apache/ozone/pull/503#discussion_r373130838", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                assertTrue(containers.get(0).equals(containerInfo));\n          \n          \n            \n                assertEquals(containerInfo, containers.get(0));", "author": "adoroszlai", "createdAt": "2020-01-30T18:54:26Z", "path": "hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/scm/TestReconContainerManager.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon.scm;\n+\n+import static org.apache.hadoop.hdds.protocol.proto.HddsProtos.LifeCycleState.OPEN;\n+import static org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationFactor.ONE;\n+import static org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationType.STAND_ALONE;\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_SCM_NAMES;\n+import static org.apache.hadoop.ozone.OzoneConfigKeys.OZONE_METADATA_DIRS;\n+import static org.apache.hadoop.ozone.recon.AbstractOMMetadataManagerTest.getRandomPipeline;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.NavigableSet;\n+\n+import org.apache.hadoop.hdds.conf.OzoneConfiguration;\n+import org.apache.hadoop.hdds.scm.container.ContainerID;\n+import org.apache.hadoop.hdds.scm.container.ContainerInfo;\n+import org.apache.hadoop.hdds.scm.container.common.helpers.ContainerWithPipeline;\n+import org.apache.hadoop.hdds.scm.net.NetworkTopology;\n+import org.apache.hadoop.hdds.scm.net.NetworkTopologyImpl;\n+import org.apache.hadoop.hdds.scm.node.NodeManager;\n+import org.apache.hadoop.hdds.scm.node.SCMNodeManager;\n+import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n+import org.apache.hadoop.hdds.scm.server.SCMStorageConfig;\n+import org.apache.hadoop.hdds.server.events.EventQueue;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+\n+/**\n+ * Test Recon Container Manager.\n+ */\n+public class TestReconContainerManager {\n+\n+  @Rule\n+  public TemporaryFolder temporaryFolder = new TemporaryFolder();\n+\n+  private OzoneConfiguration conf;\n+  private SCMStorageConfig scmStorageConfig;\n+  private ReconPipelineManager pipelineManager;\n+  private ReconContainerManager containerManager;\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    conf = new OzoneConfiguration();\n+    conf.set(OZONE_METADATA_DIRS,\n+        temporaryFolder.newFolder().getAbsolutePath());\n+    conf.set(OZONE_SCM_NAMES, \"localhost\");\n+    scmStorageConfig = new ReconStorageConfig(conf);\n+    NetworkTopology clusterMap = new NetworkTopologyImpl(conf);\n+    EventQueue eventQueue = new EventQueue();\n+    NodeManager nodeManager =\n+        new SCMNodeManager(conf, scmStorageConfig, eventQueue, clusterMap);\n+    pipelineManager = new ReconPipelineManager(conf, nodeManager, eventQueue);\n+    containerManager = new ReconContainerManager(conf, pipelineManager);\n+  }\n+\n+  @After\n+  public void tearDown() throws IOException {\n+    containerManager.close();\n+    pipelineManager.close();\n+  }\n+\n+  @Test\n+  public void testAddNewContainer() throws IOException {\n+    ContainerID containerID = new ContainerID(100L);\n+    Pipeline pipeline = getRandomPipeline();\n+    pipelineManager.addPipeline(pipeline);\n+    ContainerInfo containerInfo =\n+        new ContainerInfo.Builder()\n+            .setContainerID(containerID.getId())\n+            .setNumberOfKeys(10)\n+            .setPipelineID(pipeline.getId())\n+            .setReplicationFactor(ONE)\n+            .setOwner(\"test\")\n+            .setState(OPEN)\n+            .setReplicationType(STAND_ALONE)\n+            .build();\n+    ContainerWithPipeline containerWithPipeline =\n+        new ContainerWithPipeline(containerInfo, pipeline);\n+\n+    assertFalse(containerManager.exists(containerID));\n+\n+    containerManager.addNewContainer(\n+        containerID.getId(), containerWithPipeline);\n+\n+    assertTrue(containerManager.exists(containerID));\n+\n+    List<ContainerInfo> containers = containerManager.getContainers(OPEN);\n+    assertEquals(1, containers.size());\n+    assertTrue(containers.get(0).equals(containerInfo));", "originalCommit": "7c99a43c432cad15a173f13e5e99a3ddf6105f77", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzE1MTYxMw==", "url": "https://github.com/apache/ozone/pull/503#discussion_r373151613", "bodyText": "Fixed.", "author": "avijayanhwx", "createdAt": "2020-01-30T19:35:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzEzMDgzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzEzMTE0NA==", "url": "https://github.com/apache/ozone/pull/503#discussion_r373131144", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                assertTrue(containersInPipeline.first().equals(containerID));\n          \n          \n            \n                assertEquals(containerID, containersInPipeline.first());", "author": "adoroszlai", "createdAt": "2020-01-30T18:55:02Z", "path": "hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/scm/TestReconContainerManager.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon.scm;\n+\n+import static org.apache.hadoop.hdds.protocol.proto.HddsProtos.LifeCycleState.OPEN;\n+import static org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationFactor.ONE;\n+import static org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationType.STAND_ALONE;\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_SCM_NAMES;\n+import static org.apache.hadoop.ozone.OzoneConfigKeys.OZONE_METADATA_DIRS;\n+import static org.apache.hadoop.ozone.recon.AbstractOMMetadataManagerTest.getRandomPipeline;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.NavigableSet;\n+\n+import org.apache.hadoop.hdds.conf.OzoneConfiguration;\n+import org.apache.hadoop.hdds.scm.container.ContainerID;\n+import org.apache.hadoop.hdds.scm.container.ContainerInfo;\n+import org.apache.hadoop.hdds.scm.container.common.helpers.ContainerWithPipeline;\n+import org.apache.hadoop.hdds.scm.net.NetworkTopology;\n+import org.apache.hadoop.hdds.scm.net.NetworkTopologyImpl;\n+import org.apache.hadoop.hdds.scm.node.NodeManager;\n+import org.apache.hadoop.hdds.scm.node.SCMNodeManager;\n+import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n+import org.apache.hadoop.hdds.scm.server.SCMStorageConfig;\n+import org.apache.hadoop.hdds.server.events.EventQueue;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+\n+/**\n+ * Test Recon Container Manager.\n+ */\n+public class TestReconContainerManager {\n+\n+  @Rule\n+  public TemporaryFolder temporaryFolder = new TemporaryFolder();\n+\n+  private OzoneConfiguration conf;\n+  private SCMStorageConfig scmStorageConfig;\n+  private ReconPipelineManager pipelineManager;\n+  private ReconContainerManager containerManager;\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    conf = new OzoneConfiguration();\n+    conf.set(OZONE_METADATA_DIRS,\n+        temporaryFolder.newFolder().getAbsolutePath());\n+    conf.set(OZONE_SCM_NAMES, \"localhost\");\n+    scmStorageConfig = new ReconStorageConfig(conf);\n+    NetworkTopology clusterMap = new NetworkTopologyImpl(conf);\n+    EventQueue eventQueue = new EventQueue();\n+    NodeManager nodeManager =\n+        new SCMNodeManager(conf, scmStorageConfig, eventQueue, clusterMap);\n+    pipelineManager = new ReconPipelineManager(conf, nodeManager, eventQueue);\n+    containerManager = new ReconContainerManager(conf, pipelineManager);\n+  }\n+\n+  @After\n+  public void tearDown() throws IOException {\n+    containerManager.close();\n+    pipelineManager.close();\n+  }\n+\n+  @Test\n+  public void testAddNewContainer() throws IOException {\n+    ContainerID containerID = new ContainerID(100L);\n+    Pipeline pipeline = getRandomPipeline();\n+    pipelineManager.addPipeline(pipeline);\n+    ContainerInfo containerInfo =\n+        new ContainerInfo.Builder()\n+            .setContainerID(containerID.getId())\n+            .setNumberOfKeys(10)\n+            .setPipelineID(pipeline.getId())\n+            .setReplicationFactor(ONE)\n+            .setOwner(\"test\")\n+            .setState(OPEN)\n+            .setReplicationType(STAND_ALONE)\n+            .build();\n+    ContainerWithPipeline containerWithPipeline =\n+        new ContainerWithPipeline(containerInfo, pipeline);\n+\n+    assertFalse(containerManager.exists(containerID));\n+\n+    containerManager.addNewContainer(\n+        containerID.getId(), containerWithPipeline);\n+\n+    assertTrue(containerManager.exists(containerID));\n+\n+    List<ContainerInfo> containers = containerManager.getContainers(OPEN);\n+    assertEquals(1, containers.size());\n+    assertTrue(containers.get(0).equals(containerInfo));\n+    NavigableSet<ContainerID> containersInPipeline =\n+        pipelineManager.getContainersInPipeline(pipeline.getId());\n+    assertEquals(1, containersInPipeline.size());\n+    assertTrue(containersInPipeline.first().equals(containerID));", "originalCommit": "7c99a43c432cad15a173f13e5e99a3ddf6105f77", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzE1MTY0Ng==", "url": "https://github.com/apache/ozone/pull/503#discussion_r373151646", "bodyText": "Fixed.", "author": "avijayanhwx", "createdAt": "2020-01-30T19:35:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzEzMTE0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzEzNTUyMA==", "url": "https://github.com/apache/ozone/pull/503#discussion_r373135520", "bodyText": "Seems to be duplicated between these test classes.  Would be nice to reduce it in a follow-up.", "author": "adoroszlai", "createdAt": "2020-01-30T19:03:37Z", "path": "hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/scm/TestReconIncrementalContainerReportHandler.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon.scm;\n+\n+import static org.apache.hadoop.hdds.protocol.MockDatanodeDetails.randomDatanodeDetails;\n+import static org.apache.hadoop.hdds.protocol.proto.HddsProtos.LifeCycleState.OPEN;\n+import static org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationFactor.ONE;\n+import static org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationType.STAND_ALONE;\n+import static org.apache.hadoop.hdds.scm.ScmConfigKeys.OZONE_SCM_NAMES;\n+import static org.apache.hadoop.ozone.OzoneConfigKeys.OZONE_METADATA_DIRS;\n+import static org.apache.hadoop.ozone.recon.AbstractOMMetadataManagerTest.getRandomPipeline;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+import java.io.IOException;\n+\n+import org.apache.hadoop.hdds.conf.OzoneConfiguration;\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos.ContainerReplicaProto;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos.ContainerReplicaProto.State;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos.IncrementalContainerReportProto;\n+import org.apache.hadoop.hdds.scm.container.ContainerID;\n+import org.apache.hadoop.hdds.scm.container.ContainerInfo;\n+import org.apache.hadoop.hdds.scm.container.common.helpers.ContainerWithPipeline;\n+import org.apache.hadoop.hdds.scm.net.NetworkTopology;\n+import org.apache.hadoop.hdds.scm.net.NetworkTopologyImpl;\n+import org.apache.hadoop.hdds.scm.node.NodeManager;\n+import org.apache.hadoop.hdds.scm.node.SCMNodeManager;\n+import org.apache.hadoop.hdds.scm.node.states.NodeNotFoundException;\n+import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n+import org.apache.hadoop.hdds.scm.server.SCMDatanodeHeartbeatDispatcher.IncrementalContainerReportFromDatanode;\n+import org.apache.hadoop.hdds.scm.server.SCMStorageConfig;\n+import org.apache.hadoop.hdds.server.events.EventPublisher;\n+import org.apache.hadoop.hdds.server.events.EventQueue;\n+import org.apache.hadoop.ozone.recon.spi.StorageContainerServiceProvider;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+\n+/**\n+ * Test Recon ICR handler.\n+ */\n+public class TestReconIncrementalContainerReportHandler {\n+\n+  @Rule\n+  public TemporaryFolder temporaryFolder = new TemporaryFolder();\n+\n+  private OzoneConfiguration conf;\n+  private SCMStorageConfig scmStorageConfig;\n+  private ReconPipelineManager pipelineManager;\n+  private ReconContainerManager containerManager;\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    conf = new OzoneConfiguration();\n+    conf.set(OZONE_METADATA_DIRS,\n+        temporaryFolder.newFolder().getAbsolutePath());\n+    conf.set(OZONE_SCM_NAMES, \"localhost\");\n+    scmStorageConfig = new ReconStorageConfig(conf);\n+    NetworkTopology clusterMap = new NetworkTopologyImpl(conf);\n+    EventQueue eventQueue = new EventQueue();\n+    NodeManager nodeManager =\n+        new SCMNodeManager(conf, scmStorageConfig, eventQueue, clusterMap);\n+    pipelineManager = new ReconPipelineManager(conf, nodeManager, eventQueue);\n+    containerManager = new ReconContainerManager(conf, pipelineManager);\n+  }\n+\n+  @After\n+  public void tearDown() throws IOException {\n+    containerManager.close();\n+    pipelineManager.close();\n+  }", "originalCommit": "7c99a43c432cad15a173f13e5e99a3ddf6105f77", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzE1MTc0MA==", "url": "https://github.com/apache/ozone/pull/503#discussion_r373151740", "bodyText": "Thanks for keeping me honest :) Fixed.", "author": "avijayanhwx", "createdAt": "2020-01-30T19:35:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzEzNTUyMA=="}], "type": "inlineReview"}, {"oid": "4088c06eb9e510b3c91808babe22adf473dd4666", "url": "https://github.com/apache/ozone/commit/4088c06eb9e510b3c91808babe22adf473dd4666", "message": "HDDS-2850. Unit test refactoring.", "committedDate": "2020-01-30T19:34:44Z", "type": "commit"}]}