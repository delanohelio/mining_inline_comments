{"pr_number": 266, "pr_title": "Refactor stream encoder and Add data encoder for protobuf", "pr_createdAt": "2020-04-21T12:42:37Z", "pr_url": "https://github.com/linkedin/rest.li/pull/266", "timeline": [{"oid": "55a9d658d370692789d141aada97b00f9cb2b87b", "url": "https://github.com/linkedin/rest.li/commit/55a9d658d370692789d141aada97b00f9cb2b87b", "message": "Refactor stream encoder and Add data encoder for protobuf", "committedDate": "2020-04-21T12:53:13Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjM1NDg4Nw==", "url": "https://github.com/linkedin/rest.li/pull/266#discussion_r412354887", "bodyText": "Why did we make this public?", "author": "karthikrg", "createdAt": "2020-04-21T17:34:41Z", "path": "data/src/main/java/com/linkedin/data/codec/AbstractJacksonDataCodec.java", "diffHunk": "@@ -248,7 +248,7 @@ public void objectToJsonGenerator(Object object, JsonGenerator generator, boolea\n     protected final JsonGenerator _generator;\n     private final boolean _orderMapEntriesByKey;\n \n-    protected JacksonTraverseCallback(JsonGenerator generator)\n+    public JacksonTraverseCallback(JsonGenerator generator)", "originalCommit": "55a9d658d370692789d141aada97b00f9cb2b87b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjQ3ODA1MQ==", "url": "https://github.com/linkedin/rest.li/pull/266#discussion_r412478051", "bodyText": "to access in entity stream encoders. reverted as not required now", "author": "aman1309", "createdAt": "2020-04-21T20:43:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjM1NDg4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjM1NjA0MA==", "url": "https://github.com/linkedin/rest.li/pull/266#discussion_r412356040", "bodyText": "Suggest renaming this to createTraverseCallback for consistency with the blocking codec", "author": "karthikrg", "createdAt": "2020-04-21T17:36:15Z", "path": "data/src/main/java/com/linkedin/data/codec/entitystream/AbstractDataEncoder.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+   Copyright (c) 2020 LinkedIn Corp.\n+\n+   Licensed under the Apache License, Version 2.0 (the \"License\");\n+   you may not use this file except in compliance with the License.\n+   You may obtain a copy of the License at\n+\n+       http://www.apache.org/licenses/LICENSE-2.0\n+\n+   Unless required by applicable law or agreed to in writing, software\n+   distributed under the License is distributed on an \"AS IS\" BASIS,\n+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+   See the License for the specific language governing permissions and\n+   limitations under the License.\n+ */\n+\n+package com.linkedin.data.codec.entitystream;\n+\n+import com.linkedin.data.ByteString;\n+import com.linkedin.data.Data;\n+import com.linkedin.data.DataComplex;\n+import com.linkedin.data.DataList;\n+import com.linkedin.data.DataMap;\n+import com.linkedin.entitystream.WriteHandle;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.util.ArrayDeque;\n+import java.util.Deque;\n+import java.util.Iterator;\n+import java.util.Map;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Abstract data type encoder for a {@link com.linkedin.data.DataComplex} object implemented as a\n+ * {@link com.linkedin.entitystream.Writer} writing to an {@link com.linkedin.entitystream.EntityStream} of\n+ * {@link ByteString}. The implementation writes to an internal non-blocking <code>OutputStream</code>\n+ * implementation that has a fixed-size primary buffer and an unbounded overflow buffer. Because the bytes are pulled\n+ * from the encoder asynchronously, it needs to keep the state in a stack.\n+ *\n+ * @author kramgopa, xma\n+ */\n+abstract class AbstractDataEncoder implements DataEncoder\n+{\n+  private static final Logger LOGGER = LoggerFactory.getLogger(AbstractDataEncoder.class);\n+\n+  private static final Object MAP = new Object();\n+  private static final Object LIST = new Object();\n+\n+  private Data.TraverseCallback _traverseCallback;\n+  private QueueBufferedOutputStream _out;\n+  private Deque<DataComplex> _stack;\n+  private Deque<Iterator<?>> _iteratorStack;\n+  private Deque<Object> _typeStack;\n+  private WriteHandle<? super ByteString> _writeHandle;\n+  private boolean _done;\n+\n+  private AbstractDataEncoder(int bufferSize)\n+  {\n+    _out = new QueueBufferedOutputStream(bufferSize);\n+    _stack = new ArrayDeque<>();\n+    _iteratorStack = new ArrayDeque<>();\n+    _typeStack = new ArrayDeque<>();\n+    _done = false;\n+  }\n+\n+  protected AbstractDataEncoder(DataMap dataMap, int bufferSize)\n+  {\n+    this(bufferSize);\n+\n+    _stack.push(dataMap);\n+    _typeStack.push(MAP);\n+  }\n+\n+  protected AbstractDataEncoder(DataList dataList, int bufferSize)\n+  {\n+    this(bufferSize);\n+\n+    _stack.push(dataList);\n+    _typeStack.push(LIST);\n+  }\n+\n+  @Override\n+  public void onInit(WriteHandle<? super ByteString> wh)\n+  {\n+    _writeHandle = wh;\n+\n+    try\n+    {\n+      _traverseCallback = initTraverseCallback(_out);\n+    }\n+    catch (IOException e)\n+    {\n+      _writeHandle.error(e);\n+    }\n+  }\n+\n+  abstract protected Data.TraverseCallback initTraverseCallback(OutputStream out) throws IOException;", "originalCommit": "55a9d658d370692789d141aada97b00f9cb2b87b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjM1NzI5Mw==", "url": "https://github.com/linkedin/rest.li/pull/266#discussion_r412357293", "bodyText": "This part seems to be the same as the else condition in the list. Suggest moving this to a common method?", "author": "karthikrg", "createdAt": "2020-04-21T17:38:03Z", "path": "data/src/main/java/com/linkedin/data/codec/entitystream/AbstractDataEncoder.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+   Copyright (c) 2020 LinkedIn Corp.\n+\n+   Licensed under the Apache License, Version 2.0 (the \"License\");\n+   you may not use this file except in compliance with the License.\n+   You may obtain a copy of the License at\n+\n+       http://www.apache.org/licenses/LICENSE-2.0\n+\n+   Unless required by applicable law or agreed to in writing, software\n+   distributed under the License is distributed on an \"AS IS\" BASIS,\n+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+   See the License for the specific language governing permissions and\n+   limitations under the License.\n+ */\n+\n+package com.linkedin.data.codec.entitystream;\n+\n+import com.linkedin.data.ByteString;\n+import com.linkedin.data.Data;\n+import com.linkedin.data.DataComplex;\n+import com.linkedin.data.DataList;\n+import com.linkedin.data.DataMap;\n+import com.linkedin.entitystream.WriteHandle;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.util.ArrayDeque;\n+import java.util.Deque;\n+import java.util.Iterator;\n+import java.util.Map;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Abstract data type encoder for a {@link com.linkedin.data.DataComplex} object implemented as a\n+ * {@link com.linkedin.entitystream.Writer} writing to an {@link com.linkedin.entitystream.EntityStream} of\n+ * {@link ByteString}. The implementation writes to an internal non-blocking <code>OutputStream</code>\n+ * implementation that has a fixed-size primary buffer and an unbounded overflow buffer. Because the bytes are pulled\n+ * from the encoder asynchronously, it needs to keep the state in a stack.\n+ *\n+ * @author kramgopa, xma\n+ */\n+abstract class AbstractDataEncoder implements DataEncoder\n+{\n+  private static final Logger LOGGER = LoggerFactory.getLogger(AbstractDataEncoder.class);\n+\n+  private static final Object MAP = new Object();\n+  private static final Object LIST = new Object();\n+\n+  private Data.TraverseCallback _traverseCallback;\n+  private QueueBufferedOutputStream _out;\n+  private Deque<DataComplex> _stack;\n+  private Deque<Iterator<?>> _iteratorStack;\n+  private Deque<Object> _typeStack;\n+  private WriteHandle<? super ByteString> _writeHandle;\n+  private boolean _done;\n+\n+  private AbstractDataEncoder(int bufferSize)\n+  {\n+    _out = new QueueBufferedOutputStream(bufferSize);\n+    _stack = new ArrayDeque<>();\n+    _iteratorStack = new ArrayDeque<>();\n+    _typeStack = new ArrayDeque<>();\n+    _done = false;\n+  }\n+\n+  protected AbstractDataEncoder(DataMap dataMap, int bufferSize)\n+  {\n+    this(bufferSize);\n+\n+    _stack.push(dataMap);\n+    _typeStack.push(MAP);\n+  }\n+\n+  protected AbstractDataEncoder(DataList dataList, int bufferSize)\n+  {\n+    this(bufferSize);\n+\n+    _stack.push(dataList);\n+    _typeStack.push(LIST);\n+  }\n+\n+  @Override\n+  public void onInit(WriteHandle<? super ByteString> wh)\n+  {\n+    _writeHandle = wh;\n+\n+    try\n+    {\n+      _traverseCallback = initTraverseCallback(_out);\n+    }\n+    catch (IOException e)\n+    {\n+      _writeHandle.error(e);\n+    }\n+  }\n+\n+  abstract protected Data.TraverseCallback initTraverseCallback(OutputStream out) throws IOException;\n+\n+  abstract protected void flushOutputStream(Data.TraverseCallback traverseCallback) throws IOException;\n+\n+  /**\n+   * Pre-process this {@link DataMap} before serializing it.\n+   *\n+   * <p>This can be overridden by implementations to modify the map before serializing. Implementations may also\n+   * choose to directly serialize the map in whatever form they prefer, and return null to indicate that they have\n+   * internally handled serialization.</p>\n+   */\n+  protected DataMap preProcessMap(DataMap dataMap) throws IOException\n+  {\n+    return dataMap;\n+  }\n+\n+  /**\n+   * Pre-process this {@link DataList} before serializing it.\n+   *\n+   * <p>This can be overridden by implementations to modify the map before serializing. Implementations may also\n+   * choose to directly serialize the list in whatever form they prefer, and return null to indicate that they have\n+   * internally handled serialization.</p>\n+   */\n+  protected DataList preProcessList(DataList dataList) throws IOException\n+  {\n+    return dataList;\n+  }\n+\n+  /**\n+   * Create an iterator that will be used by the encoder to iterate over entries of this {@link DataMap} when\n+   * serializing.\n+   *\n+   * <p>This can be overridden by implementations to control the order in which entries are serialized. It is\n+   * highly recommended to not modify the iterator or the backing map after this method has been called. Doing so\n+   * may result in a {@link java.util.ConcurrentModificationException}</p>\n+   */\n+  protected Iterator<Map.Entry<String, Object>> createIterator(DataMap dataMap) throws IOException\n+  {\n+    return dataMap.entrySet().iterator();\n+  }\n+\n+  /**\n+   * Create an iterator that will be used by the encoder to iterate over elements of this {@link DataList} when\n+   * serializing.\n+   *\n+   * <p>This can be overridden by implementations to control the order in which elements are serialized. It is\n+   * highly recommended to not modify the iterator or the backing list after this method has been called. Doing so\n+   * may result in a {@link java.util.ConcurrentModificationException}</p>\n+   */\n+  protected Iterator<Object> createIterator(DataList dataList) throws IOException\n+  {\n+    return dataList.iterator();\n+  }\n+\n+  @Override\n+  public void onWritePossible()\n+  {\n+    while (_writeHandle.remaining() > 0)\n+    {\n+      if (_done)\n+      {\n+        if (_out.isEmpty())\n+        {\n+          _writeHandle.done();\n+          break;\n+        }\n+        else\n+        {\n+          _writeHandle.write(_out.getBytes());\n+        }\n+      }\n+      else if (_out.isFull())\n+      {\n+        _writeHandle.write(_out.getBytes());\n+      }\n+      else\n+      {\n+        try\n+        {\n+          generate();\n+        }\n+        catch (Exception e)\n+        {\n+          _writeHandle.error(e);\n+          break;\n+        }\n+      }\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unchecked\")\n+  private void generate()\n+      throws Exception\n+  {\n+    while (!_out.isFull())\n+    {\n+      DataComplex current = _stack.peek();\n+      if (_iteratorStack.size() != _stack.size())\n+      {\n+        if (_typeStack.peek() == MAP)\n+        {\n+          DataMap dataMap = preProcessMap((DataMap) current);\n+          if (dataMap != null)\n+          {\n+            _iteratorStack.push(createIterator(dataMap));\n+            _traverseCallback.startMap(dataMap);\n+          }\n+          else\n+          {\n+            _stack.pop();", "originalCommit": "55a9d658d370692789d141aada97b00f9cb2b87b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjM2MDIyOA==", "url": "https://github.com/linkedin/rest.li/pull/266#discussion_r412360228", "bodyText": "This method contract seems weird. What if we made TraverseCallback implement Closeable and called close on it?", "author": "karthikrg", "createdAt": "2020-04-21T17:41:50Z", "path": "data/src/main/java/com/linkedin/data/codec/entitystream/AbstractDataEncoder.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+   Copyright (c) 2020 LinkedIn Corp.\n+\n+   Licensed under the Apache License, Version 2.0 (the \"License\");\n+   you may not use this file except in compliance with the License.\n+   You may obtain a copy of the License at\n+\n+       http://www.apache.org/licenses/LICENSE-2.0\n+\n+   Unless required by applicable law or agreed to in writing, software\n+   distributed under the License is distributed on an \"AS IS\" BASIS,\n+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+   See the License for the specific language governing permissions and\n+   limitations under the License.\n+ */\n+\n+package com.linkedin.data.codec.entitystream;\n+\n+import com.linkedin.data.ByteString;\n+import com.linkedin.data.Data;\n+import com.linkedin.data.DataComplex;\n+import com.linkedin.data.DataList;\n+import com.linkedin.data.DataMap;\n+import com.linkedin.entitystream.WriteHandle;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.util.ArrayDeque;\n+import java.util.Deque;\n+import java.util.Iterator;\n+import java.util.Map;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Abstract data type encoder for a {@link com.linkedin.data.DataComplex} object implemented as a\n+ * {@link com.linkedin.entitystream.Writer} writing to an {@link com.linkedin.entitystream.EntityStream} of\n+ * {@link ByteString}. The implementation writes to an internal non-blocking <code>OutputStream</code>\n+ * implementation that has a fixed-size primary buffer and an unbounded overflow buffer. Because the bytes are pulled\n+ * from the encoder asynchronously, it needs to keep the state in a stack.\n+ *\n+ * @author kramgopa, xma\n+ */\n+abstract class AbstractDataEncoder implements DataEncoder\n+{\n+  private static final Logger LOGGER = LoggerFactory.getLogger(AbstractDataEncoder.class);\n+\n+  private static final Object MAP = new Object();\n+  private static final Object LIST = new Object();\n+\n+  private Data.TraverseCallback _traverseCallback;\n+  private QueueBufferedOutputStream _out;\n+  private Deque<DataComplex> _stack;\n+  private Deque<Iterator<?>> _iteratorStack;\n+  private Deque<Object> _typeStack;\n+  private WriteHandle<? super ByteString> _writeHandle;\n+  private boolean _done;\n+\n+  private AbstractDataEncoder(int bufferSize)\n+  {\n+    _out = new QueueBufferedOutputStream(bufferSize);\n+    _stack = new ArrayDeque<>();\n+    _iteratorStack = new ArrayDeque<>();\n+    _typeStack = new ArrayDeque<>();\n+    _done = false;\n+  }\n+\n+  protected AbstractDataEncoder(DataMap dataMap, int bufferSize)\n+  {\n+    this(bufferSize);\n+\n+    _stack.push(dataMap);\n+    _typeStack.push(MAP);\n+  }\n+\n+  protected AbstractDataEncoder(DataList dataList, int bufferSize)\n+  {\n+    this(bufferSize);\n+\n+    _stack.push(dataList);\n+    _typeStack.push(LIST);\n+  }\n+\n+  @Override\n+  public void onInit(WriteHandle<? super ByteString> wh)\n+  {\n+    _writeHandle = wh;\n+\n+    try\n+    {\n+      _traverseCallback = initTraverseCallback(_out);\n+    }\n+    catch (IOException e)\n+    {\n+      _writeHandle.error(e);\n+    }\n+  }\n+\n+  abstract protected Data.TraverseCallback initTraverseCallback(OutputStream out) throws IOException;\n+\n+  abstract protected void flushOutputStream(Data.TraverseCallback traverseCallback) throws IOException;", "originalCommit": "55a9d658d370692789d141aada97b00f9cb2b87b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjQ5MDkyMg==", "url": "https://github.com/linkedin/rest.li/pull/266#discussion_r412490922", "bodyText": "I initially thought it would be backward compatible but since I override Callback in AbstractJacksonDataEncoder now it can be done. Thanks", "author": "aman1309", "createdAt": "2020-04-21T21:05:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjM2MDIyOA=="}], "type": "inlineReview"}, {"oid": "baea7789b9c6a194850ed302c923aa93cc4835d8", "url": "https://github.com/linkedin/rest.li/commit/baea7789b9c6a194850ed302c923aa93cc4835d8", "message": "address Karthik comments", "committedDate": "2020-04-21T22:11:53Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzU1MDM5NQ==", "url": "https://github.com/linkedin/rest.li/pull/266#discussion_r413550395", "bodyText": "I understand that it is moved from \"AbstractJacksonDataEncoder\"\nWhat runtime unchecked exceptions are expected ?", "author": "ndarshanrestless", "createdAt": "2020-04-23T06:43:50Z", "path": "data/src/main/java/com/linkedin/data/codec/entitystream/AbstractDataEncoder.java", "diffHunk": "@@ -0,0 +1,337 @@\n+/*\n+   Copyright (c) 2020 LinkedIn Corp.\n+\n+   Licensed under the Apache License, Version 2.0 (the \"License\");\n+   you may not use this file except in compliance with the License.\n+   You may obtain a copy of the License at\n+\n+       http://www.apache.org/licenses/LICENSE-2.0\n+\n+   Unless required by applicable law or agreed to in writing, software\n+   distributed under the License is distributed on an \"AS IS\" BASIS,\n+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+   See the License for the specific language governing permissions and\n+   limitations under the License.\n+ */\n+\n+package com.linkedin.data.codec.entitystream;\n+\n+import com.linkedin.data.ByteString;\n+import com.linkedin.data.Data;\n+import com.linkedin.data.DataComplex;\n+import com.linkedin.data.DataList;\n+import com.linkedin.data.DataMap;\n+import com.linkedin.entitystream.WriteHandle;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.util.ArrayDeque;\n+import java.util.Deque;\n+import java.util.Iterator;\n+import java.util.Map;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Abstract data type encoder for a {@link com.linkedin.data.DataComplex} object implemented as a\n+ * {@link com.linkedin.entitystream.Writer} writing to an {@link com.linkedin.entitystream.EntityStream} of\n+ * {@link ByteString}. The implementation writes to an internal non-blocking <code>OutputStream</code>\n+ * implementation that has a fixed-size primary buffer and an unbounded overflow buffer. Because the bytes are pulled\n+ * from the encoder asynchronously, it needs to keep the state in a stack.\n+ *\n+ * @author kramgopa, xma\n+ */\n+abstract class AbstractDataEncoder implements DataEncoder\n+{\n+  private static final Logger LOGGER = LoggerFactory.getLogger(AbstractDataEncoder.class);\n+\n+  private static final Object MAP = new Object();\n+  private static final Object LIST = new Object();\n+\n+  private Data.TraverseCallback _traverseCallback;\n+  private QueueBufferedOutputStream _out;\n+  private Deque<DataComplex> _stack;\n+  private Deque<Iterator<?>> _iteratorStack;\n+  private Deque<Object> _typeStack;\n+  private WriteHandle<? super ByteString> _writeHandle;\n+  private boolean _done;\n+\n+  private AbstractDataEncoder(int bufferSize)\n+  {\n+    _out = new QueueBufferedOutputStream(bufferSize);\n+    _stack = new ArrayDeque<>();\n+    _iteratorStack = new ArrayDeque<>();\n+    _typeStack = new ArrayDeque<>();\n+    _done = false;\n+  }\n+\n+  protected AbstractDataEncoder(DataMap dataMap, int bufferSize)\n+  {\n+    this(bufferSize);\n+\n+    _stack.push(dataMap);\n+    _typeStack.push(MAP);\n+  }\n+\n+  protected AbstractDataEncoder(DataList dataList, int bufferSize)\n+  {\n+    this(bufferSize);\n+\n+    _stack.push(dataList);\n+    _typeStack.push(LIST);\n+  }\n+\n+  @Override\n+  public void onInit(WriteHandle<? super ByteString> wh)\n+  {\n+    _writeHandle = wh;\n+\n+    try\n+    {\n+      _traverseCallback = createTraverseCallback(_out);\n+    }\n+    catch (IOException e)\n+    {\n+      _writeHandle.error(e);\n+    }\n+  }\n+\n+  abstract protected Data.TraverseCallback createTraverseCallback(OutputStream out) throws IOException;\n+\n+  /**\n+   * Pre-process this {@link DataMap} before serializing it.\n+   *\n+   * <p>This can be overridden by implementations to modify the map before serializing. Implementations may also\n+   * choose to directly serialize the map in whatever form they prefer, and return null to indicate that they have\n+   * internally handled serialization.</p>\n+   */\n+  protected DataMap preProcessMap(DataMap dataMap) throws IOException\n+  {\n+    return dataMap;\n+  }\n+\n+  /**\n+   * Pre-process this {@link DataList} before serializing it.\n+   *\n+   * <p>This can be overridden by implementations to modify the map before serializing. Implementations may also\n+   * choose to directly serialize the list in whatever form they prefer, and return null to indicate that they have\n+   * internally handled serialization.</p>\n+   */\n+  protected DataList preProcessList(DataList dataList) throws IOException\n+  {\n+    return dataList;\n+  }\n+\n+  /**\n+   * Create an iterator that will be used by the encoder to iterate over entries of this {@link DataMap} when\n+   * serializing.\n+   *\n+   * <p>This can be overridden by implementations to control the order in which entries are serialized. It is\n+   * highly recommended to not modify the iterator or the backing map after this method has been called. Doing so\n+   * may result in a {@link java.util.ConcurrentModificationException}</p>\n+   */\n+  protected Iterator<Map.Entry<String, Object>> createIterator(DataMap dataMap) throws IOException\n+  {\n+    return dataMap.entrySet().iterator();\n+  }\n+\n+  /**\n+   * Create an iterator that will be used by the encoder to iterate over elements of this {@link DataList} when\n+   * serializing.\n+   *\n+   * <p>This can be overridden by implementations to control the order in which elements are serialized. It is\n+   * highly recommended to not modify the iterator or the backing list after this method has been called. Doing so\n+   * may result in a {@link java.util.ConcurrentModificationException}</p>\n+   */\n+  protected Iterator<Object> createIterator(DataList dataList) throws IOException\n+  {\n+    return dataList.iterator();\n+  }\n+\n+  @Override\n+  public void onWritePossible()\n+  {\n+    while (_writeHandle.remaining() > 0)\n+    {\n+      if (_done)\n+      {\n+        if (_out.isEmpty())\n+        {\n+          _writeHandle.done();\n+          break;\n+        }\n+        else\n+        {\n+          _writeHandle.write(_out.getBytes());\n+        }\n+      }\n+      else if (_out.isFull())\n+      {\n+        _writeHandle.write(_out.getBytes());\n+      }\n+      else\n+      {\n+        try\n+        {\n+          generate();\n+        }\n+        catch (Exception e)\n+        {\n+          _writeHandle.error(e);\n+          break;\n+        }\n+      }\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unchecked\")", "originalCommit": "baea7789b9c6a194850ed302c923aa93cc4835d8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzU2ODA5Nw==", "url": "https://github.com/linkedin/rest.li/pull/266#discussion_r413568097", "bodyText": "line 242", "author": "aman1309", "createdAt": "2020-04-23T07:13:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzU1MDM5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzU1NTE4Mw==", "url": "https://github.com/linkedin/rest.li/pull/266#discussion_r413555183", "bodyText": "What percentage of test coverage does this provide for ProtobufDataEncoder.java (in-fact for AbstractDataEncoder)  ?", "author": "ndarshanrestless", "createdAt": "2020-04-23T06:50:37Z", "path": "data/src/test/java/com/linkedin/data/codec/entitystream/TestProtobufDataEncoder.java", "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+    Copyright (c) 2020 LinkedIn Corp.\n+\n+    Licensed under the Apache License, Version 2.0 (the \"License\");\n+    you may not use this file except in compliance with the License.\n+    You may obtain a copy of the License at\n+\n+        http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing, software\n+    distributed under the License is distributed on an \"AS IS\" BASIS,\n+    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+    See the License for the specific language governing permissions and\n+    limitations under the License.\n+\n+ */\n+\n+package com.linkedin.data.codec.entitystream;\n+\n+import com.linkedin.data.ByteString;\n+import com.linkedin.data.ChunkedByteStringCollector;\n+import com.linkedin.data.DataComplex;\n+import com.linkedin.data.DataList;\n+import com.linkedin.data.DataMap;\n+import com.linkedin.data.TestUtil;\n+import com.linkedin.data.codec.CodecDataProviders;\n+import com.linkedin.data.codec.ProtobufDataCodec;\n+import com.linkedin.entitystream.CollectingReader;\n+import com.linkedin.entitystream.EntityStream;\n+import com.linkedin.entitystream.EntityStreams;\n+import org.testng.annotations.Test;\n+\n+import static org.testng.Assert.*;\n+\n+", "originalCommit": "baea7789b9c6a194850ed302c923aa93cc4835d8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzU3OTIzNw==", "url": "https://github.com/linkedin/rest.li/pull/266#discussion_r413579237", "bodyText": "82%. missing null and IOException cases. will try to add them", "author": "aman1309", "createdAt": "2020-04-23T07:32:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzU1NTE4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzU1Njk1Nw==", "url": "https://github.com/linkedin/rest.li/pull/266#discussion_r413556957", "bodyText": "worth logging ?", "author": "ndarshanrestless", "createdAt": "2020-04-23T06:52:47Z", "path": "data/src/main/java/com/linkedin/data/codec/entitystream/AbstractDataEncoder.java", "diffHunk": "@@ -0,0 +1,337 @@\n+/*\n+   Copyright (c) 2020 LinkedIn Corp.\n+\n+   Licensed under the Apache License, Version 2.0 (the \"License\");\n+   you may not use this file except in compliance with the License.\n+   You may obtain a copy of the License at\n+\n+       http://www.apache.org/licenses/LICENSE-2.0\n+\n+   Unless required by applicable law or agreed to in writing, software\n+   distributed under the License is distributed on an \"AS IS\" BASIS,\n+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+   See the License for the specific language governing permissions and\n+   limitations under the License.\n+ */\n+\n+package com.linkedin.data.codec.entitystream;\n+\n+import com.linkedin.data.ByteString;\n+import com.linkedin.data.Data;\n+import com.linkedin.data.DataComplex;\n+import com.linkedin.data.DataList;\n+import com.linkedin.data.DataMap;\n+import com.linkedin.entitystream.WriteHandle;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.util.ArrayDeque;\n+import java.util.Deque;\n+import java.util.Iterator;\n+import java.util.Map;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Abstract data type encoder for a {@link com.linkedin.data.DataComplex} object implemented as a\n+ * {@link com.linkedin.entitystream.Writer} writing to an {@link com.linkedin.entitystream.EntityStream} of\n+ * {@link ByteString}. The implementation writes to an internal non-blocking <code>OutputStream</code>\n+ * implementation that has a fixed-size primary buffer and an unbounded overflow buffer. Because the bytes are pulled\n+ * from the encoder asynchronously, it needs to keep the state in a stack.\n+ *\n+ * @author kramgopa, xma\n+ */\n+abstract class AbstractDataEncoder implements DataEncoder\n+{\n+  private static final Logger LOGGER = LoggerFactory.getLogger(AbstractDataEncoder.class);\n+\n+  private static final Object MAP = new Object();\n+  private static final Object LIST = new Object();\n+\n+  private Data.TraverseCallback _traverseCallback;\n+  private QueueBufferedOutputStream _out;\n+  private Deque<DataComplex> _stack;\n+  private Deque<Iterator<?>> _iteratorStack;\n+  private Deque<Object> _typeStack;\n+  private WriteHandle<? super ByteString> _writeHandle;\n+  private boolean _done;\n+\n+  private AbstractDataEncoder(int bufferSize)\n+  {\n+    _out = new QueueBufferedOutputStream(bufferSize);\n+    _stack = new ArrayDeque<>();\n+    _iteratorStack = new ArrayDeque<>();\n+    _typeStack = new ArrayDeque<>();\n+    _done = false;\n+  }\n+\n+  protected AbstractDataEncoder(DataMap dataMap, int bufferSize)\n+  {\n+    this(bufferSize);\n+\n+    _stack.push(dataMap);\n+    _typeStack.push(MAP);\n+  }\n+\n+  protected AbstractDataEncoder(DataList dataList, int bufferSize)\n+  {\n+    this(bufferSize);\n+\n+    _stack.push(dataList);\n+    _typeStack.push(LIST);\n+  }\n+\n+  @Override\n+  public void onInit(WriteHandle<? super ByteString> wh)\n+  {\n+    _writeHandle = wh;\n+\n+    try\n+    {\n+      _traverseCallback = createTraverseCallback(_out);\n+    }\n+    catch (IOException e)\n+    {\n+      _writeHandle.error(e);\n+    }\n+  }\n+\n+  abstract protected Data.TraverseCallback createTraverseCallback(OutputStream out) throws IOException;\n+\n+  /**\n+   * Pre-process this {@link DataMap} before serializing it.\n+   *\n+   * <p>This can be overridden by implementations to modify the map before serializing. Implementations may also\n+   * choose to directly serialize the map in whatever form they prefer, and return null to indicate that they have\n+   * internally handled serialization.</p>\n+   */\n+  protected DataMap preProcessMap(DataMap dataMap) throws IOException\n+  {\n+    return dataMap;\n+  }\n+\n+  /**\n+   * Pre-process this {@link DataList} before serializing it.\n+   *\n+   * <p>This can be overridden by implementations to modify the map before serializing. Implementations may also\n+   * choose to directly serialize the list in whatever form they prefer, and return null to indicate that they have\n+   * internally handled serialization.</p>\n+   */\n+  protected DataList preProcessList(DataList dataList) throws IOException\n+  {\n+    return dataList;\n+  }\n+\n+  /**\n+   * Create an iterator that will be used by the encoder to iterate over entries of this {@link DataMap} when\n+   * serializing.\n+   *\n+   * <p>This can be overridden by implementations to control the order in which entries are serialized. It is\n+   * highly recommended to not modify the iterator or the backing map after this method has been called. Doing so\n+   * may result in a {@link java.util.ConcurrentModificationException}</p>\n+   */\n+  protected Iterator<Map.Entry<String, Object>> createIterator(DataMap dataMap) throws IOException\n+  {\n+    return dataMap.entrySet().iterator();\n+  }\n+\n+  /**\n+   * Create an iterator that will be used by the encoder to iterate over elements of this {@link DataList} when\n+   * serializing.\n+   *\n+   * <p>This can be overridden by implementations to control the order in which elements are serialized. It is\n+   * highly recommended to not modify the iterator or the backing list after this method has been called. Doing so\n+   * may result in a {@link java.util.ConcurrentModificationException}</p>\n+   */\n+  protected Iterator<Object> createIterator(DataList dataList) throws IOException\n+  {\n+    return dataList.iterator();\n+  }\n+\n+  @Override\n+  public void onWritePossible()\n+  {\n+    while (_writeHandle.remaining() > 0)\n+    {\n+      if (_done)\n+      {\n+        if (_out.isEmpty())\n+        {\n+          _writeHandle.done();\n+          break;\n+        }\n+        else\n+        {\n+          _writeHandle.write(_out.getBytes());\n+        }\n+      }\n+      else if (_out.isFull())\n+      {\n+        _writeHandle.write(_out.getBytes());\n+      }\n+      else\n+      {\n+        try\n+        {\n+          generate();\n+        }\n+        catch (Exception e)\n+        {\n+          _writeHandle.error(e);", "originalCommit": "baea7789b9c6a194850ed302c923aa93cc4835d8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzU2OTA3OA==", "url": "https://github.com/linkedin/rest.li/pull/266#discussion_r413569078", "bodyText": "this should be done in writeHandle.error if required", "author": "aman1309", "createdAt": "2020-04-23T07:15:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzU1Njk1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzU2MDQxNw==", "url": "https://github.com/linkedin/rest.li/pull/266#discussion_r413560417", "bodyText": "Consider \"defensive coding\". If possible, exactly list the specific exception instead of generic \"Exception\" which will the   caller prepare and handle it better. Or may be in this specific situation that is overkill as you not conditionally handling it in the caller ?", "author": "ndarshanrestless", "createdAt": "2020-04-23T06:59:33Z", "path": "data/src/main/java/com/linkedin/data/codec/entitystream/AbstractDataEncoder.java", "diffHunk": "@@ -0,0 +1,337 @@\n+/*\n+   Copyright (c) 2020 LinkedIn Corp.\n+\n+   Licensed under the Apache License, Version 2.0 (the \"License\");\n+   you may not use this file except in compliance with the License.\n+   You may obtain a copy of the License at\n+\n+       http://www.apache.org/licenses/LICENSE-2.0\n+\n+   Unless required by applicable law or agreed to in writing, software\n+   distributed under the License is distributed on an \"AS IS\" BASIS,\n+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+   See the License for the specific language governing permissions and\n+   limitations under the License.\n+ */\n+\n+package com.linkedin.data.codec.entitystream;\n+\n+import com.linkedin.data.ByteString;\n+import com.linkedin.data.Data;\n+import com.linkedin.data.DataComplex;\n+import com.linkedin.data.DataList;\n+import com.linkedin.data.DataMap;\n+import com.linkedin.entitystream.WriteHandle;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.util.ArrayDeque;\n+import java.util.Deque;\n+import java.util.Iterator;\n+import java.util.Map;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Abstract data type encoder for a {@link com.linkedin.data.DataComplex} object implemented as a\n+ * {@link com.linkedin.entitystream.Writer} writing to an {@link com.linkedin.entitystream.EntityStream} of\n+ * {@link ByteString}. The implementation writes to an internal non-blocking <code>OutputStream</code>\n+ * implementation that has a fixed-size primary buffer and an unbounded overflow buffer. Because the bytes are pulled\n+ * from the encoder asynchronously, it needs to keep the state in a stack.\n+ *\n+ * @author kramgopa, xma\n+ */\n+abstract class AbstractDataEncoder implements DataEncoder\n+{\n+  private static final Logger LOGGER = LoggerFactory.getLogger(AbstractDataEncoder.class);\n+\n+  private static final Object MAP = new Object();\n+  private static final Object LIST = new Object();\n+\n+  private Data.TraverseCallback _traverseCallback;\n+  private QueueBufferedOutputStream _out;\n+  private Deque<DataComplex> _stack;\n+  private Deque<Iterator<?>> _iteratorStack;\n+  private Deque<Object> _typeStack;\n+  private WriteHandle<? super ByteString> _writeHandle;\n+  private boolean _done;\n+\n+  private AbstractDataEncoder(int bufferSize)\n+  {\n+    _out = new QueueBufferedOutputStream(bufferSize);\n+    _stack = new ArrayDeque<>();\n+    _iteratorStack = new ArrayDeque<>();\n+    _typeStack = new ArrayDeque<>();\n+    _done = false;\n+  }\n+\n+  protected AbstractDataEncoder(DataMap dataMap, int bufferSize)\n+  {\n+    this(bufferSize);\n+\n+    _stack.push(dataMap);\n+    _typeStack.push(MAP);\n+  }\n+\n+  protected AbstractDataEncoder(DataList dataList, int bufferSize)\n+  {\n+    this(bufferSize);\n+\n+    _stack.push(dataList);\n+    _typeStack.push(LIST);\n+  }\n+\n+  @Override\n+  public void onInit(WriteHandle<? super ByteString> wh)\n+  {\n+    _writeHandle = wh;\n+\n+    try\n+    {\n+      _traverseCallback = createTraverseCallback(_out);\n+    }\n+    catch (IOException e)\n+    {\n+      _writeHandle.error(e);\n+    }\n+  }\n+\n+  abstract protected Data.TraverseCallback createTraverseCallback(OutputStream out) throws IOException;\n+\n+  /**\n+   * Pre-process this {@link DataMap} before serializing it.\n+   *\n+   * <p>This can be overridden by implementations to modify the map before serializing. Implementations may also\n+   * choose to directly serialize the map in whatever form they prefer, and return null to indicate that they have\n+   * internally handled serialization.</p>\n+   */\n+  protected DataMap preProcessMap(DataMap dataMap) throws IOException\n+  {\n+    return dataMap;\n+  }\n+\n+  /**\n+   * Pre-process this {@link DataList} before serializing it.\n+   *\n+   * <p>This can be overridden by implementations to modify the map before serializing. Implementations may also\n+   * choose to directly serialize the list in whatever form they prefer, and return null to indicate that they have\n+   * internally handled serialization.</p>\n+   */\n+  protected DataList preProcessList(DataList dataList) throws IOException\n+  {\n+    return dataList;\n+  }\n+\n+  /**\n+   * Create an iterator that will be used by the encoder to iterate over entries of this {@link DataMap} when\n+   * serializing.\n+   *\n+   * <p>This can be overridden by implementations to control the order in which entries are serialized. It is\n+   * highly recommended to not modify the iterator or the backing map after this method has been called. Doing so\n+   * may result in a {@link java.util.ConcurrentModificationException}</p>\n+   */\n+  protected Iterator<Map.Entry<String, Object>> createIterator(DataMap dataMap) throws IOException\n+  {\n+    return dataMap.entrySet().iterator();\n+  }\n+\n+  /**\n+   * Create an iterator that will be used by the encoder to iterate over elements of this {@link DataList} when\n+   * serializing.\n+   *\n+   * <p>This can be overridden by implementations to control the order in which elements are serialized. It is\n+   * highly recommended to not modify the iterator or the backing list after this method has been called. Doing so\n+   * may result in a {@link java.util.ConcurrentModificationException}</p>\n+   */\n+  protected Iterator<Object> createIterator(DataList dataList) throws IOException\n+  {\n+    return dataList.iterator();\n+  }\n+\n+  @Override\n+  public void onWritePossible()\n+  {\n+    while (_writeHandle.remaining() > 0)\n+    {\n+      if (_done)\n+      {\n+        if (_out.isEmpty())\n+        {\n+          _writeHandle.done();\n+          break;\n+        }\n+        else\n+        {\n+          _writeHandle.write(_out.getBytes());\n+        }\n+      }\n+      else if (_out.isFull())\n+      {\n+        _writeHandle.write(_out.getBytes());\n+      }\n+      else\n+      {\n+        try\n+        {\n+          generate();\n+        }\n+        catch (Exception e)\n+        {\n+          _writeHandle.error(e);\n+          break;\n+        }\n+      }\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unchecked\")\n+  private void generate()\n+      throws Exception", "originalCommit": "baea7789b9c6a194850ed302c923aa93cc4835d8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzU3MzYwNQ==", "url": "https://github.com/linkedin/rest.li/pull/266#discussion_r413573605", "bodyText": "Exception is used here to avoid missing any kind of exception in any caller and that writeHandle.error method is invoked with certainty.", "author": "aman1309", "createdAt": "2020-04-23T07:23:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzU2MDQxNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQ0MDUyNw==", "url": "https://github.com/linkedin/rest.li/pull/266#discussion_r414440527", "bodyText": "IF the proto writer is closed by the encoder, subsequent flush() on the writer might fail?\nCheck Line 119 and 135 in ProtobufDataCodec\nThough the TraverseCallback.close() is not called from this codec, it is odd that both callback and the codec can call flush() or close() on the protoWriter.\nCan we make this cleaner? We can assume the callback takes ownership of the writer and it will be responsible for calling flush/close on it. The codec/encoder should use only the callback.close. What do you think?", "author": "karthikbalasub", "createdAt": "2020-04-24T09:41:37Z", "path": "li-protobuf/src/main/java/com/linkedin/data/protobuf/ProtoWriter.java", "diffHunk": "@@ -357,4 +358,11 @@ public void writeString(String value, Function<Integer, Byte> leadingOrdinalGene\n       throw new EOFException(String.format(\"Pos: %d, limit: %d, len: %d\", _position, _limit, 1));\n     }\n   }\n+\n+  @Override\n+  public void close() throws IOException\n+  {\n+    flush();\n+    _out.close();", "originalCommit": "baea7789b9c6a194850ed302c923aa93cc4835d8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDUwNTgwMg==", "url": "https://github.com/linkedin/rest.li/pull/266#discussion_r414505802", "bodyText": "close method is to be called last, there must be no flush pending after its invoked. so no there shouldn't be any failure.\nwill update DataCodec using traverse callback.close", "author": "aman1309", "createdAt": "2020-04-24T11:33:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQ0MDUyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDY5NzU1MA==", "url": "https://github.com/linkedin/rest.li/pull/266#discussion_r414697550", "bodyText": "I agree with Aman. As long as we make DataCodec use TraverseCallback.close(), we should be good here.", "author": "karthikrg", "createdAt": "2020-04-24T16:15:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQ0MDUyNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQ2MjUyOA==", "url": "https://github.com/linkedin/rest.li/pull/266#discussion_r414462528", "bodyText": "I find it odd that both the traverse callback and the encoder can write using _generator. Ideally all writing to _generator should be done in the traverse callback (ie no _generator member in the Encoder class).\nThese protected methods wouldn't be needed as the overriding codecs can override using the traverse callback now.\nI see these are used only by the LICOR codec. Should we clean this up? This would be breaking API change, so would require a major version bump, but the code would be cleaner.\n@karthikrg what do you think?", "author": "karthikbalasub", "createdAt": "2020-04-24T10:16:44Z", "path": "data/src/main/java/com/linkedin/data/codec/entitystream/AbstractJacksonDataEncoder.java", "diffHunk": "@@ -43,61 +37,28 @@\n  *\n  * @author kramgopa, xma\n  */\n-abstract class AbstractJacksonDataEncoder implements DataEncoder\n+abstract class AbstractJacksonDataEncoder extends AbstractDataEncoder\n {\n-  private static final Logger LOGGER = LoggerFactory.getLogger(AbstractJacksonDataEncoder.class);\n-\n-  private static final Object MAP = new Object();\n-  private static final Object LIST = new Object();\n-\n   protected JsonFactory _jsonFactory;\n   protected JsonGenerator _generator;\n-  private QueueBufferedOutputStream _out;\n-  private Deque<DataComplex> _stack;\n-  private Deque<Iterator<?>> _iteratorStack;\n-  private Deque<Object> _typeStack;\n-  private WriteHandle<? super ByteString> _writeHandle;\n-  private boolean _done;\n-\n-  private AbstractJacksonDataEncoder(JsonFactory jsonFactory, int bufferSize)\n-  {\n-    _jsonFactory = jsonFactory;\n-    _out = new QueueBufferedOutputStream(bufferSize);\n-    _stack = new ArrayDeque<>();\n-    _iteratorStack = new ArrayDeque<>();\n-    _typeStack = new ArrayDeque<>();\n-    _done = false;\n-  }\n \n   protected AbstractJacksonDataEncoder(JsonFactory jsonFactory, DataMap dataMap, int bufferSize)\n   {\n-    this(jsonFactory, bufferSize);\n-\n-    _stack.push(dataMap);\n-    _typeStack.push(MAP);\n+    super(dataMap, bufferSize);\n+    _jsonFactory = jsonFactory;\n   }\n \n   protected AbstractJacksonDataEncoder(JsonFactory jsonFactory, DataList dataList, int bufferSize)\n   {\n-    this(jsonFactory, bufferSize);\n-\n-    _stack.push(dataList);\n-    _typeStack.push(LIST);\n+    super(dataList, bufferSize);\n+    _jsonFactory = jsonFactory;\n   }\n \n   @Override\n-  public void onInit(WriteHandle<? super ByteString> wh)\n+  protected Data.TraverseCallback createTraverseCallback(OutputStream out) throws IOException\n   {\n-    _writeHandle = wh;\n-\n-    try\n-    {\n-      _generator = _jsonFactory.createGenerator(_out);\n-    }\n-    catch (IOException e)\n-    {\n-      _writeHandle.error(e);\n-    }\n+    _generator = _jsonFactory.createGenerator(out);\n+    return new JacksonStreamTraverseCallback(_generator);\n   }\n \n   protected void writeStartObject() throws IOException", "originalCommit": "baea7789b9c6a194850ed302c923aa93cc4835d8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQ4MzU0Mg==", "url": "https://github.com/linkedin/rest.li/pull/266#discussion_r414483542", "bodyText": "I overrode callback not to wait for major version. should we do major version bump just for this? I can add a todo when we plan to do major version bump this can be added with it.", "author": "aman1309", "createdAt": "2020-04-24T10:53:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQ2MjUyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDY5ODI3Mw==", "url": "https://github.com/linkedin/rest.li/pull/266#discussion_r414698273", "bodyText": "This PR is making a lot of changes to the way jackson works. At this point making a breaking change may inhibit our internal dependency testing. Why don't we do this particular one as a follow up RB?", "author": "karthikrg", "createdAt": "2020-04-24T16:16:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQ2MjUyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDc1MjcwOQ==", "url": "https://github.com/linkedin/rest.li/pull/266#discussion_r414752709", "bodyText": "On second thought we don't need to introduce a major version for this. Just deprecate these methods and point to the travers callback as the way to make customizations", "author": "karthikbalasub", "createdAt": "2020-04-24T17:45:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQ2MjUyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDc1MTQyNg==", "url": "https://github.com/linkedin/rest.li/pull/266#discussion_r414751426", "bodyText": "Why do you need to flush here?\nThe behavior should be consistent: traverseCallback handles flush/close on the generator. And this should be documented on createTraverseCallback method", "author": "karthikbalasub", "createdAt": "2020-04-24T17:42:59Z", "path": "data/src/main/java/com/linkedin/data/codec/AbstractJacksonDataCodec.java", "diffHunk": "@@ -115,20 +115,11 @@ protected JsonGenerator createJsonGenerator(Writer out) throws IOException\n \n   protected void writeObject(Object object, JsonGenerator generator) throws IOException\n   {\n-    try\n+    try (Data.TraverseCallback callback = createTraverseCallback(generator))\n     {\n-      Data.TraverseCallback callback = createTraverseCallback(generator);\n       Data.traverse(object, callback);\n       generator.flush();", "originalCommit": "39d6ee44701037cbde1592f60c2a36eea868ea72", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDgyMDQyNQ==", "url": "https://github.com/linkedin/rest.li/pull/266#discussion_r414820425", "bodyText": "generate close implementation has a condition on flush before stream close that why kept it here", "author": "aman1309", "createdAt": "2020-04-24T19:44:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDc1MTQyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDgzNzgzMw==", "url": "https://github.com/linkedin/rest.li/pull/266#discussion_r414837833", "bodyText": "My point is about consistency between different codecs. Protobuf codec assumes the callback handles the flush, while this code has to call it explicitly.\nWe should make it consistent and set the expectation that the traverse callback should handle flushing/closing the generator.\nThen the codec's would just close the traverse callback.", "author": "karthikbalasub", "createdAt": "2020-04-24T20:17:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDc1MTQyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDg5NjQ3MQ==", "url": "https://github.com/linkedin/rest.li/pull/266#discussion_r414896471", "bodyText": "moved flush to callback close", "author": "aman1309", "createdAt": "2020-04-24T22:24:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDc1MTQyNg=="}], "type": "inlineReview"}, {"oid": "acc922f0ac9c4b60736bc75df04c5c4ad9390230", "url": "https://github.com/linkedin/rest.li/commit/acc922f0ac9c4b60736bc75df04c5c4ad9390230", "message": "address karthik comments", "committedDate": "2020-04-24T22:23:34Z", "type": "forcePushed"}, {"oid": "de8ff1da7de13144c35353334bdf2e63e1e2de5f", "url": "https://github.com/linkedin/rest.li/commit/de8ff1da7de13144c35353334bdf2e63e1e2de5f", "message": "address karthik comments", "committedDate": "2020-04-24T22:34:52Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDk0MjM0Mw==", "url": "https://github.com/linkedin/rest.li/pull/266#discussion_r414942343", "bodyText": "Please add javadoc on this method.\nDocument that the callback returned should take ownership of the output stream and close it before the callback is closed.", "author": "karthikbalasub", "createdAt": "2020-04-25T01:09:25Z", "path": "data/src/main/java/com/linkedin/data/codec/entitystream/AbstractDataEncoder.java", "diffHunk": "@@ -0,0 +1,337 @@\n+/*\n+   Copyright (c) 2020 LinkedIn Corp.\n+\n+   Licensed under the Apache License, Version 2.0 (the \"License\");\n+   you may not use this file except in compliance with the License.\n+   You may obtain a copy of the License at\n+\n+       http://www.apache.org/licenses/LICENSE-2.0\n+\n+   Unless required by applicable law or agreed to in writing, software\n+   distributed under the License is distributed on an \"AS IS\" BASIS,\n+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+   See the License for the specific language governing permissions and\n+   limitations under the License.\n+ */\n+\n+package com.linkedin.data.codec.entitystream;\n+\n+import com.linkedin.data.ByteString;\n+import com.linkedin.data.Data;\n+import com.linkedin.data.DataComplex;\n+import com.linkedin.data.DataList;\n+import com.linkedin.data.DataMap;\n+import com.linkedin.entitystream.WriteHandle;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.util.ArrayDeque;\n+import java.util.Deque;\n+import java.util.Iterator;\n+import java.util.Map;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Abstract data type encoder for a {@link com.linkedin.data.DataComplex} object implemented as a\n+ * {@link com.linkedin.entitystream.Writer} writing to an {@link com.linkedin.entitystream.EntityStream} of\n+ * {@link ByteString}. The implementation writes to an internal non-blocking <code>OutputStream</code>\n+ * implementation that has a fixed-size primary buffer and an unbounded overflow buffer. Because the bytes are pulled\n+ * from the encoder asynchronously, it needs to keep the state in a stack.\n+ *\n+ * @author kramgopa, xma\n+ */\n+abstract class AbstractDataEncoder implements DataEncoder\n+{\n+  private static final Logger LOGGER = LoggerFactory.getLogger(AbstractDataEncoder.class);\n+\n+  private static final Object MAP = new Object();\n+  private static final Object LIST = new Object();\n+\n+  private Data.TraverseCallback _traverseCallback;\n+  private QueueBufferedOutputStream _out;\n+  private Deque<DataComplex> _stack;\n+  private Deque<Iterator<?>> _iteratorStack;\n+  private Deque<Object> _typeStack;\n+  private WriteHandle<? super ByteString> _writeHandle;\n+  private boolean _done;\n+\n+  private AbstractDataEncoder(int bufferSize)\n+  {\n+    _out = new QueueBufferedOutputStream(bufferSize);\n+    _stack = new ArrayDeque<>();\n+    _iteratorStack = new ArrayDeque<>();\n+    _typeStack = new ArrayDeque<>();\n+    _done = false;\n+  }\n+\n+  protected AbstractDataEncoder(DataMap dataMap, int bufferSize)\n+  {\n+    this(bufferSize);\n+\n+    _stack.push(dataMap);\n+    _typeStack.push(MAP);\n+  }\n+\n+  protected AbstractDataEncoder(DataList dataList, int bufferSize)\n+  {\n+    this(bufferSize);\n+\n+    _stack.push(dataList);\n+    _typeStack.push(LIST);\n+  }\n+\n+  @Override\n+  public void onInit(WriteHandle<? super ByteString> wh)\n+  {\n+    _writeHandle = wh;\n+\n+    try\n+    {\n+      _traverseCallback = createTraverseCallback(_out);\n+    }\n+    catch (IOException e)\n+    {\n+      _writeHandle.error(e);\n+    }\n+  }\n+\n+  abstract protected Data.TraverseCallback createTraverseCallback(OutputStream out) throws IOException;", "originalCommit": "de8ff1da7de13144c35353334bdf2e63e1e2de5f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDk0MjUzOA==", "url": "https://github.com/linkedin/rest.li/pull/266#discussion_r414942538", "bodyText": "Make these javadoc comments so they appear in api docs..", "author": "karthikbalasub", "createdAt": "2020-04-25T01:10:24Z", "path": "data/src/main/java/com/linkedin/data/codec/entitystream/AbstractJacksonDataEncoder.java", "diffHunk": "@@ -43,330 +37,115 @@\n  *\n  * @author kramgopa, xma\n  */\n-abstract class AbstractJacksonDataEncoder implements DataEncoder\n+abstract class AbstractJacksonDataEncoder extends AbstractDataEncoder\n {\n-  private static final Logger LOGGER = LoggerFactory.getLogger(AbstractJacksonDataEncoder.class);\n-\n-  private static final Object MAP = new Object();\n-  private static final Object LIST = new Object();\n-\n   protected JsonFactory _jsonFactory;\n   protected JsonGenerator _generator;\n-  private QueueBufferedOutputStream _out;\n-  private Deque<DataComplex> _stack;\n-  private Deque<Iterator<?>> _iteratorStack;\n-  private Deque<Object> _typeStack;\n-  private WriteHandle<? super ByteString> _writeHandle;\n-  private boolean _done;\n-\n-  private AbstractJacksonDataEncoder(JsonFactory jsonFactory, int bufferSize)\n-  {\n-    _jsonFactory = jsonFactory;\n-    _out = new QueueBufferedOutputStream(bufferSize);\n-    _stack = new ArrayDeque<>();\n-    _iteratorStack = new ArrayDeque<>();\n-    _typeStack = new ArrayDeque<>();\n-    _done = false;\n-  }\n \n   protected AbstractJacksonDataEncoder(JsonFactory jsonFactory, DataMap dataMap, int bufferSize)\n   {\n-    this(jsonFactory, bufferSize);\n-\n-    _stack.push(dataMap);\n-    _typeStack.push(MAP);\n+    super(dataMap, bufferSize);\n+    _jsonFactory = jsonFactory;\n   }\n \n   protected AbstractJacksonDataEncoder(JsonFactory jsonFactory, DataList dataList, int bufferSize)\n   {\n-    this(jsonFactory, bufferSize);\n-\n-    _stack.push(dataList);\n-    _typeStack.push(LIST);\n+    super(dataList, bufferSize);\n+    _jsonFactory = jsonFactory;\n   }\n \n   @Override\n-  public void onInit(WriteHandle<? super ByteString> wh)\n+  protected Data.TraverseCallback createTraverseCallback(OutputStream out) throws IOException\n   {\n-    _writeHandle = wh;\n-\n-    try\n-    {\n-      _generator = _jsonFactory.createGenerator(_out);\n-    }\n-    catch (IOException e)\n-    {\n-      _writeHandle.error(e);\n-    }\n+    _generator = _jsonFactory.createGenerator(out);\n+    return new JacksonStreamTraverseCallback(_generator);\n   }\n \n+  // method is moved to @Data.TraverseCallback. Extend JacksonStreamTraverseCallback to override method behaviour.\n+  @Deprecated\n   protected void writeStartObject() throws IOException\n   {\n     _generator.writeStartObject();\n   }\n \n+  // method is moved to @Data.TraverseCallback. Extend JacksonStreamTraverseCallback to override method behaviour.", "originalCommit": "de8ff1da7de13144c35353334bdf2e63e1e2de5f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "859f61afc354ab7c74fb0e8ba4e042a5ab8cb5ff", "url": "https://github.com/linkedin/rest.li/commit/859f61afc354ab7c74fb0e8ba4e042a5ab8cb5ff", "message": "Refactor stream encoder and Add data encoder for protobuf", "committedDate": "2020-05-12T07:48:32Z", "type": "forcePushed"}, {"oid": "efd6ae7a97356755445d38f777aab2a025f96cad", "url": "https://github.com/linkedin/rest.li/commit/efd6ae7a97356755445d38f777aab2a025f96cad", "message": "Refactor stream encoder and Add data encoder for protobuf", "committedDate": "2020-05-12T08:02:43Z", "type": "commit"}, {"oid": "efd6ae7a97356755445d38f777aab2a025f96cad", "url": "https://github.com/linkedin/rest.li/commit/efd6ae7a97356755445d38f777aab2a025f96cad", "message": "Refactor stream encoder and Add data encoder for protobuf", "committedDate": "2020-05-12T08:02:43Z", "type": "forcePushed"}]}