{"pr_number": 13282, "pr_title": "[BEAM-11172] Enable KafkaIO performance test for Dataflow runner v2 with SDF.", "pr_createdAt": "2020-11-07T01:37:04Z", "pr_url": "https://github.com/apache/beam/pull/13282", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDY3OTA0Mw==", "url": "https://github.com/apache/beam/pull/13282#discussion_r520679043", "bodyText": "Why do we need this function? Is it possible to have a timestamp out of window bounds?", "author": "aromanenko-dev", "createdAt": "2020-11-10T16:03:33Z", "path": "sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/ReadFromKafkaDoFn.java", "diffHunk": "@@ -407,4 +408,13 @@ public double getTotalSize(double numRecords) {\n       return avgRecordSize.get() * numRecords / (1 + avgRecordGap.get());\n     }\n   }\n+\n+  private static Instant ensureTimestampWithinBounds(Instant timestamp) {", "originalCommit": "cbdcd5a110bc2f38ddf014d8886154637fc89cb7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk4NDY3NQ==", "url": "https://github.com/apache/beam/pull/13282#discussion_r520984675", "bodyText": "The MIN_TIMESTAMP produced in Dataflow is smaller than BoundedWindow.MIN_TIMESTAMP.", "author": "boyuanzz", "createdAt": "2020-11-11T01:14:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDY3OTA0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDY4MTQ4MQ==", "url": "https://github.com/apache/beam/pull/13282#discussion_r520681481", "bodyText": "Why not to use metrics for counting?", "author": "aromanenko-dev", "createdAt": "2020-11-10T16:06:46Z", "path": "sdks/java/io/kafka/src/test/java/org/apache/beam/sdk/io/kafka/KafkaIOIT.java", "diffHunk": "@@ -115,6 +122,43 @@ public static void setup() throws IOException {\n             .get();\n   }\n \n+  @Test\n+  public void testKafkaIOWithRunnerV2() throws IOException {\n+    writePipeline\n+        .apply(\"Generate records\", Read.from(new SyntheticBoundedSource(sourceOptions)))\n+        .apply(\"Measure write time\", ParDo.of(new TimeMonitor<>(NAMESPACE, WRITE_TIME_METRIC_NAME)))\n+        .apply(\"Write to Kafka\", writeToKafka());\n+\n+    readPipeline.getOptions().as(Options.class).setStreaming(true);\n+    PCollection<Integer> elementCount =\n+        readPipeline\n+            .apply(\"Read from Runner V2 Kafka\", readFromKafka())\n+            .apply(\n+                \"Measure read time\", ParDo.of(new TimeMonitor<>(NAMESPACE, READ_TIME_METRIC_NAME)))\n+            .apply(\"Map records to strings\", MapElements.via(new MapKafkaRecordsToStrings()))\n+            .apply(\n+                \"Keyed by empty key\",\n+                MapElements.into(new TypeDescriptor<KV<byte[], String>>() {})\n+                    .via(element -> KV.of(new byte[0], element)))\n+            .apply(\n+                \"Counting elements\", ParDo.of(new CountingElementFn(options.getNumberOfRecords())));", "originalCommit": "cbdcd5a110bc2f38ddf014d8886154637fc89cb7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk4NTE4Nw==", "url": "https://github.com/apache/beam/pull/13282#discussion_r520985187", "bodyText": "Yes, counter works as well. I think we can use existing element counter as well.", "author": "boyuanzz", "createdAt": "2020-11-11T01:15:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDY4MTQ4MQ=="}], "type": "inlineReview"}, {"oid": "013a8784b6740bba589daa28cb3d1c4e4ac07937", "url": "https://github.com/apache/beam/commit/013a8784b6740bba589daa28cb3d1c4e4ac07937", "message": "Update tests.", "committedDate": "2020-11-11T04:30:32Z", "type": "forcePushed"}, {"oid": "c8729f3589903700f3e266833e1ffc391cb7ec35", "url": "https://github.com/apache/beam/commit/c8729f3589903700f3e266833e1ffc391cb7ec35", "message": "Update test setup", "committedDate": "2020-11-11T18:39:51Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTY0NzI4NQ==", "url": "https://github.com/apache/beam/pull/13282#discussion_r521647285", "bodyText": "Instead of naming the test after the runner, is it possible to name the test after the behavior that is being tested and use the configuration to ensure it runs on the appropriate runners? Is there a reason to have both this test and testKafkaReadsAndWritesProperly?\nIf so, it would be good to understand the difference through the test naming. From what I can tell the material difference is that this test uses a streaming pipeline to read where testKafkaReadsAndWritesProperly uses a batch one.", "author": "tysonjh", "createdAt": "2020-11-11T21:24:44Z", "path": "sdks/java/io/kafka/src/test/java/org/apache/beam/sdk/io/kafka/KafkaIOIT.java", "diffHunk": "@@ -115,16 +116,55 @@ public static void setup() throws IOException {\n             .get();\n   }\n \n+  @Test\n+  public void testKafkaIOWithRunnerV2() throws IOException {", "originalCommit": "c8729f3589903700f3e266833e1ffc391cb7ec35", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTY4MDc1OQ==", "url": "https://github.com/apache/beam/pull/13282#discussion_r521680759", "bodyText": "That's correct. I'll do the renaming. Thanks for catching that!", "author": "boyuanzz", "createdAt": "2020-11-11T22:38:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTY0NzI4NQ=="}], "type": "inlineReview"}, {"oid": "d32629a17b3cda161f6be81459f6749a6d64499e", "url": "https://github.com/apache/beam/commit/d32629a17b3cda161f6be81459f6749a6d64499e", "message": "Enable KafkaIO performance test for runner v2 with SDF.", "committedDate": "2020-11-12T01:06:55Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjE4NTIyNQ==", "url": "https://github.com/apache/beam/pull/13282#discussion_r522185225", "bodyText": "nit: Please, remove \"Runner V2\"", "author": "aromanenko-dev", "createdAt": "2020-11-12T15:18:23Z", "path": "sdks/java/io/kafka/src/test/java/org/apache/beam/sdk/io/kafka/KafkaIOIT.java", "diffHunk": "@@ -116,15 +117,54 @@ public static void setup() throws IOException {\n   }\n \n   @Test\n-  public void testKafkaIOReadsAndWritesCorrectly() throws IOException {\n+  public void testKafkaIOReadsAndWritesCorrectlyInStreaming() throws IOException {\n+    // Use batch pipeline to write records.\n+    writePipeline\n+        .apply(\"Generate records\", Read.from(new SyntheticBoundedSource(sourceOptions)))\n+        .apply(\"Measure write time\", ParDo.of(new TimeMonitor<>(NAMESPACE, WRITE_TIME_METRIC_NAME)))\n+        .apply(\"Write to Kafka\", writeToKafka());\n+\n+    // Use streaming pipeline to read Kafka records.\n+    readPipeline.getOptions().as(Options.class).setStreaming(true);\n+    readPipeline\n+        .apply(\"Read from Runner V2 Kafka\", readFromKafka())", "originalCommit": "d32629a17b3cda161f6be81459f6749a6d64499e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "730e7c064a878facbb6b5d3560445d2c513742ae", "url": "https://github.com/apache/beam/commit/730e7c064a878facbb6b5d3560445d2c513742ae", "message": "[BEAM-11172] Enable KafkaIO performance test for runner v2 with SDF.", "committedDate": "2020-11-12T19:13:49Z", "type": "commit"}, {"oid": "730e7c064a878facbb6b5d3560445d2c513742ae", "url": "https://github.com/apache/beam/commit/730e7c064a878facbb6b5d3560445d2c513742ae", "message": "[BEAM-11172] Enable KafkaIO performance test for runner v2 with SDF.", "committedDate": "2020-11-12T19:13:49Z", "type": "forcePushed"}]}