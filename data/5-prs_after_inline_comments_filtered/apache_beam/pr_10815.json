{"pr_number": 10815, "pr_title": "[BEAM-9279] Make HBase.ReadAll based on Reads instead of HBaseQuery", "pr_createdAt": "2020-02-10T08:48:39Z", "pr_url": "https://github.com/apache/beam/pull/10815", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjkyOTAxOA==", "url": "https://github.com/apache/beam/pull/10815#discussion_r376929018", "bodyText": "This was required to keep the Read class immutable. This is some kind of magic I did not know before in case you did not too https://lingpipe-blog.com/2009/08/10/serializing-immutable-singletons-serialization-proxy/", "author": "iemejia", "createdAt": "2020-02-10T08:52:06Z", "path": "sdks/java/io/hbase/src/main/java/org/apache/beam/sdk/io/hbase/HBaseIO.java", "diffHunk": "@@ -240,63 +245,109 @@ private Read(\n     @Override\n     public void populateDisplayData(DisplayData.Builder builder) {\n       super.populateDisplayData(builder);\n-      builder.add(DisplayData.item(\"configuration\", serializableConfiguration.get().toString()));\n+      builder.add(DisplayData.item(\"configuration\", configuration.toString()));\n       builder.add(DisplayData.item(\"tableId\", tableId));\n-      builder.addIfNotNull(DisplayData.item(\"scan\", serializableScan.get().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"scan\", scan.toString()));\n     }\n \n     public Configuration getConfiguration() {\n-      return serializableConfiguration.get();\n+      return configuration;\n     }\n \n     public String getTableId() {\n       return tableId;\n     }\n \n     public Scan getScan() {\n-      return serializableScan.get();\n+      return scan;\n     }\n \n     /** Returns the range of keys that will be read from the table. */\n     public ByteKeyRange getKeyRange() {\n-      byte[] startRow = serializableScan.get().getStartRow();\n-      byte[] stopRow = serializableScan.get().getStopRow();\n+      byte[] startRow = scan.getStartRow();\n+      byte[] stopRow = scan.getStopRow();\n       return ByteKeyRange.of(ByteKey.copyFrom(startRow), ByteKey.copyFrom(stopRow));\n     }\n \n-    private final SerializableConfiguration serializableConfiguration;\n+    @Override\n+    public boolean equals(Object o) {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      Read read = (Read) o;\n+      return configuration.toString().equals(read.configuration.toString())\n+          && Objects.equals(tableId, read.tableId)\n+          && scan.toString().equals(read.scan.toString());\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+      return Objects.hash(configuration, tableId, scan);\n+    }\n+\n+    private Object writeReplace() {", "originalCommit": "df531f48a8dbf3e567036e5acbd9bcc4633e9924", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDUxNTI4Mw==", "url": "https://github.com/apache/beam/pull/10815#discussion_r394515283", "bodyText": "Add it into method Javadoc please", "author": "aromanenko-dev", "createdAt": "2020-03-18T17:21:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjkyOTAxOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg2MDY1Nw==", "url": "https://github.com/apache/beam/pull/10815#discussion_r394860657", "bodyText": "good idea, doing it.", "author": "iemejia", "createdAt": "2020-03-19T08:31:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjkyOTAxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjkzMDYxOQ==", "url": "https://github.com/apache/beam/pull/10815#discussion_r376930619", "bodyText": "This creates a connection for each Read element, this is arguable costly because its nature is 1 to many, but it is an acceptable trade-off to support multiple Configurations and have the multi cluster flexibility.\nConnection initialization could be improved in the future via some sort of class based Pool mechanism (as we do for JdbcIO).", "author": "iemejia", "createdAt": "2020-02-10T08:55:47Z", "path": "sdks/java/io/hbase/src/main/java/org/apache/beam/sdk/io/hbase/HBaseReadSplittableDoFn.java", "diffHunk": "@@ -32,65 +31,50 @@\n import org.apache.hadoop.hbase.client.ConnectionFactory;\n import org.apache.hadoop.hbase.client.Result;\n import org.apache.hadoop.hbase.client.ResultScanner;\n-import org.apache.hadoop.hbase.client.Scan;\n import org.apache.hadoop.hbase.client.Table;\n \n /** A SplittableDoFn to read from HBase. */\n @BoundedPerElement\n-class HBaseReadSplittableDoFn extends DoFn<HBaseQuery, Result> {\n-  private final SerializableConfiguration serializableConfiguration;\n-\n-  private transient Connection connection;\n-\n-  HBaseReadSplittableDoFn(SerializableConfiguration serializableConfiguration) {\n-    this.serializableConfiguration = serializableConfiguration;\n-  }\n-\n-  @Setup\n-  public void setup() throws Exception {\n-    connection = ConnectionFactory.createConnection(serializableConfiguration.get());\n-  }\n-\n-  private static Scan newScanInRange(Scan scan, ByteKeyRange range) throws IOException {\n-    return new Scan(scan)\n-        .setStartRow(range.getStartKey().getBytes())\n-        .setStopRow(range.getEndKey().getBytes());\n-  }\n+class HBaseReadSplittableDoFn extends DoFn<Read, Result> {\n+  HBaseReadSplittableDoFn() {}\n \n   @ProcessElement\n-  public void processElement(ProcessContext c, RestrictionTracker<ByteKeyRange, ByteKey> tracker)\n+  public void processElement(\n+      @Element Read read,\n+      OutputReceiver<Result> out,\n+      RestrictionTracker<ByteKeyRange, ByteKey> tracker)\n       throws Exception {\n-    final HBaseQuery query = c.element();\n-    TableName tableName = TableName.valueOf(query.getTableId());\n+    Connection connection = ConnectionFactory.createConnection(read.getConfiguration());", "originalCommit": "df531f48a8dbf3e567036e5acbd9bcc4633e9924", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDUzNDA5Mw==", "url": "https://github.com/apache/beam/pull/10815#discussion_r394534093", "bodyText": "Please, add TODO about that.  Did you try to run performance test to see how much it's slower?", "author": "aromanenko-dev", "createdAt": "2020-03-18T17:51:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjkzMDYxOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg1OTMyNA==", "url": "https://github.com/apache/beam/pull/10815#discussion_r394859324", "bodyText": "Better filled https://issues.apache.org/jira/browse/BEAM-9554 to track this. No I did not test performance because this is a quite particular case as I mention, for users doing 1 to n queries when n is big this time would not be considerable, the real issue can manifest mostly in pipelines with streaming where we would like to do reads per window with multiple windows kind of similar to what we found for JdbcIO writes (but this case is waaay more common).", "author": "iemejia", "createdAt": "2020-03-19T08:28:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjkzMDYxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTAyNTI4Nw==", "url": "https://github.com/apache/beam/pull/10815#discussion_r379025287", "bodyText": "Is it a breaking change of users API?", "author": "aromanenko-dev", "createdAt": "2020-02-13T17:59:03Z", "path": "sdks/java/io/hbase/src/main/java/org/apache/beam/sdk/io/hbase/HBaseIO.java", "diffHunk": "@@ -240,63 +245,109 @@ private Read(\n     @Override\n     public void populateDisplayData(DisplayData.Builder builder) {\n       super.populateDisplayData(builder);\n-      builder.add(DisplayData.item(\"configuration\", serializableConfiguration.get().toString()));\n+      builder.add(DisplayData.item(\"configuration\", configuration.toString()));\n       builder.add(DisplayData.item(\"tableId\", tableId));\n-      builder.addIfNotNull(DisplayData.item(\"scan\", serializableScan.get().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"scan\", scan.toString()));\n     }\n \n     public Configuration getConfiguration() {\n-      return serializableConfiguration.get();\n+      return configuration;\n     }\n \n     public String getTableId() {\n       return tableId;\n     }\n \n     public Scan getScan() {\n-      return serializableScan.get();\n+      return scan;\n     }\n \n     /** Returns the range of keys that will be read from the table. */\n     public ByteKeyRange getKeyRange() {\n-      byte[] startRow = serializableScan.get().getStartRow();\n-      byte[] stopRow = serializableScan.get().getStopRow();\n+      byte[] startRow = scan.getStartRow();\n+      byte[] stopRow = scan.getStopRow();\n       return ByteKeyRange.of(ByteKey.copyFrom(startRow), ByteKey.copyFrom(stopRow));\n     }\n \n-    private final SerializableConfiguration serializableConfiguration;\n+    @Override\n+    public boolean equals(Object o) {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      Read read = (Read) o;\n+      return configuration.toString().equals(read.configuration.toString())\n+          && Objects.equals(tableId, read.tableId)\n+          && scan.toString().equals(read.scan.toString());\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+      return Objects.hash(configuration, tableId, scan);\n+    }\n+\n+    private Object writeReplace() {\n+      return new SerializationProxy(this);\n+    }\n+\n+    private static class SerializationProxy implements Serializable {\n+      public SerializationProxy() {}\n+\n+      public SerializationProxy(Read read) {\n+        configuration = read.configuration;\n+        tableId = read.tableId;\n+        scan = read.scan;\n+      }\n+\n+      private void writeObject(ObjectOutputStream out) throws IOException {\n+        SerializableCoder.of(SerializableConfiguration.class)\n+            .encode(new SerializableConfiguration(this.configuration), out);\n+        StringUtf8Coder.of().encode(this.tableId, out);\n+        ProtobufUtil.toScan(this.scan).writeDelimitedTo(out);\n+      }\n+\n+      private void readObject(ObjectInputStream in) throws IOException {\n+        this.configuration = SerializableCoder.of(SerializableConfiguration.class).decode(in).get();\n+        this.tableId = StringUtf8Coder.of().decode(in);\n+        this.scan = ProtobufUtil.toScan(ClientProtos.Scan.parseDelimitedFrom(in));\n+      }\n+\n+      Object readResolve() {\n+        return HBaseIO.read().withConfiguration(configuration).withTableId(tableId).withScan(scan);\n+      }\n+\n+      private Configuration configuration;\n+      private String tableId;\n+      private Scan scan;\n+    }\n+\n+    @SuppressFBWarnings(\"SE_BAD_FIELD\")\n+    private final Configuration configuration;\n+\n     private final String tableId;\n-    private final SerializableScan serializableScan;\n+\n+    @SuppressFBWarnings(\"SE_BAD_FIELD\")\n+    private final Scan scan;\n   }\n \n   /**\n    * A {@link PTransform} that works like {@link #read}, but executes read operations coming from a\n-   * {@link PCollection} of {@link HBaseQuery}.\n+   * {@link PCollection} of {@link Read}.\n    */\n   public static ReadAll readAll() {\n-    return new ReadAll(null);\n+    return new ReadAll();\n   }\n \n   /** Implementation of {@link #readAll}. */\n-  public static class ReadAll extends PTransform<PCollection<HBaseQuery>, PCollection<Result>> {\n-\n-    private ReadAll(SerializableConfiguration serializableConfiguration) {\n-      this.serializableConfiguration = serializableConfiguration;\n-    }\n-\n-    /** Reads from the HBase instance indicated by the* given configuration. */\n-    public ReadAll withConfiguration(Configuration configuration) {\n-      checkArgument(configuration != null, \"configuration can not be null\");\n-      return new ReadAll(new SerializableConfiguration(configuration));\n-    }\n+  public static class ReadAll extends PTransform<PCollection<Read>, PCollection<Result>> {", "originalCommit": "df531f48a8dbf3e567036e5acbd9bcc4633e9924", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE2MjM1OA==", "url": "https://github.com/apache/beam/pull/10815#discussion_r379162358", "bodyText": "Yes and it is intended, notice however that the only breaking change is for the SDF based read transform ReadAll. Also let's not forget that HBaseIO is still Experimental and Reads based on SDF for HBaseIO are Experimental^2. However after this change I seriously doubt the API will change in the future.", "author": "iemejia", "createdAt": "2020-02-13T22:47:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTAyNTI4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDUzMDQzMA==", "url": "https://github.com/apache/beam/pull/10815#discussion_r394530430", "bodyText": "Please, add this warning/note to top class Javadoc", "author": "aromanenko-dev", "createdAt": "2020-03-18T17:45:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTAyNTI4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg3NzAyNg==", "url": "https://github.com/apache/beam/pull/10815#discussion_r394877026", "bodyText": "I better do this in the CHANGES.md release notes file, so this gets announced with the release notes. Java will cover making users aware at the code level :)", "author": "iemejia", "createdAt": "2020-03-19T09:02:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTAyNTI4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDUxMjI1MA==", "url": "https://github.com/apache/beam/pull/10815#discussion_r394512250", "bodyText": "type \"scancan\"", "author": "aromanenko-dev", "createdAt": "2020-03-18T17:16:54Z", "path": "sdks/java/io/hbase/src/main/java/org/apache/beam/sdk/io/hbase/HBaseIO.java", "diffHunk": "@@ -173,33 +182,33 @@ public static Read read() {\n     /** Reads from the HBase instance indicated by the* given configuration. */\n     public Read withConfiguration(Configuration configuration) {\n       checkArgument(configuration != null, \"configuration can not be null\");\n-      return new Read(new SerializableConfiguration(configuration), tableId, serializableScan);\n+      return new Read(new Configuration(configuration), tableId, scan);\n     }\n \n     /** Reads from the specified table. */\n     public Read withTableId(String tableId) {\n       checkArgument(tableId != null, \"tableIdcan not be null\");\n-      return new Read(serializableConfiguration, tableId, serializableScan);\n+      return new Read(configuration, tableId, scan);\n     }\n \n     /** Filters the rows read from HBase using the given* scan. */\n     public Read withScan(Scan scan) {\n       checkArgument(scan != null, \"scancan not be null\");", "originalCommit": "df531f48a8dbf3e567036e5acbd9bcc4633e9924", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg0NjIxOA==", "url": "https://github.com/apache/beam/pull/10815#discussion_r394846218", "bodyText": "good one, fixing it", "author": "iemejia", "createdAt": "2020-03-19T08:00:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDUxMjI1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDUxMjUwNA==", "url": "https://github.com/apache/beam/pull/10815#discussion_r394512504", "bodyText": "typo \"tableIdcan\"", "author": "aromanenko-dev", "createdAt": "2020-03-18T17:17:18Z", "path": "sdks/java/io/hbase/src/main/java/org/apache/beam/sdk/io/hbase/HBaseIO.java", "diffHunk": "@@ -173,33 +182,33 @@ public static Read read() {\n     /** Reads from the HBase instance indicated by the* given configuration. */\n     public Read withConfiguration(Configuration configuration) {\n       checkArgument(configuration != null, \"configuration can not be null\");\n-      return new Read(new SerializableConfiguration(configuration), tableId, serializableScan);\n+      return new Read(new Configuration(configuration), tableId, scan);\n     }\n \n     /** Reads from the specified table. */\n     public Read withTableId(String tableId) {\n       checkArgument(tableId != null, \"tableIdcan not be null\");", "originalCommit": "df531f48a8dbf3e567036e5acbd9bcc4633e9924", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg0NjM2MQ==", "url": "https://github.com/apache/beam/pull/10815#discussion_r394846361", "bodyText": "fixing it, actually they were more ocurrencdes of this 'can' mistake I fixed them all now.", "author": "iemejia", "createdAt": "2020-03-19T08:01:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDUxMjUwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDkwNzA0NA==", "url": "https://github.com/apache/beam/pull/10815#discussion_r394907044", "bodyText": "thanks", "author": "aromanenko-dev", "createdAt": "2020-03-19T09:54:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDUxMjUwNA=="}], "type": "inlineReview"}, {"oid": "4fa842024c4da8db479505b256528f06173f9699", "url": "https://github.com/apache/beam/commit/4fa842024c4da8db479505b256528f06173f9699", "message": "[BEAM-9279] Refactor HBase to disminish relying on Serializable wrappers", "committedDate": "2020-03-19T09:32:30Z", "type": "commit"}, {"oid": "8b653b430875a3652dc01c0ba60ecb3f8239c299", "url": "https://github.com/apache/beam/commit/8b653b430875a3652dc01c0ba60ecb3f8239c299", "message": "[BEAM-9279] Make HBase.ReadAll based on Reads instead of HBaseQuery\n\nThis enable pipelines that can read from multiple configurations\nenabling pipelines to read simultaneously from multiple HBase clusters.", "committedDate": "2020-03-19T09:32:30Z", "type": "commit"}, {"oid": "8b653b430875a3652dc01c0ba60ecb3f8239c299", "url": "https://github.com/apache/beam/commit/8b653b430875a3652dc01c0ba60ecb3f8239c299", "message": "[BEAM-9279] Make HBase.ReadAll based on Reads instead of HBaseQuery\n\nThis enable pipelines that can read from multiple configurations\nenabling pipelines to read simultaneously from multiple HBase clusters.", "committedDate": "2020-03-19T09:32:30Z", "type": "forcePushed"}]}