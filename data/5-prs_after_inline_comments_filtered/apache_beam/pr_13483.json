{"pr_number": 13483, "pr_title": "[BEAM-11800] Support ARRAY_AGG fn for Zetasql dialect", "pr_createdAt": "2020-12-04T07:19:25Z", "pr_url": "https://github.com/apache/beam/pull/13483", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODg0MjUzMg==", "url": "https://github.com/apache/beam/pull/13483#discussion_r538842532", "bodyText": "I think here we expect schema:\nSchema schema = Schema.builder().addArrayField(\"array_field\", FieldType.of(FieldType.INT64)).build();\n\nmeaning it is an \"array of int64\"", "author": "robinyqiu", "createdAt": "2020-12-08T22:05:43Z", "path": "sdks/java/extensions/sql/zetasql/src/test/java/org/apache/beam/sdk/extensions/sql/zetasql/ZetaSqlDialectSpecTest.java", "diffHunk": "@@ -4067,4 +4060,21 @@ public void testSimpleTableName() {\n             Row.withSchema(singleField).addValues(15L).build());\n     pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n   }\n+\n+  @Test\n+  public void testArrayAggregation() {\n+    String sql =\n+            \"SELECT ARRAY_AGG(x) AS array_agg\\n\" +\n+                    \"FROM UNNEST([2, 1, -2, 3, -2, 1, 2]) AS x\";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    Schema schema = Schema.builder().addArrayField(\"array_field\", FieldType.of(Schema.TypeName.ARRAY)).build();", "originalCommit": "5216b44cab5042b9c55db6bb6bc3a2ec956f2957", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODg0OTk2MA==", "url": "https://github.com/apache/beam/pull/13483#discussion_r538849960", "bodyText": "Here you simply created an array type without specifying the element type. I guess that's why the error message says the \"inferred type is ARRAY NOT NULL\" (just array type, your can ignore the \"NOT NULL\" suffix), where it should be \"BIGINT NOT NULL ARRAY NOT NULL\" (array of bigint).\nTo create an array type with element type specified, you may want to use createTypeFactory().createArrayType(), like here: https://github.com/robinyqiu/beam/blob/cbe87445d4259b6b485bc010231dda1895022d83/sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/ZetaSqlCalciteTranslationUtils.java#L170", "author": "robinyqiu", "createdAt": "2020-12-08T22:18:11Z", "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/translation/SqlOperators.java", "diffHunk": "@@ -81,6 +72,12 @@\n           x -> createTypeFactory().createSqlType(SqlTypeName.VARCHAR),\n           new UdafImpl<>(new StringAgg.StringAggString()));\n \n+  public static final SqlOperator ARR_AGG_ARR_FN =\n+          createUdafOperator(\n+                  \"array_agg\",\n+                  x -> createTypeFactory().createSqlType(SqlTypeName.ARRAY),", "originalCommit": "5216b44cab5042b9c55db6bb6bc3a2ec956f2957", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTYwMDY1NQ==", "url": "https://github.com/apache/beam/pull/13483#discussion_r539600655", "bodyText": "But ARRAY_AGG should support all element types, not just INT64. https://github.com/google/zetasql/blob/master/docs/aggregate_functions.md#array_agg", "author": "ibzib", "createdAt": "2020-12-09T19:52:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODg0OTk2MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTYwMjMxOQ==", "url": "https://github.com/apache/beam/pull/13483#discussion_r539602319", "bodyText": "@ibzib exactly. I try to implement generic array like not sure if it is the correct way.\nprivate static RelDataType relDataType =\nnew JavaTypeFactoryImpl(RelDataTypeSystem.DEFAULT)\n.builder()\n.add(\"col_tinyint\", SqlTypeName.TINYINT)\n.add(\"col_smallint\", SqlTypeName.SMALLINT)\n.add(\"col_integer\", SqlTypeName.INTEGER)\n.add(\"col_bigint\", SqlTypeName.BIGINT)\n.add(\"col_float\", SqlTypeName.FLOAT)\n.add(\"col_double\", SqlTypeName.DOUBLE)\n.add(\"col_decimal\", SqlTypeName.DECIMAL)\n.add(\"col_string_varchar\", SqlTypeName.VARCHAR)\n.add(\"col_time\", SqlTypeName.TIME)\n.add(\"col_date\", SqlTypeName.DATE)\n.add(\"col_timestamp_with_local_time_zone\", SqlTypeName.TIMESTAMP_WITH_LOCAL_TIME_ZONE)\n.add(\"col_timestamp\", SqlTypeName.TIMESTAMP)\n.add(\"col_boolean\", SqlTypeName.BOOLEAN)\n.build();\npublic static final SqlOperator ARR_AGG_ARR_FN =\ncreateUdafOperator(\n\"array_agg\",\nx -> createTypeFactory().createArrayType(relDataType, -1),\nnew UdafImpl<>(new ArrayAgg.ArrayAggArray()));\n@robinyqiu", "author": "sonam-vend", "createdAt": "2020-12-09T19:54:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODg0OTk2MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTY2NDMyNg==", "url": "https://github.com/apache/beam/pull/13483#discussion_r539664326", "bodyText": "Yeah, ARRAY_AGG should be generic. I said the type should be \"BIGINT NOT NULL ARRAY NOT NULL\" because that's from the error message.\nSonam, I believe there is some way that you can get the element type from the input x. You don't need to define your new mapping.", "author": "robinyqiu", "createdAt": "2020-12-09T21:33:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODg0OTk2MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTk4MzU1Ng==", "url": "https://github.com/apache/beam/pull/13483#discussion_r539983556", "bodyText": "x -> createTypeFactory().createArrayType(x.getOperandType(0), -1) worked.\nThanks @robinyqiu  @ibzib", "author": "sonam-vend", "createdAt": "2020-12-10T08:51:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODg0OTk2MA=="}], "type": "inlineReview"}, {"oid": "b9903af960d97ada08e00a6cf35e33d13f64f210", "url": "https://github.com/apache/beam/commit/b9903af960d97ada08e00a6cf35e33d13f64f210", "message": "Implemeted ARRAY_AGG fn for Zetasql dialect", "committedDate": "2021-02-12T08:36:00Z", "type": "commit"}, {"oid": "eebf131d48ea11708c817031783938b64b4b36cb", "url": "https://github.com/apache/beam/commit/eebf131d48ea11708c817031783938b64b4b36cb", "message": "savning current dir", "committedDate": "2021-02-12T08:36:06Z", "type": "commit"}, {"oid": "98fb3b4a05634652e176da1d3a3edd022fe2ae49", "url": "https://github.com/apache/beam/commit/98fb3b4a05634652e176da1d3a3edd022fe2ae49", "message": "Modified implementation of array_Agg", "committedDate": "2021-02-12T08:36:06Z", "type": "commit"}, {"oid": "dd26f61524c165a2440718a49029e7f0f203ee8c", "url": "https://github.com/apache/beam/commit/dd26f61524c165a2440718a49029e7f0f203ee8c", "message": "draft implementation", "committedDate": "2021-02-12T10:35:46Z", "type": "commit"}, {"oid": "dd26f61524c165a2440718a49029e7f0f203ee8c", "url": "https://github.com/apache/beam/commit/dd26f61524c165a2440718a49029e7f0f203ee8c", "message": "draft implementation", "committedDate": "2021-02-12T10:35:46Z", "type": "forcePushed"}, {"oid": "cc09191ca9fafd3f82173a75e4d720e0417514fb", "url": "https://github.com/apache/beam/commit/cc09191ca9fafd3f82173a75e4d720e0417514fb", "message": "a fix in the code", "committedDate": "2021-02-17T06:00:31Z", "type": "commit"}, {"oid": "03f3bba96468ab49b98924dcdc1cc7718b005410", "url": "https://github.com/apache/beam/commit/03f3bba96468ab49b98924dcdc1cc7718b005410", "message": "renamed test", "committedDate": "2021-02-17T06:14:37Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3ODgwODA5MA==", "url": "https://github.com/apache/beam/pull/13483#discussion_r578808090", "bodyText": "The Beam ARRAY type expect the data to be a Collection type, not Object[] type (i.e Beam ARRAY != Java array). That's why you get the error during cast. The fix should be simple: change the return type of this function to list (also the third class generic parameter).", "author": "robinyqiu", "createdAt": "2021-02-18T23:02:44Z", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/udaf/ArrayAgg.java", "diffHunk": "@@ -0,0 +1,54 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.udaf;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.beam.sdk.transforms.Combine;\n+\n+public class ArrayAgg {\n+\n+  public static class ArrayAggArray extends Combine.CombineFn<Object, List<Object>, Object[]> {\n+    @Override\n+    public List<Object> createAccumulator() {\n+      return new ArrayList<>();\n+    }\n+\n+    @Override\n+    public List<Object> addInput(List<Object> accum, Object input) {\n+      accum.add(input);\n+      return accum;\n+    }\n+\n+    @Override\n+    public List<Object> mergeAccumulators(Iterable<List<Object>> accums) {\n+      List<Object> merged = new ArrayList<>();\n+      for (List<Object> accum : accums) {\n+        for (Object o : accum) {\n+          merged.add(o);\n+        }\n+      }\n+      return merged;\n+    }\n+\n+    @Override\n+    public Object[] extractOutput(List<Object> accumulator) {", "originalCommit": "03f3bba96468ab49b98924dcdc1cc7718b005410", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "161811df8def52c94e285076d19fc36173ee3fd6", "url": "https://github.com/apache/beam/commit/161811df8def52c94e285076d19fc36173ee3fd6", "message": "fixed return type", "committedDate": "2021-02-19T09:26:36Z", "type": "commit"}]}