{"pr_number": 11151, "pr_title": "[BEAM-9468]  Hl7v2 io", "pr_createdAt": "2020-03-18T01:28:29Z", "pr_url": "https://github.com/apache/beam/pull/11151", "timeline": [{"oid": "ea18728e6459afcc7b8093e57d88a3d55bc0e576", "url": "https://github.com/apache/beam/commit/ea18728e6459afcc7b8093e57d88a3d55bc0e576", "message": "add HL7v2IO and FhirIO, test dependency issue", "committedDate": "2020-03-12T01:01:18Z", "type": "commit"}, {"oid": "c5bda9fd2460afebc051d1b68636d6686916e4dd", "url": "https://github.com/apache/beam/commit/c5bda9fd2460afebc051d1b68636d6686916e4dd", "message": "add to changes", "committedDate": "2020-03-12T01:19:48Z", "type": "commit"}, {"oid": "1669f80bb68a73e0016532ef1c5b9ead62c4785b", "url": "https://github.com/apache/beam/commit/1669f80bb68a73e0016532ef1c5b9ead62c4785b", "message": "minor updates", "committedDate": "2020-03-16T18:56:52Z", "type": "commit"}, {"oid": "e9d70ec58bee4a231fffc5f932d4f00fdf687107", "url": "https://github.com/apache/beam/commit/e9d70ec58bee4a231fffc5f932d4f00fdf687107", "message": "staging before splitting PRs", "committedDate": "2020-03-17T23:09:01Z", "type": "commit"}, {"oid": "d6967914e10da1bf42815573b567cfff564d71a1", "url": "https://github.com/apache/beam/commit/d6967914e10da1bf42815573b567cfff564d71a1", "message": "remove FhirIO", "committedDate": "2020-03-17T23:10:43Z", "type": "commit"}, {"oid": "6b30a6248552d0765f7af228f21072c70d42756d", "url": "https://github.com/apache/beam/commit/6b30a6248552d0765f7af228f21072c70d42756d", "message": "simplify HL7v2IO structure", "committedDate": "2020-03-18T01:06:44Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDYzMTU5Nw==", "url": "https://github.com/apache/beam/pull/11151#discussion_r394631597", "bodyText": "I would recommend that the output of the transform be something like WriteResult returned by BigQueryIO.Write.\nThat should give you a more digestable output type for new users, with things like getFailedElements, etc. Thoughts?", "author": "pabloem", "createdAt": "2020-03-18T20:50:58Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -0,0 +1,620 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.healthcare;\n+\n+import com.google.api.services.healthcare.v1alpha2.model.IngestMessageResponse;\n+import com.google.api.services.healthcare.v1alpha2.model.Message;\n+import com.google.auto.value.AutoValue;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.io.gcp.datastore.AdaptiveThrottler;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubIO;\n+import org.apache.beam.sdk.metrics.Counter;\n+import org.apache.beam.sdk.metrics.Metrics;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionTuple;\n+import org.apache.beam.sdk.values.PDone;\n+import org.apache.beam.sdk.values.TupleTag;\n+import org.apache.beam.sdk.values.TupleTagList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Throwables;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * {@link HL7v2IO} provides an API for reading from and writing to <a\n+ * href=\"https://cloud.google.com/healthcare/docs/concepts/hl7v2\">Google Cloud Healthcare HL7v2 API.\n+ * </a>\n+ *\n+ * <p>Read HL7v2 Messages are fetched from the HL7v2 store based on the {@link PCollection} of of\n+ * message IDs {@link String}s produced by the {@link AutoValue_HL7v2IO_Read#getMessageIDTransform}\n+ * as {@link PCollectionTuple}*** containing an {@link HL7v2IO.Read#OUT} tag for successfully", "originalCommit": "6b30a6248552d0765f7af228f21072c70d42756d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI2OTIxMg==", "url": "https://github.com/apache/beam/pull/11151#discussion_r395269212", "bodyText": "Agreed. This is cleaner, I never thought of extending POutput, thanks for the tip!", "author": "jaketf", "createdAt": "2020-03-19T19:29:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDYzMTU5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDYzMjQwNw==", "url": "https://github.com/apache/beam/pull/11151#discussion_r394632407", "bodyText": "I believe you don't need the new here.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n             *     new HLv2IO.readNotifications(options.getNotificationSubscription())\n          \n          \n            \n             *     HLv2IO.readNotifications(options.getNotificationSubscription())", "author": "pabloem", "createdAt": "2020-03-18T20:52:24Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -0,0 +1,620 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.healthcare;\n+\n+import com.google.api.services.healthcare.v1alpha2.model.IngestMessageResponse;\n+import com.google.api.services.healthcare.v1alpha2.model.Message;\n+import com.google.auto.value.AutoValue;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.io.gcp.datastore.AdaptiveThrottler;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubIO;\n+import org.apache.beam.sdk.metrics.Counter;\n+import org.apache.beam.sdk.metrics.Metrics;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionTuple;\n+import org.apache.beam.sdk.values.PDone;\n+import org.apache.beam.sdk.values.TupleTag;\n+import org.apache.beam.sdk.values.TupleTagList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Throwables;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * {@link HL7v2IO} provides an API for reading from and writing to <a\n+ * href=\"https://cloud.google.com/healthcare/docs/concepts/hl7v2\">Google Cloud Healthcare HL7v2 API.\n+ * </a>\n+ *\n+ * <p>Read HL7v2 Messages are fetched from the HL7v2 store based on the {@link PCollection} of of\n+ * message IDs {@link String}s produced by the {@link AutoValue_HL7v2IO_Read#getMessageIDTransform}\n+ * as {@link PCollectionTuple}*** containing an {@link HL7v2IO.Read#OUT} tag for successfully\n+ * fetched messages and a {@link HL7v2IO.Read#DEAD_LETTER} tag for message IDs that could not be\n+ * fetched.\n+ *\n+ * <p>HL7v2 stores can be read in several ways: - Unbounded: based on the Pub/Sub Notification\n+ * Channel {@link HL7v2IO#readNotificationSubscription(String)} - Bounded: based on reading an\n+ * entire HL7v2 store (or stores) {@link HL7v2IO#readHL7v2Store(String)} - Bounded: based on reading\n+ * an HL7v2 store with a filter\n+ *\n+ * <p>Note, due to the flexibility of this Read transform, this must output a dead letter queue.\n+ * This handles the scenario where the the PTransform that populates a PCollection of message IDs\n+ * contains message IDs that do not exist in the HL7v2 stores.\n+ *\n+ * <p>Example:\n+ *\n+ * <pre>{@code\n+ * PipelineOptions options = ...;\n+ * Pipeline pipeline = Pipeline.create(options)\n+ *\n+ *\n+ * PCollectionTuple messages = pipeline.apply(\n+ *     new HLv2IO.readNotifications(options.getNotificationSubscription())", "originalCommit": "6b30a6248552d0765f7af228f21072c70d42756d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDY2ODUxNA==", "url": "https://github.com/apache/beam/pull/11151#discussion_r394668514", "bodyText": "Under this interface, you would do something like this:\nPipeline p = ....\nPCollectionTuple pct = p.apply(HL7v2IO.read(PubSubIO.read().fromTopic(....)));\n\nThis is a little odd. A more natural way of doing this would be something like this:\nPipeline p = ....\nPCollection<String> messageIds = p.apply(PubSubIO.read().fromTopic(....));\n\nHL7v2IO.Read.Result result = messageIds.apply(HL7v2IO.readAll());\n\nThis way, HL7v2IO.Read takes in a PCollection<String> containing the message IDs, instead of having a PTransform be a parameter, which is not commonly done elsewhere.\nThis is similar to how FileIO transforms work. Check out the functions match, matchAll, readMatches. https://beam.apache.org/releases/javadoc/2.19.0/index.html?org/apache/beam/sdk/io/FileIO.html", "author": "pabloem", "createdAt": "2020-03-18T22:10:51Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -0,0 +1,620 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.healthcare;\n+\n+import com.google.api.services.healthcare.v1alpha2.model.IngestMessageResponse;\n+import com.google.api.services.healthcare.v1alpha2.model.Message;\n+import com.google.auto.value.AutoValue;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.io.gcp.datastore.AdaptiveThrottler;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubIO;\n+import org.apache.beam.sdk.metrics.Counter;\n+import org.apache.beam.sdk.metrics.Metrics;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionTuple;\n+import org.apache.beam.sdk.values.PDone;\n+import org.apache.beam.sdk.values.TupleTag;\n+import org.apache.beam.sdk.values.TupleTagList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Throwables;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * {@link HL7v2IO} provides an API for reading from and writing to <a\n+ * href=\"https://cloud.google.com/healthcare/docs/concepts/hl7v2\">Google Cloud Healthcare HL7v2 API.\n+ * </a>\n+ *\n+ * <p>Read HL7v2 Messages are fetched from the HL7v2 store based on the {@link PCollection} of of\n+ * message IDs {@link String}s produced by the {@link AutoValue_HL7v2IO_Read#getMessageIDTransform}\n+ * as {@link PCollectionTuple}*** containing an {@link HL7v2IO.Read#OUT} tag for successfully\n+ * fetched messages and a {@link HL7v2IO.Read#DEAD_LETTER} tag for message IDs that could not be\n+ * fetched.\n+ *\n+ * <p>HL7v2 stores can be read in several ways: - Unbounded: based on the Pub/Sub Notification\n+ * Channel {@link HL7v2IO#readNotificationSubscription(String)} - Bounded: based on reading an\n+ * entire HL7v2 store (or stores) {@link HL7v2IO#readHL7v2Store(String)} - Bounded: based on reading\n+ * an HL7v2 store with a filter\n+ *\n+ * <p>Note, due to the flexibility of this Read transform, this must output a dead letter queue.\n+ * This handles the scenario where the the PTransform that populates a PCollection of message IDs\n+ * contains message IDs that do not exist in the HL7v2 stores.\n+ *\n+ * <p>Example:\n+ *\n+ * <pre>{@code\n+ * PipelineOptions options = ...;\n+ * Pipeline pipeline = Pipeline.create(options)\n+ *\n+ *\n+ * PCollectionTuple messages = pipeline.apply(\n+ *     new HLv2IO.readNotifications(options.getNotificationSubscription())\n+ *\n+ * // Write errors to your favorite dead letter  queue (e.g. Pub/Sub, GCS, BigQuery)\n+ * messages.get(PubsubNotificationToHL7v2Message.DEAD_LETTER)\n+ *    .apply(\"WriteToDeadLetterQueue\", ...);\n+ *\n+ * PCollection<Message> fetchedMessages = fetchResults.get(PubsubNotificationToHL7v2Message.OUT)\n+ *    .apply(\"ExtractFetchedMessage\",\n+ *    MapElements\n+ *        .into(TypeDescriptor.of(Message.class))\n+ *        .via(FailsafeElement::getPayload));\n+ *\n+ * // Go about your happy path transformations.\n+ * PCollection<Message> out = fetchedMessages.apply(\"ProcessFetchedMessages\", ...);\n+ *\n+ * // Write using the Message.Ingest method of the HL7v2 REST API.\n+ * out.apply(HL7v2IO.ingestMessages(options.getOutputHL7v2Store()));\n+ *\n+ * pipeline.run();\n+ *\n+ * }***\n+ * </pre>\n+ */\n+public class HL7v2IO {\n+  // TODO add metrics for failed records.\n+\n+  private static Read.Builder read(PTransform<PBegin, PCollection<String>> messageIDTransform) {", "originalCommit": "6b30a6248552d0765f7af228f21072c70d42756d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk0NjExNA==", "url": "https://github.com/apache/beam/pull/11151#discussion_r395946114", "bodyText": "refactored to implement both  HL7v2IO.[Read,Write].Result", "author": "jaketf", "createdAt": "2020-03-21T01:06:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDY2ODUxNA=="}], "type": "inlineReview"}, {"oid": "89955a9aab4ebc29dd0faf29c5b94075dc2c64c2", "url": "https://github.com/apache/beam/commit/89955a9aab4ebc29dd0faf29c5b94075dc2c64c2", "message": "add write result", "committedDate": "2020-03-20T15:29:52Z", "type": "commit"}, {"oid": "255905df34370a113556af7e894987483478f636", "url": "https://github.com/apache/beam/commit/255905df34370a113556af7e894987483478f636", "message": "refactor to HL7v2IO.Read.Result", "committedDate": "2020-03-20T21:31:23Z", "type": "commit"}, {"oid": "bfd8c9f9e0bc3a35fcf080b8d6e206b0a9bbd038", "url": "https://github.com/apache/beam/commit/bfd8c9f9e0bc3a35fcf080b8d6e206b0a9bbd038", "message": "add Coders and HL7v2IOTest", "committedDate": "2020-03-21T00:55:47Z", "type": "commit"}, {"oid": "4927c5b788458a46199f1e9a54f7e5958dddf71e", "url": "https://github.com/apache/beam/commit/4927c5b788458a46199f1e9a54f7e5958dddf71e", "message": "spotless", "committedDate": "2020-03-21T00:57:35Z", "type": "commit"}, {"oid": "cc43cc8a216fecad24afb3d97b53136fcd85e2a9", "url": "https://github.com/apache/beam/commit/cc43cc8a216fecad24afb3d97b53136fcd85e2a9", "message": "encode more of the Message", "committedDate": "2020-03-21T01:04:04Z", "type": "commit"}, {"oid": "8bcd6d0ac5868e0745cca7269324da3f696f9e7d", "url": "https://github.com/apache/beam/commit/8bcd6d0ac5868e0745cca7269324da3f696f9e7d", "message": "fix read result getPipeline", "committedDate": "2020-03-23T18:00:43Z", "type": "commit"}, {"oid": "1ccbabbe52389a76313a2f2d276ce52fcd73fa30", "url": "https://github.com/apache/beam/commit/1ccbabbe52389a76313a2f2d276ce52fcd73fa30", "message": "add adaptive throttler to write", "committedDate": "2020-03-23T18:38:13Z", "type": "commit"}, {"oid": "2470d5fa5d0bc4bdd94adbf0a4356143aa2e93b9", "url": "https://github.com/apache/beam/commit/2470d5fa5d0bc4bdd94adbf0a4356143aa2e93b9", "message": "remove unused import", "committedDate": "2020-03-23T18:49:30Z", "type": "commit"}, {"oid": "2a75b2e4126ee36583e737369192b1bc89205bf7", "url": "https://github.com/apache/beam/commit/2a75b2e4126ee36583e737369192b1bc89205bf7", "message": "improve test readability", "committedDate": "2020-03-23T18:57:57Z", "type": "commit"}, {"oid": "d90f2b5c06846e0400f2220fd70c14e0d2ab5939", "url": "https://github.com/apache/beam/commit/d90f2b5c06846e0400f2220fd70c14e0d2ab5939", "message": "nvm spotless apply didn't like that", "committedDate": "2020-03-23T19:30:12Z", "type": "commit"}, {"oid": "0c8dd1afaeb22e77794d16dbec7a158954ff8e74", "url": "https://github.com/apache/beam/commit/0c8dd1afaeb22e77794d16dbec7a158954ff8e74", "message": "scaffolding of Read integration test\n\nscaffolding of Read integration test", "committedDate": "2020-03-23T21:08:27Z", "type": "commit"}, {"oid": "7481810448fc020fc9c5624f15dcdf8c2c54d78c", "url": "https://github.com/apache/beam/commit/7481810448fc020fc9c5624f15dcdf8c2c54d78c", "message": "scaffolding for Write IT", "committedDate": "2020-03-23T21:25:35Z", "type": "commit"}, {"oid": "1f1bc2cdda9744036fd9f7cd8cd839ee05cf40de", "url": "https://github.com/apache/beam/commit/1f1bc2cdda9744036fd9f7cd8cd839ee05cf40de", "message": "small integration test", "committedDate": "2020-03-23T23:11:52Z", "type": "commit"}, {"oid": "03fef194d3828318e91a1a567ac46fc2ee25a756", "url": "https://github.com/apache/beam/commit/03fef194d3828318e91a1a567ac46fc2ee25a756", "message": "clean up", "committedDate": "2020-03-24T18:38:46Z", "type": "commit"}, {"oid": "b98f78d11e30e122c4d7a44884c844bde8b6f59c", "url": "https://github.com/apache/beam/commit/b98f78d11e30e122c4d7a44884c844bde8b6f59c", "message": "fix integration tests", "committedDate": "2020-03-24T20:05:56Z", "type": "commit"}, {"oid": "80597c9bba967067c974c8da74bd038b52fd0e7e", "url": "https://github.com/apache/beam/commit/80597c9bba967067c974c8da74bd038b52fd0e7e", "message": "add labels to Message coder", "committedDate": "2020-03-24T20:53:37Z", "type": "commit"}, {"oid": "c3881fd703914cbaa5aed823a9d681a3d02c703e", "url": "https://github.com/apache/beam/commit/c3881fd703914cbaa5aed823a9d681a3d02c703e", "message": "add parsed data coder", "committedDate": "2020-03-24T21:00:09Z", "type": "commit"}, {"oid": "634a166fb79da97ea6df2c84e0970c27f01e68ed", "url": "https://github.com/apache/beam/commit/634a166fb79da97ea6df2c84e0970c27f01e68ed", "message": "Refactor to use HL7v2Message wrapper class\n\n* Expose schematized data as JSON string to support motivating use case of\nHL7v2 -> FHIR via HCLS DataHamonization Mapping Engine.\n* The healthcare model Message class has fields\n(namely ParsedData and PatientIds) that are difficult to deal with in the Coder\nand provide little value for users.", "committedDate": "2020-03-24T22:42:46Z", "type": "commit"}, {"oid": "d50f06cb67b04757b9eb5da8c34c8b9c6632aeb0", "url": "https://github.com/apache/beam/commit/d50f06cb67b04757b9eb5da8c34c8b9c6632aeb0", "message": "set scope and user agent", "committedDate": "2020-03-24T23:02:10Z", "type": "commit"}, {"oid": "cac03ec30c77e6bd45954e659b875d0378370892", "url": "https://github.com/apache/beam/commit/cac03ec30c77e6bd45954e659b875d0378370892", "message": "add schematized data to coder", "committedDate": "2020-03-24T23:08:35Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODE4MDg0OA==", "url": "https://github.com/apache/beam/pull/11151#discussion_r398180848", "bodyText": "It might be worth supporting a the extra options on the new list API (view, and orderBy).  In particular, the view can return the full message payload right in the list, thereby saving a future retrieval step.", "author": "brianlucier", "createdAt": "2020-03-25T21:27:56Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -0,0 +1,658 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.healthcare;\n+\n+import com.google.api.services.healthcare.v1alpha2.model.Message;\n+import com.google.auto.value.AutoValue;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.beam.sdk.Pipeline;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.gcp.datastore.AdaptiveThrottler;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubIO;\n+import org.apache.beam.sdk.metrics.Counter;\n+import org.apache.beam.sdk.metrics.Metrics;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionTuple;\n+import org.apache.beam.sdk.values.PInput;\n+import org.apache.beam.sdk.values.POutput;\n+import org.apache.beam.sdk.values.PValue;\n+import org.apache.beam.sdk.values.TupleTag;\n+import org.apache.beam.sdk.values.TupleTagList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Throwables;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * {@link HL7v2IO} provides an API for reading from and writing to <a\n+ * href=\"https://cloud.google.com/healthcare/docs/concepts/hl7v2\">Google Cloud Healthcare HL7v2 API.\n+ * </a>\n+ *\n+ * <p>Read\n+ *\n+ * <p>HL7v2 Messages are fetched from the HL7v2 store based on the {@link PCollection} of message\n+ * IDs {@link String}s as {@link HL7v2IO.Read.Result} where one can call {@link\n+ * Read.Result#getMessages()} to retrived a {@link PCollection} containing the successfully fetched\n+ * {@link HL7v2Message}s and/or {@link Read.Result#getFailedReads()} to retrieve a {@link\n+ * PCollection} of {@link HealthcareIOError} containing the msgID that could not be fetched and the\n+ * exception as a {@link HealthcareIOError<String>}, this can be used to write to the dead letter\n+ * storage system of your choosing.\n+ *\n+ * <p>Write\n+ *\n+ * <p>A bounded or unbounded {@link PCollection} of {@link HL7v2Message} can be ingested into an\n+ * HL7v2 store using {@link HL7v2IO#ingestMessages(String)}. This will return a {@link\n+ * HL7v2IO.Write.Result} on which you can call {@link Write.Result#getFailedInsertsWithErr()} to\n+ * retrieve a {@link PCollection} of {@link HealthcareIOError<HL7v2Message>} containing the Message\n+ * that failed to be ingested and the exception. This can be used to write to the dead letter\n+ * storage system of your chosing.\n+ *\n+ * <p>Unbounded Example:\n+ *\n+ * <pre>{@code\n+ * PipelineOptions options = ...;\n+ * Pipeline p = Pipeline.create(options);\n+ *\n+ * HL7v2IO.Read.Result readResult = p\n+ *   .apply(\n+ *     \"Read HL7v2 notifications\",\n+ *     PubSubIO.readStrings().fromTopic(options.getNotificationSubscription()))\n+ *   .apply(HL7v2IO.readAll());\n+ *\n+ * // Write errors to your favorite dead letter  queue (e.g. Pub/Sub, GCS, BigQuery)\n+ * readResult.getFailedReads().apply(\"WriteToDeadLetterQueue\", ...);\n+ *\n+ *\n+ * // Go about your happy path transformations.\n+ * PCollection<HL7v2Message> out = readResult.getMessages().apply(\"ProcessFetchedMessages\", ...);\n+ *\n+ * // Write using the Message.Ingest method of the HL7v2 REST API.\n+ * out.apply(HL7v2IO.ingestMessages(options.getOutputHL7v2Store()));\n+ *\n+ * pipeline.run();\n+ *\n+ * }***\n+ * </pre>\n+ *\n+ * <p>Bounded Example:\n+ *\n+ * <pre>{@code\n+ * PipelineOptions options = ...;\n+ * Pipeline p = Pipeline.create(options);\n+ *\n+ * HL7v2IO.Read.Result readResult = p\n+ *   .apply(\n+ *       \"List messages in HL7v2 store with filter\",\n+ *       ListHL7v2MessageIDs(\n+ *           Collections.singletonList(options.getInputHL7v2Store()), option.getHL7v2Filter()))\n+ *   .apply(HL7v2IO.readAll());\n+ *\n+ * // Write errors to your favorite dead letter  queue (e.g. Pub/Sub, GCS, BigQuery)\n+ * readResult.getFailedReads().apply(\"WriteToDeadLetterQueue\", ...);\n+ *\n+ *\n+ * // Go about your happy path transformations.\n+ * PCollection<HL7v2Message> out = readResult.getMessages().apply(\"ProcessFetchedMessages\", ...);\n+ *\n+ * // Write using the Message.Ingest method of the HL7v2 REST API.\n+ * out.apply(HL7v2IO.ingestMessages(options.getOutputHL7v2Store()));\n+ *\n+ * pipeline.run().waitUntilFinish();\n+ * }***\n+ * </pre>\n+ */\n+public class HL7v2IO {\n+\n+  private static Write.Builder write(String hl7v2Store) {\n+    return new AutoValue_HL7v2IO_Write.Builder().setHL7v2Store(hl7v2Store);\n+  }\n+\n+  public static Read readAll() {\n+    return new Read();\n+  }\n+\n+  /**\n+   * Write with Messages.Ingest method. @see <a\n+   * href=https://cloud.google.com/healthcare/docs/reference/rest/v1beta1/projects.locations.datasets.hl7V2Stores.messages/ingest></a>\n+   *\n+   * @param hl7v2Store the hl 7 v 2 store\n+   * @return the write\n+   */\n+  public static Write ingestMessages(String hl7v2Store) {\n+    return write(hl7v2Store).setWriteMethod(Write.WriteMethod.INGEST).build();\n+  }\n+\n+  // TODO add hyper links to this doc string.\n+  /**\n+   * The type Read that reads HL7v2 message contents given a PCollection of message IDs strings.\n+   *\n+   * <p>These could be sourced from any {@link PCollection} of {@link String}s but the most popular\n+   * patterns would be {@link PubsubIO#readStrings()} reading a subscription on an HL7v2 Store's\n+   * notification channel topic or using {@link ListHL7v2MessageIDs} to list HL7v2 message IDs with\n+   * an optional filter using Ingest write method. @see <a\n+   * href=https://cloud.google.com/healthcare/docs/reference/rest/v1beta1/projects.locations.datasets.hl7V2Stores.messages/list></a>.\n+   */\n+  public static class Read extends PTransform<PCollection<String>, Read.Result> {\n+\n+    public Read() {}\n+\n+    public static class Result implements POutput, PInput {\n+      private PCollection<HL7v2Message> messages;\n+\n+      private PCollection<HealthcareIOError<String>> failedReads;\n+      PCollectionTuple pct;\n+\n+      public static Result of(PCollectionTuple pct) throws IllegalArgumentException {\n+        if (pct.getAll()\n+            .keySet()\n+            .containsAll((Collection<?>) TupleTagList.of(OUT).and(DEAD_LETTER))) {\n+          return new Result(pct);\n+        } else {\n+          throw new IllegalArgumentException(\n+              \"The PCollection tuple must have the HL7v2IO.Read.OUT \"\n+                  + \"and HL7v2IO.Read.DEAD_LETTER tuple tags\");\n+        }\n+      }\n+\n+      private Result(PCollectionTuple pct) {\n+        this.pct = pct;\n+        this.messages = pct.get(OUT).setCoder(new HL7v2MessageCoder());\n+        this.failedReads =\n+            pct.get(DEAD_LETTER).setCoder(new HealthcareIOErrorCoder<>(StringUtf8Coder.of()));\n+      }\n+\n+      public PCollection<HealthcareIOError<String>> getFailedReads() {\n+        return failedReads;\n+      }\n+\n+      public PCollection<HL7v2Message> getMessages() {\n+        return messages;\n+      }\n+\n+      @Override\n+      public Pipeline getPipeline() {\n+        return this.pct.getPipeline();\n+      }\n+\n+      @Override\n+      public Map<TupleTag<?>, PValue> expand() {\n+        return ImmutableMap.of(OUT, messages);\n+      }\n+\n+      @Override\n+      public void finishSpecifyingOutput(\n+          String transformName, PInput input, PTransform<?, ?> transform) {}\n+    }\n+\n+    /** The tag for the main output of HL7v2 Messages. */\n+    public static final TupleTag<HL7v2Message> OUT = new TupleTag<HL7v2Message>() {};\n+    /** The tag for the deadletter output of HL7v2 Messages. */\n+    public static final TupleTag<HealthcareIOError<String>> DEAD_LETTER =\n+        new TupleTag<HealthcareIOError<String>>() {};\n+\n+    @Override\n+    public Result expand(PCollection<String> input) {\n+      return input.apply(\"Fetch HL7v2 messages\", new FetchHL7v2Message());\n+    }\n+\n+    /**\n+     * DoFn to fetch a message from an Google Cloud Healthcare HL7v2 store based on msgID\n+     *\n+     * <p>This DoFn consumes a {@link PCollection} of notifications {@link String}s from the HL7v2\n+     * store, and fetches the actual {@link HL7v2Message} object based on the id in the notification\n+     * and will output a {@link PCollectionTuple} which contains the output and dead-letter {@link\n+     * PCollection}.\n+     *\n+     * <p>The {@link PCollectionTuple} output will contain the following {@link PCollection}:\n+     *\n+     * <ul>\n+     *   <li>{@link HL7v2IO.Read#OUT} - Contains all {@link PCollection} records successfully read\n+     *       from the HL7v2 store.\n+     *   <li>{@link HL7v2IO.Read#DEAD_LETTER} - Contains all {@link PCollection} of {@link\n+     *       HealthcareIOError<String>} message IDs which failed to be fetched from the HL7v2 store,\n+     *       with error message and stacktrace.\n+     * </ul>\n+     *\n+     * <p>Example:\n+     *\n+     * <pre>{@code\n+     * PipelineOptions options = ...;\n+     * Pipeline pipeline = Pipeline.create(options)\n+     *\n+     * PCollection<String> msgIDs = pipeline.apply(\n+     *    \"ReadHL7v2Notifications\",\n+     *    PubsubIO.readStrings().fromSubscription(options.getInputSubscription()));\n+     *\n+     * PCollectionTuple fetchResults = msgIDs.apply(\n+     *    \"FetchHL7v2Messages\",\n+     *    new FetchHL7v2Message;\n+     *\n+     * // Write errors to your favorite dead letter  queue (e.g. Pub/Sub, GCS, BigQuery)\n+     * fetchResults.get(PubsubNotificationToHL7v2Message.DEAD_LETTER)\n+     *    .apply(\"WriteToDeadLetterQueue\", ...);\n+     *\n+     * PCollection<Message> fetchedMessages = fetchResults.get(PubsubNotificationToHL7v2Message.OUT)\n+     *    .apply(\"ExtractFetchedMessage\",\n+     *    MapElements\n+     *        .into(TypeDescriptor.of(Message.class))\n+     *        .via(FailsafeElement::getPayload));\n+     *\n+     * // Go about your happy path transformations.\n+     * fetchedMessages.apply(\"ProcessFetchedMessages\", ...)\n+     *\n+     * }****\n+     * </pre>\n+     */\n+    public static class FetchHL7v2Message extends PTransform<PCollection<String>, Result> {\n+\n+      /** Instantiates a new Fetch HL7v2 message DoFn. */\n+      public FetchHL7v2Message() {}\n+\n+      @Override\n+      public Result expand(PCollection<String> msgIds) {\n+        return new Result(\n+            msgIds.apply(\n+                ParDo.of(new FetchHL7v2Message.HL7v2MessageGetFn())\n+                    .withOutputTags(HL7v2IO.Read.OUT, TupleTagList.of(HL7v2IO.Read.DEAD_LETTER))));\n+      }\n+\n+      /** DoFn for fetching messages from the HL7v2 store with error handling. */\n+      public static class HL7v2MessageGetFn extends DoFn<String, HL7v2Message> {\n+\n+        private Counter failedMessageGets =\n+            Metrics.counter(FetchHL7v2Message.HL7v2MessageGetFn.class, \"failed-message-reads\");\n+        private static final Logger LOG =\n+            LoggerFactory.getLogger(FetchHL7v2Message.HL7v2MessageGetFn.class);\n+        private final Counter throttledSeconds =\n+            Metrics.counter(\n+                FetchHL7v2Message.HL7v2MessageGetFn.class, \"cumulative-throttling-seconds\");\n+        private final Counter successfulHL7v2MessageGets =\n+            Metrics.counter(\n+                FetchHL7v2Message.HL7v2MessageGetFn.class, \"successful-hl7v2-message-gets\");\n+        private HealthcareApiClient client;\n+        private transient AdaptiveThrottler throttler;\n+\n+        /** Instantiates a new Hl 7 v 2 message get fn. */\n+        HL7v2MessageGetFn() {}\n+\n+        /**\n+         * Instantiate healthcare client.\n+         *\n+         * @throws IOException the io exception\n+         */\n+        @Setup\n+        public void instantiateHealthcareClient() throws IOException {\n+          this.client = new HttpHealthcareApiClient();\n+        }\n+\n+        /** Start bundle. */\n+        @StartBundle\n+        public void startBundle() {\n+          if (throttler == null) {\n+            throttler = new AdaptiveThrottler(1200000, 10000, 1.25);\n+          }\n+        }\n+\n+        /**\n+         * Process element.\n+         *\n+         * @param context the context\n+         */\n+        @ProcessElement\n+        public void processElement(ProcessContext context) {\n+          String msgId = context.element();\n+          try {\n+            context.output(HL7v2Message.fromModel(fetchMessage(this.client, msgId)));\n+          } catch (Exception e) {\n+            failedMessageGets.inc();\n+            LOG.warn(\n+                String.format(\n+                    \"Error fetching HL7v2 message with ID %s writing to Dead Letter \"\n+                        + \"Queue. Cause: %s Stack Trace: %s\",\n+                    msgId, e.getMessage(), Throwables.getStackTraceAsString(e)));\n+            context.output(HL7v2IO.Read.DEAD_LETTER, HealthcareIOError.of(msgId, e));\n+          }\n+        }\n+\n+        private Message fetchMessage(HealthcareApiClient client, String msgId)\n+            throws IOException, ParseException, IllegalArgumentException, InterruptedException {\n+          final int throttleWaitSeconds = 5;\n+          long startTime = System.currentTimeMillis();\n+          Sleeper sleeper = Sleeper.DEFAULT;\n+          if (throttler.throttleRequest(startTime)) {\n+            LOG.info(String.format(\"Delaying request for %s due to previous failures.\", msgId));\n+            this.throttledSeconds.inc(throttleWaitSeconds);\n+            sleeper.sleep(throttleWaitSeconds * 1000);\n+          }\n+\n+          com.google.api.services.healthcare.v1alpha2.model.Message msg =\n+              client.getHL7v2Message(msgId);\n+\n+          this.throttler.successfulRequest(startTime);\n+          if (msg == null) {\n+            throw new IOException(String.format(\"GET request for %s returned null\", msgId));\n+          }\n+          this.successfulHL7v2MessageGets.inc();\n+          return msg;\n+        }\n+      }\n+    }\n+  }\n+\n+  /** The type List HL7v2 message IDs. */\n+  public static class ListHL7v2MessageIDs extends PTransform<PBegin, PCollection<String>> {\n+\n+    private final List<String> hl7v2Stores;\n+    private final String filter;\n+\n+    /**\n+     * Instantiates a new List HL7v2 message IDs with filter.\n+     *\n+     * @param hl7v2Stores the HL7v2 stores\n+     * @param filter the filter\n+     */\n+    ListHL7v2MessageIDs(List<String> hl7v2Stores, String filter) {", "originalCommit": "cac03ec30c77e6bd45954e659b875d0378370892", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODIwMDM5NA==", "url": "https://github.com/apache/beam/pull/11151#discussion_r398200394", "bodyText": "Thanks for bringing this up.\nAgreed on supporting getting the messages from the alpha2 list API to save the extra retrieval.\nIMO this DoFn should remain as is to support backwards compatibility with the beta1 list api (which only has message IDs in the response) through a similar code path to the real time use cases which would subscribe to pubsub notifications (which also only have the message IDs and require retrieval).\n@pabloem @lastomato thoughts on how we should best handle the two different APIs minimizing calls where possible?\nI see two possible strategies:\n\nRely on user to use a different PTransform depending on which API version they are trying to hit.\n\nFor beta1 api requiring \"get\" after list: HL7v2IO.ListHL7v2MessageIDs -> HL7v2IO.Read(current path).\nAdd a new PTransform for alpha2 api (where message contents are in the list): HL7v2IO.V2.Read extends PTransform<PBegin, HL7v2Message>\n\n\nRestructuring so we can support both API responses with a single composite PTransform that follows this logic:\n\nListMessageFn makes the message list call and outputs to two PCollections with the following logic:\n\nIF response contains the hl7V2Messages key and either output the messages to the PCollection<HL7v2Message> with a V2 tuple tag\nELSE  output the messageIDs PCollection<String> with a V1 tuple tag\n\n\nOn the V1 tagged PCollection apply HL7v2IO.Read to produce a PCollection<HL7v2Message>\nFlatten the two PCollection<HL7v2Message> (one of which will always in theory be empty) to form your ultimate output collection\n\n\n\nMy thoughts of trade-offs are:\n\nPros: Simpler execution path, simpler to implement (strictly additive) given work already done. Cons: User has to know what they're doing and need to document / maintain both paths\nPros: Simpler interface for users Cons: more complicated execution path, heavier lift.\n\nI'm torn on which would be preferable and would love input on which approach others think is cleanest before implementing. (Or suggestions to something I haven't thought of!)", "author": "jaketf", "createdAt": "2020-03-25T22:08:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODE4MDg0OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODU4NDYyNg==", "url": "https://github.com/apache/beam/pull/11151#discussion_r398584626", "bodyText": "As a user -- I'll know what version of the V2 store I am using and likely am never switching back and forth.  For instance, I would just ignore the beta PTransform and use the alpha one.  Seems like that is not a large user burden.", "author": "brianlucier", "createdAt": "2020-03-26T13:47:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODE4MDg0OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQ1MjUwMQ==", "url": "https://github.com/apache/beam/pull/11151#discussion_r399452501", "bodyText": "This can be resolved because beta API also supports view now.\nRefactored to serve this use case w/ a separate PTransform and updated docstring.", "author": "jaketf", "createdAt": "2020-03-27T18:10:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODE4MDg0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODIxNTIwNg==", "url": "https://github.com/apache/beam/pull/11151#discussion_r398215206", "bodyText": "Note, this ArrayMap<String, String> is basically the Message model.\nIf you use the alpha API to query an beta HL7v2 store, there will be a single key name with the message ID value.\nIf you use the alpha API to query an alpha HL7v2 store, there will be all of the keys in the Message model.", "author": "jaketf", "createdAt": "2020-03-25T22:42:41Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HttpHealthcareApiClient.java", "diffHunk": "@@ -0,0 +1,452 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.healthcare;\n+\n+import com.google.api.client.http.HttpHeaders;\n+import com.google.api.client.http.HttpRequest;\n+import com.google.api.client.http.HttpRequestInitializer;\n+import com.google.api.client.http.javanet.NetHttpTransport;\n+import com.google.api.client.json.JsonFactory;\n+import com.google.api.client.json.gson.GsonFactory;\n+import com.google.api.client.util.ArrayMap;\n+import com.google.api.services.healthcare.v1alpha2.CloudHealthcare;\n+import com.google.api.services.healthcare.v1alpha2.CloudHealthcare.Projects.Locations.Datasets.Hl7V2Stores.Messages;\n+import com.google.api.services.healthcare.v1alpha2.CloudHealthcareScopes;\n+import com.google.api.services.healthcare.v1alpha2.model.CreateMessageRequest;\n+import com.google.api.services.healthcare.v1alpha2.model.Empty;\n+import com.google.api.services.healthcare.v1alpha2.model.Hl7V2Store;\n+import com.google.api.services.healthcare.v1alpha2.model.HttpBody;\n+import com.google.api.services.healthcare.v1alpha2.model.IngestMessageRequest;\n+import com.google.api.services.healthcare.v1alpha2.model.IngestMessageResponse;\n+import com.google.api.services.healthcare.v1alpha2.model.ListMessagesResponse;\n+import com.google.api.services.healthcare.v1alpha2.model.Message;\n+import com.google.api.services.healthcare.v1alpha2.model.SearchResourcesRequest;\n+import com.google.auth.oauth2.GoogleCredentials;\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.net.URI;\n+import java.text.ParseException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NoSuchElementException;\n+import java.util.Spliterator;\n+import java.util.Spliterators;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.extensions.gcp.util.RetryHttpRequestInitializer;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Strings;\n+\n+/**\n+ * A client that talks to the Cloud Healthcare API through HTTP requests. This client is created\n+ * mainly to encapsulate the unserializable dependencies, since most generated classes are not\n+ * serializable in the HTTP client.\n+ */\n+public class HttpHealthcareApiClient<T> implements HealthcareApiClient, Serializable {\n+\n+  private transient CloudHealthcare client;\n+\n+  /**\n+   * Instantiates a new Http healthcare api client.\n+   *\n+   * @throws IOException the io exception\n+   */\n+  public HttpHealthcareApiClient() throws IOException {\n+    initClient();\n+  }\n+\n+  /**\n+   * Instantiates a new Http healthcare api client.\n+   *\n+   * @param client the client\n+   * @throws IOException the io exception\n+   */\n+  public HttpHealthcareApiClient(CloudHealthcare client) throws IOException {\n+    this.client = client;\n+    initClient();\n+  }\n+\n+  @VisibleForTesting\n+  static <T, X extends Collection<T>> Stream<T> flattenIteratorCollectionsToStream(\n+      Iterator<X> iterator) {\n+    Spliterator<Collection<T>> spliterator = Spliterators.spliteratorUnknownSize(iterator, 0);\n+    return StreamSupport.stream(spliterator, false).flatMap(Collection::stream);\n+  }\n+\n+  public JsonFactory getJsonFactory() {\n+    return this.client.getJsonFactory();\n+  }\n+\n+  @Override\n+  public ListMessagesResponse makeHL7v2ListRequest(\n+      String hl7v2Store, @Nullable String filter, @Nullable String pageToken) throws IOException {\n+\n+    Messages.List baseRequest =\n+        client\n+            .projects()\n+            .locations()\n+            .datasets()\n+            .hl7V2Stores()\n+            .messages()\n+            .list(hl7v2Store)\n+            .setPageToken(pageToken);\n+\n+    if (Strings.isNullOrEmpty(filter)) {\n+      return baseRequest.execute();\n+    } else {\n+      return baseRequest.setFilter(filter).execute();\n+    }\n+  }\n+\n+  /**\n+   * Gets message id page iterator.\n+   *\n+   * @param hl7v2Store the HL7v2 store\n+   * @return the message id page iterator\n+   * @throws IOException the io exception\n+   */\n+  @Override\n+  public Stream<String> getHL7v2MessageIDStream(String hl7v2Store) throws IOException {\n+    return getHL7v2MessageIDStream(hl7v2Store, null);\n+  }\n+\n+  /**\n+   * Get a {@link Stream} of message IDs from flattening the pages of a new {@link\n+   * HL7v2MessageIDPages}.\n+   *\n+   * @param hl7v2Store the HL7v2 store\n+   * @param filter the filter\n+   * @return the message id Stream\n+   * @throws IOException the io exception\n+   */\n+  @Override\n+  public Stream<String> getHL7v2MessageIDStream(String hl7v2Store, @Nullable String filter)\n+      throws IOException {\n+    Iterator<List<String>> iterator = new HL7v2MessageIDPages(this, hl7v2Store, filter).iterator();\n+    return flattenIteratorCollectionsToStream(iterator);\n+  }\n+\n+  /**\n+   * Gets HL7v2 message.\n+   *\n+   * @param msgName the msg name\n+   * @return the message\n+   * @throws IOException the io exception\n+   * @throws ParseException the parse exception\n+   */\n+  @Override\n+  public Message getHL7v2Message(String msgName) throws IOException {\n+    Message msg =\n+        client.projects().locations().datasets().hl7V2Stores().messages().get(msgName).execute();\n+    if (msg == null) {\n+      throw new IOException(String.format(\"Couldn't find message: %s.\", msgName));\n+    }\n+    return msg;\n+  }\n+\n+  @Override\n+  public Empty deleteHL7v2Message(String msgName) throws IOException {\n+    return client\n+        .projects()\n+        .locations()\n+        .datasets()\n+        .hl7V2Stores()\n+        .messages()\n+        .delete(msgName)\n+        .execute();\n+  }\n+\n+  /**\n+   * Gets HL7v2 store.\n+   *\n+   * @param storeName the store name\n+   * @return the HL7v2 store\n+   * @throws IOException the io exception\n+   */\n+  @Override\n+  public Hl7V2Store getHL7v2Store(String storeName) throws IOException {\n+    return client.projects().locations().datasets().hl7V2Stores().get(storeName).execute();\n+  }\n+\n+  @Override\n+  public IngestMessageResponse ingestHL7v2Message(String hl7v2Store, Message msg)\n+      throws IOException {\n+    IngestMessageRequest ingestMessageRequest = new IngestMessageRequest();\n+    ingestMessageRequest.setMessage(msg);\n+    return client\n+        .projects()\n+        .locations()\n+        .datasets()\n+        .hl7V2Stores()\n+        .messages()\n+        .ingest(hl7v2Store, ingestMessageRequest)\n+        .execute();\n+  }\n+\n+  @Override\n+  public HttpBody fhirSearch(String fhirStore, SearchResourcesRequest query) throws IOException {\n+    return client\n+        .projects()\n+        .locations()\n+        .datasets()\n+        .fhirStores()\n+        .fhir()\n+        .search(fhirStore, query)\n+        .execute();\n+  }\n+\n+  @Override\n+  public Message createHL7v2Message(String hl7v2Store, Message msg) throws IOException {\n+    CreateMessageRequest createMessageRequest = new CreateMessageRequest();\n+    createMessageRequest.setMessage(msg);\n+    return client\n+        .projects()\n+        .locations()\n+        .datasets()\n+        .hl7V2Stores()\n+        .messages()\n+        .create(hl7v2Store, createMessageRequest)\n+        .execute();\n+  }\n+\n+  @Override\n+  public HttpBody createFhirResource(String fhirStore, String type, HttpBody body)\n+      throws IOException {\n+    return client\n+        .projects()\n+        .locations()\n+        .datasets()\n+        .fhirStores()\n+        .fhir()\n+        .create(fhirStore, type, body)\n+        .execute();\n+  }\n+\n+  @Override\n+  public HttpBody executeFhirBundle(String fhirStore, HttpBody bundle) throws IOException {\n+    return client\n+        .projects()\n+        .locations()\n+        .datasets()\n+        .fhirStores()\n+        .fhir()\n+        .executeBundle(fhirStore, bundle)\n+        .execute();\n+  }\n+\n+  @Override\n+  public HttpBody listFHIRResourceForPatient(String fhirStore, String patient) throws IOException {\n+    return client\n+        .projects()\n+        .locations()\n+        .datasets()\n+        .fhirStores()\n+        .fhir()\n+        .patientEverything(patient)\n+        .execute();\n+  }\n+\n+  @Override\n+  public HttpBody readFHIRResource(String fhirStore, String resource) throws IOException {\n+    return client.projects().locations().datasets().fhirStores().fhir().read(resource).execute();\n+  }\n+\n+  private static class AuthenticatedRetryInitializer extends RetryHttpRequestInitializer {\n+    GoogleCredentials credentials;\n+\n+    public AuthenticatedRetryInitializer(GoogleCredentials credentials) {\n+      super();\n+      this.credentials = credentials;\n+    }\n+\n+    @Override\n+    public void initialize(HttpRequest request) throws IOException {\n+      super.initialize(request);\n+      if (!credentials.hasRequestMetadata()) {\n+        return;\n+      }\n+      HttpHeaders requestHeaders = request.getHeaders();\n+      requestHeaders.setUserAgent(\"apache-beam-hl7v2-io\");\n+      URI uri = null;\n+      if (request.getUrl() != null) {\n+        uri = request.getUrl().toURI();\n+      }\n+      Map<String, List<String>> credentialHeaders = credentials.getRequestMetadata(uri);\n+      if (credentialHeaders == null) {\n+        return;\n+      }\n+      for (Map.Entry<String, List<String>> entry : credentialHeaders.entrySet()) {\n+        String headerName = entry.getKey();\n+        List<String> requestValues = new ArrayList<>(entry.getValue());\n+        requestHeaders.put(headerName, requestValues);\n+      }\n+    }\n+  }\n+\n+  private void initClient() throws IOException {\n+    // Create a HttpRequestInitializer, which will provide a baseline configuration to all requests.\n+    // HttpRequestInitializer requestInitializer = new RetryHttpRequestInitializer();\n+    // GoogleCredentials credentials = GoogleCredentials.getApplicationDefault();\n+    HttpRequestInitializer requestInitializer =\n+        new AuthenticatedRetryInitializer(\n+            GoogleCredentials.getApplicationDefault()\n+                .createScoped(CloudHealthcareScopes.CLOUD_PLATFORM));\n+\n+    client =\n+        new CloudHealthcare.Builder(new NetHttpTransport(), new GsonFactory(), requestInitializer)\n+            .setApplicationName(\"apache-beam-hl7v2-io\")\n+            .build();\n+  }\n+\n+  public static class HL7v2MessageIDPages implements Iterable<List<String>> {\n+\n+    private final String hl7v2Store;\n+    private final String filter;\n+    private transient HealthcareApiClient client;\n+\n+    /**\n+     * Instantiates a new HL7v2 message id pages.\n+     *\n+     * @param client the client\n+     * @param hl7v2Store the HL7v2 store\n+     */\n+    HL7v2MessageIDPages(HealthcareApiClient client, String hl7v2Store) {\n+      this.client = client;\n+      this.hl7v2Store = hl7v2Store;\n+      this.filter = null;\n+    }\n+\n+    /**\n+     * Instantiates a new HL7v2 message id pages.\n+     *\n+     * @param client the client\n+     * @param hl7v2Store the HL7v2 store\n+     * @param filter the filter\n+     */\n+    HL7v2MessageIDPages(HealthcareApiClient client, String hl7v2Store, @Nullable String filter) {\n+      this.client = client;\n+      this.hl7v2Store = hl7v2Store;\n+      this.filter = filter;\n+    }\n+\n+    /**\n+     * Make list request list messages response.\n+     *\n+     * @param client the client\n+     * @param hl7v2Store the hl 7 v 2 store\n+     * @param filter the filter\n+     * @param pageToken the page token\n+     * @return the list messages response\n+     * @throws IOException the io exception\n+     */\n+    public static ListMessagesResponse makeListRequest(\n+        HealthcareApiClient client,\n+        String hl7v2Store,\n+        @Nullable String filter,\n+        @Nullable String pageToken)\n+        throws IOException {\n+      return client.makeHL7v2ListRequest(hl7v2Store, filter, pageToken);\n+    }\n+\n+    @Override\n+    public Iterator<List<String>> iterator() {\n+      return new HL7v2MessageIDPagesIterator(this.client, this.hl7v2Store, this.filter);\n+    }\n+\n+    /** The type Hl7v2 message id pages iterator. */\n+    public static class HL7v2MessageIDPagesIterator implements Iterator<List<String>> {\n+\n+      private final String hl7v2Store;\n+      private final String filter;\n+      private HealthcareApiClient client;\n+      private String pageToken;\n+      private boolean isFirstRequest;\n+\n+      /**\n+       * Instantiates a new Hl 7 v 2 message id pages iterator.\n+       *\n+       * @param client the client\n+       * @param hl7v2Store the hl 7 v 2 store\n+       * @param filter the filter\n+       */\n+      HL7v2MessageIDPagesIterator(\n+          HealthcareApiClient client, String hl7v2Store, @Nullable String filter) {\n+        this.client = client;\n+        this.hl7v2Store = hl7v2Store;\n+        this.filter = filter;\n+        this.pageToken = null;\n+        this.isFirstRequest = true;\n+      }\n+\n+      @Override\n+      public boolean hasNext() throws NoSuchElementException {\n+        if (isFirstRequest) {\n+          try {\n+            ListMessagesResponse response = makeListRequest(client, hl7v2Store, filter, pageToken);\n+            List<String> msgs = response.getMessages();\n+            if (msgs == null) {\n+              if (response.get(\"hl7V2Messages\") != null) {\n+                return ((ArrayList<ArrayMap<String, String>>) response.get(\"hl7V2Messages\")).size()\n+                    > 0;\n+              }\n+              return false;\n+            } else {\n+              return !msgs.isEmpty();\n+            }\n+          } catch (IOException e) {\n+            throw new NoSuchElementException(\n+                String.format(\n+                    \"Failed to list first page of HL7v2 messages from %s: %s\",\n+                    hl7v2Store, e.getMessage()));\n+          }\n+        }\n+        return this.pageToken != null;\n+      }\n+\n+      @Override\n+      public List<String> next() throws NoSuchElementException {\n+        try {\n+          ListMessagesResponse response = makeListRequest(client, hl7v2Store, filter, pageToken);\n+          this.isFirstRequest = false;\n+          this.pageToken = response.getNextPageToken();\n+          List<String> msgs = response.getMessages();\n+          if (msgs == null && response.get(\"hl7V2Messages\") != null) {", "originalCommit": "cac03ec30c77e6bd45954e659b875d0378370892", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODU3Njc0Mg==", "url": "https://github.com/apache/beam/pull/11151#discussion_r398576742", "bodyText": "This abstract modeling of the Message would work just fine.", "author": "brianlucier", "createdAt": "2020-03-26T13:36:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODIxNTIwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODU3NjA5Nw==", "url": "https://github.com/apache/beam/pull/11151#discussion_r398576097", "bodyText": "Does the client handle quota-based retries on 429 responses?  Or is left to the caller to handle retries?", "author": "brianlucier", "createdAt": "2020-03-26T13:36:02Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HttpHealthcareApiClient.java", "diffHunk": "@@ -0,0 +1,452 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.healthcare;\n+\n+import com.google.api.client.http.HttpHeaders;\n+import com.google.api.client.http.HttpRequest;\n+import com.google.api.client.http.HttpRequestInitializer;\n+import com.google.api.client.http.javanet.NetHttpTransport;\n+import com.google.api.client.json.JsonFactory;\n+import com.google.api.client.json.gson.GsonFactory;\n+import com.google.api.client.util.ArrayMap;\n+import com.google.api.services.healthcare.v1alpha2.CloudHealthcare;\n+import com.google.api.services.healthcare.v1alpha2.CloudHealthcare.Projects.Locations.Datasets.Hl7V2Stores.Messages;\n+import com.google.api.services.healthcare.v1alpha2.CloudHealthcareScopes;\n+import com.google.api.services.healthcare.v1alpha2.model.CreateMessageRequest;\n+import com.google.api.services.healthcare.v1alpha2.model.Empty;\n+import com.google.api.services.healthcare.v1alpha2.model.Hl7V2Store;\n+import com.google.api.services.healthcare.v1alpha2.model.HttpBody;\n+import com.google.api.services.healthcare.v1alpha2.model.IngestMessageRequest;\n+import com.google.api.services.healthcare.v1alpha2.model.IngestMessageResponse;\n+import com.google.api.services.healthcare.v1alpha2.model.ListMessagesResponse;\n+import com.google.api.services.healthcare.v1alpha2.model.Message;\n+import com.google.api.services.healthcare.v1alpha2.model.SearchResourcesRequest;\n+import com.google.auth.oauth2.GoogleCredentials;\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.net.URI;\n+import java.text.ParseException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NoSuchElementException;\n+import java.util.Spliterator;\n+import java.util.Spliterators;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.extensions.gcp.util.RetryHttpRequestInitializer;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Strings;\n+\n+/**\n+ * A client that talks to the Cloud Healthcare API through HTTP requests. This client is created\n+ * mainly to encapsulate the unserializable dependencies, since most generated classes are not\n+ * serializable in the HTTP client.\n+ */\n+public class HttpHealthcareApiClient<T> implements HealthcareApiClient, Serializable {\n+\n+  private transient CloudHealthcare client;\n+\n+  /**\n+   * Instantiates a new Http healthcare api client.\n+   *\n+   * @throws IOException the io exception\n+   */\n+  public HttpHealthcareApiClient() throws IOException {\n+    initClient();\n+  }\n+\n+  /**\n+   * Instantiates a new Http healthcare api client.\n+   *\n+   * @param client the client\n+   * @throws IOException the io exception\n+   */\n+  public HttpHealthcareApiClient(CloudHealthcare client) throws IOException {\n+    this.client = client;\n+    initClient();\n+  }\n+\n+  @VisibleForTesting\n+  static <T, X extends Collection<T>> Stream<T> flattenIteratorCollectionsToStream(\n+      Iterator<X> iterator) {\n+    Spliterator<Collection<T>> spliterator = Spliterators.spliteratorUnknownSize(iterator, 0);\n+    return StreamSupport.stream(spliterator, false).flatMap(Collection::stream);\n+  }\n+\n+  public JsonFactory getJsonFactory() {\n+    return this.client.getJsonFactory();\n+  }\n+\n+  @Override\n+  public ListMessagesResponse makeHL7v2ListRequest(\n+      String hl7v2Store, @Nullable String filter, @Nullable String pageToken) throws IOException {\n+\n+    Messages.List baseRequest =\n+        client\n+            .projects()\n+            .locations()\n+            .datasets()\n+            .hl7V2Stores()\n+            .messages()\n+            .list(hl7v2Store)\n+            .setPageToken(pageToken);\n+\n+    if (Strings.isNullOrEmpty(filter)) {\n+      return baseRequest.execute();\n+    } else {\n+      return baseRequest.setFilter(filter).execute();\n+    }\n+  }\n+\n+  /**\n+   * Gets message id page iterator.\n+   *\n+   * @param hl7v2Store the HL7v2 store\n+   * @return the message id page iterator\n+   * @throws IOException the io exception\n+   */\n+  @Override\n+  public Stream<String> getHL7v2MessageIDStream(String hl7v2Store) throws IOException {\n+    return getHL7v2MessageIDStream(hl7v2Store, null);\n+  }\n+\n+  /**\n+   * Get a {@link Stream} of message IDs from flattening the pages of a new {@link\n+   * HL7v2MessageIDPages}.\n+   *\n+   * @param hl7v2Store the HL7v2 store\n+   * @param filter the filter\n+   * @return the message id Stream\n+   * @throws IOException the io exception\n+   */\n+  @Override\n+  public Stream<String> getHL7v2MessageIDStream(String hl7v2Store, @Nullable String filter)\n+      throws IOException {\n+    Iterator<List<String>> iterator = new HL7v2MessageIDPages(this, hl7v2Store, filter).iterator();\n+    return flattenIteratorCollectionsToStream(iterator);\n+  }\n+\n+  /**\n+   * Gets HL7v2 message.\n+   *\n+   * @param msgName the msg name\n+   * @return the message\n+   * @throws IOException the io exception\n+   * @throws ParseException the parse exception\n+   */\n+  @Override\n+  public Message getHL7v2Message(String msgName) throws IOException {\n+    Message msg =\n+        client.projects().locations().datasets().hl7V2Stores().messages().get(msgName).execute();\n+    if (msg == null) {\n+      throw new IOException(String.format(\"Couldn't find message: %s.\", msgName));\n+    }\n+    return msg;\n+  }\n+\n+  @Override\n+  public Empty deleteHL7v2Message(String msgName) throws IOException {\n+    return client\n+        .projects()\n+        .locations()\n+        .datasets()\n+        .hl7V2Stores()\n+        .messages()\n+        .delete(msgName)\n+        .execute();\n+  }\n+\n+  /**\n+   * Gets HL7v2 store.\n+   *\n+   * @param storeName the store name\n+   * @return the HL7v2 store\n+   * @throws IOException the io exception\n+   */\n+  @Override\n+  public Hl7V2Store getHL7v2Store(String storeName) throws IOException {\n+    return client.projects().locations().datasets().hl7V2Stores().get(storeName).execute();\n+  }\n+\n+  @Override\n+  public IngestMessageResponse ingestHL7v2Message(String hl7v2Store, Message msg)\n+      throws IOException {\n+    IngestMessageRequest ingestMessageRequest = new IngestMessageRequest();\n+    ingestMessageRequest.setMessage(msg);\n+    return client\n+        .projects()\n+        .locations()\n+        .datasets()\n+        .hl7V2Stores()\n+        .messages()\n+        .ingest(hl7v2Store, ingestMessageRequest)\n+        .execute();\n+  }", "originalCommit": "cac03ec30c77e6bd45954e659b875d0378370892", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg1ODUzMw==", "url": "https://github.com/apache/beam/pull/11151#discussion_r398858533", "bodyText": "yes here we extend RetryHttpRequestInitializer", "author": "jaketf", "createdAt": "2020-03-26T20:07:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODU3NjA5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODU4NjEwNg==", "url": "https://github.com/apache/beam/pull/11151#discussion_r398586106", "bodyText": "I like that the switch is here... looking fwd to it :)", "author": "brianlucier", "createdAt": "2020-03-26T13:49:36Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -0,0 +1,658 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.healthcare;\n+\n+import com.google.api.services.healthcare.v1alpha2.model.Message;\n+import com.google.auto.value.AutoValue;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.beam.sdk.Pipeline;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.gcp.datastore.AdaptiveThrottler;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubIO;\n+import org.apache.beam.sdk.metrics.Counter;\n+import org.apache.beam.sdk.metrics.Metrics;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionTuple;\n+import org.apache.beam.sdk.values.PInput;\n+import org.apache.beam.sdk.values.POutput;\n+import org.apache.beam.sdk.values.PValue;\n+import org.apache.beam.sdk.values.TupleTag;\n+import org.apache.beam.sdk.values.TupleTagList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Throwables;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * {@link HL7v2IO} provides an API for reading from and writing to <a\n+ * href=\"https://cloud.google.com/healthcare/docs/concepts/hl7v2\">Google Cloud Healthcare HL7v2 API.\n+ * </a>\n+ *\n+ * <p>Read\n+ *\n+ * <p>HL7v2 Messages are fetched from the HL7v2 store based on the {@link PCollection} of message\n+ * IDs {@link String}s as {@link HL7v2IO.Read.Result} where one can call {@link\n+ * Read.Result#getMessages()} to retrived a {@link PCollection} containing the successfully fetched\n+ * {@link HL7v2Message}s and/or {@link Read.Result#getFailedReads()} to retrieve a {@link\n+ * PCollection} of {@link HealthcareIOError} containing the msgID that could not be fetched and the\n+ * exception as a {@link HealthcareIOError<String>}, this can be used to write to the dead letter\n+ * storage system of your choosing.\n+ *\n+ * <p>Write\n+ *\n+ * <p>A bounded or unbounded {@link PCollection} of {@link HL7v2Message} can be ingested into an\n+ * HL7v2 store using {@link HL7v2IO#ingestMessages(String)}. This will return a {@link\n+ * HL7v2IO.Write.Result} on which you can call {@link Write.Result#getFailedInsertsWithErr()} to\n+ * retrieve a {@link PCollection} of {@link HealthcareIOError<HL7v2Message>} containing the Message\n+ * that failed to be ingested and the exception. This can be used to write to the dead letter\n+ * storage system of your chosing.\n+ *\n+ * <p>Unbounded Example:\n+ *\n+ * <pre>{@code\n+ * PipelineOptions options = ...;\n+ * Pipeline p = Pipeline.create(options);\n+ *\n+ * HL7v2IO.Read.Result readResult = p\n+ *   .apply(\n+ *     \"Read HL7v2 notifications\",\n+ *     PubSubIO.readStrings().fromTopic(options.getNotificationSubscription()))\n+ *   .apply(HL7v2IO.readAll());\n+ *\n+ * // Write errors to your favorite dead letter  queue (e.g. Pub/Sub, GCS, BigQuery)\n+ * readResult.getFailedReads().apply(\"WriteToDeadLetterQueue\", ...);\n+ *\n+ *\n+ * // Go about your happy path transformations.\n+ * PCollection<HL7v2Message> out = readResult.getMessages().apply(\"ProcessFetchedMessages\", ...);\n+ *\n+ * // Write using the Message.Ingest method of the HL7v2 REST API.\n+ * out.apply(HL7v2IO.ingestMessages(options.getOutputHL7v2Store()));\n+ *\n+ * pipeline.run();\n+ *\n+ * }***\n+ * </pre>\n+ *\n+ * <p>Bounded Example:\n+ *\n+ * <pre>{@code\n+ * PipelineOptions options = ...;\n+ * Pipeline p = Pipeline.create(options);\n+ *\n+ * HL7v2IO.Read.Result readResult = p\n+ *   .apply(\n+ *       \"List messages in HL7v2 store with filter\",\n+ *       ListHL7v2MessageIDs(\n+ *           Collections.singletonList(options.getInputHL7v2Store()), option.getHL7v2Filter()))\n+ *   .apply(HL7v2IO.readAll());\n+ *\n+ * // Write errors to your favorite dead letter  queue (e.g. Pub/Sub, GCS, BigQuery)\n+ * readResult.getFailedReads().apply(\"WriteToDeadLetterQueue\", ...);\n+ *\n+ *\n+ * // Go about your happy path transformations.\n+ * PCollection<HL7v2Message> out = readResult.getMessages().apply(\"ProcessFetchedMessages\", ...);\n+ *\n+ * // Write using the Message.Ingest method of the HL7v2 REST API.\n+ * out.apply(HL7v2IO.ingestMessages(options.getOutputHL7v2Store()));\n+ *\n+ * pipeline.run().waitUntilFinish();\n+ * }***\n+ * </pre>\n+ */\n+public class HL7v2IO {\n+\n+  private static Write.Builder write(String hl7v2Store) {\n+    return new AutoValue_HL7v2IO_Write.Builder().setHL7v2Store(hl7v2Store);\n+  }\n+\n+  public static Read readAll() {\n+    return new Read();\n+  }\n+\n+  /**\n+   * Write with Messages.Ingest method. @see <a\n+   * href=https://cloud.google.com/healthcare/docs/reference/rest/v1beta1/projects.locations.datasets.hl7V2Stores.messages/ingest></a>\n+   *\n+   * @param hl7v2Store the hl 7 v 2 store\n+   * @return the write\n+   */\n+  public static Write ingestMessages(String hl7v2Store) {\n+    return write(hl7v2Store).setWriteMethod(Write.WriteMethod.INGEST).build();\n+  }\n+\n+  // TODO add hyper links to this doc string.\n+  /**\n+   * The type Read that reads HL7v2 message contents given a PCollection of message IDs strings.\n+   *\n+   * <p>These could be sourced from any {@link PCollection} of {@link String}s but the most popular\n+   * patterns would be {@link PubsubIO#readStrings()} reading a subscription on an HL7v2 Store's\n+   * notification channel topic or using {@link ListHL7v2MessageIDs} to list HL7v2 message IDs with\n+   * an optional filter using Ingest write method. @see <a\n+   * href=https://cloud.google.com/healthcare/docs/reference/rest/v1beta1/projects.locations.datasets.hl7V2Stores.messages/list></a>.\n+   */\n+  public static class Read extends PTransform<PCollection<String>, Read.Result> {\n+\n+    public Read() {}\n+\n+    public static class Result implements POutput, PInput {\n+      private PCollection<HL7v2Message> messages;\n+\n+      private PCollection<HealthcareIOError<String>> failedReads;\n+      PCollectionTuple pct;\n+\n+      public static Result of(PCollectionTuple pct) throws IllegalArgumentException {\n+        if (pct.getAll()\n+            .keySet()\n+            .containsAll((Collection<?>) TupleTagList.of(OUT).and(DEAD_LETTER))) {\n+          return new Result(pct);\n+        } else {\n+          throw new IllegalArgumentException(\n+              \"The PCollection tuple must have the HL7v2IO.Read.OUT \"\n+                  + \"and HL7v2IO.Read.DEAD_LETTER tuple tags\");\n+        }\n+      }\n+\n+      private Result(PCollectionTuple pct) {\n+        this.pct = pct;\n+        this.messages = pct.get(OUT).setCoder(new HL7v2MessageCoder());\n+        this.failedReads =\n+            pct.get(DEAD_LETTER).setCoder(new HealthcareIOErrorCoder<>(StringUtf8Coder.of()));\n+      }\n+\n+      public PCollection<HealthcareIOError<String>> getFailedReads() {\n+        return failedReads;\n+      }\n+\n+      public PCollection<HL7v2Message> getMessages() {\n+        return messages;\n+      }\n+\n+      @Override\n+      public Pipeline getPipeline() {\n+        return this.pct.getPipeline();\n+      }\n+\n+      @Override\n+      public Map<TupleTag<?>, PValue> expand() {\n+        return ImmutableMap.of(OUT, messages);\n+      }\n+\n+      @Override\n+      public void finishSpecifyingOutput(\n+          String transformName, PInput input, PTransform<?, ?> transform) {}\n+    }\n+\n+    /** The tag for the main output of HL7v2 Messages. */\n+    public static final TupleTag<HL7v2Message> OUT = new TupleTag<HL7v2Message>() {};\n+    /** The tag for the deadletter output of HL7v2 Messages. */\n+    public static final TupleTag<HealthcareIOError<String>> DEAD_LETTER =\n+        new TupleTag<HealthcareIOError<String>>() {};\n+\n+    @Override\n+    public Result expand(PCollection<String> input) {\n+      return input.apply(\"Fetch HL7v2 messages\", new FetchHL7v2Message());\n+    }\n+\n+    /**\n+     * DoFn to fetch a message from an Google Cloud Healthcare HL7v2 store based on msgID\n+     *\n+     * <p>This DoFn consumes a {@link PCollection} of notifications {@link String}s from the HL7v2\n+     * store, and fetches the actual {@link HL7v2Message} object based on the id in the notification\n+     * and will output a {@link PCollectionTuple} which contains the output and dead-letter {@link\n+     * PCollection}.\n+     *\n+     * <p>The {@link PCollectionTuple} output will contain the following {@link PCollection}:\n+     *\n+     * <ul>\n+     *   <li>{@link HL7v2IO.Read#OUT} - Contains all {@link PCollection} records successfully read\n+     *       from the HL7v2 store.\n+     *   <li>{@link HL7v2IO.Read#DEAD_LETTER} - Contains all {@link PCollection} of {@link\n+     *       HealthcareIOError<String>} message IDs which failed to be fetched from the HL7v2 store,\n+     *       with error message and stacktrace.\n+     * </ul>\n+     *\n+     * <p>Example:\n+     *\n+     * <pre>{@code\n+     * PipelineOptions options = ...;\n+     * Pipeline pipeline = Pipeline.create(options)\n+     *\n+     * PCollection<String> msgIDs = pipeline.apply(\n+     *    \"ReadHL7v2Notifications\",\n+     *    PubsubIO.readStrings().fromSubscription(options.getInputSubscription()));\n+     *\n+     * PCollectionTuple fetchResults = msgIDs.apply(\n+     *    \"FetchHL7v2Messages\",\n+     *    new FetchHL7v2Message;\n+     *\n+     * // Write errors to your favorite dead letter  queue (e.g. Pub/Sub, GCS, BigQuery)\n+     * fetchResults.get(PubsubNotificationToHL7v2Message.DEAD_LETTER)\n+     *    .apply(\"WriteToDeadLetterQueue\", ...);\n+     *\n+     * PCollection<Message> fetchedMessages = fetchResults.get(PubsubNotificationToHL7v2Message.OUT)\n+     *    .apply(\"ExtractFetchedMessage\",\n+     *    MapElements\n+     *        .into(TypeDescriptor.of(Message.class))\n+     *        .via(FailsafeElement::getPayload));\n+     *\n+     * // Go about your happy path transformations.\n+     * fetchedMessages.apply(\"ProcessFetchedMessages\", ...)\n+     *\n+     * }****\n+     * </pre>\n+     */\n+    public static class FetchHL7v2Message extends PTransform<PCollection<String>, Result> {\n+\n+      /** Instantiates a new Fetch HL7v2 message DoFn. */\n+      public FetchHL7v2Message() {}\n+\n+      @Override\n+      public Result expand(PCollection<String> msgIds) {\n+        return new Result(\n+            msgIds.apply(\n+                ParDo.of(new FetchHL7v2Message.HL7v2MessageGetFn())\n+                    .withOutputTags(HL7v2IO.Read.OUT, TupleTagList.of(HL7v2IO.Read.DEAD_LETTER))));\n+      }\n+\n+      /** DoFn for fetching messages from the HL7v2 store with error handling. */\n+      public static class HL7v2MessageGetFn extends DoFn<String, HL7v2Message> {\n+\n+        private Counter failedMessageGets =\n+            Metrics.counter(FetchHL7v2Message.HL7v2MessageGetFn.class, \"failed-message-reads\");\n+        private static final Logger LOG =\n+            LoggerFactory.getLogger(FetchHL7v2Message.HL7v2MessageGetFn.class);\n+        private final Counter throttledSeconds =\n+            Metrics.counter(\n+                FetchHL7v2Message.HL7v2MessageGetFn.class, \"cumulative-throttling-seconds\");\n+        private final Counter successfulHL7v2MessageGets =\n+            Metrics.counter(\n+                FetchHL7v2Message.HL7v2MessageGetFn.class, \"successful-hl7v2-message-gets\");\n+        private HealthcareApiClient client;\n+        private transient AdaptiveThrottler throttler;\n+\n+        /** Instantiates a new Hl 7 v 2 message get fn. */\n+        HL7v2MessageGetFn() {}\n+\n+        /**\n+         * Instantiate healthcare client.\n+         *\n+         * @throws IOException the io exception\n+         */\n+        @Setup\n+        public void instantiateHealthcareClient() throws IOException {\n+          this.client = new HttpHealthcareApiClient();\n+        }\n+\n+        /** Start bundle. */\n+        @StartBundle\n+        public void startBundle() {\n+          if (throttler == null) {\n+            throttler = new AdaptiveThrottler(1200000, 10000, 1.25);\n+          }\n+        }\n+\n+        /**\n+         * Process element.\n+         *\n+         * @param context the context\n+         */\n+        @ProcessElement\n+        public void processElement(ProcessContext context) {\n+          String msgId = context.element();\n+          try {\n+            context.output(HL7v2Message.fromModel(fetchMessage(this.client, msgId)));\n+          } catch (Exception e) {\n+            failedMessageGets.inc();\n+            LOG.warn(\n+                String.format(\n+                    \"Error fetching HL7v2 message with ID %s writing to Dead Letter \"\n+                        + \"Queue. Cause: %s Stack Trace: %s\",\n+                    msgId, e.getMessage(), Throwables.getStackTraceAsString(e)));\n+            context.output(HL7v2IO.Read.DEAD_LETTER, HealthcareIOError.of(msgId, e));\n+          }\n+        }\n+\n+        private Message fetchMessage(HealthcareApiClient client, String msgId)\n+            throws IOException, ParseException, IllegalArgumentException, InterruptedException {\n+          final int throttleWaitSeconds = 5;\n+          long startTime = System.currentTimeMillis();\n+          Sleeper sleeper = Sleeper.DEFAULT;\n+          if (throttler.throttleRequest(startTime)) {\n+            LOG.info(String.format(\"Delaying request for %s due to previous failures.\", msgId));\n+            this.throttledSeconds.inc(throttleWaitSeconds);\n+            sleeper.sleep(throttleWaitSeconds * 1000);\n+          }\n+\n+          com.google.api.services.healthcare.v1alpha2.model.Message msg =\n+              client.getHL7v2Message(msgId);\n+\n+          this.throttler.successfulRequest(startTime);\n+          if (msg == null) {\n+            throw new IOException(String.format(\"GET request for %s returned null\", msgId));\n+          }\n+          this.successfulHL7v2MessageGets.inc();\n+          return msg;\n+        }\n+      }\n+    }\n+  }\n+\n+  /** The type List HL7v2 message IDs. */\n+  public static class ListHL7v2MessageIDs extends PTransform<PBegin, PCollection<String>> {\n+\n+    private final List<String> hl7v2Stores;\n+    private final String filter;\n+\n+    /**\n+     * Instantiates a new List HL7v2 message IDs with filter.\n+     *\n+     * @param hl7v2Stores the HL7v2 stores\n+     * @param filter the filter\n+     */\n+    ListHL7v2MessageIDs(List<String> hl7v2Stores, String filter) {\n+      this.hl7v2Stores = hl7v2Stores;\n+      this.filter = filter;\n+    }\n+\n+    /**\n+     * Instantiates a new List HL7v2 message IDs without filter.\n+     *\n+     * @param hl7v2Stores the HL7v2 stores\n+     */\n+    ListHL7v2MessageIDs(List<String> hl7v2Stores) {\n+      this.hl7v2Stores = hl7v2Stores;\n+      this.filter = null;\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      return input.apply(Create.of(this.hl7v2Stores)).apply(ParDo.of(new ListHL7v2Fn(this.filter)));\n+    }\n+  }\n+\n+  /** The type List HL7v2 fn. */\n+  static class ListHL7v2Fn extends DoFn<String, String> {\n+\n+    private final String filter;\n+    private transient HealthcareApiClient client;\n+\n+    /**\n+     * Instantiates a new List HL7v2 fn.\n+     *\n+     * @param filter the filter\n+     */\n+    ListHL7v2Fn(String filter) {\n+      this.filter = filter;\n+    }\n+\n+    /**\n+     * Init client.\n+     *\n+     * @throws IOException the io exception\n+     */\n+    @Setup\n+    public void initClient() throws IOException {\n+      this.client = new HttpHealthcareApiClient();\n+    }\n+\n+    /**\n+     * List messages.\n+     *\n+     * @param context the context\n+     * @throws IOException the io exception\n+     */\n+    @ProcessElement\n+    public void listMessages(ProcessContext context) throws IOException {\n+      String hl7v2Store = context.element();\n+      // Output all elements of all pages.\n+      this.client.getHL7v2MessageIDStream(hl7v2Store, this.filter).forEach(context::output);\n+    }\n+  }\n+\n+  /** The type Write. */\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<HL7v2Message>, Write.Result> {\n+\n+    /** The tag for the successful writes to HL7v2 store`. */\n+    public static final TupleTag<HealthcareIOError<HL7v2Message>> SUCCESS =\n+        new TupleTag<HealthcareIOError<HL7v2Message>>() {};\n+    /** The tag for the failed writes to HL7v2 store`. */\n+    public static final TupleTag<HealthcareIOError<HL7v2Message>> FAILED =\n+        new TupleTag<HealthcareIOError<HL7v2Message>>() {};\n+\n+    /**\n+     * Gets HL7v2 store.\n+     *\n+     * @return the HL7v2 store\n+     */\n+    abstract String getHL7v2Store();\n+\n+    /**\n+     * Gets write method.\n+     *\n+     * @return the write method\n+     */\n+    abstract WriteMethod getWriteMethod();\n+\n+    @Override\n+    public Result expand(PCollection<HL7v2Message> messages) {\n+      return messages.apply(new WriteHL7v2(this.getHL7v2Store(), this.getWriteMethod()));\n+    }\n+\n+    /** The enum Write method. */\n+    public enum WriteMethod {\n+      /**\n+       * Ingest write method. @see <a\n+       * href=https://cloud.google.com/healthcare/docs/reference/rest/v1beta1/projects.locations.datasets.hl7V2Stores.messages/ingest></a>\n+       */\n+      INGEST,\n+      /**\n+       * Batch import write method. This is not yet supported by the HL7v2 API, but can be used to\n+       * improve throughput once available.\n+       */\n+      BATCH_IMPORT\n+    }\n+\n+    /** The type Builder. */\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+\n+      /**\n+       * Sets HL7v2 store.\n+       *\n+       * @param hl7v2Store the HL7v2 store\n+       * @return the HL7v2 store\n+       */\n+      abstract Builder setHL7v2Store(String hl7v2Store);\n+\n+      /**\n+       * Sets write method.\n+       *\n+       * @param writeMethod the write method\n+       * @return the write method\n+       */\n+      abstract Builder setWriteMethod(WriteMethod writeMethod);\n+\n+      /**\n+       * Build write.\n+       *\n+       * @return the write\n+       */\n+      abstract Write build();\n+    }\n+\n+    public static class Result implements POutput {\n+      private final Pipeline pipeline;\n+      private final PCollection<HealthcareIOError<HL7v2Message>> failedInsertsWithErr;\n+\n+      /** Creates a {@link HL7v2IO.Write.Result} in the given {@link Pipeline}. */\n+      static Result in(\n+          Pipeline pipeline, PCollection<HealthcareIOError<HL7v2Message>> failedInserts) {\n+        return new Result(pipeline, failedInserts);\n+      }\n+\n+      public PCollection<HealthcareIOError<HL7v2Message>> getFailedInsertsWithErr() {\n+        return this.failedInsertsWithErr;\n+      }\n+\n+      @Override\n+      public Pipeline getPipeline() {\n+        return this.pipeline;\n+      }\n+\n+      @Override\n+      public Map<TupleTag<?>, PValue> expand() {\n+        failedInsertsWithErr.setCoder(new HealthcareIOErrorCoder<>(new HL7v2MessageCoder()));\n+        return ImmutableMap.of(FAILED, failedInsertsWithErr);\n+      }\n+\n+      @Override\n+      public void finishSpecifyingOutput(\n+          String transformName, PInput input, PTransform<?, ?> transform) {}\n+\n+      private Result(\n+          Pipeline pipeline, PCollection<HealthcareIOError<HL7v2Message>> failedInsertsWithErr) {\n+        this.pipeline = pipeline;\n+        this.failedInsertsWithErr = failedInsertsWithErr;\n+      }\n+    }\n+  }\n+\n+  /** The type Write hl 7 v 2. */\n+  static class WriteHL7v2 extends PTransform<PCollection<HL7v2Message>, Write.Result> {\n+    private final String hl7v2Store;\n+    private final Write.WriteMethod writeMethod;\n+\n+    /**\n+     * Instantiates a new Write hl 7 v 2.\n+     *\n+     * @param hl7v2Store the hl 7 v 2 store\n+     * @param writeMethod the write method\n+     */\n+    WriteHL7v2(String hl7v2Store, Write.WriteMethod writeMethod) {\n+      this.hl7v2Store = hl7v2Store;\n+      this.writeMethod = writeMethod;\n+    }\n+\n+    @Override\n+    public Write.Result expand(PCollection<HL7v2Message> input) {\n+      PCollection<HealthcareIOError<HL7v2Message>> failedInserts =\n+          input\n+              .apply(ParDo.of(new WriteHL7v2Fn(hl7v2Store, writeMethod)))\n+              .setCoder(new HealthcareIOErrorCoder<>(new HL7v2MessageCoder()));\n+      return Write.Result.in(input.getPipeline(), failedInserts);\n+    }\n+\n+    /** The type Write hl 7 v 2 fn. */\n+    static class WriteHL7v2Fn extends DoFn<HL7v2Message, HealthcareIOError<HL7v2Message>> {\n+      // TODO when the healthcare API releases a bulk import method this should use that to improve\n+      // throughput.\n+\n+      private Counter failedMessageWrites =\n+          Metrics.counter(WriteHL7v2Fn.class, \"failed-hl7v2-message-writes\");\n+      private final String hl7v2Store;\n+      private final Counter throttledSeconds =\n+          Metrics.counter(WriteHL7v2Fn.class, \"cumulative-throttling-seconds\");\n+      private final Counter successfulHL7v2MessageWrites =\n+          Metrics.counter(WriteHL7v2.class, \"successful-hl7v2-message-writes\");\n+      private transient AdaptiveThrottler throttler;\n+      private final Write.WriteMethod writeMethod;\n+\n+      private static final Logger LOG = LoggerFactory.getLogger(WriteHL7v2.WriteHL7v2Fn.class);\n+      private transient HealthcareApiClient client;\n+\n+      /**\n+       * Instantiates a new Write HL7v2 fn.\n+       *\n+       * @param hl7v2Store the HL7v2 store\n+       * @param writeMethod the write method\n+       */\n+      WriteHL7v2Fn(String hl7v2Store, Write.WriteMethod writeMethod) {\n+        this.hl7v2Store = hl7v2Store;\n+        this.writeMethod = writeMethod;\n+      }\n+\n+      /**\n+       * Init client.\n+       *\n+       * @throws IOException the io exception\n+       */\n+      @Setup\n+      public void initClient() throws IOException {\n+        this.client = new HttpHealthcareApiClient();\n+      }\n+\n+      @StartBundle\n+      public void startBundle() {\n+        if (throttler == null) {\n+          throttler = new AdaptiveThrottler(1200000, 10000, 1.25);\n+        }\n+      }\n+\n+      /**\n+       * Write messages.\n+       *\n+       * @param context the context\n+       */\n+      @ProcessElement\n+      public void writeMessages(ProcessContext context) {\n+        HL7v2Message msg = context.element();\n+        final int throttleWaitSeconds = 5;\n+        long startTime = System.currentTimeMillis();\n+        Sleeper sleeper = Sleeper.DEFAULT;\n+        switch (writeMethod) {\n+          case BATCH_IMPORT:\n+            throw new UnsupportedOperationException(\"The Batch import API is not available yet\");", "originalCommit": "cac03ec30c77e6bd45954e659b875d0378370892", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODU4ODE4NQ==", "url": "https://github.com/apache/beam/pull/11151#discussion_r398588185", "bodyText": "I believe the reason for failure may be relevant.  a 429 would want a certain number of retries, where a 401 or 403 may need to refresh the credentials, where another error is likely a hard stop.", "author": "brianlucier", "createdAt": "2020-03-26T13:52:05Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -0,0 +1,658 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.healthcare;\n+\n+import com.google.api.services.healthcare.v1alpha2.model.Message;\n+import com.google.auto.value.AutoValue;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.beam.sdk.Pipeline;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.gcp.datastore.AdaptiveThrottler;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubIO;\n+import org.apache.beam.sdk.metrics.Counter;\n+import org.apache.beam.sdk.metrics.Metrics;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionTuple;\n+import org.apache.beam.sdk.values.PInput;\n+import org.apache.beam.sdk.values.POutput;\n+import org.apache.beam.sdk.values.PValue;\n+import org.apache.beam.sdk.values.TupleTag;\n+import org.apache.beam.sdk.values.TupleTagList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Throwables;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * {@link HL7v2IO} provides an API for reading from and writing to <a\n+ * href=\"https://cloud.google.com/healthcare/docs/concepts/hl7v2\">Google Cloud Healthcare HL7v2 API.\n+ * </a>\n+ *\n+ * <p>Read\n+ *\n+ * <p>HL7v2 Messages are fetched from the HL7v2 store based on the {@link PCollection} of message\n+ * IDs {@link String}s as {@link HL7v2IO.Read.Result} where one can call {@link\n+ * Read.Result#getMessages()} to retrived a {@link PCollection} containing the successfully fetched\n+ * {@link HL7v2Message}s and/or {@link Read.Result#getFailedReads()} to retrieve a {@link\n+ * PCollection} of {@link HealthcareIOError} containing the msgID that could not be fetched and the\n+ * exception as a {@link HealthcareIOError<String>}, this can be used to write to the dead letter\n+ * storage system of your choosing.\n+ *\n+ * <p>Write\n+ *\n+ * <p>A bounded or unbounded {@link PCollection} of {@link HL7v2Message} can be ingested into an\n+ * HL7v2 store using {@link HL7v2IO#ingestMessages(String)}. This will return a {@link\n+ * HL7v2IO.Write.Result} on which you can call {@link Write.Result#getFailedInsertsWithErr()} to\n+ * retrieve a {@link PCollection} of {@link HealthcareIOError<HL7v2Message>} containing the Message\n+ * that failed to be ingested and the exception. This can be used to write to the dead letter\n+ * storage system of your chosing.\n+ *\n+ * <p>Unbounded Example:\n+ *\n+ * <pre>{@code\n+ * PipelineOptions options = ...;\n+ * Pipeline p = Pipeline.create(options);\n+ *\n+ * HL7v2IO.Read.Result readResult = p\n+ *   .apply(\n+ *     \"Read HL7v2 notifications\",\n+ *     PubSubIO.readStrings().fromTopic(options.getNotificationSubscription()))\n+ *   .apply(HL7v2IO.readAll());\n+ *\n+ * // Write errors to your favorite dead letter  queue (e.g. Pub/Sub, GCS, BigQuery)\n+ * readResult.getFailedReads().apply(\"WriteToDeadLetterQueue\", ...);\n+ *\n+ *\n+ * // Go about your happy path transformations.\n+ * PCollection<HL7v2Message> out = readResult.getMessages().apply(\"ProcessFetchedMessages\", ...);\n+ *\n+ * // Write using the Message.Ingest method of the HL7v2 REST API.\n+ * out.apply(HL7v2IO.ingestMessages(options.getOutputHL7v2Store()));\n+ *\n+ * pipeline.run();\n+ *\n+ * }***\n+ * </pre>\n+ *\n+ * <p>Bounded Example:\n+ *\n+ * <pre>{@code\n+ * PipelineOptions options = ...;\n+ * Pipeline p = Pipeline.create(options);\n+ *\n+ * HL7v2IO.Read.Result readResult = p\n+ *   .apply(\n+ *       \"List messages in HL7v2 store with filter\",\n+ *       ListHL7v2MessageIDs(\n+ *           Collections.singletonList(options.getInputHL7v2Store()), option.getHL7v2Filter()))\n+ *   .apply(HL7v2IO.readAll());\n+ *\n+ * // Write errors to your favorite dead letter  queue (e.g. Pub/Sub, GCS, BigQuery)\n+ * readResult.getFailedReads().apply(\"WriteToDeadLetterQueue\", ...);\n+ *\n+ *\n+ * // Go about your happy path transformations.\n+ * PCollection<HL7v2Message> out = readResult.getMessages().apply(\"ProcessFetchedMessages\", ...);\n+ *\n+ * // Write using the Message.Ingest method of the HL7v2 REST API.\n+ * out.apply(HL7v2IO.ingestMessages(options.getOutputHL7v2Store()));\n+ *\n+ * pipeline.run().waitUntilFinish();\n+ * }***\n+ * </pre>\n+ */\n+public class HL7v2IO {\n+\n+  private static Write.Builder write(String hl7v2Store) {\n+    return new AutoValue_HL7v2IO_Write.Builder().setHL7v2Store(hl7v2Store);\n+  }\n+\n+  public static Read readAll() {\n+    return new Read();\n+  }\n+\n+  /**\n+   * Write with Messages.Ingest method. @see <a\n+   * href=https://cloud.google.com/healthcare/docs/reference/rest/v1beta1/projects.locations.datasets.hl7V2Stores.messages/ingest></a>\n+   *\n+   * @param hl7v2Store the hl 7 v 2 store\n+   * @return the write\n+   */\n+  public static Write ingestMessages(String hl7v2Store) {\n+    return write(hl7v2Store).setWriteMethod(Write.WriteMethod.INGEST).build();\n+  }\n+\n+  // TODO add hyper links to this doc string.\n+  /**\n+   * The type Read that reads HL7v2 message contents given a PCollection of message IDs strings.\n+   *\n+   * <p>These could be sourced from any {@link PCollection} of {@link String}s but the most popular\n+   * patterns would be {@link PubsubIO#readStrings()} reading a subscription on an HL7v2 Store's\n+   * notification channel topic or using {@link ListHL7v2MessageIDs} to list HL7v2 message IDs with\n+   * an optional filter using Ingest write method. @see <a\n+   * href=https://cloud.google.com/healthcare/docs/reference/rest/v1beta1/projects.locations.datasets.hl7V2Stores.messages/list></a>.\n+   */\n+  public static class Read extends PTransform<PCollection<String>, Read.Result> {\n+\n+    public Read() {}\n+\n+    public static class Result implements POutput, PInput {\n+      private PCollection<HL7v2Message> messages;\n+\n+      private PCollection<HealthcareIOError<String>> failedReads;\n+      PCollectionTuple pct;\n+\n+      public static Result of(PCollectionTuple pct) throws IllegalArgumentException {\n+        if (pct.getAll()\n+            .keySet()\n+            .containsAll((Collection<?>) TupleTagList.of(OUT).and(DEAD_LETTER))) {\n+          return new Result(pct);\n+        } else {\n+          throw new IllegalArgumentException(\n+              \"The PCollection tuple must have the HL7v2IO.Read.OUT \"\n+                  + \"and HL7v2IO.Read.DEAD_LETTER tuple tags\");\n+        }\n+      }\n+\n+      private Result(PCollectionTuple pct) {\n+        this.pct = pct;\n+        this.messages = pct.get(OUT).setCoder(new HL7v2MessageCoder());\n+        this.failedReads =\n+            pct.get(DEAD_LETTER).setCoder(new HealthcareIOErrorCoder<>(StringUtf8Coder.of()));\n+      }\n+\n+      public PCollection<HealthcareIOError<String>> getFailedReads() {\n+        return failedReads;\n+      }\n+\n+      public PCollection<HL7v2Message> getMessages() {\n+        return messages;\n+      }\n+\n+      @Override\n+      public Pipeline getPipeline() {\n+        return this.pct.getPipeline();\n+      }\n+\n+      @Override\n+      public Map<TupleTag<?>, PValue> expand() {\n+        return ImmutableMap.of(OUT, messages);\n+      }\n+\n+      @Override\n+      public void finishSpecifyingOutput(\n+          String transformName, PInput input, PTransform<?, ?> transform) {}\n+    }\n+\n+    /** The tag for the main output of HL7v2 Messages. */\n+    public static final TupleTag<HL7v2Message> OUT = new TupleTag<HL7v2Message>() {};\n+    /** The tag for the deadletter output of HL7v2 Messages. */\n+    public static final TupleTag<HealthcareIOError<String>> DEAD_LETTER =\n+        new TupleTag<HealthcareIOError<String>>() {};\n+\n+    @Override\n+    public Result expand(PCollection<String> input) {\n+      return input.apply(\"Fetch HL7v2 messages\", new FetchHL7v2Message());\n+    }\n+\n+    /**\n+     * DoFn to fetch a message from an Google Cloud Healthcare HL7v2 store based on msgID\n+     *\n+     * <p>This DoFn consumes a {@link PCollection} of notifications {@link String}s from the HL7v2\n+     * store, and fetches the actual {@link HL7v2Message} object based on the id in the notification\n+     * and will output a {@link PCollectionTuple} which contains the output and dead-letter {@link\n+     * PCollection}.\n+     *\n+     * <p>The {@link PCollectionTuple} output will contain the following {@link PCollection}:\n+     *\n+     * <ul>\n+     *   <li>{@link HL7v2IO.Read#OUT} - Contains all {@link PCollection} records successfully read\n+     *       from the HL7v2 store.\n+     *   <li>{@link HL7v2IO.Read#DEAD_LETTER} - Contains all {@link PCollection} of {@link\n+     *       HealthcareIOError<String>} message IDs which failed to be fetched from the HL7v2 store,\n+     *       with error message and stacktrace.\n+     * </ul>\n+     *\n+     * <p>Example:\n+     *\n+     * <pre>{@code\n+     * PipelineOptions options = ...;\n+     * Pipeline pipeline = Pipeline.create(options)\n+     *\n+     * PCollection<String> msgIDs = pipeline.apply(\n+     *    \"ReadHL7v2Notifications\",\n+     *    PubsubIO.readStrings().fromSubscription(options.getInputSubscription()));\n+     *\n+     * PCollectionTuple fetchResults = msgIDs.apply(\n+     *    \"FetchHL7v2Messages\",\n+     *    new FetchHL7v2Message;\n+     *\n+     * // Write errors to your favorite dead letter  queue (e.g. Pub/Sub, GCS, BigQuery)\n+     * fetchResults.get(PubsubNotificationToHL7v2Message.DEAD_LETTER)\n+     *    .apply(\"WriteToDeadLetterQueue\", ...);\n+     *\n+     * PCollection<Message> fetchedMessages = fetchResults.get(PubsubNotificationToHL7v2Message.OUT)\n+     *    .apply(\"ExtractFetchedMessage\",\n+     *    MapElements\n+     *        .into(TypeDescriptor.of(Message.class))\n+     *        .via(FailsafeElement::getPayload));\n+     *\n+     * // Go about your happy path transformations.\n+     * fetchedMessages.apply(\"ProcessFetchedMessages\", ...)\n+     *\n+     * }****\n+     * </pre>\n+     */\n+    public static class FetchHL7v2Message extends PTransform<PCollection<String>, Result> {\n+\n+      /** Instantiates a new Fetch HL7v2 message DoFn. */\n+      public FetchHL7v2Message() {}\n+\n+      @Override\n+      public Result expand(PCollection<String> msgIds) {\n+        return new Result(\n+            msgIds.apply(\n+                ParDo.of(new FetchHL7v2Message.HL7v2MessageGetFn())\n+                    .withOutputTags(HL7v2IO.Read.OUT, TupleTagList.of(HL7v2IO.Read.DEAD_LETTER))));\n+      }\n+\n+      /** DoFn for fetching messages from the HL7v2 store with error handling. */\n+      public static class HL7v2MessageGetFn extends DoFn<String, HL7v2Message> {\n+\n+        private Counter failedMessageGets =\n+            Metrics.counter(FetchHL7v2Message.HL7v2MessageGetFn.class, \"failed-message-reads\");\n+        private static final Logger LOG =\n+            LoggerFactory.getLogger(FetchHL7v2Message.HL7v2MessageGetFn.class);\n+        private final Counter throttledSeconds =\n+            Metrics.counter(\n+                FetchHL7v2Message.HL7v2MessageGetFn.class, \"cumulative-throttling-seconds\");\n+        private final Counter successfulHL7v2MessageGets =\n+            Metrics.counter(\n+                FetchHL7v2Message.HL7v2MessageGetFn.class, \"successful-hl7v2-message-gets\");\n+        private HealthcareApiClient client;\n+        private transient AdaptiveThrottler throttler;\n+\n+        /** Instantiates a new Hl 7 v 2 message get fn. */\n+        HL7v2MessageGetFn() {}\n+\n+        /**\n+         * Instantiate healthcare client.\n+         *\n+         * @throws IOException the io exception\n+         */\n+        @Setup\n+        public void instantiateHealthcareClient() throws IOException {\n+          this.client = new HttpHealthcareApiClient();\n+        }\n+\n+        /** Start bundle. */\n+        @StartBundle\n+        public void startBundle() {\n+          if (throttler == null) {\n+            throttler = new AdaptiveThrottler(1200000, 10000, 1.25);\n+          }\n+        }\n+\n+        /**\n+         * Process element.\n+         *\n+         * @param context the context\n+         */\n+        @ProcessElement\n+        public void processElement(ProcessContext context) {\n+          String msgId = context.element();\n+          try {\n+            context.output(HL7v2Message.fromModel(fetchMessage(this.client, msgId)));\n+          } catch (Exception e) {\n+            failedMessageGets.inc();\n+            LOG.warn(\n+                String.format(\n+                    \"Error fetching HL7v2 message with ID %s writing to Dead Letter \"\n+                        + \"Queue. Cause: %s Stack Trace: %s\",\n+                    msgId, e.getMessage(), Throwables.getStackTraceAsString(e)));\n+            context.output(HL7v2IO.Read.DEAD_LETTER, HealthcareIOError.of(msgId, e));\n+          }\n+        }\n+\n+        private Message fetchMessage(HealthcareApiClient client, String msgId)\n+            throws IOException, ParseException, IllegalArgumentException, InterruptedException {\n+          final int throttleWaitSeconds = 5;\n+          long startTime = System.currentTimeMillis();\n+          Sleeper sleeper = Sleeper.DEFAULT;\n+          if (throttler.throttleRequest(startTime)) {\n+            LOG.info(String.format(\"Delaying request for %s due to previous failures.\", msgId));\n+            this.throttledSeconds.inc(throttleWaitSeconds);\n+            sleeper.sleep(throttleWaitSeconds * 1000);\n+          }\n+\n+          com.google.api.services.healthcare.v1alpha2.model.Message msg =\n+              client.getHL7v2Message(msgId);\n+\n+          this.throttler.successfulRequest(startTime);\n+          if (msg == null) {\n+            throw new IOException(String.format(\"GET request for %s returned null\", msgId));\n+          }\n+          this.successfulHL7v2MessageGets.inc();\n+          return msg;\n+        }\n+      }\n+    }\n+  }\n+\n+  /** The type List HL7v2 message IDs. */\n+  public static class ListHL7v2MessageIDs extends PTransform<PBegin, PCollection<String>> {\n+\n+    private final List<String> hl7v2Stores;\n+    private final String filter;\n+\n+    /**\n+     * Instantiates a new List HL7v2 message IDs with filter.\n+     *\n+     * @param hl7v2Stores the HL7v2 stores\n+     * @param filter the filter\n+     */\n+    ListHL7v2MessageIDs(List<String> hl7v2Stores, String filter) {\n+      this.hl7v2Stores = hl7v2Stores;\n+      this.filter = filter;\n+    }\n+\n+    /**\n+     * Instantiates a new List HL7v2 message IDs without filter.\n+     *\n+     * @param hl7v2Stores the HL7v2 stores\n+     */\n+    ListHL7v2MessageIDs(List<String> hl7v2Stores) {\n+      this.hl7v2Stores = hl7v2Stores;\n+      this.filter = null;\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      return input.apply(Create.of(this.hl7v2Stores)).apply(ParDo.of(new ListHL7v2Fn(this.filter)));\n+    }\n+  }\n+\n+  /** The type List HL7v2 fn. */\n+  static class ListHL7v2Fn extends DoFn<String, String> {\n+\n+    private final String filter;\n+    private transient HealthcareApiClient client;\n+\n+    /**\n+     * Instantiates a new List HL7v2 fn.\n+     *\n+     * @param filter the filter\n+     */\n+    ListHL7v2Fn(String filter) {\n+      this.filter = filter;\n+    }\n+\n+    /**\n+     * Init client.\n+     *\n+     * @throws IOException the io exception\n+     */\n+    @Setup\n+    public void initClient() throws IOException {\n+      this.client = new HttpHealthcareApiClient();\n+    }\n+\n+    /**\n+     * List messages.\n+     *\n+     * @param context the context\n+     * @throws IOException the io exception\n+     */\n+    @ProcessElement\n+    public void listMessages(ProcessContext context) throws IOException {\n+      String hl7v2Store = context.element();\n+      // Output all elements of all pages.\n+      this.client.getHL7v2MessageIDStream(hl7v2Store, this.filter).forEach(context::output);\n+    }\n+  }\n+\n+  /** The type Write. */\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<HL7v2Message>, Write.Result> {\n+\n+    /** The tag for the successful writes to HL7v2 store`. */\n+    public static final TupleTag<HealthcareIOError<HL7v2Message>> SUCCESS =\n+        new TupleTag<HealthcareIOError<HL7v2Message>>() {};\n+    /** The tag for the failed writes to HL7v2 store`. */\n+    public static final TupleTag<HealthcareIOError<HL7v2Message>> FAILED =\n+        new TupleTag<HealthcareIOError<HL7v2Message>>() {};\n+\n+    /**\n+     * Gets HL7v2 store.\n+     *\n+     * @return the HL7v2 store\n+     */\n+    abstract String getHL7v2Store();\n+\n+    /**\n+     * Gets write method.\n+     *\n+     * @return the write method\n+     */\n+    abstract WriteMethod getWriteMethod();\n+\n+    @Override\n+    public Result expand(PCollection<HL7v2Message> messages) {\n+      return messages.apply(new WriteHL7v2(this.getHL7v2Store(), this.getWriteMethod()));\n+    }\n+\n+    /** The enum Write method. */\n+    public enum WriteMethod {\n+      /**\n+       * Ingest write method. @see <a\n+       * href=https://cloud.google.com/healthcare/docs/reference/rest/v1beta1/projects.locations.datasets.hl7V2Stores.messages/ingest></a>\n+       */\n+      INGEST,\n+      /**\n+       * Batch import write method. This is not yet supported by the HL7v2 API, but can be used to\n+       * improve throughput once available.\n+       */\n+      BATCH_IMPORT\n+    }\n+\n+    /** The type Builder. */\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+\n+      /**\n+       * Sets HL7v2 store.\n+       *\n+       * @param hl7v2Store the HL7v2 store\n+       * @return the HL7v2 store\n+       */\n+      abstract Builder setHL7v2Store(String hl7v2Store);\n+\n+      /**\n+       * Sets write method.\n+       *\n+       * @param writeMethod the write method\n+       * @return the write method\n+       */\n+      abstract Builder setWriteMethod(WriteMethod writeMethod);\n+\n+      /**\n+       * Build write.\n+       *\n+       * @return the write\n+       */\n+      abstract Write build();\n+    }\n+\n+    public static class Result implements POutput {\n+      private final Pipeline pipeline;\n+      private final PCollection<HealthcareIOError<HL7v2Message>> failedInsertsWithErr;\n+\n+      /** Creates a {@link HL7v2IO.Write.Result} in the given {@link Pipeline}. */\n+      static Result in(\n+          Pipeline pipeline, PCollection<HealthcareIOError<HL7v2Message>> failedInserts) {\n+        return new Result(pipeline, failedInserts);\n+      }\n+\n+      public PCollection<HealthcareIOError<HL7v2Message>> getFailedInsertsWithErr() {\n+        return this.failedInsertsWithErr;\n+      }\n+\n+      @Override\n+      public Pipeline getPipeline() {\n+        return this.pipeline;\n+      }\n+\n+      @Override\n+      public Map<TupleTag<?>, PValue> expand() {\n+        failedInsertsWithErr.setCoder(new HealthcareIOErrorCoder<>(new HL7v2MessageCoder()));\n+        return ImmutableMap.of(FAILED, failedInsertsWithErr);\n+      }\n+\n+      @Override\n+      public void finishSpecifyingOutput(\n+          String transformName, PInput input, PTransform<?, ?> transform) {}\n+\n+      private Result(\n+          Pipeline pipeline, PCollection<HealthcareIOError<HL7v2Message>> failedInsertsWithErr) {\n+        this.pipeline = pipeline;\n+        this.failedInsertsWithErr = failedInsertsWithErr;\n+      }\n+    }\n+  }\n+\n+  /** The type Write hl 7 v 2. */\n+  static class WriteHL7v2 extends PTransform<PCollection<HL7v2Message>, Write.Result> {\n+    private final String hl7v2Store;\n+    private final Write.WriteMethod writeMethod;\n+\n+    /**\n+     * Instantiates a new Write hl 7 v 2.\n+     *\n+     * @param hl7v2Store the hl 7 v 2 store\n+     * @param writeMethod the write method\n+     */\n+    WriteHL7v2(String hl7v2Store, Write.WriteMethod writeMethod) {\n+      this.hl7v2Store = hl7v2Store;\n+      this.writeMethod = writeMethod;\n+    }\n+\n+    @Override\n+    public Write.Result expand(PCollection<HL7v2Message> input) {\n+      PCollection<HealthcareIOError<HL7v2Message>> failedInserts =\n+          input\n+              .apply(ParDo.of(new WriteHL7v2Fn(hl7v2Store, writeMethod)))\n+              .setCoder(new HealthcareIOErrorCoder<>(new HL7v2MessageCoder()));\n+      return Write.Result.in(input.getPipeline(), failedInserts);\n+    }\n+\n+    /** The type Write hl 7 v 2 fn. */\n+    static class WriteHL7v2Fn extends DoFn<HL7v2Message, HealthcareIOError<HL7v2Message>> {\n+      // TODO when the healthcare API releases a bulk import method this should use that to improve\n+      // throughput.\n+\n+      private Counter failedMessageWrites =\n+          Metrics.counter(WriteHL7v2Fn.class, \"failed-hl7v2-message-writes\");\n+      private final String hl7v2Store;\n+      private final Counter throttledSeconds =\n+          Metrics.counter(WriteHL7v2Fn.class, \"cumulative-throttling-seconds\");\n+      private final Counter successfulHL7v2MessageWrites =\n+          Metrics.counter(WriteHL7v2.class, \"successful-hl7v2-message-writes\");\n+      private transient AdaptiveThrottler throttler;\n+      private final Write.WriteMethod writeMethod;\n+\n+      private static final Logger LOG = LoggerFactory.getLogger(WriteHL7v2.WriteHL7v2Fn.class);\n+      private transient HealthcareApiClient client;\n+\n+      /**\n+       * Instantiates a new Write HL7v2 fn.\n+       *\n+       * @param hl7v2Store the HL7v2 store\n+       * @param writeMethod the write method\n+       */\n+      WriteHL7v2Fn(String hl7v2Store, Write.WriteMethod writeMethod) {\n+        this.hl7v2Store = hl7v2Store;\n+        this.writeMethod = writeMethod;\n+      }\n+\n+      /**\n+       * Init client.\n+       *\n+       * @throws IOException the io exception\n+       */\n+      @Setup\n+      public void initClient() throws IOException {\n+        this.client = new HttpHealthcareApiClient();\n+      }\n+\n+      @StartBundle\n+      public void startBundle() {\n+        if (throttler == null) {\n+          throttler = new AdaptiveThrottler(1200000, 10000, 1.25);\n+        }\n+      }\n+\n+      /**\n+       * Write messages.\n+       *\n+       * @param context the context\n+       */\n+      @ProcessElement\n+      public void writeMessages(ProcessContext context) {\n+        HL7v2Message msg = context.element();\n+        final int throttleWaitSeconds = 5;\n+        long startTime = System.currentTimeMillis();\n+        Sleeper sleeper = Sleeper.DEFAULT;\n+        switch (writeMethod) {\n+          case BATCH_IMPORT:\n+            throw new UnsupportedOperationException(\"The Batch import API is not available yet\");\n+          case INGEST:\n+          default:\n+            try {\n+              if (throttler.throttleRequest(startTime)) {\n+                LOG.info(\"Delaying request due to previous failures.\");\n+                this.throttledSeconds.inc(throttleWaitSeconds);\n+                sleeper.sleep(throttleWaitSeconds * 1000);\n+                this.throttler.successfulRequest(startTime);\n+                this.successfulHL7v2MessageWrites.inc();\n+              }\n+              client.ingestHL7v2Message(hl7v2Store, msg.toModel());\n+            } catch (Exception e) {\n+              failedMessageWrites.inc();", "originalCommit": "cac03ec30c77e6bd45954e659b875d0378370892", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg1NjYwNg==", "url": "https://github.com/apache/beam/pull/11151#discussion_r398856606", "bodyText": "all retryable errors will be retried by the request initializer in the http client.\nI think adding the throttling was a premature optimization on my part. We should remove adaptive throttling entirely and test this at load and see if throttling is necessary.", "author": "jaketf", "createdAt": "2020-03-26T20:03:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODU4ODE4NQ=="}], "type": "inlineReview"}, {"oid": "ba9d0239dea565b76e07546596d4e52ccf69bd4d", "url": "https://github.com/apache/beam/commit/ba9d0239dea565b76e07546596d4e52ccf69bd4d", "message": "refactor list fn to avoid double get, improve tests, extract json from schematized data", "committedDate": "2020-03-26T22:59:55Z", "type": "commit"}, {"oid": "d10ec356d417dedf295da1db347642e77f3c924c", "url": "https://github.com/apache/beam/commit/d10ec356d417dedf295da1db347642e77f3c924c", "message": "add IT for new ListHL7v2Messages PTransform", "committedDate": "2020-03-26T23:20:15Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk0OTUwNQ==", "url": "https://github.com/apache/beam/pull/11151#discussion_r398949505", "bodyText": "@brianlucier PTAL at this updated doc string.\nit describes my latest change in ba9d023 to avoid the double get whenever we reading a whole HL7v2Store with Messages.List API by adding the view=FULL param.", "author": "jaketf", "createdAt": "2020-03-26T23:22:35Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -0,0 +1,636 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.healthcare;\n+\n+import com.google.api.services.healthcare.v1alpha2.model.Message;\n+import com.google.auto.value.AutoValue;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.beam.sdk.Pipeline;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.gcp.datastore.AdaptiveThrottler;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubIO;\n+import org.apache.beam.sdk.metrics.Counter;\n+import org.apache.beam.sdk.metrics.Metrics;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionTuple;\n+import org.apache.beam.sdk.values.PInput;\n+import org.apache.beam.sdk.values.POutput;\n+import org.apache.beam.sdk.values.PValue;\n+import org.apache.beam.sdk.values.TupleTag;\n+import org.apache.beam.sdk.values.TupleTagList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Throwables;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * {@link HL7v2IO} provides an API for reading from and writing to <a\n+ * href=\"https://cloud.google.com/healthcare/docs/concepts/hl7v2\">Google Cloud Healthcare HL7v2 API.\n+ * </a>\n+ *\n+ * <p>Read", "originalCommit": "ba9d0239dea565b76e07546596d4e52ccf69bd4d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM1ODI4Mw==", "url": "https://github.com/apache/beam/pull/11151#discussion_r404358283", "bodyText": "How would one build a transform that reads the whole HL8v2Store (as opposed to individual message IDs)?", "author": "pabloem", "createdAt": "2020-04-06T20:11:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk0OTUwNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM3MjUyOQ==", "url": "https://github.com/apache/beam/pull/11151#discussion_r404372529", "bodyText": "@pabloem please see descripion and example added to this javadoc string.", "author": "jaketf", "createdAt": "2020-04-06T20:37:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk0OTUwNQ=="}], "type": "inlineReview"}, {"oid": "7acdef79f8e06a5b6cb0a977536450bbbb9bcb07", "url": "https://github.com/apache/beam/commit/7acdef79f8e06a5b6cb0a977536450bbbb9bcb07", "message": "migration to latest beta client library", "committedDate": "2020-03-27T00:32:37Z", "type": "commit"}, {"oid": "f26e11739709569da4ed77c60e6b897f4f309530", "url": "https://github.com/apache/beam/commit/f26e11739709569da4ed77c60e6b897f4f309530", "message": "beta api migration", "committedDate": "2020-03-27T00:41:27Z", "type": "commit"}, {"oid": "fb4163efe2ee1614ea9146feb4a7f8ba17e3dd08", "url": "https://github.com/apache/beam/commit/fb4163efe2ee1614ea9146feb4a7f8ba17e3dd08", "message": "add RunWith", "committedDate": "2020-03-27T23:30:19Z", "type": "commit"}, {"oid": "4287aa1dc435d2e0ec17f44110f651bc713bed24", "url": "https://github.com/apache/beam/commit/4287aa1dc435d2e0ec17f44110f651bc713bed24", "message": "remove adaptive throttling", "committedDate": "2020-04-01T18:14:24Z", "type": "commit"}, {"oid": "04d0471f4c6d1d1e1d6814939519dd2c36ae296f", "url": "https://github.com/apache/beam/commit/04d0471f4c6d1d1e1d6814939519dd2c36ae296f", "message": "revert AdaptiveThrottler to package private", "committedDate": "2020-04-01T18:17:25Z", "type": "commit"}, {"oid": "a87764fd37f78dcef01b31fb30e835df0db3b9a2", "url": "https://github.com/apache/beam/commit/a87764fd37f78dcef01b31fb30e835df0db3b9a2", "message": "fix javadoc", "committedDate": "2020-04-01T18:39:25Z", "type": "commit"}, {"oid": "6a627855cd1618413f7e15ddf4699f48f8f2faa6", "url": "https://github.com/apache/beam/commit/6a627855cd1618413f7e15ddf4699f48f8f2faa6", "message": "add HealthcareIOErrorToTableRow convenience transform", "committedDate": "2020-04-03T21:19:37Z", "type": "commit"}, {"oid": "54b90b9920d1a403ad8a1be756e451d4d64f5998", "url": "https://github.com/apache/beam/commit/54b90b9920d1a403ad8a1be756e451d4d64f5998", "message": "spotless", "committedDate": "2020-04-03T21:22:35Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTgyNjUyNw==", "url": "https://github.com/apache/beam/pull/11151#discussion_r401826527", "bodyText": "Does this test actually write to that HL7vStore? If so, can multiple tests run at the same time? - it's not necessary, but I'd like to clarify.\nWe may also be able to provision something on the apache-beam-testing GCP project, if it's not very high-maintenance : )", "author": "pabloem", "createdAt": "2020-04-01T18:35:41Z", "path": "sdks/java/io/google-cloud-platform/src/test/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IOWriteIT.java", "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.healthcare;\n+\n+import static org.apache.beam.sdk.io.gcp.healthcare.HL7v2IOTestUtil.MESSAGES;\n+import static org.apache.beam.sdk.io.gcp.healthcare.HL7v2IOTestUtil.deleteAllHL7v2Messages;\n+import static org.junit.Assert.assertEquals;\n+\n+import java.io.IOException;\n+import org.apache.beam.sdk.Pipeline;\n+import org.apache.beam.sdk.options.PipelineOptionsFactory;\n+import org.apache.beam.sdk.testing.PAssert;\n+import org.apache.beam.sdk.testing.TestPipeline;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.JUnit4;\n+\n+@RunWith(JUnit4.class)\n+public class HL7v2IOWriteIT {\n+\n+  private HL7v2IOTestOptions options;\n+  private transient HealthcareApiClient client;\n+\n+  @Before\n+  public void setup() throws Exception {\n+    if (client == null) {\n+      client = new HttpHealthcareApiClient();\n+    }\n+    PipelineOptionsFactory.register(HL7v2IOTestOptions.class);\n+    options = TestPipeline.testingPipelineOptions().as(HL7v2IOTestOptions.class);\n+    options.setHL7v2Store(\n+        \"projects/jferriero-dev/locations/us-central1/datasets/raw-dataset/hl7V2Stores/jake-hl7\");", "originalCommit": "04d0471f4c6d1d1e1d6814939519dd2c36ae296f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM2Mjc3OQ==", "url": "https://github.com/apache/beam/pull/11151#discussion_r404362779", "bodyText": "Yes it does write to HL7v2 store.\nThese Integration Tests should not run in parallel (as the success criteria is based on counting messages in HL7v2 store).\nThis should be very low maintenance. Let's connect offline about how you typically create resources in this project.", "author": "jaketf", "createdAt": "2020-04-06T20:19:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTgyNjUyNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDMzNDU4OA==", "url": "https://github.com/apache/beam/pull/11151#discussion_r404334588", "bodyText": "I see the observedTime is not serialized/deserialized. This means that the observedTime for a HealthcareIOError event will keep changing as the event is serialized / deserialized. Though I guess it will be roughly accurate when it's written out. WDYT?", "author": "pabloem", "createdAt": "2020-04-06T19:27:45Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HealthcareIOErrorCoder.java", "diffHunk": "@@ -0,0 +1,54 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.healthcare;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.CoderException;\n+import org.apache.beam.sdk.coders.CustomCoder;\n+import org.apache.beam.sdk.coders.NullableCoder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+\n+public class HealthcareIOErrorCoder<T> extends CustomCoder<HealthcareIOError<T>> {\n+  private final Coder<T> originalCoder;\n+  private static final NullableCoder<String> STRING_CODER = NullableCoder.of(StringUtf8Coder.of());\n+\n+  HealthcareIOErrorCoder(Coder<T> originalCoder) {\n+    this.originalCoder = NullableCoder.of(originalCoder);\n+  }\n+\n+  @Override\n+  public void encode(HealthcareIOError<T> value, OutputStream outStream)\n+      throws CoderException, IOException {\n+\n+    originalCoder.encode(value.getDataResource(), outStream);\n+", "originalCommit": "54b90b9920d1a403ad8a1be756e451d4d64f5998", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM2NjgxOA==", "url": "https://github.com/apache/beam/pull/11151#discussion_r404366818", "bodyText": "Good Catch.\nWe should serialize / deserialize observed time, no reason to introduce that drift even if it is small.", "author": "jaketf", "createdAt": "2020-04-06T20:27:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDMzNDU4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM0NzU4MQ==", "url": "https://github.com/apache/beam/pull/11151#discussion_r404347581", "bodyText": "This section of the code may represent a performance blocker, as we're issuing a single blocking call per message. This is fine, but you may eventually want to batch messages to send for ingestion. It also depends of whether the service supports batching.\nWe do something like that for BigQuery streaming inserts: https://github.com/apache/beam/blob/master/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/StreamingWriteFn.java#L85-L156\nWe send a list of messages [m1, m2, m3, ...], and if there are any errors, BQ also returns a list of errors that can be mapped to individual messages.", "author": "pabloem", "createdAt": "2020-04-06T19:51:39Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -0,0 +1,597 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.healthcare;\n+\n+import com.google.api.services.healthcare.v1beta1.model.Message;\n+import com.google.auto.value.AutoValue;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.beam.sdk.Pipeline;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubIO;\n+import org.apache.beam.sdk.metrics.Counter;\n+import org.apache.beam.sdk.metrics.Metrics;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionTuple;\n+import org.apache.beam.sdk.values.PInput;\n+import org.apache.beam.sdk.values.POutput;\n+import org.apache.beam.sdk.values.PValue;\n+import org.apache.beam.sdk.values.TupleTag;\n+import org.apache.beam.sdk.values.TupleTagList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Throwables;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * {@link HL7v2IO} provides an API for reading from and writing to <a\n+ * href=\"https://cloud.google.com/healthcare/docs/concepts/hl7v2\">Google Cloud Healthcare HL7v2 API.\n+ * </a>\n+ *\n+ * <p>Read\n+ *\n+ * <p>HL7v2 Messages can be fetched from the HL7v2 store in two ways Message Fetching and Message\n+ * Listing.\n+ *\n+ * <p>Message Fetching\n+ *\n+ * <p>Message Fetching with {@link HL7v2IO.Read} supports use cases where you have a ${@link\n+ * PCollection} of message IDS. This is appropriate for reading the HL7v2 notifications from a\n+ * Pub/Sub subscription with {@link PubsubIO#readStrings()} or in cases where you have a manually\n+ * prepared list of messages that you need to process (e.g. in a text file read with {@link\n+ * org.apache.beam.sdk.io.TextIO}) .\n+ *\n+ * <p>Fetch Message contents from HL7v2 Store based on the {@link PCollection} of message ID strings\n+ * {@link HL7v2IO.Read.Result} where one can call {@link Read.Result#getMessages()} to retrived a\n+ * {@link PCollection} containing the successfully fetched {@link HL7v2Message}s and/or {@link\n+ * Read.Result#getFailedReads()} to retrieve a {@link PCollection} of {@link HealthcareIOError}\n+ * containing the msgID that could not be fetched and the exception as a {@link HealthcareIOError},\n+ * this can be used to write to the dead letter storage system of your choosing. This error handling\n+ * is mainly to catch scenarios where the upstream {@link PCollection} contains IDs that are not\n+ * valid or are not reachable due to permissions issues.\n+ *\n+ * <p>Message Listing Message Listing with {@link HL7v2IO.ListHL7v2Messages} supports batch use\n+ * cases where you want to process all the messages in an HL7v2 store or those matching a\n+ * filter @see <a\n+ * href=>https://cloud.google.com/healthcare/docs/reference/rest/v1beta1/projects.locations.datasets.hl7V2Stores.messages/list#query-parameters</a>\n+ * This paginates through results of a Messages.List call @see <a\n+ * href=>https://cloud.google.com/healthcare/docs/reference/rest/v1beta1/projects.locations.datasets.hl7V2Stores.messages/list</a>\n+ * and outputs directly to a {@link PCollection} of {@link HL7v2Message}. In these use cases, the\n+ * error handling similar to above is unnecessary because we are listing from the source of truth\n+ * the pipeline should fail transparently if this transform fails to paginate through all the\n+ * results.\n+ *\n+ * <p>Write\n+ *\n+ * <p>A bounded or unbounded {@link PCollection} of {@link HL7v2Message} can be ingested into an\n+ * HL7v2 store using {@link HL7v2IO#ingestMessages(String)}. This will return a {@link\n+ * HL7v2IO.Write.Result} on which you can call {@link Write.Result#getFailedInsertsWithErr()} to\n+ * retrieve a {@link PCollection} of {@link HealthcareIOError} containing the {@link HL7v2Message}\n+ * that failed to be ingested and the exception. This can be used to write to the dead letter\n+ * storage system of your chosing.\n+ *\n+ * <p>Unbounded Example:\n+ *\n+ * <pre>{@code\n+ * PipelineOptions options = ...;\n+ * Pipeline p = Pipeline.create(options);\n+ *\n+ * HL7v2IO.Read.Result readResult = p\n+ *   .apply(\n+ *     \"Read HL7v2 notifications\",\n+ *     PubSubIO.readStrings().fromTopic(options.getNotificationSubscription()))\n+ *   .apply(HL7v2IO.readAll());\n+ *\n+ * // Write errors to your favorite dead letter  queue (e.g. Pub/Sub, GCS, BigQuery)\n+ * readResult.getFailedReads().apply(\"WriteToDeadLetterQueue\", ...);\n+ *\n+ *\n+ * // Go about your happy path transformations.\n+ * PCollection<HL7v2Message> out = readResult.getMessages().apply(\"ProcessFetchedMessages\", ...);\n+ *\n+ * // Write using the Message.Ingest method of the HL7v2 REST API.\n+ * out.apply(HL7v2IO.ingestMessages(options.getOutputHL7v2Store()));\n+ *\n+ * pipeline.run();\n+ *\n+ * }***\n+ * </pre>\n+ *\n+ * <p>Bounded Read Example:\n+ *\n+ * <pre>{@code\n+ * PipelineOptions options = ...;\n+ * Pipeline p = Pipeline.create(options);\n+ *\n+ * PCollection<HL7v2Message> out = p\n+ *   .apply(\n+ *       \"List messages in HL7v2 store with filter\",\n+ *       ListHL7v2Messages(\n+ *           Collections.singletonList(options.getInputHL7v2Store()), option.getHL7v2Filter()))\n+ *    // Go about your happy path transformations.\n+ *   .apply(\"Process HL7v2 Messages\", ...);\n+ * pipeline.run().waitUntilFinish();\n+ * }***\n+ * </pre>\n+ */\n+public class HL7v2IO {\n+\n+  private static Write.Builder write(String hl7v2Store) {\n+    return new AutoValue_HL7v2IO_Write.Builder().setHL7v2Store(hl7v2Store);\n+  }\n+\n+  public static Read readAll() {\n+    return new Read();\n+  }\n+\n+  /**\n+   * Write with Messages.Ingest method. @see <a\n+   * href=https://cloud.google.com/healthcare/docs/reference/rest/v1beta1/projects.locations.datasets.hl7V2Stores.messages/ingest></a>\n+   *\n+   * @param hl7v2Store the hl 7 v 2 store\n+   * @return the write\n+   */\n+  public static Write ingestMessages(String hl7v2Store) {\n+    return write(hl7v2Store).setWriteMethod(Write.WriteMethod.INGEST).build();\n+  }\n+\n+  // TODO add hyper links to this doc string.\n+  /**\n+   * The type Read that reads HL7v2 message contents given a PCollection of message IDs strings.\n+   *\n+   * <p>These could be sourced from any {@link PCollection} of {@link String}s but the most popular\n+   * patterns would be {@link PubsubIO#readStrings()} reading a subscription on an HL7v2 Store's\n+   * notification channel topic or using {@link ListHL7v2Messages} to list HL7v2 message IDs with an\n+   * optional filter using Ingest write method. @see <a\n+   * href=https://cloud.google.com/healthcare/docs/reference/rest/v1beta1/projects.locations.datasets.hl7V2Stores.messages/list></a>.\n+   */\n+  public static class Read extends PTransform<PCollection<String>, Read.Result> {\n+\n+    public Read() {}\n+\n+    public static class Result implements POutput, PInput {\n+      private PCollection<HL7v2Message> messages;\n+\n+      private PCollection<HealthcareIOError<String>> failedReads;\n+      PCollectionTuple pct;\n+\n+      public static Result of(PCollectionTuple pct) throws IllegalArgumentException {\n+        if (pct.getAll()\n+            .keySet()\n+            .containsAll((Collection<?>) TupleTagList.of(OUT).and(DEAD_LETTER))) {\n+          return new Result(pct);\n+        } else {\n+          throw new IllegalArgumentException(\n+              \"The PCollection tuple must have the HL7v2IO.Read.OUT \"\n+                  + \"and HL7v2IO.Read.DEAD_LETTER tuple tags\");\n+        }\n+      }\n+\n+      private Result(PCollectionTuple pct) {\n+        this.pct = pct;\n+        this.messages = pct.get(OUT).setCoder(new HL7v2MessageCoder());\n+        this.failedReads =\n+            pct.get(DEAD_LETTER).setCoder(new HealthcareIOErrorCoder<>(StringUtf8Coder.of()));\n+      }\n+\n+      public PCollection<HealthcareIOError<String>> getFailedReads() {\n+        return failedReads;\n+      }\n+\n+      public PCollection<HL7v2Message> getMessages() {\n+        return messages;\n+      }\n+\n+      @Override\n+      public Pipeline getPipeline() {\n+        return this.pct.getPipeline();\n+      }\n+\n+      @Override\n+      public Map<TupleTag<?>, PValue> expand() {\n+        return ImmutableMap.of(OUT, messages);\n+      }\n+\n+      @Override\n+      public void finishSpecifyingOutput(\n+          String transformName, PInput input, PTransform<?, ?> transform) {}\n+    }\n+\n+    /** The tag for the main output of HL7v2 Messages. */\n+    public static final TupleTag<HL7v2Message> OUT = new TupleTag<HL7v2Message>() {};\n+    /** The tag for the deadletter output of HL7v2 Messages. */\n+    public static final TupleTag<HealthcareIOError<String>> DEAD_LETTER =\n+        new TupleTag<HealthcareIOError<String>>() {};\n+\n+    @Override\n+    public Result expand(PCollection<String> input) {\n+      return input.apply(\"Fetch HL7v2 messages\", new FetchHL7v2Message());\n+    }\n+\n+    /**\n+     * DoFn to fetch a message from an Google Cloud Healthcare HL7v2 store based on msgID\n+     *\n+     * <p>This DoFn consumes a {@link PCollection} of notifications {@link String}s from the HL7v2\n+     * store, and fetches the actual {@link HL7v2Message} object based on the id in the notification\n+     * and will output a {@link PCollectionTuple} which contains the output and dead-letter {@link\n+     * PCollection}.\n+     *\n+     * <p>The {@link PCollectionTuple} output will contain the following {@link PCollection}:\n+     *\n+     * <ul>\n+     *   <li>{@link HL7v2IO.Read#OUT} - Contains all {@link PCollection} records successfully read\n+     *       from the HL7v2 store.\n+     *   <li>{@link HL7v2IO.Read#DEAD_LETTER} - Contains all {@link PCollection} of {@link\n+     *       HealthcareIOError} message IDs which failed to be fetched from the HL7v2 store, with\n+     *       error message and stacktrace.\n+     * </ul>\n+     */\n+    public static class FetchHL7v2Message extends PTransform<PCollection<String>, Result> {\n+\n+      /** Instantiates a new Fetch HL7v2 message DoFn. */\n+      public FetchHL7v2Message() {}\n+\n+      @Override\n+      public Result expand(PCollection<String> msgIds) {\n+        return new Result(\n+            msgIds.apply(\n+                ParDo.of(new FetchHL7v2Message.HL7v2MessageGetFn())\n+                    .withOutputTags(HL7v2IO.Read.OUT, TupleTagList.of(HL7v2IO.Read.DEAD_LETTER))));\n+      }\n+\n+      /** DoFn for fetching messages from the HL7v2 store with error handling. */\n+      public static class HL7v2MessageGetFn extends DoFn<String, HL7v2Message> {\n+\n+        private Counter failedMessageGets =\n+            Metrics.counter(FetchHL7v2Message.HL7v2MessageGetFn.class, \"failed-message-reads\");\n+        private static final Logger LOG =\n+            LoggerFactory.getLogger(FetchHL7v2Message.HL7v2MessageGetFn.class);\n+        private final Counter successfulHL7v2MessageGets =\n+            Metrics.counter(\n+                FetchHL7v2Message.HL7v2MessageGetFn.class, \"successful-hl7v2-message-gets\");\n+        private HealthcareApiClient client;\n+\n+        /** Instantiates a new Hl 7 v 2 message get fn. */\n+        HL7v2MessageGetFn() {}\n+\n+        /**\n+         * Instantiate healthcare client.\n+         *\n+         * @throws IOException the io exception\n+         */\n+        @Setup\n+        public void instantiateHealthcareClient() throws IOException {\n+          this.client = new HttpHealthcareApiClient();\n+        }\n+\n+        /**\n+         * Process element.\n+         *\n+         * @param context the context\n+         */\n+        @ProcessElement\n+        public void processElement(ProcessContext context) {\n+          String msgId = context.element();\n+          try {\n+            context.output(HL7v2Message.fromModel(fetchMessage(this.client, msgId)));\n+          } catch (Exception e) {\n+            failedMessageGets.inc();\n+            LOG.warn(\n+                String.format(\n+                    \"Error fetching HL7v2 message with ID %s writing to Dead Letter \"\n+                        + \"Queue. Cause: %s Stack Trace: %s\",\n+                    msgId, e.getMessage(), Throwables.getStackTraceAsString(e)));\n+            context.output(HL7v2IO.Read.DEAD_LETTER, HealthcareIOError.of(msgId, e));\n+          }\n+        }\n+\n+        private Message fetchMessage(HealthcareApiClient client, String msgId)\n+            throws IOException, ParseException, IllegalArgumentException, InterruptedException {\n+          long startTime = System.currentTimeMillis();\n+\n+          com.google.api.services.healthcare.v1beta1.model.Message msg =\n+              client.getHL7v2Message(msgId);\n+\n+          if (msg == null) {\n+            throw new IOException(String.format(\"GET request for %s returned null\", msgId));\n+          }\n+          this.successfulHL7v2MessageGets.inc();\n+          return msg;\n+        }\n+      }\n+    }\n+  }\n+\n+  /** List HL7v2 messages. */\n+  public static class ListHL7v2Messages extends PTransform<PBegin, PCollection<HL7v2Message>> {\n+    private final List<String> hl7v2Stores;\n+    private final String filter;\n+\n+    /**\n+     * Instantiates a new List HL7v2 message IDs with filter.\n+     *\n+     * @param hl7v2Stores the HL7v2 stores\n+     * @param filter the filter\n+     */\n+    ListHL7v2Messages(List<String> hl7v2Stores, String filter) {\n+      this.hl7v2Stores = hl7v2Stores;\n+      this.filter = filter;\n+    }\n+\n+    ListHL7v2Messages(List<String> hl7v2Stores) {\n+      this.hl7v2Stores = hl7v2Stores;\n+      this.filter = null;\n+    }\n+\n+    @Override\n+    public PCollection<HL7v2Message> expand(PBegin input) {\n+      return input\n+          .apply(Create.of(this.hl7v2Stores))\n+          .apply(ParDo.of(new ListHL7v2MessagesFn(this.filter)));\n+    }\n+  }\n+\n+  static class ListHL7v2MessagesFn extends DoFn<String, HL7v2Message> {\n+\n+    private final String filter;\n+    private transient HealthcareApiClient client;\n+\n+    /**\n+     * Instantiates a new List HL7v2 fn.\n+     *\n+     * @param filter the filter\n+     */\n+    ListHL7v2MessagesFn(String filter) {\n+      this.filter = filter;\n+    }\n+\n+    /**\n+     * Init client.\n+     *\n+     * @throws IOException the io exception\n+     */\n+    @Setup\n+    public void initClient() throws IOException {\n+      this.client = new HttpHealthcareApiClient();\n+    }\n+\n+    /**\n+     * List messages.\n+     *\n+     * @param context the context\n+     * @throws IOException the io exception\n+     */\n+    @ProcessElement\n+    public void listMessages(ProcessContext context) throws IOException {\n+      String hl7v2Store = context.element();\n+      // Output all elements of all pages.\n+      this.client.getHL7v2MessageStream(hl7v2Store, this.filter).forEach(context::output);\n+    }\n+  }\n+\n+  /** The type Write. */\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<HL7v2Message>, Write.Result> {\n+\n+    /** The tag for the successful writes to HL7v2 store`. */\n+    public static final TupleTag<HealthcareIOError<HL7v2Message>> SUCCESS =\n+        new TupleTag<HealthcareIOError<HL7v2Message>>() {};\n+    /** The tag for the failed writes to HL7v2 store`. */\n+    public static final TupleTag<HealthcareIOError<HL7v2Message>> FAILED =\n+        new TupleTag<HealthcareIOError<HL7v2Message>>() {};\n+\n+    /**\n+     * Gets HL7v2 store.\n+     *\n+     * @return the HL7v2 store\n+     */\n+    abstract String getHL7v2Store();\n+\n+    /**\n+     * Gets write method.\n+     *\n+     * @return the write method\n+     */\n+    abstract WriteMethod getWriteMethod();\n+\n+    @Override\n+    public Result expand(PCollection<HL7v2Message> messages) {\n+      return messages.apply(new WriteHL7v2(this.getHL7v2Store(), this.getWriteMethod()));\n+    }\n+\n+    /** The enum Write method. */\n+    public enum WriteMethod {\n+      /**\n+       * Ingest write method. @see <a\n+       * href=https://cloud.google.com/healthcare/docs/reference/rest/v1beta1/projects.locations.datasets.hl7V2Stores.messages/ingest></a>\n+       */\n+      INGEST,\n+      /**\n+       * Batch import write method. This is not yet supported by the HL7v2 API, but can be used to\n+       * improve throughput once available.\n+       */\n+      BATCH_IMPORT\n+    }\n+\n+    /** The type Builder. */\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+\n+      /**\n+       * Sets HL7v2 store.\n+       *\n+       * @param hl7v2Store the HL7v2 store\n+       * @return the HL7v2 store\n+       */\n+      abstract Builder setHL7v2Store(String hl7v2Store);\n+\n+      /**\n+       * Sets write method.\n+       *\n+       * @param writeMethod the write method\n+       * @return the write method\n+       */\n+      abstract Builder setWriteMethod(WriteMethod writeMethod);\n+\n+      /**\n+       * Build write.\n+       *\n+       * @return the write\n+       */\n+      abstract Write build();\n+    }\n+\n+    public static class Result implements POutput {\n+      private final Pipeline pipeline;\n+      private final PCollection<HealthcareIOError<HL7v2Message>> failedInsertsWithErr;\n+\n+      /** Creates a {@link HL7v2IO.Write.Result} in the given {@link Pipeline}. */\n+      static Result in(\n+          Pipeline pipeline, PCollection<HealthcareIOError<HL7v2Message>> failedInserts) {\n+        return new Result(pipeline, failedInserts);\n+      }\n+\n+      public PCollection<HealthcareIOError<HL7v2Message>> getFailedInsertsWithErr() {\n+        return this.failedInsertsWithErr;\n+      }\n+\n+      @Override\n+      public Pipeline getPipeline() {\n+        return this.pipeline;\n+      }\n+\n+      @Override\n+      public Map<TupleTag<?>, PValue> expand() {\n+        failedInsertsWithErr.setCoder(new HealthcareIOErrorCoder<>(new HL7v2MessageCoder()));\n+        return ImmutableMap.of(FAILED, failedInsertsWithErr);\n+      }\n+\n+      @Override\n+      public void finishSpecifyingOutput(\n+          String transformName, PInput input, PTransform<?, ?> transform) {}\n+\n+      private Result(\n+          Pipeline pipeline, PCollection<HealthcareIOError<HL7v2Message>> failedInsertsWithErr) {\n+        this.pipeline = pipeline;\n+        this.failedInsertsWithErr = failedInsertsWithErr;\n+      }\n+    }\n+  }\n+\n+  /** The type Write hl 7 v 2. */\n+  static class WriteHL7v2 extends PTransform<PCollection<HL7v2Message>, Write.Result> {\n+    private final String hl7v2Store;\n+    private final Write.WriteMethod writeMethod;\n+\n+    /**\n+     * Instantiates a new Write hl 7 v 2.\n+     *\n+     * @param hl7v2Store the hl 7 v 2 store\n+     * @param writeMethod the write method\n+     */\n+    WriteHL7v2(String hl7v2Store, Write.WriteMethod writeMethod) {\n+      this.hl7v2Store = hl7v2Store;\n+      this.writeMethod = writeMethod;\n+    }\n+\n+    @Override\n+    public Write.Result expand(PCollection<HL7v2Message> input) {\n+      PCollection<HealthcareIOError<HL7v2Message>> failedInserts =\n+          input\n+              .apply(ParDo.of(new WriteHL7v2Fn(hl7v2Store, writeMethod)))\n+              .setCoder(new HealthcareIOErrorCoder<>(new HL7v2MessageCoder()));\n+      return Write.Result.in(input.getPipeline(), failedInserts);\n+    }\n+\n+    /** The type Write hl 7 v 2 fn. */\n+    static class WriteHL7v2Fn extends DoFn<HL7v2Message, HealthcareIOError<HL7v2Message>> {\n+      // TODO when the healthcare API releases a bulk import method this should use that to improve\n+      // throughput.\n+\n+      private Counter failedMessageWrites =\n+          Metrics.counter(WriteHL7v2Fn.class, \"failed-hl7v2-message-writes\");\n+      private final String hl7v2Store;\n+      private final Counter successfulHL7v2MessageWrites =\n+          Metrics.counter(WriteHL7v2.class, \"successful-hl7v2-message-writes\");\n+      private final Write.WriteMethod writeMethod;\n+\n+      private static final Logger LOG = LoggerFactory.getLogger(WriteHL7v2.WriteHL7v2Fn.class);\n+      private transient HealthcareApiClient client;\n+\n+      /**\n+       * Instantiates a new Write HL7v2 fn.\n+       *\n+       * @param hl7v2Store the HL7v2 store\n+       * @param writeMethod the write method\n+       */\n+      WriteHL7v2Fn(String hl7v2Store, Write.WriteMethod writeMethod) {\n+        this.hl7v2Store = hl7v2Store;\n+        this.writeMethod = writeMethod;\n+      }\n+\n+      /**\n+       * Init client.\n+       *\n+       * @throws IOException the io exception\n+       */\n+      @Setup\n+      public void initClient() throws IOException {\n+        this.client = new HttpHealthcareApiClient();\n+      }\n+\n+      /**\n+       * Write messages.\n+       *\n+       * @param context the context\n+       */\n+      @ProcessElement\n+      public void writeMessages(ProcessContext context) {\n+        HL7v2Message msg = context.element();\n+        long startTime = System.currentTimeMillis();\n+        Sleeper sleeper = Sleeper.DEFAULT;\n+        switch (writeMethod) {\n+          case BATCH_IMPORT:\n+            throw new UnsupportedOperationException(\"The Batch import API is not available yet\");\n+          case INGEST:\n+          default:\n+            try {\n+              client.ingestHL7v2Message(hl7v2Store, msg.toModel());", "originalCommit": "54b90b9920d1a403ad8a1be756e451d4d64f5998", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM2NzQ5Nw==", "url": "https://github.com/apache/beam/pull/11151#discussion_r404367497", "bodyText": "The service does not support batching yet.", "author": "jaketf", "createdAt": "2020-04-06T20:28:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM0NzU4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTE1MDgyMw==", "url": "https://github.com/apache/beam/pull/11151#discussion_r409150823", "bodyText": "Please add a TODO for this. I think this is a critical performance bottleneck.", "author": "chamikaramj", "createdAt": "2020-04-15T21:41:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM0NzU4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM1MzA4NA==", "url": "https://github.com/apache/beam/pull/11151#discussion_r404353084", "bodyText": "I guess it's not a DoFn?", "author": "pabloem", "createdAt": "2020-04-06T20:01:35Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -0,0 +1,597 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.healthcare;\n+\n+import com.google.api.services.healthcare.v1beta1.model.Message;\n+import com.google.auto.value.AutoValue;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.beam.sdk.Pipeline;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubIO;\n+import org.apache.beam.sdk.metrics.Counter;\n+import org.apache.beam.sdk.metrics.Metrics;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionTuple;\n+import org.apache.beam.sdk.values.PInput;\n+import org.apache.beam.sdk.values.POutput;\n+import org.apache.beam.sdk.values.PValue;\n+import org.apache.beam.sdk.values.TupleTag;\n+import org.apache.beam.sdk.values.TupleTagList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Throwables;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * {@link HL7v2IO} provides an API for reading from and writing to <a\n+ * href=\"https://cloud.google.com/healthcare/docs/concepts/hl7v2\">Google Cloud Healthcare HL7v2 API.\n+ * </a>\n+ *\n+ * <p>Read\n+ *\n+ * <p>HL7v2 Messages can be fetched from the HL7v2 store in two ways Message Fetching and Message\n+ * Listing.\n+ *\n+ * <p>Message Fetching\n+ *\n+ * <p>Message Fetching with {@link HL7v2IO.Read} supports use cases where you have a ${@link\n+ * PCollection} of message IDS. This is appropriate for reading the HL7v2 notifications from a\n+ * Pub/Sub subscription with {@link PubsubIO#readStrings()} or in cases where you have a manually\n+ * prepared list of messages that you need to process (e.g. in a text file read with {@link\n+ * org.apache.beam.sdk.io.TextIO}) .\n+ *\n+ * <p>Fetch Message contents from HL7v2 Store based on the {@link PCollection} of message ID strings\n+ * {@link HL7v2IO.Read.Result} where one can call {@link Read.Result#getMessages()} to retrived a\n+ * {@link PCollection} containing the successfully fetched {@link HL7v2Message}s and/or {@link\n+ * Read.Result#getFailedReads()} to retrieve a {@link PCollection} of {@link HealthcareIOError}\n+ * containing the msgID that could not be fetched and the exception as a {@link HealthcareIOError},\n+ * this can be used to write to the dead letter storage system of your choosing. This error handling\n+ * is mainly to catch scenarios where the upstream {@link PCollection} contains IDs that are not\n+ * valid or are not reachable due to permissions issues.\n+ *\n+ * <p>Message Listing Message Listing with {@link HL7v2IO.ListHL7v2Messages} supports batch use\n+ * cases where you want to process all the messages in an HL7v2 store or those matching a\n+ * filter @see <a\n+ * href=>https://cloud.google.com/healthcare/docs/reference/rest/v1beta1/projects.locations.datasets.hl7V2Stores.messages/list#query-parameters</a>\n+ * This paginates through results of a Messages.List call @see <a\n+ * href=>https://cloud.google.com/healthcare/docs/reference/rest/v1beta1/projects.locations.datasets.hl7V2Stores.messages/list</a>\n+ * and outputs directly to a {@link PCollection} of {@link HL7v2Message}. In these use cases, the\n+ * error handling similar to above is unnecessary because we are listing from the source of truth\n+ * the pipeline should fail transparently if this transform fails to paginate through all the\n+ * results.\n+ *\n+ * <p>Write\n+ *\n+ * <p>A bounded or unbounded {@link PCollection} of {@link HL7v2Message} can be ingested into an\n+ * HL7v2 store using {@link HL7v2IO#ingestMessages(String)}. This will return a {@link\n+ * HL7v2IO.Write.Result} on which you can call {@link Write.Result#getFailedInsertsWithErr()} to\n+ * retrieve a {@link PCollection} of {@link HealthcareIOError} containing the {@link HL7v2Message}\n+ * that failed to be ingested and the exception. This can be used to write to the dead letter\n+ * storage system of your chosing.\n+ *\n+ * <p>Unbounded Example:\n+ *\n+ * <pre>{@code\n+ * PipelineOptions options = ...;\n+ * Pipeline p = Pipeline.create(options);\n+ *\n+ * HL7v2IO.Read.Result readResult = p\n+ *   .apply(\n+ *     \"Read HL7v2 notifications\",\n+ *     PubSubIO.readStrings().fromTopic(options.getNotificationSubscription()))\n+ *   .apply(HL7v2IO.readAll());\n+ *\n+ * // Write errors to your favorite dead letter  queue (e.g. Pub/Sub, GCS, BigQuery)\n+ * readResult.getFailedReads().apply(\"WriteToDeadLetterQueue\", ...);\n+ *\n+ *\n+ * // Go about your happy path transformations.\n+ * PCollection<HL7v2Message> out = readResult.getMessages().apply(\"ProcessFetchedMessages\", ...);\n+ *\n+ * // Write using the Message.Ingest method of the HL7v2 REST API.\n+ * out.apply(HL7v2IO.ingestMessages(options.getOutputHL7v2Store()));\n+ *\n+ * pipeline.run();\n+ *\n+ * }***\n+ * </pre>\n+ *\n+ * <p>Bounded Read Example:\n+ *\n+ * <pre>{@code\n+ * PipelineOptions options = ...;\n+ * Pipeline p = Pipeline.create(options);\n+ *\n+ * PCollection<HL7v2Message> out = p\n+ *   .apply(\n+ *       \"List messages in HL7v2 store with filter\",\n+ *       ListHL7v2Messages(\n+ *           Collections.singletonList(options.getInputHL7v2Store()), option.getHL7v2Filter()))\n+ *    // Go about your happy path transformations.\n+ *   .apply(\"Process HL7v2 Messages\", ...);\n+ * pipeline.run().waitUntilFinish();\n+ * }***\n+ * </pre>\n+ */\n+public class HL7v2IO {\n+\n+  private static Write.Builder write(String hl7v2Store) {\n+    return new AutoValue_HL7v2IO_Write.Builder().setHL7v2Store(hl7v2Store);\n+  }\n+\n+  public static Read readAll() {\n+    return new Read();\n+  }\n+\n+  /**\n+   * Write with Messages.Ingest method. @see <a\n+   * href=https://cloud.google.com/healthcare/docs/reference/rest/v1beta1/projects.locations.datasets.hl7V2Stores.messages/ingest></a>\n+   *\n+   * @param hl7v2Store the hl 7 v 2 store\n+   * @return the write\n+   */\n+  public static Write ingestMessages(String hl7v2Store) {\n+    return write(hl7v2Store).setWriteMethod(Write.WriteMethod.INGEST).build();\n+  }\n+\n+  // TODO add hyper links to this doc string.\n+  /**\n+   * The type Read that reads HL7v2 message contents given a PCollection of message IDs strings.\n+   *\n+   * <p>These could be sourced from any {@link PCollection} of {@link String}s but the most popular\n+   * patterns would be {@link PubsubIO#readStrings()} reading a subscription on an HL7v2 Store's\n+   * notification channel topic or using {@link ListHL7v2Messages} to list HL7v2 message IDs with an\n+   * optional filter using Ingest write method. @see <a\n+   * href=https://cloud.google.com/healthcare/docs/reference/rest/v1beta1/projects.locations.datasets.hl7V2Stores.messages/list></a>.\n+   */\n+  public static class Read extends PTransform<PCollection<String>, Read.Result> {\n+\n+    public Read() {}\n+\n+    public static class Result implements POutput, PInput {\n+      private PCollection<HL7v2Message> messages;\n+\n+      private PCollection<HealthcareIOError<String>> failedReads;\n+      PCollectionTuple pct;\n+\n+      public static Result of(PCollectionTuple pct) throws IllegalArgumentException {\n+        if (pct.getAll()\n+            .keySet()\n+            .containsAll((Collection<?>) TupleTagList.of(OUT).and(DEAD_LETTER))) {\n+          return new Result(pct);\n+        } else {\n+          throw new IllegalArgumentException(\n+              \"The PCollection tuple must have the HL7v2IO.Read.OUT \"\n+                  + \"and HL7v2IO.Read.DEAD_LETTER tuple tags\");\n+        }\n+      }\n+\n+      private Result(PCollectionTuple pct) {\n+        this.pct = pct;\n+        this.messages = pct.get(OUT).setCoder(new HL7v2MessageCoder());\n+        this.failedReads =\n+            pct.get(DEAD_LETTER).setCoder(new HealthcareIOErrorCoder<>(StringUtf8Coder.of()));\n+      }\n+\n+      public PCollection<HealthcareIOError<String>> getFailedReads() {\n+        return failedReads;\n+      }\n+\n+      public PCollection<HL7v2Message> getMessages() {\n+        return messages;\n+      }\n+\n+      @Override\n+      public Pipeline getPipeline() {\n+        return this.pct.getPipeline();\n+      }\n+\n+      @Override\n+      public Map<TupleTag<?>, PValue> expand() {\n+        return ImmutableMap.of(OUT, messages);\n+      }\n+\n+      @Override\n+      public void finishSpecifyingOutput(\n+          String transformName, PInput input, PTransform<?, ?> transform) {}\n+    }\n+\n+    /** The tag for the main output of HL7v2 Messages. */\n+    public static final TupleTag<HL7v2Message> OUT = new TupleTag<HL7v2Message>() {};\n+    /** The tag for the deadletter output of HL7v2 Messages. */\n+    public static final TupleTag<HealthcareIOError<String>> DEAD_LETTER =\n+        new TupleTag<HealthcareIOError<String>>() {};\n+\n+    @Override\n+    public Result expand(PCollection<String> input) {\n+      return input.apply(\"Fetch HL7v2 messages\", new FetchHL7v2Message());\n+    }\n+\n+    /**\n+     * DoFn to fetch a message from an Google Cloud Healthcare HL7v2 store based on msgID", "originalCommit": "54b90b9920d1a403ad8a1be756e451d4d64f5998", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM1NjYzNQ==", "url": "https://github.com/apache/beam/pull/11151#discussion_r404356635", "bodyText": "This is the same as the Write transform. It may be useful to batch multiple fetches in a single request if possible. This should be fine for now, as workers / PubSub are able to scale to very high parallelism in streaming, but may be a valuable optimization later. (or now if you have the time / the HL7v2 service supports it)", "author": "pabloem", "createdAt": "2020-04-06T20:08:29Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -0,0 +1,597 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.healthcare;\n+\n+import com.google.api.services.healthcare.v1beta1.model.Message;\n+import com.google.auto.value.AutoValue;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.beam.sdk.Pipeline;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubIO;\n+import org.apache.beam.sdk.metrics.Counter;\n+import org.apache.beam.sdk.metrics.Metrics;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionTuple;\n+import org.apache.beam.sdk.values.PInput;\n+import org.apache.beam.sdk.values.POutput;\n+import org.apache.beam.sdk.values.PValue;\n+import org.apache.beam.sdk.values.TupleTag;\n+import org.apache.beam.sdk.values.TupleTagList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Throwables;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * {@link HL7v2IO} provides an API for reading from and writing to <a\n+ * href=\"https://cloud.google.com/healthcare/docs/concepts/hl7v2\">Google Cloud Healthcare HL7v2 API.\n+ * </a>\n+ *\n+ * <p>Read\n+ *\n+ * <p>HL7v2 Messages can be fetched from the HL7v2 store in two ways Message Fetching and Message\n+ * Listing.\n+ *\n+ * <p>Message Fetching\n+ *\n+ * <p>Message Fetching with {@link HL7v2IO.Read} supports use cases where you have a ${@link\n+ * PCollection} of message IDS. This is appropriate for reading the HL7v2 notifications from a\n+ * Pub/Sub subscription with {@link PubsubIO#readStrings()} or in cases where you have a manually\n+ * prepared list of messages that you need to process (e.g. in a text file read with {@link\n+ * org.apache.beam.sdk.io.TextIO}) .\n+ *\n+ * <p>Fetch Message contents from HL7v2 Store based on the {@link PCollection} of message ID strings\n+ * {@link HL7v2IO.Read.Result} where one can call {@link Read.Result#getMessages()} to retrived a\n+ * {@link PCollection} containing the successfully fetched {@link HL7v2Message}s and/or {@link\n+ * Read.Result#getFailedReads()} to retrieve a {@link PCollection} of {@link HealthcareIOError}\n+ * containing the msgID that could not be fetched and the exception as a {@link HealthcareIOError},\n+ * this can be used to write to the dead letter storage system of your choosing. This error handling\n+ * is mainly to catch scenarios where the upstream {@link PCollection} contains IDs that are not\n+ * valid or are not reachable due to permissions issues.\n+ *\n+ * <p>Message Listing Message Listing with {@link HL7v2IO.ListHL7v2Messages} supports batch use\n+ * cases where you want to process all the messages in an HL7v2 store or those matching a\n+ * filter @see <a\n+ * href=>https://cloud.google.com/healthcare/docs/reference/rest/v1beta1/projects.locations.datasets.hl7V2Stores.messages/list#query-parameters</a>\n+ * This paginates through results of a Messages.List call @see <a\n+ * href=>https://cloud.google.com/healthcare/docs/reference/rest/v1beta1/projects.locations.datasets.hl7V2Stores.messages/list</a>\n+ * and outputs directly to a {@link PCollection} of {@link HL7v2Message}. In these use cases, the\n+ * error handling similar to above is unnecessary because we are listing from the source of truth\n+ * the pipeline should fail transparently if this transform fails to paginate through all the\n+ * results.\n+ *\n+ * <p>Write\n+ *\n+ * <p>A bounded or unbounded {@link PCollection} of {@link HL7v2Message} can be ingested into an\n+ * HL7v2 store using {@link HL7v2IO#ingestMessages(String)}. This will return a {@link\n+ * HL7v2IO.Write.Result} on which you can call {@link Write.Result#getFailedInsertsWithErr()} to\n+ * retrieve a {@link PCollection} of {@link HealthcareIOError} containing the {@link HL7v2Message}\n+ * that failed to be ingested and the exception. This can be used to write to the dead letter\n+ * storage system of your chosing.\n+ *\n+ * <p>Unbounded Example:\n+ *\n+ * <pre>{@code\n+ * PipelineOptions options = ...;\n+ * Pipeline p = Pipeline.create(options);\n+ *\n+ * HL7v2IO.Read.Result readResult = p\n+ *   .apply(\n+ *     \"Read HL7v2 notifications\",\n+ *     PubSubIO.readStrings().fromTopic(options.getNotificationSubscription()))\n+ *   .apply(HL7v2IO.readAll());\n+ *\n+ * // Write errors to your favorite dead letter  queue (e.g. Pub/Sub, GCS, BigQuery)\n+ * readResult.getFailedReads().apply(\"WriteToDeadLetterQueue\", ...);\n+ *\n+ *\n+ * // Go about your happy path transformations.\n+ * PCollection<HL7v2Message> out = readResult.getMessages().apply(\"ProcessFetchedMessages\", ...);\n+ *\n+ * // Write using the Message.Ingest method of the HL7v2 REST API.\n+ * out.apply(HL7v2IO.ingestMessages(options.getOutputHL7v2Store()));\n+ *\n+ * pipeline.run();\n+ *\n+ * }***\n+ * </pre>\n+ *\n+ * <p>Bounded Read Example:\n+ *\n+ * <pre>{@code\n+ * PipelineOptions options = ...;\n+ * Pipeline p = Pipeline.create(options);\n+ *\n+ * PCollection<HL7v2Message> out = p\n+ *   .apply(\n+ *       \"List messages in HL7v2 store with filter\",\n+ *       ListHL7v2Messages(\n+ *           Collections.singletonList(options.getInputHL7v2Store()), option.getHL7v2Filter()))\n+ *    // Go about your happy path transformations.\n+ *   .apply(\"Process HL7v2 Messages\", ...);\n+ * pipeline.run().waitUntilFinish();\n+ * }***\n+ * </pre>\n+ */\n+public class HL7v2IO {\n+\n+  private static Write.Builder write(String hl7v2Store) {\n+    return new AutoValue_HL7v2IO_Write.Builder().setHL7v2Store(hl7v2Store);\n+  }\n+\n+  public static Read readAll() {\n+    return new Read();\n+  }\n+\n+  /**\n+   * Write with Messages.Ingest method. @see <a\n+   * href=https://cloud.google.com/healthcare/docs/reference/rest/v1beta1/projects.locations.datasets.hl7V2Stores.messages/ingest></a>\n+   *\n+   * @param hl7v2Store the hl 7 v 2 store\n+   * @return the write\n+   */\n+  public static Write ingestMessages(String hl7v2Store) {\n+    return write(hl7v2Store).setWriteMethod(Write.WriteMethod.INGEST).build();\n+  }\n+\n+  // TODO add hyper links to this doc string.\n+  /**\n+   * The type Read that reads HL7v2 message contents given a PCollection of message IDs strings.\n+   *\n+   * <p>These could be sourced from any {@link PCollection} of {@link String}s but the most popular\n+   * patterns would be {@link PubsubIO#readStrings()} reading a subscription on an HL7v2 Store's\n+   * notification channel topic or using {@link ListHL7v2Messages} to list HL7v2 message IDs with an\n+   * optional filter using Ingest write method. @see <a\n+   * href=https://cloud.google.com/healthcare/docs/reference/rest/v1beta1/projects.locations.datasets.hl7V2Stores.messages/list></a>.\n+   */\n+  public static class Read extends PTransform<PCollection<String>, Read.Result> {\n+\n+    public Read() {}\n+\n+    public static class Result implements POutput, PInput {\n+      private PCollection<HL7v2Message> messages;\n+\n+      private PCollection<HealthcareIOError<String>> failedReads;\n+      PCollectionTuple pct;\n+\n+      public static Result of(PCollectionTuple pct) throws IllegalArgumentException {\n+        if (pct.getAll()\n+            .keySet()\n+            .containsAll((Collection<?>) TupleTagList.of(OUT).and(DEAD_LETTER))) {\n+          return new Result(pct);\n+        } else {\n+          throw new IllegalArgumentException(\n+              \"The PCollection tuple must have the HL7v2IO.Read.OUT \"\n+                  + \"and HL7v2IO.Read.DEAD_LETTER tuple tags\");\n+        }\n+      }\n+\n+      private Result(PCollectionTuple pct) {\n+        this.pct = pct;\n+        this.messages = pct.get(OUT).setCoder(new HL7v2MessageCoder());\n+        this.failedReads =\n+            pct.get(DEAD_LETTER).setCoder(new HealthcareIOErrorCoder<>(StringUtf8Coder.of()));\n+      }\n+\n+      public PCollection<HealthcareIOError<String>> getFailedReads() {\n+        return failedReads;\n+      }\n+\n+      public PCollection<HL7v2Message> getMessages() {\n+        return messages;\n+      }\n+\n+      @Override\n+      public Pipeline getPipeline() {\n+        return this.pct.getPipeline();\n+      }\n+\n+      @Override\n+      public Map<TupleTag<?>, PValue> expand() {\n+        return ImmutableMap.of(OUT, messages);\n+      }\n+\n+      @Override\n+      public void finishSpecifyingOutput(\n+          String transformName, PInput input, PTransform<?, ?> transform) {}\n+    }\n+\n+    /** The tag for the main output of HL7v2 Messages. */\n+    public static final TupleTag<HL7v2Message> OUT = new TupleTag<HL7v2Message>() {};\n+    /** The tag for the deadletter output of HL7v2 Messages. */\n+    public static final TupleTag<HealthcareIOError<String>> DEAD_LETTER =\n+        new TupleTag<HealthcareIOError<String>>() {};\n+\n+    @Override\n+    public Result expand(PCollection<String> input) {\n+      return input.apply(\"Fetch HL7v2 messages\", new FetchHL7v2Message());\n+    }\n+\n+    /**\n+     * DoFn to fetch a message from an Google Cloud Healthcare HL7v2 store based on msgID\n+     *\n+     * <p>This DoFn consumes a {@link PCollection} of notifications {@link String}s from the HL7v2\n+     * store, and fetches the actual {@link HL7v2Message} object based on the id in the notification\n+     * and will output a {@link PCollectionTuple} which contains the output and dead-letter {@link\n+     * PCollection}.\n+     *\n+     * <p>The {@link PCollectionTuple} output will contain the following {@link PCollection}:\n+     *\n+     * <ul>\n+     *   <li>{@link HL7v2IO.Read#OUT} - Contains all {@link PCollection} records successfully read\n+     *       from the HL7v2 store.\n+     *   <li>{@link HL7v2IO.Read#DEAD_LETTER} - Contains all {@link PCollection} of {@link\n+     *       HealthcareIOError} message IDs which failed to be fetched from the HL7v2 store, with\n+     *       error message and stacktrace.\n+     * </ul>\n+     */\n+    public static class FetchHL7v2Message extends PTransform<PCollection<String>, Result> {\n+\n+      /** Instantiates a new Fetch HL7v2 message DoFn. */\n+      public FetchHL7v2Message() {}\n+\n+      @Override\n+      public Result expand(PCollection<String> msgIds) {\n+        return new Result(\n+            msgIds.apply(\n+                ParDo.of(new FetchHL7v2Message.HL7v2MessageGetFn())\n+                    .withOutputTags(HL7v2IO.Read.OUT, TupleTagList.of(HL7v2IO.Read.DEAD_LETTER))));\n+      }\n+\n+      /** DoFn for fetching messages from the HL7v2 store with error handling. */\n+      public static class HL7v2MessageGetFn extends DoFn<String, HL7v2Message> {\n+\n+        private Counter failedMessageGets =\n+            Metrics.counter(FetchHL7v2Message.HL7v2MessageGetFn.class, \"failed-message-reads\");\n+        private static final Logger LOG =\n+            LoggerFactory.getLogger(FetchHL7v2Message.HL7v2MessageGetFn.class);\n+        private final Counter successfulHL7v2MessageGets =\n+            Metrics.counter(\n+                FetchHL7v2Message.HL7v2MessageGetFn.class, \"successful-hl7v2-message-gets\");\n+        private HealthcareApiClient client;\n+\n+        /** Instantiates a new Hl 7 v 2 message get fn. */\n+        HL7v2MessageGetFn() {}\n+\n+        /**\n+         * Instantiate healthcare client.\n+         *\n+         * @throws IOException the io exception\n+         */\n+        @Setup\n+        public void instantiateHealthcareClient() throws IOException {\n+          this.client = new HttpHealthcareApiClient();\n+        }\n+\n+        /**\n+         * Process element.\n+         *\n+         * @param context the context\n+         */\n+        @ProcessElement\n+        public void processElement(ProcessContext context) {\n+          String msgId = context.element();\n+          try {\n+            context.output(HL7v2Message.fromModel(fetchMessage(this.client, msgId)));\n+          } catch (Exception e) {\n+            failedMessageGets.inc();\n+            LOG.warn(\n+                String.format(\n+                    \"Error fetching HL7v2 message with ID %s writing to Dead Letter \"\n+                        + \"Queue. Cause: %s Stack Trace: %s\",\n+                    msgId, e.getMessage(), Throwables.getStackTraceAsString(e)));\n+            context.output(HL7v2IO.Read.DEAD_LETTER, HealthcareIOError.of(msgId, e));\n+          }\n+        }\n+\n+        private Message fetchMessage(HealthcareApiClient client, String msgId)\n+            throws IOException, ParseException, IllegalArgumentException, InterruptedException {\n+          long startTime = System.currentTimeMillis();\n+\n+          com.google.api.services.healthcare.v1beta1.model.Message msg =", "originalCommit": "54b90b9920d1a403ad8a1be756e451d4d64f5998", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM3MTUyMg==", "url": "https://github.com/apache/beam/pull/11151#discussion_r404371522", "bodyText": "API only supports get an individual resource or list resources w/ a filter.\nOne day if we could requests a list of message IDs that would be a great optimization!\n@lastomato do you know if HL7 search or any other roadmap for API to support this?", "author": "jaketf", "createdAt": "2020-04-06T20:35:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM1NjYzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM1NzcxOA==", "url": "https://github.com/apache/beam/pull/11151#discussion_r404357718", "bodyText": "This may be a matter of style, but ingestMessages makes me think of ingesting them into the pipeline - though perhaps users will have a clear context when they write their pipelines.", "author": "pabloem", "createdAt": "2020-04-06T20:10:27Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -0,0 +1,597 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.healthcare;\n+\n+import com.google.api.services.healthcare.v1beta1.model.Message;\n+import com.google.auto.value.AutoValue;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.beam.sdk.Pipeline;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubIO;\n+import org.apache.beam.sdk.metrics.Counter;\n+import org.apache.beam.sdk.metrics.Metrics;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionTuple;\n+import org.apache.beam.sdk.values.PInput;\n+import org.apache.beam.sdk.values.POutput;\n+import org.apache.beam.sdk.values.PValue;\n+import org.apache.beam.sdk.values.TupleTag;\n+import org.apache.beam.sdk.values.TupleTagList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Throwables;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * {@link HL7v2IO} provides an API for reading from and writing to <a\n+ * href=\"https://cloud.google.com/healthcare/docs/concepts/hl7v2\">Google Cloud Healthcare HL7v2 API.\n+ * </a>\n+ *\n+ * <p>Read\n+ *\n+ * <p>HL7v2 Messages can be fetched from the HL7v2 store in two ways Message Fetching and Message\n+ * Listing.\n+ *\n+ * <p>Message Fetching\n+ *\n+ * <p>Message Fetching with {@link HL7v2IO.Read} supports use cases where you have a ${@link\n+ * PCollection} of message IDS. This is appropriate for reading the HL7v2 notifications from a\n+ * Pub/Sub subscription with {@link PubsubIO#readStrings()} or in cases where you have a manually\n+ * prepared list of messages that you need to process (e.g. in a text file read with {@link\n+ * org.apache.beam.sdk.io.TextIO}) .\n+ *\n+ * <p>Fetch Message contents from HL7v2 Store based on the {@link PCollection} of message ID strings\n+ * {@link HL7v2IO.Read.Result} where one can call {@link Read.Result#getMessages()} to retrived a\n+ * {@link PCollection} containing the successfully fetched {@link HL7v2Message}s and/or {@link\n+ * Read.Result#getFailedReads()} to retrieve a {@link PCollection} of {@link HealthcareIOError}\n+ * containing the msgID that could not be fetched and the exception as a {@link HealthcareIOError},\n+ * this can be used to write to the dead letter storage system of your choosing. This error handling\n+ * is mainly to catch scenarios where the upstream {@link PCollection} contains IDs that are not\n+ * valid or are not reachable due to permissions issues.\n+ *\n+ * <p>Message Listing Message Listing with {@link HL7v2IO.ListHL7v2Messages} supports batch use\n+ * cases where you want to process all the messages in an HL7v2 store or those matching a\n+ * filter @see <a\n+ * href=>https://cloud.google.com/healthcare/docs/reference/rest/v1beta1/projects.locations.datasets.hl7V2Stores.messages/list#query-parameters</a>\n+ * This paginates through results of a Messages.List call @see <a\n+ * href=>https://cloud.google.com/healthcare/docs/reference/rest/v1beta1/projects.locations.datasets.hl7V2Stores.messages/list</a>\n+ * and outputs directly to a {@link PCollection} of {@link HL7v2Message}. In these use cases, the\n+ * error handling similar to above is unnecessary because we are listing from the source of truth\n+ * the pipeline should fail transparently if this transform fails to paginate through all the\n+ * results.\n+ *\n+ * <p>Write\n+ *\n+ * <p>A bounded or unbounded {@link PCollection} of {@link HL7v2Message} can be ingested into an\n+ * HL7v2 store using {@link HL7v2IO#ingestMessages(String)}. This will return a {@link\n+ * HL7v2IO.Write.Result} on which you can call {@link Write.Result#getFailedInsertsWithErr()} to\n+ * retrieve a {@link PCollection} of {@link HealthcareIOError} containing the {@link HL7v2Message}\n+ * that failed to be ingested and the exception. This can be used to write to the dead letter\n+ * storage system of your chosing.\n+ *\n+ * <p>Unbounded Example:\n+ *\n+ * <pre>{@code\n+ * PipelineOptions options = ...;\n+ * Pipeline p = Pipeline.create(options);\n+ *\n+ * HL7v2IO.Read.Result readResult = p\n+ *   .apply(\n+ *     \"Read HL7v2 notifications\",\n+ *     PubSubIO.readStrings().fromTopic(options.getNotificationSubscription()))\n+ *   .apply(HL7v2IO.readAll());\n+ *\n+ * // Write errors to your favorite dead letter  queue (e.g. Pub/Sub, GCS, BigQuery)\n+ * readResult.getFailedReads().apply(\"WriteToDeadLetterQueue\", ...);\n+ *\n+ *\n+ * // Go about your happy path transformations.\n+ * PCollection<HL7v2Message> out = readResult.getMessages().apply(\"ProcessFetchedMessages\", ...);\n+ *\n+ * // Write using the Message.Ingest method of the HL7v2 REST API.\n+ * out.apply(HL7v2IO.ingestMessages(options.getOutputHL7v2Store()));\n+ *\n+ * pipeline.run();\n+ *\n+ * }***\n+ * </pre>\n+ *\n+ * <p>Bounded Read Example:\n+ *\n+ * <pre>{@code\n+ * PipelineOptions options = ...;\n+ * Pipeline p = Pipeline.create(options);\n+ *\n+ * PCollection<HL7v2Message> out = p\n+ *   .apply(\n+ *       \"List messages in HL7v2 store with filter\",\n+ *       ListHL7v2Messages(\n+ *           Collections.singletonList(options.getInputHL7v2Store()), option.getHL7v2Filter()))\n+ *    // Go about your happy path transformations.\n+ *   .apply(\"Process HL7v2 Messages\", ...);\n+ * pipeline.run().waitUntilFinish();\n+ * }***\n+ * </pre>\n+ */\n+public class HL7v2IO {\n+\n+  private static Write.Builder write(String hl7v2Store) {\n+    return new AutoValue_HL7v2IO_Write.Builder().setHL7v2Store(hl7v2Store);\n+  }\n+\n+  public static Read readAll() {\n+    return new Read();\n+  }\n+\n+  /**\n+   * Write with Messages.Ingest method. @see <a\n+   * href=https://cloud.google.com/healthcare/docs/reference/rest/v1beta1/projects.locations.datasets.hl7V2Stores.messages/ingest></a>\n+   *\n+   * @param hl7v2Store the hl 7 v 2 store\n+   * @return the write\n+   */\n+  public static Write ingestMessages(String hl7v2Store) {", "originalCommit": "54b90b9920d1a403ad8a1be756e451d4d64f5998", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM2ODkzOQ==", "url": "https://github.com/apache/beam/pull/11151#discussion_r404368939", "bodyText": "This is supposed to mirror the ingest REST API method that's used.", "author": "jaketf", "createdAt": "2020-04-06T20:30:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM1NzcxOA=="}], "type": "inlineReview"}, {"oid": "a10c894c026ef6c5f49758c1847a32436867f059", "url": "https://github.com/apache/beam/commit/a10c894c026ef6c5f49758c1847a32436867f059", "message": "Add convenience function for writing deadletter to bigquery", "committedDate": "2020-04-06T20:14:57Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM3NDQ0Mg==", "url": "https://github.com/apache/beam/pull/11151#discussion_r404374442", "bodyText": "The message listing implementation in HttpHealthcareApiClient.HL7v2MessagePages iterator will be a bottleneck here as it has to paginate through the list results in a single thread. The API does not support reading from an offset.\nThe choice for stream here should eagerly output results as each page is retrieved from the API rather than blocking until all pages have been read.", "author": "jaketf", "createdAt": "2020-04-06T20:40:36Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -0,0 +1,597 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.healthcare;\n+\n+import com.google.api.services.healthcare.v1beta1.model.Message;\n+import com.google.auto.value.AutoValue;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.beam.sdk.Pipeline;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubIO;\n+import org.apache.beam.sdk.metrics.Counter;\n+import org.apache.beam.sdk.metrics.Metrics;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionTuple;\n+import org.apache.beam.sdk.values.PInput;\n+import org.apache.beam.sdk.values.POutput;\n+import org.apache.beam.sdk.values.PValue;\n+import org.apache.beam.sdk.values.TupleTag;\n+import org.apache.beam.sdk.values.TupleTagList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Throwables;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * {@link HL7v2IO} provides an API for reading from and writing to <a\n+ * href=\"https://cloud.google.com/healthcare/docs/concepts/hl7v2\">Google Cloud Healthcare HL7v2 API.\n+ * </a>\n+ *\n+ * <p>Read\n+ *\n+ * <p>HL7v2 Messages can be fetched from the HL7v2 store in two ways Message Fetching and Message\n+ * Listing.\n+ *\n+ * <p>Message Fetching\n+ *\n+ * <p>Message Fetching with {@link HL7v2IO.Read} supports use cases where you have a ${@link\n+ * PCollection} of message IDS. This is appropriate for reading the HL7v2 notifications from a\n+ * Pub/Sub subscription with {@link PubsubIO#readStrings()} or in cases where you have a manually\n+ * prepared list of messages that you need to process (e.g. in a text file read with {@link\n+ * org.apache.beam.sdk.io.TextIO}) .\n+ *\n+ * <p>Fetch Message contents from HL7v2 Store based on the {@link PCollection} of message ID strings\n+ * {@link HL7v2IO.Read.Result} where one can call {@link Read.Result#getMessages()} to retrived a\n+ * {@link PCollection} containing the successfully fetched {@link HL7v2Message}s and/or {@link\n+ * Read.Result#getFailedReads()} to retrieve a {@link PCollection} of {@link HealthcareIOError}\n+ * containing the msgID that could not be fetched and the exception as a {@link HealthcareIOError},\n+ * this can be used to write to the dead letter storage system of your choosing. This error handling\n+ * is mainly to catch scenarios where the upstream {@link PCollection} contains IDs that are not\n+ * valid or are not reachable due to permissions issues.\n+ *\n+ * <p>Message Listing Message Listing with {@link HL7v2IO.ListHL7v2Messages} supports batch use\n+ * cases where you want to process all the messages in an HL7v2 store or those matching a\n+ * filter @see <a\n+ * href=>https://cloud.google.com/healthcare/docs/reference/rest/v1beta1/projects.locations.datasets.hl7V2Stores.messages/list#query-parameters</a>\n+ * This paginates through results of a Messages.List call @see <a\n+ * href=>https://cloud.google.com/healthcare/docs/reference/rest/v1beta1/projects.locations.datasets.hl7V2Stores.messages/list</a>\n+ * and outputs directly to a {@link PCollection} of {@link HL7v2Message}. In these use cases, the\n+ * error handling similar to above is unnecessary because we are listing from the source of truth\n+ * the pipeline should fail transparently if this transform fails to paginate through all the\n+ * results.\n+ *\n+ * <p>Write\n+ *\n+ * <p>A bounded or unbounded {@link PCollection} of {@link HL7v2Message} can be ingested into an\n+ * HL7v2 store using {@link HL7v2IO#ingestMessages(String)}. This will return a {@link\n+ * HL7v2IO.Write.Result} on which you can call {@link Write.Result#getFailedInsertsWithErr()} to\n+ * retrieve a {@link PCollection} of {@link HealthcareIOError} containing the {@link HL7v2Message}\n+ * that failed to be ingested and the exception. This can be used to write to the dead letter\n+ * storage system of your chosing.\n+ *\n+ * <p>Unbounded Example:\n+ *\n+ * <pre>{@code\n+ * PipelineOptions options = ...;\n+ * Pipeline p = Pipeline.create(options);\n+ *\n+ * HL7v2IO.Read.Result readResult = p\n+ *   .apply(\n+ *     \"Read HL7v2 notifications\",\n+ *     PubSubIO.readStrings().fromTopic(options.getNotificationSubscription()))\n+ *   .apply(HL7v2IO.readAll());\n+ *\n+ * // Write errors to your favorite dead letter  queue (e.g. Pub/Sub, GCS, BigQuery)\n+ * readResult.getFailedReads().apply(\"WriteToDeadLetterQueue\", ...);\n+ *\n+ *\n+ * // Go about your happy path transformations.\n+ * PCollection<HL7v2Message> out = readResult.getMessages().apply(\"ProcessFetchedMessages\", ...);\n+ *\n+ * // Write using the Message.Ingest method of the HL7v2 REST API.\n+ * out.apply(HL7v2IO.ingestMessages(options.getOutputHL7v2Store()));\n+ *\n+ * pipeline.run();\n+ *\n+ * }***\n+ * </pre>\n+ *\n+ * <p>Bounded Read Example:\n+ *\n+ * <pre>{@code\n+ * PipelineOptions options = ...;\n+ * Pipeline p = Pipeline.create(options);\n+ *\n+ * PCollection<HL7v2Message> out = p\n+ *   .apply(\n+ *       \"List messages in HL7v2 store with filter\",\n+ *       ListHL7v2Messages(\n+ *           Collections.singletonList(options.getInputHL7v2Store()), option.getHL7v2Filter()))\n+ *    // Go about your happy path transformations.\n+ *   .apply(\"Process HL7v2 Messages\", ...);\n+ * pipeline.run().waitUntilFinish();\n+ * }***\n+ * </pre>\n+ */\n+public class HL7v2IO {\n+\n+  private static Write.Builder write(String hl7v2Store) {\n+    return new AutoValue_HL7v2IO_Write.Builder().setHL7v2Store(hl7v2Store);\n+  }\n+\n+  public static Read readAll() {\n+    return new Read();\n+  }\n+\n+  /**\n+   * Write with Messages.Ingest method. @see <a\n+   * href=https://cloud.google.com/healthcare/docs/reference/rest/v1beta1/projects.locations.datasets.hl7V2Stores.messages/ingest></a>\n+   *\n+   * @param hl7v2Store the hl 7 v 2 store\n+   * @return the write\n+   */\n+  public static Write ingestMessages(String hl7v2Store) {\n+    return write(hl7v2Store).setWriteMethod(Write.WriteMethod.INGEST).build();\n+  }\n+\n+  // TODO add hyper links to this doc string.\n+  /**\n+   * The type Read that reads HL7v2 message contents given a PCollection of message IDs strings.\n+   *\n+   * <p>These could be sourced from any {@link PCollection} of {@link String}s but the most popular\n+   * patterns would be {@link PubsubIO#readStrings()} reading a subscription on an HL7v2 Store's\n+   * notification channel topic or using {@link ListHL7v2Messages} to list HL7v2 message IDs with an\n+   * optional filter using Ingest write method. @see <a\n+   * href=https://cloud.google.com/healthcare/docs/reference/rest/v1beta1/projects.locations.datasets.hl7V2Stores.messages/list></a>.\n+   */\n+  public static class Read extends PTransform<PCollection<String>, Read.Result> {\n+\n+    public Read() {}\n+\n+    public static class Result implements POutput, PInput {\n+      private PCollection<HL7v2Message> messages;\n+\n+      private PCollection<HealthcareIOError<String>> failedReads;\n+      PCollectionTuple pct;\n+\n+      public static Result of(PCollectionTuple pct) throws IllegalArgumentException {\n+        if (pct.getAll()\n+            .keySet()\n+            .containsAll((Collection<?>) TupleTagList.of(OUT).and(DEAD_LETTER))) {\n+          return new Result(pct);\n+        } else {\n+          throw new IllegalArgumentException(\n+              \"The PCollection tuple must have the HL7v2IO.Read.OUT \"\n+                  + \"and HL7v2IO.Read.DEAD_LETTER tuple tags\");\n+        }\n+      }\n+\n+      private Result(PCollectionTuple pct) {\n+        this.pct = pct;\n+        this.messages = pct.get(OUT).setCoder(new HL7v2MessageCoder());\n+        this.failedReads =\n+            pct.get(DEAD_LETTER).setCoder(new HealthcareIOErrorCoder<>(StringUtf8Coder.of()));\n+      }\n+\n+      public PCollection<HealthcareIOError<String>> getFailedReads() {\n+        return failedReads;\n+      }\n+\n+      public PCollection<HL7v2Message> getMessages() {\n+        return messages;\n+      }\n+\n+      @Override\n+      public Pipeline getPipeline() {\n+        return this.pct.getPipeline();\n+      }\n+\n+      @Override\n+      public Map<TupleTag<?>, PValue> expand() {\n+        return ImmutableMap.of(OUT, messages);\n+      }\n+\n+      @Override\n+      public void finishSpecifyingOutput(\n+          String transformName, PInput input, PTransform<?, ?> transform) {}\n+    }\n+\n+    /** The tag for the main output of HL7v2 Messages. */\n+    public static final TupleTag<HL7v2Message> OUT = new TupleTag<HL7v2Message>() {};\n+    /** The tag for the deadletter output of HL7v2 Messages. */\n+    public static final TupleTag<HealthcareIOError<String>> DEAD_LETTER =\n+        new TupleTag<HealthcareIOError<String>>() {};\n+\n+    @Override\n+    public Result expand(PCollection<String> input) {\n+      return input.apply(\"Fetch HL7v2 messages\", new FetchHL7v2Message());\n+    }\n+\n+    /**\n+     * DoFn to fetch a message from an Google Cloud Healthcare HL7v2 store based on msgID\n+     *\n+     * <p>This DoFn consumes a {@link PCollection} of notifications {@link String}s from the HL7v2\n+     * store, and fetches the actual {@link HL7v2Message} object based on the id in the notification\n+     * and will output a {@link PCollectionTuple} which contains the output and dead-letter {@link\n+     * PCollection}.\n+     *\n+     * <p>The {@link PCollectionTuple} output will contain the following {@link PCollection}:\n+     *\n+     * <ul>\n+     *   <li>{@link HL7v2IO.Read#OUT} - Contains all {@link PCollection} records successfully read\n+     *       from the HL7v2 store.\n+     *   <li>{@link HL7v2IO.Read#DEAD_LETTER} - Contains all {@link PCollection} of {@link\n+     *       HealthcareIOError} message IDs which failed to be fetched from the HL7v2 store, with\n+     *       error message and stacktrace.\n+     * </ul>\n+     */\n+    public static class FetchHL7v2Message extends PTransform<PCollection<String>, Result> {\n+\n+      /** Instantiates a new Fetch HL7v2 message DoFn. */\n+      public FetchHL7v2Message() {}\n+\n+      @Override\n+      public Result expand(PCollection<String> msgIds) {\n+        return new Result(\n+            msgIds.apply(\n+                ParDo.of(new FetchHL7v2Message.HL7v2MessageGetFn())\n+                    .withOutputTags(HL7v2IO.Read.OUT, TupleTagList.of(HL7v2IO.Read.DEAD_LETTER))));\n+      }\n+\n+      /** DoFn for fetching messages from the HL7v2 store with error handling. */\n+      public static class HL7v2MessageGetFn extends DoFn<String, HL7v2Message> {\n+\n+        private Counter failedMessageGets =\n+            Metrics.counter(FetchHL7v2Message.HL7v2MessageGetFn.class, \"failed-message-reads\");\n+        private static final Logger LOG =\n+            LoggerFactory.getLogger(FetchHL7v2Message.HL7v2MessageGetFn.class);\n+        private final Counter successfulHL7v2MessageGets =\n+            Metrics.counter(\n+                FetchHL7v2Message.HL7v2MessageGetFn.class, \"successful-hl7v2-message-gets\");\n+        private HealthcareApiClient client;\n+\n+        /** Instantiates a new Hl 7 v 2 message get fn. */\n+        HL7v2MessageGetFn() {}\n+\n+        /**\n+         * Instantiate healthcare client.\n+         *\n+         * @throws IOException the io exception\n+         */\n+        @Setup\n+        public void instantiateHealthcareClient() throws IOException {\n+          this.client = new HttpHealthcareApiClient();\n+        }\n+\n+        /**\n+         * Process element.\n+         *\n+         * @param context the context\n+         */\n+        @ProcessElement\n+        public void processElement(ProcessContext context) {\n+          String msgId = context.element();\n+          try {\n+            context.output(HL7v2Message.fromModel(fetchMessage(this.client, msgId)));\n+          } catch (Exception e) {\n+            failedMessageGets.inc();\n+            LOG.warn(\n+                String.format(\n+                    \"Error fetching HL7v2 message with ID %s writing to Dead Letter \"\n+                        + \"Queue. Cause: %s Stack Trace: %s\",\n+                    msgId, e.getMessage(), Throwables.getStackTraceAsString(e)));\n+            context.output(HL7v2IO.Read.DEAD_LETTER, HealthcareIOError.of(msgId, e));\n+          }\n+        }\n+\n+        private Message fetchMessage(HealthcareApiClient client, String msgId)\n+            throws IOException, ParseException, IllegalArgumentException, InterruptedException {\n+          long startTime = System.currentTimeMillis();\n+\n+          com.google.api.services.healthcare.v1beta1.model.Message msg =\n+              client.getHL7v2Message(msgId);\n+\n+          if (msg == null) {\n+            throw new IOException(String.format(\"GET request for %s returned null\", msgId));\n+          }\n+          this.successfulHL7v2MessageGets.inc();\n+          return msg;\n+        }\n+      }\n+    }\n+  }\n+\n+  /** List HL7v2 messages. */\n+  public static class ListHL7v2Messages extends PTransform<PBegin, PCollection<HL7v2Message>> {\n+    private final List<String> hl7v2Stores;\n+    private final String filter;\n+\n+    /**\n+     * Instantiates a new List HL7v2 message IDs with filter.\n+     *\n+     * @param hl7v2Stores the HL7v2 stores\n+     * @param filter the filter\n+     */\n+    ListHL7v2Messages(List<String> hl7v2Stores, String filter) {\n+      this.hl7v2Stores = hl7v2Stores;\n+      this.filter = filter;\n+    }\n+\n+    ListHL7v2Messages(List<String> hl7v2Stores) {\n+      this.hl7v2Stores = hl7v2Stores;\n+      this.filter = null;\n+    }\n+\n+    @Override\n+    public PCollection<HL7v2Message> expand(PBegin input) {\n+      return input\n+          .apply(Create.of(this.hl7v2Stores))\n+          .apply(ParDo.of(new ListHL7v2MessagesFn(this.filter)));\n+    }\n+  }\n+\n+  static class ListHL7v2MessagesFn extends DoFn<String, HL7v2Message> {\n+\n+    private final String filter;\n+    private transient HealthcareApiClient client;\n+\n+    /**\n+     * Instantiates a new List HL7v2 fn.\n+     *\n+     * @param filter the filter\n+     */\n+    ListHL7v2MessagesFn(String filter) {\n+      this.filter = filter;\n+    }\n+\n+    /**\n+     * Init client.\n+     *\n+     * @throws IOException the io exception\n+     */\n+    @Setup\n+    public void initClient() throws IOException {\n+      this.client = new HttpHealthcareApiClient();\n+    }\n+\n+    /**\n+     * List messages.\n+     *\n+     * @param context the context\n+     * @throws IOException the io exception\n+     */\n+    @ProcessElement\n+    public void listMessages(ProcessContext context) throws IOException {\n+      String hl7v2Store = context.element();\n+      // Output all elements of all pages.\n+      this.client.getHL7v2MessageStream(hl7v2Store, this.filter).forEach(context::output);", "originalCommit": "a10c894c026ef6c5f49758c1847a32436867f059", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTE1MDA1NA==", "url": "https://github.com/apache/beam/pull/11151#discussion_r409150054", "bodyText": "Yeah, this can be a performance bottleneck and this whole operation will be limited to a single machine. Usually sources need an additional level of parallelism due to being high fanout. BTW it might sense to add a Reshuffle at the end here just to allow any subsequent steps to parallelize.", "author": "chamikaramj", "createdAt": "2020-04-15T21:39:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM3NDQ0Mg=="}], "type": "inlineReview"}, {"oid": "0ea5c7d07a25e5b00c17e94309a479a24a339294", "url": "https://github.com/apache/beam/commit/0ea5c7d07a25e5b00c17e94309a479a24a339294", "message": "Address review feedback\n\n* Fix FetchHL7v2Message javadoc\n* Add observedTime to HealthcareIOErrorCoder", "committedDate": "2020-04-06T20:49:00Z", "type": "commit"}, {"oid": "d4f95b7dbcf0868e97cfd6ce90db92d53d3fbc5d", "url": "https://github.com/apache/beam/commit/d4f95b7dbcf0868e97cfd6ce90db92d53d3fbc5d", "message": "Improve API surface for users", "committedDate": "2020-04-06T21:36:28Z", "type": "commit"}, {"oid": "1bbf10c4454cbd11f968b24c2ff815c01cb36b15", "url": "https://github.com/apache/beam/commit/1bbf10c4454cbd11f968b24c2ff815c01cb36b15", "message": "ephemeral HL7v2 stores in integration tests", "committedDate": "2020-04-07T00:15:09Z", "type": "commit"}, {"oid": "c9bb521d849ce137b1e85a2a8774693c75f1a54f", "url": "https://github.com/apache/beam/commit/c9bb521d849ce137b1e85a2a8774693c75f1a54f", "message": "prepare integration tests for apache-beam-testing", "committedDate": "2020-04-07T01:10:47Z", "type": "commit"}, {"oid": "730ab3263029047ec7f790207babdaa03519b10d", "url": "https://github.com/apache/beam/commit/730ab3263029047ec7f790207babdaa03519b10d", "message": "fix docstring typos", "committedDate": "2020-04-09T01:51:09Z", "type": "commit"}, {"oid": "59dc3c240bf1982d84af41b8704b743ae1aeadcf", "url": "https://github.com/apache/beam/commit/59dc3c240bf1982d84af41b8704b743ae1aeadcf", "message": "update google_clients_version to 1.30.9", "committedDate": "2020-04-10T23:11:00Z", "type": "commit"}, {"oid": "785a593714de0662094a8a3afbfbbc6f0c171759", "url": "https://github.com/apache/beam/commit/785a593714de0662094a8a3afbfbbc6f0c171759", "message": "Merge branch 'master' into HL7v2IO", "committedDate": "2020-04-10T23:14:12Z", "type": "commit"}, {"oid": "d4d4211cc6448f878aa8b289b82beeefb254ab0a", "url": "https://github.com/apache/beam/commit/d4d4211cc6448f878aa8b289b82beeefb254ab0a", "message": "Merge branch 'master' into HL7v2IO", "committedDate": "2020-04-13T17:03:34Z", "type": "commit"}, {"oid": "efa40e640dbab90d1668afb77df7b310b0ddd55f", "url": "https://github.com/apache/beam/commit/efa40e640dbab90d1668afb77df7b310b0ddd55f", "message": "fix merge issue w/ duplicate google_oauth_clients_version", "committedDate": "2020-04-13T21:35:49Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTA1NTYzMA==", "url": "https://github.com/apache/beam/pull/11151#discussion_r409055630", "bodyText": "Memo: this uses com.google.api.client.json.gson.GsonFactory.", "author": "suztomo", "createdAt": "2020-04-15T18:42:08Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HttpHealthcareApiClient.java", "diffHunk": "@@ -0,0 +1,459 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.healthcare;\n+\n+import com.google.api.client.http.HttpHeaders;\n+import com.google.api.client.http.HttpRequest;\n+import com.google.api.client.http.HttpRequestInitializer;\n+import com.google.api.client.http.javanet.NetHttpTransport;\n+import com.google.api.client.json.JsonFactory;\n+import com.google.api.client.json.gson.GsonFactory;\n+import com.google.api.services.healthcare.v1beta1.CloudHealthcare;\n+import com.google.api.services.healthcare.v1beta1.CloudHealthcare.Projects.Locations.Datasets.Hl7V2Stores.Messages;\n+import com.google.api.services.healthcare.v1beta1.CloudHealthcareScopes;\n+import com.google.api.services.healthcare.v1beta1.model.CreateMessageRequest;\n+import com.google.api.services.healthcare.v1beta1.model.Empty;\n+import com.google.api.services.healthcare.v1beta1.model.Hl7V2Store;\n+import com.google.api.services.healthcare.v1beta1.model.HttpBody;\n+import com.google.api.services.healthcare.v1beta1.model.IngestMessageRequest;\n+import com.google.api.services.healthcare.v1beta1.model.IngestMessageResponse;\n+import com.google.api.services.healthcare.v1beta1.model.ListMessagesResponse;\n+import com.google.api.services.healthcare.v1beta1.model.Message;\n+import com.google.api.services.healthcare.v1beta1.model.SearchResourcesRequest;\n+import com.google.auth.oauth2.GoogleCredentials;\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.net.URI;\n+import java.text.ParseException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NoSuchElementException;\n+import java.util.Spliterator;\n+import java.util.Spliterators;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.extensions.gcp.util.RetryHttpRequestInitializer;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Strings;\n+\n+/**\n+ * A client that talks to the Cloud Healthcare API through HTTP requests. This client is created\n+ * mainly to encapsulate the unserializable dependencies, since most generated classes are not\n+ * serializable in the HTTP client.\n+ */\n+public class HttpHealthcareApiClient<T> implements HealthcareApiClient, Serializable {\n+\n+  private transient CloudHealthcare client;\n+\n+  /**\n+   * Instantiates a new Http healthcare api client.\n+   *\n+   * @throws IOException the io exception\n+   */\n+  public HttpHealthcareApiClient() throws IOException {\n+    initClient();\n+  }\n+\n+  /**\n+   * Instantiates a new Http healthcare api client.\n+   *\n+   * @param client the client\n+   * @throws IOException the io exception\n+   */\n+  public HttpHealthcareApiClient(CloudHealthcare client) throws IOException {\n+    this.client = client;\n+    initClient();\n+  }\n+\n+  @VisibleForTesting\n+  static <T, X extends Collection<T>> Stream<T> flattenIteratorCollectionsToStream(\n+      Iterator<X> iterator) {\n+    Spliterator<Collection<T>> spliterator = Spliterators.spliteratorUnknownSize(iterator, 0);\n+    return StreamSupport.stream(spliterator, false).flatMap(Collection::stream);\n+  }\n+\n+  public JsonFactory getJsonFactory() {\n+    return this.client.getJsonFactory();\n+  }\n+\n+  @Override\n+  public Hl7V2Store createHL7v2Store(String dataset, String name) throws IOException {\n+    Hl7V2Store store = new Hl7V2Store();\n+    return client\n+        .projects()\n+        .locations()\n+        .datasets()\n+        .hl7V2Stores()\n+        .create(dataset, store)\n+        .setHl7V2StoreId(name)\n+        .execute();\n+  }\n+\n+  @Override\n+  public Empty deleteHL7v2Store(String name) throws IOException {\n+    return client.projects().locations().datasets().hl7V2Stores().delete(name).execute();\n+  }\n+\n+  @Override\n+  public ListMessagesResponse makeHL7v2ListRequest(\n+      String hl7v2Store, @Nullable String filter, @Nullable String pageToken) throws IOException {\n+\n+    Messages.List baseRequest =\n+        client\n+            .projects()\n+            .locations()\n+            .datasets()\n+            .hl7V2Stores()\n+            .messages()\n+            .list(hl7v2Store)\n+            .set(\"view\", \"full\")\n+            .setPageToken(pageToken);\n+\n+    if (Strings.isNullOrEmpty(filter)) {\n+      return baseRequest.execute();\n+    } else {\n+      return baseRequest.setFilter(filter).execute();\n+    }\n+  }\n+\n+  /**\n+   * Gets message id page iterator.\n+   *\n+   * @param hl7v2Store the HL7v2 store\n+   * @return the message id page iterator\n+   * @throws IOException the io exception\n+   */\n+  @Override\n+  public Stream<HL7v2Message> getHL7v2MessageStream(String hl7v2Store) throws IOException {\n+    return getHL7v2MessageStream(hl7v2Store, null);\n+  }\n+\n+  /**\n+   * Get a {@link Stream} of message IDs from flattening the pages of a new {@link\n+   * HL7v2MessagePages}.\n+   *\n+   * @param hl7v2Store the HL7v2 store\n+   * @param filter the filter\n+   * @return the message id Stream\n+   * @throws IOException the io exception\n+   */\n+  @Override\n+  public Stream<HL7v2Message> getHL7v2MessageStream(String hl7v2Store, @Nullable String filter)\n+      throws IOException {\n+    Iterator<List<HL7v2Message>> iterator =\n+        new HL7v2MessagePages(this, hl7v2Store, filter).iterator();\n+    return flattenIteratorCollectionsToStream(iterator);\n+  }\n+\n+  /**\n+   * Gets HL7v2 message.\n+   *\n+   * @param msgName the msg name\n+   * @return the message\n+   * @throws IOException the io exception\n+   * @throws ParseException the parse exception\n+   */\n+  @Override\n+  public Message getHL7v2Message(String msgName) throws IOException {\n+    Message msg =\n+        client.projects().locations().datasets().hl7V2Stores().messages().get(msgName).execute();\n+    if (msg == null) {\n+      throw new IOException(String.format(\"Couldn't find message: %s.\", msgName));\n+    }\n+    return msg;\n+  }\n+\n+  @Override\n+  public Empty deleteHL7v2Message(String msgName) throws IOException {\n+    return client\n+        .projects()\n+        .locations()\n+        .datasets()\n+        .hl7V2Stores()\n+        .messages()\n+        .delete(msgName)\n+        .execute();\n+  }\n+\n+  /**\n+   * Gets HL7v2 store.\n+   *\n+   * @param storeName the store name\n+   * @return the HL7v2 store\n+   * @throws IOException the io exception\n+   */\n+  @Override\n+  public Hl7V2Store getHL7v2Store(String storeName) throws IOException {\n+    return client.projects().locations().datasets().hl7V2Stores().get(storeName).execute();\n+  }\n+\n+  @Override\n+  public IngestMessageResponse ingestHL7v2Message(String hl7v2Store, Message msg)\n+      throws IOException {\n+    IngestMessageRequest ingestMessageRequest = new IngestMessageRequest();\n+    ingestMessageRequest.setMessage(msg);\n+    return client\n+        .projects()\n+        .locations()\n+        .datasets()\n+        .hl7V2Stores()\n+        .messages()\n+        .ingest(hl7v2Store, ingestMessageRequest)\n+        .execute();\n+  }\n+\n+  @Override\n+  public HttpBody fhirSearch(String fhirStore, SearchResourcesRequest query) throws IOException {\n+    return client\n+        .projects()\n+        .locations()\n+        .datasets()\n+        .fhirStores()\n+        .fhir()\n+        .search(fhirStore, query)\n+        .execute();\n+  }\n+\n+  @Override\n+  public Message createHL7v2Message(String hl7v2Store, Message msg) throws IOException {\n+    CreateMessageRequest createMessageRequest = new CreateMessageRequest();\n+    createMessageRequest.setMessage(msg);\n+    return client\n+        .projects()\n+        .locations()\n+        .datasets()\n+        .hl7V2Stores()\n+        .messages()\n+        .create(hl7v2Store, createMessageRequest)\n+        .execute();\n+  }\n+\n+  @Override\n+  public HttpBody createFhirResource(String fhirStore, String type, HttpBody body)\n+      throws IOException {\n+    return client\n+        .projects()\n+        .locations()\n+        .datasets()\n+        .fhirStores()\n+        .fhir()\n+        .create(fhirStore, type, body)\n+        .execute();\n+  }\n+\n+  @Override\n+  public HttpBody executeFhirBundle(String fhirStore, HttpBody bundle) throws IOException {\n+    return client\n+        .projects()\n+        .locations()\n+        .datasets()\n+        .fhirStores()\n+        .fhir()\n+        .executeBundle(fhirStore, bundle)\n+        .execute();\n+  }\n+\n+  @Override\n+  public HttpBody listFHIRResourceForPatient(String fhirStore, String patient) throws IOException {\n+    return client\n+        .projects()\n+        .locations()\n+        .datasets()\n+        .fhirStores()\n+        .fhir()\n+        .patientEverything(patient)\n+        .execute();\n+  }\n+\n+  @Override\n+  public HttpBody readFHIRResource(String fhirStore, String resource) throws IOException {\n+    return client.projects().locations().datasets().fhirStores().fhir().read(resource).execute();\n+  }\n+\n+  private static class AuthenticatedRetryInitializer extends RetryHttpRequestInitializer {\n+    GoogleCredentials credentials;\n+\n+    public AuthenticatedRetryInitializer(GoogleCredentials credentials) {\n+      super();\n+      this.credentials = credentials;\n+    }\n+\n+    @Override\n+    public void initialize(HttpRequest request) throws IOException {\n+      super.initialize(request);\n+      if (!credentials.hasRequestMetadata()) {\n+        return;\n+      }\n+      HttpHeaders requestHeaders = request.getHeaders();\n+      requestHeaders.setUserAgent(\"apache-beam-hl7v2-io\");\n+      URI uri = null;\n+      if (request.getUrl() != null) {\n+        uri = request.getUrl().toURI();\n+      }\n+      Map<String, List<String>> credentialHeaders = credentials.getRequestMetadata(uri);\n+      if (credentialHeaders == null) {\n+        return;\n+      }\n+      for (Map.Entry<String, List<String>> entry : credentialHeaders.entrySet()) {\n+        String headerName = entry.getKey();\n+        List<String> requestValues = new ArrayList<>(entry.getValue());\n+        requestHeaders.put(headerName, requestValues);\n+      }\n+    }\n+  }\n+\n+  private void initClient() throws IOException {\n+    // Create a HttpRequestInitializer, which will provide a baseline configuration to all requests.\n+    // HttpRequestInitializer requestInitializer = new RetryHttpRequestInitializer();\n+    // GoogleCredentials credentials = GoogleCredentials.getApplicationDefault();\n+    HttpRequestInitializer requestInitializer =\n+        new AuthenticatedRetryInitializer(\n+            GoogleCredentials.getApplicationDefault()\n+                .createScoped(CloudHealthcareScopes.CLOUD_PLATFORM));\n+\n+    client =\n+        new CloudHealthcare.Builder(new NetHttpTransport(), new GsonFactory(), requestInitializer)", "originalCommit": "efa40e640dbab90d1668afb77df7b310b0ddd55f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTA1NzY5OA==", "url": "https://github.com/apache/beam/pull/11151#discussion_r409057698", "bodyText": "I see CloudHealthcare.Builder accepts JacksonFactory.\nhttps://github.com/googleapis/google-api-java-client-services/blob/master/clients/google-api-services-healthcare/v1beta1/1.30.1/com/google/api/services/healthcare/v1beta1/CloudHealthcare.java#L16349", "author": "suztomo", "createdAt": "2020-04-15T18:45:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTA1NTYzMA=="}], "type": "inlineReview"}, {"oid": "cacad23f9c871939aabaee5fa1f6de1ee66207fb", "url": "https://github.com/apache/beam/commit/cacad23f9c871939aabaee5fa1f6de1ee66207fb", "message": "Use Jackson", "committedDate": "2020-04-15T19:02:24Z", "type": "commit"}, {"oid": "5f453d528ed2b3d428fd6726a4cbe96abd265515", "url": "https://github.com/apache/beam/commit/5f453d528ed2b3d428fd6726a4cbe96abd265515", "message": "spotlessApply", "committedDate": "2020-04-15T20:19:46Z", "type": "commit"}, {"oid": "da3d3f1025801099ec117a33370f5c8d710ce970", "url": "https://github.com/apache/beam/commit/da3d3f1025801099ec117a33370f5c8d710ce970", "message": "add TODO to add support for batch API in the future once available", "committedDate": "2020-04-15T22:20:05Z", "type": "commit"}, {"oid": "a0db4e8a52c0e3d3c5cd1203886d3798226a6331", "url": "https://github.com/apache/beam/commit/a0db4e8a52c0e3d3c5cd1203886d3798226a6331", "message": "add reshuffle to increase downstream paralelism", "committedDate": "2020-04-15T22:23:41Z", "type": "commit"}, {"oid": "c50df5f3c66627172b7d75cea5ba0971ef83da57", "url": "https://github.com/apache/beam/commit/c50df5f3c66627172b7d75cea5ba0971ef83da57", "message": "add setCoder before reshuffle", "committedDate": "2020-04-15T22:33:53Z", "type": "commit"}]}