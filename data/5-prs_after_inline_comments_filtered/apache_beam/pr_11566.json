{"pr_number": 11566, "pr_title": "[BEAM-9723] Add DLP integration transforms", "pr_createdAt": "2020-04-29T09:41:32Z", "pr_url": "https://github.com/apache/beam/pull/11566", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzA1ODc1Ng==", "url": "https://github.com/apache/beam/pull/11566#discussion_r423058756", "bodyText": "@santhh Can you give me a hand here? I'm getting IllegalArgumentException here because of the OutputReceiver being parametrized with Iterable instead of KV", "author": "mwalenia", "createdAt": "2020-05-11T13:57:25Z", "path": "sdks/java/extensions/ml/src/main/java/org/apache/beam/sdk/extensions/ml/BatchRequestForDLP.java", "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.ml;\n+\n+import static java.nio.charset.StandardCharsets.UTF_8;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.metrics.Counter;\n+import org.apache.beam.sdk.metrics.Metrics;\n+import org.apache.beam.sdk.state.BagState;\n+import org.apache.beam.sdk.state.StateSpec;\n+import org.apache.beam.sdk.state.StateSpecs;\n+import org.apache.beam.sdk.state.TimeDomain;\n+import org.apache.beam.sdk.state.Timer;\n+import org.apache.beam.sdk.state.TimerSpec;\n+import org.apache.beam.sdk.state.TimerSpecs;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.windowing.BoundedWindow;\n+import org.apache.beam.sdk.values.KV;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * DoFn batching the input PCollection into bigger requests in order to better utilize the Cloud DLP\n+ * service.\n+ */\n+@Experimental\n+class BatchRequestForDLP extends DoFn<KV<String, String>, KV<String, String>> {\n+  public static final Logger LOG = LoggerFactory.getLogger(BatchRequestForDLP.class);\n+  private final Counter numberOfElementsBagged =\n+      Metrics.counter(BatchRequestForDLP.class, \"numberOfElementsBagged\");\n+  private final Integer batchSize;\n+\n+  public BatchRequestForDLP(Integer batchSize) {\n+    this.batchSize = batchSize;\n+  }\n+\n+  @StateId(\"elementsBag\")\n+  private final StateSpec<BagState<KV<String, String>>> elementsBag = StateSpecs.bag();\n+\n+  @TimerId(\"eventTimer\")\n+  private final TimerSpec eventTimer = TimerSpecs.timer(TimeDomain.EVENT_TIME);\n+\n+  @ProcessElement\n+  public void process(\n+      @Element KV<String, String> element,\n+      @StateId(\"elementsBag\") BagState<KV<String, String>> elementsBag,\n+      @TimerId(\"eventTimer\") Timer eventTimer,\n+      BoundedWindow w) {\n+    elementsBag.add(element);\n+    eventTimer.set(w.maxTimestamp());\n+  }\n+\n+  @OnTimer(\"eventTimer\")\n+  public void onTimer(\n+      @StateId(\"elementsBag\") BagState<KV<String, String>> elementsBag,\n+      OutputReceiver<KV<String, Iterable<String>>> output) {", "originalCommit": "59525abad6224ebb5ff63954a56385a3e0db81a0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjgzMTYxOQ==", "url": "https://github.com/apache/beam/pull/11566#discussion_r426831619", "bodyText": "Is there a guarantee that at least one element will be in the elementsBag iterator or is there a chance for a NoSuchElementsException on the next() call?", "author": "tysonjh", "createdAt": "2020-05-18T18:57:37Z", "path": "sdks/java/extensions/ml/src/main/java/org/apache/beam/sdk/extensions/ml/BatchRequestForDLP.java", "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.ml;\n+\n+import com.google.privacy.dlp.v2.Table;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.metrics.Counter;\n+import org.apache.beam.sdk.metrics.Metrics;\n+import org.apache.beam.sdk.state.BagState;\n+import org.apache.beam.sdk.state.StateSpec;\n+import org.apache.beam.sdk.state.StateSpecs;\n+import org.apache.beam.sdk.state.TimeDomain;\n+import org.apache.beam.sdk.state.Timer;\n+import org.apache.beam.sdk.state.TimerSpec;\n+import org.apache.beam.sdk.state.TimerSpecs;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.windowing.BoundedWindow;\n+import org.apache.beam.sdk.values.KV;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * DoFn batching the input PCollection into bigger requests in order to better utilize the Cloud DLP\n+ * service.\n+ */\n+@Experimental\n+class BatchRequestForDLP extends DoFn<KV<String, Table.Row>, KV<String, Iterable<Table.Row>>> {\n+  public static final Logger LOG = LoggerFactory.getLogger(BatchRequestForDLP.class);\n+\n+  private final Counter numberOfRowsBagged =\n+      Metrics.counter(BatchRequestForDLP.class, \"numberOfRowsBagged\");\n+  private final Integer batchSize;\n+\n+  @StateId(\"elementsBag\")\n+  private final StateSpec<BagState<KV<String, Table.Row>>> elementsBag = StateSpecs.bag();\n+\n+  @TimerId(\"eventTimer\")\n+  private final TimerSpec eventTimer = TimerSpecs.timer(TimeDomain.EVENT_TIME);\n+\n+  public BatchRequestForDLP(Integer batchSize) {\n+    this.batchSize = batchSize;\n+  }\n+\n+  @ProcessElement\n+  public void process(\n+      @Element KV<String, Table.Row> element,\n+      @StateId(\"elementsBag\") BagState<KV<String, Table.Row>> elementsBag,\n+      @TimerId(\"eventTimer\") Timer eventTimer,\n+      BoundedWindow w) {\n+    elementsBag.add(element);\n+    eventTimer.set(w.maxTimestamp());\n+  }\n+\n+  @OnTimer(\"eventTimer\")\n+  public void onTimer(\n+      @StateId(\"elementsBag\") BagState<KV<String, Table.Row>> elementsBag,\n+      OutputReceiver<KV<String, Iterable<Table.Row>>> output) {\n+    String key = elementsBag.read().iterator().next().getKey();", "originalCommit": "e4984b7c3112e18a15b5cee76af7ae9398f76fa8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzM3NzQyOQ==", "url": "https://github.com/apache/beam/pull/11566#discussion_r427377429", "bodyText": "I think a check (hasNext) will be helpful. I don't see there will be a case for no such element but possible.", "author": "santhh", "createdAt": "2020-05-19T15:06:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjgzMTYxOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTIxMzY0Ng==", "url": "https://github.com/apache/beam/pull/11566#discussion_r429213646", "bodyText": "Ok, done!", "author": "mwalenia", "createdAt": "2020-05-22T12:20:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjgzMTYxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkwMTgxMQ==", "url": "https://github.com/apache/beam/pull/11566#discussion_r426901811", "bodyText": "Nit: Can you move this to the first line of the if block to avoid splitting the code like this? Also it would be nice to have the unit in the log message for the bufferSize (e.g bytes).", "author": "tysonjh", "createdAt": "2020-05-18T21:25:53Z", "path": "sdks/java/extensions/ml/src/main/java/org/apache/beam/sdk/extensions/ml/BatchRequestForDLP.java", "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.ml;\n+\n+import com.google.privacy.dlp.v2.Table;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.metrics.Counter;\n+import org.apache.beam.sdk.metrics.Metrics;\n+import org.apache.beam.sdk.state.BagState;\n+import org.apache.beam.sdk.state.StateSpec;\n+import org.apache.beam.sdk.state.StateSpecs;\n+import org.apache.beam.sdk.state.TimeDomain;\n+import org.apache.beam.sdk.state.Timer;\n+import org.apache.beam.sdk.state.TimerSpec;\n+import org.apache.beam.sdk.state.TimerSpecs;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.windowing.BoundedWindow;\n+import org.apache.beam.sdk.values.KV;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * DoFn batching the input PCollection into bigger requests in order to better utilize the Cloud DLP\n+ * service.\n+ */\n+@Experimental\n+class BatchRequestForDLP extends DoFn<KV<String, Table.Row>, KV<String, Iterable<Table.Row>>> {\n+  public static final Logger LOG = LoggerFactory.getLogger(BatchRequestForDLP.class);\n+\n+  private final Counter numberOfRowsBagged =\n+      Metrics.counter(BatchRequestForDLP.class, \"numberOfRowsBagged\");\n+  private final Integer batchSize;\n+\n+  @StateId(\"elementsBag\")\n+  private final StateSpec<BagState<KV<String, Table.Row>>> elementsBag = StateSpecs.bag();\n+\n+  @TimerId(\"eventTimer\")\n+  private final TimerSpec eventTimer = TimerSpecs.timer(TimeDomain.EVENT_TIME);\n+\n+  public BatchRequestForDLP(Integer batchSize) {\n+    this.batchSize = batchSize;\n+  }\n+\n+  @ProcessElement\n+  public void process(\n+      @Element KV<String, Table.Row> element,\n+      @StateId(\"elementsBag\") BagState<KV<String, Table.Row>> elementsBag,\n+      @TimerId(\"eventTimer\") Timer eventTimer,\n+      BoundedWindow w) {\n+    elementsBag.add(element);\n+    eventTimer.set(w.maxTimestamp());\n+  }\n+\n+  @OnTimer(\"eventTimer\")\n+  public void onTimer(\n+      @StateId(\"elementsBag\") BagState<KV<String, Table.Row>> elementsBag,\n+      OutputReceiver<KV<String, Iterable<Table.Row>>> output) {\n+    String key = elementsBag.read().iterator().next().getKey();\n+    AtomicInteger bufferSize = new AtomicInteger();\n+    List<Table.Row> rows = new ArrayList<>();\n+    elementsBag\n+        .read()\n+        .forEach(\n+            element -> {\n+              int elementSize = element.getValue().getSerializedSize();\n+              boolean clearBuffer = bufferSize.intValue() + elementSize > batchSize;\n+              if (clearBuffer) {\n+                numberOfRowsBagged.inc(rows.size());\n+                LOG.debug(\"Clear Buffer {} , Key {}\", bufferSize.intValue(), element.getKey());", "originalCommit": "e4984b7c3112e18a15b5cee76af7ae9398f76fa8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODYwNTU2MA==", "url": "https://github.com/apache/beam/pull/11566#discussion_r428605560", "bodyText": "Sure, I'll move it and add units. Thanks!", "author": "mwalenia", "createdAt": "2020-05-21T11:51:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkwMTgxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkwNDY5Mw==", "url": "https://github.com/apache/beam/pull/11566#discussion_r426904693", "bodyText": "Nit: This log message would be more clear if it said the action being taken like.. 'Outputting remaining {} rows'.", "author": "tysonjh", "createdAt": "2020-05-18T21:32:25Z", "path": "sdks/java/extensions/ml/src/main/java/org/apache/beam/sdk/extensions/ml/BatchRequestForDLP.java", "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.ml;\n+\n+import com.google.privacy.dlp.v2.Table;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.metrics.Counter;\n+import org.apache.beam.sdk.metrics.Metrics;\n+import org.apache.beam.sdk.state.BagState;\n+import org.apache.beam.sdk.state.StateSpec;\n+import org.apache.beam.sdk.state.StateSpecs;\n+import org.apache.beam.sdk.state.TimeDomain;\n+import org.apache.beam.sdk.state.Timer;\n+import org.apache.beam.sdk.state.TimerSpec;\n+import org.apache.beam.sdk.state.TimerSpecs;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.windowing.BoundedWindow;\n+import org.apache.beam.sdk.values.KV;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * DoFn batching the input PCollection into bigger requests in order to better utilize the Cloud DLP\n+ * service.\n+ */\n+@Experimental\n+class BatchRequestForDLP extends DoFn<KV<String, Table.Row>, KV<String, Iterable<Table.Row>>> {\n+  public static final Logger LOG = LoggerFactory.getLogger(BatchRequestForDLP.class);\n+\n+  private final Counter numberOfRowsBagged =\n+      Metrics.counter(BatchRequestForDLP.class, \"numberOfRowsBagged\");\n+  private final Integer batchSize;\n+\n+  @StateId(\"elementsBag\")\n+  private final StateSpec<BagState<KV<String, Table.Row>>> elementsBag = StateSpecs.bag();\n+\n+  @TimerId(\"eventTimer\")\n+  private final TimerSpec eventTimer = TimerSpecs.timer(TimeDomain.EVENT_TIME);\n+\n+  public BatchRequestForDLP(Integer batchSize) {\n+    this.batchSize = batchSize;\n+  }\n+\n+  @ProcessElement\n+  public void process(\n+      @Element KV<String, Table.Row> element,\n+      @StateId(\"elementsBag\") BagState<KV<String, Table.Row>> elementsBag,\n+      @TimerId(\"eventTimer\") Timer eventTimer,\n+      BoundedWindow w) {\n+    elementsBag.add(element);\n+    eventTimer.set(w.maxTimestamp());\n+  }\n+\n+  @OnTimer(\"eventTimer\")\n+  public void onTimer(\n+      @StateId(\"elementsBag\") BagState<KV<String, Table.Row>> elementsBag,\n+      OutputReceiver<KV<String, Iterable<Table.Row>>> output) {\n+    String key = elementsBag.read().iterator().next().getKey();\n+    AtomicInteger bufferSize = new AtomicInteger();\n+    List<Table.Row> rows = new ArrayList<>();\n+    elementsBag\n+        .read()\n+        .forEach(\n+            element -> {\n+              int elementSize = element.getValue().getSerializedSize();\n+              boolean clearBuffer = bufferSize.intValue() + elementSize > batchSize;\n+              if (clearBuffer) {\n+                numberOfRowsBagged.inc(rows.size());\n+                LOG.debug(\"Clear Buffer {} , Key {}\", bufferSize.intValue(), element.getKey());\n+                output.output(KV.of(element.getKey(), rows));\n+                rows.clear();\n+                bufferSize.set(0);\n+              }\n+              rows.add(element.getValue());\n+              bufferSize.getAndAdd(element.getValue().getSerializedSize());\n+            });\n+    if (!rows.isEmpty()) {\n+      LOG.debug(\"Remaining rows {}\", rows.size());", "originalCommit": "e4984b7c3112e18a15b5cee76af7ae9398f76fa8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTIxMzcwOQ==", "url": "https://github.com/apache/beam/pull/11566#discussion_r429213709", "bodyText": "Done, thanks", "author": "mwalenia", "createdAt": "2020-05-22T12:20:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkwNDY5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkxNTAzNA==", "url": "https://github.com/apache/beam/pull/11566#discussion_r426915034", "bodyText": "Can you use DLP_PAYLOAD_LIMIT instead?", "author": "tysonjh", "createdAt": "2020-05-18T21:57:28Z", "path": "sdks/java/extensions/ml/src/test/java/org/apache/beam/sdk/extensions/ml/DLPTextOperationsIT.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.ml;\n+\n+import static org.junit.Assert.assertTrue;\n+\n+import com.google.privacy.dlp.v2.CharacterMaskConfig;\n+import com.google.privacy.dlp.v2.DeidentifyConfig;\n+import com.google.privacy.dlp.v2.DeidentifyContentResponse;\n+import com.google.privacy.dlp.v2.Finding;\n+import com.google.privacy.dlp.v2.InfoType;\n+import com.google.privacy.dlp.v2.InfoTypeTransformations;\n+import com.google.privacy.dlp.v2.InspectConfig;\n+import com.google.privacy.dlp.v2.InspectContentResponse;\n+import com.google.privacy.dlp.v2.Likelihood;\n+import com.google.privacy.dlp.v2.PrimitiveTransformation;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.beam.sdk.extensions.gcp.options.GcpOptions;\n+import org.apache.beam.sdk.testing.PAssert;\n+import org.apache.beam.sdk.testing.TestPipeline;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.JUnit4;\n+\n+@RunWith(JUnit4.class)\n+public class DLPTextOperationsIT {\n+  @Rule public TestPipeline testPipeline = TestPipeline.create();\n+\n+  private static final String IDENTIFYING_TEXT = \"mary.sue@example.com\";\n+  private static InfoType emailAddress = InfoType.newBuilder().setName(\"EMAIL_ADDRESS\").build();\n+  private static final InspectConfig inspectConfig =\n+      InspectConfig.newBuilder()\n+          .addInfoTypes(emailAddress)\n+          .setMinLikelihood(Likelihood.LIKELY)\n+          .build();\n+\n+  @Test\n+  public void inspectsText() {\n+    String projectId = testPipeline.getOptions().as(GcpOptions.class).getProject();\n+    PCollection<KV<String, InspectContentResponse>> inspectionResult =\n+        testPipeline\n+            .apply(Create.of(KV.of(\"\", IDENTIFYING_TEXT)))\n+            .apply(\n+                DLPInspectText.newBuilder()\n+                    .setBatchSize(52400)", "originalCommit": "e4984b7c3112e18a15b5cee76af7ae9398f76fa8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzM4NDc3NQ==", "url": "https://github.com/apache/beam/pull/11566#discussion_r427384775", "bodyText": "or the batch size should work. Also 52400 is the max allowed. So we should use something like 52000 for default as there will be some bytes for header.", "author": "santhh", "createdAt": "2020-05-19T15:16:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkxNTAzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODYwNjU4Nw==", "url": "https://github.com/apache/beam/pull/11566#discussion_r428606587", "bodyText": "@santhh Is it 52400 or 524000? It should be the latter, since we're setting the limit to 524 kb, I think.", "author": "mwalenia", "createdAt": "2020-05-21T11:53:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkxNTAzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTIxMzgxMg==", "url": "https://github.com/apache/beam/pull/11566#discussion_r429213812", "bodyText": "@santhh Can you weigh in here?", "author": "mwalenia", "createdAt": "2020-05-22T12:20:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkxNTAzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkxNTY2MA==", "url": "https://github.com/apache/beam/pull/11566#discussion_r426915660", "bodyText": "Having the units in the name is helpful when the type is non-descriptive. Where did this number come from?", "author": "tysonjh", "createdAt": "2020-05-18T21:59:11Z", "path": "sdks/java/extensions/ml/src/main/java/org/apache/beam/sdk/extensions/ml/DLPReidentifyText.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.ml;\n+\n+import com.google.auto.value.AutoValue;\n+import com.google.cloud.dlp.v2.DlpServiceClient;\n+import com.google.privacy.dlp.v2.ContentItem;\n+import com.google.privacy.dlp.v2.DeidentifyConfig;\n+import com.google.privacy.dlp.v2.FieldId;\n+import com.google.privacy.dlp.v2.InspectConfig;\n+import com.google.privacy.dlp.v2.ProjectName;\n+import com.google.privacy.dlp.v2.ReidentifyContentRequest;\n+import com.google.privacy.dlp.v2.ReidentifyContentResponse;\n+import com.google.privacy.dlp.v2.Table;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionView;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A {@link PTransform} connecting to Cloud DLP and inspecting text for identifying data according\n+ * to provided settings.\n+ *\n+ * <p>Either inspectTemplateName (String) or inspectConfig {@link InspectConfig} need to be set, the\n+ * same goes for reidentifyTemplateName or reidentifyConfig.\n+ *\n+ * <p>Batch size defines how big are batches sent to DLP at once in bytes.\n+ */\n+@Experimental\n+@AutoValue\n+public abstract class DLPReidentifyText\n+    extends PTransform<\n+        PCollection<KV<String, String>>, PCollection<KV<String, ReidentifyContentResponse>>> {\n+\n+  public static final Logger LOG = LoggerFactory.getLogger(DLPInspectText.class);\n+\n+  public static final Integer DLP_PAYLOAD_LIMIT = 52400;", "originalCommit": "e4984b7c3112e18a15b5cee76af7ae9398f76fa8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzM4MzMzNQ==", "url": "https://github.com/apache/beam/pull/11566#discussion_r427383335", "bodyText": "Actually this can be taken out. There is a validation that it never goes above 524KB/payload before calling the API. With state/timer based approach,  it's not needed.", "author": "santhh", "createdAt": "2020-05-19T15:14:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkxNTY2MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzg4MDMwMw==", "url": "https://github.com/apache/beam/pull/11566#discussion_r427880303", "bodyText": "I agree with Tyson's comment about early validation, I think I'll leave the limits in here.", "author": "mwalenia", "createdAt": "2020-05-20T09:45:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkxNTY2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkyMzIwMA==", "url": "https://github.com/apache/beam/pull/11566#discussion_r426923200", "bodyText": "Please add a comment. It would also be beneficial to name this variable with a unit like batchSizeBytes.", "author": "tysonjh", "createdAt": "2020-05-18T22:19:28Z", "path": "sdks/java/extensions/ml/src/main/java/org/apache/beam/sdk/extensions/ml/BatchRequestForDLP.java", "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.ml;\n+\n+import com.google.privacy.dlp.v2.Table;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.metrics.Counter;\n+import org.apache.beam.sdk.metrics.Metrics;\n+import org.apache.beam.sdk.state.BagState;\n+import org.apache.beam.sdk.state.StateSpec;\n+import org.apache.beam.sdk.state.StateSpecs;\n+import org.apache.beam.sdk.state.TimeDomain;\n+import org.apache.beam.sdk.state.Timer;\n+import org.apache.beam.sdk.state.TimerSpec;\n+import org.apache.beam.sdk.state.TimerSpecs;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.windowing.BoundedWindow;\n+import org.apache.beam.sdk.values.KV;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * DoFn batching the input PCollection into bigger requests in order to better utilize the Cloud DLP\n+ * service.\n+ */\n+@Experimental\n+class BatchRequestForDLP extends DoFn<KV<String, Table.Row>, KV<String, Iterable<Table.Row>>> {\n+  public static final Logger LOG = LoggerFactory.getLogger(BatchRequestForDLP.class);\n+\n+  private final Counter numberOfRowsBagged =\n+      Metrics.counter(BatchRequestForDLP.class, \"numberOfRowsBagged\");\n+  private final Integer batchSize;\n+\n+  @StateId(\"elementsBag\")\n+  private final StateSpec<BagState<KV<String, Table.Row>>> elementsBag = StateSpecs.bag();\n+\n+  @TimerId(\"eventTimer\")\n+  private final TimerSpec eventTimer = TimerSpecs.timer(TimeDomain.EVENT_TIME);\n+\n+  public BatchRequestForDLP(Integer batchSize) {", "originalCommit": "e4984b7c3112e18a15b5cee76af7ae9398f76fa8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY4MzAxOQ==", "url": "https://github.com/apache/beam/pull/11566#discussion_r427683019", "bodyText": "+1", "author": "santhh", "createdAt": "2020-05-20T00:58:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkyMzIwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkyMzc2NA==", "url": "https://github.com/apache/beam/pull/11566#discussion_r426923764", "bodyText": "An incorrect configuration should result in an exception at pipeline construction time if possible. The sooner an exception can be raised to the user the better (e.g. pipeline construction vs. pipeline runtime).\nA couple options are,\n\nAdd precondition checks into the Builder for the AutoValue. You could do this by implementing your own public DLPDeidentifyText build() method the checks preconditions and then calls a generated autoBuild method.\nAdd precondition checks into the constructor of the DoFn.", "author": "tysonjh", "createdAt": "2020-05-18T22:20:49Z", "path": "sdks/java/extensions/ml/src/main/java/org/apache/beam/sdk/extensions/ml/DLPDeidentifyText.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.ml;\n+\n+import com.google.auto.value.AutoValue;\n+import com.google.cloud.dlp.v2.DlpServiceClient;\n+import com.google.privacy.dlp.v2.ContentItem;\n+import com.google.privacy.dlp.v2.DeidentifyConfig;\n+import com.google.privacy.dlp.v2.DeidentifyContentRequest;\n+import com.google.privacy.dlp.v2.DeidentifyContentResponse;\n+import com.google.privacy.dlp.v2.FieldId;\n+import com.google.privacy.dlp.v2.InspectConfig;\n+import com.google.privacy.dlp.v2.ProjectName;\n+import com.google.privacy.dlp.v2.Table;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionView;\n+\n+/**\n+ * A {@link PTransform} connecting to Cloud DLP and deidentifying text according to provided\n+ * settings. The transform supports both CSV formatted input data and unstructured input.\n+ *\n+ * <p>If the csvHeader property is set, csvDelimiter also should be, else the results will be\n+ * incorrect. If csvHeader is not set, input is assumed to be unstructured.", "originalCommit": "e4984b7c3112e18a15b5cee76af7ae9398f76fa8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTIxMzk3NQ==", "url": "https://github.com/apache/beam/pull/11566#discussion_r429213975", "bodyText": "Thanks for this remark, I added early validation to the code.", "author": "mwalenia", "createdAt": "2020-05-22T12:21:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkyMzc2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkyNjc2MQ==", "url": "https://github.com/apache/beam/pull/11566#discussion_r426926761", "bodyText": "Since the delimiter is configurable, what about dropping the 'csv'? You could add details in the comments as to where the delimiter applies and the default value.", "author": "tysonjh", "createdAt": "2020-05-18T22:29:26Z", "path": "sdks/java/extensions/ml/src/main/java/org/apache/beam/sdk/extensions/ml/DLPDeidentifyText.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.ml;\n+\n+import com.google.auto.value.AutoValue;\n+import com.google.cloud.dlp.v2.DlpServiceClient;\n+import com.google.privacy.dlp.v2.ContentItem;\n+import com.google.privacy.dlp.v2.DeidentifyConfig;\n+import com.google.privacy.dlp.v2.DeidentifyContentRequest;\n+import com.google.privacy.dlp.v2.DeidentifyContentResponse;\n+import com.google.privacy.dlp.v2.FieldId;\n+import com.google.privacy.dlp.v2.InspectConfig;\n+import com.google.privacy.dlp.v2.ProjectName;\n+import com.google.privacy.dlp.v2.Table;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionView;\n+\n+/**\n+ * A {@link PTransform} connecting to Cloud DLP and deidentifying text according to provided\n+ * settings. The transform supports both CSV formatted input data and unstructured input.\n+ *\n+ * <p>If the csvHeader property is set, csvDelimiter also should be, else the results will be\n+ * incorrect. If csvHeader is not set, input is assumed to be unstructured.\n+ *\n+ * <p>Either inspectTemplateName (String) or inspectConfig {@link InspectConfig} need to be set. The\n+ * situation is the same with deidentifyTemplateName and deidentifyConfig ({@link DeidentifyConfig}.\n+ *\n+ * <p>Batch size defines how big are batches sent to DLP at once in bytes.\n+ *\n+ * <p>The transform outputs {@link KV} of {@link String} (eg. filename) and {@link\n+ * DeidentifyContentResponse}, which will contain {@link Table} of results for the user to consume.\n+ */\n+@Experimental\n+@AutoValue\n+public abstract class DLPDeidentifyText\n+    extends PTransform<\n+        PCollection<KV<String, String>>, PCollection<KV<String, DeidentifyContentResponse>>> {\n+\n+  @Nullable\n+  public abstract String inspectTemplateName();\n+\n+  @Nullable\n+  public abstract String deidentifyTemplateName();\n+\n+  @Nullable\n+  public abstract InspectConfig inspectConfig();\n+\n+  @Nullable\n+  public abstract DeidentifyConfig deidentifyConfig();\n+\n+  @Nullable\n+  public abstract PCollectionView<List<String>> csvHeader();\n+\n+  @Nullable\n+  public abstract String csvDelimiter();", "originalCommit": "e4984b7c3112e18a15b5cee76af7ae9398f76fa8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzM4MDc2Nw==", "url": "https://github.com/apache/beam/pull/11566#discussion_r427380767", "bodyText": "For the delimiter - it's column delimiter.  \",\" \"|\" May be rename? Cause row delimiter(\"\\n\") is managed by how the records are read using File IO or Text IO.", "author": "santhh", "createdAt": "2020-05-19T15:11:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkyNjc2MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTIxNDAxMQ==", "url": "https://github.com/apache/beam/pull/11566#discussion_r429214011", "bodyText": "Ok, renamed", "author": "mwalenia", "createdAt": "2020-05-22T12:21:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkyNjc2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkyOTE5NA==", "url": "https://github.com/apache/beam/pull/11566#discussion_r426929194", "bodyText": "It would be helpful if these abstract methods, and possibly those in the builder, had comments.", "author": "tysonjh", "createdAt": "2020-05-18T22:36:47Z", "path": "sdks/java/extensions/ml/src/main/java/org/apache/beam/sdk/extensions/ml/DLPDeidentifyText.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.ml;\n+\n+import com.google.auto.value.AutoValue;\n+import com.google.cloud.dlp.v2.DlpServiceClient;\n+import com.google.privacy.dlp.v2.ContentItem;\n+import com.google.privacy.dlp.v2.DeidentifyConfig;\n+import com.google.privacy.dlp.v2.DeidentifyContentRequest;\n+import com.google.privacy.dlp.v2.DeidentifyContentResponse;\n+import com.google.privacy.dlp.v2.FieldId;\n+import com.google.privacy.dlp.v2.InspectConfig;\n+import com.google.privacy.dlp.v2.ProjectName;\n+import com.google.privacy.dlp.v2.Table;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionView;\n+\n+/**\n+ * A {@link PTransform} connecting to Cloud DLP and deidentifying text according to provided\n+ * settings. The transform supports both CSV formatted input data and unstructured input.\n+ *\n+ * <p>If the csvHeader property is set, csvDelimiter also should be, else the results will be\n+ * incorrect. If csvHeader is not set, input is assumed to be unstructured.\n+ *\n+ * <p>Either inspectTemplateName (String) or inspectConfig {@link InspectConfig} need to be set. The\n+ * situation is the same with deidentifyTemplateName and deidentifyConfig ({@link DeidentifyConfig}.\n+ *\n+ * <p>Batch size defines how big are batches sent to DLP at once in bytes.\n+ *\n+ * <p>The transform outputs {@link KV} of {@link String} (eg. filename) and {@link\n+ * DeidentifyContentResponse}, which will contain {@link Table} of results for the user to consume.\n+ */\n+@Experimental\n+@AutoValue\n+public abstract class DLPDeidentifyText\n+    extends PTransform<\n+        PCollection<KV<String, String>>, PCollection<KV<String, DeidentifyContentResponse>>> {\n+\n+  @Nullable\n+  public abstract String inspectTemplateName();", "originalCommit": "e4984b7c3112e18a15b5cee76af7ae9398f76fa8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTIwMjI1NA==", "url": "https://github.com/apache/beam/pull/11566#discussion_r429202254", "bodyText": "Sure, I'll add comments", "author": "mwalenia", "createdAt": "2020-05-22T11:52:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkyOTE5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkzMjUzOA==", "url": "https://github.com/apache/beam/pull/11566#discussion_r426932538", "bodyText": "Would you move the comments about how a method works, or what it does, to the method definition please?", "author": "tysonjh", "createdAt": "2020-05-18T22:46:55Z", "path": "sdks/java/extensions/ml/src/main/java/org/apache/beam/sdk/extensions/ml/DLPDeidentifyText.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.ml;\n+\n+import com.google.auto.value.AutoValue;\n+import com.google.cloud.dlp.v2.DlpServiceClient;\n+import com.google.privacy.dlp.v2.ContentItem;\n+import com.google.privacy.dlp.v2.DeidentifyConfig;\n+import com.google.privacy.dlp.v2.DeidentifyContentRequest;\n+import com.google.privacy.dlp.v2.DeidentifyContentResponse;\n+import com.google.privacy.dlp.v2.FieldId;\n+import com.google.privacy.dlp.v2.InspectConfig;\n+import com.google.privacy.dlp.v2.ProjectName;\n+import com.google.privacy.dlp.v2.Table;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionView;\n+\n+/**\n+ * A {@link PTransform} connecting to Cloud DLP and deidentifying text according to provided\n+ * settings. The transform supports both CSV formatted input data and unstructured input.\n+ *\n+ * <p>If the csvHeader property is set, csvDelimiter also should be, else the results will be\n+ * incorrect. If csvHeader is not set, input is assumed to be unstructured.\n+ *\n+ * <p>Either inspectTemplateName (String) or inspectConfig {@link InspectConfig} need to be set. The\n+ * situation is the same with deidentifyTemplateName and deidentifyConfig ({@link DeidentifyConfig}.\n+ *\n+ * <p>Batch size defines how big are batches sent to DLP at once in bytes.", "originalCommit": "e4984b7c3112e18a15b5cee76af7ae9398f76fa8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzM3OTE3NA==", "url": "https://github.com/apache/beam/pull/11566#discussion_r427379174", "bodyText": "This will be used for inspect contents for any DLP info types provided in the inspect template. e.g- SSN, US_PASSPORT", "author": "santhh", "createdAt": "2020-05-19T15:09:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkzMjUzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzQwMzQ1NA==", "url": "https://github.com/apache/beam/pull/11566#discussion_r427403454", "bodyText": "Are you agreeing that the comments should be moved to the methods, or that the comments are also useful here for the template inspection (I'm unfamiliar with what the 'inspect contents' and 'inspect template' actions)?", "author": "tysonjh", "createdAt": "2020-05-19T15:41:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkzMjUzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTI5NjIxOQ==", "url": "https://github.com/apache/beam/pull/11566#discussion_r429296219", "bodyText": "I think moving to the method definition will be more helpful.", "author": "santhh", "createdAt": "2020-05-22T14:55:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkzMjUzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkzMzU1NA==", "url": "https://github.com/apache/beam/pull/11566#discussion_r426933554", "bodyText": "See my earlier comment about moving configuration exceptions like this to pipeline construction time. Doing so will give earlier feedback to the user and avoid having to spin up workers and processing part of the pipeline before running into a configuration issue.", "author": "tysonjh", "createdAt": "2020-05-18T22:49:49Z", "path": "sdks/java/extensions/ml/src/main/java/org/apache/beam/sdk/extensions/ml/DLPDeidentifyText.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.ml;\n+\n+import com.google.auto.value.AutoValue;\n+import com.google.cloud.dlp.v2.DlpServiceClient;\n+import com.google.privacy.dlp.v2.ContentItem;\n+import com.google.privacy.dlp.v2.DeidentifyConfig;\n+import com.google.privacy.dlp.v2.DeidentifyContentRequest;\n+import com.google.privacy.dlp.v2.DeidentifyContentResponse;\n+import com.google.privacy.dlp.v2.FieldId;\n+import com.google.privacy.dlp.v2.InspectConfig;\n+import com.google.privacy.dlp.v2.ProjectName;\n+import com.google.privacy.dlp.v2.Table;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionView;\n+\n+/**\n+ * A {@link PTransform} connecting to Cloud DLP and deidentifying text according to provided\n+ * settings. The transform supports both CSV formatted input data and unstructured input.\n+ *\n+ * <p>If the csvHeader property is set, csvDelimiter also should be, else the results will be\n+ * incorrect. If csvHeader is not set, input is assumed to be unstructured.\n+ *\n+ * <p>Either inspectTemplateName (String) or inspectConfig {@link InspectConfig} need to be set. The\n+ * situation is the same with deidentifyTemplateName and deidentifyConfig ({@link DeidentifyConfig}.\n+ *\n+ * <p>Batch size defines how big are batches sent to DLP at once in bytes.\n+ *\n+ * <p>The transform outputs {@link KV} of {@link String} (eg. filename) and {@link\n+ * DeidentifyContentResponse}, which will contain {@link Table} of results for the user to consume.\n+ */\n+@Experimental\n+@AutoValue\n+public abstract class DLPDeidentifyText\n+    extends PTransform<\n+        PCollection<KV<String, String>>, PCollection<KV<String, DeidentifyContentResponse>>> {\n+\n+  @Nullable\n+  public abstract String inspectTemplateName();\n+\n+  @Nullable\n+  public abstract String deidentifyTemplateName();\n+\n+  @Nullable\n+  public abstract InspectConfig inspectConfig();\n+\n+  @Nullable\n+  public abstract DeidentifyConfig deidentifyConfig();\n+\n+  @Nullable\n+  public abstract PCollectionView<List<String>> csvHeader();\n+\n+  @Nullable\n+  public abstract String csvDelimiter();\n+\n+  public abstract Integer batchSize();\n+\n+  public abstract String projectId();\n+\n+  @AutoValue.Builder\n+  public abstract static class Builder {\n+    public abstract Builder setInspectTemplateName(String inspectTemplateName);\n+\n+    public abstract Builder setCsvHeader(PCollectionView<List<String>> csvHeader);\n+\n+    public abstract Builder setCsvDelimiter(String delimiter);\n+\n+    public abstract Builder setBatchSize(Integer batchSize);\n+\n+    public abstract Builder setProjectId(String projectId);\n+\n+    public abstract Builder setDeidentifyTemplateName(String deidentifyTemplateName);\n+\n+    public abstract Builder setInspectConfig(InspectConfig inspectConfig);\n+\n+    public abstract Builder setDeidentifyConfig(DeidentifyConfig deidentifyConfig);\n+\n+    public abstract DLPDeidentifyText build();\n+  }\n+\n+  public static DLPDeidentifyText.Builder newBuilder() {\n+    return new AutoValue_DLPDeidentifyText.Builder();\n+  }\n+\n+  /**\n+   * The transform batches the contents of input PCollection and then calls Cloud DLP service to\n+   * perform the deidentification.\n+   *\n+   * @param input input PCollection\n+   * @return PCollection after transformations\n+   */\n+  @Override\n+  public PCollection<KV<String, DeidentifyContentResponse>> expand(\n+      PCollection<KV<String, String>> input) {\n+    return input\n+        .apply(ParDo.of(new MapStringToDlpRow(csvDelimiter())))\n+        .apply(\"Batch Contents\", ParDo.of(new BatchRequestForDLP(batchSize())))\n+        .apply(\n+            \"DLPDeidentify\",\n+            ParDo.of(\n+                new DeidentifyText(\n+                    projectId(),\n+                    inspectTemplateName(),\n+                    deidentifyTemplateName(),\n+                    inspectConfig(),\n+                    deidentifyConfig(),\n+                    csvHeader())));\n+  }\n+\n+  static class DeidentifyText\n+      extends DoFn<KV<String, Iterable<Table.Row>>, KV<String, DeidentifyContentResponse>> {\n+    private final String projectId;\n+    private final String inspectTemplateName;\n+    private final String deidentifyTemplateName;\n+    private final InspectConfig inspectConfig;\n+    private final DeidentifyConfig deidentifyConfig;\n+    private final PCollectionView<List<String>> csvHeaders;\n+    private transient DeidentifyContentRequest.Builder requestBuilder;\n+\n+    @Setup\n+    public void setup() throws IOException {\n+      requestBuilder =\n+          DeidentifyContentRequest.newBuilder().setParent(ProjectName.of(projectId).toString());\n+      if (inspectTemplateName != null) {\n+        requestBuilder.setInspectTemplateName(inspectTemplateName);\n+      }\n+      if (inspectConfig != null) {\n+        requestBuilder.setInspectConfig(inspectConfig);\n+      }\n+      if (inspectConfig == null && inspectTemplateName == null) {\n+        throw new IllegalArgumentException(\n+            \"Either inspectConfig or inspectTemplateName need to be set!\");\n+      }", "originalCommit": "e4984b7c3112e18a15b5cee76af7ae9398f76fa8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzQwNDkzMw==", "url": "https://github.com/apache/beam/pull/11566#discussion_r427404933", "bodyText": "What is the expected input? I didn't see where that is mentioned. I think the KV contains a filename key and content string value?", "author": "tysonjh", "createdAt": "2020-05-19T15:43:37Z", "path": "sdks/java/extensions/ml/src/main/java/org/apache/beam/sdk/extensions/ml/DLPDeidentifyText.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.ml;\n+\n+import com.google.auto.value.AutoValue;\n+import com.google.cloud.dlp.v2.DlpServiceClient;\n+import com.google.privacy.dlp.v2.ContentItem;\n+import com.google.privacy.dlp.v2.DeidentifyConfig;\n+import com.google.privacy.dlp.v2.DeidentifyContentRequest;\n+import com.google.privacy.dlp.v2.DeidentifyContentResponse;\n+import com.google.privacy.dlp.v2.FieldId;\n+import com.google.privacy.dlp.v2.InspectConfig;\n+import com.google.privacy.dlp.v2.ProjectName;\n+import com.google.privacy.dlp.v2.Table;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionView;\n+\n+/**\n+ * A {@link PTransform} connecting to Cloud DLP and deidentifying text according to provided\n+ * settings. The transform supports both CSV formatted input data and unstructured input.\n+ *\n+ * <p>If the csvHeader property is set, csvDelimiter also should be, else the results will be\n+ * incorrect. If csvHeader is not set, input is assumed to be unstructured.\n+ *\n+ * <p>Either inspectTemplateName (String) or inspectConfig {@link InspectConfig} need to be set. The\n+ * situation is the same with deidentifyTemplateName and deidentifyConfig ({@link DeidentifyConfig}.\n+ *\n+ * <p>Batch size defines how big are batches sent to DLP at once in bytes.\n+ *\n+ * <p>The transform outputs {@link KV} of {@link String} (eg. filename) and {@link\n+ * DeidentifyContentResponse}, which will contain {@link Table} of results for the user to consume.", "originalCommit": "e4984b7c3112e18a15b5cee76af7ae9398f76fa8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzQxMTc4Mw==", "url": "https://github.com/apache/beam/pull/11566#discussion_r427411783", "bodyText": "Is a header required? As a user, if I set a null header, I wouldn't expect to see one in the output.\n@santhh do you have an opinion regarding this?", "author": "tysonjh", "createdAt": "2020-05-19T15:53:15Z", "path": "sdks/java/extensions/ml/src/main/java/org/apache/beam/sdk/extensions/ml/DLPDeidentifyText.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.ml;\n+\n+import com.google.auto.value.AutoValue;\n+import com.google.cloud.dlp.v2.DlpServiceClient;\n+import com.google.privacy.dlp.v2.ContentItem;\n+import com.google.privacy.dlp.v2.DeidentifyConfig;\n+import com.google.privacy.dlp.v2.DeidentifyContentRequest;\n+import com.google.privacy.dlp.v2.DeidentifyContentResponse;\n+import com.google.privacy.dlp.v2.FieldId;\n+import com.google.privacy.dlp.v2.InspectConfig;\n+import com.google.privacy.dlp.v2.ProjectName;\n+import com.google.privacy.dlp.v2.Table;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionView;\n+\n+/**\n+ * A {@link PTransform} connecting to Cloud DLP and deidentifying text according to provided\n+ * settings. The transform supports both CSV formatted input data and unstructured input.\n+ *\n+ * <p>If the csvHeader property is set, csvDelimiter also should be, else the results will be\n+ * incorrect. If csvHeader is not set, input is assumed to be unstructured.\n+ *\n+ * <p>Either inspectTemplateName (String) or inspectConfig {@link InspectConfig} need to be set. The\n+ * situation is the same with deidentifyTemplateName and deidentifyConfig ({@link DeidentifyConfig}.\n+ *\n+ * <p>Batch size defines how big are batches sent to DLP at once in bytes.\n+ *\n+ * <p>The transform outputs {@link KV} of {@link String} (eg. filename) and {@link\n+ * DeidentifyContentResponse}, which will contain {@link Table} of results for the user to consume.\n+ */\n+@Experimental\n+@AutoValue\n+public abstract class DLPDeidentifyText\n+    extends PTransform<\n+        PCollection<KV<String, String>>, PCollection<KV<String, DeidentifyContentResponse>>> {\n+\n+  @Nullable\n+  public abstract String inspectTemplateName();\n+\n+  @Nullable\n+  public abstract String deidentifyTemplateName();\n+\n+  @Nullable\n+  public abstract InspectConfig inspectConfig();\n+\n+  @Nullable\n+  public abstract DeidentifyConfig deidentifyConfig();\n+\n+  @Nullable\n+  public abstract PCollectionView<List<String>> csvHeader();\n+\n+  @Nullable\n+  public abstract String csvDelimiter();\n+\n+  public abstract Integer batchSize();\n+\n+  public abstract String projectId();\n+\n+  @AutoValue.Builder\n+  public abstract static class Builder {\n+    public abstract Builder setInspectTemplateName(String inspectTemplateName);\n+\n+    public abstract Builder setCsvHeader(PCollectionView<List<String>> csvHeader);\n+\n+    public abstract Builder setCsvDelimiter(String delimiter);\n+\n+    public abstract Builder setBatchSize(Integer batchSize);\n+\n+    public abstract Builder setProjectId(String projectId);\n+\n+    public abstract Builder setDeidentifyTemplateName(String deidentifyTemplateName);\n+\n+    public abstract Builder setInspectConfig(InspectConfig inspectConfig);\n+\n+    public abstract Builder setDeidentifyConfig(DeidentifyConfig deidentifyConfig);\n+\n+    public abstract DLPDeidentifyText build();\n+  }\n+\n+  public static DLPDeidentifyText.Builder newBuilder() {\n+    return new AutoValue_DLPDeidentifyText.Builder();\n+  }\n+\n+  /**\n+   * The transform batches the contents of input PCollection and then calls Cloud DLP service to\n+   * perform the deidentification.\n+   *\n+   * @param input input PCollection\n+   * @return PCollection after transformations\n+   */\n+  @Override\n+  public PCollection<KV<String, DeidentifyContentResponse>> expand(\n+      PCollection<KV<String, String>> input) {\n+    return input\n+        .apply(ParDo.of(new MapStringToDlpRow(csvDelimiter())))\n+        .apply(\"Batch Contents\", ParDo.of(new BatchRequestForDLP(batchSize())))\n+        .apply(\n+            \"DLPDeidentify\",\n+            ParDo.of(\n+                new DeidentifyText(\n+                    projectId(),\n+                    inspectTemplateName(),\n+                    deidentifyTemplateName(),\n+                    inspectConfig(),\n+                    deidentifyConfig(),\n+                    csvHeader())));\n+  }\n+\n+  static class DeidentifyText\n+      extends DoFn<KV<String, Iterable<Table.Row>>, KV<String, DeidentifyContentResponse>> {\n+    private final String projectId;\n+    private final String inspectTemplateName;\n+    private final String deidentifyTemplateName;\n+    private final InspectConfig inspectConfig;\n+    private final DeidentifyConfig deidentifyConfig;\n+    private final PCollectionView<List<String>> csvHeaders;\n+    private transient DeidentifyContentRequest.Builder requestBuilder;\n+\n+    @Setup\n+    public void setup() throws IOException {\n+      requestBuilder =\n+          DeidentifyContentRequest.newBuilder().setParent(ProjectName.of(projectId).toString());\n+      if (inspectTemplateName != null) {\n+        requestBuilder.setInspectTemplateName(inspectTemplateName);\n+      }\n+      if (inspectConfig != null) {\n+        requestBuilder.setInspectConfig(inspectConfig);\n+      }\n+      if (inspectConfig == null && inspectTemplateName == null) {\n+        throw new IllegalArgumentException(\n+            \"Either inspectConfig or inspectTemplateName need to be set!\");\n+      }\n+      if (deidentifyConfig != null) {\n+        requestBuilder.setDeidentifyConfig(deidentifyConfig);\n+      }\n+      if (deidentifyTemplateName != null) {\n+        requestBuilder.setDeidentifyTemplateName(deidentifyTemplateName);\n+      }\n+      if (deidentifyConfig == null && deidentifyTemplateName == null) {\n+        throw new IllegalArgumentException(\n+            \"Either deidentifyConfig or deidentifyTemplateName need to be set!\");\n+      }\n+    }\n+\n+    public DeidentifyText(\n+        String projectId,\n+        String inspectTemplateName,\n+        String deidentifyTemplateName,\n+        InspectConfig inspectConfig,\n+        DeidentifyConfig deidentifyConfig,\n+        PCollectionView<List<String>> csvHeaders) {\n+      this.projectId = projectId;\n+      this.inspectTemplateName = inspectTemplateName;\n+      this.deidentifyTemplateName = deidentifyTemplateName;\n+      this.inspectConfig = inspectConfig;\n+      this.deidentifyConfig = deidentifyConfig;\n+      this.csvHeaders = csvHeaders;\n+    }\n+\n+    @ProcessElement\n+    public void processElement(ProcessContext c) throws IOException {\n+      try (DlpServiceClient dlpServiceClient = DlpServiceClient.create()) {\n+        String fileName = c.element().getKey();\n+        List<FieldId> dlpTableHeaders;\n+        if (csvHeaders != null) {\n+          dlpTableHeaders =\n+              c.sideInput(csvHeaders).stream()\n+                  .map(header -> FieldId.newBuilder().setName(header).build())\n+                  .collect(Collectors.toList());\n+        } else {\n+          // handle unstructured input\n+          dlpTableHeaders = new ArrayList<>();\n+          dlpTableHeaders.add(FieldId.newBuilder().setName(\"value\").build());", "originalCommit": "e4984b7c3112e18a15b5cee76af7ae9398f76fa8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY4NDgxOA==", "url": "https://github.com/apache/beam/pull/11566#discussion_r427684818", "bodyText": "no it's not required. If the header is not set, we should assume  request is not table content type just string. True for any request.", "author": "santhh", "createdAt": "2020-05-20T01:05:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzQxMTc4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODY2MTc4MA==", "url": "https://github.com/apache/beam/pull/11566#discussion_r428661780", "bodyText": "the header isn't required from the user, but if we want to have the input to DLP Cloud service structured as a table, there needs to be at least 1 header, hence the 'value' added here.", "author": "mwalenia", "createdAt": "2020-05-21T13:47:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzQxMTc4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTI5NzI5OA==", "url": "https://github.com/apache/beam/pull/11566#discussion_r429297298", "bodyText": "Correct needs to be one header. How does it know when to use table vs string as content item?", "author": "santhh", "createdAt": "2020-05-22T14:57:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzQxMTc4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTI5Nzg2NA==", "url": "https://github.com/apache/beam/pull/11566#discussion_r429297864", "bodyText": "or is it two different sub transforms?", "author": "santhh", "createdAt": "2020-05-22T14:58:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzQxMTc4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTgxNjExNA==", "url": "https://github.com/apache/beam/pull/11566#discussion_r429816114", "bodyText": "It's not two subtransforms, input is assumed to be a string if there are no table headers passed as a side input", "author": "mwalenia", "createdAt": "2020-05-25T08:53:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzQxMTc4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjg3Njg3OQ==", "url": "https://github.com/apache/beam/pull/11566#discussion_r432876879", "bodyText": "got it! perfect.", "author": "santhh", "createdAt": "2020-05-30T18:33:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzQxMTc4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzQxNDYyMA==", "url": "https://github.com/apache/beam/pull/11566#discussion_r427414620", "bodyText": "I wonder if it would be helpful to link to the Cloud DLP content for each type of service for users in these transform comments?", "author": "tysonjh", "createdAt": "2020-05-19T15:57:09Z", "path": "sdks/java/extensions/ml/src/main/java/org/apache/beam/sdk/extensions/ml/DLPDeidentifyText.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.ml;\n+\n+import com.google.auto.value.AutoValue;\n+import com.google.cloud.dlp.v2.DlpServiceClient;\n+import com.google.privacy.dlp.v2.ContentItem;\n+import com.google.privacy.dlp.v2.DeidentifyConfig;\n+import com.google.privacy.dlp.v2.DeidentifyContentRequest;\n+import com.google.privacy.dlp.v2.DeidentifyContentResponse;\n+import com.google.privacy.dlp.v2.FieldId;\n+import com.google.privacy.dlp.v2.InspectConfig;\n+import com.google.privacy.dlp.v2.ProjectName;\n+import com.google.privacy.dlp.v2.Table;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionView;\n+\n+/**\n+ * A {@link PTransform} connecting to Cloud DLP and deidentifying text according to provided", "originalCommit": "e4984b7c3112e18a15b5cee76af7ae9398f76fa8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzQ3MTEyNw==", "url": "https://github.com/apache/beam/pull/11566#discussion_r427471127", "bodyText": "It's good practice to start all javadoc comments with a short summary fragment. There are more details at Google's java style guide [1]. For example, I would phrase the summary fragment for this class as:\n'Batches input rows to reduce the number of requests sent to the Cloud DLP service.'\nWould you please go through this CL and add such comments to public classes and methods? I personally like to add them to all classes, non-trivial methods, and tricky blocks of code, regardless of access modifiers.\n[1] https://google.github.io/styleguide/javaguide.html#s7.2-summary-fragment", "author": "tysonjh", "createdAt": "2020-05-19T17:22:39Z", "path": "sdks/java/extensions/ml/src/main/java/org/apache/beam/sdk/extensions/ml/BatchRequestForDLP.java", "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.ml;\n+\n+import com.google.privacy.dlp.v2.Table;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.metrics.Counter;\n+import org.apache.beam.sdk.metrics.Metrics;\n+import org.apache.beam.sdk.state.BagState;\n+import org.apache.beam.sdk.state.StateSpec;\n+import org.apache.beam.sdk.state.StateSpecs;\n+import org.apache.beam.sdk.state.TimeDomain;\n+import org.apache.beam.sdk.state.Timer;\n+import org.apache.beam.sdk.state.TimerSpec;\n+import org.apache.beam.sdk.state.TimerSpecs;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.windowing.BoundedWindow;\n+import org.apache.beam.sdk.values.KV;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * DoFn batching the input PCollection into bigger requests in order to better utilize the Cloud DLP", "originalCommit": "e4984b7c3112e18a15b5cee76af7ae9398f76fa8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzYzOTc2NQ==", "url": "https://github.com/apache/beam/pull/11566#discussion_r427639765", "bodyText": "Some places c is used, some places context is used, please pick one and use throughout. I prefer context.", "author": "tysonjh", "createdAt": "2020-05-19T22:37:47Z", "path": "sdks/java/extensions/ml/src/main/java/org/apache/beam/sdk/extensions/ml/MapStringToDlpRow.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.ml;\n+\n+import com.google.privacy.dlp.v2.Table;\n+import com.google.privacy.dlp.v2.Value;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Objects;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.values.KV;\n+\n+class MapStringToDlpRow extends DoFn<KV<String, String>, KV<String, Table.Row>> {\n+  private final String delimiter;\n+\n+  public MapStringToDlpRow(String delimiter) {\n+    this.delimiter = delimiter;\n+  }\n+\n+  @ProcessElement\n+  public void processElement(ProcessContext context) {", "originalCommit": "e4984b7c3112e18a15b5cee76af7ae9398f76fa8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODY2NjE4Mw==", "url": "https://github.com/apache/beam/pull/11566#discussion_r428666183", "bodyText": "Ok, will do!", "author": "mwalenia", "createdAt": "2020-05-21T13:55:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzYzOTc2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjc1NjE1Mg==", "url": "https://github.com/apache/beam/pull/11566#discussion_r432756152", "bodyText": "Thank you.", "author": "tysonjh", "createdAt": "2020-05-29T21:53:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzYzOTc2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY4MTE1Ng==", "url": "https://github.com/apache/beam/pull/11566#discussion_r427681156", "bodyText": "should this be re-identify?", "author": "santhh", "createdAt": "2020-05-20T00:50:59Z", "path": "sdks/java/extensions/ml/src/main/java/org/apache/beam/sdk/extensions/ml/DLPReidentifyText.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.ml;\n+\n+import com.google.auto.value.AutoValue;\n+import com.google.cloud.dlp.v2.DlpServiceClient;\n+import com.google.privacy.dlp.v2.ContentItem;\n+import com.google.privacy.dlp.v2.DeidentifyConfig;\n+import com.google.privacy.dlp.v2.FieldId;\n+import com.google.privacy.dlp.v2.InspectConfig;\n+import com.google.privacy.dlp.v2.ProjectName;\n+import com.google.privacy.dlp.v2.ReidentifyContentRequest;\n+import com.google.privacy.dlp.v2.ReidentifyContentResponse;\n+import com.google.privacy.dlp.v2.Table;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionView;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A {@link PTransform} connecting to Cloud DLP and inspecting text for identifying data according\n+ * to provided settings.\n+ *\n+ * <p>Either inspectTemplateName (String) or inspectConfig {@link InspectConfig} need to be set, the\n+ * same goes for reidentifyTemplateName or reidentifyConfig.\n+ *\n+ * <p>Batch size defines how big are batches sent to DLP at once in bytes.\n+ */\n+@Experimental\n+@AutoValue\n+public abstract class DLPReidentifyText\n+    extends PTransform<\n+        PCollection<KV<String, String>>, PCollection<KV<String, ReidentifyContentResponse>>> {\n+\n+  public static final Logger LOG = LoggerFactory.getLogger(DLPInspectText.class);\n+\n+  public static final Integer DLP_PAYLOAD_LIMIT = 52400;\n+\n+  @Nullable\n+  public abstract String inspectTemplateName();\n+\n+  @Nullable\n+  public abstract String reidentifyTemplateName();\n+\n+  @Nullable\n+  public abstract InspectConfig inspectConfig();\n+\n+  @Nullable\n+  public abstract DeidentifyConfig reidentifyConfig();\n+\n+  @Nullable\n+  public abstract String csvDelimiter();\n+\n+  @Nullable\n+  public abstract PCollectionView<List<String>> csvHeaders();\n+\n+  public abstract Integer batchSize();\n+\n+  public abstract String projectId();\n+\n+  @AutoValue.Builder\n+  public abstract static class Builder {\n+    public abstract Builder setInspectTemplateName(String inspectTemplateName);\n+\n+    public abstract Builder setInspectConfig(InspectConfig inspectConfig);\n+\n+    public abstract Builder setReidentifyConfig(DeidentifyConfig deidentifyConfig);\n+\n+    public abstract Builder setReidentifyTemplateName(String deidentifyTemplateName);\n+\n+    public abstract Builder setBatchSize(Integer batchSize);\n+\n+    public abstract Builder setCsvHeaders(PCollectionView<List<String>> csvHeaders);\n+\n+    public abstract Builder setCsvDelimiter(String delimiter);\n+\n+    public abstract Builder setProjectId(String projectId);\n+\n+    public abstract DLPReidentifyText build();\n+  }\n+\n+  public static DLPReidentifyText.Builder newBuilder() {\n+    return new AutoValue_DLPReidentifyText.Builder();\n+  }\n+\n+  @Override\n+  public PCollection<KV<String, ReidentifyContentResponse>> expand(\n+      PCollection<KV<String, String>> input) {\n+    return input\n+        .apply(ParDo.of(new MapStringToDlpRow(csvDelimiter())))\n+        .apply(\"Batch Contents\", ParDo.of(new BatchRequestForDLP(batchSize())))\n+        .apply(\n+            \"DLPDeidentify\",", "originalCommit": "e4984b7c3112e18a15b5cee76af7ae9398f76fa8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzg3MjExOQ==", "url": "https://github.com/apache/beam/pull/11566#discussion_r427872119", "bodyText": "Right, I'll rename this", "author": "mwalenia", "createdAt": "2020-05-20T09:32:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY4MTE1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY4MTc3OA==", "url": "https://github.com/apache/beam/pull/11566#discussion_r427681778", "bodyText": "for re-id inspect template can be optional. only re-id template is required. we should just check if inspect template passed or not. if not take it as valid request.", "author": "santhh", "createdAt": "2020-05-20T00:53:27Z", "path": "sdks/java/extensions/ml/src/main/java/org/apache/beam/sdk/extensions/ml/DLPReidentifyText.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.ml;\n+\n+import com.google.auto.value.AutoValue;\n+import com.google.cloud.dlp.v2.DlpServiceClient;\n+import com.google.privacy.dlp.v2.ContentItem;\n+import com.google.privacy.dlp.v2.DeidentifyConfig;\n+import com.google.privacy.dlp.v2.FieldId;\n+import com.google.privacy.dlp.v2.InspectConfig;\n+import com.google.privacy.dlp.v2.ProjectName;\n+import com.google.privacy.dlp.v2.ReidentifyContentRequest;\n+import com.google.privacy.dlp.v2.ReidentifyContentResponse;\n+import com.google.privacy.dlp.v2.Table;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionView;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A {@link PTransform} connecting to Cloud DLP and inspecting text for identifying data according\n+ * to provided settings.\n+ *\n+ * <p>Either inspectTemplateName (String) or inspectConfig {@link InspectConfig} need to be set, the\n+ * same goes for reidentifyTemplateName or reidentifyConfig.\n+ *\n+ * <p>Batch size defines how big are batches sent to DLP at once in bytes.\n+ */\n+@Experimental\n+@AutoValue\n+public abstract class DLPReidentifyText\n+    extends PTransform<\n+        PCollection<KV<String, String>>, PCollection<KV<String, ReidentifyContentResponse>>> {\n+\n+  public static final Logger LOG = LoggerFactory.getLogger(DLPInspectText.class);\n+\n+  public static final Integer DLP_PAYLOAD_LIMIT = 52400;\n+\n+  @Nullable\n+  public abstract String inspectTemplateName();\n+\n+  @Nullable\n+  public abstract String reidentifyTemplateName();\n+\n+  @Nullable\n+  public abstract InspectConfig inspectConfig();\n+\n+  @Nullable\n+  public abstract DeidentifyConfig reidentifyConfig();\n+\n+  @Nullable\n+  public abstract String csvDelimiter();\n+\n+  @Nullable\n+  public abstract PCollectionView<List<String>> csvHeaders();\n+\n+  public abstract Integer batchSize();\n+\n+  public abstract String projectId();\n+\n+  @AutoValue.Builder\n+  public abstract static class Builder {\n+    public abstract Builder setInspectTemplateName(String inspectTemplateName);\n+\n+    public abstract Builder setInspectConfig(InspectConfig inspectConfig);\n+\n+    public abstract Builder setReidentifyConfig(DeidentifyConfig deidentifyConfig);\n+\n+    public abstract Builder setReidentifyTemplateName(String deidentifyTemplateName);\n+\n+    public abstract Builder setBatchSize(Integer batchSize);\n+\n+    public abstract Builder setCsvHeaders(PCollectionView<List<String>> csvHeaders);\n+\n+    public abstract Builder setCsvDelimiter(String delimiter);\n+\n+    public abstract Builder setProjectId(String projectId);\n+\n+    public abstract DLPReidentifyText build();\n+  }\n+\n+  public static DLPReidentifyText.Builder newBuilder() {\n+    return new AutoValue_DLPReidentifyText.Builder();\n+  }\n+\n+  @Override\n+  public PCollection<KV<String, ReidentifyContentResponse>> expand(\n+      PCollection<KV<String, String>> input) {\n+    return input\n+        .apply(ParDo.of(new MapStringToDlpRow(csvDelimiter())))\n+        .apply(\"Batch Contents\", ParDo.of(new BatchRequestForDLP(batchSize())))\n+        .apply(\n+            \"DLPDeidentify\",\n+            ParDo.of(\n+                new ReidentifyText(\n+                    projectId(),\n+                    inspectTemplateName(),\n+                    reidentifyTemplateName(),\n+                    inspectConfig(),\n+                    reidentifyConfig(),\n+                    csvHeaders())));\n+  }\n+\n+  public static class ReidentifyText\n+      extends DoFn<KV<String, Iterable<Table.Row>>, KV<String, ReidentifyContentResponse>> {\n+    private final String projectId;\n+    private final String inspectTemplateName;\n+    private final String reidentifyTemplateName;\n+    private final InspectConfig inspectConfig;\n+    private final DeidentifyConfig reidentifyConfig;\n+    private transient ReidentifyContentRequest.Builder requestBuilder;\n+    private final PCollectionView<List<String>> csvHeader;\n+\n+    @Setup\n+    public void setup() throws IOException {\n+      requestBuilder =\n+          ReidentifyContentRequest.newBuilder().setParent(ProjectName.of(projectId).toString());\n+      if (inspectTemplateName != null) {\n+        requestBuilder.setInspectTemplateName(inspectTemplateName);\n+      }\n+      if (inspectConfig != null) {\n+        requestBuilder.setInspectConfig(inspectConfig);\n+      }\n+      if (inspectConfig == null && inspectTemplateName == null) {\n+        throw new IllegalArgumentException(\n+            \"Either inspectConfig or inspectTemplateName need to be set!\");", "originalCommit": "e4984b7c3112e18a15b5cee76af7ae9398f76fa8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODY3NjU5NQ==", "url": "https://github.com/apache/beam/pull/11566#discussion_r428676595", "bodyText": "Thanks!", "author": "mwalenia", "createdAt": "2020-05-21T14:12:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY4MTc3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY4Mzg0Ng==", "url": "https://github.com/apache/beam/pull/11566#discussion_r427683846", "bodyText": "For de-id - it's also same as re-id. de-id template in required but inspect is optional.", "author": "santhh", "createdAt": "2020-05-20T01:01:24Z", "path": "sdks/java/extensions/ml/src/main/java/org/apache/beam/sdk/extensions/ml/DLPDeidentifyText.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.ml;\n+\n+import com.google.auto.value.AutoValue;\n+import com.google.cloud.dlp.v2.DlpServiceClient;\n+import com.google.privacy.dlp.v2.ContentItem;\n+import com.google.privacy.dlp.v2.DeidentifyConfig;\n+import com.google.privacy.dlp.v2.DeidentifyContentRequest;\n+import com.google.privacy.dlp.v2.DeidentifyContentResponse;\n+import com.google.privacy.dlp.v2.FieldId;\n+import com.google.privacy.dlp.v2.InspectConfig;\n+import com.google.privacy.dlp.v2.ProjectName;\n+import com.google.privacy.dlp.v2.Table;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionView;\n+\n+/**\n+ * A {@link PTransform} connecting to Cloud DLP and deidentifying text according to provided\n+ * settings. The transform supports both CSV formatted input data and unstructured input.\n+ *\n+ * <p>If the csvHeader property is set, csvDelimiter also should be, else the results will be\n+ * incorrect. If csvHeader is not set, input is assumed to be unstructured.\n+ *\n+ * <p>Either inspectTemplateName (String) or inspectConfig {@link InspectConfig} need to be set. The\n+ * situation is the same with deidentifyTemplateName and deidentifyConfig ({@link DeidentifyConfig}.\n+ *\n+ * <p>Batch size defines how big are batches sent to DLP at once in bytes.\n+ *\n+ * <p>The transform outputs {@link KV} of {@link String} (eg. filename) and {@link\n+ * DeidentifyContentResponse}, which will contain {@link Table} of results for the user to consume.\n+ */\n+@Experimental\n+@AutoValue\n+public abstract class DLPDeidentifyText\n+    extends PTransform<\n+        PCollection<KV<String, String>>, PCollection<KV<String, DeidentifyContentResponse>>> {\n+\n+  @Nullable\n+  public abstract String inspectTemplateName();\n+\n+  @Nullable\n+  public abstract String deidentifyTemplateName();\n+\n+  @Nullable\n+  public abstract InspectConfig inspectConfig();\n+\n+  @Nullable\n+  public abstract DeidentifyConfig deidentifyConfig();\n+\n+  @Nullable\n+  public abstract PCollectionView<List<String>> csvHeader();\n+\n+  @Nullable\n+  public abstract String csvDelimiter();\n+\n+  public abstract Integer batchSize();\n+\n+  public abstract String projectId();\n+\n+  @AutoValue.Builder\n+  public abstract static class Builder {\n+    public abstract Builder setInspectTemplateName(String inspectTemplateName);\n+\n+    public abstract Builder setCsvHeader(PCollectionView<List<String>> csvHeader);\n+\n+    public abstract Builder setCsvDelimiter(String delimiter);\n+\n+    public abstract Builder setBatchSize(Integer batchSize);\n+\n+    public abstract Builder setProjectId(String projectId);\n+\n+    public abstract Builder setDeidentifyTemplateName(String deidentifyTemplateName);\n+\n+    public abstract Builder setInspectConfig(InspectConfig inspectConfig);\n+\n+    public abstract Builder setDeidentifyConfig(DeidentifyConfig deidentifyConfig);\n+\n+    public abstract DLPDeidentifyText build();\n+  }\n+", "originalCommit": "e4984b7c3112e18a15b5cee76af7ae9398f76fa8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODY3OTk1NQ==", "url": "https://github.com/apache/beam/pull/11566#discussion_r428679955", "bodyText": "Thanks!", "author": "mwalenia", "createdAt": "2020-05-21T14:17:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY4Mzg0Ng=="}], "type": "inlineReview"}, {"oid": "7e2d93374e17dc3441a761880fb7283fe32f940c", "url": "https://github.com/apache/beam/commit/7e2d93374e17dc3441a761880fb7283fe32f940c", "message": "[BEAM-9723] Add DLP integration transforms", "committedDate": "2020-05-25T08:32:16Z", "type": "commit"}, {"oid": "3b87bff6153345f7f0561c2dd09fbccda13c4277", "url": "https://github.com/apache/beam/commit/3b87bff6153345f7f0561c2dd09fbccda13c4277", "message": "Separate logger for the batching DoFn", "committedDate": "2020-05-25T08:32:16Z", "type": "commit"}, {"oid": "d44bb857d662ff6dcf80d4dfdf305ed40a510008", "url": "https://github.com/apache/beam/commit/d44bb857d662ff6dcf80d4dfdf305ed40a510008", "message": "Modify the batching algorithm", "committedDate": "2020-05-25T08:32:17Z", "type": "commit"}, {"oid": "45cd3f599aed360d780889ec0e50a07a9ac68c7a", "url": "https://github.com/apache/beam/commit/45cd3f599aed360d780889ec0e50a07a9ac68c7a", "message": "Rework DLP transforms into more usable forms", "committedDate": "2020-05-25T08:32:17Z", "type": "commit"}, {"oid": "926a47c69234a421c601feb9aa1c2bc7a43a1962", "url": "https://github.com/apache/beam/commit/926a47c69234a421c601feb9aa1c2bc7a43a1962", "message": "Add default GCP project for testing", "committedDate": "2020-05-25T08:32:17Z", "type": "commit"}, {"oid": "8847d275759ee3677a87577a36e434afcef07bf9", "url": "https://github.com/apache/beam/commit/8847d275759ee3677a87577a36e434afcef07bf9", "message": "First batch of fixes after code review", "committedDate": "2020-05-25T08:32:18Z", "type": "commit"}, {"oid": "00add365d3d8168a6dbdad4d63b76892a3609399", "url": "https://github.com/apache/beam/commit/00add365d3d8168a6dbdad4d63b76892a3609399", "message": "Add javadocs to DLP transforms. Add more tests", "committedDate": "2020-05-25T08:32:18Z", "type": "forcePushed"}, {"oid": "7b2c379d38d4c0cc97f8e89f8399406d0fe3534d", "url": "https://github.com/apache/beam/commit/7b2c379d38d4c0cc97f8e89f8399406d0fe3534d", "message": "Add javadocs to DLP transforms. Add more tests", "committedDate": "2020-05-25T10:07:30Z", "type": "commit"}, {"oid": "7b2c379d38d4c0cc97f8e89f8399406d0fe3534d", "url": "https://github.com/apache/beam/commit/7b2c379d38d4c0cc97f8e89f8399406d0fe3534d", "message": "Add javadocs to DLP transforms. Add more tests", "committedDate": "2020-05-25T10:07:30Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTE5ODkzNg==", "url": "https://github.com/apache/beam/pull/11566#discussion_r431198936", "bodyText": "I think we previously agreed that the term 'csv' here is misleading since it could be any delimiter not just a comma. Perhaps the right name for this is getHeaderColumns()? That would match nicely with getColumnDelimiter, setColumnDelimiter, and setHeaderColumns().\nThat would follow the style guide from here more closely, though it would require updating other getters to match but the setters in the builder already conform.", "author": "tysonjh", "createdAt": "2020-05-27T14:52:26Z", "path": "sdks/java/extensions/ml/src/main/java/org/apache/beam/sdk/extensions/ml/DLPDeidentifyText.java", "diffHunk": "@@ -0,0 +1,267 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.ml;\n+\n+import com.google.auto.value.AutoValue;\n+import com.google.cloud.dlp.v2.DlpServiceClient;\n+import com.google.privacy.dlp.v2.ContentItem;\n+import com.google.privacy.dlp.v2.DeidentifyConfig;\n+import com.google.privacy.dlp.v2.DeidentifyContentRequest;\n+import com.google.privacy.dlp.v2.DeidentifyContentResponse;\n+import com.google.privacy.dlp.v2.FieldId;\n+import com.google.privacy.dlp.v2.InspectConfig;\n+import com.google.privacy.dlp.v2.ProjectName;\n+import com.google.privacy.dlp.v2.Table;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionView;\n+\n+/**\n+ * A {@link PTransform} connecting to Cloud DLP (https://cloud.google.com/dlp/docs/libraries) and\n+ * deidentifying text according to provided settings. The transform supports both CSV formatted\n+ * input data and unstructured input.\n+ *\n+ * <p>If the csvHeader property is set and a sideinput with CSV headers is added to the PTransform,\n+ * csvDelimiter also should be set, else the results will be incorrect. If csvHeader is neither set\n+ * nor passed as sideinput, input is assumed to be unstructured.\n+ *\n+ * <p>Either deidentifyTemplateName (String) or deidentifyConfig {@link DeidentifyConfig} need to be\n+ * set. inspectTemplateName and inspectConfig ({@link InspectConfig} are optional.\n+ *\n+ * <p>Batch size defines how big are batches sent to DLP at once in bytes.\n+ *\n+ * <p>The transform consumes {@link KV} of {@link String}s (assumed to be filename as key and\n+ * contents as value) and outputs {@link KV} of {@link String} (eg. filename) and {@link\n+ * DeidentifyContentResponse}, which will contain {@link Table} of results for the user to consume.\n+ */\n+@Experimental\n+@AutoValue\n+public abstract class DLPDeidentifyText\n+    extends PTransform<\n+        PCollection<KV<String, String>>, PCollection<KV<String, DeidentifyContentResponse>>> {\n+\n+  public static final Integer DLP_PAYLOAD_LIMIT_BYTES = 524000;\n+\n+  /** @return Template name for data inspection. */\n+  @Nullable\n+  public abstract String inspectTemplateName();\n+\n+  /** @return Template name for data deidentification. */\n+  @Nullable\n+  public abstract String deidentifyTemplateName();\n+\n+  /**\n+   * @return Configuration object for data inspection. If present, supersedes the template settings.\n+   */\n+  @Nullable\n+  public abstract InspectConfig inspectConfig();\n+\n+  /** @return Configuration object for deidentification. If present, supersedes the template. */\n+  @Nullable\n+  public abstract DeidentifyConfig deidentifyConfig();\n+\n+  /** @return List of column names if the input KV value is a CSV formatted row. */\n+  @Nullable\n+  public abstract PCollectionView<List<String>> csvHeader();", "originalCommit": "7b2c379d38d4c0cc97f8e89f8399406d0fe3534d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYyNzk3Mw==", "url": "https://github.com/apache/beam/pull/11566#discussion_r431627973", "bodyText": "Right, I must have missed that. Thanks!", "author": "mwalenia", "createdAt": "2020-05-28T07:14:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTE5ODkzNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTIwMTI4NQ==", "url": "https://github.com/apache/beam/pull/11566#discussion_r431201285", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n             * deidentifying text according to provided settings. The transform supports both CSV formatted\n          \n          \n            \n             * deidentifying text according to provided settings. The transform supports both delimited", "author": "tysonjh", "createdAt": "2020-05-27T14:54:58Z", "path": "sdks/java/extensions/ml/src/main/java/org/apache/beam/sdk/extensions/ml/DLPDeidentifyText.java", "diffHunk": "@@ -0,0 +1,267 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.ml;\n+\n+import com.google.auto.value.AutoValue;\n+import com.google.cloud.dlp.v2.DlpServiceClient;\n+import com.google.privacy.dlp.v2.ContentItem;\n+import com.google.privacy.dlp.v2.DeidentifyConfig;\n+import com.google.privacy.dlp.v2.DeidentifyContentRequest;\n+import com.google.privacy.dlp.v2.DeidentifyContentResponse;\n+import com.google.privacy.dlp.v2.FieldId;\n+import com.google.privacy.dlp.v2.InspectConfig;\n+import com.google.privacy.dlp.v2.ProjectName;\n+import com.google.privacy.dlp.v2.Table;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionView;\n+\n+/**\n+ * A {@link PTransform} connecting to Cloud DLP (https://cloud.google.com/dlp/docs/libraries) and\n+ * deidentifying text according to provided settings. The transform supports both CSV formatted", "originalCommit": "7b2c379d38d4c0cc97f8e89f8399406d0fe3534d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ2MzUwOQ==", "url": "https://github.com/apache/beam/pull/11566#discussion_r431463509", "bodyText": "Since the builder has setter methods prefixed with set having parity with getters prefixed with get would be nice. Also dropping the csv makes sense.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              public abstract String csvColumnDelimiter();\n          \n          \n            \n              public abstract String getColumnDelimiter();", "author": "tysonjh", "createdAt": "2020-05-27T21:51:18Z", "path": "sdks/java/extensions/ml/src/main/java/org/apache/beam/sdk/extensions/ml/DLPDeidentifyText.java", "diffHunk": "@@ -0,0 +1,267 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.ml;\n+\n+import com.google.auto.value.AutoValue;\n+import com.google.cloud.dlp.v2.DlpServiceClient;\n+import com.google.privacy.dlp.v2.ContentItem;\n+import com.google.privacy.dlp.v2.DeidentifyConfig;\n+import com.google.privacy.dlp.v2.DeidentifyContentRequest;\n+import com.google.privacy.dlp.v2.DeidentifyContentResponse;\n+import com.google.privacy.dlp.v2.FieldId;\n+import com.google.privacy.dlp.v2.InspectConfig;\n+import com.google.privacy.dlp.v2.ProjectName;\n+import com.google.privacy.dlp.v2.Table;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionView;\n+\n+/**\n+ * A {@link PTransform} connecting to Cloud DLP (https://cloud.google.com/dlp/docs/libraries) and\n+ * deidentifying text according to provided settings. The transform supports both CSV formatted\n+ * input data and unstructured input.\n+ *\n+ * <p>If the csvHeader property is set and a sideinput with CSV headers is added to the PTransform,\n+ * csvDelimiter also should be set, else the results will be incorrect. If csvHeader is neither set\n+ * nor passed as sideinput, input is assumed to be unstructured.\n+ *\n+ * <p>Either deidentifyTemplateName (String) or deidentifyConfig {@link DeidentifyConfig} need to be\n+ * set. inspectTemplateName and inspectConfig ({@link InspectConfig} are optional.\n+ *\n+ * <p>Batch size defines how big are batches sent to DLP at once in bytes.\n+ *\n+ * <p>The transform consumes {@link KV} of {@link String}s (assumed to be filename as key and\n+ * contents as value) and outputs {@link KV} of {@link String} (eg. filename) and {@link\n+ * DeidentifyContentResponse}, which will contain {@link Table} of results for the user to consume.\n+ */\n+@Experimental\n+@AutoValue\n+public abstract class DLPDeidentifyText\n+    extends PTransform<\n+        PCollection<KV<String, String>>, PCollection<KV<String, DeidentifyContentResponse>>> {\n+\n+  public static final Integer DLP_PAYLOAD_LIMIT_BYTES = 524000;\n+\n+  /** @return Template name for data inspection. */\n+  @Nullable\n+  public abstract String inspectTemplateName();\n+\n+  /** @return Template name for data deidentification. */\n+  @Nullable\n+  public abstract String deidentifyTemplateName();\n+\n+  /**\n+   * @return Configuration object for data inspection. If present, supersedes the template settings.\n+   */\n+  @Nullable\n+  public abstract InspectConfig inspectConfig();\n+\n+  /** @return Configuration object for deidentification. If present, supersedes the template. */\n+  @Nullable\n+  public abstract DeidentifyConfig deidentifyConfig();\n+\n+  /** @return List of column names if the input KV value is a CSV formatted row. */\n+  @Nullable\n+  public abstract PCollectionView<List<String>> csvHeader();\n+\n+  /** @return Delimiter to be used when splitting values from input strings into columns. */\n+  @Nullable\n+  public abstract String csvColumnDelimiter();", "originalCommit": "7b2c379d38d4c0cc97f8e89f8399406d0fe3534d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ2OTUyMA==", "url": "https://github.com/apache/beam/pull/11566#discussion_r431469520", "bodyText": "Since this is just a collection of column names for the header, I don't think the prefix csv is relevant here. Below is my suggestion that drops the csv, adds the word 'column', and adds a comment that describes the relationship between this method and the setColumnDelimiter.\nNote: I talk about the default header \"value\" here. It would make sense to mention this in getHeaderColumns() if my assumption is correct.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                /** @param csvHeader List of column names if the input KV value is a CSV formatted row. */\n          \n          \n            \n                public abstract Builder setCsvHeader(PCollectionView<List<String>> csvHeader);\n          \n          \n            \n                /** \n          \n          \n            \n                *  Sets the header column names corresponding to the delimited values of the input KV. If no header is set, \n          \n          \n            \n                *  a single column name \"value\" will be used for the header. If specified, requires that a delimiter is \n          \n          \n            \n                *  set using setColumnDelimiter.\n          \n          \n            \n                */\n          \n          \n            \n                public abstract Builder setHeaderColumns(PCollectionView<List<String>> header);", "author": "tysonjh", "createdAt": "2020-05-27T22:05:15Z", "path": "sdks/java/extensions/ml/src/main/java/org/apache/beam/sdk/extensions/ml/DLPDeidentifyText.java", "diffHunk": "@@ -0,0 +1,267 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.ml;\n+\n+import com.google.auto.value.AutoValue;\n+import com.google.cloud.dlp.v2.DlpServiceClient;\n+import com.google.privacy.dlp.v2.ContentItem;\n+import com.google.privacy.dlp.v2.DeidentifyConfig;\n+import com.google.privacy.dlp.v2.DeidentifyContentRequest;\n+import com.google.privacy.dlp.v2.DeidentifyContentResponse;\n+import com.google.privacy.dlp.v2.FieldId;\n+import com.google.privacy.dlp.v2.InspectConfig;\n+import com.google.privacy.dlp.v2.ProjectName;\n+import com.google.privacy.dlp.v2.Table;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionView;\n+\n+/**\n+ * A {@link PTransform} connecting to Cloud DLP (https://cloud.google.com/dlp/docs/libraries) and\n+ * deidentifying text according to provided settings. The transform supports both CSV formatted\n+ * input data and unstructured input.\n+ *\n+ * <p>If the csvHeader property is set and a sideinput with CSV headers is added to the PTransform,\n+ * csvDelimiter also should be set, else the results will be incorrect. If csvHeader is neither set\n+ * nor passed as sideinput, input is assumed to be unstructured.\n+ *\n+ * <p>Either deidentifyTemplateName (String) or deidentifyConfig {@link DeidentifyConfig} need to be\n+ * set. inspectTemplateName and inspectConfig ({@link InspectConfig} are optional.\n+ *\n+ * <p>Batch size defines how big are batches sent to DLP at once in bytes.\n+ *\n+ * <p>The transform consumes {@link KV} of {@link String}s (assumed to be filename as key and\n+ * contents as value) and outputs {@link KV} of {@link String} (eg. filename) and {@link\n+ * DeidentifyContentResponse}, which will contain {@link Table} of results for the user to consume.\n+ */\n+@Experimental\n+@AutoValue\n+public abstract class DLPDeidentifyText\n+    extends PTransform<\n+        PCollection<KV<String, String>>, PCollection<KV<String, DeidentifyContentResponse>>> {\n+\n+  public static final Integer DLP_PAYLOAD_LIMIT_BYTES = 524000;\n+\n+  /** @return Template name for data inspection. */\n+  @Nullable\n+  public abstract String inspectTemplateName();\n+\n+  /** @return Template name for data deidentification. */\n+  @Nullable\n+  public abstract String deidentifyTemplateName();\n+\n+  /**\n+   * @return Configuration object for data inspection. If present, supersedes the template settings.\n+   */\n+  @Nullable\n+  public abstract InspectConfig inspectConfig();\n+\n+  /** @return Configuration object for deidentification. If present, supersedes the template. */\n+  @Nullable\n+  public abstract DeidentifyConfig deidentifyConfig();\n+\n+  /** @return List of column names if the input KV value is a CSV formatted row. */\n+  @Nullable\n+  public abstract PCollectionView<List<String>> csvHeader();\n+\n+  /** @return Delimiter to be used when splitting values from input strings into columns. */\n+  @Nullable\n+  public abstract String csvColumnDelimiter();\n+\n+  /** @return Size of input elements batch to be sent to Cloud DLP service in one request. */\n+  public abstract Integer batchSizeBytes();\n+\n+  /** @return ID of Google Cloud project to be used when deidentifying data. */\n+  public abstract String projectId();\n+\n+  @AutoValue.Builder\n+  public abstract static class Builder {\n+    /** @param inspectTemplateName Template name for data inspection. */\n+    public abstract Builder setInspectTemplateName(String inspectTemplateName);\n+\n+    /** @param csvHeader List of column names if the input KV value is a CSV formatted row. */\n+    public abstract Builder setCsvHeader(PCollectionView<List<String>> csvHeader);", "originalCommit": "7b2c379d38d4c0cc97f8e89f8399406d0fe3534d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ3MDA2Mw==", "url": "https://github.com/apache/beam/pull/11566#discussion_r431470063", "bodyText": "Similarly here, no need to say csv in the method name or comments since it may be any delimiter. Also mention how this method relates to the setHeader method above.", "author": "tysonjh", "createdAt": "2020-05-27T22:06:43Z", "path": "sdks/java/extensions/ml/src/main/java/org/apache/beam/sdk/extensions/ml/DLPDeidentifyText.java", "diffHunk": "@@ -0,0 +1,267 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.ml;\n+\n+import com.google.auto.value.AutoValue;\n+import com.google.cloud.dlp.v2.DlpServiceClient;\n+import com.google.privacy.dlp.v2.ContentItem;\n+import com.google.privacy.dlp.v2.DeidentifyConfig;\n+import com.google.privacy.dlp.v2.DeidentifyContentRequest;\n+import com.google.privacy.dlp.v2.DeidentifyContentResponse;\n+import com.google.privacy.dlp.v2.FieldId;\n+import com.google.privacy.dlp.v2.InspectConfig;\n+import com.google.privacy.dlp.v2.ProjectName;\n+import com.google.privacy.dlp.v2.Table;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionView;\n+\n+/**\n+ * A {@link PTransform} connecting to Cloud DLP (https://cloud.google.com/dlp/docs/libraries) and\n+ * deidentifying text according to provided settings. The transform supports both CSV formatted\n+ * input data and unstructured input.\n+ *\n+ * <p>If the csvHeader property is set and a sideinput with CSV headers is added to the PTransform,\n+ * csvDelimiter also should be set, else the results will be incorrect. If csvHeader is neither set\n+ * nor passed as sideinput, input is assumed to be unstructured.\n+ *\n+ * <p>Either deidentifyTemplateName (String) or deidentifyConfig {@link DeidentifyConfig} need to be\n+ * set. inspectTemplateName and inspectConfig ({@link InspectConfig} are optional.\n+ *\n+ * <p>Batch size defines how big are batches sent to DLP at once in bytes.\n+ *\n+ * <p>The transform consumes {@link KV} of {@link String}s (assumed to be filename as key and\n+ * contents as value) and outputs {@link KV} of {@link String} (eg. filename) and {@link\n+ * DeidentifyContentResponse}, which will contain {@link Table} of results for the user to consume.\n+ */\n+@Experimental\n+@AutoValue\n+public abstract class DLPDeidentifyText\n+    extends PTransform<\n+        PCollection<KV<String, String>>, PCollection<KV<String, DeidentifyContentResponse>>> {\n+\n+  public static final Integer DLP_PAYLOAD_LIMIT_BYTES = 524000;\n+\n+  /** @return Template name for data inspection. */\n+  @Nullable\n+  public abstract String inspectTemplateName();\n+\n+  /** @return Template name for data deidentification. */\n+  @Nullable\n+  public abstract String deidentifyTemplateName();\n+\n+  /**\n+   * @return Configuration object for data inspection. If present, supersedes the template settings.\n+   */\n+  @Nullable\n+  public abstract InspectConfig inspectConfig();\n+\n+  /** @return Configuration object for deidentification. If present, supersedes the template. */\n+  @Nullable\n+  public abstract DeidentifyConfig deidentifyConfig();\n+\n+  /** @return List of column names if the input KV value is a CSV formatted row. */\n+  @Nullable\n+  public abstract PCollectionView<List<String>> csvHeader();\n+\n+  /** @return Delimiter to be used when splitting values from input strings into columns. */\n+  @Nullable\n+  public abstract String csvColumnDelimiter();\n+\n+  /** @return Size of input elements batch to be sent to Cloud DLP service in one request. */\n+  public abstract Integer batchSizeBytes();\n+\n+  /** @return ID of Google Cloud project to be used when deidentifying data. */\n+  public abstract String projectId();\n+\n+  @AutoValue.Builder\n+  public abstract static class Builder {\n+    /** @param inspectTemplateName Template name for data inspection. */\n+    public abstract Builder setInspectTemplateName(String inspectTemplateName);\n+\n+    /** @param csvHeader List of column names if the input KV value is a CSV formatted row. */\n+    public abstract Builder setCsvHeader(PCollectionView<List<String>> csvHeader);\n+\n+    /**\n+     * @param delimiter Delimiter to be used when splitting values from input strings into columns.\n+     */\n+    public abstract Builder setCsvColumnDelimiter(String delimiter);", "originalCommit": "7b2c379d38d4c0cc97f8e89f8399406d0fe3534d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ3MTcyOA==", "url": "https://github.com/apache/beam/pull/11566#discussion_r431471728", "bodyText": "This condition is not checked in the build() method. Can it be?", "author": "tysonjh", "createdAt": "2020-05-27T22:10:49Z", "path": "sdks/java/extensions/ml/src/main/java/org/apache/beam/sdk/extensions/ml/DLPDeidentifyText.java", "diffHunk": "@@ -0,0 +1,267 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.ml;\n+\n+import com.google.auto.value.AutoValue;\n+import com.google.cloud.dlp.v2.DlpServiceClient;\n+import com.google.privacy.dlp.v2.ContentItem;\n+import com.google.privacy.dlp.v2.DeidentifyConfig;\n+import com.google.privacy.dlp.v2.DeidentifyContentRequest;\n+import com.google.privacy.dlp.v2.DeidentifyContentResponse;\n+import com.google.privacy.dlp.v2.FieldId;\n+import com.google.privacy.dlp.v2.InspectConfig;\n+import com.google.privacy.dlp.v2.ProjectName;\n+import com.google.privacy.dlp.v2.Table;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionView;\n+\n+/**\n+ * A {@link PTransform} connecting to Cloud DLP (https://cloud.google.com/dlp/docs/libraries) and\n+ * deidentifying text according to provided settings. The transform supports both CSV formatted\n+ * input data and unstructured input.\n+ *\n+ * <p>If the csvHeader property is set and a sideinput with CSV headers is added to the PTransform,\n+ * csvDelimiter also should be set, else the results will be incorrect. If csvHeader is neither set\n+ * nor passed as sideinput, input is assumed to be unstructured.", "originalCommit": "7b2c379d38d4c0cc97f8e89f8399406d0fe3534d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTY0MDkwNQ==", "url": "https://github.com/apache/beam/pull/11566#discussion_r431640905", "bodyText": "Sure, that's a good idea.", "author": "mwalenia", "createdAt": "2020-05-28T07:40:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ3MTcyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ3NTcxNQ==", "url": "https://github.com/apache/beam/pull/11566#discussion_r431475715", "bodyText": "It seems like the formatting is strange in this class. There aren't empty newlines between methods, did it pass the spotless check?\nAlso can you apply the comments from previous transforms to this class? For example, dropping the csv, naming getters with a prefix get, ensuring that all preconditions are validated in the build() method.", "author": "tysonjh", "createdAt": "2020-05-27T22:20:52Z", "path": "sdks/java/extensions/ml/src/main/java/org/apache/beam/sdk/extensions/ml/DLPInspectText.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.ml;\n+\n+import com.google.auto.value.AutoValue;\n+import com.google.cloud.dlp.v2.DlpServiceClient;\n+import com.google.privacy.dlp.v2.ContentItem;\n+import com.google.privacy.dlp.v2.FieldId;\n+import com.google.privacy.dlp.v2.InspectConfig;\n+import com.google.privacy.dlp.v2.InspectContentRequest;\n+import com.google.privacy.dlp.v2.InspectContentResponse;\n+import com.google.privacy.dlp.v2.ProjectName;\n+import com.google.privacy.dlp.v2.Table;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionView;\n+\n+/**\n+ * A {@link PTransform} connecting to Cloud DLP (https://cloud.google.com/dlp/docs/libraries) and\n+ * inspecting text for identifying data according to provided settings. The transform supports both\n+ * CSV formatted input data and unstructured input.\n+ *\n+ * <p>If the csvHeader property is set and a sideinput with CSV headers is added to the PTransform,\n+ * csvDelimiter also should be set, else the results will be incorrect. If csvHeader is neither set\n+ * nor passed as sideinput, input is assumed to be unstructured.\n+ *\n+ * <p>Batch size defines how big are batches sent to DLP at once in bytes.\n+ *\n+ * <p>The transform consumes {@link KV} of {@link String}s (assumed to be filename as key and\n+ * contents as value) and outputs {@link KV} of {@link String} (eg. filename) and {@link\n+ * InspectContentResponse}, which will contain {@link Table} of results for the user to consume.\n+ *\n+ * <p>Either inspectTemplateName (String) or inspectConfig {@link InspectConfig} need to be set.\n+ *\n+ * <p>Batch size defines how big are batches sent to DLP at once in bytes.\n+ */\n+@Experimental\n+@AutoValue\n+public abstract class DLPInspectText", "originalCommit": "7b2c379d38d4c0cc97f8e89f8399406d0fe3534d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTY0MTA5Nw==", "url": "https://github.com/apache/beam/pull/11566#discussion_r431641097", "bodyText": "The class passed spotless, I'll reformat it anyway.", "author": "mwalenia", "createdAt": "2020-05-28T07:40:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ3NTcxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjc1NTU2MA==", "url": "https://github.com/apache/beam/pull/11566#discussion_r432755560", "bodyText": "Thank you.", "author": "tysonjh", "createdAt": "2020-05-29T21:51:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ3NTcxNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ3Nzg3MA==", "url": "https://github.com/apache/beam/pull/11566#discussion_r431477870", "bodyText": "Similarly with this class, please apply comments from previous transforms here. For example, dropping the csv, naming getters with a prefix get, ensuring that all preconditions are validated in the build() method.", "author": "tysonjh", "createdAt": "2020-05-27T22:26:26Z", "path": "sdks/java/extensions/ml/src/main/java/org/apache/beam/sdk/extensions/ml/DLPReidentifyText.java", "diffHunk": "@@ -0,0 +1,271 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.ml;\n+\n+import com.google.auto.value.AutoValue;\n+import com.google.cloud.dlp.v2.DlpServiceClient;\n+import com.google.privacy.dlp.v2.ContentItem;\n+import com.google.privacy.dlp.v2.DeidentifyConfig;\n+import com.google.privacy.dlp.v2.FieldId;\n+import com.google.privacy.dlp.v2.InspectConfig;\n+import com.google.privacy.dlp.v2.ProjectName;\n+import com.google.privacy.dlp.v2.ReidentifyContentRequest;\n+import com.google.privacy.dlp.v2.ReidentifyContentResponse;\n+import com.google.privacy.dlp.v2.Table;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionView;\n+\n+/**\n+ * A {@link PTransform} connecting to Cloud DLP (https://cloud.google.com/dlp/docs/libraries) and\n+ * inspecting text for identifying data according to provided settings.\n+ *\n+ * <p>The transform supports both CSV formatted input data and unstructured input.\n+ *\n+ * <p>If the csvHeader property is set and a sideinput with CSV headers is added to the PTransform,\n+ * csvDelimiter also should be set, else the results will be incorrect. If csvHeader is neither set\n+ * nor passed as sideinput, input is assumed to be unstructured.\n+ *\n+ * <p>Batch size defines how big are batches sent to DLP at once in bytes.\n+ *\n+ * <p>The transform consumes {@link KV} of {@link String}s (assumed to be filename as key and\n+ * contents as value) and outputs {@link KV} of {@link String} (eg. filename) and {@link\n+ * ReidentifyContentResponse}, which will contain {@link Table} of results for the user to consume.\n+ *\n+ * <p>Batch size defines how big are batches sent to DLP at once in bytes.\n+ *\n+ * <p>Either reidentifyTemplateName {@link String} or reidentifyConfig {@link DeidentifyConfig} need\n+ * to be set. inspectConfig {@link InspectConfig} and inspectTemplateName {@link String} are\n+ * optional.\n+ *\n+ * <p>Batch size defines how big are batches sent to DLP at once in bytes.\n+ */\n+@Experimental\n+@AutoValue\n+public abstract class DLPReidentifyText", "originalCommit": "7b2c379d38d4c0cc97f8e89f8399406d0fe3534d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTY0MTE2NQ==", "url": "https://github.com/apache/beam/pull/11566#discussion_r431641165", "bodyText": "Sure!", "author": "mwalenia", "createdAt": "2020-05-28T07:41:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ3Nzg3MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjc1NjEwMg==", "url": "https://github.com/apache/beam/pull/11566#discussion_r432756102", "bodyText": "Thank you.", "author": "tysonjh", "createdAt": "2020-05-29T21:53:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ3Nzg3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ3OTU4Ng==", "url": "https://github.com/apache/beam/pull/11566#discussion_r431479586", "bodyText": "I'm getting a bit confused at when a header is present and when one isn't now. When building the table for the request to the cloud API, if no header is present, we set one to \"value\" by default. If that column header ends up in the response, should this method also return \"value\" when set to null?\nIf that is the case, this needs to be clear in the comments somewhere.", "author": "tysonjh", "createdAt": "2020-05-27T22:30:54Z", "path": "sdks/java/extensions/ml/src/main/java/org/apache/beam/sdk/extensions/ml/DLPDeidentifyText.java", "diffHunk": "@@ -0,0 +1,267 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.ml;\n+\n+import com.google.auto.value.AutoValue;\n+import com.google.cloud.dlp.v2.DlpServiceClient;\n+import com.google.privacy.dlp.v2.ContentItem;\n+import com.google.privacy.dlp.v2.DeidentifyConfig;\n+import com.google.privacy.dlp.v2.DeidentifyContentRequest;\n+import com.google.privacy.dlp.v2.DeidentifyContentResponse;\n+import com.google.privacy.dlp.v2.FieldId;\n+import com.google.privacy.dlp.v2.InspectConfig;\n+import com.google.privacy.dlp.v2.ProjectName;\n+import com.google.privacy.dlp.v2.Table;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionView;\n+\n+/**\n+ * A {@link PTransform} connecting to Cloud DLP (https://cloud.google.com/dlp/docs/libraries) and\n+ * deidentifying text according to provided settings. The transform supports both CSV formatted\n+ * input data and unstructured input.\n+ *\n+ * <p>If the csvHeader property is set and a sideinput with CSV headers is added to the PTransform,\n+ * csvDelimiter also should be set, else the results will be incorrect. If csvHeader is neither set\n+ * nor passed as sideinput, input is assumed to be unstructured.\n+ *\n+ * <p>Either deidentifyTemplateName (String) or deidentifyConfig {@link DeidentifyConfig} need to be\n+ * set. inspectTemplateName and inspectConfig ({@link InspectConfig} are optional.\n+ *\n+ * <p>Batch size defines how big are batches sent to DLP at once in bytes.\n+ *\n+ * <p>The transform consumes {@link KV} of {@link String}s (assumed to be filename as key and\n+ * contents as value) and outputs {@link KV} of {@link String} (eg. filename) and {@link\n+ * DeidentifyContentResponse}, which will contain {@link Table} of results for the user to consume.\n+ */\n+@Experimental\n+@AutoValue\n+public abstract class DLPDeidentifyText\n+    extends PTransform<\n+        PCollection<KV<String, String>>, PCollection<KV<String, DeidentifyContentResponse>>> {\n+\n+  public static final Integer DLP_PAYLOAD_LIMIT_BYTES = 524000;\n+\n+  /** @return Template name for data inspection. */\n+  @Nullable\n+  public abstract String inspectTemplateName();\n+\n+  /** @return Template name for data deidentification. */\n+  @Nullable\n+  public abstract String deidentifyTemplateName();\n+\n+  /**\n+   * @return Configuration object for data inspection. If present, supersedes the template settings.\n+   */\n+  @Nullable\n+  public abstract InspectConfig inspectConfig();\n+\n+  /** @return Configuration object for deidentification. If present, supersedes the template. */\n+  @Nullable\n+  public abstract DeidentifyConfig deidentifyConfig();\n+\n+  /** @return List of column names if the input KV value is a CSV formatted row. */", "originalCommit": "7b2c379d38d4c0cc97f8e89f8399406d0fe3534d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTc1MzMxNg==", "url": "https://github.com/apache/beam/pull/11566#discussion_r431753316", "bodyText": "I don't think this should return \"value\" if there's no header from the user, this property is for user-defined headers only and I don't think there's need to return the defaults anyway. We'd need to evaluate existence of the sideinput in the internal DoFn anyway, so there wouldn't be much gain in terms of code complexity anyway.", "author": "mwalenia", "createdAt": "2020-05-28T11:01:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ3OTU4Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjc1NzA1OA==", "url": "https://github.com/apache/beam/pull/11566#discussion_r432757058", "bodyText": "OK, sounds good.", "author": "tysonjh", "createdAt": "2020-05-29T21:56:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ3OTU4Ng=="}], "type": "inlineReview"}, {"oid": "987be4871c02e186903e8e5f452106accf7e9a0d", "url": "https://github.com/apache/beam/commit/987be4871c02e186903e8e5f452106accf7e9a0d", "message": "Get rid of CSV mentions", "committedDate": "2020-05-28T07:13:53Z", "type": "commit"}, {"oid": "2327f6f0162bb4760bd82173f3575f0fc228ce7a", "url": "https://github.com/apache/beam/commit/2327f6f0162bb4760bd82173f3575f0fc228ce7a", "message": "Rename getters to get*", "committedDate": "2020-05-28T07:18:03Z", "type": "commit"}, {"oid": "ff69b1de58056c79302223388a3e283da7363d1f", "url": "https://github.com/apache/beam/commit/ff69b1de58056c79302223388a3e283da7363d1f", "message": "Add delimiter requirement check to builders. Formatting in DLPInspectText", "committedDate": "2020-05-28T07:40:25Z", "type": "commit"}, {"oid": "c787b2a77b856cf23d4ac8aab082b5e542be7e23", "url": "https://github.com/apache/beam/commit/c787b2a77b856cf23d4ac8aab082b5e542be7e23", "message": "Add test of mapping delimited rows, verify table headers in deidentification", "committedDate": "2020-05-28T08:39:44Z", "type": "commit"}, {"oid": "423cd4d22e057e6018000afc793723f3ed1ba072", "url": "https://github.com/apache/beam/commit/423cd4d22e057e6018000afc793723f3ed1ba072", "message": "Add tests for preconditions in DLP transforms", "committedDate": "2020-05-28T09:41:51Z", "type": "commit"}, {"oid": "6a37f33b8d20f423e7e3384b8f992713e6a88325", "url": "https://github.com/apache/beam/commit/6a37f33b8d20f423e7e3384b8f992713e6a88325", "message": "Add more preconditions with tests", "committedDate": "2020-05-28T10:59:04Z", "type": "commit"}, {"oid": "80764a8fe303fbaf68d3c976ea952a06757b2222", "url": "https://github.com/apache/beam/commit/80764a8fe303fbaf68d3c976ea952a06757b2222", "message": "Change default GCP project name", "committedDate": "2020-05-28T11:49:51Z", "type": "commit"}, {"oid": "a4411f1d594d519eecff944869964758663729b9", "url": "https://github.com/apache/beam/commit/a4411f1d594d519eecff944869964758663729b9", "message": "Add info to CHANGES.md", "committedDate": "2020-05-28T11:59:25Z", "type": "commit"}, {"oid": "1f0e1bab149e4f28869f87c9a38cf5da7cf9e49a", "url": "https://github.com/apache/beam/commit/1f0e1bab149e4f28869f87c9a38cf5da7cf9e49a", "message": "Merge branch 'master' into BEAM-9723-java-dlp", "committedDate": "2020-05-28T12:45:35Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjg3NzM4NQ==", "url": "https://github.com/apache/beam/pull/11566#discussion_r432877385", "bodyText": "Does it make sense to move the creation of client in startBundle? Just commenting for overall all three use cases.", "author": "santhh", "createdAt": "2020-05-30T18:39:21Z", "path": "sdks/java/extensions/ml/src/main/java/org/apache/beam/sdk/extensions/ml/DLPReidentifyText.java", "diffHunk": "@@ -0,0 +1,281 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.ml;\n+\n+import com.google.auto.value.AutoValue;\n+import com.google.cloud.dlp.v2.DlpServiceClient;\n+import com.google.privacy.dlp.v2.ContentItem;\n+import com.google.privacy.dlp.v2.DeidentifyConfig;\n+import com.google.privacy.dlp.v2.FieldId;\n+import com.google.privacy.dlp.v2.InspectConfig;\n+import com.google.privacy.dlp.v2.ProjectName;\n+import com.google.privacy.dlp.v2.ReidentifyContentRequest;\n+import com.google.privacy.dlp.v2.ReidentifyContentResponse;\n+import com.google.privacy.dlp.v2.Table;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionView;\n+\n+/**\n+ * A {@link PTransform} connecting to Cloud DLP (https://cloud.google.com/dlp/docs/libraries) and\n+ * inspecting text for identifying data according to provided settings.\n+ *\n+ * <p>The transform supports both delimited columnar input data and unstructured input.\n+ *\n+ * <p>If the headerColumns property is set and a sideinput with headers is added to the PTransform,\n+ * delimiter also should be set, else the results will be incorrect. If headerColumns is neither set\n+ * nor passed as sideinput, input is assumed to be unstructured.\n+ *\n+ * <p>Batch size defines how big are batches sent to DLP at once in bytes.\n+ *\n+ * <p>The transform consumes {@link KV} of {@link String}s (assumed to be filename as key and\n+ * contents as value) and outputs {@link KV} of {@link String} (eg. filename) and {@link\n+ * ReidentifyContentResponse}, which will contain {@link Table} of results for the user to consume.\n+ *\n+ * <p>Batch size defines how big are batches sent to DLP at once in bytes.\n+ *\n+ * <p>Either reidentifyTemplateName {@link String} or reidentifyConfig {@link DeidentifyConfig} need\n+ * to be set. inspectConfig {@link InspectConfig} and inspectTemplateName {@link String} are\n+ * optional.\n+ *\n+ * <p>Batch size defines how big are batches sent to DLP at once in bytes.\n+ */\n+@Experimental\n+@AutoValue\n+public abstract class DLPReidentifyText\n+    extends PTransform<\n+        PCollection<KV<String, String>>, PCollection<KV<String, ReidentifyContentResponse>>> {\n+\n+  public static final Integer DLP_PAYLOAD_LIMIT_BYTES = 524000;\n+\n+  /** @return Template name for data inspection. */\n+  @Nullable\n+  public abstract String getInspectTemplateName();\n+\n+  /** @return Template name for data reidentification. */\n+  @Nullable\n+  public abstract String getReidentifyTemplateName();\n+\n+  /**\n+   * @return Configuration object for data inspection. If present, supersedes the template settings.\n+   */\n+  @Nullable\n+  public abstract InspectConfig getInspectConfig();\n+\n+  /** @return Configuration object for reidentification. If present, supersedes the template. */\n+  @Nullable\n+  public abstract DeidentifyConfig getReidentifyConfig();\n+\n+  /** @return Delimiter to be used when splitting values from input strings into columns. */\n+  @Nullable\n+  public abstract String getColumnDelimiter();\n+\n+  /** @return List of column names if the input KV value is a delimited row. */\n+  @Nullable\n+  public abstract PCollectionView<List<String>> getHeaderColumns();\n+\n+  /** @return Size of input elements batch to be sent to Cloud DLP service in one request. */\n+  public abstract Integer getBatchSizeBytes();\n+\n+  /** @return ID of Google Cloud project to be used when deidentifying data. */\n+  public abstract String getProjectId();\n+\n+  @AutoValue.Builder\n+  public abstract static class Builder {\n+    /** @param inspectTemplateName Template name for data inspection. */\n+    public abstract Builder setInspectTemplateName(String inspectTemplateName);\n+\n+    /**\n+     * @param inspectConfig Configuration object for data inspection. If present, supersedes the\n+     *     template settings.\n+     */\n+    public abstract Builder setInspectConfig(InspectConfig inspectConfig);\n+\n+    /**\n+     * @param reidentifyConfig Configuration object for data deidentification. If present,\n+     *     supersedes the template settings.\n+     */\n+    public abstract Builder setReidentifyConfig(DeidentifyConfig reidentifyConfig);\n+\n+    /** @param reidentifyTemplateName Template name for data deidentification. */\n+    public abstract Builder setReidentifyTemplateName(String reidentifyTemplateName);\n+\n+    /**\n+     * @param batchSize Size of input elements batch to be sent to Cloud DLP service in one request.\n+     */\n+    public abstract Builder setBatchSizeBytes(Integer batchSize);\n+    /** @param headerColumns List of column names if the input KV value is a delimited row. */\n+    public abstract Builder setHeaderColumns(PCollectionView<List<String>> headerColumns);\n+\n+    /**\n+     * @param delimiter Delimiter to be used when splitting values from input strings into columns.\n+     */\n+    public abstract Builder setColumnDelimiter(String delimiter);\n+\n+    /** @param projectId ID of Google Cloud project to be used when deidentifying data. */\n+    public abstract Builder setProjectId(String projectId);\n+\n+    abstract DLPReidentifyText autoBuild();\n+\n+    public DLPReidentifyText build() {\n+      DLPReidentifyText dlpReidentifyText = autoBuild();\n+      if (dlpReidentifyText.getReidentifyConfig() == null\n+          && dlpReidentifyText.getReidentifyTemplateName() == null) {\n+        throw new IllegalArgumentException(\n+            \"Either reidentifyConfig or reidentifyTemplateName need to be set!\");\n+      }\n+      if (dlpReidentifyText.getBatchSizeBytes() > DLP_PAYLOAD_LIMIT_BYTES) {\n+        throw new IllegalArgumentException(\n+            String.format(\n+                \"Batch size is too large! It should be smaller or equal than %d.\",\n+                DLP_PAYLOAD_LIMIT_BYTES));\n+      }\n+      if (dlpReidentifyText.getColumnDelimiter() == null\n+          && dlpReidentifyText.getHeaderColumns() != null) {\n+        throw new IllegalArgumentException(\n+            \"Column delimiter should be set if headers are present.\");\n+      }\n+      if (dlpReidentifyText.getHeaderColumns() == null\n+          && dlpReidentifyText.getColumnDelimiter() != null) {\n+        throw new IllegalArgumentException(\n+            \"Column headers should be supplied when delimiter is present.\");\n+      }\n+      return dlpReidentifyText;\n+    }\n+  }\n+\n+  public static DLPReidentifyText.Builder newBuilder() {\n+    return new AutoValue_DLPReidentifyText.Builder();\n+  }\n+\n+  /**\n+   * The transform converts the contents of input PCollection into {@link Table.Row}s and then calls\n+   * Cloud DLP service to perform the reidentification according to provided settings.\n+   *\n+   * @param input input PCollection\n+   * @return PCollection after transformations\n+   */\n+  @Override\n+  public PCollection<KV<String, ReidentifyContentResponse>> expand(\n+      PCollection<KV<String, String>> input) {\n+    return input\n+        .apply(ParDo.of(new MapStringToDlpRow(getColumnDelimiter())))\n+        .apply(\"Batch Contents\", ParDo.of(new BatchRequestForDLP(getBatchSizeBytes())))\n+        .apply(\n+            \"DLPReidentify\",\n+            ParDo.of(\n+                new ReidentifyText(\n+                    getProjectId(),\n+                    getInspectTemplateName(),\n+                    getReidentifyTemplateName(),\n+                    getInspectConfig(),\n+                    getReidentifyConfig(),\n+                    getHeaderColumns())));\n+  }\n+\n+  /** Performs the calls to Cloud DLP service on GCP. */\n+  static class ReidentifyText\n+      extends DoFn<KV<String, Iterable<Table.Row>>, KV<String, ReidentifyContentResponse>> {\n+    private final String projectId;\n+    private final String inspectTemplateName;\n+    private final String reidentifyTemplateName;\n+    private final InspectConfig inspectConfig;\n+    private final DeidentifyConfig reidentifyConfig;\n+    private transient ReidentifyContentRequest.Builder requestBuilder;\n+    private final PCollectionView<List<String>> headerColumns;\n+\n+    @Setup\n+    public void setup() throws IOException {\n+      requestBuilder =\n+          ReidentifyContentRequest.newBuilder().setParent(ProjectName.of(projectId).toString());\n+      if (inspectTemplateName != null) {\n+        requestBuilder.setInspectTemplateName(inspectTemplateName);\n+      }\n+      if (inspectConfig != null) {\n+        requestBuilder.setInspectConfig(inspectConfig);\n+      }\n+      if (reidentifyConfig != null) {\n+        requestBuilder.setReidentifyConfig(reidentifyConfig);\n+      }\n+      if (reidentifyTemplateName != null) {\n+        requestBuilder.setReidentifyTemplateName(reidentifyTemplateName);\n+      }\n+    }\n+\n+    /**\n+     * @param projectId ID of GCP project that should be used for deidentification.\n+     * @param inspectTemplateName Template name for inspection. Optional.\n+     * @param reidentifyTemplateName Template name for reidentification. Either this or\n+     *     reidentifyConfig is required.\n+     * @param inspectConfig Configuration object for inspection. Optional.\n+     * @param reidentifyConfig Reidentification config containing data transformations. Either this\n+     *     or reidentifyTemplateName is required.\n+     * @param headerColumns Header row of the table if applicable.\n+     */\n+    public ReidentifyText(\n+        String projectId,\n+        String inspectTemplateName,\n+        String reidentifyTemplateName,\n+        InspectConfig inspectConfig,\n+        DeidentifyConfig reidentifyConfig,\n+        PCollectionView<List<String>> headerColumns) {\n+      this.projectId = projectId;\n+      this.inspectTemplateName = inspectTemplateName;\n+      this.reidentifyTemplateName = reidentifyTemplateName;\n+      this.inspectConfig = inspectConfig;\n+      this.reidentifyConfig = reidentifyConfig;\n+      this.headerColumns = headerColumns;\n+    }\n+\n+    @ProcessElement\n+    public void processElement(ProcessContext context) throws IOException {\n+      try (DlpServiceClient dlpServiceClient = DlpServiceClient.create()) {", "originalCommit": "1f0e1bab149e4f28869f87c9a38cf5da7cf9e49a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzA2OTY1MQ==", "url": "https://github.com/apache/beam/pull/11566#discussion_r433069651", "bodyText": "We can move it to startBundle or to setup and close the client in teardown.", "author": "mwalenia", "createdAt": "2020-06-01T06:51:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjg3NzM4NQ=="}], "type": "inlineReview"}, {"oid": "5c18ed1e8e197e88469a00db73b8f8f3b8a65f85", "url": "https://github.com/apache/beam/commit/5c18ed1e8e197e88469a00db73b8f8f3b8a65f85", "message": "Move initialization of dlpServiceClient to setup/teardown methods", "committedDate": "2020-06-01T08:48:11Z", "type": "commit"}, {"oid": "4345b72f47ebe21a28b6885d67f24a53f3695be0", "url": "https://github.com/apache/beam/commit/4345b72f47ebe21a28b6885d67f24a53f3695be0", "message": "Merge branch 'BEAM-9723-java-dlp' of github.com:apache/beam into BEAM-9723-java-dlp", "committedDate": "2020-06-01T08:50:02Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzkwNzI5MQ==", "url": "https://github.com/apache/beam/pull/11566#discussion_r453907291", "bodyText": "@mwalenia Hi Michal- I have tried with 2.23 snapshot yesterday. Do you think it was missed to pass on the side input in this step? like .withSideInputs(headerColumns)", "author": "santhh", "createdAt": "2020-07-13T20:18:48Z", "path": "sdks/java/extensions/ml/src/main/java/org/apache/beam/sdk/extensions/ml/DLPDeidentifyText.java", "diffHunk": "@@ -0,0 +1,282 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.ml;\n+\n+import com.google.auto.value.AutoValue;\n+import com.google.cloud.dlp.v2.DlpServiceClient;\n+import com.google.privacy.dlp.v2.ContentItem;\n+import com.google.privacy.dlp.v2.DeidentifyConfig;\n+import com.google.privacy.dlp.v2.DeidentifyContentRequest;\n+import com.google.privacy.dlp.v2.DeidentifyContentResponse;\n+import com.google.privacy.dlp.v2.FieldId;\n+import com.google.privacy.dlp.v2.InspectConfig;\n+import com.google.privacy.dlp.v2.ProjectName;\n+import com.google.privacy.dlp.v2.Table;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionView;\n+\n+/**\n+ * A {@link PTransform} connecting to Cloud DLP (https://cloud.google.com/dlp/docs/libraries) and\n+ * deidentifying text according to provided settings. The transform supports both columnar delimited\n+ * input data (eg. CSV) and unstructured input.\n+ *\n+ * <p>If the headerColumns property is set and a sideinput with table headers is added to the\n+ * PTransform, delimiter also should be set, else the results will be incorrect. If headerColumns is\n+ * neither set nor passed as side input, input is assumed to be unstructured.\n+ *\n+ * <p>Either deidentifyTemplateName (String) or deidentifyConfig {@link DeidentifyConfig} need to be\n+ * set. inspectTemplateName and inspectConfig ({@link InspectConfig} are optional.\n+ *\n+ * <p>Batch size defines how big are batches sent to DLP at once in bytes.\n+ *\n+ * <p>The transform consumes {@link KV} of {@link String}s (assumed to be filename as key and\n+ * contents as value) and outputs {@link KV} of {@link String} (eg. filename) and {@link\n+ * DeidentifyContentResponse}, which will contain {@link Table} of results for the user to consume.\n+ */\n+@Experimental\n+@AutoValue\n+public abstract class DLPDeidentifyText\n+    extends PTransform<\n+        PCollection<KV<String, String>>, PCollection<KV<String, DeidentifyContentResponse>>> {\n+\n+  public static final Integer DLP_PAYLOAD_LIMIT_BYTES = 524000;\n+\n+  /** @return Template name for data inspection. */\n+  @Nullable\n+  public abstract String getInspectTemplateName();\n+\n+  /** @return Template name for data deidentification. */\n+  @Nullable\n+  public abstract String getDeidentifyTemplateName();\n+\n+  /**\n+   * @return Configuration object for data inspection. If present, supersedes the template settings.\n+   */\n+  @Nullable\n+  public abstract InspectConfig getInspectConfig();\n+\n+  /** @return Configuration object for deidentification. If present, supersedes the template. */\n+  @Nullable\n+  public abstract DeidentifyConfig getDeidentifyConfig();\n+\n+  /** @return List of column names if the input KV value is a delimited row. */\n+  @Nullable\n+  public abstract PCollectionView<List<String>> getHeaderColumns();\n+\n+  /** @return Delimiter to be used when splitting values from input strings into columns. */\n+  @Nullable\n+  public abstract String getColumnDelimiter();\n+\n+  /** @return Size of input elements batch to be sent to Cloud DLP service in one request. */\n+  public abstract Integer getBatchSizeBytes();\n+\n+  /** @return ID of Google Cloud project to be used when deidentifying data. */\n+  public abstract String getProjectId();\n+\n+  @AutoValue.Builder\n+  public abstract static class Builder {\n+    /** @param inspectTemplateName Template name for data inspection. */\n+    public abstract Builder setInspectTemplateName(String inspectTemplateName);\n+\n+    /** @param headerColumns List of column names if the input KV value is a delimited row. */\n+    public abstract Builder setHeaderColumns(PCollectionView<List<String>> headerColumns);\n+\n+    /**\n+     * @param delimiter Delimiter to be used when splitting values from input strings into columns.\n+     */\n+    public abstract Builder setColumnDelimiter(String delimiter);\n+\n+    /**\n+     * @param batchSize Size of input elements batch to be sent to Cloud DLP service in one request.\n+     */\n+    public abstract Builder setBatchSizeBytes(Integer batchSize);\n+\n+    /** @param projectId ID of Google Cloud project to be used when deidentifying data. */\n+    public abstract Builder setProjectId(String projectId);\n+\n+    /** @param deidentifyTemplateName Template name for data deidentification. */\n+    public abstract Builder setDeidentifyTemplateName(String deidentifyTemplateName);\n+\n+    /**\n+     * @param inspectConfig Configuration object for data inspection. If present, supersedes the\n+     *     template settings.\n+     */\n+    public abstract Builder setInspectConfig(InspectConfig inspectConfig);\n+\n+    /**\n+     * @param deidentifyConfig Configuration object for data deidentification. If present,\n+     *     supersedes the template settings.\n+     */\n+    public abstract Builder setDeidentifyConfig(DeidentifyConfig deidentifyConfig);\n+\n+    abstract DLPDeidentifyText autoBuild();\n+\n+    public DLPDeidentifyText build() {\n+      DLPDeidentifyText dlpDeidentifyText = autoBuild();\n+      if (dlpDeidentifyText.getDeidentifyConfig() == null\n+          && dlpDeidentifyText.getDeidentifyTemplateName() == null) {\n+        throw new IllegalArgumentException(\n+            \"Either deidentifyConfig or deidentifyTemplateName need to be set!\");\n+      }\n+      if (dlpDeidentifyText.getBatchSizeBytes() > DLP_PAYLOAD_LIMIT_BYTES) {\n+        throw new IllegalArgumentException(\n+            String.format(\n+                \"Batch size is too large! It should be smaller or equal than %d.\",\n+                DLP_PAYLOAD_LIMIT_BYTES));\n+      }\n+      if (dlpDeidentifyText.getColumnDelimiter() == null\n+          && dlpDeidentifyText.getHeaderColumns() != null) {\n+        throw new IllegalArgumentException(\n+            \"Column delimiter should be set if headers are present.\");\n+      }\n+      if (dlpDeidentifyText.getHeaderColumns() == null\n+          && dlpDeidentifyText.getColumnDelimiter() != null) {\n+        throw new IllegalArgumentException(\n+            \"Column headers should be supplied when delimiter is present.\");\n+      }\n+      return dlpDeidentifyText;\n+    }\n+  }\n+\n+  public static DLPDeidentifyText.Builder newBuilder() {\n+    return new AutoValue_DLPDeidentifyText.Builder();\n+  }\n+\n+  /**\n+   * The transform converts the contents of input PCollection into {@link Table.Row}s and then calls\n+   * Cloud DLP service to perform the deidentification according to provided settings.\n+   *\n+   * @param input input PCollection\n+   * @return PCollection after transformations\n+   */\n+  @Override\n+  public PCollection<KV<String, DeidentifyContentResponse>> expand(\n+      PCollection<KV<String, String>> input) {\n+    return input\n+        .apply(ParDo.of(new MapStringToDlpRow(getColumnDelimiter())))\n+        .apply(\"Batch Contents\", ParDo.of(new BatchRequestForDLP(getBatchSizeBytes())))\n+        .apply(\n+            \"DLPDeidentify\",\n+            ParDo.of(\n+                new DeidentifyText(\n+                    getProjectId(),\n+                    getInspectTemplateName(),\n+                    getDeidentifyTemplateName(),\n+                    getInspectConfig(),\n+                    getDeidentifyConfig(),\n+                    getHeaderColumns())));\n+  }\n+", "originalCommit": "4345b72f47ebe21a28b6885d67f24a53f3695be0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDgzMTk5MQ==", "url": "https://github.com/apache/beam/pull/11566#discussion_r454831991", "bodyText": "Thanks for your keen eye, it must have slipped our minds during review to check for the side input here. I'll try to get this fixed and ready for 2.23.", "author": "mwalenia", "createdAt": "2020-07-15T06:55:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzkwNzI5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTEyNDA0NA==", "url": "https://github.com/apache/beam/pull/11566#discussion_r455124044", "bodyText": "Thank you.", "author": "santhh", "createdAt": "2020-07-15T15:04:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzkwNzI5MQ=="}], "type": "inlineReview"}]}