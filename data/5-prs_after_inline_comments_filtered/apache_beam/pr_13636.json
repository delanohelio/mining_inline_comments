{"pr_number": 13636, "pr_title": "[BEAM-11411] [BEAM-11410] Kafka to pub sub E2E test", "pr_createdAt": "2020-12-30T14:58:59Z", "pr_url": "https://github.com/apache/beam/pull/13636", "timeline": [{"oid": "abda0aee7530cb3330a43783b441c0923f0036b7", "url": "https://github.com/apache/beam/commit/abda0aee7530cb3330a43783b441c0923f0036b7", "message": "Add E2E test with kafka and pubsub emulators", "committedDate": "2020-12-28T08:51:24Z", "type": "commit"}, {"oid": "6eaca3ef5a3d733eac9f623098c8e2a057295edc", "url": "https://github.com/apache/beam/commit/6eaca3ef5a3d733eac9f623098c8e2a057295edc", "message": "add dependencies", "committedDate": "2020-12-28T09:13:43Z", "type": "commit"}, {"oid": "70109d61b6ed34a653a8645f08f67d0769a98d3f", "url": "https://github.com/apache/beam/commit/70109d61b6ed34a653a8645f08f67d0769a98d3f", "message": "add more dependencies", "committedDate": "2020-12-28T09:41:57Z", "type": "commit"}, {"oid": "d03aaee379f4576121f7a81475124ecfd4019541", "url": "https://github.com/apache/beam/commit/d03aaee379f4576121f7a81475124ecfd4019541", "message": "add more and more dependencies", "committedDate": "2020-12-28T10:04:35Z", "type": "commit"}, {"oid": "baf0aaa784a9fa01bce0b96a99f712c7cad49680", "url": "https://github.com/apache/beam/commit/baf0aaa784a9fa01bce0b96a99f712c7cad49680", "message": "Merge branch 'master' of https://github.com/akvelon/beam into KafkaToPubSubE2E", "committedDate": "2020-12-28T16:28:39Z", "type": "commit"}, {"oid": "3928c47430c7f7112f07faa5dd3abe4df3a42f8f", "url": "https://github.com/apache/beam/commit/3928c47430c7f7112f07faa5dd3abe4df3a42f8f", "message": "- added testcontainers gcloud dependency\n- updated TestPubsubSignal to be compatible with PubSub emulator\n- KafkaToPubsubTest refactoring", "committedDate": "2020-12-29T12:09:10Z", "type": "commit"}, {"oid": "e5910831aedfa8b01046a2296fddb24580378296", "url": "https://github.com/apache/beam/commit/e5910831aedfa8b01046a2296fddb24580378296", "message": "- reverted unnecessary changes\n- changed logging to throwing errors", "committedDate": "2020-12-29T13:54:32Z", "type": "commit"}, {"oid": "9cea89e7c2f6622e6f8dfe05624e0be7b7431cc9", "url": "https://github.com/apache/beam/commit/9cea89e7c2f6622e6f8dfe05624e0be7b7431cc9", "message": "- moved RunKafkaContainer to utils package\n- moved E2E test to separate test class", "committedDate": "2020-12-29T14:25:57Z", "type": "commit"}, {"oid": "fd8fda7c04f75a8341c713644f8926e7d33f5016", "url": "https://github.com/apache/beam/commit/fd8fda7c04f75a8341c713644f8926e7d33f5016", "message": "- reverted unnecessary changes\n- added newline at the end of file", "committedDate": "2020-12-30T09:20:54Z", "type": "commit"}, {"oid": "9dcac86262329ffc02927a6001d15ac11a6870a3", "url": "https://github.com/apache/beam/commit/9dcac86262329ffc02927a6001d15ac11a6870a3", "message": "- added missing license headers", "committedDate": "2020-12-30T15:04:47Z", "type": "commit"}, {"oid": "bc7b38a6753b514a6df07dc56e20e7fd4500fd8c", "url": "https://github.com/apache/beam/commit/bc7b38a6753b514a6df07dc56e20e7fd4500fd8c", "message": "fixed formatting", "committedDate": "2020-12-30T16:03:50Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDI3NTk3MQ==", "url": "https://github.com/apache/beam/pull/13636#discussion_r550275971", "bodyText": "You might look at using TestPubsub to create the test topic instead of creating it manually. TestPubsub also has a method that you can use to check the topic receives some expected messages, which would save you from creating the readFromPubsub transform to signal success from within the pipeline: \n  \n    \n      beam/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsub/TestPubsub.java\n    \n    \n         Line 342\n      in\n      5e17b69\n    \n    \n    \n    \n\n        \n          \n             public PollingAssertion assertThatTopicEventuallyReceives(Matcher<PubsubMessage>... matchers) { \n        \n    \n  \n\n\nIt will be tricky to make this work with the pubsub test container though, since we'll need to start the test container before the TestPubsub Rule initializes its topic. This would be really useful infrastructure though as it would allow us to run many other pubsub tests against the fake instead of prod pubsub.", "author": "TheNeuralBit", "createdAt": "2020-12-30T17:49:25Z", "path": "examples/java/src/test/java/org/apache/beam/examples/complete/kafkatopubsub/KafkaToPubsubE2ETest.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.examples.complete.kafkatopubsub;\n+\n+import static org.apache.beam.examples.complete.kafkatopubsub.transforms.FormatTransform.readFromKafka;\n+\n+import com.google.auth.Credentials;\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.function.Supplier;\n+import org.apache.beam.examples.complete.kafkatopubsub.utils.RunKafkaContainer;\n+import org.apache.beam.runners.direct.DirectOptions;\n+import org.apache.beam.sdk.PipelineResult;\n+import org.apache.beam.sdk.extensions.gcp.auth.NoopCredentialFactory;\n+import org.apache.beam.sdk.extensions.gcp.options.GcpOptions;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubClient;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubIO;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubJsonClient;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubOptions;\n+import org.apache.beam.sdk.io.gcp.pubsub.TestPubsubSignal;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.testing.TestPipeline;\n+import org.apache.beam.sdk.transforms.Values;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.joda.time.Duration;\n+import org.junit.BeforeClass;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.testcontainers.containers.PubSubEmulatorContainer;\n+import org.testcontainers.utility.DockerImageName;\n+\n+/** E2E test for {@link KafkaToPubsub} pipeline. */\n+public class KafkaToPubsubE2ETest {\n+\n+  @Rule public final transient TestPipeline pipeline = TestPipeline.fromOptions(OPTIONS);\n+  @Rule public transient TestPubsubSignal signal = TestPubsubSignal.fromOptions(OPTIONS);\n+\n+  private static final String PUBSUB_EMULATOR_IMAGE =\n+      \"gcr.io/google.com/cloudsdktool/cloud-sdk:316.0.0-emulators\";\n+  private static final String PUBSUB_MESSAGE = \"test pubsub message\";\n+  private static final String PROJECT_ID = \"try-kafka-pubsub\";\n+  private static final String TOPIC_NAME = \"listen-to-kafka\";\n+  private static final PubsubClient.TopicPath TOPIC_PATH =\n+      PubsubClient.topicPathFromName(PROJECT_ID, TOPIC_NAME);\n+  private static final PipelineOptions OPTIONS = TestPipeline.testingPipelineOptions();\n+\n+  @BeforeClass\n+  public static void beforeClass() throws Exception {\n+    Credentials credentials = NoopCredentialFactory.fromOptions(OPTIONS).getCredential();\n+    OPTIONS.as(GcpOptions.class).setGcpCredential(credentials);\n+    OPTIONS.as(GcpOptions.class).setProject(PROJECT_ID);\n+    setupPubsubContainer(OPTIONS.as(PubsubOptions.class));\n+    createPubsubTopicForTest(OPTIONS.as(PubsubOptions.class));\n+  }\n+\n+  @Test\n+  public void testKafkaToPubsubE2E() throws IOException {\n+    pipeline.getOptions().as(DirectOptions.class).setBlockOnRun(false);\n+\n+    RunKafkaContainer rkc = new RunKafkaContainer(PUBSUB_MESSAGE);\n+    String bootstrapServer = rkc.getBootstrapServer();\n+    String[] kafkaTopicsList = new String[] {rkc.getTopicName()};\n+\n+    String pubsubTopicPath = TOPIC_PATH.getPath();\n+\n+    Map<String, Object> kafkaConfig = new HashMap<>();\n+    Map<String, String> sslConfig = new HashMap<>();\n+\n+    PCollection<KV<String, String>> readStrings =\n+        pipeline.apply(\n+            \"readFromKafka\",\n+            readFromKafka(bootstrapServer, Arrays.asList(kafkaTopicsList), kafkaConfig, sslConfig));\n+\n+    PCollection<String> readFromPubsub =\n+        readStrings\n+            .apply(Values.create())\n+            .apply(\"writeToPubSub\", PubsubIO.writeStrings().to(pubsubTopicPath))\n+            .getPipeline()\n+            .apply(\"readFromPubsub\", PubsubIO.readStrings().fromTopic(pubsubTopicPath));\n+\n+    readFromPubsub.apply(\n+        \"waitForTestMessage\",\n+        signal.signalSuccessWhen(\n+            readFromPubsub.getCoder(),\n+            input -> {\n+              if (input == null) {\n+                return false;\n+              }\n+              return input.stream().anyMatch(message -> Objects.equals(message, PUBSUB_MESSAGE));\n+            }));\n+\n+    Supplier<Void> start = signal.waitForStart(Duration.standardSeconds(10));\n+    pipeline.apply(signal.signalStart());\n+    PipelineResult job = pipeline.run();\n+    start.get();\n+    signal.waitForSuccess(Duration.standardMinutes(2));\n+    try {\n+      job.cancel();\n+    } catch (IOException | UnsupportedOperationException e) {\n+      throw new AssertionError(\"Could not stop pipeline.\", e);\n+    }\n+  }\n+\n+  private static void setupPubsubContainer(PubsubOptions options) {\n+    PubSubEmulatorContainer emulator =\n+        new PubSubEmulatorContainer(DockerImageName.parse(PUBSUB_EMULATOR_IMAGE));\n+    emulator.start();\n+    String pubsubUrl = emulator.getEmulatorEndpoint();\n+    options.setPubsubRootUrl(\"http://\" + pubsubUrl);\n+  }\n+\n+  private static void createPubsubTopicForTest(PubsubOptions options) {\n+    try {\n+      PubsubClient pubsubClient = PubsubJsonClient.FACTORY.newClient(null, null, options);\n+      pubsubClient.createTopic(TOPIC_PATH);\n+    } catch (Exception e) {\n+      throw new RuntimeException(e);", "originalCommit": "bc7b38a6753b514a6df07dc56e20e7fd4500fd8c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ4MTIxNQ==", "url": "https://github.com/apache/beam/pull/13636#discussion_r556481215", "bodyText": "Thank you for the suggestion, changed to using TestPubsub", "author": "ramazan-yapparov", "createdAt": "2021-01-13T12:23:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDI3NTk3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Njk1MjEzNw==", "url": "https://github.com/apache/beam/pull/13636#discussion_r556952137", "bodyText": "Awesome! Thanks for making TestPubSub work with the emulator container \ud83d\udc4d\nIs the trick to making sure the test container is run before TestPubsub to make the container a @ClassRule?", "author": "TheNeuralBit", "createdAt": "2021-01-13T23:49:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDI3NTk3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzA5NjA2OA==", "url": "https://github.com/apache/beam/pull/13636#discussion_r557096068", "bodyText": "Exactly", "author": "ramazan-yapparov", "createdAt": "2021-01-14T07:21:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDI3NTk3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDI3NzgzMA==", "url": "https://github.com/apache/beam/pull/13636#discussion_r550277830", "bodyText": "Could you instead inject the data in the test after the pipeline has started?", "author": "TheNeuralBit", "createdAt": "2020-12-30T17:56:06Z", "path": "examples/java/src/test/java/org/apache/beam/examples/complete/kafkatopubsub/utils/RunKafkaContainer.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.examples.complete.kafkatopubsub.utils;\n+\n+import java.util.UUID;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.testcontainers.containers.KafkaContainer;\n+import org.testcontainers.utility.DockerImageName;\n+\n+/** Run kafka container in separate thread to produce message. */\n+public class RunKafkaContainer {\n+\n+  private static final String KAFKA_IMAGE_NAME = \"confluentinc/cp-kafka:5.4.3\";\n+  private final String topicName;\n+  private final KafkaProducer<String, String> producer;\n+  private final String bootstrapServer;\n+\n+  public RunKafkaContainer(String pubsubMessage) {\n+    bootstrapServer = setupKafkaContainer();\n+    topicName = \"messages-topic\";\n+    producer =\n+        new KafkaProducer<>(\n+            ImmutableMap.of(\n+                ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,\n+                bootstrapServer,\n+                ProducerConfig.CLIENT_ID_CONFIG,\n+                UUID.randomUUID().toString()),\n+            new StringSerializer(),\n+            new StringSerializer());\n+    Runnable kafkaProducer =\n+        () -> {\n+          try {\n+            producer.send(new ProducerRecord<>(topicName, \"testcontainers\", pubsubMessage)).get();\n+            System.out.println(\"Producer sent\");\n+          } catch (ExecutionException | InterruptedException e) {\n+            throw new RuntimeException(\"Something went wrong in kafka producer\", e);\n+          }\n+        };\n+    // Without saving `.schedule(...)` result to variable checkframework will fail\n+    @SuppressWarnings(\"unused\")\n+    ScheduledFuture<?> schedule =\n+        Executors.newSingleThreadScheduledExecutor().schedule(kafkaProducer, 10, TimeUnit.SECONDS);", "originalCommit": "bc7b38a6753b514a6df07dc56e20e7fd4500fd8c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ4MTU3Mg==", "url": "https://github.com/apache/beam/pull/13636#discussion_r556481572", "bodyText": "Fixed, thanks", "author": "ramazan-yapparov", "createdAt": "2021-01-13T12:23:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDI3NzgzMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDI3NzkxOA==", "url": "https://github.com/apache/beam/pull/13636#discussion_r550277918", "bodyText": "It would be preferable to run the exact KafkaToPubsub pipeline, then use utilities outside of the pipeline to inject data to the kafka topic, and then to verify the pubsub topic receives the expected messages. As noted in my other comment TestPubsub can help with the latter.", "author": "TheNeuralBit", "createdAt": "2020-12-30T17:56:22Z", "path": "examples/java/src/test/java/org/apache/beam/examples/complete/kafkatopubsub/KafkaToPubsubE2ETest.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.examples.complete.kafkatopubsub;\n+\n+import static org.apache.beam.examples.complete.kafkatopubsub.transforms.FormatTransform.readFromKafka;\n+\n+import com.google.auth.Credentials;\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.function.Supplier;\n+import org.apache.beam.examples.complete.kafkatopubsub.utils.RunKafkaContainer;\n+import org.apache.beam.runners.direct.DirectOptions;\n+import org.apache.beam.sdk.PipelineResult;\n+import org.apache.beam.sdk.extensions.gcp.auth.NoopCredentialFactory;\n+import org.apache.beam.sdk.extensions.gcp.options.GcpOptions;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubClient;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubIO;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubJsonClient;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubOptions;\n+import org.apache.beam.sdk.io.gcp.pubsub.TestPubsubSignal;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.testing.TestPipeline;\n+import org.apache.beam.sdk.transforms.Values;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.joda.time.Duration;\n+import org.junit.BeforeClass;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.testcontainers.containers.PubSubEmulatorContainer;\n+import org.testcontainers.utility.DockerImageName;\n+\n+/** E2E test for {@link KafkaToPubsub} pipeline. */\n+public class KafkaToPubsubE2ETest {\n+\n+  @Rule public final transient TestPipeline pipeline = TestPipeline.fromOptions(OPTIONS);\n+  @Rule public transient TestPubsubSignal signal = TestPubsubSignal.fromOptions(OPTIONS);\n+\n+  private static final String PUBSUB_EMULATOR_IMAGE =\n+      \"gcr.io/google.com/cloudsdktool/cloud-sdk:316.0.0-emulators\";\n+  private static final String PUBSUB_MESSAGE = \"test pubsub message\";\n+  private static final String PROJECT_ID = \"try-kafka-pubsub\";\n+  private static final String TOPIC_NAME = \"listen-to-kafka\";\n+  private static final PubsubClient.TopicPath TOPIC_PATH =\n+      PubsubClient.topicPathFromName(PROJECT_ID, TOPIC_NAME);\n+  private static final PipelineOptions OPTIONS = TestPipeline.testingPipelineOptions();\n+\n+  @BeforeClass\n+  public static void beforeClass() throws Exception {\n+    Credentials credentials = NoopCredentialFactory.fromOptions(OPTIONS).getCredential();\n+    OPTIONS.as(GcpOptions.class).setGcpCredential(credentials);\n+    OPTIONS.as(GcpOptions.class).setProject(PROJECT_ID);\n+    setupPubsubContainer(OPTIONS.as(PubsubOptions.class));\n+    createPubsubTopicForTest(OPTIONS.as(PubsubOptions.class));\n+  }\n+\n+  @Test\n+  public void testKafkaToPubsubE2E() throws IOException {\n+    pipeline.getOptions().as(DirectOptions.class).setBlockOnRun(false);\n+\n+    RunKafkaContainer rkc = new RunKafkaContainer(PUBSUB_MESSAGE);\n+    String bootstrapServer = rkc.getBootstrapServer();\n+    String[] kafkaTopicsList = new String[] {rkc.getTopicName()};\n+\n+    String pubsubTopicPath = TOPIC_PATH.getPath();\n+\n+    Map<String, Object> kafkaConfig = new HashMap<>();\n+    Map<String, String> sslConfig = new HashMap<>();\n+\n+    PCollection<KV<String, String>> readStrings =\n+        pipeline.apply(\n+            \"readFromKafka\",\n+            readFromKafka(bootstrapServer, Arrays.asList(kafkaTopicsList), kafkaConfig, sslConfig));\n+\n+    PCollection<String> readFromPubsub =\n+        readStrings\n+            .apply(Values.create())\n+            .apply(\"writeToPubSub\", PubsubIO.writeStrings().to(pubsubTopicPath))\n+            .getPipeline()\n+            .apply(\"readFromPubsub\", PubsubIO.readStrings().fromTopic(pubsubTopicPath));", "originalCommit": "bc7b38a6753b514a6df07dc56e20e7fd4500fd8c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ4MTk5NA==", "url": "https://github.com/apache/beam/pull/13636#discussion_r556481994", "bodyText": "Fixed that, now instead of building the pipeline in the test we execute KafkaToPubsub#run method", "author": "ramazan-yapparov", "createdAt": "2021-01-13T12:24:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDI3NzkxOA=="}], "type": "inlineReview"}, {"oid": "4cf50bfcf103cf5b33360fce0dce280eb431bcf7", "url": "https://github.com/apache/beam/commit/4cf50bfcf103cf5b33360fce0dce280eb431bcf7", "message": "Moved from using TestPubsubSignal to using TestPubsub", "committedDate": "2021-01-12T12:26:24Z", "type": "commit"}, {"oid": "7798b354105d6f7793d1d99c638bb365c10641ae", "url": "https://github.com/apache/beam/commit/7798b354105d6f7793d1d99c638bb365c10641ae", "message": "- changed manual containers execution to using @ClassRule\n- removed RunKafkaContainer class completely\n- sending kafka message directly in test instead of using a scheduler", "committedDate": "2021-01-12T14:25:26Z", "type": "commit"}, {"oid": "ccb082e1d29b0266dabf7de3bac41880b44e852d", "url": "https://github.com/apache/beam/commit/ccb082e1d29b0266dabf7de3bac41880b44e852d", "message": "- updates test so it now runs actual pipeline instead of building it manually\n- added new property to KafkaToPubsubOptions for kafka consumer configuration", "committedDate": "2021-01-13T10:33:20Z", "type": "commit"}, {"oid": "dea9b6f4d476c9ddeffb37f63fa1245bef3e0299", "url": "https://github.com/apache/beam/commit/dea9b6f4d476c9ddeffb37f63fa1245bef3e0299", "message": "Merge branch 'master' of github.com:akvelon/beam into KafkaToPubSubE2E", "committedDate": "2021-01-13T10:35:34Z", "type": "commit"}, {"oid": "c66262f8871b2fa105edc27862eff1e84c5cf547", "url": "https://github.com/apache/beam/commit/c66262f8871b2fa105edc27862eff1e84c5cf547", "message": "- increased message waiting duration to 1 minute\n- reverted unnecessary change in TestPubsubSignal\n- minor fixes", "committedDate": "2021-01-13T12:21:07Z", "type": "commit"}, {"oid": "579c00e1dd116258569be3d091d883eb5fdc19c9", "url": "https://github.com/apache/beam/commit/579c00e1dd116258569be3d091d883eb5fdc19c9", "message": "Fixed formatting issues", "committedDate": "2021-01-13T13:19:08Z", "type": "commit"}, {"oid": "00208863d8ad96f082856cfe034a2f3052fb524c", "url": "https://github.com/apache/beam/commit/00208863d8ad96f082856cfe034a2f3052fb524c", "message": "Fixed styling issue", "committedDate": "2021-01-13T13:36:38Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Njk1NDA1Mw==", "url": "https://github.com/apache/beam/pull/13636#discussion_r556954053", "bodyText": "Could you rename this to KafkaToPubsubIT? Our build files assume *Test is a unit test and *IT is an integration test.", "author": "TheNeuralBit", "createdAt": "2021-01-13T23:54:52Z", "path": "examples/java/src/test/java/org/apache/beam/examples/complete/kafkatopubsub/KafkaToPubsubE2ETest.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.examples.complete.kafkatopubsub;\n+\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.hasProperty;\n+\n+import com.google.auth.Credentials;\n+import java.nio.charset.StandardCharsets;\n+import java.util.UUID;\n+import java.util.concurrent.ExecutionException;\n+import org.apache.beam.examples.complete.kafkatopubsub.options.KafkaToPubsubOptions;\n+import org.apache.beam.examples.complete.kafkatopubsub.transforms.FormatTransform.FORMAT;\n+import org.apache.beam.runners.direct.DirectOptions;\n+import org.apache.beam.sdk.PipelineResult;\n+import org.apache.beam.sdk.extensions.gcp.auth.NoopCredentialFactory;\n+import org.apache.beam.sdk.extensions.gcp.options.GcpOptions;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubOptions;\n+import org.apache.beam.sdk.io.gcp.pubsub.TestPubsub;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.testing.TestPipeline;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.joda.time.Duration;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.testcontainers.containers.KafkaContainer;\n+import org.testcontainers.containers.PubSubEmulatorContainer;\n+import org.testcontainers.utility.DockerImageName;\n+\n+/** E2E test for {@link KafkaToPubsub} pipeline. */\n+public class KafkaToPubsubE2ETest {", "originalCommit": "00208863d8ad96f082856cfe034a2f3052fb524c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Njk1NTMxMQ==", "url": "https://github.com/apache/beam/pull/13636#discussion_r556955311", "bodyText": "We have a precommit check that should run this example on Dataflow. It looks like this test isn't run there now, but that's likely because the name is Test and not IT.\nWhen you rename the test and this runs on Dataflow, this timeout won't be long enough, since Dataflow takes several minutes to start up workers. You should bump it up to 10 minutes probably.", "author": "TheNeuralBit", "createdAt": "2021-01-13T23:58:15Z", "path": "examples/java/src/test/java/org/apache/beam/examples/complete/kafkatopubsub/KafkaToPubsubE2ETest.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.examples.complete.kafkatopubsub;\n+\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.hasProperty;\n+\n+import com.google.auth.Credentials;\n+import java.nio.charset.StandardCharsets;\n+import java.util.UUID;\n+import java.util.concurrent.ExecutionException;\n+import org.apache.beam.examples.complete.kafkatopubsub.options.KafkaToPubsubOptions;\n+import org.apache.beam.examples.complete.kafkatopubsub.transforms.FormatTransform.FORMAT;\n+import org.apache.beam.runners.direct.DirectOptions;\n+import org.apache.beam.sdk.PipelineResult;\n+import org.apache.beam.sdk.extensions.gcp.auth.NoopCredentialFactory;\n+import org.apache.beam.sdk.extensions.gcp.options.GcpOptions;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubOptions;\n+import org.apache.beam.sdk.io.gcp.pubsub.TestPubsub;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.testing.TestPipeline;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.joda.time.Duration;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.testcontainers.containers.KafkaContainer;\n+import org.testcontainers.containers.PubSubEmulatorContainer;\n+import org.testcontainers.utility.DockerImageName;\n+\n+/** E2E test for {@link KafkaToPubsub} pipeline. */\n+public class KafkaToPubsubE2ETest {\n+  private static final String PUBSUB_EMULATOR_IMAGE =\n+      \"gcr.io/google.com/cloudsdktool/cloud-sdk:316.0.0-emulators\";\n+  private static final String KAFKA_IMAGE_NAME = \"confluentinc/cp-kafka:5.4.3\";\n+  private static final String PUBSUB_MESSAGE = \"test pubsub message\";\n+  private static final String KAFKA_TOPIC_NAME = \"messages-topic\";\n+  private static final String PROJECT_ID = \"try-kafka-pubsub\";\n+  private static final PipelineOptions OPTIONS = TestPipeline.testingPipelineOptions();\n+\n+  @ClassRule\n+  public static final PubSubEmulatorContainer PUB_SUB_EMULATOR_CONTAINER =\n+      new PubSubEmulatorContainer(DockerImageName.parse(PUBSUB_EMULATOR_IMAGE));\n+\n+  @ClassRule\n+  public static final KafkaContainer KAFKA_CONTAINER =\n+      new KafkaContainer(DockerImageName.parse(KAFKA_IMAGE_NAME));\n+\n+  @Rule public final transient TestPipeline pipeline = TestPipeline.fromOptions(OPTIONS);\n+  @Rule public final transient TestPubsub testPubsub = TestPubsub.fromOptions(OPTIONS);\n+\n+  @BeforeClass\n+  public static void beforeClass() throws Exception {\n+    Credentials credentials = NoopCredentialFactory.fromOptions(OPTIONS).getCredential();\n+    OPTIONS.as(DirectOptions.class).setBlockOnRun(false);\n+    OPTIONS.as(GcpOptions.class).setGcpCredential(credentials);\n+    OPTIONS.as(GcpOptions.class).setProject(PROJECT_ID);\n+    OPTIONS\n+        .as(PubsubOptions.class)\n+        .setPubsubRootUrl(\"http://\" + PUB_SUB_EMULATOR_CONTAINER.getEmulatorEndpoint());\n+    OPTIONS.as(KafkaToPubsubOptions.class).setOutputFormat(FORMAT.PUBSUB);\n+    OPTIONS\n+        .as(KafkaToPubsubOptions.class)\n+        .setBootstrapServers(KAFKA_CONTAINER.getBootstrapServers());\n+    OPTIONS.as(KafkaToPubsubOptions.class).setInputTopics(KAFKA_TOPIC_NAME);\n+    OPTIONS\n+        .as(KafkaToPubsubOptions.class)\n+        .setKafkaConsumerConfig(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG + \"=earliest\");\n+  }\n+\n+  @Before\n+  public void setUp() {\n+    OPTIONS.as(KafkaToPubsubOptions.class).setOutputTopic(testPubsub.topicPath().getPath());\n+  }\n+\n+  @Test\n+  public void testKafkaToPubsubE2E() throws Exception {\n+    PipelineResult job = KafkaToPubsub.run(pipeline, OPTIONS.as(KafkaToPubsubOptions.class));\n+\n+    sendKafkaMessage();\n+    testPubsub\n+        .assertThatTopicEventuallyReceives(\n+            hasProperty(\"payload\", equalTo(PUBSUB_MESSAGE.getBytes(StandardCharsets.UTF_8))))\n+        .waitForUpTo(Duration.standardMinutes(1));", "originalCommit": "00208863d8ad96f082856cfe034a2f3052fb524c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "f68fd02d0f50acbb1425cfeb4618f4438d47f350", "url": "https://github.com/apache/beam/commit/f68fd02d0f50acbb1425cfeb4618f4438d47f350", "message": "Merge branch 'master' of github.com:apache/beam into KafkaToPubSubE2E", "committedDate": "2021-01-14T11:50:03Z", "type": "commit"}, {"oid": "46f44c96e545900289af0309fa238442d4e57d4b", "url": "https://github.com/apache/beam/commit/46f44c96e545900289af0309fa238442d4e57d4b", "message": "Intentionally broke the test", "committedDate": "2021-01-14T12:56:47Z", "type": "commit"}, {"oid": "24ddb6e9eee92445696aa162abe3aa5daaafdeb8", "url": "https://github.com/apache/beam/commit/24ddb6e9eee92445696aa162abe3aa5daaafdeb8", "message": "Fixed broken test", "committedDate": "2021-01-14T13:39:31Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjI3NDQ3NA==", "url": "https://github.com/apache/beam/pull/13636#discussion_r562274474", "bodyText": "nit: If I were writing this I would probably combine these two lines and avoid creating the Pair:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    .map(kv -> Pair.of(kv[0], kv[1]))\n          \n          \n            \n                    .collect(Collectors.toMap(Pair::getKey, Pair::getValue));\n          \n          \n            \n                    .collect(Collectors.toMap(kv -> kv[0], kv -> kv[1]));\n          \n      \n    \n    \n  \n\nIf you prefer it with the Pair that's fine too.\nOne thing I think we should change is make this a private static method in KafkaToPubsub, since it's only used there.", "author": "TheNeuralBit", "createdAt": "2021-01-21T23:55:27Z", "path": "examples/java/src/main/java/org/apache/beam/examples/complete/kafkatopubsub/kafka/consumer/Utils.java", "diffHunk": "@@ -162,4 +165,11 @@ public static boolean isSslSpecified(KafkaToPubsubOptions options) {\n         || options.getKeystorePath() != null\n         || options.getKeyPassword() != null;\n   }\n+\n+  public static Map<String, Object> parseKafkaConsumerConfig(String kafkaConsumerConfig) {\n+    return Arrays.stream(kafkaConsumerConfig.split(\";\"))\n+        .map(s -> s.split(\"=\"))\n+        .map(kv -> Pair.of(kv[0], kv[1]))\n+        .collect(Collectors.toMap(Pair::getKey, Pair::getValue));", "originalCommit": "24ddb6e9eee92445696aa162abe3aa5daaafdeb8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzYwNTIzMA==", "url": "https://github.com/apache/beam/pull/13636#discussion_r563605230", "bodyText": "Removed Pair related code, but left method in place.\nThis class is created for such methods, in my opinion it is better to declare them in Utils in order to leave main class as clean as possible", "author": "ramazan-yapparov", "createdAt": "2021-01-25T10:14:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjI3NDQ3NA=="}], "type": "inlineReview"}, {"oid": "f6410c53553497eed48c574c81b0a55d26090304", "url": "https://github.com/apache/beam/commit/f6410c53553497eed48c574c81b0a55d26090304", "message": "Minor fixes", "committedDate": "2021-01-22T09:19:31Z", "type": "commit"}, {"oid": "3e166d922ba9d4d0e8cc8d6b89d0f197707f4a42", "url": "https://github.com/apache/beam/commit/3e166d922ba9d4d0e8cc8d6b89d0f197707f4a42", "message": "Merge branch 'master' of github.com:apache/beam into KafkaToPubSubE2E", "committedDate": "2021-01-22T09:20:21Z", "type": "commit"}, {"oid": "9e6ac2050d217a133d81892ecbec6f7ab8bf3d2d", "url": "https://github.com/apache/beam/commit/9e6ac2050d217a133d81892ecbec6f7ab8bf3d2d", "message": "Merge branch 'master' of github.com:apache/beam into KafkaToPubSubE2E", "committedDate": "2021-01-24T21:15:37Z", "type": "commit"}]}