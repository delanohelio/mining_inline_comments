{"pr_number": 10945, "pr_title": "[BEAM-9295] Add Flink 1.10 build target and Make FlinkRunner compatible with Flink 1.10", "pr_createdAt": "2020-02-24T03:16:54Z", "pr_url": "https://github.com/apache/beam/pull/10945", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDI4NDIzNw==", "url": "https://github.com/apache/beam/pull/10945#discussion_r384284237", "bodyText": "It has sets the default managed memory size to 128MB for MiniCluster in https://issues.apache.org/jira/browse/FLINK-15763. Have set it to a large value when the master host is [local]. Appreciate for any suggestions on a better way to address this issue.", "author": "sunjincheng121", "createdAt": "2020-02-26T05:41:33Z", "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkExecutionEnvironments.java", "diffHunk": "@@ -67,6 +69,7 @@ static ExecutionEnvironment createBatchExecutionEnvironment(\n \n     // depending on the master, create the right environment.\n     if (\"[local]\".equals(flinkMasterHostPort)) {\n+      flinkConfiguration.set(TaskManagerOptions.MANAGED_MEMORY_SIZE, MemorySize.parse(\"2048m\"));", "originalCommit": "156c43747f81ee6b539af054769f54155ff039c4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "82b781c3f39ffe684ca93bde7c8520244cdfe4a3", "url": "https://github.com/apache/beam/commit/82b781c3f39ffe684ca93bde7c8520244cdfe4a3", "message": "fixup! [BEAM-9295] Add Flink 1.10 build target and Make FlinkRunner compatible with Flink 1.10", "committedDate": "2020-02-27T03:51:22Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTU3NzQyNg==", "url": "https://github.com/apache/beam/pull/10945#discussion_r385577426", "bodyText": "This cannot be removed yet. The feature is only present in 1.8.", "author": "mxm", "createdAt": "2020-02-28T09:01:17Z", "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkExecutionEnvironments.java", "diffHunk": "@@ -311,78 +302,4 @@ private static void applyLatencyTrackingInterval(\n     long latencyTrackingInterval = options.getLatencyTrackingInterval();\n     config.setLatencyTrackingInterval(latencyTrackingInterval);\n   }\n-\n-  /**\n-   * Remote stream environment that supports job execution with restore from savepoint.\n-   *\n-   * <p>This class can be removed once Flink provides this functionality.\n-   *\n-   * <p>TODO: https://issues.apache.org/jira/browse/BEAM-5396\n-   */\n-  private static class BeamFlinkRemoteStreamEnvironment extends RemoteStreamEnvironment {", "originalCommit": "82b781c3f39ffe684ca93bde7c8520244cdfe4a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjAwMjg0MA==", "url": "https://github.com/apache/beam/pull/10945#discussion_r386002840", "bodyText": "BeamFlinkRemoteStreamEnvironment has not been removed. Actually it has been moved to runner 1.7. The reason is that in 1.10 we don't need it any more. What do you think?", "author": "sunjincheng121", "createdAt": "2020-02-29T05:20:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTU3NzQyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc2MzA4Nw==", "url": "https://github.com/apache/beam/pull/10945#discussion_r389763087", "bodyText": "I didn't see that. In this case \ud83d\udc4d", "author": "mxm", "createdAt": "2020-03-09T15:22:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTU3NzQyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTU3ODU5NA==", "url": "https://github.com/apache/beam/pull/10945#discussion_r385578594", "bodyText": "No need to copy everything because of one change package name. We can load JobStatus dynamically.", "author": "mxm", "createdAt": "2020-02-28T09:04:12Z", "path": "runners/flink/1.10/src/test/java/org/apache/beam/runners/flink/FlinkSubmissionTest.java", "diffHunk": "@@ -0,0 +1,256 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.flink;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+\n+import java.io.File;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Modifier;\n+import java.nio.file.Files;\n+import java.security.Permission;\n+import java.util.Collection;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.beam.runners.core.construction.resources.PipelineResources;\n+import org.apache.beam.sdk.Pipeline;\n+import org.apache.beam.sdk.io.GenerateSequence;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.PipelineOptionsFactory;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Charsets;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Iterables;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.client.cli.CliFrontend;\n+import org.apache.flink.configuration.ConfigConstants;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.JobManagerOptions;\n+import org.apache.flink.configuration.RestOptions;\n+import org.apache.flink.runtime.client.JobStatusMessage;\n+import org.apache.flink.runtime.minicluster.MiniClusterConfiguration;\n+import org.apache.flink.runtime.minicluster.RpcServiceSharing;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+import org.junit.rules.Timeout;\n+\n+/**\n+ * End-to-end submission test of Beam jobs on a Flink cluster.\n+ *\n+ * <p>This test is copied to 1.10 is becauses the package name of JobStatus has changed in Flink\n+ * 1.10, please refer to", "originalCommit": "82b781c3f39ffe684ca93bde7c8520244cdfe4a3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "3657ca43c6d58172083c9b980f1d42cbba1cd95a", "url": "https://github.com/apache/beam/commit/3657ca43c6d58172083c9b980f1d42cbba1cd95a", "message": "[BEAM-9295] Add Flink 1.10 build target and Make FlinkRunner compatible with Flink 1.10", "committedDate": "2020-02-29T05:18:48Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc2MTAzOA==", "url": "https://github.com/apache/beam/pull/10945#discussion_r389761038", "bodyText": "We could avoid duplication of this file and just have a check method which branches depending on whether we have 1.10 or a version below.", "author": "mxm", "createdAt": "2020-03-09T15:20:04Z", "path": "runners/flink/1.10/src/test/java/org/apache/beam/runners/flink/FlinkExecutionEnvironmentsTest.java", "diffHunk": "@@ -0,0 +1,533 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.flink;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.instanceOf;\n+import static org.hamcrest.core.Is.is;\n+import static org.junit.Assert.assertEquals;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.file.Files;\n+import java.util.Collections;\n+import org.apache.beam.sdk.options.PipelineOptionsFactory;\n+import org.apache.flink.api.java.ExecutionEnvironment;\n+import org.apache.flink.api.java.LocalEnvironment;\n+import org.apache.flink.api.java.RemoteEnvironment;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.RestOptions;\n+import org.apache.flink.runtime.jobgraph.SavepointConfigOptions;\n+import org.apache.flink.streaming.api.environment.LocalStreamEnvironment;\n+import org.apache.flink.streaming.api.environment.RemoteStreamEnvironment;\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.ExpectedException;\n+import org.junit.rules.TemporaryFolder;\n+import org.powermock.reflect.Whitebox;\n+\n+/**\n+ * Tests for {@link FlinkExecutionEnvironments}.\n+ *\n+ * <p>This test is copied to 1.10 is becauses the field host, port, etc have been removed from\n+ * RemoteEnvironment in Flink 1.10, please refer to\n+ * https://github.com/apache/flink/commit/057c036784242c674ea6091549cdbc98688827a6 for more details.\n+ */\n+public class FlinkExecutionEnvironmentsTest {\n+\n+  @Rule public TemporaryFolder temporaryFolder = new TemporaryFolder();\n+  @Rule public ExpectedException expectedException = ExpectedException.none();\n+\n+  @Test\n+  public void shouldSetParallelismBatch() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+    options.setParallelism(42);\n+\n+    ExecutionEnvironment bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(options.getParallelism(), is(42));\n+    assertThat(bev.getParallelism(), is(42));\n+  }\n+\n+  @Test\n+  public void shouldSetParallelismStreaming() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+    options.setParallelism(42);\n+\n+    StreamExecutionEnvironment sev =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(options.getParallelism(), is(42));\n+    assertThat(sev.getParallelism(), is(42));\n+  }\n+\n+  @Test\n+  public void shouldSetMaxParallelismStreaming() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+    options.setMaxParallelism(42);\n+\n+    StreamExecutionEnvironment sev =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(options.getMaxParallelism(), is(42));\n+    assertThat(sev.getMaxParallelism(), is(42));\n+  }\n+\n+  @Test\n+  public void shouldInferParallelismFromEnvironmentBatch() throws IOException {\n+    String flinkConfDir = extractFlinkConfig();\n+\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+    options.setFlinkMaster(\"host:80\");\n+\n+    ExecutionEnvironment bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList(), flinkConfDir);\n+\n+    assertThat(options.getParallelism(), is(23));\n+    assertThat(bev.getParallelism(), is(23));\n+  }\n+\n+  @Test\n+  public void shouldInferParallelismFromEnvironmentStreaming() throws IOException {\n+    String confDir = extractFlinkConfig();\n+\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+    options.setFlinkMaster(\"host:80\");\n+\n+    StreamExecutionEnvironment sev =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList(), confDir);\n+\n+    assertThat(options.getParallelism(), is(23));\n+    assertThat(sev.getParallelism(), is(23));\n+  }\n+\n+  @Test\n+  public void shouldFallbackToDefaultParallelismBatch() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+    options.setFlinkMaster(\"host:80\");\n+\n+    ExecutionEnvironment bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(options.getParallelism(), is(1));\n+    assertThat(bev.getParallelism(), is(1));\n+  }\n+\n+  @Test\n+  public void shouldFallbackToDefaultParallelismStreaming() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+    options.setFlinkMaster(\"host:80\");\n+\n+    StreamExecutionEnvironment sev =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(options.getParallelism(), is(1));\n+    assertThat(sev.getParallelism(), is(1));\n+  }\n+\n+  @Test\n+  public void useDefaultParallelismFromContextBatch() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+\n+    ExecutionEnvironment bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(bev, instanceOf(LocalEnvironment.class));\n+    assertThat(options.getParallelism(), is(LocalStreamEnvironment.getDefaultLocalParallelism()));\n+    assertThat(bev.getParallelism(), is(LocalStreamEnvironment.getDefaultLocalParallelism()));\n+  }\n+\n+  @Test\n+  public void useDefaultParallelismFromContextStreaming() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+\n+    StreamExecutionEnvironment sev =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(sev, instanceOf(LocalStreamEnvironment.class));\n+    assertThat(options.getParallelism(), is(LocalStreamEnvironment.getDefaultLocalParallelism()));\n+    assertThat(sev.getParallelism(), is(LocalStreamEnvironment.getDefaultLocalParallelism()));\n+  }\n+\n+  @Test\n+  public void shouldParsePortForRemoteEnvironmentBatch() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+    options.setFlinkMaster(\"host:1234\");\n+\n+    ExecutionEnvironment bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(bev, instanceOf(RemoteEnvironment.class));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"host\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(1234));\n+  }\n+\n+  @Test\n+  public void shouldParsePortForRemoteEnvironmentStreaming() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+    options.setFlinkMaster(\"host:1234\");\n+\n+    StreamExecutionEnvironment sev =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(sev, instanceOf(RemoteStreamEnvironment.class));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"host\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(1234));\n+  }\n+\n+  @Test\n+  public void shouldAllowPortOmissionForRemoteEnvironmentBatch() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+    options.setFlinkMaster(\"host\");\n+\n+    ExecutionEnvironment bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(bev, instanceOf(RemoteEnvironment.class));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"host\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(RestOptions.PORT.defaultValue()));\n+  }\n+\n+  @Test\n+  public void shouldAllowPortOmissionForRemoteEnvironmentStreaming() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+    options.setFlinkMaster(\"host\");\n+\n+    StreamExecutionEnvironment sev =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(sev, instanceOf(RemoteStreamEnvironment.class));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"host\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(RestOptions.PORT.defaultValue()));\n+  }\n+\n+  @Test\n+  public void shouldTreatAutoAndEmptyHostTheSameBatch() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+\n+    ExecutionEnvironment sev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    options.setFlinkMaster(\"[auto]\");\n+\n+    ExecutionEnvironment sev2 =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertEquals(sev.getClass(), sev2.getClass());\n+  }\n+\n+  @Test\n+  public void shouldTreatAutoAndEmptyHostTheSameStreaming() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+\n+    StreamExecutionEnvironment sev =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    options.setFlinkMaster(\"[auto]\");\n+\n+    StreamExecutionEnvironment sev2 =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertEquals(sev.getClass(), sev2.getClass());\n+  }\n+\n+  @Test\n+  public void shouldDetectMalformedPortBatch() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+    options.setFlinkMaster(\"host:p0rt\");\n+\n+    expectedException.expect(IllegalArgumentException.class);\n+    expectedException.expectMessage(\"Unparseable port number\");\n+\n+    FlinkExecutionEnvironments.createBatchExecutionEnvironment(options, Collections.emptyList());\n+  }\n+\n+  @Test\n+  public void shouldDetectMalformedPortStreaming() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+    options.setFlinkMaster(\"host:p0rt\");\n+\n+    expectedException.expect(IllegalArgumentException.class);\n+    expectedException.expectMessage(\"Unparseable port number\");\n+\n+    FlinkExecutionEnvironments.createStreamExecutionEnvironment(options, Collections.emptyList());\n+  }\n+\n+  @Test\n+  public void shouldSupportIPv4Batch() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+\n+    options.setFlinkMaster(\"192.168.1.1:1234\");\n+    ExecutionEnvironment bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"192.168.1.1\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(1234));\n+\n+    options.setFlinkMaster(\"192.168.1.1\");\n+    bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"192.168.1.1\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(RestOptions.PORT.defaultValue()));\n+  }\n+\n+  @Test\n+  public void shouldSupportIPv4Streaming() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+\n+    options.setFlinkMaster(\"192.168.1.1:1234\");\n+    ExecutionEnvironment bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"192.168.1.1\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(1234));\n+\n+    options.setFlinkMaster(\"192.168.1.1\");\n+    bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"192.168.1.1\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(RestOptions.PORT.defaultValue()));\n+  }\n+\n+  @Test\n+  public void shouldSupportIPv6Batch() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+\n+    options.setFlinkMaster(\"[FE80:CD00:0000:0CDE:1257:0000:211E:729C]:1234\");\n+    ExecutionEnvironment bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"fe80:cd00:0:cde:1257:0:211e:729c\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(1234));\n+\n+    options.setFlinkMaster(\"FE80:CD00:0000:0CDE:1257:0000:211E:729C\");\n+    bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"fe80:cd00:0:cde:1257:0:211e:729c\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(RestOptions.PORT.defaultValue()));\n+  }\n+\n+  @Test\n+  public void shouldSupportIPv6Streaming() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+\n+    options.setFlinkMaster(\"[FE80:CD00:0000:0CDE:1257:0000:211E:729C]:1234\");\n+    StreamExecutionEnvironment sev =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList());\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"fe80:cd00:0:cde:1257:0:211e:729c\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(1234));\n+\n+    options.setFlinkMaster(\"FE80:CD00:0000:0CDE:1257:0000:211E:729C\");\n+    sev =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList());\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"fe80:cd00:0:cde:1257:0:211e:729c\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(RestOptions.PORT.defaultValue()));\n+  }\n+\n+  @Test\n+  public void shouldRemoveHttpProtocolFromHostBatch() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+\n+    for (String flinkMaster :\n+        new String[] {\n+          \"http://host:1234\", \" http://host:1234\", \"https://host:1234\", \" https://host:1234\"\n+        }) {\n+      options.setFlinkMaster(flinkMaster);\n+      ExecutionEnvironment sev =\n+          FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+              options, Collections.emptyList());\n+      assertThat(\n+          ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n+              .getString(RestOptions.ADDRESS),\n+          is(\"host\"));\n+      assertThat(\n+          ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n+              .getInteger(RestOptions.PORT),\n+          is(1234));", "originalCommit": "7d87a6db4e71b753693058ac8010c04b8f78ab2e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc2MTcxNw==", "url": "https://github.com/apache/beam/pull/10945#discussion_r389761717", "bodyText": "We could avoid duplicating this file if we had a Flink 1.10 dependent branching here.", "author": "mxm", "createdAt": "2020-03-09T15:20:59Z", "path": "runners/flink/1.10/src/test/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironmentTest.java", "diffHunk": "@@ -0,0 +1,441 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.flink;\n+\n+import static org.apache.beam.sdk.testing.RegexMatcher.matches;\n+import static org.hamcrest.CoreMatchers.containsString;\n+import static org.hamcrest.CoreMatchers.instanceOf;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.not;\n+import static org.hamcrest.CoreMatchers.startsWith;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.hasItem;\n+import static org.hamcrest.core.Every.everyItem;\n+import static org.junit.Assert.assertThrows;\n+import static org.junit.Assert.fail;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.PrintStream;\n+import java.io.Serializable;\n+import java.net.MalformedURLException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.beam.runners.core.construction.PTransformMatchers;\n+import org.apache.beam.runners.core.construction.PTransformTranslation;\n+import org.apache.beam.runners.core.construction.resources.PipelineResources;\n+import org.apache.beam.sdk.Pipeline;\n+import org.apache.beam.sdk.io.GenerateSequence;\n+import org.apache.beam.sdk.io.TextIO;\n+import org.apache.beam.sdk.options.PipelineOptionsFactory;\n+import org.apache.beam.sdk.runners.PTransformOverride;\n+import org.apache.beam.sdk.runners.PTransformOverrideFactory;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.windowing.FixedWindows;\n+import org.apache.beam.sdk.transforms.windowing.Window;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Charsets;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.flink.api.java.ExecutionEnvironment;\n+import org.apache.flink.api.java.RemoteEnvironment;\n+import org.apache.flink.client.cli.ExecutionConfigAccessor;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.streaming.api.environment.RemoteStreamEnvironment;\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+import org.hamcrest.BaseMatcher;\n+import org.hamcrest.Description;\n+import org.hamcrest.Matchers;\n+import org.joda.time.Duration;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.JUnit4;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Mockito;\n+import org.powermock.reflect.Whitebox;\n+\n+/**\n+ * Tests for {@link FlinkPipelineExecutionEnvironment}.\n+ *\n+ * <p>This test is copied to 1.10 is becauses the field jarFiles has been removed from\n+ * RemoteEnvironment in Flink 1.10, please refer to\n+ * https://github.com/apache/flink/commit/057c036784242c674ea6091549cdbc98688827a6 for more details.\n+ */\n+@RunWith(JUnit4.class)\n+public class FlinkPipelineExecutionEnvironmentTest implements Serializable {\n+\n+  @Rule public transient TemporaryFolder tmpFolder = new TemporaryFolder();\n+\n+  @Test\n+  public void shouldRecognizeAndTranslateStreamingPipeline() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+    options.setFlinkMaster(\"[auto]\");\n+\n+    FlinkPipelineExecutionEnvironment flinkEnv = new FlinkPipelineExecutionEnvironment(options);\n+    Pipeline pipeline = Pipeline.create();\n+\n+    pipeline\n+        .apply(GenerateSequence.from(0).withRate(1, Duration.standardSeconds(1)))\n+        .apply(\n+            ParDo.of(\n+                new DoFn<Long, String>() {\n+\n+                  @ProcessElement\n+                  public void processElement(ProcessContext c) throws Exception {\n+                    c.output(Long.toString(c.element()));\n+                  }\n+                }))\n+        .apply(Window.into(FixedWindows.of(Duration.standardHours(1))))\n+        .apply(TextIO.write().withNumShards(1).withWindowedWrites().to(\"/dummy/path\"));\n+\n+    flinkEnv.translate(pipeline);\n+\n+    // no exception should be thrown\n+  }\n+\n+  @Test\n+  public void shouldPrepareFilesToStageWhenFlinkMasterIsSetExplicitly() throws IOException {\n+    FlinkPipelineOptions options = testPreparingResourcesToStage(\"localhost:8081\", true, false);\n+\n+    assertThat(options.getFilesToStage().size(), is(2));\n+    assertThat(options.getFilesToStage().get(0), matches(\".*\\\\.jar\"));\n+  }\n+\n+  @Test\n+  public void shouldFailWhenFileDoesNotExistAndFlinkMasterIsSetExplicitly() {\n+    assertThrows(\n+        \"To-be-staged file does not exist: \",\n+        IllegalStateException.class,\n+        () -> testPreparingResourcesToStage(\"localhost:8081\", true, true));\n+  }\n+\n+  @Test\n+  public void shouldNotPrepareFilesToStageWhenFlinkMasterIsSetToAuto() throws IOException {\n+    FlinkPipelineOptions options = testPreparingResourcesToStage(\"[auto]\");\n+\n+    assertThat(options.getFilesToStage().size(), is(2));\n+    assertThat(options.getFilesToStage(), everyItem(not(matches(\".*\\\\.jar\"))));\n+  }\n+\n+  @Test\n+  public void shouldNotPrepareFilesToStagewhenFlinkMasterIsSetToCollection() throws IOException {\n+    FlinkPipelineOptions options = testPreparingResourcesToStage(\"[collection]\");\n+\n+    assertThat(options.getFilesToStage().size(), is(2));\n+    assertThat(options.getFilesToStage(), everyItem(not(matches(\".*\\\\.jar\"))));\n+  }\n+\n+  @Test\n+  public void shouldNotPrepareFilesToStageWhenFlinkMasterIsSetToLocal() throws IOException {\n+    FlinkPipelineOptions options = testPreparingResourcesToStage(\"[local]\");\n+\n+    assertThat(options.getFilesToStage().size(), is(2));\n+    assertThat(options.getFilesToStage(), everyItem(not(matches(\".*\\\\.jar\"))));\n+  }\n+\n+  @Test\n+  public void shouldUseDefaultTempLocationIfNoneSet() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+    options.setFlinkMaster(\"clusterAddress\");\n+\n+    FlinkPipelineExecutionEnvironment flinkEnv = new FlinkPipelineExecutionEnvironment(options);\n+\n+    Pipeline pipeline = Pipeline.create(options);\n+    flinkEnv.translate(pipeline);\n+\n+    String defaultTmpDir = System.getProperty(\"java.io.tmpdir\");\n+\n+    assertThat(options.getFilesToStage(), hasItem(startsWith(defaultTmpDir)));\n+  }\n+\n+  @Test\n+  public void shouldUsePreparedFilesOnRemoteEnvironment() throws Exception {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+    options.setFlinkMaster(\"clusterAddress\");\n+\n+    FlinkPipelineExecutionEnvironment flinkEnv = new FlinkPipelineExecutionEnvironment(options);\n+\n+    Pipeline pipeline = Pipeline.create(options);\n+    flinkEnv.translate(pipeline);\n+\n+    ExecutionEnvironment executionEnvironment = flinkEnv.getBatchExecutionEnvironment();\n+    assertThat(executionEnvironment, instanceOf(RemoteEnvironment.class));\n+\n+    ExecutionConfigAccessor accesor =\n+        ExecutionConfigAccessor.fromConfiguration(\n+            (Configuration) Whitebox.getInternalState(executionEnvironment, \"configuration\"));\n+    List<URL> jarFiles = accesor.getJars();", "originalCommit": "7d87a6db4e71b753693058ac8010c04b8f78ab2e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "1f513ad3ba814fb4ef9f52bbf935d5cdc11f96ff", "url": "https://github.com/apache/beam/commit/1f513ad3ba814fb4ef9f52bbf935d5cdc11f96ff", "message": "[BEAM-9295] Add Flink 1.10 build target and Make FlinkRunner compatible with Flink 1.10", "committedDate": "2020-03-10T08:17:06Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDIzOTkwNw==", "url": "https://github.com/apache/beam/pull/10945#discussion_r390239907", "bodyText": "I have the feeling this won't be reliable enough. Why not instead taskmanager.memory.managed.fraction?", "author": "mxm", "createdAt": "2020-03-10T11:06:23Z", "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkExecutionEnvironments.java", "diffHunk": "@@ -77,6 +67,7 @@ static ExecutionEnvironment createBatchExecutionEnvironment(\n \n     // depending on the master, create the right environment.\n     if (\"[local]\".equals(flinkMasterHostPort)) {\n+      flinkConfiguration.setString(\"taskmanager.memory.managed.size\", \"2048m\");", "originalCommit": "1f513ad3ba814fb4ef9f52bbf935d5cdc11f96ff", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDI4NzYwNQ==", "url": "https://github.com/apache/beam/pull/10945#discussion_r390287605", "bodyText": "It will set the taskmanager.memory.managed.size as 128MB for MiniCluster if it's not set. I think set taskmanager.memory.managed.fraction\" doesn't take effect here. Thoughts? :)", "author": "sunjincheng121", "createdAt": "2020-03-10T12:47:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDIzOTkwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDMyODYwNg==", "url": "https://github.com/apache/beam/pull/10945#discussion_r390328606", "bodyText": "I'm hesitant with this default because it will always pre-allocate 2GB of memory which won't be used most of the time, except for the one large record test case you mentioned.\nWe could set I'd go for something like https://github.com/apache/flink/blob/42a56f4c75693773e21fa2dea45df640c2d7f9da/flink-runtime/src/main/java/org/apache/flink/runtime/clusterframework/TaskExecutorProcessUtils.java#L287 based on the memory available.\nActually, that is what the Flink 1.8 code used to do: https://github.com/apache/flink/blob/60d9b96456f142f8d18d5882016840a00159403e/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskManagerServices.java#L296\nSo let's just check the free memory and use a fraction for memory managed memory by default. What do you think?", "author": "mxm", "createdAt": "2020-03-10T13:53:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDIzOTkwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDc0NzUxMQ==", "url": "https://github.com/apache/beam/pull/10945#discussion_r390747511", "bodyText": "Thanks @mxm, Sounds good to me ;)", "author": "sunjincheng121", "createdAt": "2020-03-11T05:03:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDIzOTkwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTEyMjAxOA==", "url": "https://github.com/apache/beam/pull/10945#discussion_r391122018", "bodyText": "Cool, thanks for the changes.", "author": "mxm", "createdAt": "2020-03-11T17:00:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDIzOTkwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDI0MDYxNA==", "url": "https://github.com/apache/beam/pull/10945#discussion_r390240614", "bodyText": "We shouldn't be catching throwable here.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                } catch (Throwable t) {\n          \n          \n            \n                } catch (FieldNotFoundException e) {", "author": "mxm", "createdAt": "2020-03-10T11:07:58Z", "path": "runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkExecutionEnvironmentsTest.java", "diffHunk": "@@ -438,8 +424,34 @@ public void shouldSetSavepointRestoreForRemoteStreaming() {\n             options, Collections.emptyList());\n     // subject to change with https://issues.apache.org/jira/browse/FLINK-11048\n     assertThat(sev, instanceOf(RemoteStreamEnvironment.class));\n-    assertThat(\n-        Whitebox.getInternalState(sev, \"restoreSettings\"),\n-        is(SavepointRestoreSettings.forPath(path)));\n+    assertThat(getSavepointPath(sev), is(path));\n+  }\n+\n+  private void checkHostAndPort(Object env, String expectedHost, int expectedPort) {\n+    try {\n+      assertThat(Whitebox.getInternalState(env, \"host\"), is(expectedHost));\n+      assertThat(Whitebox.getInternalState(env, \"port\"), is(expectedPort));\n+    } catch (Throwable t) {", "originalCommit": "1f513ad3ba814fb4ef9f52bbf935d5cdc11f96ff", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDI0MDcyNQ==", "url": "https://github.com/apache/beam/pull/10945#discussion_r390240725", "bodyText": "We shouldn't be catching throwable here.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                } catch (Throwable t) {\n          \n          \n            \n                } catch (FieldNotFoundException e) {", "author": "mxm", "createdAt": "2020-03-10T11:08:12Z", "path": "runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkExecutionEnvironmentsTest.java", "diffHunk": "@@ -438,8 +424,34 @@ public void shouldSetSavepointRestoreForRemoteStreaming() {\n             options, Collections.emptyList());\n     // subject to change with https://issues.apache.org/jira/browse/FLINK-11048\n     assertThat(sev, instanceOf(RemoteStreamEnvironment.class));\n-    assertThat(\n-        Whitebox.getInternalState(sev, \"restoreSettings\"),\n-        is(SavepointRestoreSettings.forPath(path)));\n+    assertThat(getSavepointPath(sev), is(path));\n+  }\n+\n+  private void checkHostAndPort(Object env, String expectedHost, int expectedPort) {\n+    try {\n+      assertThat(Whitebox.getInternalState(env, \"host\"), is(expectedHost));\n+      assertThat(Whitebox.getInternalState(env, \"port\"), is(expectedPort));\n+    } catch (Throwable t) {\n+      // for flink 1.10+\n+      String host =\n+          ((Configuration) Whitebox.getInternalState(env, \"configuration\"))\n+              .getString(RestOptions.ADDRESS);\n+      int port =\n+          ((Configuration) Whitebox.getInternalState(env, \"configuration\"))\n+              .getInteger(RestOptions.PORT);\n+      assertThat(\n+          new InetSocketAddress(host, port), is(new InetSocketAddress(expectedHost, expectedPort)));\n+    }\n+  }\n+\n+  private String getSavepointPath(Object env) {\n+    try {\n+      return ((SavepointRestoreSettings) Whitebox.getInternalState(env, \"restoreSettings\"))\n+          .getRestorePath();\n+    } catch (Throwable t) {", "originalCommit": "1f513ad3ba814fb4ef9f52bbf935d5cdc11f96ff", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDI0MTE4OA==", "url": "https://github.com/apache/beam/pull/10945#discussion_r390241188", "bodyText": "We shouldn't be catching throwable here.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                } catch (Throwable t) {\n          \n          \n            \n                } catch (FieldNotFoundException e) {", "author": "mxm", "createdAt": "2020-03-10T11:09:10Z", "path": "runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironmentTest.java", "diffHunk": "@@ -418,4 +426,20 @@ private FlinkPipelineOptions setPipelineOptions(\n             })\n         .collect(Collectors.toList());\n   }\n+\n+  private List<URL> getJars(Object env) throws Exception {\n+    try {\n+      return (List<URL>) Whitebox.getInternalState(env, \"jarFiles\");\n+    } catch (Throwable t) {", "originalCommit": "1f513ad3ba814fb4ef9f52bbf935d5cdc11f96ff", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "4cc537a76643d3c58b27ffb4af32bccba7a8bc6d", "url": "https://github.com/apache/beam/commit/4cc537a76643d3c58b27ffb4af32bccba7a8bc6d", "message": "[BEAM-9295] Add Flink 1.10 build target and Make FlinkRunner compatible with Flink 1.10", "committedDate": "2020-03-10T12:45:21Z", "type": "forcePushed"}, {"oid": "f91b390c8bbab4afe14734c1266da51dcc7558c9", "url": "https://github.com/apache/beam/commit/f91b390c8bbab4afe14734c1266da51dcc7558c9", "message": "[BEAM-9295] Add Flink 1.10 build target and Make FlinkRunner compatible with Flink 1.10", "committedDate": "2020-03-11T04:58:43Z", "type": "commit"}, {"oid": "f91b390c8bbab4afe14734c1266da51dcc7558c9", "url": "https://github.com/apache/beam/commit/f91b390c8bbab4afe14734c1266da51dcc7558c9", "message": "[BEAM-9295] Add Flink 1.10 build target and Make FlinkRunner compatible with Flink 1.10", "committedDate": "2020-03-11T04:58:43Z", "type": "forcePushed"}]}