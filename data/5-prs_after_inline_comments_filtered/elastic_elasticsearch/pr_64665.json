{"pr_number": 64665, "pr_title": "[ML] add new snapshot upgrader API for upgrading older snapshots", "pr_createdAt": "2020-11-05T18:27:30Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/64665", "timeline": [{"oid": "374d83df6012ca1b973da13f3262ea438d748305", "url": "https://github.com/elastic/elasticsearch/commit/374d83df6012ca1b973da13f3262ea438d748305", "message": "[ML] add new snapshot upgrader API\n\nThis new API provides a way for users to upgrade their own anomaly job\nmodel snapshots.\n\nTo upgrade a snapshot the following is done:\n- Open a native process given the job id and the desired snapshot id\n- load the snapshot to the process\n- write the snapshot again from the native task (now updated via the\n  native process)\n\ncloses #64154", "committedDate": "2020-11-05T18:22:27Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI3MTU3NQ==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r518271575", "bodyText": "I am not 100% how to do this. Right now this test effectively just checks that the parameters are parsed and sent as the resulting error indicates that we at least tried to load the model snapshot.\nThe solution might be to get an actual snapshot, and then manually updating the doc so that the min_version is old.", "author": "benwtrent", "createdAt": "2020-11-05T18:28:42Z", "path": "client/rest-high-level/src/test/java/org/elasticsearch/client/MachineLearningIT.java", "diffHunk": "@@ -2803,6 +2813,19 @@ public void testUpdateModelSnapshot() throws Exception {\n             getModelSnapshotsResponse2.snapshots().get(0).getDescription());\n     }\n \n+    public void testUpgradeJobSnapshot() throws Exception {\n+        String jobId = \"test-upgrade-model-snapshot\";\n+        String snapshotId = \"1541587919\";\n+\n+        createModelSnapshot(jobId, snapshotId, Version.V_7_0_0);\n+        //TODO add a true state from the past somehow", "originalCommit": "374d83df6012ca1b973da13f3262ea438d748305", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTk3NDM2MQ==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r519974361", "bodyText": "The solution might be to get an actual snapshot, and then manually updating the doc so that the min_version is old.\n\nYes, in terms of testing the infrastructure that would be a good way.  Run a simple job like farequote, update the model snapshot document after the job is closed to have a min_version from the previous major, then upgrade it.  Not sure this needs to be done in the HRLC tests though - for such a complex test the native multi node tests seems like the single place to do it.  I am happy to leave this test as-is, just testing the parameter passing.\nIn terms of testing actual upgrade, it could be done in the BWC tests.  We could have a BWC test (Java, not YAML) that does nothing when the old cluster is on the same major, but when the old cluster is on a different major it opens/runs/closes a job in the old cluster, then upgrades its model snapshot in the fully upgraded cluster (and does nothing in the mixed cluster).", "author": "droberts195", "createdAt": "2020-11-09T17:05:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI3MTU3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDAzMDA0Mg==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r520030042", "bodyText": "yeah, I have a BWC test class covering this case.", "author": "benwtrent", "createdAt": "2020-11-09T18:34:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI3MTU3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI3MjQ4MA==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r518272480", "bodyText": "This is a master node action as we always want the latest cluster state information.", "author": "benwtrent", "createdAt": "2020-11-05T18:30:09Z", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/action/UpgradeJobModelSnapshotAction.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.action;\n+\n+import org.elasticsearch.action.ActionRequestValidationException;\n+import org.elasticsearch.action.ActionResponse;\n+import org.elasticsearch.action.ActionType;\n+import org.elasticsearch.action.support.master.MasterNodeRequest;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.xpack.core.ml.job.config.Job;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+\n+import java.io.IOException;\n+import java.util.Objects;\n+\n+public class UpgradeJobModelSnapshotAction extends ActionType<UpgradeJobModelSnapshotAction.Response> {\n+\n+    public static final UpgradeJobModelSnapshotAction INSTANCE = new UpgradeJobModelSnapshotAction();\n+    public static final String NAME = \"cluster:admin/xpack/ml/job/model_snapshots/upgrade\";\n+\n+    private UpgradeJobModelSnapshotAction() {\n+        super(NAME, Response::new);\n+    }\n+\n+    public static class Request extends MasterNodeRequest<Request> implements ToXContentObject {", "originalCommit": "374d83df6012ca1b973da13f3262ea438d748305", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI3MzQ4Ng==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r518273486", "bodyText": "I didn't opt for a \"writing_old_state\" or an \"opened\" state as neither really conveyed any information. If the state is null, we know that either it is not assigned to a node or it is assigned and still loading the old snapshot.\nOnce we are in the reading_new_state, then that indicates that we have reached the point of no return and any failure from that state indicates a corrupted job model snapshot.", "author": "benwtrent", "createdAt": "2020-11-05T18:31:51Z", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/job/snapshot/upgrade/SnapshotUpgradeState.java", "diffHunk": "@@ -0,0 +1,37 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.job.snapshot.upgrade;\n+\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+\n+import java.io.IOException;\n+import java.util.Locale;\n+\n+public enum SnapshotUpgradeState implements Writeable {\n+\n+    READING_NEW_STATE, STOPPED, FAILED;", "originalCommit": "374d83df6012ca1b973da13f3262ea438d748305", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTk4NTA0Mg==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r519985042", "bodyText": "reading_new_state is very much from the perspective of the Java code rather than the end user.  As an end user who doesn't even know that the code is split between Java and C++ I would have thought writing_new_state makes more sense.  Or saving_new_state would be a compromise that makes sense to both end users and Java developers.\nI would also introduce a reading_old_state or loading_old_state enum value that can be used in stats and API responses instead of null.  We went through that cycle with job states.  Initially there was no opening state, because a null task state basically meant that.  But then we found it was nicer to have a specific enum value for it and translate null to that enum value in some places.  Even if it's not used anywhere initially it will avoid BWC code to add it to the enum from the outset.", "author": "droberts195", "createdAt": "2020-11-09T17:21:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI3MzQ4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI3NDA4NA==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r518274084", "bodyText": "pipelineId is for renaming the resulting file pipeline. See below comments for further explanation", "author": "benwtrent", "createdAt": "2020-11-05T18:32:55Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/MachineLearning.java", "diffHunk": "@@ -678,8 +684,8 @@ protected Clock getClock() {\n             }\n         } else {\n             mlController = new DummyController();\n-            autodetectProcessFactory = (job, autodetectParams, executorService, onProcessCrash) ->\n-                    new BlackHoleAutodetectProcess(job.getId(), onProcessCrash);\n+            autodetectProcessFactory = (pipelineId, job, autodetectParams, executorService, onProcessCrash) ->", "originalCommit": "374d83df6012ca1b973da13f3262ea438d748305", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI3NTQ4Nw==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r518275487", "bodyText": "This just eliminates the small edge cases of requiring job node assignment to take into account node version. These processes are short lived, and restricting the cluster to not be a mixed cluster is a sane limitation. Especially since this API is meant to be used right before upgrading to the next major version.", "author": "benwtrent", "createdAt": "2020-11-05T18:35:24Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/action/TransportUpgradeJobModelSnapshotAction.java", "diffHunk": "@@ -0,0 +1,258 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.action;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ResourceAlreadyExistsException;\n+import org.elasticsearch.ResourceNotFoundException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.support.ActionFilters;\n+import org.elasticsearch.action.support.master.TransportMasterNodeAction;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.block.ClusterBlockException;\n+import org.elasticsearch.cluster.block.ClusterBlockLevel;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.inject.Inject;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.license.LicenseUtils;\n+import org.elasticsearch.license.XPackLicenseState;\n+import org.elasticsearch.persistent.PersistentTasksCustomMetadata;\n+import org.elasticsearch.persistent.PersistentTasksCustomMetadata.PersistentTask;\n+import org.elasticsearch.persistent.PersistentTasksService;\n+import org.elasticsearch.tasks.Task;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.transport.TransportService;\n+import org.elasticsearch.xpack.core.XPackField;\n+import org.elasticsearch.xpack.core.ml.MlTasks;\n+import org.elasticsearch.xpack.core.ml.action.UpgradeJobModelSnapshotAction;\n+import org.elasticsearch.xpack.core.ml.action.UpgradeJobModelSnapshotAction.Request;\n+import org.elasticsearch.xpack.core.ml.action.UpgradeJobModelSnapshotAction.Response;\n+import org.elasticsearch.xpack.core.ml.job.config.Job;\n+import org.elasticsearch.xpack.core.ml.job.messages.Messages;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.ModelSnapshot;\n+import org.elasticsearch.xpack.core.ml.job.results.Result;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.ml.MlConfigMigrationEligibilityCheck;\n+import org.elasticsearch.xpack.ml.job.persistence.JobConfigProvider;\n+import org.elasticsearch.xpack.ml.job.persistence.JobResultsProvider;\n+import org.elasticsearch.xpack.ml.job.snapshot.upgrader.SnapshotUpgradePredicate;\n+import org.elasticsearch.xpack.ml.job.snapshot.upgrader.SnapshotUpgradeTaskParams;\n+import org.elasticsearch.xpack.ml.process.MlMemoryTracker;\n+\n+\n+public class TransportUpgradeJobModelSnapshotAction extends TransportMasterNodeAction<Request, Response> {\n+\n+    // If the snapshot is from any version other than the current major, we consider it for upgrade.\n+    // This is to support upgrading to the NEXT major without worry\n+    private static final byte UPGRADE_FROM_MAJOR = Version.CURRENT.major;\n+\n+    private static final Logger logger = LogManager.getLogger(TransportUpgradeJobModelSnapshotAction.class);\n+\n+    private final XPackLicenseState licenseState;\n+    private final PersistentTasksService persistentTasksService;\n+    private final JobConfigProvider jobConfigProvider;\n+    private final JobResultsProvider jobResultsProvider;\n+    private final MlMemoryTracker memoryTracker;\n+    private final MlConfigMigrationEligibilityCheck migrationEligibilityCheck;\n+\n+    @Inject\n+    public TransportUpgradeJobModelSnapshotAction(Settings settings, TransportService transportService, ThreadPool threadPool,\n+                                                  XPackLicenseState licenseState, ClusterService clusterService,\n+                                                  PersistentTasksService persistentTasksService, ActionFilters actionFilters,\n+                                                  IndexNameExpressionResolver indexNameExpressionResolver,\n+                                                  JobConfigProvider jobConfigProvider, MlMemoryTracker memoryTracker,\n+                                                  JobResultsProvider jobResultsProvider) {\n+        super(UpgradeJobModelSnapshotAction.NAME, transportService, clusterService, threadPool, actionFilters, Request::new,\n+            indexNameExpressionResolver, Response::new, ThreadPool.Names.SAME);\n+        this.licenseState = licenseState;\n+        this.persistentTasksService = persistentTasksService;\n+        this.jobConfigProvider = jobConfigProvider;\n+        this.jobResultsProvider = jobResultsProvider;\n+        this.memoryTracker = memoryTracker;\n+        this.migrationEligibilityCheck = new MlConfigMigrationEligibilityCheck(settings, clusterService);\n+    }\n+\n+    @Override\n+    protected ClusterBlockException checkBlock(Request request, ClusterState state) {\n+        return state.blocks().globalBlockedException(ClusterBlockLevel.METADATA_WRITE);\n+    }\n+\n+    @Override\n+    protected void masterOperation(Task task, Request request, ClusterState state,\n+                                   ActionListener<Response> listener) {\n+        if (migrationEligibilityCheck.jobIsEligibleForMigration(request.getJobId(), state)) {\n+            listener.onFailure(ExceptionsHelper.configHasNotBeenMigrated(\"upgrade job snapshot\", request.getJobId()));\n+            return;\n+        }\n+\n+        if (licenseState.checkFeature(XPackLicenseState.Feature.MACHINE_LEARNING) == false) {\n+            listener.onFailure(LicenseUtils.newComplianceException(XPackField.MACHINE_LEARNING));\n+            return;\n+        }\n+\n+        if (state.nodes().getMaxNodeVersion().after(state.nodes().getMinNodeVersion())) {\n+            listener.onFailure(ExceptionsHelper.conflictStatusException(\n+                \"Cannot upgrade job [{}] snapshot [{}] as not all nodes are on version {}. All nodes must be the same version\",", "originalCommit": "374d83df6012ca1b973da13f3262ea438d748305", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI3NjAzNA==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r518276034", "bodyText": "this limitation is effectively a throttling limitation. While conceptually it is possible to upgrade numerous snapshots for the same job, we don't want users to do incidentally overload their cluster and prevent other ML jobs from being started.", "author": "benwtrent", "createdAt": "2020-11-05T18:36:19Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/action/TransportUpgradeJobModelSnapshotAction.java", "diffHunk": "@@ -0,0 +1,258 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.action;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ResourceAlreadyExistsException;\n+import org.elasticsearch.ResourceNotFoundException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.support.ActionFilters;\n+import org.elasticsearch.action.support.master.TransportMasterNodeAction;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.block.ClusterBlockException;\n+import org.elasticsearch.cluster.block.ClusterBlockLevel;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.inject.Inject;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.license.LicenseUtils;\n+import org.elasticsearch.license.XPackLicenseState;\n+import org.elasticsearch.persistent.PersistentTasksCustomMetadata;\n+import org.elasticsearch.persistent.PersistentTasksCustomMetadata.PersistentTask;\n+import org.elasticsearch.persistent.PersistentTasksService;\n+import org.elasticsearch.tasks.Task;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.transport.TransportService;\n+import org.elasticsearch.xpack.core.XPackField;\n+import org.elasticsearch.xpack.core.ml.MlTasks;\n+import org.elasticsearch.xpack.core.ml.action.UpgradeJobModelSnapshotAction;\n+import org.elasticsearch.xpack.core.ml.action.UpgradeJobModelSnapshotAction.Request;\n+import org.elasticsearch.xpack.core.ml.action.UpgradeJobModelSnapshotAction.Response;\n+import org.elasticsearch.xpack.core.ml.job.config.Job;\n+import org.elasticsearch.xpack.core.ml.job.messages.Messages;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.ModelSnapshot;\n+import org.elasticsearch.xpack.core.ml.job.results.Result;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.ml.MlConfigMigrationEligibilityCheck;\n+import org.elasticsearch.xpack.ml.job.persistence.JobConfigProvider;\n+import org.elasticsearch.xpack.ml.job.persistence.JobResultsProvider;\n+import org.elasticsearch.xpack.ml.job.snapshot.upgrader.SnapshotUpgradePredicate;\n+import org.elasticsearch.xpack.ml.job.snapshot.upgrader.SnapshotUpgradeTaskParams;\n+import org.elasticsearch.xpack.ml.process.MlMemoryTracker;\n+\n+\n+public class TransportUpgradeJobModelSnapshotAction extends TransportMasterNodeAction<Request, Response> {\n+\n+    // If the snapshot is from any version other than the current major, we consider it for upgrade.\n+    // This is to support upgrading to the NEXT major without worry\n+    private static final byte UPGRADE_FROM_MAJOR = Version.CURRENT.major;\n+\n+    private static final Logger logger = LogManager.getLogger(TransportUpgradeJobModelSnapshotAction.class);\n+\n+    private final XPackLicenseState licenseState;\n+    private final PersistentTasksService persistentTasksService;\n+    private final JobConfigProvider jobConfigProvider;\n+    private final JobResultsProvider jobResultsProvider;\n+    private final MlMemoryTracker memoryTracker;\n+    private final MlConfigMigrationEligibilityCheck migrationEligibilityCheck;\n+\n+    @Inject\n+    public TransportUpgradeJobModelSnapshotAction(Settings settings, TransportService transportService, ThreadPool threadPool,\n+                                                  XPackLicenseState licenseState, ClusterService clusterService,\n+                                                  PersistentTasksService persistentTasksService, ActionFilters actionFilters,\n+                                                  IndexNameExpressionResolver indexNameExpressionResolver,\n+                                                  JobConfigProvider jobConfigProvider, MlMemoryTracker memoryTracker,\n+                                                  JobResultsProvider jobResultsProvider) {\n+        super(UpgradeJobModelSnapshotAction.NAME, transportService, clusterService, threadPool, actionFilters, Request::new,\n+            indexNameExpressionResolver, Response::new, ThreadPool.Names.SAME);\n+        this.licenseState = licenseState;\n+        this.persistentTasksService = persistentTasksService;\n+        this.jobConfigProvider = jobConfigProvider;\n+        this.jobResultsProvider = jobResultsProvider;\n+        this.memoryTracker = memoryTracker;\n+        this.migrationEligibilityCheck = new MlConfigMigrationEligibilityCheck(settings, clusterService);\n+    }\n+\n+    @Override\n+    protected ClusterBlockException checkBlock(Request request, ClusterState state) {\n+        return state.blocks().globalBlockedException(ClusterBlockLevel.METADATA_WRITE);\n+    }\n+\n+    @Override\n+    protected void masterOperation(Task task, Request request, ClusterState state,\n+                                   ActionListener<Response> listener) {\n+        if (migrationEligibilityCheck.jobIsEligibleForMigration(request.getJobId(), state)) {\n+            listener.onFailure(ExceptionsHelper.configHasNotBeenMigrated(\"upgrade job snapshot\", request.getJobId()));\n+            return;\n+        }\n+\n+        if (licenseState.checkFeature(XPackLicenseState.Feature.MACHINE_LEARNING) == false) {\n+            listener.onFailure(LicenseUtils.newComplianceException(XPackField.MACHINE_LEARNING));\n+            return;\n+        }\n+\n+        if (state.nodes().getMaxNodeVersion().after(state.nodes().getMinNodeVersion())) {\n+            listener.onFailure(ExceptionsHelper.conflictStatusException(\n+                \"Cannot upgrade job [{}] snapshot [{}] as not all nodes are on version {}. All nodes must be the same version\",\n+                request.getJobId(),\n+                request.getSnapshotId(),\n+                state.nodes().getMaxNodeVersion().toString()));\n+            return;\n+        }\n+\n+        PersistentTasksCustomMetadata customMetadata = state.getMetadata().custom(PersistentTasksCustomMetadata.TYPE);\n+        if (customMetadata != null && (customMetadata.findTasks(\n+            MlTasks.JOB_SNAPSHOT_UPGRADE_TASK_NAME,\n+            t -> t.getParams() instanceof SnapshotUpgradeTaskParams\n+                && ((SnapshotUpgradeTaskParams)t.getParams()).getJobId().equals(request.getJobId())).isEmpty() == false)) {\n+            listener.onFailure(ExceptionsHelper.conflictStatusException(\n+                \"Cannot upgrade job [{}] snapshot [{}] as there is currently a snapshot for this job being upgraded\",\n+                request.getJobId(),\n+                request.getSnapshotId()));\n+            return;", "originalCommit": "374d83df6012ca1b973da13f3262ea438d748305", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI3NjY5MA==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r518276690", "bodyText": "I opted for a failure here instead of a silent OK as it seemed nicer to say \"hey, we didn't do anything\" than that the update was completed.\nEspecially since this API should only be used when a deprecation warning indicates that a snapshot is too old to use in the next major version.", "author": "benwtrent", "createdAt": "2020-11-05T18:37:25Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/action/TransportUpgradeJobModelSnapshotAction.java", "diffHunk": "@@ -0,0 +1,258 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.action;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ResourceAlreadyExistsException;\n+import org.elasticsearch.ResourceNotFoundException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.support.ActionFilters;\n+import org.elasticsearch.action.support.master.TransportMasterNodeAction;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.block.ClusterBlockException;\n+import org.elasticsearch.cluster.block.ClusterBlockLevel;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.inject.Inject;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.license.LicenseUtils;\n+import org.elasticsearch.license.XPackLicenseState;\n+import org.elasticsearch.persistent.PersistentTasksCustomMetadata;\n+import org.elasticsearch.persistent.PersistentTasksCustomMetadata.PersistentTask;\n+import org.elasticsearch.persistent.PersistentTasksService;\n+import org.elasticsearch.tasks.Task;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.transport.TransportService;\n+import org.elasticsearch.xpack.core.XPackField;\n+import org.elasticsearch.xpack.core.ml.MlTasks;\n+import org.elasticsearch.xpack.core.ml.action.UpgradeJobModelSnapshotAction;\n+import org.elasticsearch.xpack.core.ml.action.UpgradeJobModelSnapshotAction.Request;\n+import org.elasticsearch.xpack.core.ml.action.UpgradeJobModelSnapshotAction.Response;\n+import org.elasticsearch.xpack.core.ml.job.config.Job;\n+import org.elasticsearch.xpack.core.ml.job.messages.Messages;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.ModelSnapshot;\n+import org.elasticsearch.xpack.core.ml.job.results.Result;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.ml.MlConfigMigrationEligibilityCheck;\n+import org.elasticsearch.xpack.ml.job.persistence.JobConfigProvider;\n+import org.elasticsearch.xpack.ml.job.persistence.JobResultsProvider;\n+import org.elasticsearch.xpack.ml.job.snapshot.upgrader.SnapshotUpgradePredicate;\n+import org.elasticsearch.xpack.ml.job.snapshot.upgrader.SnapshotUpgradeTaskParams;\n+import org.elasticsearch.xpack.ml.process.MlMemoryTracker;\n+\n+\n+public class TransportUpgradeJobModelSnapshotAction extends TransportMasterNodeAction<Request, Response> {\n+\n+    // If the snapshot is from any version other than the current major, we consider it for upgrade.\n+    // This is to support upgrading to the NEXT major without worry\n+    private static final byte UPGRADE_FROM_MAJOR = Version.CURRENT.major;\n+\n+    private static final Logger logger = LogManager.getLogger(TransportUpgradeJobModelSnapshotAction.class);\n+\n+    private final XPackLicenseState licenseState;\n+    private final PersistentTasksService persistentTasksService;\n+    private final JobConfigProvider jobConfigProvider;\n+    private final JobResultsProvider jobResultsProvider;\n+    private final MlMemoryTracker memoryTracker;\n+    private final MlConfigMigrationEligibilityCheck migrationEligibilityCheck;\n+\n+    @Inject\n+    public TransportUpgradeJobModelSnapshotAction(Settings settings, TransportService transportService, ThreadPool threadPool,\n+                                                  XPackLicenseState licenseState, ClusterService clusterService,\n+                                                  PersistentTasksService persistentTasksService, ActionFilters actionFilters,\n+                                                  IndexNameExpressionResolver indexNameExpressionResolver,\n+                                                  JobConfigProvider jobConfigProvider, MlMemoryTracker memoryTracker,\n+                                                  JobResultsProvider jobResultsProvider) {\n+        super(UpgradeJobModelSnapshotAction.NAME, transportService, clusterService, threadPool, actionFilters, Request::new,\n+            indexNameExpressionResolver, Response::new, ThreadPool.Names.SAME);\n+        this.licenseState = licenseState;\n+        this.persistentTasksService = persistentTasksService;\n+        this.jobConfigProvider = jobConfigProvider;\n+        this.jobResultsProvider = jobResultsProvider;\n+        this.memoryTracker = memoryTracker;\n+        this.migrationEligibilityCheck = new MlConfigMigrationEligibilityCheck(settings, clusterService);\n+    }\n+\n+    @Override\n+    protected ClusterBlockException checkBlock(Request request, ClusterState state) {\n+        return state.blocks().globalBlockedException(ClusterBlockLevel.METADATA_WRITE);\n+    }\n+\n+    @Override\n+    protected void masterOperation(Task task, Request request, ClusterState state,\n+                                   ActionListener<Response> listener) {\n+        if (migrationEligibilityCheck.jobIsEligibleForMigration(request.getJobId(), state)) {\n+            listener.onFailure(ExceptionsHelper.configHasNotBeenMigrated(\"upgrade job snapshot\", request.getJobId()));\n+            return;\n+        }\n+\n+        if (licenseState.checkFeature(XPackLicenseState.Feature.MACHINE_LEARNING) == false) {\n+            listener.onFailure(LicenseUtils.newComplianceException(XPackField.MACHINE_LEARNING));\n+            return;\n+        }\n+\n+        if (state.nodes().getMaxNodeVersion().after(state.nodes().getMinNodeVersion())) {\n+            listener.onFailure(ExceptionsHelper.conflictStatusException(\n+                \"Cannot upgrade job [{}] snapshot [{}] as not all nodes are on version {}. All nodes must be the same version\",\n+                request.getJobId(),\n+                request.getSnapshotId(),\n+                state.nodes().getMaxNodeVersion().toString()));\n+            return;\n+        }\n+\n+        PersistentTasksCustomMetadata customMetadata = state.getMetadata().custom(PersistentTasksCustomMetadata.TYPE);\n+        if (customMetadata != null && (customMetadata.findTasks(\n+            MlTasks.JOB_SNAPSHOT_UPGRADE_TASK_NAME,\n+            t -> t.getParams() instanceof SnapshotUpgradeTaskParams\n+                && ((SnapshotUpgradeTaskParams)t.getParams()).getJobId().equals(request.getJobId())).isEmpty() == false)) {\n+            listener.onFailure(ExceptionsHelper.conflictStatusException(\n+                \"Cannot upgrade job [{}] snapshot [{}] as there is currently a snapshot for this job being upgraded\",\n+                request.getJobId(),\n+                request.getSnapshotId()));\n+            return;\n+        }\n+\n+        final SnapshotUpgradeTaskParams params = new SnapshotUpgradeTaskParams(request.getJobId(), request.getSnapshotId());\n+        // Wait for job to be started\n+        ActionListener<PersistentTask<SnapshotUpgradeTaskParams>> waitForJobToStart = ActionListener.wrap(\n+            persistentTask -> waitForJobStarted(persistentTask.getId(), params, request, listener),\n+            e -> {\n+                if (ExceptionsHelper.unwrapCause(e) instanceof ResourceAlreadyExistsException) {\n+                    e = ExceptionsHelper.conflictStatusException(\n+                        \"Cannot upgrade job [{}] snapshot [{}] because upgrade is already in progress\",\n+                        e,\n+                        request.getJobId(),\n+                        request.getSnapshotId());\n+                }\n+                listener.onFailure(e);\n+            });\n+\n+        // Start job task\n+        ActionListener<Long> memoryRequirementRefreshListener = ActionListener.wrap(\n+            mem -> {\n+                logger.info(\"[{}] [{}] sending start upgrade request\", params.getJobId(), params.getSnapshotId());\n+                persistentTasksService.sendStartRequest(\n+                    MlTasks.snapshotUpgradeTaskId(params.getJobId(), params.getSnapshotId()),\n+                    MlTasks.JOB_SNAPSHOT_UPGRADE_TASK_NAME,\n+                    params,\n+                    waitForJobToStart);\n+            },\n+            listener::onFailure\n+        );\n+\n+        // Check that model snapshot exists and should actually be upgraded\n+        // Then refresh the memory\n+        ActionListener<Result<ModelSnapshot>> getSnapshotHandler = ActionListener.wrap(\n+            response -> {\n+                if (response == null) {\n+                    listener.onFailure(\n+                        new ResourceNotFoundException(\n+                            Messages.getMessage(Messages.REST_NO_SUCH_MODEL_SNAPSHOT, request.getSnapshotId(), request.getJobId())));\n+                    return;\n+                }\n+                if (response.result.getMinVersion().major >= UPGRADE_FROM_MAJOR) {\n+                    listener.onFailure(ExceptionsHelper.conflictStatusException(\n+                        \"Cannot upgrade job [{}] snapshot [{}] as it is already compatible with current major version {}\",\n+                        request.getJobId(),\n+                        request.getSnapshotId(),\n+                        UPGRADE_FROM_MAJOR));\n+                    return;\n+                }", "originalCommit": "374d83df6012ca1b973da13f3262ea438d748305", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTk4OTY1NQ==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r519989655", "bodyText": "I would do the check on the exact version rather than just the major.  Although it shouldn't be necessary, upgrading the format from e.g. 7.0 format to 7.11 format might be a useful piece of functionality to have in the future to work around some other bug.", "author": "droberts195", "createdAt": "2020-11-09T17:28:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI3NjY5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDAyOTY0NQ==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r520029645", "bodyText": "I can do that. It just didn't seem 100% necessary given the current state of things. Also, it doesn't seem that the min_version is really ever changed to the latest version. So, it very well could be that somebody calls this api numerous times in a row and since min_version is never changed, no error is returned.\nI suppose this is \"buyer beware\" and the API won't hurt anything directly.", "author": "benwtrent", "createdAt": "2020-11-09T18:33:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI3NjY5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI3NzUwMQ==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r518277501", "bodyText": "It doesn't make sense to upgrade the currently used snapshot of the job. If a job has been closed for an extended period of time (two major versions to be exact), it is probably a good idea to open it anyways for other reasons (job config updates, etc.)", "author": "benwtrent", "createdAt": "2020-11-05T18:38:50Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/action/TransportUpgradeJobModelSnapshotAction.java", "diffHunk": "@@ -0,0 +1,258 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.action;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ResourceAlreadyExistsException;\n+import org.elasticsearch.ResourceNotFoundException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.support.ActionFilters;\n+import org.elasticsearch.action.support.master.TransportMasterNodeAction;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.block.ClusterBlockException;\n+import org.elasticsearch.cluster.block.ClusterBlockLevel;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.inject.Inject;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.license.LicenseUtils;\n+import org.elasticsearch.license.XPackLicenseState;\n+import org.elasticsearch.persistent.PersistentTasksCustomMetadata;\n+import org.elasticsearch.persistent.PersistentTasksCustomMetadata.PersistentTask;\n+import org.elasticsearch.persistent.PersistentTasksService;\n+import org.elasticsearch.tasks.Task;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.transport.TransportService;\n+import org.elasticsearch.xpack.core.XPackField;\n+import org.elasticsearch.xpack.core.ml.MlTasks;\n+import org.elasticsearch.xpack.core.ml.action.UpgradeJobModelSnapshotAction;\n+import org.elasticsearch.xpack.core.ml.action.UpgradeJobModelSnapshotAction.Request;\n+import org.elasticsearch.xpack.core.ml.action.UpgradeJobModelSnapshotAction.Response;\n+import org.elasticsearch.xpack.core.ml.job.config.Job;\n+import org.elasticsearch.xpack.core.ml.job.messages.Messages;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.ModelSnapshot;\n+import org.elasticsearch.xpack.core.ml.job.results.Result;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.ml.MlConfigMigrationEligibilityCheck;\n+import org.elasticsearch.xpack.ml.job.persistence.JobConfigProvider;\n+import org.elasticsearch.xpack.ml.job.persistence.JobResultsProvider;\n+import org.elasticsearch.xpack.ml.job.snapshot.upgrader.SnapshotUpgradePredicate;\n+import org.elasticsearch.xpack.ml.job.snapshot.upgrader.SnapshotUpgradeTaskParams;\n+import org.elasticsearch.xpack.ml.process.MlMemoryTracker;\n+\n+\n+public class TransportUpgradeJobModelSnapshotAction extends TransportMasterNodeAction<Request, Response> {\n+\n+    // If the snapshot is from any version other than the current major, we consider it for upgrade.\n+    // This is to support upgrading to the NEXT major without worry\n+    private static final byte UPGRADE_FROM_MAJOR = Version.CURRENT.major;\n+\n+    private static final Logger logger = LogManager.getLogger(TransportUpgradeJobModelSnapshotAction.class);\n+\n+    private final XPackLicenseState licenseState;\n+    private final PersistentTasksService persistentTasksService;\n+    private final JobConfigProvider jobConfigProvider;\n+    private final JobResultsProvider jobResultsProvider;\n+    private final MlMemoryTracker memoryTracker;\n+    private final MlConfigMigrationEligibilityCheck migrationEligibilityCheck;\n+\n+    @Inject\n+    public TransportUpgradeJobModelSnapshotAction(Settings settings, TransportService transportService, ThreadPool threadPool,\n+                                                  XPackLicenseState licenseState, ClusterService clusterService,\n+                                                  PersistentTasksService persistentTasksService, ActionFilters actionFilters,\n+                                                  IndexNameExpressionResolver indexNameExpressionResolver,\n+                                                  JobConfigProvider jobConfigProvider, MlMemoryTracker memoryTracker,\n+                                                  JobResultsProvider jobResultsProvider) {\n+        super(UpgradeJobModelSnapshotAction.NAME, transportService, clusterService, threadPool, actionFilters, Request::new,\n+            indexNameExpressionResolver, Response::new, ThreadPool.Names.SAME);\n+        this.licenseState = licenseState;\n+        this.persistentTasksService = persistentTasksService;\n+        this.jobConfigProvider = jobConfigProvider;\n+        this.jobResultsProvider = jobResultsProvider;\n+        this.memoryTracker = memoryTracker;\n+        this.migrationEligibilityCheck = new MlConfigMigrationEligibilityCheck(settings, clusterService);\n+    }\n+\n+    @Override\n+    protected ClusterBlockException checkBlock(Request request, ClusterState state) {\n+        return state.blocks().globalBlockedException(ClusterBlockLevel.METADATA_WRITE);\n+    }\n+\n+    @Override\n+    protected void masterOperation(Task task, Request request, ClusterState state,\n+                                   ActionListener<Response> listener) {\n+        if (migrationEligibilityCheck.jobIsEligibleForMigration(request.getJobId(), state)) {\n+            listener.onFailure(ExceptionsHelper.configHasNotBeenMigrated(\"upgrade job snapshot\", request.getJobId()));\n+            return;\n+        }\n+\n+        if (licenseState.checkFeature(XPackLicenseState.Feature.MACHINE_LEARNING) == false) {\n+            listener.onFailure(LicenseUtils.newComplianceException(XPackField.MACHINE_LEARNING));\n+            return;\n+        }\n+\n+        if (state.nodes().getMaxNodeVersion().after(state.nodes().getMinNodeVersion())) {\n+            listener.onFailure(ExceptionsHelper.conflictStatusException(\n+                \"Cannot upgrade job [{}] snapshot [{}] as not all nodes are on version {}. All nodes must be the same version\",\n+                request.getJobId(),\n+                request.getSnapshotId(),\n+                state.nodes().getMaxNodeVersion().toString()));\n+            return;\n+        }\n+\n+        PersistentTasksCustomMetadata customMetadata = state.getMetadata().custom(PersistentTasksCustomMetadata.TYPE);\n+        if (customMetadata != null && (customMetadata.findTasks(\n+            MlTasks.JOB_SNAPSHOT_UPGRADE_TASK_NAME,\n+            t -> t.getParams() instanceof SnapshotUpgradeTaskParams\n+                && ((SnapshotUpgradeTaskParams)t.getParams()).getJobId().equals(request.getJobId())).isEmpty() == false)) {\n+            listener.onFailure(ExceptionsHelper.conflictStatusException(\n+                \"Cannot upgrade job [{}] snapshot [{}] as there is currently a snapshot for this job being upgraded\",\n+                request.getJobId(),\n+                request.getSnapshotId()));\n+            return;\n+        }\n+\n+        final SnapshotUpgradeTaskParams params = new SnapshotUpgradeTaskParams(request.getJobId(), request.getSnapshotId());\n+        // Wait for job to be started\n+        ActionListener<PersistentTask<SnapshotUpgradeTaskParams>> waitForJobToStart = ActionListener.wrap(\n+            persistentTask -> waitForJobStarted(persistentTask.getId(), params, request, listener),\n+            e -> {\n+                if (ExceptionsHelper.unwrapCause(e) instanceof ResourceAlreadyExistsException) {\n+                    e = ExceptionsHelper.conflictStatusException(\n+                        \"Cannot upgrade job [{}] snapshot [{}] because upgrade is already in progress\",\n+                        e,\n+                        request.getJobId(),\n+                        request.getSnapshotId());\n+                }\n+                listener.onFailure(e);\n+            });\n+\n+        // Start job task\n+        ActionListener<Long> memoryRequirementRefreshListener = ActionListener.wrap(\n+            mem -> {\n+                logger.info(\"[{}] [{}] sending start upgrade request\", params.getJobId(), params.getSnapshotId());\n+                persistentTasksService.sendStartRequest(\n+                    MlTasks.snapshotUpgradeTaskId(params.getJobId(), params.getSnapshotId()),\n+                    MlTasks.JOB_SNAPSHOT_UPGRADE_TASK_NAME,\n+                    params,\n+                    waitForJobToStart);\n+            },\n+            listener::onFailure\n+        );\n+\n+        // Check that model snapshot exists and should actually be upgraded\n+        // Then refresh the memory\n+        ActionListener<Result<ModelSnapshot>> getSnapshotHandler = ActionListener.wrap(\n+            response -> {\n+                if (response == null) {\n+                    listener.onFailure(\n+                        new ResourceNotFoundException(\n+                            Messages.getMessage(Messages.REST_NO_SUCH_MODEL_SNAPSHOT, request.getSnapshotId(), request.getJobId())));\n+                    return;\n+                }\n+                if (response.result.getMinVersion().major >= UPGRADE_FROM_MAJOR) {\n+                    listener.onFailure(ExceptionsHelper.conflictStatusException(\n+                        \"Cannot upgrade job [{}] snapshot [{}] as it is already compatible with current major version {}\",\n+                        request.getJobId(),\n+                        request.getSnapshotId(),\n+                        UPGRADE_FROM_MAJOR));\n+                    return;\n+                }\n+                memoryTracker.refreshAnomalyDetectorJobMemoryAndAllOthers(params.getJobId(), memoryRequirementRefreshListener);\n+            },\n+            listener::onFailure\n+        );\n+\n+        ActionListener<Job> getJobHandler = ActionListener.wrap(\n+            job -> {\n+                if (request.getSnapshotId().equals(job.getModelSnapshotId())) {\n+                    listener.onFailure(ExceptionsHelper.conflictStatusException(\n+                        \"Cannot upgrade snapshot [{}] for job [{}] as it is the current primary job snapshot\",\n+                        request.getSnapshotId(),\n+                        request.getJobId()\n+                    ));", "originalCommit": "374d83df6012ca1b973da13f3262ea438d748305", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTk5MjAwNg==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r519992006", "bodyText": "This means extra complication for the Kibana upgrade assistant though.  For every model snapshot that exists that is too old it will now have to recommend one of two possible courses of action, depending on whether the snapshot is the active one or not.  Opening and closing a job normally without sending it any data doesn't rewrite the snapshot, so the user would also have to feed some data to actually change the active model snapshot of the job.  So I think this check should be altered to only ban upgrading the active snapshot if the job is open.", "author": "droberts195", "createdAt": "2020-11-09T17:31:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI3NzUwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDAyOTc1Nw==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r520029757", "bodyText": "So I think this check should be altered to only ban upgrading the active snapshot if the job is open.\n\n100%, this seems good", "author": "benwtrent", "createdAt": "2020-11-09T18:34:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI3NzUwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI3ODkyNw==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r518278927", "bodyText": "It seemed weird to me that I had to write the header ahead of time as I only wanted to load and then persist the snapshot, but I ran into weird failures when I didn't.\nI can dig further if desired.", "author": "benwtrent", "createdAt": "2020-11-05T18:41:18Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/job/process/autodetect/JobModelSnapshotUpgrader.java", "diffHunk": "@@ -0,0 +1,308 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.job.process.autodetect;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ElasticsearchStatusException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.CheckedSupplier;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.concurrent.EsRejectedExecutionException;\n+import org.elasticsearch.common.util.concurrent.ThreadContext;\n+import org.elasticsearch.core.internal.io.IOUtils;\n+import org.elasticsearch.persistent.PersistentTasksCustomMetadata.PersistentTask;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.xpack.core.ml.job.config.AnalysisConfig;\n+import org.elasticsearch.xpack.core.ml.job.config.Job;\n+import org.elasticsearch.xpack.core.ml.job.snapshot.upgrade.SnapshotUpgradeState;\n+import org.elasticsearch.xpack.core.ml.job.snapshot.upgrade.SnapshotUpgradeTaskState;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.ml.MachineLearning;\n+import org.elasticsearch.xpack.ml.job.persistence.JobResultsPersister;\n+import org.elasticsearch.xpack.ml.job.persistence.StateStreamer;\n+import org.elasticsearch.xpack.ml.job.process.autodetect.output.JobSnapshotUpgraderResultProcessor;\n+import org.elasticsearch.xpack.ml.job.process.autodetect.params.AutodetectParams;\n+import org.elasticsearch.xpack.ml.job.snapshot.upgrader.SnapshotUpgradeTask;\n+import org.elasticsearch.xpack.ml.process.NativeStorageProvider;\n+import org.elasticsearch.xpack.ml.process.writer.LengthEncodedWriter;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeoutException;\n+import java.util.function.BiConsumer;\n+import java.util.function.Consumer;\n+import java.util.function.Supplier;\n+\n+import static org.elasticsearch.xpack.ml.MachineLearning.UTILITY_THREAD_POOL_NAME;\n+\n+public final class JobModelSnapshotUpgrader {\n+\n+    private static final Logger logger = LogManager.getLogger(JobModelSnapshotUpgrader.class);\n+\n+    private final SnapshotUpgradeTask task;\n+    private final Job job;\n+    private final String jobId;\n+    private final String snapshotId;\n+    private final AutodetectParams params;\n+    private final Client client;\n+    private final Consumer<Exception> onFinish;\n+    private final Supplier<Boolean> continueRunning;\n+    private final ThreadPool threadPool;\n+    private final AutodetectProcessFactory autodetectProcessFactory;\n+    private final JobResultsPersister jobResultsPersister;\n+    private final NativeStorageProvider nativeStorageProvider;\n+\n+    JobModelSnapshotUpgrader(SnapshotUpgradeTask task,\n+                             Job job,\n+                             AutodetectParams params,\n+                             ThreadPool threadPool,\n+                             AutodetectProcessFactory autodetectProcessFactory,\n+                             JobResultsPersister jobResultsPersister,\n+                             Client client,\n+                             NativeStorageProvider nativeStorageProvider,\n+                             Consumer<Exception> onFinish,\n+                             Supplier<Boolean> continueRunning) {\n+        this.task = Objects.requireNonNull(task);\n+        this.job = Objects.requireNonNull(job);\n+        this.params = Objects.requireNonNull(params);\n+        this.threadPool = Objects.requireNonNull(threadPool);\n+        this.autodetectProcessFactory = Objects.requireNonNull(autodetectProcessFactory);\n+        this.jobResultsPersister = Objects.requireNonNull(jobResultsPersister);\n+        this.nativeStorageProvider = Objects.requireNonNull(nativeStorageProvider);\n+        this.client = Objects.requireNonNull(client);\n+        this.onFinish = Objects.requireNonNull(onFinish);\n+        this.continueRunning = Objects.requireNonNull(continueRunning);\n+        this.jobId = task.getJobId();\n+        this.snapshotId = task.getSnapshotId();\n+    }\n+\n+    void start() {\n+        // A TP with no queue, so that we fail immediately if there are no threads available\n+        ExecutorService autodetectExecutorService = threadPool.executor(MachineLearning.JOB_COMMS_THREAD_POOL_NAME);\n+\n+        AutodetectProcess process = autodetectProcessFactory.createAutodetectProcess(jobId + \"-\" + snapshotId,\n+            job,\n+            params,\n+            autodetectExecutorService,\n+            (reason) -> {\n+                setTaskToFailed(reason, ActionListener.wrap(t -> {}, f -> {}));\n+                try {\n+                    nativeStorageProvider.cleanupLocalTmpStorage(task.getDescription());\n+                } catch (IOException e) {\n+                    logger.error(\n+                        new ParameterizedMessage(\"[{}] [{}] failed to delete temporary files snapshot upgrade\", jobId, snapshotId),\n+                        e);\n+                }\n+            });\n+        JobSnapshotUpgraderResultProcessor processor = new JobSnapshotUpgraderResultProcessor(\n+            jobId,\n+            snapshotId,\n+            jobResultsPersister,\n+            process);\n+        AutodetectWorkerExecutorService autodetectWorkerExecutor;\n+        try (ThreadContext.StoredContext ignore = threadPool.getThreadContext().stashContext()) {\n+            autodetectWorkerExecutor = new AutodetectWorkerExecutorService(threadPool.getThreadContext());\n+            autodetectExecutorService.submit(autodetectWorkerExecutor::start);\n+            autodetectExecutorService.submit(processor::process);\n+        } catch (EsRejectedExecutionException e) {\n+            // If submitting the operation to read the results from the process fails we need to close\n+            // the process too, so that other submitted operations to threadpool are stopped.\n+            try {\n+                IOUtils.close(process);\n+            } catch (IOException ioe) {\n+                logger.error(\"Can't close autodetect\", ioe);\n+            }\n+            onFinish.accept(e);\n+            return;\n+        }\n+\n+        StateStreamer stateStreamer = new StateStreamer(client);\n+        Executor executor = new Executor(stateStreamer, processor, autodetectWorkerExecutor, process);\n+        if (continueRunning.get() == false) {\n+            onFinish.accept(null);\n+            return;\n+        }\n+        executor.execute();\n+    }\n+\n+    void setTaskToFailed(String reason, ActionListener<PersistentTask<?>> listener) {\n+        SnapshotUpgradeTaskState taskState = new SnapshotUpgradeTaskState(\n+            SnapshotUpgradeState.FAILED,\n+            task.getAllocationId(),\n+            reason);\n+        task.updatePersistentTaskState(taskState, ActionListener.wrap(\n+            listener::onResponse,\n+            f -> {\n+                logger.warn(\n+                    () -> new ParameterizedMessage(\"[{}] [{}] failed to set task to failed\", task.getJobId(), task.getSnapshotId()),\n+                    f);\n+                listener.onFailure(f);\n+            }\n+        ));\n+    }\n+\n+    private class Executor {\n+\n+        private final StateStreamer stateStreamer;\n+        private final JobSnapshotUpgraderResultProcessor processor;\n+        private final ExecutorService autodetectWorkerExecutor;\n+        private final AutodetectProcess process;\n+\n+        Executor(StateStreamer stateStreamer,\n+                 JobSnapshotUpgraderResultProcessor processor,\n+                 ExecutorService autodetectWorkerExecutor,\n+                 AutodetectProcess process) {\n+            this.stateStreamer = stateStreamer;\n+            this.processor = processor;\n+            this.autodetectWorkerExecutor = autodetectWorkerExecutor;\n+            this.process = process;\n+        }\n+\n+        void execute() {\n+            this.restoreState();\n+        }\n+\n+        protected final Map<String, Integer> outputFieldIndexes() {\n+            Map<String, Integer> fieldIndexes = new HashMap<>();\n+            // time field\n+            fieldIndexes.put(job.getDataDescription().getTimeField(), 0);\n+            int index = 1;\n+            for (String field : job.getAnalysisConfig().analysisFields()) {\n+                if (AnalysisConfig.ML_CATEGORY_FIELD.equals(field) == false) {\n+                    fieldIndexes.put(field, index++);\n+                }\n+            }\n+            fieldIndexes.put(LengthEncodedWriter.CONTROL_FIELD_NAME, index);\n+            return fieldIndexes;\n+        }\n+\n+        void writeHeader() throws IOException {", "originalCommit": "374d83df6012ca1b973da13f3262ea438d748305", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTk5NDkyNg==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r519994926", "bodyText": "I am not surprised you had to write a header.  You could probably get away with writing one with just the control field (field name .).  But it's not particularly important, so I'm happy to leave what's here.", "author": "droberts195", "createdAt": "2020-11-09T17:36:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI3ODkyNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI3OTY2Mw==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r518279663", "bodyText": "The regular autodetect communicator doesn't have this issue as the callbacks don't ever feed back into the same executor pool. But here, it does, and to handle it, I am pushing off to the utility thread to execute the shutdown (which needs to use the autodetect executor).", "author": "benwtrent", "createdAt": "2020-11-05T18:42:36Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/job/process/autodetect/JobModelSnapshotUpgrader.java", "diffHunk": "@@ -0,0 +1,308 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.job.process.autodetect;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ElasticsearchStatusException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.CheckedSupplier;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.concurrent.EsRejectedExecutionException;\n+import org.elasticsearch.common.util.concurrent.ThreadContext;\n+import org.elasticsearch.core.internal.io.IOUtils;\n+import org.elasticsearch.persistent.PersistentTasksCustomMetadata.PersistentTask;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.xpack.core.ml.job.config.AnalysisConfig;\n+import org.elasticsearch.xpack.core.ml.job.config.Job;\n+import org.elasticsearch.xpack.core.ml.job.snapshot.upgrade.SnapshotUpgradeState;\n+import org.elasticsearch.xpack.core.ml.job.snapshot.upgrade.SnapshotUpgradeTaskState;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.ml.MachineLearning;\n+import org.elasticsearch.xpack.ml.job.persistence.JobResultsPersister;\n+import org.elasticsearch.xpack.ml.job.persistence.StateStreamer;\n+import org.elasticsearch.xpack.ml.job.process.autodetect.output.JobSnapshotUpgraderResultProcessor;\n+import org.elasticsearch.xpack.ml.job.process.autodetect.params.AutodetectParams;\n+import org.elasticsearch.xpack.ml.job.snapshot.upgrader.SnapshotUpgradeTask;\n+import org.elasticsearch.xpack.ml.process.NativeStorageProvider;\n+import org.elasticsearch.xpack.ml.process.writer.LengthEncodedWriter;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeoutException;\n+import java.util.function.BiConsumer;\n+import java.util.function.Consumer;\n+import java.util.function.Supplier;\n+\n+import static org.elasticsearch.xpack.ml.MachineLearning.UTILITY_THREAD_POOL_NAME;\n+\n+public final class JobModelSnapshotUpgrader {\n+\n+    private static final Logger logger = LogManager.getLogger(JobModelSnapshotUpgrader.class);\n+\n+    private final SnapshotUpgradeTask task;\n+    private final Job job;\n+    private final String jobId;\n+    private final String snapshotId;\n+    private final AutodetectParams params;\n+    private final Client client;\n+    private final Consumer<Exception> onFinish;\n+    private final Supplier<Boolean> continueRunning;\n+    private final ThreadPool threadPool;\n+    private final AutodetectProcessFactory autodetectProcessFactory;\n+    private final JobResultsPersister jobResultsPersister;\n+    private final NativeStorageProvider nativeStorageProvider;\n+\n+    JobModelSnapshotUpgrader(SnapshotUpgradeTask task,\n+                             Job job,\n+                             AutodetectParams params,\n+                             ThreadPool threadPool,\n+                             AutodetectProcessFactory autodetectProcessFactory,\n+                             JobResultsPersister jobResultsPersister,\n+                             Client client,\n+                             NativeStorageProvider nativeStorageProvider,\n+                             Consumer<Exception> onFinish,\n+                             Supplier<Boolean> continueRunning) {\n+        this.task = Objects.requireNonNull(task);\n+        this.job = Objects.requireNonNull(job);\n+        this.params = Objects.requireNonNull(params);\n+        this.threadPool = Objects.requireNonNull(threadPool);\n+        this.autodetectProcessFactory = Objects.requireNonNull(autodetectProcessFactory);\n+        this.jobResultsPersister = Objects.requireNonNull(jobResultsPersister);\n+        this.nativeStorageProvider = Objects.requireNonNull(nativeStorageProvider);\n+        this.client = Objects.requireNonNull(client);\n+        this.onFinish = Objects.requireNonNull(onFinish);\n+        this.continueRunning = Objects.requireNonNull(continueRunning);\n+        this.jobId = task.getJobId();\n+        this.snapshotId = task.getSnapshotId();\n+    }\n+\n+    void start() {\n+        // A TP with no queue, so that we fail immediately if there are no threads available\n+        ExecutorService autodetectExecutorService = threadPool.executor(MachineLearning.JOB_COMMS_THREAD_POOL_NAME);\n+\n+        AutodetectProcess process = autodetectProcessFactory.createAutodetectProcess(jobId + \"-\" + snapshotId,\n+            job,\n+            params,\n+            autodetectExecutorService,\n+            (reason) -> {\n+                setTaskToFailed(reason, ActionListener.wrap(t -> {}, f -> {}));\n+                try {\n+                    nativeStorageProvider.cleanupLocalTmpStorage(task.getDescription());\n+                } catch (IOException e) {\n+                    logger.error(\n+                        new ParameterizedMessage(\"[{}] [{}] failed to delete temporary files snapshot upgrade\", jobId, snapshotId),\n+                        e);\n+                }\n+            });\n+        JobSnapshotUpgraderResultProcessor processor = new JobSnapshotUpgraderResultProcessor(\n+            jobId,\n+            snapshotId,\n+            jobResultsPersister,\n+            process);\n+        AutodetectWorkerExecutorService autodetectWorkerExecutor;\n+        try (ThreadContext.StoredContext ignore = threadPool.getThreadContext().stashContext()) {\n+            autodetectWorkerExecutor = new AutodetectWorkerExecutorService(threadPool.getThreadContext());\n+            autodetectExecutorService.submit(autodetectWorkerExecutor::start);\n+            autodetectExecutorService.submit(processor::process);\n+        } catch (EsRejectedExecutionException e) {\n+            // If submitting the operation to read the results from the process fails we need to close\n+            // the process too, so that other submitted operations to threadpool are stopped.\n+            try {\n+                IOUtils.close(process);\n+            } catch (IOException ioe) {\n+                logger.error(\"Can't close autodetect\", ioe);\n+            }\n+            onFinish.accept(e);\n+            return;\n+        }\n+\n+        StateStreamer stateStreamer = new StateStreamer(client);\n+        Executor executor = new Executor(stateStreamer, processor, autodetectWorkerExecutor, process);\n+        if (continueRunning.get() == false) {\n+            onFinish.accept(null);\n+            return;\n+        }\n+        executor.execute();\n+    }\n+\n+    void setTaskToFailed(String reason, ActionListener<PersistentTask<?>> listener) {\n+        SnapshotUpgradeTaskState taskState = new SnapshotUpgradeTaskState(\n+            SnapshotUpgradeState.FAILED,\n+            task.getAllocationId(),\n+            reason);\n+        task.updatePersistentTaskState(taskState, ActionListener.wrap(\n+            listener::onResponse,\n+            f -> {\n+                logger.warn(\n+                    () -> new ParameterizedMessage(\"[{}] [{}] failed to set task to failed\", task.getJobId(), task.getSnapshotId()),\n+                    f);\n+                listener.onFailure(f);\n+            }\n+        ));\n+    }\n+\n+    private class Executor {\n+\n+        private final StateStreamer stateStreamer;\n+        private final JobSnapshotUpgraderResultProcessor processor;\n+        private final ExecutorService autodetectWorkerExecutor;\n+        private final AutodetectProcess process;\n+\n+        Executor(StateStreamer stateStreamer,\n+                 JobSnapshotUpgraderResultProcessor processor,\n+                 ExecutorService autodetectWorkerExecutor,\n+                 AutodetectProcess process) {\n+            this.stateStreamer = stateStreamer;\n+            this.processor = processor;\n+            this.autodetectWorkerExecutor = autodetectWorkerExecutor;\n+            this.process = process;\n+        }\n+\n+        void execute() {\n+            this.restoreState();\n+        }\n+\n+        protected final Map<String, Integer> outputFieldIndexes() {\n+            Map<String, Integer> fieldIndexes = new HashMap<>();\n+            // time field\n+            fieldIndexes.put(job.getDataDescription().getTimeField(), 0);\n+            int index = 1;\n+            for (String field : job.getAnalysisConfig().analysisFields()) {\n+                if (AnalysisConfig.ML_CATEGORY_FIELD.equals(field) == false) {\n+                    fieldIndexes.put(field, index++);\n+                }\n+            }\n+            fieldIndexes.put(LengthEncodedWriter.CONTROL_FIELD_NAME, index);\n+            return fieldIndexes;\n+        }\n+\n+        void writeHeader() throws IOException {\n+            Map<String, Integer> outFieldIndexes = outputFieldIndexes();\n+            // header is all the analysis input fields + the time field + control field\n+            int numFields = outFieldIndexes.size();\n+            String[] record = new String[numFields];\n+            for (Map.Entry<String, Integer> entry : outFieldIndexes.entrySet()) {\n+                record[entry.getValue()] = entry.getKey();\n+            }\n+            // Write the header\n+            process.writeRecord(record);\n+        }\n+\n+        void restoreState() {\n+            try {\n+                process.restoreState(stateStreamer, params.modelSnapshot());\n+            } catch (Exception e) {\n+                logger.error(() -> new ParameterizedMessage(\"[{}] [{}] failed to write old state\", jobId, snapshotId), e);\n+                setTaskToFailed(\"Failed to write old state due to: \" + e.getMessage(),\n+                    ActionListener.wrap(t -> shutdown(e), f -> shutdown(e)));\n+                return;\n+            }\n+            task.updatePersistentTaskState(\n+                new SnapshotUpgradeTaskState(SnapshotUpgradeState.READING_NEW_STATE, task.getAllocationId(), \"\"),\n+                ActionListener.wrap(\n+                    readingNewState -> {\n+                        if (continueRunning.get() == false) {\n+                            shutdown(null);\n+                            return;\n+                        }\n+                        submitOperation(() -> {\n+                            writeHeader();\n+                            process.persistState(\n+                                // C++ is expecting the timestamp to be in seconds, not Milliseconds\n+                                params.modelSnapshot().getTimestamp().getTime()/1000,\n+                                params.modelSnapshot().getSnapshotId(),\n+                                params.modelSnapshot().getDescription());\n+                            return null;\n+                            // Execute callback in the UTILITY thread pool, as the current thread in the callback will be one in the\n+                            // autodetectWorkerExecutor. Trying to run the callback in that executor will cause a dead lock as that\n+                            // executor has a single processing queue.\n+                        }, (aVoid, e) -> threadPool.executor(UTILITY_THREAD_POOL_NAME).execute(() -> shutdown(e)));", "originalCommit": "374d83df6012ca1b973da13f3262ea438d748305", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI4MDgyMw==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r518280823", "bodyText": "One of the requirements was that this upgrade be possible WHILE the referenced job is running. Consequently, the snapshot upgrade task and the job task COULD be assigned to the same node. If the pipeline ID was not given directly, this would cause a file name conflict.\nAdmittedly, there is already this \"unique pipeline flag\" but that is a long value. I thought it would be nice to include the snapshot ID directly in the pipeline name. It makes the resulting logs very easy to investigate snapshot upgrader issues by looking for <job_id>-<snapshot_id>", "author": "benwtrent", "createdAt": "2020-11-05T18:44:37Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/job/process/autodetect/NativeAutodetectProcessFactory.java", "diffHunk": "@@ -71,26 +71,27 @@ void setProcessConnectTimeout(TimeValue processConnectTimeout) {\n     }\n \n     @Override\n-    public AutodetectProcess createAutodetectProcess(Job job,\n+    public AutodetectProcess createAutodetectProcess(String pipelineId,\n+                                                     Job job,", "originalCommit": "374d83df6012ca1b973da13f3262ea438d748305", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI4MTczMQ==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r518281731", "bodyText": "I created a new processor here as I didn't want to chance ANY other result being written back. This just protects us from inadvertently updating the job results/state when we didn't mean to.\nI possibly could have had an AbstractResultProcessor class, but shared code was so little, it didn't really seem worth it.", "author": "benwtrent", "createdAt": "2020-11-05T18:46:12Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/job/process/autodetect/output/JobSnapshotUpgraderResultProcessor.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.job.process.autodetect.output;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.bulk.BulkResponse;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.xpack.core.ml.MachineLearningField;\n+import org.elasticsearch.xpack.core.ml.annotations.Annotation;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.output.FlushAcknowledgement;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.CategorizerStats;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.ModelSizeStats;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.ModelSnapshot;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.Quantiles;\n+import org.elasticsearch.xpack.core.ml.job.results.AnomalyRecord;\n+import org.elasticsearch.xpack.core.ml.job.results.Bucket;\n+import org.elasticsearch.xpack.core.ml.job.results.CategoryDefinition;\n+import org.elasticsearch.xpack.core.ml.job.results.Forecast;\n+import org.elasticsearch.xpack.core.ml.job.results.ForecastRequestStats;\n+import org.elasticsearch.xpack.core.ml.job.results.Influencer;\n+import org.elasticsearch.xpack.core.ml.job.results.ModelPlot;\n+import org.elasticsearch.xpack.ml.job.persistence.JobResultsPersister;\n+import org.elasticsearch.xpack.ml.job.process.autodetect.AutodetectProcess;\n+import org.elasticsearch.xpack.ml.job.results.AutodetectResult;\n+\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+\n+/**\n+ * A runnable class that reads the autodetect process output in the\n+ * {@link #process()} method and persists parsed\n+ * results via the {@linkplain JobResultsPersister} passed in the constructor.\n+ * <p>\n+ * This is a single purpose result processor and only handles snapshot writes\n+ */\n+public class JobSnapshotUpgraderResultProcessor {", "originalCommit": "374d83df6012ca1b973da13f3262ea438d748305", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI4MjM1OQ==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r518282359", "bodyText": "In all my testing, the task is only null when it has been removed from cluster state. Since this predicate runs AFTER we have confirmed the task has been added to state (the start task API), it is good to assume that null is removal and thus is completion.", "author": "benwtrent", "createdAt": "2020-11-05T18:47:18Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/job/snapshot/upgrader/SnapshotUpgradePredicate.java", "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.job.snapshot.upgrader;\n+\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.persistent.PersistentTasksCustomMetadata;\n+import org.elasticsearch.xpack.core.ml.job.snapshot.upgrade.SnapshotUpgradeState;\n+import org.elasticsearch.xpack.core.ml.job.snapshot.upgrade.SnapshotUpgradeTaskState;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+\n+import java.util.Optional;\n+import java.util.function.Predicate;\n+\n+import static org.elasticsearch.xpack.ml.job.task.OpenJobPersistentTasksExecutor.checkAssignmentState;\n+\n+public class SnapshotUpgradePredicate implements Predicate<PersistentTasksCustomMetadata.PersistentTask<?>> {\n+    private final boolean waitForCompletion;\n+    private final Logger logger;\n+    private volatile Exception exception;\n+    private volatile String node = \"\";\n+    private volatile boolean shouldCancel;\n+    private volatile boolean isCompleted;\n+\n+    public SnapshotUpgradePredicate(boolean waitForCompletion, Logger logger) {\n+        this.waitForCompletion = waitForCompletion;\n+        this.logger = logger;\n+    }\n+\n+    public Exception getException() {\n+        return exception;\n+    }\n+\n+    public String getNode() {\n+        return node;\n+    }\n+\n+    public boolean isShouldCancel() {\n+        return shouldCancel;\n+    }\n+\n+    public boolean isCompleted() {\n+        return isCompleted;\n+    }\n+\n+    @Override\n+    public boolean test(PersistentTasksCustomMetadata.PersistentTask<?> persistentTask) {\n+        // Persistent task being null means it has been removed from state, and is now complete\n+        if (persistentTask == null) {\n+            isCompleted = true;\n+            return true;\n+        }", "originalCommit": "374d83df6012ca1b973da13f3262ea438d748305", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI4MjkxMw==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r518282913", "bodyText": "If we are assigned to a new node while reading_new_state, the snapshot could be corrupted since the files are being overwritten one by one.\nConsequently, we audit, log and then delete the snapshot as it is unusable anyways.\nIt MIGHT be better to add a flag to the snapshot that says \"bad snapshot\". But, the way to recover here would be to delete the job model state and then restore from an elasticsearch snapshot...Up for debate.", "author": "benwtrent", "createdAt": "2020-11-05T18:48:16Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/job/snapshot/upgrader/SnapshotUpgradeTaskExecutor.java", "diffHunk": "@@ -0,0 +1,282 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.job.snapshot.upgrader;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.ElasticsearchStatusException;\n+import org.elasticsearch.ResourceNotFoundException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.persistent.AllocatedPersistentTask;\n+import org.elasticsearch.persistent.PersistentTaskState;\n+import org.elasticsearch.persistent.PersistentTasksCustomMetadata;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.tasks.TaskId;\n+import org.elasticsearch.xpack.core.ml.MlConfigIndex;\n+import org.elasticsearch.xpack.core.ml.MlTasks;\n+import org.elasticsearch.xpack.core.ml.job.persistence.AnomalyDetectorsIndex;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.ModelSnapshot;\n+import org.elasticsearch.xpack.core.ml.job.results.Result;\n+import org.elasticsearch.xpack.core.ml.job.snapshot.upgrade.SnapshotUpgradeState;\n+import org.elasticsearch.xpack.core.ml.job.snapshot.upgrade.SnapshotUpgradeTaskState;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.ml.MachineLearning;\n+import org.elasticsearch.xpack.ml.job.JobNodeSelector;\n+import org.elasticsearch.xpack.ml.job.persistence.JobDataDeleter;\n+import org.elasticsearch.xpack.ml.job.persistence.JobResultsProvider;\n+import org.elasticsearch.xpack.ml.job.process.autodetect.AutodetectProcessManager;\n+import org.elasticsearch.xpack.ml.notifications.AnomalyDetectionAuditor;\n+import org.elasticsearch.xpack.ml.process.MlMemoryTracker;\n+import org.elasticsearch.xpack.ml.task.AbstractJobPersistentTasksExecutor;\n+\n+import java.util.Collections;\n+import java.util.Map;\n+import java.util.Optional;\n+\n+\n+public class SnapshotUpgradeTaskExecutor extends AbstractJobPersistentTasksExecutor<SnapshotUpgradeTaskParams> {\n+\n+    private static final Logger logger = LogManager.getLogger(SnapshotUpgradeTaskExecutor.class);\n+    private final AutodetectProcessManager autodetectProcessManager;\n+    private final AnomalyDetectionAuditor auditor;\n+    private final JobResultsProvider jobResultsProvider;\n+    private volatile ClusterState clusterState;\n+    private final Client client;\n+\n+    public SnapshotUpgradeTaskExecutor(Settings settings,\n+                                       ClusterService clusterService,\n+                                       AutodetectProcessManager autodetectProcessManager,\n+                                       MlMemoryTracker memoryTracker,\n+                                       IndexNameExpressionResolver expressionResolver,\n+                                       Client client) {\n+        super(MlTasks.JOB_SNAPSHOT_UPGRADE_TASK_NAME,\n+            MachineLearning.UTILITY_THREAD_POOL_NAME,\n+            settings,\n+            clusterService,\n+            memoryTracker,\n+            expressionResolver);\n+        this.autodetectProcessManager = autodetectProcessManager;\n+        this.auditor = new AnomalyDetectionAuditor(client, clusterService);\n+        this.jobResultsProvider = new JobResultsProvider(client, settings, expressionResolver);\n+        this.client = client;\n+        clusterService.addListener(event -> clusterState = event.state());\n+    }\n+\n+    @Override\n+    public PersistentTasksCustomMetadata.Assignment getAssignment(SnapshotUpgradeTaskParams params, ClusterState clusterState) {\n+        boolean isMemoryTrackerRecentlyRefreshed = memoryTracker.isRecentlyRefreshed();\n+        Optional<PersistentTasksCustomMetadata.Assignment> optionalAssignment = getPotentialAssignment(params, clusterState);\n+        if (optionalAssignment.isPresent()) {\n+            return optionalAssignment.get();\n+        }\n+        JobNodeSelector jobNodeSelector = new JobNodeSelector(\n+            clusterState,\n+            params.getJobId(),\n+            MlTasks.JOB_SNAPSHOT_UPGRADE_TASK_NAME,\n+            memoryTracker,\n+            0,\n+            node -> null);\n+        return jobNodeSelector.selectNode(\n+            Integer.MAX_VALUE,\n+            Integer.MAX_VALUE,\n+            maxMachineMemoryPercent,\n+            isMemoryTrackerRecentlyRefreshed,\n+            useAutoMemoryPercentage);\n+    }\n+\n+    @Override\n+    protected void nodeOperation(AllocatedPersistentTask task, SnapshotUpgradeTaskParams params, PersistentTaskState state) {\n+        SnapshotUpgradeTaskState jobTaskState = (SnapshotUpgradeTaskState) state;\n+        SnapshotUpgradeState jobState = jobTaskState == null ? null : jobTaskState.getState();\n+        logger.info(\"[{}] [{}] starting to execute task\",\n+            params.getJobId(),\n+            params.getSnapshotId());\n+\n+        // This means that we have loaded the snapshot and possibly snapshot was partially updated\n+        // This is no good, we should remove the snapshot\n+        if (SnapshotUpgradeState.READING_NEW_STATE.equals(jobState)) {\n+            deleteSnapshotAndFailTask(task, params.getJobId(), params.getSnapshotId());\n+            return;", "originalCommit": "374d83df6012ca1b973da13f3262ea438d748305", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI4NDc1OQ==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r518284759", "bodyText": "After backport I want to add a mixed cluster test (to make sure the mixed node error throws) and I want to verify that the min_version is updated on the new snapshot.\nRight now, since 8.x does not support upgrades from 6.x, that is not possible here. But in 7.x, it will be good to test that min_version gets adjusted.", "author": "benwtrent", "createdAt": "2020-11-05T18:51:14Z", "path": "x-pack/qa/rolling-upgrade/src/test/java/org/elasticsearch/upgrades/MlJobSnapshotUpgradeIT.java", "diffHunk": "@@ -0,0 +1,276 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.upgrades;\n+\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.client.MachineLearningClient;\n+import org.elasticsearch.client.Request;\n+import org.elasticsearch.client.RequestOptions;\n+import org.elasticsearch.client.RestClient;\n+import org.elasticsearch.client.RestHighLevelClient;\n+import org.elasticsearch.client.ml.CloseJobRequest;\n+import org.elasticsearch.client.ml.CloseJobResponse;\n+import org.elasticsearch.client.ml.FlushJobRequest;\n+import org.elasticsearch.client.ml.FlushJobResponse;\n+import org.elasticsearch.client.ml.GetJobRequest;\n+import org.elasticsearch.client.ml.GetJobResponse;\n+import org.elasticsearch.client.ml.GetJobStatsRequest;\n+import org.elasticsearch.client.ml.GetModelSnapshotsRequest;\n+import org.elasticsearch.client.ml.GetModelSnapshotsResponse;\n+import org.elasticsearch.client.ml.OpenJobRequest;\n+import org.elasticsearch.client.ml.OpenJobResponse;\n+import org.elasticsearch.client.ml.PostDataRequest;\n+import org.elasticsearch.client.ml.PostDataResponse;\n+import org.elasticsearch.client.ml.PutJobRequest;\n+import org.elasticsearch.client.ml.PutJobResponse;\n+import org.elasticsearch.client.ml.RevertModelSnapshotRequest;\n+import org.elasticsearch.client.ml.UpgradeJobModelSnapshotRequest;\n+import org.elasticsearch.client.ml.job.config.AnalysisConfig;\n+import org.elasticsearch.client.ml.job.config.DataDescription;\n+import org.elasticsearch.client.ml.job.config.Detector;\n+import org.elasticsearch.client.ml.job.config.Job;\n+import org.elasticsearch.client.ml.job.process.DataCounts;\n+import org.elasticsearch.client.ml.job.process.ModelSnapshot;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.bytes.BytesArray;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.XContentType;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.xpack.test.rest.XPackRestTestConstants;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.greaterThan;\n+import static org.hamcrest.Matchers.hasSize;\n+import static org.hamcrest.Matchers.is;\n+\n+public class MlJobSnapshotUpgradeIT extends AbstractUpgradeTestCase {\n+\n+    private static final String JOB_ID = \"ml-snapshots-upgrade-job\";\n+\n+    private static class HLRC extends RestHighLevelClient {\n+        HLRC(RestClient restClient) {\n+            super(restClient, RestClient::close, new ArrayList<>());\n+        }\n+    }\n+\n+    private MachineLearningClient hlrc;\n+\n+    @Override\n+    protected Collection<String> templatesToWaitFor() {\n+        return Stream.concat(XPackRestTestConstants.ML_POST_V660_TEMPLATES.stream(),\n+            super.templatesToWaitFor().stream()).collect(Collectors.toSet());\n+    }\n+\n+    protected static void waitForPendingUpgraderTasks() throws Exception {\n+        waitForPendingTasks(adminClient(), taskName -> taskName.startsWith(\"xpack/ml/job/snapshot/upgrade\") == false);\n+    }\n+\n+    /**\n+     * The purpose of this test is to ensure that when a job is open through a rolling upgrade we upgrade the results\n+     * index mappings when it is assigned to an upgraded node even if no other ML endpoint is called after the upgrade\n+     */\n+    public void testSnapshotUpgrader() throws Exception {\n+        hlrc = new HLRC(client()).machineLearning();\n+        //assumeTrue(\"Snapshot upgrader should only upgrade from the last major\", UPGRADE_FROM_VERSION.major < 7);\n+        Request adjustLoggingLevels = new Request(\"PUT\", \"/_cluster/settings\");\n+        adjustLoggingLevels.setJsonEntity(\n+            \"{\\\"transient\\\": {\" +\n+                \"\\\"logger.org.elasticsearch.xpack.ml\\\": \\\"trace\\\"\" +\n+                \"}}\");\n+        client().performRequest(adjustLoggingLevels);\n+        switch (CLUSTER_TYPE) {\n+            case OLD:\n+                createJobAndSnapshots();\n+                break;\n+            case MIXED:\n+                // Add mixed cluster test after backported\n+                break;\n+            case UPGRADED:\n+                ensureHealth((request -> {\n+                    request.addParameter(\"timeout\", \"70s\");\n+                    request.addParameter(\"wait_for_nodes\", \"3\");\n+                    request.addParameter(\"wait_for_status\", \"yellow\");\n+                }));\n+                testSnapshotUpgrade();\n+                waitForPendingUpgraderTasks();\n+                break;\n+            default:\n+                throw new UnsupportedOperationException(\"Unknown cluster type [\" + CLUSTER_TYPE + \"]\");\n+        }\n+    }\n+\n+    private void testSnapshotUpgrade() throws Exception {\n+        Job job = getJob(JOB_ID).jobs().get(0);\n+        String currentSnapshot = job.getModelSnapshotId();\n+\n+        GetModelSnapshotsResponse modelSnapshots = getModelSnapshots(job.getId());\n+        assertThat(modelSnapshots.snapshots(), hasSize(2));\n+        assertThat(modelSnapshots.snapshots().get(0).getMinVersion().major, equalTo((byte)7));\n+        assertThat(modelSnapshots.snapshots().get(1).getMinVersion().major, equalTo((byte)7));\n+\n+        ModelSnapshot snapshot = modelSnapshots.snapshots()\n+            .stream()\n+            .filter(s -> s.getSnapshotId().equals(currentSnapshot) == false)\n+            .findFirst()\n+            .orElseThrow(() -> new ElasticsearchException(\"Not found snapshot other than \" + currentSnapshot));\n+\n+        assertThat(hlrc.upgradeJobSnapshot(\n+            new UpgradeJobModelSnapshotRequest(JOB_ID, snapshot.getSnapshotId(), null, true),\n+            RequestOptions.DEFAULT).isCompleted(), is(true));\n+\n+        List<ModelSnapshot> snapshots = getModelSnapshots(job.getId(), snapshot.getSnapshotId()).snapshots();\n+        assertThat(snapshots, hasSize(1));\n+        assertThat(snapshot.getLatestRecordTimeStamp(), equalTo(snapshots.get(0).getLatestRecordTimeStamp()));\n+\n+        // Does the snapshot still work?\n+        assertThat(hlrc.getJobStats(new GetJobStatsRequest(JOB_ID), RequestOptions.DEFAULT)\n+                .jobStats()\n+                .get(0)\n+                .getDataCounts().getLatestRecordTimeStamp(),\n+            greaterThan(snapshot.getLatestRecordTimeStamp()));", "originalCommit": "374d83df6012ca1b973da13f3262ea438d748305", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTk3NTczNg==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r519975736", "bodyText": "As above, this will be complex and expensive, and I am not sure that is justified for the docs tests.  We can do it once as part of the native multi node tests, but burning that CPU many times in a full CI run seems unjustified.", "author": "droberts195", "createdAt": "2020-11-09T17:07:34Z", "path": "client/rest-high-level/src/test/java/org/elasticsearch/client/documentation/MlClientDocumentationIT.java", "diffHunk": "@@ -2332,6 +2336,83 @@ public void onFailure(Exception e) {\n         }\n     }\n \n+    public void testUpgradeJobSnapshot() throws IOException, InterruptedException {\n+        RestHighLevelClient client = highLevelClient();\n+\n+        String jobId = \"test-upgrade-job-model-snapshot\";\n+        String snapshotId = \"1541587919\";\n+        Job job = MachineLearningIT.buildJob(jobId);\n+        client.machineLearning().putJob(new PutJobRequest(job), RequestOptions.DEFAULT);\n+\n+        // Let us index a snapshot\n+        String documentId = jobId + \"_model_snapshot_\" + snapshotId;\n+        IndexRequest indexRequest = new IndexRequest(\".ml-anomalies-shared\").id(documentId);\n+        indexRequest.setRefreshPolicy(WriteRequest.RefreshPolicy.IMMEDIATE);\n+        indexRequest.source(\"{\\\"job_id\\\":\\\"test-upgrade-job-model-snapshot\\\", \\\"timestamp\\\":1541587919000, \" +\n+            \"\\\"description\\\":\\\"State persisted due to job close at 2018-11-07T10:51:59+0000\\\", \" +\n+            \"\\\"snapshot_id\\\":\\\"1541587919\\\", \\\"snapshot_doc_count\\\":1, \\\"model_size_stats\\\":{\" +\n+            \"\\\"job_id\\\":\\\"test-revert-model-snapshot\\\", \\\"result_type\\\":\\\"model_size_stats\\\",\\\"model_bytes\\\":51722, \" +\n+            \"\\\"total_by_field_count\\\":3, \\\"total_over_field_count\\\":0, \\\"total_partition_field_count\\\":2,\" +\n+            \"\\\"bucket_allocation_failures_count\\\":0, \\\"memory_status\\\":\\\"ok\\\", \\\"log_time\\\":1541587919000, \" +\n+            \"\\\"timestamp\\\":1519930800000}, \\\"latest_record_time_stamp\\\":1519931700000,\" +\n+            \"\\\"latest_result_time_stamp\\\":1519930800000, \\\"retain\\\":false, \" +\n+            \"\\\"quantiles\\\":{\\\"job_id\\\":\\\"test-revert-model-snapshot\\\", \\\"timestamp\\\":1541587919000, \" +\n+            \"\\\"quantile_state\\\":\\\"state\\\"}}\", XContentType.JSON);\n+        client.index(indexRequest, RequestOptions.DEFAULT);\n+\n+        {\n+            // tag::upgrade-job-model-snapshot-request\n+            UpgradeJobModelSnapshotRequest request = new UpgradeJobModelSnapshotRequest(\n+                jobId, // <1>\n+                snapshotId, // <2>\n+                TimeValue.timeValueMinutes(30), // <3>\n+                false); // <4>\n+            // end::upgrade-job-model-snapshot-request\n+\n+            try {\n+                // tag::upgrade-job-model-snapshot-execute\n+                UpgradeJobModelSnapshotResponse response = client.machineLearning().upgradeJobSnapshot(request, RequestOptions.DEFAULT);\n+                // end::upgrade-job-model-snapshot-execute\n+            } catch (ElasticsearchException ex) {\n+                // TODO have a true snapshot in the past to upgrade?", "originalCommit": "374d83df6012ca1b973da13f3262ea438d748305", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDAzMDE0NQ==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r520030145", "bodyText": "yeah, I have a BWC test class covering this case.", "author": "benwtrent", "createdAt": "2020-11-09T18:34:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTk3NTczNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjAzNTAxMA==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r522035010", "bodyText": "In that case I think you should remove the TODO from here and instead have a comment to say that this is just checking syntax because actual upgrade is covered elsewhere.", "author": "droberts195", "createdAt": "2020-11-12T11:26:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTk3NTczNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTk4NTY3Mg==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r519985672", "bodyText": "Did you consider UncheckedIOException?", "author": "droberts195", "createdAt": "2020-11-09T17:22:15Z", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/job/snapshot/upgrade/SnapshotUpgradeTaskState.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.core.ml.job.snapshot.upgrade;\n+\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.persistent.PersistentTaskState;\n+import org.elasticsearch.persistent.PersistentTasksCustomMetadata;\n+import org.elasticsearch.xpack.core.ml.MlTasks;\n+\n+import java.io.IOException;\n+import java.util.Objects;\n+\n+public class SnapshotUpgradeTaskState implements PersistentTaskState {\n+\n+    public static final String NAME = MlTasks.JOB_SNAPSHOT_UPGRADE_TASK_NAME;\n+\n+    private static ParseField STATE = new ParseField(\"state\");\n+    private static ParseField ALLOCATION_ID = new ParseField(\"allocation_id\");\n+    private static ParseField REASON = new ParseField(\"reason\");\n+\n+    private final SnapshotUpgradeState state;\n+    private final long allocationId;\n+    private final String reason;\n+\n+    private static final ConstructingObjectParser<SnapshotUpgradeTaskState, Void> PARSER =\n+        new ConstructingObjectParser<>(NAME, true,\n+            a -> new SnapshotUpgradeTaskState((SnapshotUpgradeState) a[0], (long) a[1], (String) a[2]));\n+\n+    static {\n+        PARSER.declareString(ConstructingObjectParser.constructorArg(), SnapshotUpgradeState::fromString, STATE);\n+        PARSER.declareLong(ConstructingObjectParser.constructorArg(), ALLOCATION_ID);\n+        PARSER.declareString(ConstructingObjectParser.optionalConstructorArg(), REASON);\n+    }\n+\n+    public static SnapshotUpgradeTaskState fromXContent(XContentParser parser) {\n+        try {\n+            return PARSER.parse(parser, null);\n+        } catch (IOException e) {\n+            throw new RuntimeException(e);", "originalCommit": "374d83df6012ca1b973da13f3262ea438d748305", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "e6c6a1f37c42ce17d484979510e52b8a5a9ff1d1", "url": "https://github.com/elastic/elasticsearch/commit/e6c6a1f37c42ce17d484979510e52b8a5a9ff1d1", "message": "addressing PR comments", "committedDate": "2020-11-09T19:11:05Z", "type": "commit"}, {"oid": "e22a764d7b6d5c51e5359f89a9e7e8112fd2d80b", "url": "https://github.com/elastic/elasticsearch/commit/e22a764d7b6d5c51e5359f89a9e7e8112fd2d80b", "message": "adding comment about timeouts relation to wait_for_completion", "committedDate": "2020-11-09T19:13:25Z", "type": "commit"}, {"oid": "aec881454ccd0655e981fcf2bdcda39b06f08de9", "url": "https://github.com/elastic/elasticsearch/commit/aec881454ccd0655e981fcf2bdcda39b06f08de9", "message": "Merge remote-tracking branch 'upstream/master' into feature/ml-add-snapshot-upgrader-api", "committedDate": "2020-11-10T14:09:11Z", "type": "commit"}, {"oid": "29348b371873df2a2115b9492977c38dc10b243c", "url": "https://github.com/elastic/elasticsearch/commit/29348b371873df2a2115b9492977c38dc10b243c", "message": "fixing some tests and addressing pr comment", "committedDate": "2020-11-10T14:34:50Z", "type": "commit"}, {"oid": "7ba38b6560b885fcb19e09f2c6f59cbe955f9231", "url": "https://github.com/elastic/elasticsearch/commit/7ba38b6560b885fcb19e09f2c6f59cbe955f9231", "message": "fixing style", "committedDate": "2020-11-10T14:42:11Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjAzODc2Mg==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r522038762", "bodyText": "Please add a Javadoc comment to say whether snapshotTimestamp is in epoch millis or epoch seconds.  Also, it might be worth adding Seconds or Millis to the variable name to make ultra clear which it is for future maintainers.", "author": "droberts195", "createdAt": "2020-11-12T11:33:14Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/job/process/autodetect/writer/AutodetectControlMsgWriter.java", "diffHunk": "@@ -244,4 +244,15 @@ public void writeStartBackgroundPersistMessage() throws IOException {\n         fillCommandBuffer();\n         lengthEncodedWriter.flush();\n     }\n+\n+    public void writeStartBackgroundPersistMessage(long snapshotTimestamp, String snapshotId, String description) throws IOException {", "originalCommit": "7ba38b6560b885fcb19e09f2c6f59cbe955f9231", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjAzOTQ2NQ==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r522039465", "bodyText": "Please add whether this is epoch seconds or epoch millis.", "author": "droberts195", "createdAt": "2020-11-12T11:34:35Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/process/NativeProcess.java", "diffHunk": "@@ -36,6 +36,15 @@\n      */\n     void persistState() throws IOException;\n \n+    /**\n+     * Ask the process to persist state, even if it is unchanged.\n+     * @param snapshotTimestamp The snapshot timestamp", "originalCommit": "7ba38b6560b885fcb19e09f2c6f59cbe955f9231", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjA0MDUwMQ==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r522040501", "bodyText": "Since Java rarely uses epoch seconds, it's probably better to move the /1000 closer to the point of passing the information to the C++ process, e.g. in AutodetectControlMsgWriter.", "author": "droberts195", "createdAt": "2020-11-12T11:36:29Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/job/process/autodetect/JobModelSnapshotUpgrader.java", "diffHunk": "@@ -0,0 +1,308 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.job.process.autodetect;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ElasticsearchStatusException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.CheckedSupplier;\n+import org.elasticsearch.common.util.concurrent.AbstractRunnable;\n+import org.elasticsearch.common.util.concurrent.EsRejectedExecutionException;\n+import org.elasticsearch.common.util.concurrent.ThreadContext;\n+import org.elasticsearch.core.internal.io.IOUtils;\n+import org.elasticsearch.persistent.PersistentTasksCustomMetadata.PersistentTask;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.xpack.core.ml.job.config.AnalysisConfig;\n+import org.elasticsearch.xpack.core.ml.job.config.Job;\n+import org.elasticsearch.xpack.core.ml.job.snapshot.upgrade.SnapshotUpgradeState;\n+import org.elasticsearch.xpack.core.ml.job.snapshot.upgrade.SnapshotUpgradeTaskState;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.ml.MachineLearning;\n+import org.elasticsearch.xpack.ml.job.persistence.JobResultsPersister;\n+import org.elasticsearch.xpack.ml.job.persistence.StateStreamer;\n+import org.elasticsearch.xpack.ml.job.process.autodetect.output.JobSnapshotUpgraderResultProcessor;\n+import org.elasticsearch.xpack.ml.job.process.autodetect.params.AutodetectParams;\n+import org.elasticsearch.xpack.ml.job.snapshot.upgrader.SnapshotUpgradeTask;\n+import org.elasticsearch.xpack.ml.process.NativeStorageProvider;\n+import org.elasticsearch.xpack.ml.process.writer.LengthEncodedWriter;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeoutException;\n+import java.util.function.BiConsumer;\n+import java.util.function.Consumer;\n+import java.util.function.Supplier;\n+\n+import static org.elasticsearch.xpack.ml.MachineLearning.UTILITY_THREAD_POOL_NAME;\n+\n+public final class JobModelSnapshotUpgrader {\n+\n+    private static final Logger logger = LogManager.getLogger(JobModelSnapshotUpgrader.class);\n+\n+    private final SnapshotUpgradeTask task;\n+    private final Job job;\n+    private final String jobId;\n+    private final String snapshotId;\n+    private final AutodetectParams params;\n+    private final Client client;\n+    private final Consumer<Exception> onFinish;\n+    private final Supplier<Boolean> continueRunning;\n+    private final ThreadPool threadPool;\n+    private final AutodetectProcessFactory autodetectProcessFactory;\n+    private final JobResultsPersister jobResultsPersister;\n+    private final NativeStorageProvider nativeStorageProvider;\n+\n+    JobModelSnapshotUpgrader(SnapshotUpgradeTask task,\n+                             Job job,\n+                             AutodetectParams params,\n+                             ThreadPool threadPool,\n+                             AutodetectProcessFactory autodetectProcessFactory,\n+                             JobResultsPersister jobResultsPersister,\n+                             Client client,\n+                             NativeStorageProvider nativeStorageProvider,\n+                             Consumer<Exception> onFinish,\n+                             Supplier<Boolean> continueRunning) {\n+        this.task = Objects.requireNonNull(task);\n+        this.job = Objects.requireNonNull(job);\n+        this.params = Objects.requireNonNull(params);\n+        this.threadPool = Objects.requireNonNull(threadPool);\n+        this.autodetectProcessFactory = Objects.requireNonNull(autodetectProcessFactory);\n+        this.jobResultsPersister = Objects.requireNonNull(jobResultsPersister);\n+        this.nativeStorageProvider = Objects.requireNonNull(nativeStorageProvider);\n+        this.client = Objects.requireNonNull(client);\n+        this.onFinish = Objects.requireNonNull(onFinish);\n+        this.continueRunning = Objects.requireNonNull(continueRunning);\n+        this.jobId = task.getJobId();\n+        this.snapshotId = task.getSnapshotId();\n+    }\n+\n+    void start() {\n+        // A TP with no queue, so that we fail immediately if there are no threads available\n+        ExecutorService autodetectExecutorService = threadPool.executor(MachineLearning.JOB_COMMS_THREAD_POOL_NAME);\n+\n+        AutodetectProcess process = autodetectProcessFactory.createAutodetectProcess(jobId + \"-\" + snapshotId,\n+            job,\n+            params,\n+            autodetectExecutorService,\n+            (reason) -> {\n+                setTaskToFailed(reason, ActionListener.wrap(t -> {}, f -> {}));\n+                try {\n+                    nativeStorageProvider.cleanupLocalTmpStorage(task.getDescription());\n+                } catch (IOException e) {\n+                    logger.error(\n+                        new ParameterizedMessage(\"[{}] [{}] failed to delete temporary files snapshot upgrade\", jobId, snapshotId),\n+                        e);\n+                }\n+            });\n+        JobSnapshotUpgraderResultProcessor processor = new JobSnapshotUpgraderResultProcessor(\n+            jobId,\n+            snapshotId,\n+            jobResultsPersister,\n+            process);\n+        AutodetectWorkerExecutorService autodetectWorkerExecutor;\n+        try (ThreadContext.StoredContext ignore = threadPool.getThreadContext().stashContext()) {\n+            autodetectWorkerExecutor = new AutodetectWorkerExecutorService(threadPool.getThreadContext());\n+            autodetectExecutorService.submit(autodetectWorkerExecutor::start);\n+            autodetectExecutorService.submit(processor::process);\n+        } catch (EsRejectedExecutionException e) {\n+            // If submitting the operation to read the results from the process fails we need to close\n+            // the process too, so that other submitted operations to threadpool are stopped.\n+            try {\n+                IOUtils.close(process);\n+            } catch (IOException ioe) {\n+                logger.error(\"Can't close autodetect\", ioe);\n+            }\n+            onFinish.accept(e);\n+            return;\n+        }\n+\n+        StateStreamer stateStreamer = new StateStreamer(client);\n+        Executor executor = new Executor(stateStreamer, processor, autodetectWorkerExecutor, process);\n+        if (continueRunning.get() == false) {\n+            onFinish.accept(null);\n+            return;\n+        }\n+        executor.execute();\n+    }\n+\n+    void setTaskToFailed(String reason, ActionListener<PersistentTask<?>> listener) {\n+        SnapshotUpgradeTaskState taskState = new SnapshotUpgradeTaskState(\n+            SnapshotUpgradeState.FAILED,\n+            task.getAllocationId(),\n+            reason);\n+        task.updatePersistentTaskState(taskState, ActionListener.wrap(\n+            listener::onResponse,\n+            f -> {\n+                logger.warn(\n+                    () -> new ParameterizedMessage(\"[{}] [{}] failed to set task to failed\", task.getJobId(), task.getSnapshotId()),\n+                    f);\n+                listener.onFailure(f);\n+            }\n+        ));\n+    }\n+\n+    private class Executor {\n+\n+        private final StateStreamer stateStreamer;\n+        private final JobSnapshotUpgraderResultProcessor processor;\n+        private final ExecutorService autodetectWorkerExecutor;\n+        private final AutodetectProcess process;\n+\n+        Executor(StateStreamer stateStreamer,\n+                 JobSnapshotUpgraderResultProcessor processor,\n+                 ExecutorService autodetectWorkerExecutor,\n+                 AutodetectProcess process) {\n+            this.stateStreamer = stateStreamer;\n+            this.processor = processor;\n+            this.autodetectWorkerExecutor = autodetectWorkerExecutor;\n+            this.process = process;\n+        }\n+\n+        void execute() {\n+            this.restoreState();\n+        }\n+\n+        protected final Map<String, Integer> outputFieldIndexes() {\n+            Map<String, Integer> fieldIndexes = new HashMap<>();\n+            // time field\n+            fieldIndexes.put(job.getDataDescription().getTimeField(), 0);\n+            int index = 1;\n+            for (String field : job.getAnalysisConfig().analysisFields()) {\n+                if (AnalysisConfig.ML_CATEGORY_FIELD.equals(field) == false) {\n+                    fieldIndexes.put(field, index++);\n+                }\n+            }\n+            fieldIndexes.put(LengthEncodedWriter.CONTROL_FIELD_NAME, index);\n+            return fieldIndexes;\n+        }\n+\n+        void writeHeader() throws IOException {\n+            Map<String, Integer> outFieldIndexes = outputFieldIndexes();\n+            // header is all the analysis input fields + the time field + control field\n+            int numFields = outFieldIndexes.size();\n+            String[] record = new String[numFields];\n+            for (Map.Entry<String, Integer> entry : outFieldIndexes.entrySet()) {\n+                record[entry.getValue()] = entry.getKey();\n+            }\n+            // Write the header\n+            process.writeRecord(record);\n+        }\n+\n+        void restoreState() {\n+            try {\n+                process.restoreState(stateStreamer, params.modelSnapshot());\n+            } catch (Exception e) {\n+                logger.error(() -> new ParameterizedMessage(\"[{}] [{}] failed to write old state\", jobId, snapshotId), e);\n+                setTaskToFailed(\"Failed to write old state due to: \" + e.getMessage(),\n+                    ActionListener.wrap(t -> shutdown(e), f -> shutdown(e)));\n+                return;\n+            }\n+            task.updatePersistentTaskState(\n+                new SnapshotUpgradeTaskState(SnapshotUpgradeState.SAVING_NEW_STATE, task.getAllocationId(), \"\"),\n+                ActionListener.wrap(\n+                    readingNewState -> {\n+                        if (continueRunning.get() == false) {\n+                            shutdown(null);\n+                            return;\n+                        }\n+                        submitOperation(() -> {\n+                            writeHeader();\n+                            process.persistState(\n+                                // C++ is expecting the timestamp to be in seconds, not Milliseconds\n+                                params.modelSnapshot().getTimestamp().getTime()/1000,", "originalCommit": "7ba38b6560b885fcb19e09f2c6f59cbe955f9231", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjA0MzA3Nw==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r522043077", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            LOGGER.warn(new ParameterizedMessage(\"[{}] Error persisting autodetect results\", jobId), e);\n          \n          \n            \n                            LOGGER.warn(new ParameterizedMessage(\"[{}] Error persisting model snapshot [{}] upgrade results\", jobId, snapshotId), e);", "author": "droberts195", "createdAt": "2020-11-12T11:41:09Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/job/process/autodetect/output/JobSnapshotUpgraderResultProcessor.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.job.process.autodetect.output;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.bulk.BulkResponse;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.xpack.core.ml.MachineLearningField;\n+import org.elasticsearch.xpack.core.ml.annotations.Annotation;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.output.FlushAcknowledgement;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.CategorizerStats;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.ModelSizeStats;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.ModelSnapshot;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.Quantiles;\n+import org.elasticsearch.xpack.core.ml.job.results.AnomalyRecord;\n+import org.elasticsearch.xpack.core.ml.job.results.Bucket;\n+import org.elasticsearch.xpack.core.ml.job.results.CategoryDefinition;\n+import org.elasticsearch.xpack.core.ml.job.results.Forecast;\n+import org.elasticsearch.xpack.core.ml.job.results.ForecastRequestStats;\n+import org.elasticsearch.xpack.core.ml.job.results.Influencer;\n+import org.elasticsearch.xpack.core.ml.job.results.ModelPlot;\n+import org.elasticsearch.xpack.ml.job.persistence.JobResultsPersister;\n+import org.elasticsearch.xpack.ml.job.process.autodetect.AutodetectProcess;\n+import org.elasticsearch.xpack.ml.job.results.AutodetectResult;\n+\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+\n+/**\n+ * A runnable class that reads the autodetect process output in the\n+ * {@link #process()} method and persists parsed\n+ * results via the {@linkplain JobResultsPersister} passed in the constructor.\n+ * <p>\n+ * This is a single purpose result processor and only handles snapshot writes\n+ */\n+public class JobSnapshotUpgraderResultProcessor {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(JobSnapshotUpgraderResultProcessor.class);\n+    final CountDownLatch completionLatch = new CountDownLatch(1);\n+    private final String jobId;\n+    private final String snapshotId;\n+    private final JobResultsPersister persister;\n+    private final AutodetectProcess process;\n+    private final JobResultsPersister.Builder bulkResultsPersister;\n+    private volatile boolean processKilled;\n+    private volatile boolean failed;\n+\n+    public JobSnapshotUpgraderResultProcessor(String jobId,\n+                                              String snapshotId,\n+                                              JobResultsPersister persister,\n+                                              AutodetectProcess autodetectProcess) {\n+        this.jobId = Objects.requireNonNull(jobId);\n+        this.snapshotId = Objects.requireNonNull(snapshotId);\n+        this.persister = Objects.requireNonNull(persister);\n+        this.process = Objects.requireNonNull(autodetectProcess);\n+        this.bulkResultsPersister = persister.bulkPersisterBuilder(jobId).shouldRetry(this::isAlive);\n+    }\n+\n+    public void process() {\n+\n+        // If a function call in this throws for some reason we don't want it\n+        // to kill the results reader thread as autodetect will be blocked\n+        // trying to write its output.\n+        try {\n+            readResults();\n+            try {\n+                if (processKilled == false) {\n+                    bulkResultsPersister.executeRequest();\n+                }\n+            } catch (Exception e) {\n+                LOGGER.warn(new ParameterizedMessage(\"[{}] Error persisting autodetect results\", jobId), e);", "originalCommit": "7ba38b6560b885fcb19e09f2c6f59cbe955f9231", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjA0MzY4NQ==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r522043685", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            LOGGER.warn(\"[{}] some results not processed due to the process being killed\", jobId);\n          \n          \n            \n                            LOGGER.warn(\"[{}] some model snapshot [{}] upgrade results not processed due to the process being killed\", jobId, snapshotId);", "author": "droberts195", "createdAt": "2020-11-12T11:42:10Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/job/process/autodetect/output/JobSnapshotUpgraderResultProcessor.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.job.process.autodetect.output;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.bulk.BulkResponse;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.xpack.core.ml.MachineLearningField;\n+import org.elasticsearch.xpack.core.ml.annotations.Annotation;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.output.FlushAcknowledgement;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.CategorizerStats;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.ModelSizeStats;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.ModelSnapshot;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.Quantiles;\n+import org.elasticsearch.xpack.core.ml.job.results.AnomalyRecord;\n+import org.elasticsearch.xpack.core.ml.job.results.Bucket;\n+import org.elasticsearch.xpack.core.ml.job.results.CategoryDefinition;\n+import org.elasticsearch.xpack.core.ml.job.results.Forecast;\n+import org.elasticsearch.xpack.core.ml.job.results.ForecastRequestStats;\n+import org.elasticsearch.xpack.core.ml.job.results.Influencer;\n+import org.elasticsearch.xpack.core.ml.job.results.ModelPlot;\n+import org.elasticsearch.xpack.ml.job.persistence.JobResultsPersister;\n+import org.elasticsearch.xpack.ml.job.process.autodetect.AutodetectProcess;\n+import org.elasticsearch.xpack.ml.job.results.AutodetectResult;\n+\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+\n+/**\n+ * A runnable class that reads the autodetect process output in the\n+ * {@link #process()} method and persists parsed\n+ * results via the {@linkplain JobResultsPersister} passed in the constructor.\n+ * <p>\n+ * This is a single purpose result processor and only handles snapshot writes\n+ */\n+public class JobSnapshotUpgraderResultProcessor {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(JobSnapshotUpgraderResultProcessor.class);\n+    final CountDownLatch completionLatch = new CountDownLatch(1);\n+    private final String jobId;\n+    private final String snapshotId;\n+    private final JobResultsPersister persister;\n+    private final AutodetectProcess process;\n+    private final JobResultsPersister.Builder bulkResultsPersister;\n+    private volatile boolean processKilled;\n+    private volatile boolean failed;\n+\n+    public JobSnapshotUpgraderResultProcessor(String jobId,\n+                                              String snapshotId,\n+                                              JobResultsPersister persister,\n+                                              AutodetectProcess autodetectProcess) {\n+        this.jobId = Objects.requireNonNull(jobId);\n+        this.snapshotId = Objects.requireNonNull(snapshotId);\n+        this.persister = Objects.requireNonNull(persister);\n+        this.process = Objects.requireNonNull(autodetectProcess);\n+        this.bulkResultsPersister = persister.bulkPersisterBuilder(jobId).shouldRetry(this::isAlive);\n+    }\n+\n+    public void process() {\n+\n+        // If a function call in this throws for some reason we don't want it\n+        // to kill the results reader thread as autodetect will be blocked\n+        // trying to write its output.\n+        try {\n+            readResults();\n+            try {\n+                if (processKilled == false) {\n+                    bulkResultsPersister.executeRequest();\n+                }\n+            } catch (Exception e) {\n+                LOGGER.warn(new ParameterizedMessage(\"[{}] Error persisting autodetect results\", jobId), e);\n+            }\n+        } catch (Exception e) {\n+            failed = true;\n+\n+            if (processKilled) {\n+                // Don't log the stack trace in this case.  Log just enough to hint\n+                // that it would have been better to close jobs before shutting down,\n+                // but we now fully expect jobs to move between nodes without doing\n+                // all their graceful close activities.\n+                LOGGER.warn(\"[{}] some results not processed due to the process being killed\", jobId);", "originalCommit": "7ba38b6560b885fcb19e09f2c6f59cbe955f9231", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjA0Mzk1MA==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r522043950", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            LOGGER.warn(\"[{}] some results not processed due to the termination of autodetect\", jobId);\n          \n          \n            \n                            LOGGER.warn(\"[{}] some model snapshot [{}] upgrade results not processed due to the termination of autodetect\", jobId, snapshotId);", "author": "droberts195", "createdAt": "2020-11-12T11:42:38Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/job/process/autodetect/output/JobSnapshotUpgraderResultProcessor.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.job.process.autodetect.output;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.bulk.BulkResponse;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.xpack.core.ml.MachineLearningField;\n+import org.elasticsearch.xpack.core.ml.annotations.Annotation;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.output.FlushAcknowledgement;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.CategorizerStats;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.ModelSizeStats;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.ModelSnapshot;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.Quantiles;\n+import org.elasticsearch.xpack.core.ml.job.results.AnomalyRecord;\n+import org.elasticsearch.xpack.core.ml.job.results.Bucket;\n+import org.elasticsearch.xpack.core.ml.job.results.CategoryDefinition;\n+import org.elasticsearch.xpack.core.ml.job.results.Forecast;\n+import org.elasticsearch.xpack.core.ml.job.results.ForecastRequestStats;\n+import org.elasticsearch.xpack.core.ml.job.results.Influencer;\n+import org.elasticsearch.xpack.core.ml.job.results.ModelPlot;\n+import org.elasticsearch.xpack.ml.job.persistence.JobResultsPersister;\n+import org.elasticsearch.xpack.ml.job.process.autodetect.AutodetectProcess;\n+import org.elasticsearch.xpack.ml.job.results.AutodetectResult;\n+\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+\n+/**\n+ * A runnable class that reads the autodetect process output in the\n+ * {@link #process()} method and persists parsed\n+ * results via the {@linkplain JobResultsPersister} passed in the constructor.\n+ * <p>\n+ * This is a single purpose result processor and only handles snapshot writes\n+ */\n+public class JobSnapshotUpgraderResultProcessor {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(JobSnapshotUpgraderResultProcessor.class);\n+    final CountDownLatch completionLatch = new CountDownLatch(1);\n+    private final String jobId;\n+    private final String snapshotId;\n+    private final JobResultsPersister persister;\n+    private final AutodetectProcess process;\n+    private final JobResultsPersister.Builder bulkResultsPersister;\n+    private volatile boolean processKilled;\n+    private volatile boolean failed;\n+\n+    public JobSnapshotUpgraderResultProcessor(String jobId,\n+                                              String snapshotId,\n+                                              JobResultsPersister persister,\n+                                              AutodetectProcess autodetectProcess) {\n+        this.jobId = Objects.requireNonNull(jobId);\n+        this.snapshotId = Objects.requireNonNull(snapshotId);\n+        this.persister = Objects.requireNonNull(persister);\n+        this.process = Objects.requireNonNull(autodetectProcess);\n+        this.bulkResultsPersister = persister.bulkPersisterBuilder(jobId).shouldRetry(this::isAlive);\n+    }\n+\n+    public void process() {\n+\n+        // If a function call in this throws for some reason we don't want it\n+        // to kill the results reader thread as autodetect will be blocked\n+        // trying to write its output.\n+        try {\n+            readResults();\n+            try {\n+                if (processKilled == false) {\n+                    bulkResultsPersister.executeRequest();\n+                }\n+            } catch (Exception e) {\n+                LOGGER.warn(new ParameterizedMessage(\"[{}] Error persisting autodetect results\", jobId), e);\n+            }\n+        } catch (Exception e) {\n+            failed = true;\n+\n+            if (processKilled) {\n+                // Don't log the stack trace in this case.  Log just enough to hint\n+                // that it would have been better to close jobs before shutting down,\n+                // but we now fully expect jobs to move between nodes without doing\n+                // all their graceful close activities.\n+                LOGGER.warn(\"[{}] some results not processed due to the process being killed\", jobId);\n+            } else if (process.isProcessAliveAfterWaiting() == false) {\n+                // Don't log the stack trace to not shadow the root cause.\n+                LOGGER.warn(\"[{}] some results not processed due to the termination of autodetect\", jobId);", "originalCommit": "7ba38b6560b885fcb19e09f2c6f59cbe955f9231", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjA0NDE5Mw==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r522044193", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            LOGGER.error(new ParameterizedMessage(\"[{}] error parsing autodetect output\", jobId), e);\n          \n          \n            \n                            LOGGER.error(new ParameterizedMessage(\"[{}] error parsing autodetect output during model snapshot [{}] upgrade\", jobId, snapshotId), e);", "author": "droberts195", "createdAt": "2020-11-12T11:43:08Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/job/process/autodetect/output/JobSnapshotUpgraderResultProcessor.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.job.process.autodetect.output;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.bulk.BulkResponse;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.xpack.core.ml.MachineLearningField;\n+import org.elasticsearch.xpack.core.ml.annotations.Annotation;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.output.FlushAcknowledgement;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.CategorizerStats;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.ModelSizeStats;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.ModelSnapshot;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.Quantiles;\n+import org.elasticsearch.xpack.core.ml.job.results.AnomalyRecord;\n+import org.elasticsearch.xpack.core.ml.job.results.Bucket;\n+import org.elasticsearch.xpack.core.ml.job.results.CategoryDefinition;\n+import org.elasticsearch.xpack.core.ml.job.results.Forecast;\n+import org.elasticsearch.xpack.core.ml.job.results.ForecastRequestStats;\n+import org.elasticsearch.xpack.core.ml.job.results.Influencer;\n+import org.elasticsearch.xpack.core.ml.job.results.ModelPlot;\n+import org.elasticsearch.xpack.ml.job.persistence.JobResultsPersister;\n+import org.elasticsearch.xpack.ml.job.process.autodetect.AutodetectProcess;\n+import org.elasticsearch.xpack.ml.job.results.AutodetectResult;\n+\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+\n+/**\n+ * A runnable class that reads the autodetect process output in the\n+ * {@link #process()} method and persists parsed\n+ * results via the {@linkplain JobResultsPersister} passed in the constructor.\n+ * <p>\n+ * This is a single purpose result processor and only handles snapshot writes\n+ */\n+public class JobSnapshotUpgraderResultProcessor {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(JobSnapshotUpgraderResultProcessor.class);\n+    final CountDownLatch completionLatch = new CountDownLatch(1);\n+    private final String jobId;\n+    private final String snapshotId;\n+    private final JobResultsPersister persister;\n+    private final AutodetectProcess process;\n+    private final JobResultsPersister.Builder bulkResultsPersister;\n+    private volatile boolean processKilled;\n+    private volatile boolean failed;\n+\n+    public JobSnapshotUpgraderResultProcessor(String jobId,\n+                                              String snapshotId,\n+                                              JobResultsPersister persister,\n+                                              AutodetectProcess autodetectProcess) {\n+        this.jobId = Objects.requireNonNull(jobId);\n+        this.snapshotId = Objects.requireNonNull(snapshotId);\n+        this.persister = Objects.requireNonNull(persister);\n+        this.process = Objects.requireNonNull(autodetectProcess);\n+        this.bulkResultsPersister = persister.bulkPersisterBuilder(jobId).shouldRetry(this::isAlive);\n+    }\n+\n+    public void process() {\n+\n+        // If a function call in this throws for some reason we don't want it\n+        // to kill the results reader thread as autodetect will be blocked\n+        // trying to write its output.\n+        try {\n+            readResults();\n+            try {\n+                if (processKilled == false) {\n+                    bulkResultsPersister.executeRequest();\n+                }\n+            } catch (Exception e) {\n+                LOGGER.warn(new ParameterizedMessage(\"[{}] Error persisting autodetect results\", jobId), e);\n+            }\n+        } catch (Exception e) {\n+            failed = true;\n+\n+            if (processKilled) {\n+                // Don't log the stack trace in this case.  Log just enough to hint\n+                // that it would have been better to close jobs before shutting down,\n+                // but we now fully expect jobs to move between nodes without doing\n+                // all their graceful close activities.\n+                LOGGER.warn(\"[{}] some results not processed due to the process being killed\", jobId);\n+            } else if (process.isProcessAliveAfterWaiting() == false) {\n+                // Don't log the stack trace to not shadow the root cause.\n+                LOGGER.warn(\"[{}] some results not processed due to the termination of autodetect\", jobId);\n+            } else {\n+                // We should only get here if the iterator throws in which\n+                // case parsing the autodetect output has failed.\n+                LOGGER.error(new ParameterizedMessage(\"[{}] error parsing autodetect output\", jobId), e);", "originalCommit": "7ba38b6560b885fcb19e09f2c6f59cbe955f9231", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjA0NDQ2MA==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r522044460", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                LOGGER.warn(new ParameterizedMessage(\"[{}] Error processing autodetect result\", jobId), e);\n          \n          \n            \n                                LOGGER.warn(new ParameterizedMessage(\"[{}] Error processing autodetect result during model snapshot [{}] upgrade\", jobId, snapshotId), e);", "author": "droberts195", "createdAt": "2020-11-12T11:43:38Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/job/process/autodetect/output/JobSnapshotUpgraderResultProcessor.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.job.process.autodetect.output;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.bulk.BulkResponse;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.xpack.core.ml.MachineLearningField;\n+import org.elasticsearch.xpack.core.ml.annotations.Annotation;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.output.FlushAcknowledgement;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.CategorizerStats;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.ModelSizeStats;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.ModelSnapshot;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.Quantiles;\n+import org.elasticsearch.xpack.core.ml.job.results.AnomalyRecord;\n+import org.elasticsearch.xpack.core.ml.job.results.Bucket;\n+import org.elasticsearch.xpack.core.ml.job.results.CategoryDefinition;\n+import org.elasticsearch.xpack.core.ml.job.results.Forecast;\n+import org.elasticsearch.xpack.core.ml.job.results.ForecastRequestStats;\n+import org.elasticsearch.xpack.core.ml.job.results.Influencer;\n+import org.elasticsearch.xpack.core.ml.job.results.ModelPlot;\n+import org.elasticsearch.xpack.ml.job.persistence.JobResultsPersister;\n+import org.elasticsearch.xpack.ml.job.process.autodetect.AutodetectProcess;\n+import org.elasticsearch.xpack.ml.job.results.AutodetectResult;\n+\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+\n+/**\n+ * A runnable class that reads the autodetect process output in the\n+ * {@link #process()} method and persists parsed\n+ * results via the {@linkplain JobResultsPersister} passed in the constructor.\n+ * <p>\n+ * This is a single purpose result processor and only handles snapshot writes\n+ */\n+public class JobSnapshotUpgraderResultProcessor {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(JobSnapshotUpgraderResultProcessor.class);\n+    final CountDownLatch completionLatch = new CountDownLatch(1);\n+    private final String jobId;\n+    private final String snapshotId;\n+    private final JobResultsPersister persister;\n+    private final AutodetectProcess process;\n+    private final JobResultsPersister.Builder bulkResultsPersister;\n+    private volatile boolean processKilled;\n+    private volatile boolean failed;\n+\n+    public JobSnapshotUpgraderResultProcessor(String jobId,\n+                                              String snapshotId,\n+                                              JobResultsPersister persister,\n+                                              AutodetectProcess autodetectProcess) {\n+        this.jobId = Objects.requireNonNull(jobId);\n+        this.snapshotId = Objects.requireNonNull(snapshotId);\n+        this.persister = Objects.requireNonNull(persister);\n+        this.process = Objects.requireNonNull(autodetectProcess);\n+        this.bulkResultsPersister = persister.bulkPersisterBuilder(jobId).shouldRetry(this::isAlive);\n+    }\n+\n+    public void process() {\n+\n+        // If a function call in this throws for some reason we don't want it\n+        // to kill the results reader thread as autodetect will be blocked\n+        // trying to write its output.\n+        try {\n+            readResults();\n+            try {\n+                if (processKilled == false) {\n+                    bulkResultsPersister.executeRequest();\n+                }\n+            } catch (Exception e) {\n+                LOGGER.warn(new ParameterizedMessage(\"[{}] Error persisting autodetect results\", jobId), e);\n+            }\n+        } catch (Exception e) {\n+            failed = true;\n+\n+            if (processKilled) {\n+                // Don't log the stack trace in this case.  Log just enough to hint\n+                // that it would have been better to close jobs before shutting down,\n+                // but we now fully expect jobs to move between nodes without doing\n+                // all their graceful close activities.\n+                LOGGER.warn(\"[{}] some results not processed due to the process being killed\", jobId);\n+            } else if (process.isProcessAliveAfterWaiting() == false) {\n+                // Don't log the stack trace to not shadow the root cause.\n+                LOGGER.warn(\"[{}] some results not processed due to the termination of autodetect\", jobId);\n+            } else {\n+                // We should only get here if the iterator throws in which\n+                // case parsing the autodetect output has failed.\n+                LOGGER.error(new ParameterizedMessage(\"[{}] error parsing autodetect output\", jobId), e);\n+            }\n+        } finally {\n+            completionLatch.countDown();\n+        }\n+    }\n+\n+    private void readResults() {\n+        try {\n+            Iterator<AutodetectResult> iterator = process.readAutodetectResults();\n+            while (iterator.hasNext()) {\n+                try {\n+                    AutodetectResult result = iterator.next();\n+                    processResult(result);\n+                } catch (Exception e) {\n+                    if (isAlive() == false) {\n+                        throw e;\n+                    }\n+                    LOGGER.warn(new ParameterizedMessage(\"[{}] Error processing autodetect result\", jobId), e);", "originalCommit": "7ba38b6560b885fcb19e09f2c6f59cbe955f9231", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjA0NTY1OQ==", "url": "https://github.com/elastic/elasticsearch/pull/64665#discussion_r522045659", "bodyText": "Consider adding assert resultType == null or something else that will detect if this happens during our integration tests.", "author": "droberts195", "createdAt": "2020-11-12T11:45:48Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/job/process/autodetect/output/JobSnapshotUpgraderResultProcessor.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.job.process.autodetect.output;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.action.bulk.BulkResponse;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.xpack.core.ml.MachineLearningField;\n+import org.elasticsearch.xpack.core.ml.annotations.Annotation;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.output.FlushAcknowledgement;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.CategorizerStats;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.ModelSizeStats;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.ModelSnapshot;\n+import org.elasticsearch.xpack.core.ml.job.process.autodetect.state.Quantiles;\n+import org.elasticsearch.xpack.core.ml.job.results.AnomalyRecord;\n+import org.elasticsearch.xpack.core.ml.job.results.Bucket;\n+import org.elasticsearch.xpack.core.ml.job.results.CategoryDefinition;\n+import org.elasticsearch.xpack.core.ml.job.results.Forecast;\n+import org.elasticsearch.xpack.core.ml.job.results.ForecastRequestStats;\n+import org.elasticsearch.xpack.core.ml.job.results.Influencer;\n+import org.elasticsearch.xpack.core.ml.job.results.ModelPlot;\n+import org.elasticsearch.xpack.ml.job.persistence.JobResultsPersister;\n+import org.elasticsearch.xpack.ml.job.process.autodetect.AutodetectProcess;\n+import org.elasticsearch.xpack.ml.job.results.AutodetectResult;\n+\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+\n+/**\n+ * A runnable class that reads the autodetect process output in the\n+ * {@link #process()} method and persists parsed\n+ * results via the {@linkplain JobResultsPersister} passed in the constructor.\n+ * <p>\n+ * This is a single purpose result processor and only handles snapshot writes\n+ */\n+public class JobSnapshotUpgraderResultProcessor {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(JobSnapshotUpgraderResultProcessor.class);\n+    final CountDownLatch completionLatch = new CountDownLatch(1);\n+    private final String jobId;\n+    private final String snapshotId;\n+    private final JobResultsPersister persister;\n+    private final AutodetectProcess process;\n+    private final JobResultsPersister.Builder bulkResultsPersister;\n+    private volatile boolean processKilled;\n+    private volatile boolean failed;\n+\n+    public JobSnapshotUpgraderResultProcessor(String jobId,\n+                                              String snapshotId,\n+                                              JobResultsPersister persister,\n+                                              AutodetectProcess autodetectProcess) {\n+        this.jobId = Objects.requireNonNull(jobId);\n+        this.snapshotId = Objects.requireNonNull(snapshotId);\n+        this.persister = Objects.requireNonNull(persister);\n+        this.process = Objects.requireNonNull(autodetectProcess);\n+        this.bulkResultsPersister = persister.bulkPersisterBuilder(jobId).shouldRetry(this::isAlive);\n+    }\n+\n+    public void process() {\n+\n+        // If a function call in this throws for some reason we don't want it\n+        // to kill the results reader thread as autodetect will be blocked\n+        // trying to write its output.\n+        try {\n+            readResults();\n+            try {\n+                if (processKilled == false) {\n+                    bulkResultsPersister.executeRequest();\n+                }\n+            } catch (Exception e) {\n+                LOGGER.warn(new ParameterizedMessage(\"[{}] Error persisting autodetect results\", jobId), e);\n+            }\n+        } catch (Exception e) {\n+            failed = true;\n+\n+            if (processKilled) {\n+                // Don't log the stack trace in this case.  Log just enough to hint\n+                // that it would have been better to close jobs before shutting down,\n+                // but we now fully expect jobs to move between nodes without doing\n+                // all their graceful close activities.\n+                LOGGER.warn(\"[{}] some results not processed due to the process being killed\", jobId);\n+            } else if (process.isProcessAliveAfterWaiting() == false) {\n+                // Don't log the stack trace to not shadow the root cause.\n+                LOGGER.warn(\"[{}] some results not processed due to the termination of autodetect\", jobId);\n+            } else {\n+                // We should only get here if the iterator throws in which\n+                // case parsing the autodetect output has failed.\n+                LOGGER.error(new ParameterizedMessage(\"[{}] error parsing autodetect output\", jobId), e);\n+            }\n+        } finally {\n+            completionLatch.countDown();\n+        }\n+    }\n+\n+    private void readResults() {\n+        try {\n+            Iterator<AutodetectResult> iterator = process.readAutodetectResults();\n+            while (iterator.hasNext()) {\n+                try {\n+                    AutodetectResult result = iterator.next();\n+                    processResult(result);\n+                } catch (Exception e) {\n+                    if (isAlive() == false) {\n+                        throw e;\n+                    }\n+                    LOGGER.warn(new ParameterizedMessage(\"[{}] Error processing autodetect result\", jobId), e);\n+                }\n+            }\n+        } finally {\n+            process.consumeAndCloseOutputStream();\n+        }\n+    }\n+\n+    public void setProcessKilled() {\n+        processKilled = true;\n+    }\n+\n+    private void logUnexpectedResult(String resultType) {\n+        LOGGER.info(\"[{}] [{}] unexpected result read [{}]\", jobId, snapshotId, resultType);\n+    }", "originalCommit": "7ba38b6560b885fcb19e09f2c6f59cbe955f9231", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "db82d801681cfd7a9d26b7de4d3cbc898c9ff9ed", "url": "https://github.com/elastic/elasticsearch/commit/db82d801681cfd7a9d26b7de4d3cbc898c9ff9ed", "message": "Merge remote-tracking branch 'upstream/master' into feature/ml-add-snapshot-upgrader-api", "committedDate": "2020-11-12T12:39:42Z", "type": "commit"}, {"oid": "51855d62cc90b6acd5b309a7095d0a3d447c8c5f", "url": "https://github.com/elastic/elasticsearch/commit/51855d62cc90b6acd5b309a7095d0a3d447c8c5f", "message": "addressing PR comments", "committedDate": "2020-11-12T12:54:33Z", "type": "commit"}]}