{"pr_number": 53986, "pr_title": "Implement aggregations on aggregate metrics", "pr_createdAt": "2020-03-23T14:58:34Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/53986", "timeline": [{"oid": "649b06e6b390da7c3f167e1cff97d671e24e49f4", "url": "https://github.com/elastic/elasticsearch/commit/649b06e6b390da7c3f167e1cff97d671e24e49f4", "message": "Implemented aggregate_metric field type for storing pre-computed aggregates", "committedDate": "2020-03-27T13:39:58Z", "type": "commit"}, {"oid": "2a6292ca25864c3cdb284b0d0a8740bba665d731", "url": "https://github.com/elastic/elasticsearch/commit/2a6292ca25864c3cdb284b0d0a8740bba665d731", "message": "Addressing code review comments", "committedDate": "2020-03-27T13:39:59Z", "type": "commit"}, {"oid": "e43595d6e714b0150554c8d6360a7047633aa404", "url": "https://github.com/elastic/elasticsearch/commit/e43595d6e714b0150554c8d6360a7047633aa404", "message": "Moved AggregateMetricFieldMapper to its own module", "committedDate": "2020-03-27T13:42:51Z", "type": "commit"}, {"oid": "7d1ef0e50f8e511d4b1bf27650403b895fba51fa", "url": "https://github.com/elastic/elasticsearch/commit/7d1ef0e50f8e511d4b1bf27650403b895fba51fa", "message": "Fix broken doc test", "committedDate": "2020-03-27T13:42:51Z", "type": "commit"}, {"oid": "8e254664b54b129c9eb0e0ecd039679de0cd0ba9", "url": "https://github.com/elastic/elasticsearch/commit/8e254664b54b129c9eb0e0ecd039679de0cd0ba9", "message": "Fixes to address code review comments", "committedDate": "2020-03-27T13:42:51Z", "type": "commit"}, {"oid": "415a34fadf9a968d6cfed53b18f712321461c07b", "url": "https://github.com/elastic/elasticsearch/commit/415a34fadf9a968d6cfed53b18f712321461c07b", "message": "Fixes to address code review comments.\n\nMake parsing of malformed values stricter and\nignore all field metrics even if a single metric\nis wrong", "committedDate": "2020-03-27T13:42:51Z", "type": "commit"}, {"oid": "9e100781b44ed2e10cd62e44ee95d40b34037f03", "url": "https://github.com/elastic/elasticsearch/commit/9e100781b44ed2e10cd62e44ee95d40b34037f03", "message": "Fix broken integration tests", "committedDate": "2020-03-27T13:44:52Z", "type": "commit"}, {"oid": "9adc268d1f006dc9ac5180bd60b3950f4c225818", "url": "https://github.com/elastic/elasticsearch/commit/9adc268d1f006dc9ac5180bd60b3950f4c225818", "message": "Added delegate field mappers of NumberFieldType", "committedDate": "2020-03-27T13:44:53Z", "type": "commit"}, {"oid": "4455be0e7754ed9ab9beae58d78998769e30c379", "url": "https://github.com/elastic/elasticsearch/commit/4455be0e7754ed9ab9beae58d78998769e30c379", "message": "Delegate queries to NumberFieldType fields", "committedDate": "2020-03-27T13:44:53Z", "type": "commit"}, {"oid": "4ef00f830cc9b7bba24be0598165afd327197351", "url": "https://github.com/elastic/elasticsearch/commit/4ef00f830cc9b7bba24be0598165afd327197351", "message": "Style fixes", "committedDate": "2020-03-27T13:44:53Z", "type": "commit"}, {"oid": "b949b169610848e18b93dc948ea8dd2b1299b25e", "url": "https://github.com/elastic/elasticsearch/commit/b949b169610848e18b93dc948ea8dd2b1299b25e", "message": "Nit: removed blank line", "committedDate": "2020-03-27T13:44:53Z", "type": "commit"}, {"oid": "61c5f85e748a73a8601b7cfe1f42ce5ff743bfa8", "url": "https://github.com/elastic/elasticsearch/commit/61c5f85e748a73a8601b7cfe1f42ce5ff743bfa8", "message": "Addressed reviewer comments", "committedDate": "2020-03-27T13:44:53Z", "type": "commit"}, {"oid": "cbb21382b759f8e9cb79c73ed4f26e597c77baf9", "url": "https://github.com/elastic/elasticsearch/commit/cbb21382b759f8e9cb79c73ed4f26e597c77baf9", "message": "Fixed NPE issue when \"metrics\" field is missing", "committedDate": "2020-03-27T13:44:53Z", "type": "commit"}, {"oid": "d15d8caa1d842258418f9250e1c7416ac44bdfc0", "url": "https://github.com/elastic/elasticsearch/commit/d15d8caa1d842258418f9250e1c7416ac44bdfc0", "message": "Added integration test", "committedDate": "2020-03-27T13:44:53Z", "type": "commit"}, {"oid": "9b6da4ac6e4d7687a30f7b3b8292efbc596a3b57", "url": "https://github.com/elastic/elasticsearch/commit/9b6da4ac6e4d7687a30f7b3b8292efbc596a3b57", "message": "Override AggregateDoubleMetricFieldMapper methods\n\nisFieldWithinQuery to handle range queries\nefficiently,\nfielddataBuilder to handle aggregations and sort,\ndocValueFormat to format double correctly", "committedDate": "2020-03-27T13:44:53Z", "type": "commit"}, {"oid": "fdf47d7a19c73b19d6b4fcab73df088d994397ac", "url": "https://github.com/elastic/elasticsearch/commit/fdf47d7a19c73b19d6b4fcab73df088d994397ac", "message": "Ensure that a metric field cannot be an array", "committedDate": "2020-03-27T13:44:53Z", "type": "commit"}, {"oid": "cc2b32bbc7348f61d3a5adae2ce7cc14ae823baf", "url": "https://github.com/elastic/elasticsearch/commit/cc2b32bbc7348f61d3a5adae2ce7cc14ae823baf", "message": "Ensure that merging two fields with different\n\nmetrics should be an error.", "committedDate": "2020-03-27T13:44:53Z", "type": "commit"}, {"oid": "3128ffd6c8bb07963d5f6a08270c082fa45e1be2", "url": "https://github.com/elastic/elasticsearch/commit/3128ffd6c8bb07963d5f6a08270c082fa45e1be2", "message": "Checkstyle", "committedDate": "2020-03-27T13:44:54Z", "type": "commit"}, {"oid": "04ad089b85e865fbcbf3198e057162c523351833", "url": "https://github.com/elastic/elasticsearch/commit/04ad089b85e865fbcbf3198e057162c523351833", "message": "Fix typo", "committedDate": "2020-03-27T13:44:54Z", "type": "commit"}, {"oid": "a67a73e4d1de11e147e1d27ded608e7756171213", "url": "https://github.com/elastic/elasticsearch/commit/a67a73e4d1de11e147e1d27ded608e7756171213", "message": "Build changes", "committedDate": "2020-03-27T13:44:54Z", "type": "commit"}, {"oid": "4001c7698b9ec1e859b5b2f27a80b02113195dbb", "url": "https://github.com/elastic/elasticsearch/commit/4001c7698b9ec1e859b5b2f27a80b02113195dbb", "message": "First draft of VS based aggs on aggregate metrics", "committedDate": "2020-03-27T13:44:54Z", "type": "commit"}, {"oid": "bd1d0b63591278e0b4a390b95623693cbe4f74fd", "url": "https://github.com/elastic/elasticsearch/commit/bd1d0b63591278e0b4a390b95623693cbe4f74fd", "message": "Moved field data related classes to x-pack plugin", "committedDate": "2020-03-27T13:44:54Z", "type": "commit"}, {"oid": "505f9d32f4c921f443286fbd3109aa6a001933ae", "url": "https://github.com/elastic/elasticsearch/commit/505f9d32f4c921f443286fbd3109aa6a001933ae", "message": "Removed AggregateDoubleMetricValues classes.\n\nNow AggregateMetricsValuesSource returns directly\na SortedNumericDoubleValues instance which\nreceived by the aggregator", "committedDate": "2020-03-27T13:44:55Z", "type": "commit"}, {"oid": "e29531d6e185b0da372ca78ad522367fca89923f", "url": "https://github.com/elastic/elasticsearch/commit/e29531d6e185b0da372ca78ad522367fca89923f", "message": "Added more tests + code cleanup", "committedDate": "2020-03-27T13:44:55Z", "type": "commit"}, {"oid": "24841e1f94c49c5de3250105b53d594b9901b87c", "url": "https://github.com/elastic/elasticsearch/commit/24841e1f94c49c5de3250105b53d594b9901b87c", "message": "And more tests", "committedDate": "2020-03-27T13:44:55Z", "type": "commit"}, {"oid": "1d2ad1c1e20088e65d8fe9aaa23d4f741bdb3106", "url": "https://github.com/elastic/elasticsearch/commit/1d2ad1c1e20088e65d8fe9aaa23d4f741bdb3106", "message": "Implemented avg agg for aggregate_metric field", "committedDate": "2020-03-27T13:44:55Z", "type": "commit"}, {"oid": "7d9a7169fcac15577668d41b7d29c3e95a60521d", "url": "https://github.com/elastic/elasticsearch/commit/7d9a7169fcac15577668d41b7d29c3e95a60521d", "message": "Fixed license issues", "committedDate": "2020-03-27T13:44:55Z", "type": "commit"}, {"oid": "3728d6f1cae14bc875973a969efa0702f8768b51", "url": "https://github.com/elastic/elasticsearch/commit/3728d6f1cae14bc875973a969efa0702f8768b51", "message": "Fix broken tests", "committedDate": "2020-03-27T13:44:55Z", "type": "commit"}, {"oid": "de264c2a9eaef6cb9e8496cd06e50c06809b0f36", "url": "https://github.com/elastic/elasticsearch/commit/de264c2a9eaef6cb9e8496cd06e50c06809b0f36", "message": "Implemented min/max aggs on aggregate_metric field", "committedDate": "2020-03-27T13:44:55Z", "type": "commit"}, {"oid": "21da92a7fab32b4bc820eca6f000118ba4ff06ca", "url": "https://github.com/elastic/elasticsearch/commit/21da92a7fab32b4bc820eca6f000118ba4ff06ca", "message": "Applied \"spotless\" to mapper-aggregate-metric", "committedDate": "2020-03-27T14:05:59Z", "type": "commit"}, {"oid": "21da92a7fab32b4bc820eca6f000118ba4ff06ca", "url": "https://github.com/elastic/elasticsearch/commit/21da92a7fab32b4bc820eca6f000118ba4ff06ca", "message": "Applied \"spotless\" to mapper-aggregate-metric", "committedDate": "2020-03-27T14:05:59Z", "type": "forcePushed"}, {"oid": "24d551af1251e38d6e0bb90d7a0307e7fe08309d", "url": "https://github.com/elastic/elasticsearch/commit/24d551af1251e38d6e0bb90d7a0307e7fe08309d", "message": "Added unit tests for AggregateMetricBackedMinAggregator", "committedDate": "2020-03-27T15:15:53Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg4NTU0MA==", "url": "https://github.com/elastic/elasticsearch/pull/53986#discussion_r399885540", "bodyText": "Future todo (not for this PR): I wonder if there is a way we could extract the BKD optimization in Core so that it can be shared by Core + Pre-aggregated metrics.\nBut not for today, future project :)", "author": "polyfractal", "createdAt": "2020-03-30T01:23:59Z", "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/aggregations/metrics/AggregateMetricBackedMaxAggregator.java", "diffHunk": "@@ -0,0 +1,200 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.aggregatemetric.aggregations.metrics;\n+\n+import org.apache.lucene.index.LeafReader;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.PointValues;\n+import org.apache.lucene.search.CollectionTerminatedException;\n+import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.util.Bits;\n+import org.apache.lucene.util.FutureArrays;\n+import org.elasticsearch.common.lease.Releasables;\n+import org.elasticsearch.common.util.BigArrays;\n+import org.elasticsearch.common.util.DoubleArray;\n+import org.elasticsearch.index.fielddata.NumericDoubleValues;\n+import org.elasticsearch.index.fielddata.SortedNumericDoubleValues;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.MultiValueMode;\n+import org.elasticsearch.search.aggregations.Aggregator;\n+import org.elasticsearch.search.aggregations.InternalAggregation;\n+import org.elasticsearch.search.aggregations.LeafBucketCollector;\n+import org.elasticsearch.search.aggregations.LeafBucketCollectorBase;\n+import org.elasticsearch.search.aggregations.metrics.InternalMax;\n+import org.elasticsearch.search.aggregations.metrics.NumericMetricsAggregator;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceConfig;\n+import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.xpack.aggregatemetric.aggregations.support.AggregateMetricsValuesSource;\n+import org.elasticsearch.xpack.aggregatemetric.mapper.AggregateDoubleMetricFieldMapper.Metric;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Function;\n+\n+import static org.elasticsearch.search.aggregations.metrics.MinAggregator.getPointReaderOrNull;\n+\n+class AggregateMetricBackedMaxAggregator extends NumericMetricsAggregator.SingleValue {\n+\n+    private final AggregateMetricsValuesSource.AggregateDoubleMetric valuesSource;\n+    final DocValueFormat formatter;\n+\n+    final String pointField;\n+    final Function<byte[], Number> pointConverter;\n+\n+    DoubleArray maxes;\n+\n+    AggregateMetricBackedMaxAggregator(\n+        String name,\n+        ValuesSourceConfig config,\n+        AggregateMetricsValuesSource.AggregateDoubleMetric valuesSource,\n+        SearchContext context,\n+        Aggregator parent,\n+        List<PipelineAggregator> pipelineAggregators,\n+        Map<String, Object> metaData\n+    )\n+        throws IOException {\n+        super(name, context, parent, pipelineAggregators, metaData);\n+        this.valuesSource = valuesSource;\n+        if (valuesSource != null) {\n+            maxes = context.bigArrays().newDoubleArray(1, false);\n+            maxes.fill(0, maxes.size(), Double.NEGATIVE_INFINITY);\n+        }\n+        this.formatter = config.format();\n+        this.pointConverter = getPointReaderOrNull(context, parent, config);\n+        if (pointConverter != null) {\n+            pointField = config.fieldContext().field();\n+        } else {\n+            pointField = null;\n+        }\n+    }\n+\n+    @Override\n+    public ScoreMode scoreMode() {\n+        return valuesSource != null && valuesSource.needsScores() ? ScoreMode.COMPLETE : ScoreMode.COMPLETE_NO_SCORES;\n+    }\n+\n+    @Override\n+    public LeafBucketCollector getLeafCollector(LeafReaderContext ctx, final LeafBucketCollector sub) throws IOException {\n+        if (valuesSource == null) {\n+            if (parent != null) {\n+                return LeafBucketCollector.NO_OP_COLLECTOR;\n+            } else {\n+                // we have no parent and the values source is empty so we can skip collecting hits.\n+                throw new CollectionTerminatedException();\n+            }\n+        }\n+        if (pointConverter != null) {", "originalCommit": "21da92a7fab32b4bc820eca6f000118ba4ff06ca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg2Njc0NA==", "url": "https://github.com/elastic/elasticsearch/pull/53986#discussion_r400866744", "bodyText": "For this PR I removed all point reader / bkd optimizations", "author": "csoulios", "createdAt": "2020-03-31T12:19:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg4NTU0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg4Nzk4MA==", "url": "https://github.com/elastic/elasticsearch/pull/53986#discussion_r399887980", "bodyText": "I think this won't end up working, or rather, will never return a valid pointConverter and so all the associated BKD logic is not needed.  E.g. MinAggregator#getPointReaderOrNull() fetches the field context and then does naive instanceof checks to see what kind of field it is (number or date atm).  Which I believe won't match because the field here is actually the pre-aggregated field class.\nWe'd need some way to tell that function (or create a new one) which metric to get out of the pre-agg field, which is harder since it's in Core.\nIt's a nice optimization but also pretty niche... I think it would be ok to remove all the point reader / bkd optimization from these aggregators to keep them simple.  We can add them back later.", "author": "polyfractal", "createdAt": "2020-03-30T01:38:29Z", "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/aggregations/metrics/AggregateMetricBackedMaxAggregator.java", "diffHunk": "@@ -0,0 +1,200 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.aggregatemetric.aggregations.metrics;\n+\n+import org.apache.lucene.index.LeafReader;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.PointValues;\n+import org.apache.lucene.search.CollectionTerminatedException;\n+import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.util.Bits;\n+import org.apache.lucene.util.FutureArrays;\n+import org.elasticsearch.common.lease.Releasables;\n+import org.elasticsearch.common.util.BigArrays;\n+import org.elasticsearch.common.util.DoubleArray;\n+import org.elasticsearch.index.fielddata.NumericDoubleValues;\n+import org.elasticsearch.index.fielddata.SortedNumericDoubleValues;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.MultiValueMode;\n+import org.elasticsearch.search.aggregations.Aggregator;\n+import org.elasticsearch.search.aggregations.InternalAggregation;\n+import org.elasticsearch.search.aggregations.LeafBucketCollector;\n+import org.elasticsearch.search.aggregations.LeafBucketCollectorBase;\n+import org.elasticsearch.search.aggregations.metrics.InternalMax;\n+import org.elasticsearch.search.aggregations.metrics.NumericMetricsAggregator;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceConfig;\n+import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.xpack.aggregatemetric.aggregations.support.AggregateMetricsValuesSource;\n+import org.elasticsearch.xpack.aggregatemetric.mapper.AggregateDoubleMetricFieldMapper.Metric;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Function;\n+\n+import static org.elasticsearch.search.aggregations.metrics.MinAggregator.getPointReaderOrNull;\n+\n+class AggregateMetricBackedMaxAggregator extends NumericMetricsAggregator.SingleValue {\n+\n+    private final AggregateMetricsValuesSource.AggregateDoubleMetric valuesSource;\n+    final DocValueFormat formatter;\n+\n+    final String pointField;\n+    final Function<byte[], Number> pointConverter;\n+\n+    DoubleArray maxes;\n+\n+    AggregateMetricBackedMaxAggregator(\n+        String name,\n+        ValuesSourceConfig config,\n+        AggregateMetricsValuesSource.AggregateDoubleMetric valuesSource,\n+        SearchContext context,\n+        Aggregator parent,\n+        List<PipelineAggregator> pipelineAggregators,\n+        Map<String, Object> metaData\n+    )\n+        throws IOException {\n+        super(name, context, parent, pipelineAggregators, metaData);\n+        this.valuesSource = valuesSource;\n+        if (valuesSource != null) {\n+            maxes = context.bigArrays().newDoubleArray(1, false);\n+            maxes.fill(0, maxes.size(), Double.NEGATIVE_INFINITY);\n+        }\n+        this.formatter = config.format();\n+        this.pointConverter = getPointReaderOrNull(context, parent, config);", "originalCommit": "21da92a7fab32b4bc820eca6f000118ba4ff06ca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg2MTIyNA==", "url": "https://github.com/elastic/elasticsearch/pull/53986#discussion_r400861224", "bodyText": "Removed all point reader / bkd optimization", "author": "csoulios", "createdAt": "2020-03-31T12:10:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg4Nzk4MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg4ODE0MQ==", "url": "https://github.com/elastic/elasticsearch/pull/53986#discussion_r399888141", "bodyText": "Ditto here too", "author": "polyfractal", "createdAt": "2020-03-30T01:39:07Z", "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/aggregations/metrics/AggregateMetricBackedMinAggregator.java", "diffHunk": "@@ -0,0 +1,232 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.aggregatemetric.aggregations.metrics;\n+\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.LeafReader;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.PointValues;\n+import org.apache.lucene.search.CollectionTerminatedException;\n+import org.apache.lucene.search.MatchAllDocsQuery;\n+import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.util.Bits;\n+import org.elasticsearch.common.lease.Releasables;\n+import org.elasticsearch.common.util.BigArrays;\n+import org.elasticsearch.common.util.DoubleArray;\n+import org.elasticsearch.index.fielddata.NumericDoubleValues;\n+import org.elasticsearch.index.fielddata.SortedNumericDoubleValues;\n+import org.elasticsearch.index.mapper.DateFieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.MultiValueMode;\n+import org.elasticsearch.search.aggregations.Aggregator;\n+import org.elasticsearch.search.aggregations.InternalAggregation;\n+import org.elasticsearch.search.aggregations.LeafBucketCollector;\n+import org.elasticsearch.search.aggregations.LeafBucketCollectorBase;\n+import org.elasticsearch.search.aggregations.metrics.InternalMin;\n+import org.elasticsearch.search.aggregations.metrics.NumericMetricsAggregator;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceConfig;\n+import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.xpack.aggregatemetric.aggregations.support.AggregateMetricsValuesSource;\n+import org.elasticsearch.xpack.aggregatemetric.mapper.AggregateDoubleMetricFieldMapper.Metric;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Function;\n+\n+class AggregateMetricBackedMinAggregator extends NumericMetricsAggregator.SingleValue {\n+    private static final int MAX_BKD_LOOKUPS = 1024;\n+\n+    private final AggregateMetricsValuesSource.AggregateDoubleMetric valuesSource;\n+    final DocValueFormat format;\n+\n+    final String pointField;\n+    final Function<byte[], Number> pointConverter;\n+\n+    DoubleArray mins;\n+\n+    AggregateMetricBackedMinAggregator(\n+        String name,\n+        ValuesSourceConfig config,\n+        AggregateMetricsValuesSource.AggregateDoubleMetric valuesSource,\n+        SearchContext context,\n+        Aggregator parent,\n+        List<PipelineAggregator> pipelineAggregators,\n+        Map<String, Object> metaData\n+    )\n+        throws IOException {\n+        super(name, context, parent, pipelineAggregators, metaData);\n+        this.valuesSource = valuesSource;\n+        if (valuesSource != null) {\n+            mins = context.bigArrays().newDoubleArray(1, false);\n+            mins.fill(0, mins.size(), Double.POSITIVE_INFINITY);\n+        }\n+        this.format = config.format();\n+        this.pointConverter = getPointReaderOrNull(context, parent, config);", "originalCommit": "21da92a7fab32b4bc820eca6f000118ba4ff06ca", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg4ODMyMA==", "url": "https://github.com/elastic/elasticsearch/pull/53986#discussion_r399888320", "bodyText": "Tiny nit: !(indexFieldData ... ) instead of ... == false", "author": "polyfractal", "createdAt": "2020-03-30T01:40:18Z", "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/aggregations/support/AggregateMetricsValuesSourceType.java", "diffHunk": "@@ -0,0 +1,63 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.aggregatemetric.aggregations.support;\n+\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.script.AggregationScript;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.AggregationExecutionException;\n+import org.elasticsearch.search.aggregations.support.FieldContext;\n+import org.elasticsearch.search.aggregations.support.ValueType;\n+import org.elasticsearch.search.aggregations.support.ValuesSource;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceType;\n+import org.elasticsearch.xpack.aggregatemetric.fielddata.IndexAggregateDoubleMetricFieldData;\n+\n+import java.util.Locale;\n+import java.util.function.LongSupplier;\n+\n+public enum AggregateMetricsValuesSourceType implements ValuesSourceType {\n+\n+    AGGREGATE_METRIC() {\n+        @Override\n+        public ValuesSource getEmpty() {\n+            throw new IllegalArgumentException(\"Can't deal with unmapped AggregateMetricsValuesSource type \" + this.value());\n+        }\n+\n+        @Override\n+        public ValuesSource getScript(AggregationScript.LeafFactory script, ValueType scriptValueType) {\n+            throw new AggregationExecutionException(\"Value source of type [\" + this.value() + \"] is not supported by scripts\");\n+        }\n+\n+        @Override\n+        public ValuesSource getField(FieldContext fieldContext, AggregationScript.LeafFactory script) {\n+            final IndexFieldData<?> indexFieldData = fieldContext.indexFieldData();\n+\n+            if (!(indexFieldData instanceof IndexAggregateDoubleMetricFieldData)) {", "originalCommit": "21da92a7fab32b4bc820eca6f000118ba4ff06ca", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDEzMzE5MQ==", "url": "https://github.com/elastic/elasticsearch/pull/53986#discussion_r400133191", "bodyText": "Should we ensure that we  have a single value per document when parsing ?", "author": "jimczi", "createdAt": "2020-03-30T11:56:06Z", "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/mapper/AggregateDoubleMetricFieldMapper.java", "diffHunk": "@@ -0,0 +1,689 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.aggregatemetric.mapper;\n+\n+import org.apache.lucene.index.DocValues;\n+import org.apache.lucene.index.IndexReader;\n+import org.apache.lucene.index.IndexableField;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.NumericDocValues;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.SortField;\n+import org.elasticsearch.common.Explicit;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.time.DateMathParser;\n+import org.elasticsearch.common.util.BigArrays;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.XContentSubParser;\n+import org.elasticsearch.common.xcontent.support.XContentMapValues;\n+import org.elasticsearch.index.IndexSettings;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.IndexFieldDataCache;\n+import org.elasticsearch.index.fielddata.ScriptDocValues;\n+import org.elasticsearch.index.fielddata.SortedBinaryDocValues;\n+import org.elasticsearch.index.fielddata.SortedNumericDoubleValues;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SimpleMappedFieldType;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryRewriteContext;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.indices.breaker.CircuitBreakerService;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.MultiValueMode;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceType;\n+import org.elasticsearch.search.sort.BucketedSort;\n+import org.elasticsearch.search.sort.SortOrder;\n+import org.elasticsearch.xpack.aggregatemetric.aggregations.support.AggregateMetricsValuesSourceType;\n+import org.elasticsearch.xpack.aggregatemetric.fielddata.IndexAggregateDoubleMetricFieldData;\n+import org.elasticsearch.xpack.aggregatemetric.fielddata.LeafAggregateDoubleMetricFieldData;\n+\n+import java.io.IOException;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.EnumMap;\n+import java.util.EnumSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import static org.elasticsearch.common.xcontent.XContentParserUtils.ensureExpectedToken;\n+\n+/** A {@link FieldMapper} for a field containing aggregate metrics such as min/max/value_count etc. */\n+public class AggregateDoubleMetricFieldMapper extends FieldMapper {\n+\n+    public static final String CONTENT_TYPE = \"aggregate_metric_double\";\n+    public static final String SUBFIELD_SEPARATOR = \"._\";\n+\n+    /**\n+     * Return the name of a subfield of an aggregate metric field\n+     *\n+     * @param fieldName the name of the aggregate metric field\n+     * @param metric    the metric type the subfield corresponds to\n+     * @return the name of the subfield\n+     */\n+    public static String subfieldName(String fieldName, Metric metric) {\n+        return fieldName + AggregateDoubleMetricFieldMapper.SUBFIELD_SEPARATOR + metric.name();\n+    }\n+\n+    /**\n+     * Mapping field names\n+     */\n+    public static class Names {\n+        public static final ParseField IGNORE_MALFORMED = new ParseField(\"ignore_malformed\");\n+        public static final ParseField METRICS = new ParseField(\"metrics\");\n+        public static final ParseField DEFAULT_METRIC = new ParseField(\"default_metric\");\n+    }\n+\n+    /**\n+     * Enum of aggregate metrics supported by this field mapper\n+     */\n+    public enum Metric {\n+        min,\n+        max,\n+        sum,\n+        value_count;\n+    }\n+\n+    public static class Defaults {\n+        public static final Explicit<Boolean> IGNORE_MALFORMED = new Explicit<>(false, false);\n+        public static final Explicit<Set<Metric>> METRICS = new Explicit<>(Collections.emptySet(), false);\n+        public static final Explicit<Metric> DEFAULT_METRIC = new Explicit<>(Metric.max, false);\n+        public static final AggregateDoubleMetricFieldType FIELD_TYPE = new AggregateDoubleMetricFieldType();\n+    }\n+\n+    public static class Builder extends FieldMapper.Builder<AggregateDoubleMetricFieldMapper.Builder, AggregateDoubleMetricFieldMapper> {\n+\n+        private Boolean ignoreMalformed;\n+\n+        /**\n+         * The aggregated metrics supported by the field type\n+         */\n+        private EnumSet<Metric> metrics;\n+\n+        /**\n+         * Set the default metric so that query operations are delegated to it.\n+         */\n+        private Metric defaultMetric;\n+\n+        public Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        public AggregateDoubleMetricFieldMapper.Builder ignoreMalformed(boolean ignoreMalformed) {\n+            this.ignoreMalformed = ignoreMalformed;\n+            return builder;\n+        }\n+\n+        protected Explicit<Boolean> ignoreMalformed(BuilderContext context) {\n+            if (ignoreMalformed != null) {\n+                return new Explicit<>(ignoreMalformed, true);\n+            }\n+            if (context.indexSettings() != null) {\n+                return new Explicit<>(IGNORE_MALFORMED_SETTING.get(context.indexSettings()), false);\n+            }\n+            return AggregateDoubleMetricFieldMapper.Defaults.IGNORE_MALFORMED;\n+        }\n+\n+        public AggregateDoubleMetricFieldMapper.Builder defaultMetric(Metric defaultMetric) {\n+            this.defaultMetric = defaultMetric;\n+            return builder;\n+        }\n+\n+        protected Explicit<Metric> defaultMetric(BuilderContext context) {\n+            if (defaultMetric != null) {\n+                if (metrics != null && metrics.contains(defaultMetric) == false) {\n+                    // The default_metric is not defined in the \"metrics\" field\n+                    throw new IllegalArgumentException(\"Metric [\" + defaultMetric + \"] is not defined in the metrics field.\");\n+                }\n+                return new Explicit<>(defaultMetric, true);\n+            }\n+\n+            // If a single metric is contained, this should be the default\n+            if (metrics != null && metrics.size() == 1) {\n+                return new Explicit<>(metrics.iterator().next(), false);\n+            }\n+\n+            if (metrics.contains(Defaults.DEFAULT_METRIC.value())) {\n+                return Defaults.DEFAULT_METRIC;\n+            }\n+            throw new IllegalArgumentException(\n+                \"Property [\" + Names.DEFAULT_METRIC.getPreferredName() + \"] must be set for field [\" + name() + \"].\"\n+            );\n+        }\n+\n+        public AggregateDoubleMetricFieldMapper.Builder metrics(EnumSet<Metric> metrics) {\n+            this.metrics = metrics;\n+            return builder;\n+        }\n+\n+        protected Explicit<Set<Metric>> metrics(BuilderContext context) {\n+            if (metrics != null) {\n+                return new Explicit<>(metrics, true);\n+            }\n+            return Defaults.METRICS;\n+        }\n+\n+        @Override\n+        public AggregateDoubleMetricFieldMapper build(BuilderContext context) {\n+            setupFieldType(context);\n+\n+            if (metrics == null || metrics.isEmpty()) {\n+                throw new IllegalArgumentException(\n+                    \"Property [\" + Names.METRICS.getPreferredName() + \"] must be set for field [\" + name() + \"].\"\n+                );\n+            }\n+\n+            EnumMap<Metric, NumberFieldMapper> metricMappers = new EnumMap<>(Metric.class);\n+            // Instantiate one NumberFieldMapper instance for each metric\n+            for (Metric m : this.metrics) {\n+                String fieldName = subfieldName(context.path().pathAsText(name), m);\n+                NumberFieldMapper.Builder builder;\n+\n+                if (m == Metric.value_count) {\n+                    // value_count metric can only be an integer and not a double\n+                    builder = new NumberFieldMapper.Builder(fieldName, NumberFieldMapper.NumberType.INTEGER);\n+                    builder.coerce(false);\n+                } else {\n+                    builder = new NumberFieldMapper.Builder(fieldName, NumberFieldMapper.NumberType.DOUBLE);\n+                }\n+                NumberFieldMapper fieldMapper = builder.build(context);\n+                metricMappers.put(m, fieldMapper);\n+            }\n+\n+            EnumMap<Metric, NumberFieldMapper.NumberFieldType> metricFields = metricMappers.entrySet()\n+                .stream()\n+                .collect(\n+                    Collectors.toMap(\n+                        Map.Entry::getKey,\n+                        e -> e.getValue().fieldType(),\n+                        (l, r) -> { throw new IllegalArgumentException(\"Duplicate keys \" + l + \"and \" + r + \".\"); },\n+                        () -> new EnumMap<>(Metric.class)\n+                    )\n+                );\n+\n+            AggregateDoubleMetricFieldType metricFieldType = (AggregateDoubleMetricFieldType) fieldType;\n+            metricFieldType.setMetricFields(metricFields);\n+\n+            Explicit<Metric> defaultMetric = defaultMetric(context);\n+            metricFieldType.setDefaultMetric(defaultMetric.value());\n+\n+            return new AggregateDoubleMetricFieldMapper(\n+                name,\n+                metricFieldType,\n+                defaultFieldType,\n+                context.indexSettings(),\n+                multiFieldsBuilder.build(this, context),\n+                ignoreMalformed(context),\n+                metrics(context),\n+                defaultMetric,\n+                copyTo,\n+                metricMappers\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        @Override\n+        public Mapper.Builder<Builder, AggregateDoubleMetricFieldMapper> parse(\n+            String name,\n+            Map<String, Object> node,\n+            ParserContext parserContext\n+        ) throws MapperParsingException {\n+            AggregateDoubleMetricFieldMapper.Builder builder = new AggregateDoubleMetricFieldMapper.Builder(name);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(Names.METRICS.getPreferredName())) {\n+                    String metricsStr[] = XContentMapValues.nodeStringArrayValue(propNode);\n+                    // Make sure that metrics are supported\n+                    EnumSet<Metric> parsedMetrics = EnumSet.noneOf(Metric.class);\n+                    for (int i = 0; i < metricsStr.length; i++) {\n+                        try {\n+                            Metric m = Metric.valueOf(metricsStr[i]);\n+                            parsedMetrics.add(m);\n+                        } catch (IllegalArgumentException e) {\n+                            throw new IllegalArgumentException(\"Metric [\" + metricsStr[i] + \"] is not supported.\", e);\n+                        }\n+                    }\n+                    builder.metrics(parsedMetrics);\n+                    iterator.remove();\n+                } else if (propName.equals(Names.DEFAULT_METRIC.getPreferredName())) {\n+                    String defaultMetric = XContentMapValues.nodeStringValue(\n+                        propNode,\n+                        name + \".\" + Names.DEFAULT_METRIC.getPreferredName()\n+                    );\n+                    try {\n+                        Metric m = Metric.valueOf(defaultMetric);\n+                        builder.defaultMetric(m);\n+                        iterator.remove();\n+                    } catch (IllegalArgumentException e) {\n+                        throw new IllegalArgumentException(\"Metric [\" + defaultMetric + \"] is not supported.\", e);\n+                    }\n+                } else if (propName.equals(Names.IGNORE_MALFORMED.getPreferredName())) {\n+                    builder.ignoreMalformed(\n+                        XContentMapValues.nodeBooleanValue(propNode, name + \".\" + Names.IGNORE_MALFORMED.getPreferredName())\n+                    );\n+                    iterator.remove();\n+                } else if (TypeParsers.parseMultiField(builder, name, parserContext, propName, propNode)) {\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class AggregateDoubleMetricFieldType extends SimpleMappedFieldType {\n+\n+        private EnumMap<Metric, NumberFieldMapper.NumberFieldType> metricFields;\n+\n+        private Metric defaultMetric;\n+\n+        public AggregateDoubleMetricFieldType() {}\n+\n+        AggregateDoubleMetricFieldType(AggregateDoubleMetricFieldType other) {\n+            super(other);\n+            this.metricFields = other.metricFields;\n+            this.defaultMetric = other.defaultMetric;\n+        }\n+\n+        @Override\n+        public MappedFieldType clone() {\n+            return new AggregateDoubleMetricFieldType(this);\n+        }\n+\n+        /**\n+         * Return a delegate field type for a given metric sub-field\n+         * @return a field type\n+         */\n+        private NumberFieldMapper.NumberFieldType delegateFieldType(Metric metric) {\n+            return metricFields.get(metric);\n+        }\n+\n+        /**\n+         * Return a delegate field type for the default metric sub-field\n+         * @return a field type\n+         */\n+        private NumberFieldMapper.NumberFieldType delegateFieldType() {\n+            return delegateFieldType(defaultMetric);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        private void setMetricFields(EnumMap<Metric, NumberFieldMapper.NumberFieldType> metricFields) {\n+            checkIfFrozen();\n+            this.metricFields = metricFields;\n+        }\n+\n+        public void addMetricField(Metric m, NumberFieldMapper.NumberFieldType subfield) {\n+            checkIfFrozen();\n+            if (metricFields == null) {\n+                metricFields = new EnumMap<>(AggregateDoubleMetricFieldMapper.Metric.class);\n+            }\n+\n+            if (name() == null) {\n+                throw new IllegalArgumentException(\"Field of type [\" + typeName() + \"] must have a name before adding a subfield\");\n+            }\n+            String subfieldName = subfieldName(name(), m);\n+            subfield.setName(subfieldName);\n+            metricFields.put(m, subfield);\n+        }\n+\n+        public void setDefaultMetric(Metric defaultMetric) {\n+            checkIfFrozen();\n+            this.defaultMetric = defaultMetric;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return delegateFieldType().existsQuery(context);\n+        }\n+\n+        @Override\n+        public Query termQuery(Object value, QueryShardContext context) {\n+            return delegateFieldType().termQuery(value, context);\n+        }\n+\n+        @Override\n+        public Query termsQuery(List<?> values, QueryShardContext context) {\n+            return delegateFieldType().termsQuery(values, context);\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            return delegateFieldType().rangeQuery(lowerTerm, upperTerm, includeLower, includeUpper, context);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            return delegateFieldType().valueForDisplay(value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(String format, ZoneId timeZone) {\n+            return delegateFieldType().docValueFormat(format, timeZone);\n+        }\n+\n+        @Override\n+        public Relation isFieldWithinQuery(\n+            IndexReader reader,\n+            Object from,\n+            Object to,\n+            boolean includeLower,\n+            boolean includeUpper,\n+            ZoneId timeZone,\n+            DateMathParser dateMathParser,\n+            QueryRewriteContext context\n+        ) throws IOException {\n+            return delegateFieldType().isFieldWithinQuery(reader, from, to, includeLower, includeUpper, timeZone, dateMathParser, context);\n+        }\n+\n+        @Override\n+        public ValuesSourceType getValuesSourceType() {\n+            return AggregateMetricsValuesSourceType.AGGREGATE_METRIC;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            return new IndexFieldData.Builder() {\n+                @Override\n+                public IndexFieldData<?> build(\n+                    IndexSettings indexSettings,\n+                    MappedFieldType fieldType,\n+                    IndexFieldDataCache cache,\n+                    CircuitBreakerService breakerService,\n+                    MapperService mapperService\n+                ) {\n+                    return new IndexAggregateDoubleMetricFieldData(indexSettings.getIndex(), fieldType.name()) {\n+                        @Override\n+                        public LeafAggregateDoubleMetricFieldData load(LeafReaderContext context) {\n+                            return new LeafAggregateDoubleMetricFieldData() {\n+                                @Override\n+                                public SortedNumericDoubleValues getAggregateMetricValues(final Metric metric) throws IOException {\n+                                    try {\n+                                        final NumericDocValues values = DocValues.getNumeric(\n+                                            context.reader(),\n+                                            subfieldName(fieldName, metric)\n+                                        );\n+\n+                                        return new SortedNumericDoubleValues() {\n+                                            @Override\n+                                            public int docValueCount() {\n+                                                return 1;", "originalCommit": "21da92a7fab32b4bc820eca6f000118ba4ff06ca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjExMzEwNw==", "url": "https://github.com/elastic/elasticsearch/pull/53986#discussion_r412113107", "bodyText": "Ensuring that values are not arrays are validated here:\n\n  \n    \n      elasticsearch/x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/mapper/AggregateDoubleMetricFieldMapper.java\n    \n    \n         Line 589\n      in\n      b9bf259\n    \n    \n    \n    \n\n        \n          \n           if (context.doc().getField(delegateFieldMapper.fieldType().name()) != null) { \n        \n    \n  \n\n\nThis code is tested at \n  \n    \n      elasticsearch/x-pack/plugin/mapper-aggregate-metric/src/test/java/org/elasticsearch/xpack/aggregatemetric/mapper/AggregateDoubleMetricFieldMapperTests.java\n    \n    \n         Line 669\n      in\n      b9bf259\n    \n    \n    \n    \n\n        \n          \n           public void testParseArrayValue() throws Exception { \n        \n    \n  \n\n\nIs there anything else I should implement?", "author": "csoulios", "createdAt": "2020-04-21T11:46:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDEzMzE5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDEzMzYxNQ==", "url": "https://github.com/elastic/elasticsearch/pull/53986#discussion_r400133615", "bodyText": "Shouldn't we return a sort field on the default metric ?", "author": "jimczi", "createdAt": "2020-03-30T11:56:54Z", "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/mapper/AggregateDoubleMetricFieldMapper.java", "diffHunk": "@@ -0,0 +1,689 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.aggregatemetric.mapper;\n+\n+import org.apache.lucene.index.DocValues;\n+import org.apache.lucene.index.IndexReader;\n+import org.apache.lucene.index.IndexableField;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.NumericDocValues;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.SortField;\n+import org.elasticsearch.common.Explicit;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.time.DateMathParser;\n+import org.elasticsearch.common.util.BigArrays;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.XContentSubParser;\n+import org.elasticsearch.common.xcontent.support.XContentMapValues;\n+import org.elasticsearch.index.IndexSettings;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.IndexFieldDataCache;\n+import org.elasticsearch.index.fielddata.ScriptDocValues;\n+import org.elasticsearch.index.fielddata.SortedBinaryDocValues;\n+import org.elasticsearch.index.fielddata.SortedNumericDoubleValues;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SimpleMappedFieldType;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryRewriteContext;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.indices.breaker.CircuitBreakerService;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.MultiValueMode;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceType;\n+import org.elasticsearch.search.sort.BucketedSort;\n+import org.elasticsearch.search.sort.SortOrder;\n+import org.elasticsearch.xpack.aggregatemetric.aggregations.support.AggregateMetricsValuesSourceType;\n+import org.elasticsearch.xpack.aggregatemetric.fielddata.IndexAggregateDoubleMetricFieldData;\n+import org.elasticsearch.xpack.aggregatemetric.fielddata.LeafAggregateDoubleMetricFieldData;\n+\n+import java.io.IOException;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.EnumMap;\n+import java.util.EnumSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import static org.elasticsearch.common.xcontent.XContentParserUtils.ensureExpectedToken;\n+\n+/** A {@link FieldMapper} for a field containing aggregate metrics such as min/max/value_count etc. */\n+public class AggregateDoubleMetricFieldMapper extends FieldMapper {\n+\n+    public static final String CONTENT_TYPE = \"aggregate_metric_double\";\n+    public static final String SUBFIELD_SEPARATOR = \"._\";\n+\n+    /**\n+     * Return the name of a subfield of an aggregate metric field\n+     *\n+     * @param fieldName the name of the aggregate metric field\n+     * @param metric    the metric type the subfield corresponds to\n+     * @return the name of the subfield\n+     */\n+    public static String subfieldName(String fieldName, Metric metric) {\n+        return fieldName + AggregateDoubleMetricFieldMapper.SUBFIELD_SEPARATOR + metric.name();\n+    }\n+\n+    /**\n+     * Mapping field names\n+     */\n+    public static class Names {\n+        public static final ParseField IGNORE_MALFORMED = new ParseField(\"ignore_malformed\");\n+        public static final ParseField METRICS = new ParseField(\"metrics\");\n+        public static final ParseField DEFAULT_METRIC = new ParseField(\"default_metric\");\n+    }\n+\n+    /**\n+     * Enum of aggregate metrics supported by this field mapper\n+     */\n+    public enum Metric {\n+        min,\n+        max,\n+        sum,\n+        value_count;\n+    }\n+\n+    public static class Defaults {\n+        public static final Explicit<Boolean> IGNORE_MALFORMED = new Explicit<>(false, false);\n+        public static final Explicit<Set<Metric>> METRICS = new Explicit<>(Collections.emptySet(), false);\n+        public static final Explicit<Metric> DEFAULT_METRIC = new Explicit<>(Metric.max, false);\n+        public static final AggregateDoubleMetricFieldType FIELD_TYPE = new AggregateDoubleMetricFieldType();\n+    }\n+\n+    public static class Builder extends FieldMapper.Builder<AggregateDoubleMetricFieldMapper.Builder, AggregateDoubleMetricFieldMapper> {\n+\n+        private Boolean ignoreMalformed;\n+\n+        /**\n+         * The aggregated metrics supported by the field type\n+         */\n+        private EnumSet<Metric> metrics;\n+\n+        /**\n+         * Set the default metric so that query operations are delegated to it.\n+         */\n+        private Metric defaultMetric;\n+\n+        public Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        public AggregateDoubleMetricFieldMapper.Builder ignoreMalformed(boolean ignoreMalformed) {\n+            this.ignoreMalformed = ignoreMalformed;\n+            return builder;\n+        }\n+\n+        protected Explicit<Boolean> ignoreMalformed(BuilderContext context) {\n+            if (ignoreMalformed != null) {\n+                return new Explicit<>(ignoreMalformed, true);\n+            }\n+            if (context.indexSettings() != null) {\n+                return new Explicit<>(IGNORE_MALFORMED_SETTING.get(context.indexSettings()), false);\n+            }\n+            return AggregateDoubleMetricFieldMapper.Defaults.IGNORE_MALFORMED;\n+        }\n+\n+        public AggregateDoubleMetricFieldMapper.Builder defaultMetric(Metric defaultMetric) {\n+            this.defaultMetric = defaultMetric;\n+            return builder;\n+        }\n+\n+        protected Explicit<Metric> defaultMetric(BuilderContext context) {\n+            if (defaultMetric != null) {\n+                if (metrics != null && metrics.contains(defaultMetric) == false) {\n+                    // The default_metric is not defined in the \"metrics\" field\n+                    throw new IllegalArgumentException(\"Metric [\" + defaultMetric + \"] is not defined in the metrics field.\");\n+                }\n+                return new Explicit<>(defaultMetric, true);\n+            }\n+\n+            // If a single metric is contained, this should be the default\n+            if (metrics != null && metrics.size() == 1) {\n+                return new Explicit<>(metrics.iterator().next(), false);\n+            }\n+\n+            if (metrics.contains(Defaults.DEFAULT_METRIC.value())) {\n+                return Defaults.DEFAULT_METRIC;\n+            }\n+            throw new IllegalArgumentException(\n+                \"Property [\" + Names.DEFAULT_METRIC.getPreferredName() + \"] must be set for field [\" + name() + \"].\"\n+            );\n+        }\n+\n+        public AggregateDoubleMetricFieldMapper.Builder metrics(EnumSet<Metric> metrics) {\n+            this.metrics = metrics;\n+            return builder;\n+        }\n+\n+        protected Explicit<Set<Metric>> metrics(BuilderContext context) {\n+            if (metrics != null) {\n+                return new Explicit<>(metrics, true);\n+            }\n+            return Defaults.METRICS;\n+        }\n+\n+        @Override\n+        public AggregateDoubleMetricFieldMapper build(BuilderContext context) {\n+            setupFieldType(context);\n+\n+            if (metrics == null || metrics.isEmpty()) {\n+                throw new IllegalArgumentException(\n+                    \"Property [\" + Names.METRICS.getPreferredName() + \"] must be set for field [\" + name() + \"].\"\n+                );\n+            }\n+\n+            EnumMap<Metric, NumberFieldMapper> metricMappers = new EnumMap<>(Metric.class);\n+            // Instantiate one NumberFieldMapper instance for each metric\n+            for (Metric m : this.metrics) {\n+                String fieldName = subfieldName(context.path().pathAsText(name), m);\n+                NumberFieldMapper.Builder builder;\n+\n+                if (m == Metric.value_count) {\n+                    // value_count metric can only be an integer and not a double\n+                    builder = new NumberFieldMapper.Builder(fieldName, NumberFieldMapper.NumberType.INTEGER);\n+                    builder.coerce(false);\n+                } else {\n+                    builder = new NumberFieldMapper.Builder(fieldName, NumberFieldMapper.NumberType.DOUBLE);\n+                }\n+                NumberFieldMapper fieldMapper = builder.build(context);\n+                metricMappers.put(m, fieldMapper);\n+            }\n+\n+            EnumMap<Metric, NumberFieldMapper.NumberFieldType> metricFields = metricMappers.entrySet()\n+                .stream()\n+                .collect(\n+                    Collectors.toMap(\n+                        Map.Entry::getKey,\n+                        e -> e.getValue().fieldType(),\n+                        (l, r) -> { throw new IllegalArgumentException(\"Duplicate keys \" + l + \"and \" + r + \".\"); },\n+                        () -> new EnumMap<>(Metric.class)\n+                    )\n+                );\n+\n+            AggregateDoubleMetricFieldType metricFieldType = (AggregateDoubleMetricFieldType) fieldType;\n+            metricFieldType.setMetricFields(metricFields);\n+\n+            Explicit<Metric> defaultMetric = defaultMetric(context);\n+            metricFieldType.setDefaultMetric(defaultMetric.value());\n+\n+            return new AggregateDoubleMetricFieldMapper(\n+                name,\n+                metricFieldType,\n+                defaultFieldType,\n+                context.indexSettings(),\n+                multiFieldsBuilder.build(this, context),\n+                ignoreMalformed(context),\n+                metrics(context),\n+                defaultMetric,\n+                copyTo,\n+                metricMappers\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        @Override\n+        public Mapper.Builder<Builder, AggregateDoubleMetricFieldMapper> parse(\n+            String name,\n+            Map<String, Object> node,\n+            ParserContext parserContext\n+        ) throws MapperParsingException {\n+            AggregateDoubleMetricFieldMapper.Builder builder = new AggregateDoubleMetricFieldMapper.Builder(name);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(Names.METRICS.getPreferredName())) {\n+                    String metricsStr[] = XContentMapValues.nodeStringArrayValue(propNode);\n+                    // Make sure that metrics are supported\n+                    EnumSet<Metric> parsedMetrics = EnumSet.noneOf(Metric.class);\n+                    for (int i = 0; i < metricsStr.length; i++) {\n+                        try {\n+                            Metric m = Metric.valueOf(metricsStr[i]);\n+                            parsedMetrics.add(m);\n+                        } catch (IllegalArgumentException e) {\n+                            throw new IllegalArgumentException(\"Metric [\" + metricsStr[i] + \"] is not supported.\", e);\n+                        }\n+                    }\n+                    builder.metrics(parsedMetrics);\n+                    iterator.remove();\n+                } else if (propName.equals(Names.DEFAULT_METRIC.getPreferredName())) {\n+                    String defaultMetric = XContentMapValues.nodeStringValue(\n+                        propNode,\n+                        name + \".\" + Names.DEFAULT_METRIC.getPreferredName()\n+                    );\n+                    try {\n+                        Metric m = Metric.valueOf(defaultMetric);\n+                        builder.defaultMetric(m);\n+                        iterator.remove();\n+                    } catch (IllegalArgumentException e) {\n+                        throw new IllegalArgumentException(\"Metric [\" + defaultMetric + \"] is not supported.\", e);\n+                    }\n+                } else if (propName.equals(Names.IGNORE_MALFORMED.getPreferredName())) {\n+                    builder.ignoreMalformed(\n+                        XContentMapValues.nodeBooleanValue(propNode, name + \".\" + Names.IGNORE_MALFORMED.getPreferredName())\n+                    );\n+                    iterator.remove();\n+                } else if (TypeParsers.parseMultiField(builder, name, parserContext, propName, propNode)) {\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class AggregateDoubleMetricFieldType extends SimpleMappedFieldType {\n+\n+        private EnumMap<Metric, NumberFieldMapper.NumberFieldType> metricFields;\n+\n+        private Metric defaultMetric;\n+\n+        public AggregateDoubleMetricFieldType() {}\n+\n+        AggregateDoubleMetricFieldType(AggregateDoubleMetricFieldType other) {\n+            super(other);\n+            this.metricFields = other.metricFields;\n+            this.defaultMetric = other.defaultMetric;\n+        }\n+\n+        @Override\n+        public MappedFieldType clone() {\n+            return new AggregateDoubleMetricFieldType(this);\n+        }\n+\n+        /**\n+         * Return a delegate field type for a given metric sub-field\n+         * @return a field type\n+         */\n+        private NumberFieldMapper.NumberFieldType delegateFieldType(Metric metric) {\n+            return metricFields.get(metric);\n+        }\n+\n+        /**\n+         * Return a delegate field type for the default metric sub-field\n+         * @return a field type\n+         */\n+        private NumberFieldMapper.NumberFieldType delegateFieldType() {\n+            return delegateFieldType(defaultMetric);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        private void setMetricFields(EnumMap<Metric, NumberFieldMapper.NumberFieldType> metricFields) {\n+            checkIfFrozen();\n+            this.metricFields = metricFields;\n+        }\n+\n+        public void addMetricField(Metric m, NumberFieldMapper.NumberFieldType subfield) {\n+            checkIfFrozen();\n+            if (metricFields == null) {\n+                metricFields = new EnumMap<>(AggregateDoubleMetricFieldMapper.Metric.class);\n+            }\n+\n+            if (name() == null) {\n+                throw new IllegalArgumentException(\"Field of type [\" + typeName() + \"] must have a name before adding a subfield\");\n+            }\n+            String subfieldName = subfieldName(name(), m);\n+            subfield.setName(subfieldName);\n+            metricFields.put(m, subfield);\n+        }\n+\n+        public void setDefaultMetric(Metric defaultMetric) {\n+            checkIfFrozen();\n+            this.defaultMetric = defaultMetric;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return delegateFieldType().existsQuery(context);\n+        }\n+\n+        @Override\n+        public Query termQuery(Object value, QueryShardContext context) {\n+            return delegateFieldType().termQuery(value, context);\n+        }\n+\n+        @Override\n+        public Query termsQuery(List<?> values, QueryShardContext context) {\n+            return delegateFieldType().termsQuery(values, context);\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            return delegateFieldType().rangeQuery(lowerTerm, upperTerm, includeLower, includeUpper, context);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            return delegateFieldType().valueForDisplay(value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(String format, ZoneId timeZone) {\n+            return delegateFieldType().docValueFormat(format, timeZone);\n+        }\n+\n+        @Override\n+        public Relation isFieldWithinQuery(\n+            IndexReader reader,\n+            Object from,\n+            Object to,\n+            boolean includeLower,\n+            boolean includeUpper,\n+            ZoneId timeZone,\n+            DateMathParser dateMathParser,\n+            QueryRewriteContext context\n+        ) throws IOException {\n+            return delegateFieldType().isFieldWithinQuery(reader, from, to, includeLower, includeUpper, timeZone, dateMathParser, context);\n+        }\n+\n+        @Override\n+        public ValuesSourceType getValuesSourceType() {\n+            return AggregateMetricsValuesSourceType.AGGREGATE_METRIC;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            return new IndexFieldData.Builder() {\n+                @Override\n+                public IndexFieldData<?> build(\n+                    IndexSettings indexSettings,\n+                    MappedFieldType fieldType,\n+                    IndexFieldDataCache cache,\n+                    CircuitBreakerService breakerService,\n+                    MapperService mapperService\n+                ) {\n+                    return new IndexAggregateDoubleMetricFieldData(indexSettings.getIndex(), fieldType.name()) {\n+                        @Override\n+                        public LeafAggregateDoubleMetricFieldData load(LeafReaderContext context) {\n+                            return new LeafAggregateDoubleMetricFieldData() {\n+                                @Override\n+                                public SortedNumericDoubleValues getAggregateMetricValues(final Metric metric) throws IOException {\n+                                    try {\n+                                        final NumericDocValues values = DocValues.getNumeric(\n+                                            context.reader(),\n+                                            subfieldName(fieldName, metric)\n+                                        );\n+\n+                                        return new SortedNumericDoubleValues() {\n+                                            @Override\n+                                            public int docValueCount() {\n+                                                return 1;\n+                                            }\n+\n+                                            @Override\n+                                            public boolean advanceExact(int doc) throws IOException {\n+                                                return values.advanceExact(doc);\n+                                            }\n+\n+                                            @Override\n+                                            public double nextValue() throws IOException {\n+                                                return Double.longBitsToDouble(values.longValue());\n+                                            }\n+                                        };\n+                                    } catch (IOException e) {\n+                                        throw new IOException(\"Cannot load doc values\", e);\n+                                    }\n+                                }\n+\n+                                @Override\n+                                public ScriptDocValues<?> getScriptValues() {\n+                                    throw new UnsupportedOperationException(\n+                                        \"The [\" + CONTENT_TYPE + \"] field does not \" + \"support scripts\"\n+                                    );\n+                                }\n+\n+                                @Override\n+                                public SortedBinaryDocValues getBytesValues() {\n+                                    throw new UnsupportedOperationException(\n+                                        \"String representation of doc values \" + \"for [\" + CONTENT_TYPE + \"] fields is not supported\"\n+                                    );\n+                                }\n+\n+                                @Override\n+                                public long ramBytesUsed() {\n+                                    return 0; // Unknown\n+                                }\n+\n+                                @Override\n+                                public void close() {}\n+                            };\n+                        }\n+\n+                        @Override\n+                        public LeafAggregateDoubleMetricFieldData loadDirect(LeafReaderContext context) {\n+                            return load(context);\n+                        }\n+\n+                        @Override\n+                        public SortField sortField(\n+                            Object missingValue,\n+                            MultiValueMode sortMode,\n+                            XFieldComparatorSource.Nested nested,\n+                            boolean reverse\n+                        ) {\n+                            throw new UnsupportedOperationException(\"can't sort on the [\" + CONTENT_TYPE + \"] field\");", "originalCommit": "21da92a7fab32b4bc820eca6f000118ba4ff06ca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjMyNzg5Mg==", "url": "https://github.com/elastic/elasticsearch/pull/53986#discussion_r412327892", "bodyText": "Fixed at 022dac2", "author": "csoulios", "createdAt": "2020-04-21T16:57:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDEzMzYxNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDEzNDE3Ng==", "url": "https://github.com/elastic/elasticsearch/pull/53986#discussion_r400134176", "bodyText": "nit: can you indent the alternatives ?", "author": "jimczi", "createdAt": "2020-03-30T11:57:57Z", "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/mapper/AggregateDoubleMetricFieldMapper.java", "diffHunk": "@@ -0,0 +1,689 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.aggregatemetric.mapper;\n+\n+import org.apache.lucene.index.DocValues;\n+import org.apache.lucene.index.IndexReader;\n+import org.apache.lucene.index.IndexableField;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.NumericDocValues;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.SortField;\n+import org.elasticsearch.common.Explicit;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.time.DateMathParser;\n+import org.elasticsearch.common.util.BigArrays;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.XContentSubParser;\n+import org.elasticsearch.common.xcontent.support.XContentMapValues;\n+import org.elasticsearch.index.IndexSettings;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.IndexFieldDataCache;\n+import org.elasticsearch.index.fielddata.ScriptDocValues;\n+import org.elasticsearch.index.fielddata.SortedBinaryDocValues;\n+import org.elasticsearch.index.fielddata.SortedNumericDoubleValues;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SimpleMappedFieldType;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryRewriteContext;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.indices.breaker.CircuitBreakerService;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.MultiValueMode;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceType;\n+import org.elasticsearch.search.sort.BucketedSort;\n+import org.elasticsearch.search.sort.SortOrder;\n+import org.elasticsearch.xpack.aggregatemetric.aggregations.support.AggregateMetricsValuesSourceType;\n+import org.elasticsearch.xpack.aggregatemetric.fielddata.IndexAggregateDoubleMetricFieldData;\n+import org.elasticsearch.xpack.aggregatemetric.fielddata.LeafAggregateDoubleMetricFieldData;\n+\n+import java.io.IOException;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.EnumMap;\n+import java.util.EnumSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import static org.elasticsearch.common.xcontent.XContentParserUtils.ensureExpectedToken;\n+\n+/** A {@link FieldMapper} for a field containing aggregate metrics such as min/max/value_count etc. */\n+public class AggregateDoubleMetricFieldMapper extends FieldMapper {\n+\n+    public static final String CONTENT_TYPE = \"aggregate_metric_double\";\n+    public static final String SUBFIELD_SEPARATOR = \"._\";\n+\n+    /**\n+     * Return the name of a subfield of an aggregate metric field\n+     *\n+     * @param fieldName the name of the aggregate metric field\n+     * @param metric    the metric type the subfield corresponds to\n+     * @return the name of the subfield\n+     */\n+    public static String subfieldName(String fieldName, Metric metric) {\n+        return fieldName + AggregateDoubleMetricFieldMapper.SUBFIELD_SEPARATOR + metric.name();\n+    }\n+\n+    /**\n+     * Mapping field names\n+     */\n+    public static class Names {\n+        public static final ParseField IGNORE_MALFORMED = new ParseField(\"ignore_malformed\");\n+        public static final ParseField METRICS = new ParseField(\"metrics\");\n+        public static final ParseField DEFAULT_METRIC = new ParseField(\"default_metric\");\n+    }\n+\n+    /**\n+     * Enum of aggregate metrics supported by this field mapper\n+     */\n+    public enum Metric {\n+        min,\n+        max,\n+        sum,\n+        value_count;\n+    }\n+\n+    public static class Defaults {\n+        public static final Explicit<Boolean> IGNORE_MALFORMED = new Explicit<>(false, false);\n+        public static final Explicit<Set<Metric>> METRICS = new Explicit<>(Collections.emptySet(), false);\n+        public static final Explicit<Metric> DEFAULT_METRIC = new Explicit<>(Metric.max, false);\n+        public static final AggregateDoubleMetricFieldType FIELD_TYPE = new AggregateDoubleMetricFieldType();\n+    }\n+\n+    public static class Builder extends FieldMapper.Builder<AggregateDoubleMetricFieldMapper.Builder, AggregateDoubleMetricFieldMapper> {\n+\n+        private Boolean ignoreMalformed;\n+\n+        /**\n+         * The aggregated metrics supported by the field type\n+         */\n+        private EnumSet<Metric> metrics;\n+\n+        /**\n+         * Set the default metric so that query operations are delegated to it.\n+         */\n+        private Metric defaultMetric;\n+\n+        public Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        public AggregateDoubleMetricFieldMapper.Builder ignoreMalformed(boolean ignoreMalformed) {\n+            this.ignoreMalformed = ignoreMalformed;\n+            return builder;\n+        }\n+\n+        protected Explicit<Boolean> ignoreMalformed(BuilderContext context) {\n+            if (ignoreMalformed != null) {\n+                return new Explicit<>(ignoreMalformed, true);\n+            }\n+            if (context.indexSettings() != null) {\n+                return new Explicit<>(IGNORE_MALFORMED_SETTING.get(context.indexSettings()), false);\n+            }\n+            return AggregateDoubleMetricFieldMapper.Defaults.IGNORE_MALFORMED;\n+        }\n+\n+        public AggregateDoubleMetricFieldMapper.Builder defaultMetric(Metric defaultMetric) {\n+            this.defaultMetric = defaultMetric;\n+            return builder;\n+        }\n+\n+        protected Explicit<Metric> defaultMetric(BuilderContext context) {\n+            if (defaultMetric != null) {\n+                if (metrics != null && metrics.contains(defaultMetric) == false) {\n+                    // The default_metric is not defined in the \"metrics\" field\n+                    throw new IllegalArgumentException(\"Metric [\" + defaultMetric + \"] is not defined in the metrics field.\");\n+                }\n+                return new Explicit<>(defaultMetric, true);\n+            }\n+\n+            // If a single metric is contained, this should be the default\n+            if (metrics != null && metrics.size() == 1) {\n+                return new Explicit<>(metrics.iterator().next(), false);\n+            }\n+\n+            if (metrics.contains(Defaults.DEFAULT_METRIC.value())) {\n+                return Defaults.DEFAULT_METRIC;\n+            }\n+            throw new IllegalArgumentException(\n+                \"Property [\" + Names.DEFAULT_METRIC.getPreferredName() + \"] must be set for field [\" + name() + \"].\"\n+            );\n+        }\n+\n+        public AggregateDoubleMetricFieldMapper.Builder metrics(EnumSet<Metric> metrics) {\n+            this.metrics = metrics;\n+            return builder;\n+        }\n+\n+        protected Explicit<Set<Metric>> metrics(BuilderContext context) {\n+            if (metrics != null) {\n+                return new Explicit<>(metrics, true);\n+            }\n+            return Defaults.METRICS;\n+        }\n+\n+        @Override\n+        public AggregateDoubleMetricFieldMapper build(BuilderContext context) {\n+            setupFieldType(context);\n+\n+            if (metrics == null || metrics.isEmpty()) {\n+                throw new IllegalArgumentException(\n+                    \"Property [\" + Names.METRICS.getPreferredName() + \"] must be set for field [\" + name() + \"].\"\n+                );\n+            }\n+\n+            EnumMap<Metric, NumberFieldMapper> metricMappers = new EnumMap<>(Metric.class);\n+            // Instantiate one NumberFieldMapper instance for each metric\n+            for (Metric m : this.metrics) {\n+                String fieldName = subfieldName(context.path().pathAsText(name), m);\n+                NumberFieldMapper.Builder builder;\n+\n+                if (m == Metric.value_count) {\n+                    // value_count metric can only be an integer and not a double\n+                    builder = new NumberFieldMapper.Builder(fieldName, NumberFieldMapper.NumberType.INTEGER);\n+                    builder.coerce(false);\n+                } else {\n+                    builder = new NumberFieldMapper.Builder(fieldName, NumberFieldMapper.NumberType.DOUBLE);\n+                }\n+                NumberFieldMapper fieldMapper = builder.build(context);\n+                metricMappers.put(m, fieldMapper);\n+            }\n+\n+            EnumMap<Metric, NumberFieldMapper.NumberFieldType> metricFields = metricMappers.entrySet()\n+                .stream()\n+                .collect(\n+                    Collectors.toMap(\n+                        Map.Entry::getKey,\n+                        e -> e.getValue().fieldType(),\n+                        (l, r) -> { throw new IllegalArgumentException(\"Duplicate keys \" + l + \"and \" + r + \".\"); },\n+                        () -> new EnumMap<>(Metric.class)\n+                    )\n+                );\n+\n+            AggregateDoubleMetricFieldType metricFieldType = (AggregateDoubleMetricFieldType) fieldType;\n+            metricFieldType.setMetricFields(metricFields);\n+\n+            Explicit<Metric> defaultMetric = defaultMetric(context);\n+            metricFieldType.setDefaultMetric(defaultMetric.value());\n+\n+            return new AggregateDoubleMetricFieldMapper(\n+                name,\n+                metricFieldType,\n+                defaultFieldType,\n+                context.indexSettings(),\n+                multiFieldsBuilder.build(this, context),\n+                ignoreMalformed(context),\n+                metrics(context),\n+                defaultMetric,\n+                copyTo,\n+                metricMappers\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        @Override\n+        public Mapper.Builder<Builder, AggregateDoubleMetricFieldMapper> parse(\n+            String name,\n+            Map<String, Object> node,\n+            ParserContext parserContext\n+        ) throws MapperParsingException {\n+            AggregateDoubleMetricFieldMapper.Builder builder = new AggregateDoubleMetricFieldMapper.Builder(name);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(Names.METRICS.getPreferredName())) {\n+                    String metricsStr[] = XContentMapValues.nodeStringArrayValue(propNode);\n+                    // Make sure that metrics are supported\n+                    EnumSet<Metric> parsedMetrics = EnumSet.noneOf(Metric.class);\n+                    for (int i = 0; i < metricsStr.length; i++) {\n+                        try {\n+                            Metric m = Metric.valueOf(metricsStr[i]);\n+                            parsedMetrics.add(m);\n+                        } catch (IllegalArgumentException e) {\n+                            throw new IllegalArgumentException(\"Metric [\" + metricsStr[i] + \"] is not supported.\", e);\n+                        }\n+                    }\n+                    builder.metrics(parsedMetrics);\n+                    iterator.remove();\n+                } else if (propName.equals(Names.DEFAULT_METRIC.getPreferredName())) {\n+                    String defaultMetric = XContentMapValues.nodeStringValue(\n+                        propNode,\n+                        name + \".\" + Names.DEFAULT_METRIC.getPreferredName()\n+                    );\n+                    try {\n+                        Metric m = Metric.valueOf(defaultMetric);\n+                        builder.defaultMetric(m);\n+                        iterator.remove();\n+                    } catch (IllegalArgumentException e) {\n+                        throw new IllegalArgumentException(\"Metric [\" + defaultMetric + \"] is not supported.\", e);\n+                    }\n+                } else if (propName.equals(Names.IGNORE_MALFORMED.getPreferredName())) {\n+                    builder.ignoreMalformed(\n+                        XContentMapValues.nodeBooleanValue(propNode, name + \".\" + Names.IGNORE_MALFORMED.getPreferredName())\n+                    );\n+                    iterator.remove();\n+                } else if (TypeParsers.parseMultiField(builder, name, parserContext, propName, propNode)) {\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class AggregateDoubleMetricFieldType extends SimpleMappedFieldType {\n+\n+        private EnumMap<Metric, NumberFieldMapper.NumberFieldType> metricFields;\n+\n+        private Metric defaultMetric;\n+\n+        public AggregateDoubleMetricFieldType() {}\n+\n+        AggregateDoubleMetricFieldType(AggregateDoubleMetricFieldType other) {\n+            super(other);\n+            this.metricFields = other.metricFields;\n+            this.defaultMetric = other.defaultMetric;\n+        }\n+\n+        @Override\n+        public MappedFieldType clone() {\n+            return new AggregateDoubleMetricFieldType(this);\n+        }\n+\n+        /**\n+         * Return a delegate field type for a given metric sub-field\n+         * @return a field type\n+         */\n+        private NumberFieldMapper.NumberFieldType delegateFieldType(Metric metric) {\n+            return metricFields.get(metric);\n+        }\n+\n+        /**\n+         * Return a delegate field type for the default metric sub-field\n+         * @return a field type\n+         */\n+        private NumberFieldMapper.NumberFieldType delegateFieldType() {\n+            return delegateFieldType(defaultMetric);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        private void setMetricFields(EnumMap<Metric, NumberFieldMapper.NumberFieldType> metricFields) {\n+            checkIfFrozen();\n+            this.metricFields = metricFields;\n+        }\n+\n+        public void addMetricField(Metric m, NumberFieldMapper.NumberFieldType subfield) {\n+            checkIfFrozen();\n+            if (metricFields == null) {\n+                metricFields = new EnumMap<>(AggregateDoubleMetricFieldMapper.Metric.class);\n+            }\n+\n+            if (name() == null) {\n+                throw new IllegalArgumentException(\"Field of type [\" + typeName() + \"] must have a name before adding a subfield\");\n+            }\n+            String subfieldName = subfieldName(name(), m);\n+            subfield.setName(subfieldName);\n+            metricFields.put(m, subfield);\n+        }\n+\n+        public void setDefaultMetric(Metric defaultMetric) {\n+            checkIfFrozen();\n+            this.defaultMetric = defaultMetric;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return delegateFieldType().existsQuery(context);\n+        }\n+\n+        @Override\n+        public Query termQuery(Object value, QueryShardContext context) {\n+            return delegateFieldType().termQuery(value, context);\n+        }\n+\n+        @Override\n+        public Query termsQuery(List<?> values, QueryShardContext context) {\n+            return delegateFieldType().termsQuery(values, context);\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            return delegateFieldType().rangeQuery(lowerTerm, upperTerm, includeLower, includeUpper, context);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            return delegateFieldType().valueForDisplay(value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(String format, ZoneId timeZone) {\n+            return delegateFieldType().docValueFormat(format, timeZone);\n+        }\n+\n+        @Override\n+        public Relation isFieldWithinQuery(\n+            IndexReader reader,\n+            Object from,\n+            Object to,\n+            boolean includeLower,\n+            boolean includeUpper,\n+            ZoneId timeZone,\n+            DateMathParser dateMathParser,\n+            QueryRewriteContext context\n+        ) throws IOException {\n+            return delegateFieldType().isFieldWithinQuery(reader, from, to, includeLower, includeUpper, timeZone, dateMathParser, context);\n+        }\n+\n+        @Override\n+        public ValuesSourceType getValuesSourceType() {\n+            return AggregateMetricsValuesSourceType.AGGREGATE_METRIC;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            return new IndexFieldData.Builder() {\n+                @Override\n+                public IndexFieldData<?> build(\n+                    IndexSettings indexSettings,\n+                    MappedFieldType fieldType,\n+                    IndexFieldDataCache cache,\n+                    CircuitBreakerService breakerService,\n+                    MapperService mapperService\n+                ) {\n+                    return new IndexAggregateDoubleMetricFieldData(indexSettings.getIndex(), fieldType.name()) {\n+                        @Override\n+                        public LeafAggregateDoubleMetricFieldData load(LeafReaderContext context) {\n+                            return new LeafAggregateDoubleMetricFieldData() {\n+                                @Override\n+                                public SortedNumericDoubleValues getAggregateMetricValues(final Metric metric) throws IOException {\n+                                    try {\n+                                        final NumericDocValues values = DocValues.getNumeric(\n+                                            context.reader(),\n+                                            subfieldName(fieldName, metric)\n+                                        );\n+\n+                                        return new SortedNumericDoubleValues() {\n+                                            @Override\n+                                            public int docValueCount() {\n+                                                return 1;\n+                                            }\n+\n+                                            @Override\n+                                            public boolean advanceExact(int doc) throws IOException {\n+                                                return values.advanceExact(doc);\n+                                            }\n+\n+                                            @Override\n+                                            public double nextValue() throws IOException {\n+                                                return Double.longBitsToDouble(values.longValue());\n+                                            }\n+                                        };\n+                                    } catch (IOException e) {\n+                                        throw new IOException(\"Cannot load doc values\", e);\n+                                    }\n+                                }\n+\n+                                @Override\n+                                public ScriptDocValues<?> getScriptValues() {\n+                                    throw new UnsupportedOperationException(\n+                                        \"The [\" + CONTENT_TYPE + \"] field does not \" + \"support scripts\"\n+                                    );\n+                                }\n+\n+                                @Override\n+                                public SortedBinaryDocValues getBytesValues() {\n+                                    throw new UnsupportedOperationException(\n+                                        \"String representation of doc values \" + \"for [\" + CONTENT_TYPE + \"] fields is not supported\"\n+                                    );\n+                                }\n+\n+                                @Override\n+                                public long ramBytesUsed() {\n+                                    return 0; // Unknown\n+                                }\n+\n+                                @Override\n+                                public void close() {}\n+                            };\n+                        }\n+\n+                        @Override\n+                        public LeafAggregateDoubleMetricFieldData loadDirect(LeafReaderContext context) {\n+                            return load(context);\n+                        }\n+\n+                        @Override\n+                        public SortField sortField(\n+                            Object missingValue,\n+                            MultiValueMode sortMode,\n+                            XFieldComparatorSource.Nested nested,\n+                            boolean reverse\n+                        ) {\n+                            throw new UnsupportedOperationException(\"can't sort on the [\" + CONTENT_TYPE + \"] field\");\n+                        }\n+\n+                        @Override\n+                        public BucketedSort newBucketedSort(\n+                            BigArrays bigArrays,\n+                            Object missingValue,\n+                            MultiValueMode sortMode,\n+                            XFieldComparatorSource.Nested nested,\n+                            SortOrder sortOrder,\n+                            DocValueFormat format,\n+                            int bucketSize,\n+                            BucketedSort.ExtraData extra\n+                        ) {\n+                            throw new IllegalArgumentException(\"can't sort on the [\" + CONTENT_TYPE + \"] field\");\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+    }\n+\n+    private final EnumMap<Metric, NumberFieldMapper> metricFieldMappers;\n+\n+    private Explicit<Boolean> ignoreMalformed;\n+\n+    /** A set of metrics supported */\n+    private Explicit<Set<Metric>> metrics;\n+\n+    /** The default metric to be when querying this field type */\n+    protected Explicit<Metric> defaultMetric;\n+\n+    private AggregateDoubleMetricFieldMapper(\n+        String simpleName,\n+        MappedFieldType fieldType,\n+        MappedFieldType defaultFieldType,\n+        Settings indexSettings,\n+        MultiFields multiFields,\n+        Explicit<Boolean> ignoreMalformed,\n+        Explicit<Set<Metric>> metrics,\n+        Explicit<Metric> defaultMetric,\n+        CopyTo copyTo,\n+        EnumMap<Metric, NumberFieldMapper> metricFieldMappers\n+    ) {\n+        super(simpleName, fieldType, defaultFieldType, indexSettings, multiFields, copyTo);\n+        this.ignoreMalformed = ignoreMalformed;\n+        this.metrics = metrics;\n+        this.defaultMetric = defaultMetric;\n+        this.metricFieldMappers = metricFieldMappers;\n+    }\n+\n+    @Override\n+    public AggregateDoubleMetricFieldType fieldType() {\n+        return (AggregateDoubleMetricFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return fieldType.typeName();\n+    }\n+\n+    @Override\n+    protected AggregateDoubleMetricFieldMapper clone() {\n+        return (AggregateDoubleMetricFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    public Iterator<Mapper> iterator() {\n+        List<Mapper> mappers = new ArrayList<>(metricFieldMappers.values());\n+        return mappers.iterator();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context, List<IndexableField> fields) throws IOException {\n+        if (context.externalValueSet()) {\n+            throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] can't be used in multi-fields\");\n+        }\n+\n+        context.path().add(simpleName());\n+        XContentParser.Token token = null;\n+        XContentSubParser subParser = null;\n+\n+        try {\n+            token = context.parser().currentToken();\n+            if (token == XContentParser.Token.VALUE_NULL) {\n+                context.path().remove();\n+                return;\n+            }\n+\n+            ensureExpectedToken(XContentParser.Token.START_OBJECT, token, context.parser()::getTokenLocation);\n+            subParser = new XContentSubParser(context.parser());\n+            token = subParser.nextToken();\n+            while (token != XContentParser.Token.END_OBJECT) {\n+                // should be an object subfield with name a metric name\n+                ensureExpectedToken(XContentParser.Token.FIELD_NAME, token, subParser::getTokenLocation);\n+                String fieldName = subParser.currentName();\n+                Metric metric = Metric.valueOf(fieldName);\n+\n+                if (metrics.value().contains(metric) == false) {\n+                    throw new IllegalArgumentException(\n+                        \"Aggregate metric [\" + metric + \"] does not exist in the mapping of field [\" + fieldType.name() + \"]\"\n+                    );\n+                }\n+\n+                token = subParser.nextToken();\n+                // Make sure that the value is a number. Probably this will change when\n+                // new aggregate metric types are added (histogram, cardinality etc)\n+                ensureExpectedToken(XContentParser.Token.VALUE_NUMBER, token, subParser::getTokenLocation);\n+                NumberFieldMapper delegateFieldMapper = metricFieldMappers.get(metric);\n+\n+                if (context.doc().getField(delegateFieldMapper.fieldType().name()) != null) {\n+                    throw new IllegalArgumentException(\n+                        \"Field [\"\n+                            + name()\n+                            + \"] of type [\"\n+                            + typeName()\n+                            + \"] does not support indexing multiple values for the same field in the same document\"\n+                    );\n+                }\n+\n+                delegateFieldMapper.parse(context);\n+\n+                if (Metric.value_count == metric) {\n+                    Number n = context.doc().getField(delegateFieldMapper.fieldType().name()).numericValue();\n+                    if (n.intValue() < 0) {\n+                        throw new IllegalArgumentException(\n+                            \"Aggregate metric [\" + metric.name() + \"] of field [\" + fieldType.name() + \"] cannot be a negative number\"\n+                        );\n+                    }\n+                }\n+\n+                token = subParser.nextToken();\n+            }\n+\n+            for (Metric m : metrics.value()) {\n+                if (context.doc().getField(subfieldName(fieldType().name(), m)) == null) {\n+                    throw new IllegalArgumentException(\n+                        \"Aggregate metric field [\" + fieldType.name() + \"] must contain all metrics \" + metrics.value().toString()\n+                    );\n+                }\n+            }\n+        } catch (Exception e) {\n+            if (ignoreMalformed.value()) {\n+                if (subParser != null) {\n+                    // close the subParser so we advance to the end of the object\n+                    subParser.close();\n+                }\n+                context.addIgnoredField(fieldType().name());\n+            } else {\n+                // Rethrow exception as is. It is going to be caught and nested in a MapperParsingException\n+                // by its FieldMapper.MappedFieldType#parse()\n+                throw e;\n+            }\n+        }\n+        context.path().remove();\n+    }\n+\n+    @Override\n+    protected void doMerge(Mapper mergeWith) {\n+        super.doMerge(mergeWith);\n+        AggregateDoubleMetricFieldMapper other = (AggregateDoubleMetricFieldMapper) mergeWith;\n+        if (other.ignoreMalformed.explicit()) {\n+            this.ignoreMalformed = other.ignoreMalformed;\n+        }\n+\n+        if (other.metrics.explicit()) {\n+            if (this.metrics.value() != null\n+                && metrics.value().isEmpty() == false", "originalCommit": "21da92a7fab32b4bc820eca6f000118ba4ff06ca", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDEzNTQ0OQ==", "url": "https://github.com/elastic/elasticsearch/pull/53986#discussion_r400135449", "bodyText": "should also disallow removing a metric from an  existing mapping?", "author": "jimczi", "createdAt": "2020-03-30T12:00:21Z", "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/mapper/AggregateDoubleMetricFieldMapper.java", "diffHunk": "@@ -0,0 +1,689 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.aggregatemetric.mapper;\n+\n+import org.apache.lucene.index.DocValues;\n+import org.apache.lucene.index.IndexReader;\n+import org.apache.lucene.index.IndexableField;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.NumericDocValues;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.SortField;\n+import org.elasticsearch.common.Explicit;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.time.DateMathParser;\n+import org.elasticsearch.common.util.BigArrays;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.XContentSubParser;\n+import org.elasticsearch.common.xcontent.support.XContentMapValues;\n+import org.elasticsearch.index.IndexSettings;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.IndexFieldDataCache;\n+import org.elasticsearch.index.fielddata.ScriptDocValues;\n+import org.elasticsearch.index.fielddata.SortedBinaryDocValues;\n+import org.elasticsearch.index.fielddata.SortedNumericDoubleValues;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SimpleMappedFieldType;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryRewriteContext;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.indices.breaker.CircuitBreakerService;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.MultiValueMode;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceType;\n+import org.elasticsearch.search.sort.BucketedSort;\n+import org.elasticsearch.search.sort.SortOrder;\n+import org.elasticsearch.xpack.aggregatemetric.aggregations.support.AggregateMetricsValuesSourceType;\n+import org.elasticsearch.xpack.aggregatemetric.fielddata.IndexAggregateDoubleMetricFieldData;\n+import org.elasticsearch.xpack.aggregatemetric.fielddata.LeafAggregateDoubleMetricFieldData;\n+\n+import java.io.IOException;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.EnumMap;\n+import java.util.EnumSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import static org.elasticsearch.common.xcontent.XContentParserUtils.ensureExpectedToken;\n+\n+/** A {@link FieldMapper} for a field containing aggregate metrics such as min/max/value_count etc. */\n+public class AggregateDoubleMetricFieldMapper extends FieldMapper {\n+\n+    public static final String CONTENT_TYPE = \"aggregate_metric_double\";\n+    public static final String SUBFIELD_SEPARATOR = \"._\";\n+\n+    /**\n+     * Return the name of a subfield of an aggregate metric field\n+     *\n+     * @param fieldName the name of the aggregate metric field\n+     * @param metric    the metric type the subfield corresponds to\n+     * @return the name of the subfield\n+     */\n+    public static String subfieldName(String fieldName, Metric metric) {\n+        return fieldName + AggregateDoubleMetricFieldMapper.SUBFIELD_SEPARATOR + metric.name();\n+    }\n+\n+    /**\n+     * Mapping field names\n+     */\n+    public static class Names {\n+        public static final ParseField IGNORE_MALFORMED = new ParseField(\"ignore_malformed\");\n+        public static final ParseField METRICS = new ParseField(\"metrics\");\n+        public static final ParseField DEFAULT_METRIC = new ParseField(\"default_metric\");\n+    }\n+\n+    /**\n+     * Enum of aggregate metrics supported by this field mapper\n+     */\n+    public enum Metric {\n+        min,\n+        max,\n+        sum,\n+        value_count;\n+    }\n+\n+    public static class Defaults {\n+        public static final Explicit<Boolean> IGNORE_MALFORMED = new Explicit<>(false, false);\n+        public static final Explicit<Set<Metric>> METRICS = new Explicit<>(Collections.emptySet(), false);\n+        public static final Explicit<Metric> DEFAULT_METRIC = new Explicit<>(Metric.max, false);\n+        public static final AggregateDoubleMetricFieldType FIELD_TYPE = new AggregateDoubleMetricFieldType();\n+    }\n+\n+    public static class Builder extends FieldMapper.Builder<AggregateDoubleMetricFieldMapper.Builder, AggregateDoubleMetricFieldMapper> {\n+\n+        private Boolean ignoreMalformed;\n+\n+        /**\n+         * The aggregated metrics supported by the field type\n+         */\n+        private EnumSet<Metric> metrics;\n+\n+        /**\n+         * Set the default metric so that query operations are delegated to it.\n+         */\n+        private Metric defaultMetric;\n+\n+        public Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        public AggregateDoubleMetricFieldMapper.Builder ignoreMalformed(boolean ignoreMalformed) {\n+            this.ignoreMalformed = ignoreMalformed;\n+            return builder;\n+        }\n+\n+        protected Explicit<Boolean> ignoreMalformed(BuilderContext context) {\n+            if (ignoreMalformed != null) {\n+                return new Explicit<>(ignoreMalformed, true);\n+            }\n+            if (context.indexSettings() != null) {\n+                return new Explicit<>(IGNORE_MALFORMED_SETTING.get(context.indexSettings()), false);\n+            }\n+            return AggregateDoubleMetricFieldMapper.Defaults.IGNORE_MALFORMED;\n+        }\n+\n+        public AggregateDoubleMetricFieldMapper.Builder defaultMetric(Metric defaultMetric) {\n+            this.defaultMetric = defaultMetric;\n+            return builder;\n+        }\n+\n+        protected Explicit<Metric> defaultMetric(BuilderContext context) {\n+            if (defaultMetric != null) {\n+                if (metrics != null && metrics.contains(defaultMetric) == false) {\n+                    // The default_metric is not defined in the \"metrics\" field\n+                    throw new IllegalArgumentException(\"Metric [\" + defaultMetric + \"] is not defined in the metrics field.\");\n+                }\n+                return new Explicit<>(defaultMetric, true);\n+            }\n+\n+            // If a single metric is contained, this should be the default\n+            if (metrics != null && metrics.size() == 1) {\n+                return new Explicit<>(metrics.iterator().next(), false);\n+            }\n+\n+            if (metrics.contains(Defaults.DEFAULT_METRIC.value())) {\n+                return Defaults.DEFAULT_METRIC;\n+            }\n+            throw new IllegalArgumentException(\n+                \"Property [\" + Names.DEFAULT_METRIC.getPreferredName() + \"] must be set for field [\" + name() + \"].\"\n+            );\n+        }\n+\n+        public AggregateDoubleMetricFieldMapper.Builder metrics(EnumSet<Metric> metrics) {\n+            this.metrics = metrics;\n+            return builder;\n+        }\n+\n+        protected Explicit<Set<Metric>> metrics(BuilderContext context) {\n+            if (metrics != null) {\n+                return new Explicit<>(metrics, true);\n+            }\n+            return Defaults.METRICS;\n+        }\n+\n+        @Override\n+        public AggregateDoubleMetricFieldMapper build(BuilderContext context) {\n+            setupFieldType(context);\n+\n+            if (metrics == null || metrics.isEmpty()) {\n+                throw new IllegalArgumentException(\n+                    \"Property [\" + Names.METRICS.getPreferredName() + \"] must be set for field [\" + name() + \"].\"\n+                );\n+            }\n+\n+            EnumMap<Metric, NumberFieldMapper> metricMappers = new EnumMap<>(Metric.class);\n+            // Instantiate one NumberFieldMapper instance for each metric\n+            for (Metric m : this.metrics) {\n+                String fieldName = subfieldName(context.path().pathAsText(name), m);\n+                NumberFieldMapper.Builder builder;\n+\n+                if (m == Metric.value_count) {\n+                    // value_count metric can only be an integer and not a double\n+                    builder = new NumberFieldMapper.Builder(fieldName, NumberFieldMapper.NumberType.INTEGER);\n+                    builder.coerce(false);\n+                } else {\n+                    builder = new NumberFieldMapper.Builder(fieldName, NumberFieldMapper.NumberType.DOUBLE);\n+                }\n+                NumberFieldMapper fieldMapper = builder.build(context);\n+                metricMappers.put(m, fieldMapper);\n+            }\n+\n+            EnumMap<Metric, NumberFieldMapper.NumberFieldType> metricFields = metricMappers.entrySet()\n+                .stream()\n+                .collect(\n+                    Collectors.toMap(\n+                        Map.Entry::getKey,\n+                        e -> e.getValue().fieldType(),\n+                        (l, r) -> { throw new IllegalArgumentException(\"Duplicate keys \" + l + \"and \" + r + \".\"); },\n+                        () -> new EnumMap<>(Metric.class)\n+                    )\n+                );\n+\n+            AggregateDoubleMetricFieldType metricFieldType = (AggregateDoubleMetricFieldType) fieldType;\n+            metricFieldType.setMetricFields(metricFields);\n+\n+            Explicit<Metric> defaultMetric = defaultMetric(context);\n+            metricFieldType.setDefaultMetric(defaultMetric.value());\n+\n+            return new AggregateDoubleMetricFieldMapper(\n+                name,\n+                metricFieldType,\n+                defaultFieldType,\n+                context.indexSettings(),\n+                multiFieldsBuilder.build(this, context),\n+                ignoreMalformed(context),\n+                metrics(context),\n+                defaultMetric,\n+                copyTo,\n+                metricMappers\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        @Override\n+        public Mapper.Builder<Builder, AggregateDoubleMetricFieldMapper> parse(\n+            String name,\n+            Map<String, Object> node,\n+            ParserContext parserContext\n+        ) throws MapperParsingException {\n+            AggregateDoubleMetricFieldMapper.Builder builder = new AggregateDoubleMetricFieldMapper.Builder(name);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(Names.METRICS.getPreferredName())) {\n+                    String metricsStr[] = XContentMapValues.nodeStringArrayValue(propNode);\n+                    // Make sure that metrics are supported\n+                    EnumSet<Metric> parsedMetrics = EnumSet.noneOf(Metric.class);\n+                    for (int i = 0; i < metricsStr.length; i++) {\n+                        try {\n+                            Metric m = Metric.valueOf(metricsStr[i]);\n+                            parsedMetrics.add(m);\n+                        } catch (IllegalArgumentException e) {\n+                            throw new IllegalArgumentException(\"Metric [\" + metricsStr[i] + \"] is not supported.\", e);\n+                        }\n+                    }\n+                    builder.metrics(parsedMetrics);\n+                    iterator.remove();\n+                } else if (propName.equals(Names.DEFAULT_METRIC.getPreferredName())) {\n+                    String defaultMetric = XContentMapValues.nodeStringValue(\n+                        propNode,\n+                        name + \".\" + Names.DEFAULT_METRIC.getPreferredName()\n+                    );\n+                    try {\n+                        Metric m = Metric.valueOf(defaultMetric);\n+                        builder.defaultMetric(m);\n+                        iterator.remove();\n+                    } catch (IllegalArgumentException e) {\n+                        throw new IllegalArgumentException(\"Metric [\" + defaultMetric + \"] is not supported.\", e);\n+                    }\n+                } else if (propName.equals(Names.IGNORE_MALFORMED.getPreferredName())) {\n+                    builder.ignoreMalformed(\n+                        XContentMapValues.nodeBooleanValue(propNode, name + \".\" + Names.IGNORE_MALFORMED.getPreferredName())\n+                    );\n+                    iterator.remove();\n+                } else if (TypeParsers.parseMultiField(builder, name, parserContext, propName, propNode)) {\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class AggregateDoubleMetricFieldType extends SimpleMappedFieldType {\n+\n+        private EnumMap<Metric, NumberFieldMapper.NumberFieldType> metricFields;\n+\n+        private Metric defaultMetric;\n+\n+        public AggregateDoubleMetricFieldType() {}\n+\n+        AggregateDoubleMetricFieldType(AggregateDoubleMetricFieldType other) {\n+            super(other);\n+            this.metricFields = other.metricFields;\n+            this.defaultMetric = other.defaultMetric;\n+        }\n+\n+        @Override\n+        public MappedFieldType clone() {\n+            return new AggregateDoubleMetricFieldType(this);\n+        }\n+\n+        /**\n+         * Return a delegate field type for a given metric sub-field\n+         * @return a field type\n+         */\n+        private NumberFieldMapper.NumberFieldType delegateFieldType(Metric metric) {\n+            return metricFields.get(metric);\n+        }\n+\n+        /**\n+         * Return a delegate field type for the default metric sub-field\n+         * @return a field type\n+         */\n+        private NumberFieldMapper.NumberFieldType delegateFieldType() {\n+            return delegateFieldType(defaultMetric);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        private void setMetricFields(EnumMap<Metric, NumberFieldMapper.NumberFieldType> metricFields) {\n+            checkIfFrozen();\n+            this.metricFields = metricFields;\n+        }\n+\n+        public void addMetricField(Metric m, NumberFieldMapper.NumberFieldType subfield) {\n+            checkIfFrozen();\n+            if (metricFields == null) {\n+                metricFields = new EnumMap<>(AggregateDoubleMetricFieldMapper.Metric.class);\n+            }\n+\n+            if (name() == null) {\n+                throw new IllegalArgumentException(\"Field of type [\" + typeName() + \"] must have a name before adding a subfield\");\n+            }\n+            String subfieldName = subfieldName(name(), m);\n+            subfield.setName(subfieldName);\n+            metricFields.put(m, subfield);\n+        }\n+\n+        public void setDefaultMetric(Metric defaultMetric) {\n+            checkIfFrozen();\n+            this.defaultMetric = defaultMetric;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return delegateFieldType().existsQuery(context);\n+        }\n+\n+        @Override\n+        public Query termQuery(Object value, QueryShardContext context) {\n+            return delegateFieldType().termQuery(value, context);\n+        }\n+\n+        @Override\n+        public Query termsQuery(List<?> values, QueryShardContext context) {\n+            return delegateFieldType().termsQuery(values, context);\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            return delegateFieldType().rangeQuery(lowerTerm, upperTerm, includeLower, includeUpper, context);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            return delegateFieldType().valueForDisplay(value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(String format, ZoneId timeZone) {\n+            return delegateFieldType().docValueFormat(format, timeZone);\n+        }\n+\n+        @Override\n+        public Relation isFieldWithinQuery(\n+            IndexReader reader,\n+            Object from,\n+            Object to,\n+            boolean includeLower,\n+            boolean includeUpper,\n+            ZoneId timeZone,\n+            DateMathParser dateMathParser,\n+            QueryRewriteContext context\n+        ) throws IOException {\n+            return delegateFieldType().isFieldWithinQuery(reader, from, to, includeLower, includeUpper, timeZone, dateMathParser, context);\n+        }\n+\n+        @Override\n+        public ValuesSourceType getValuesSourceType() {\n+            return AggregateMetricsValuesSourceType.AGGREGATE_METRIC;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            return new IndexFieldData.Builder() {\n+                @Override\n+                public IndexFieldData<?> build(\n+                    IndexSettings indexSettings,\n+                    MappedFieldType fieldType,\n+                    IndexFieldDataCache cache,\n+                    CircuitBreakerService breakerService,\n+                    MapperService mapperService\n+                ) {\n+                    return new IndexAggregateDoubleMetricFieldData(indexSettings.getIndex(), fieldType.name()) {\n+                        @Override\n+                        public LeafAggregateDoubleMetricFieldData load(LeafReaderContext context) {\n+                            return new LeafAggregateDoubleMetricFieldData() {\n+                                @Override\n+                                public SortedNumericDoubleValues getAggregateMetricValues(final Metric metric) throws IOException {\n+                                    try {\n+                                        final NumericDocValues values = DocValues.getNumeric(\n+                                            context.reader(),\n+                                            subfieldName(fieldName, metric)\n+                                        );\n+\n+                                        return new SortedNumericDoubleValues() {\n+                                            @Override\n+                                            public int docValueCount() {\n+                                                return 1;\n+                                            }\n+\n+                                            @Override\n+                                            public boolean advanceExact(int doc) throws IOException {\n+                                                return values.advanceExact(doc);\n+                                            }\n+\n+                                            @Override\n+                                            public double nextValue() throws IOException {\n+                                                return Double.longBitsToDouble(values.longValue());\n+                                            }\n+                                        };\n+                                    } catch (IOException e) {\n+                                        throw new IOException(\"Cannot load doc values\", e);\n+                                    }\n+                                }\n+\n+                                @Override\n+                                public ScriptDocValues<?> getScriptValues() {\n+                                    throw new UnsupportedOperationException(\n+                                        \"The [\" + CONTENT_TYPE + \"] field does not \" + \"support scripts\"\n+                                    );\n+                                }\n+\n+                                @Override\n+                                public SortedBinaryDocValues getBytesValues() {\n+                                    throw new UnsupportedOperationException(\n+                                        \"String representation of doc values \" + \"for [\" + CONTENT_TYPE + \"] fields is not supported\"\n+                                    );\n+                                }\n+\n+                                @Override\n+                                public long ramBytesUsed() {\n+                                    return 0; // Unknown\n+                                }\n+\n+                                @Override\n+                                public void close() {}\n+                            };\n+                        }\n+\n+                        @Override\n+                        public LeafAggregateDoubleMetricFieldData loadDirect(LeafReaderContext context) {\n+                            return load(context);\n+                        }\n+\n+                        @Override\n+                        public SortField sortField(\n+                            Object missingValue,\n+                            MultiValueMode sortMode,\n+                            XFieldComparatorSource.Nested nested,\n+                            boolean reverse\n+                        ) {\n+                            throw new UnsupportedOperationException(\"can't sort on the [\" + CONTENT_TYPE + \"] field\");\n+                        }\n+\n+                        @Override\n+                        public BucketedSort newBucketedSort(\n+                            BigArrays bigArrays,\n+                            Object missingValue,\n+                            MultiValueMode sortMode,\n+                            XFieldComparatorSource.Nested nested,\n+                            SortOrder sortOrder,\n+                            DocValueFormat format,\n+                            int bucketSize,\n+                            BucketedSort.ExtraData extra\n+                        ) {\n+                            throw new IllegalArgumentException(\"can't sort on the [\" + CONTENT_TYPE + \"] field\");\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+    }\n+\n+    private final EnumMap<Metric, NumberFieldMapper> metricFieldMappers;\n+\n+    private Explicit<Boolean> ignoreMalformed;\n+\n+    /** A set of metrics supported */\n+    private Explicit<Set<Metric>> metrics;\n+\n+    /** The default metric to be when querying this field type */\n+    protected Explicit<Metric> defaultMetric;\n+\n+    private AggregateDoubleMetricFieldMapper(\n+        String simpleName,\n+        MappedFieldType fieldType,\n+        MappedFieldType defaultFieldType,\n+        Settings indexSettings,\n+        MultiFields multiFields,\n+        Explicit<Boolean> ignoreMalformed,\n+        Explicit<Set<Metric>> metrics,\n+        Explicit<Metric> defaultMetric,\n+        CopyTo copyTo,\n+        EnumMap<Metric, NumberFieldMapper> metricFieldMappers\n+    ) {\n+        super(simpleName, fieldType, defaultFieldType, indexSettings, multiFields, copyTo);\n+        this.ignoreMalformed = ignoreMalformed;\n+        this.metrics = metrics;\n+        this.defaultMetric = defaultMetric;\n+        this.metricFieldMappers = metricFieldMappers;\n+    }\n+\n+    @Override\n+    public AggregateDoubleMetricFieldType fieldType() {\n+        return (AggregateDoubleMetricFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return fieldType.typeName();\n+    }\n+\n+    @Override\n+    protected AggregateDoubleMetricFieldMapper clone() {\n+        return (AggregateDoubleMetricFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    public Iterator<Mapper> iterator() {\n+        List<Mapper> mappers = new ArrayList<>(metricFieldMappers.values());\n+        return mappers.iterator();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context, List<IndexableField> fields) throws IOException {\n+        if (context.externalValueSet()) {\n+            throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] can't be used in multi-fields\");\n+        }\n+\n+        context.path().add(simpleName());\n+        XContentParser.Token token = null;\n+        XContentSubParser subParser = null;\n+\n+        try {\n+            token = context.parser().currentToken();\n+            if (token == XContentParser.Token.VALUE_NULL) {\n+                context.path().remove();\n+                return;\n+            }\n+\n+            ensureExpectedToken(XContentParser.Token.START_OBJECT, token, context.parser()::getTokenLocation);\n+            subParser = new XContentSubParser(context.parser());\n+            token = subParser.nextToken();\n+            while (token != XContentParser.Token.END_OBJECT) {\n+                // should be an object subfield with name a metric name\n+                ensureExpectedToken(XContentParser.Token.FIELD_NAME, token, subParser::getTokenLocation);\n+                String fieldName = subParser.currentName();\n+                Metric metric = Metric.valueOf(fieldName);\n+\n+                if (metrics.value().contains(metric) == false) {\n+                    throw new IllegalArgumentException(\n+                        \"Aggregate metric [\" + metric + \"] does not exist in the mapping of field [\" + fieldType.name() + \"]\"\n+                    );\n+                }\n+\n+                token = subParser.nextToken();\n+                // Make sure that the value is a number. Probably this will change when\n+                // new aggregate metric types are added (histogram, cardinality etc)\n+                ensureExpectedToken(XContentParser.Token.VALUE_NUMBER, token, subParser::getTokenLocation);\n+                NumberFieldMapper delegateFieldMapper = metricFieldMappers.get(metric);\n+\n+                if (context.doc().getField(delegateFieldMapper.fieldType().name()) != null) {\n+                    throw new IllegalArgumentException(\n+                        \"Field [\"\n+                            + name()\n+                            + \"] of type [\"\n+                            + typeName()\n+                            + \"] does not support indexing multiple values for the same field in the same document\"\n+                    );\n+                }\n+\n+                delegateFieldMapper.parse(context);\n+\n+                if (Metric.value_count == metric) {\n+                    Number n = context.doc().getField(delegateFieldMapper.fieldType().name()).numericValue();\n+                    if (n.intValue() < 0) {\n+                        throw new IllegalArgumentException(\n+                            \"Aggregate metric [\" + metric.name() + \"] of field [\" + fieldType.name() + \"] cannot be a negative number\"\n+                        );\n+                    }\n+                }\n+\n+                token = subParser.nextToken();\n+            }\n+\n+            for (Metric m : metrics.value()) {\n+                if (context.doc().getField(subfieldName(fieldType().name(), m)) == null) {\n+                    throw new IllegalArgumentException(\n+                        \"Aggregate metric field [\" + fieldType.name() + \"] must contain all metrics \" + metrics.value().toString()\n+                    );\n+                }\n+            }\n+        } catch (Exception e) {\n+            if (ignoreMalformed.value()) {\n+                if (subParser != null) {\n+                    // close the subParser so we advance to the end of the object\n+                    subParser.close();\n+                }\n+                context.addIgnoredField(fieldType().name());\n+            } else {\n+                // Rethrow exception as is. It is going to be caught and nested in a MapperParsingException\n+                // by its FieldMapper.MappedFieldType#parse()\n+                throw e;\n+            }\n+        }\n+        context.path().remove();\n+    }\n+\n+    @Override\n+    protected void doMerge(Mapper mergeWith) {\n+        super.doMerge(mergeWith);\n+        AggregateDoubleMetricFieldMapper other = (AggregateDoubleMetricFieldMapper) mergeWith;\n+        if (other.ignoreMalformed.explicit()) {\n+            this.ignoreMalformed = other.ignoreMalformed;\n+        }\n+\n+        if (other.metrics.explicit()) {\n+            if (this.metrics.value() != null\n+                && metrics.value().isEmpty() == false\n+                && metrics.value().containsAll(other.metrics.value()) == false) {", "originalCommit": "21da92a7fab32b4bc820eca6f000118ba4ff06ca", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "1fe3b225a461ede27018c47aca7d34ff417dfd3a", "url": "https://github.com/elastic/elasticsearch/commit/1fe3b225a461ede27018c47aca7d34ff417dfd3a", "message": "Merge branch 'feature/aggregate-metrics' into prototype/vs-refactor-aggregate-metrics", "committedDate": "2020-03-31T10:27:51Z", "type": "commit"}, {"oid": "d7dc2044012b06efdd4b434f6f1e2a67907c739b", "url": "https://github.com/elastic/elasticsearch/commit/d7dc2044012b06efdd4b434f6f1e2a67907c739b", "message": "Addressed review comment", "committedDate": "2020-03-31T11:39:45Z", "type": "commit"}, {"oid": "d6861d19af58d2686ecf2d70fea173bb228f16d6", "url": "https://github.com/elastic/elasticsearch/commit/d6861d19af58d2686ecf2d70fea173bb228f16d6", "message": "Added tests for min aggregator", "committedDate": "2020-03-31T11:40:10Z", "type": "commit"}, {"oid": "1432ad1925620b4ce539c68dd61b9fcfb9d76d33", "url": "https://github.com/elastic/elasticsearch/commit/1432ad1925620b4ce539c68dd61b9fcfb9d76d33", "message": "Added tests for max aggregator", "committedDate": "2020-03-31T11:57:43Z", "type": "commit"}, {"oid": "f0a091f4228a7dec943f1c68dbb65323ed33469c", "url": "https://github.com/elastic/elasticsearch/commit/f0a091f4228a7dec943f1c68dbb65323ed33469c", "message": "Removed BKD optimizations for min/max aggs", "committedDate": "2020-03-31T12:16:22Z", "type": "commit"}, {"oid": "4740d593f6ac7378ff71e5194821e97dd711997f", "url": "https://github.com/elastic/elasticsearch/commit/4740d593f6ac7378ff71e5194821e97dd711997f", "message": "Added ValueCount agg backed by aggregate_metric", "committedDate": "2020-04-03T13:06:55Z", "type": "commit"}, {"oid": "71b9b40f4c70a79f272fd5b91a023bde5c071f6e", "url": "https://github.com/elastic/elasticsearch/commit/71b9b40f4c70a79f272fd5b91a023bde5c071f6e", "message": "Merge branch 'feature/aggregate-metrics' into prototype/vs-refactor-aggregate-metrics", "committedDate": "2020-04-07T14:52:58Z", "type": "commit"}, {"oid": "70bbc292c6f809d40963dcf21ed6780324818b53", "url": "https://github.com/elastic/elasticsearch/commit/70bbc292c6f809d40963dcf21ed6780324818b53", "message": "Merged changes from master", "committedDate": "2020-04-07T16:04:43Z", "type": "commit"}, {"oid": "d497fc76e85da7f551eef341fc781b141f6bf78b", "url": "https://github.com/elastic/elasticsearch/commit/d497fc76e85da7f551eef341fc781b141f6bf78b", "message": "Fixed bug with partial saving of agg metrics\n\nWhen ignore_malformed = true and a validation\nfailed for an agg metric subfield. The agg metric\nwould be partially saved by the NumberFieldMapper", "committedDate": "2020-04-13T19:09:30Z", "type": "commit"}, {"oid": "c0cc1d950ceceae088d029846240256fcdbf3378", "url": "https://github.com/elastic/elasticsearch/commit/c0cc1d950ceceae088d029846240256fcdbf3378", "message": "Merge branch 'feature/aggregate-metrics' into prototype/vs-refactor-aggregate-metrics", "committedDate": "2020-04-14T06:44:44Z", "type": "commit"}, {"oid": "1de391310ef0c833b68cd4a18062ce5967bb805f", "url": "https://github.com/elastic/elasticsearch/commit/1de391310ef0c833b68cd4a18062ce5967bb805f", "message": "Removed pipeline aggregators to merge with master", "committedDate": "2020-04-14T07:27:21Z", "type": "commit"}, {"oid": "2588b068a2dd425c10482a66e820ccb837576ee1", "url": "https://github.com/elastic/elasticsearch/commit/2588b068a2dd425c10482a66e820ccb837576ee1", "message": "Fix test", "committedDate": "2020-04-14T07:30:38Z", "type": "commit"}, {"oid": "61dbae70903ac4aecd2a4cf6f4073814c17ced8c", "url": "https://github.com/elastic/elasticsearch/commit/61dbae70903ac4aecd2a4cf6f4073814c17ced8c", "message": "Removed multifield and copyTo settings", "committedDate": "2020-04-16T06:48:29Z", "type": "commit"}, {"oid": "b9bf2599eec5896d0c2412373231cb3700bc4442", "url": "https://github.com/elastic/elasticsearch/commit/b9bf2599eec5896d0c2412373231cb3700bc4442", "message": "Modified metric subfield separator", "committedDate": "2020-04-16T06:48:56Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjA3OTAxMw==", "url": "https://github.com/elastic/elasticsearch/pull/53986#discussion_r412079013", "bodyText": "When I changed the SUBFIELD_SEPARATOR from ._ to . the yaml test Test term query on aggregate metric field started failing because it returned 0 hits. When I change the separator back to ._, test becomes successful.\nI debugged the test but values seem to be stored correctly. @polyfractal @jimczi any idea what I am missing here?\nLink to test: \n  \n    \n      elasticsearch/x-pack/plugin/src/test/resources/rest-api-spec/test/aggregate-metrics/10_basic.yml\n    \n    \n         Line 57\n      in\n      b9bf259\n    \n    \n    \n    \n\n        \n          \n           \"Test term query on aggregate metric field\":", "author": "csoulios", "createdAt": "2020-04-21T10:49:44Z", "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/mapper/AggregateDoubleMetricFieldMapper.java", "diffHunk": "@@ -47,6 +66,18 @@\n public class AggregateDoubleMetricFieldMapper extends FieldMapper {\n \n     public static final String CONTENT_TYPE = \"aggregate_metric_double\";\n+    public static final String SUBFIELD_SEPARATOR = \".\";", "originalCommit": "b9bf2599eec5896d0c2412373231cb3700bc4442", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjMwNTYyNA==", "url": "https://github.com/elastic/elasticsearch/pull/53986#discussion_r412305624", "bodyText": "Issue solved. Many thanks to @polyfractal for spotting the problem.", "author": "csoulios", "createdAt": "2020-04-21T16:27:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjA3OTAxMw=="}], "type": "inlineReview"}, {"oid": "5d956989b091f16387fa5b7289edf9967b5c1310", "url": "https://github.com/elastic/elasticsearch/commit/5d956989b091f16387fa5b7289edf9967b5c1310", "message": "Merge branch 'feature/aggregate-metrics' into prototype/vs-refactor-aggregate-metrics", "committedDate": "2020-04-21T12:08:09Z", "type": "commit"}, {"oid": "e57aa408d0f01e6708a7261abb86d6640c05e5ee", "url": "https://github.com/elastic/elasticsearch/commit/e57aa408d0f01e6708a7261abb86d6640c05e5ee", "message": "Implemented plugin getMinimalSupportedVersion()", "committedDate": "2020-04-21T12:36:02Z", "type": "commit"}, {"oid": "8584d5c9db1c4f07148092f671e9c12a3a9db217", "url": "https://github.com/elastic/elasticsearch/commit/8584d5c9db1c4f07148092f671e9c12a3a9db217", "message": "Fixed broken integration test\nFixed stylechecker error", "committedDate": "2020-04-21T15:23:32Z", "type": "commit"}, {"oid": "022dac2624ea3b348c30ec99ea7ae007999fa3fe", "url": "https://github.com/elastic/elasticsearch/commit/022dac2624ea3b348c30ec99ea7ae007999fa3fe", "message": "Implemented sortfield for aggregate_metric mapper", "committedDate": "2020-04-21T16:56:43Z", "type": "commit"}, {"oid": "157c40d31470782719b1c01cd29db7cdfff1d203", "url": "https://github.com/elastic/elasticsearch/commit/157c40d31470782719b1c01cd29db7cdfff1d203", "message": "Added yml tests for aggs on aggregate_metric field\n\nAnd fixed issues that were discovered in the\nprocess of testing", "committedDate": "2020-04-22T16:31:16Z", "type": "commit"}, {"oid": "8a90594d68183cf80dbc0b56501ea8470bb04feb", "url": "https://github.com/elastic/elasticsearch/commit/8a90594d68183cf80dbc0b56501ea8470bb04feb", "message": "Added more yml tests", "committedDate": "2020-04-22T20:11:26Z", "type": "commit"}, {"oid": "496f1d2bf6af5dd9e84a1820621a3d29b1e36ea1", "url": "https://github.com/elastic/elasticsearch/commit/496f1d2bf6af5dd9e84a1820621a3d29b1e36ea1", "message": "Merge branch 'feature/aggregate-metrics' into prototype/vs-refactor-aggregate-metrics", "committedDate": "2020-04-27T12:06:09Z", "type": "commit"}, {"oid": "92ea8d548f3c293de28949cc3020e1b0e52c5c57", "url": "https://github.com/elastic/elasticsearch/commit/92ea8d548f3c293de28949cc3020e1b0e52c5c57", "message": "Fixed errors because of merge", "committedDate": "2020-04-28T08:51:41Z", "type": "commit"}, {"oid": "873db966725ba0206d9f8f22f7410a6b5e068b90", "url": "https://github.com/elastic/elasticsearch/commit/873db966725ba0206d9f8f22f7410a6b5e068b90", "message": "Merge branch 'feature/aggregate-metrics' into prototype/vs-refactor-aggregate-metrics", "committedDate": "2020-04-28T08:52:02Z", "type": "commit"}, {"oid": "4e3538a69a45219850cfe86259d3f5dcb514d8fe", "url": "https://github.com/elastic/elasticsearch/commit/4e3538a69a45219850cfe86259d3f5dcb514d8fe", "message": "Muted failing tests", "committedDate": "2020-04-28T09:08:59Z", "type": "commit"}, {"oid": "32799eaf8aae26f90f3ad50736d57092f437df6c", "url": "https://github.com/elastic/elasticsearch/commit/32799eaf8aae26f90f3ad50736d57092f437df6c", "message": "Merge branch 'prototype/vs-refactor-aggregate-metrics' into value-count-agg-metrics", "committedDate": "2020-04-28T09:30:14Z", "type": "commit"}, {"oid": "abf673f5d19e171620ebb8d2884dbee4f1828b87", "url": "https://github.com/elastic/elasticsearch/commit/abf673f5d19e171620ebb8d2884dbee4f1828b87", "message": "Prepare merge value_count for aggregate metrics", "committedDate": "2020-04-28T10:29:23Z", "type": "commit"}, {"oid": "32be5aae223a5e876cc4aa1d6ca7890b01cb194c", "url": "https://github.com/elastic/elasticsearch/commit/32be5aae223a5e876cc4aa1d6ca7890b01cb194c", "message": "Added yml integration test for value_count\n\non aggregate metric fields", "committedDate": "2020-04-28T10:29:31Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjYwNzU2Mg==", "url": "https://github.com/elastic/elasticsearch/pull/53986#discussion_r416607562", "bodyText": "When parsing and inserting a value_count metric we took the decision to treat as integer (see \n  \n    \n      elasticsearch/x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/mapper/AggregateDoubleMetricFieldMapper.java\n    \n    \n         Line 200\n      in\n      32be5aa\n    \n    \n    \n    \n\n        \n          \n           builder = new NumberFieldMapper.Builder(fieldName, NumberFieldMapper.NumberType.INTEGER); \n        \n    \n  \n\n)\nSo when we aggregate documents, we must treat value_count sub-fields as longs and not as doubles. This part of the code is a bit ugly. Is there any better way to do this?", "author": "csoulios", "createdAt": "2020-04-28T13:21:54Z", "path": "x-pack/plugin/mapper-aggregate-metric/src/main/java/org/elasticsearch/xpack/aggregatemetric/mapper/AggregateDoubleMetricFieldMapper.java", "diffHunk": "@@ -352,10 +395,118 @@ public Relation isFieldWithinQuery(\n         }\n \n         @Override\n-        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n-            return delegateFieldType().fielddataBuilder(fullyQualifiedIndexName);\n+        public ValuesSourceType getValuesSourceType() {\n+            return AggregateMetricsValuesSourceType.AGGREGATE_METRIC;\n         }\n \n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            return new IndexFieldData.Builder() {\n+                @Override\n+                public IndexFieldData<?> build(\n+                    IndexSettings indexSettings,\n+                    MappedFieldType fieldType,\n+                    IndexFieldDataCache cache,\n+                    CircuitBreakerService breakerService,\n+                    MapperService mapperService\n+                ) {\n+                    return new IndexAggregateDoubleMetricFieldData(indexSettings.getIndex(), fieldType.name()) {\n+                        @Override\n+                        public LeafAggregateDoubleMetricFieldData load(LeafReaderContext context) {\n+                            return new LeafAggregateDoubleMetricFieldData() {\n+                                @Override\n+                                public SortedNumericDoubleValues getAggregateMetricValues(final Metric metric) throws IOException {\n+                                    try {\n+                                        final SortedNumericDocValues values = DocValues.getSortedNumeric(\n+                                            context.reader(),\n+                                            subfieldName(fieldName, metric)\n+                                        );\n+\n+                                        return new SortedNumericDoubleValues() {\n+                                            @Override\n+                                            public int docValueCount() {\n+                                                return values.docValueCount();\n+                                            }\n+\n+                                            @Override\n+                                            public boolean advanceExact(int doc) throws IOException {\n+                                                return values.advanceExact(doc);\n+                                            }\n+\n+                                            @Override\n+                                            public double nextValue() throws IOException {\n+                                                long v = values.nextValue();\n+                                                if (metric == Metric.value_count) {\n+                                                    // Only value_count metrics are encoded as integers\n+                                                    return v;\n+                                                } else {\n+                                                    // All other metrics are encoded as doubles\n+                                                    return NumericUtils.sortableLongToDouble(v);\n+                                                }", "originalCommit": "32be5aae223a5e876cc4aa1d6ca7890b01cb194c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "5cc262098d7b315b1086c2cc619edb925578f299", "url": "https://github.com/elastic/elasticsearch/commit/5cc262098d7b315b1086c2cc619edb925578f299", "message": "Do no allow merging mappers with missing metrics", "committedDate": "2020-05-12T12:11:15Z", "type": "commit"}, {"oid": "4bbbc82f4fb05b3c89dbc8bee45f08f0f28e7252", "url": "https://github.com/elastic/elasticsearch/commit/4bbbc82f4fb05b3c89dbc8bee45f08f0f28e7252", "message": "Merge branch 'feature/aggregate-metrics' into prototype/vs-refactor-aggregate-metrics", "committedDate": "2020-05-12T12:53:06Z", "type": "commit"}, {"oid": "423e81a2d5b48314da94f93e074be82acbb8b4d2", "url": "https://github.com/elastic/elasticsearch/commit/423e81a2d5b48314da94f93e074be82acbb8b4d2", "message": "Merge with master - fixes", "committedDate": "2020-05-12T17:11:00Z", "type": "commit"}, {"oid": "3bafd2fce37a18bd485c76b405bc81bc5357bc51", "url": "https://github.com/elastic/elasticsearch/commit/3bafd2fce37a18bd485c76b405bc81bc5357bc51", "message": "Fixed broken tests", "committedDate": "2020-05-13T08:23:17Z", "type": "commit"}, {"oid": "3180ba4cbb66d64d6343c94c6848ee2af8d30fea", "url": "https://github.com/elastic/elasticsearch/commit/3180ba4cbb66d64d6343c94c6848ee2af8d30fea", "message": "Merge branch 'feature/aggregate-metrics' into prototype/vs-refactor-aggregate-metrics", "committedDate": "2020-05-13T15:17:09Z", "type": "commit"}, {"oid": "6920dccb7b0da915f51b3b9148434fbc73ffa686", "url": "https://github.com/elastic/elasticsearch/commit/6920dccb7b0da915f51b3b9148434fbc73ffa686", "message": "Merge branch 'feature/aggregate-metrics' into prototype/vs-refactor-aggregate-metrics", "committedDate": "2020-05-14T06:53:55Z", "type": "commit"}, {"oid": "d37d6220c86f9ce5d40d08ae0e8b067b4b4e28e2", "url": "https://github.com/elastic/elasticsearch/commit/d37d6220c86f9ce5d40d08ae0e8b067b4b4e28e2", "message": "Fix build issues from last merge", "committedDate": "2020-05-14T07:28:49Z", "type": "commit"}]}