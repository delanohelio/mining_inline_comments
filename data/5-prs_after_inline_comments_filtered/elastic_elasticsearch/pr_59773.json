{"pr_number": 59773, "pr_title": "Add field type for version strings", "pr_createdAt": "2020-07-17T13:12:17Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/59773", "timeline": [{"oid": "2cd8f1d3a5b96cb139cf93eb26f2ffcaa6ac8bba", "url": "https://github.com/elastic/elasticsearch/commit/2cd8f1d3a5b96cb139cf93eb26f2ffcaa6ac8bba", "message": "Add field type for version strings\n\nThis PR adds a new 'version' field type that allows indexing string values\nrepresenting software versions similar to the ones defined in the Semantic\nVersioning definition (semver.org). The field behaves very similar to a\n'keyword' field but allows efficient sorting and range queries that take into\naccound the special ordering needed for version strings. For example, the main\nversion parts are sorted numerically (ie 2.0.0 < 11.0.0) whereas this wouldn't\nbe possible with 'keyword' fields today.\n\nValid version values are similar to the Semantic Versioning definition, with the\nnotable exception that in addition to the \"main\" version consiting of\nmajor.minor.patch, we allow less or more than three numeric identifiers, i.e.\n\"1.2\" or \"1.4.6.123.12\" are treated as valid too.\n\nRelates to #48878", "committedDate": "2020-07-17T13:33:26Z", "type": "forcePushed"}, {"oid": "343310c129ff67a4cb6d2e034ca538b56bf9ae9c", "url": "https://github.com/elastic/elasticsearch/commit/343310c129ff67a4cb6d2e034ca538b56bf9ae9c", "message": "Add field type for version strings\n\nThis PR adds a new 'version' field type that allows indexing string values\nrepresenting software versions similar to the ones defined in the Semantic\nVersioning definition (semver.org). The field behaves very similar to a\n'keyword' field but allows efficient sorting and range queries that take into\naccound the special ordering needed for version strings. For example, the main\nversion parts are sorted numerically (ie 2.0.0 < 11.0.0) whereas this wouldn't\nbe possible with 'keyword' fields today.\n\nValid version values are similar to the Semantic Versioning definition, with the\nnotable exception that in addition to the \"main\" version consiting of\nmajor.minor.patch, we allow less or more than three numeric identifiers, i.e.\n\"1.2\" or \"1.4.6.123.12\" are treated as valid too.\n\nRelates to #48878", "committedDate": "2020-07-20T09:00:20Z", "type": "commit"}, {"oid": "343310c129ff67a4cb6d2e034ca538b56bf9ae9c", "url": "https://github.com/elastic/elasticsearch/commit/343310c129ff67a4cb6d2e034ca538b56bf9ae9c", "message": "Add field type for version strings\n\nThis PR adds a new 'version' field type that allows indexing string values\nrepresenting software versions similar to the ones defined in the Semantic\nVersioning definition (semver.org). The field behaves very similar to a\n'keyword' field but allows efficient sorting and range queries that take into\naccound the special ordering needed for version strings. For example, the main\nversion parts are sorted numerically (ie 2.0.0 < 11.0.0) whereas this wouldn't\nbe possible with 'keyword' fields today.\n\nValid version values are similar to the Semantic Versioning definition, with the\nnotable exception that in addition to the \"main\" version consiting of\nmajor.minor.patch, we allow less or more than three numeric identifiers, i.e.\n\"1.2\" or \"1.4.6.123.12\" are treated as valid too.\n\nRelates to #48878", "committedDate": "2020-07-20T09:00:20Z", "type": "forcePushed"}, {"oid": "397a7c036827cbae0a7460da250d2df5e177d769", "url": "https://github.com/elastic/elasticsearch/commit/397a7c036827cbae0a7460da250d2df5e177d769", "message": "Add yaml for search, ranges and scripting", "committedDate": "2020-07-20T17:26:59Z", "type": "commit"}, {"oid": "08989e7c345da41fa7d75a93e56dcd17be413aba", "url": "https://github.com/elastic/elasticsearch/commit/08989e7c345da41fa7d75a93e56dcd17be413aba", "message": "Add brute force regex query support", "committedDate": "2020-07-22T17:17:57Z", "type": "commit"}, {"oid": "08989e7c345da41fa7d75a93e56dcd17be413aba", "url": "https://github.com/elastic/elasticsearch/commit/08989e7c345da41fa7d75a93e56dcd17be413aba", "message": "Add brute force regex query support", "committedDate": "2020-07-22T17:17:57Z", "type": "forcePushed"}, {"oid": "8a1acc28939452ec3fc6b6c9ee7165403dd944bf", "url": "https://github.com/elastic/elasticsearch/commit/8a1acc28939452ec3fc6b6c9ee7165403dd944bf", "message": "Add fuzzy query support", "committedDate": "2020-07-23T13:13:14Z", "type": "commit"}, {"oid": "bc972ad1474f5817f9ab6633f0059b30be621c0d", "url": "https://github.com/elastic/elasticsearch/commit/bc972ad1474f5817f9ab6633f0059b30be621c0d", "message": "Merge branch 'master' into add-version-field", "committedDate": "2020-07-23T13:36:07Z", "type": "commit"}, {"oid": "5bac78553dff91c4d2c8e4c5f9d1a92ff6453ceb", "url": "https://github.com/elastic/elasticsearch/commit/5bac78553dff91c4d2c8e4c5f9d1a92ff6453ceb", "message": "Remove some left-over commented code", "committedDate": "2020-07-23T16:04:04Z", "type": "commit"}, {"oid": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f", "url": "https://github.com/elastic/elasticsearch/commit/8a7b43cadd5bf89d3e6069057290139f17a5bd3f", "message": "Adding tests", "committedDate": "2020-07-23T16:48:19Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDg5Nzg4Ng==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r460897886", "bodyText": "What's the need of  extra TypeParsers.parseMultiField on line 169 if TypeParsers.parseField on line 155 already takes care of multi-field?   Should we choose one of these 2 options?", "author": "mayya-sharipova", "createdAt": "2020-07-27T13:41:55Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,550 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.support.XContentMapValues;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+        private boolean storeMalformed = false;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        Builder storeMalformed(boolean storeMalformed) {\n+            this.storeMalformed = storeMalformed;\n+            return builder;\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            boolean validateVersion = storeMalformed == false;\n+            return new VersionStringFieldType(buildFullName(context), indexed, validateVersion, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                storeMalformed,\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                } else if (propName.equals(\"store_malformed\")) {\n+                    builder.storeMalformed(XContentMapValues.nodeBooleanValue(propNode, name + \".store_malformed\"));\n+                    iterator.remove();\n+                } else if (TypeParsers.parseMultiField(builder::addMultiField, name, parserContext, propName, propNode)) {", "originalCommit": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDk0MTU2Mw==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r460941563", "bodyText": "Should we override and disallow indexOptions in Builder, similarly how NumberFieldMapper#Builder does it?", "author": "mayya-sharipova", "createdAt": "2020-07-27T14:41:41Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,550 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.support.XContentMapValues;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+        private boolean storeMalformed = false;\n+", "originalCommit": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDk1MDY3OQ==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r460950679", "bodyText": "Do we want to assign nullValue here as as well in cases where a string is empty or null?", "author": "mayya-sharipova", "createdAt": "2020-07-27T14:53:52Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,550 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.support.XContentMapValues;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+        private boolean storeMalformed = false;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        Builder storeMalformed(boolean storeMalformed) {\n+            this.storeMalformed = storeMalformed;\n+            return builder;\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            boolean validateVersion = storeMalformed == false;\n+            return new VersionStringFieldType(buildFullName(context), indexed, validateVersion, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                storeMalformed,\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                } else if (propName.equals(\"store_malformed\")) {\n+                    builder.storeMalformed(XContentMapValues.nodeBooleanValue(propNode, name + \".store_malformed\"));\n+                    iterator.remove();\n+                } else if (TypeParsers.parseMultiField(builder::addMultiField, name, parserContext, propName, propNode)) {\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        // if true, we want to throw errors on illegal versions at index and query time\n+        private boolean validateVersion = false;\n+\n+        public VersionStringFieldType(\n+            String name,\n+            boolean isSearchable,\n+            boolean validateVersion,\n+            Map<String, String> meta,\n+            float boost,\n+            FieldType fieldType\n+        ) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+            this.validateVersion = validateVersion;\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            EncodedVersion encodedVersion = encodeVersion(valueAsString);\n+            if (encodedVersion.isLegal == false && validateVersion) {\n+                throw new IllegalArgumentException(\"Illegal version string: \" + valueAsString);\n+            }\n+            return encodedVersion.bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private boolean storeMalformed;\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        boolean storeMalformed,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.storeMalformed = storeMalformed;\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();", "originalCommit": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTE4MjY0OQ==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461182649", "bodyText": "I actually wonder if this type should support null_value at all. I can't think of an example where it'd be useful to supply a default value for a version. And what could the default value even be?", "author": "jtibshirani", "createdAt": "2020-07-27T21:32:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDk1MDY3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTcwMzQxOA==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461703418", "bodyText": "I agree that default values are probably not that meaningful here, but e.g. 0.0.0 might be something users might want to index in case this value is null. I think I added this for versions so they behave as close to \"keyword\" fields as possible, also on the indexing side, but I'm open to discuss and remove this if you think its not required.", "author": "cbuescher", "createdAt": "2020-07-28T16:12:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDk1MDY3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ4ODE5Ng==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462488196", "bodyText": "It would be great to discuss (maybe through a different channel?), I've been wondering in general about whether most field types should support null_value.", "author": "jtibshirani", "createdAt": "2020-07-29T18:04:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDk1MDY3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzIwMTg5NA==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r477201894", "bodyText": "I changed this PR to not allow setting null_value, however we accept null as a field value in the input json in which case we don't index any value into the field.", "author": "cbuescher", "createdAt": "2020-08-26T10:33:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDk1MDY3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTExNjExNg==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461116116", "bodyText": "RELESE -> RELEASE (and same issue below)", "author": "jtibshirani", "createdAt": "2020-07-27T19:24:03Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.BytesRefBuilder;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Encodes a version string to a {@link BytesRef} that correctly sorts according to software version precedence rules like\n+ * the ones described in Semantiv Versioning (https://semver.org/)\n+ *\n+ * Version strings are considered to consist of three parts:\n+ * <ul>\n+ *  <li> a numeric major.minor.patch part starting the version string (e.g. 1.2.3)\n+ *  <li> an optional \"pre-release\" part that starts with a `-` character and can consist of several alpha-numerical sections\n+ *  separated by dots (e.g. \"-alpha.2.3\")\n+ *  <li> an optional \"build\" part that starts with a `+` character. This will simply be treated as a prefix with no guaranteed ordering,\n+ *  (although the ordering should be alphabetical in most cases).\n+ * </ul>\n+ *\n+ * The version string is encoded such that the ordering works like the following:\n+ * <ul>\n+ *  <li> Major, minor, and patch versions are always compared numerically\n+ *  <li> pre-release version have lower precedence than a normal version. (e.g 1.0.0-alpha &lt; 1.0.0)\n+ *  <li> the precedence for pre-release versions with same main version is calculated comparing each dot separated identifier from\n+ *  left to right. Identifiers consisting of only digits are compared numerically and identifiers with letters or hyphens are compared\n+ *  lexically in ASCII sort order. Numeric identifiers always have lower precedence than non-numeric identifiers.\n+ * </ul>\n+ */\n+class VersionEncoder {\n+\n+    public static final byte NUMERIC_MARKER_BYTE = (byte) 0x01;\n+    public static final byte PRERELESE_SEPARATOR_BYTE = (byte) 0x02;", "originalCommit": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTExNjI4NA==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461116284", "bodyText": "Semantiv -> Semantic", "author": "jtibshirani", "createdAt": "2020-07-27T19:24:23Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.BytesRefBuilder;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Encodes a version string to a {@link BytesRef} that correctly sorts according to software version precedence rules like\n+ * the ones described in Semantiv Versioning (https://semver.org/)", "originalCommit": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTExNzYyOA==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461117628", "bodyText": "This will simply be treated as a prefix with no guaranteed ordering, (although the ordering should be alphabetical in most cases).\n\nI'm not sure what this part means, could you clarify the behavior?", "author": "jtibshirani", "createdAt": "2020-07-27T19:26:56Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.BytesRefBuilder;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Encodes a version string to a {@link BytesRef} that correctly sorts according to software version precedence rules like\n+ * the ones described in Semantiv Versioning (https://semver.org/)\n+ *\n+ * Version strings are considered to consist of three parts:\n+ * <ul>\n+ *  <li> a numeric major.minor.patch part starting the version string (e.g. 1.2.3)\n+ *  <li> an optional \"pre-release\" part that starts with a `-` character and can consist of several alpha-numerical sections\n+ *  separated by dots (e.g. \"-alpha.2.3\")\n+ *  <li> an optional \"build\" part that starts with a `+` character. This will simply be treated as a prefix with no guaranteed ordering,", "originalCommit": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY5MzE1NA==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461693154", "bodyText": "Sorry for the confusion, it should be \"suffix\" and I changed the description to a hopefully less confusing \"ascii order\"", "author": "cbuescher", "createdAt": "2020-07-28T15:57:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTExNzYyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTE2NzI3NQ==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461167275", "bodyText": "Super small comment, you could just return Map.of(VersionStringFieldMapper.CONTENT_TYPE, new VersionStringFieldMapper.TypeParser())?", "author": "jtibshirani", "createdAt": "2020-07-27T21:01:07Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionFieldPlugin.java", "diffHunk": "@@ -0,0 +1,28 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.plugins.MapperPlugin;\n+import org.elasticsearch.plugins.Plugin;\n+\n+import java.util.Collections;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+\n+public class VersionFieldPlugin extends Plugin implements MapperPlugin {\n+\n+    public VersionFieldPlugin(Settings settings) {}\n+\n+    @Override\n+    public Map<String, Mapper.TypeParser> getMappers() {", "originalCommit": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTE2ODUzNQ==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461168535", "bodyText": "Great unit test coverage!", "author": "jtibshirani", "createdAt": "2020-07-27T21:03:37Z", "path": "x-pack/plugin/versionfield/src/test/java/org/elasticsearch/xpack/versionfield/VersionEncoderTests.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.util.BytesRef;\n+import org.elasticsearch.test.ESTestCase;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.util.Arrays;\n+\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.decodeVersion;\n+\n+public class VersionEncoderTests extends ESTestCase {\n+\n+    public void testEncodingOrderingSemver() {", "originalCommit": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTE4ODEwMg==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461188102", "bodyText": "Small comment, maybe we could have a constructor (or static factory method) to create illegal versions, like EncodedVersion.createIllegalVersion(versionString) ? This would avoid exposing the option to create an illegal version plus parsed components.", "author": "jtibshirani", "createdAt": "2020-07-27T21:43:49Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.BytesRefBuilder;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Encodes a version string to a {@link BytesRef} that correctly sorts according to software version precedence rules like\n+ * the ones described in Semantiv Versioning (https://semver.org/)\n+ *\n+ * Version strings are considered to consist of three parts:\n+ * <ul>\n+ *  <li> a numeric major.minor.patch part starting the version string (e.g. 1.2.3)\n+ *  <li> an optional \"pre-release\" part that starts with a `-` character and can consist of several alpha-numerical sections\n+ *  separated by dots (e.g. \"-alpha.2.3\")\n+ *  <li> an optional \"build\" part that starts with a `+` character. This will simply be treated as a prefix with no guaranteed ordering,\n+ *  (although the ordering should be alphabetical in most cases).\n+ * </ul>\n+ *\n+ * The version string is encoded such that the ordering works like the following:\n+ * <ul>\n+ *  <li> Major, minor, and patch versions are always compared numerically\n+ *  <li> pre-release version have lower precedence than a normal version. (e.g 1.0.0-alpha &lt; 1.0.0)\n+ *  <li> the precedence for pre-release versions with same main version is calculated comparing each dot separated identifier from\n+ *  left to right. Identifiers consisting of only digits are compared numerically and identifiers with letters or hyphens are compared\n+ *  lexically in ASCII sort order. Numeric identifiers always have lower precedence than non-numeric identifiers.\n+ * </ul>\n+ */\n+class VersionEncoder {\n+\n+    public static final byte NUMERIC_MARKER_BYTE = (byte) 0x01;\n+    public static final byte PRERELESE_SEPARATOR_BYTE = (byte) 0x02;\n+    public static final byte NO_PRERELESE_SEPARATOR_BYTE = (byte) 0x03;\n+\n+    private static final char PRERELESE_SEPARATOR = '-';\n+    private static final char DOT_SEPARATOR = '.';\n+    private static final char BUILD_SEPARATOR = '+';\n+\n+    // Regex to test relaxed Semver Main Version validity. Allows for more or less than three main version parts\n+    private static Pattern LEGAL_MAIN_VERSION_SEMVER = Pattern.compile(\"(0|[1-9]\\\\d*)(\\\\.(0|[1-9]\\\\d*))*\");\n+\n+    private static Pattern LEGAL_PRERELEASE_VERSION_SEMVER = Pattern.compile(\n+        \"(?:-((?:0|[1-9]\\\\d*|\\\\d*[a-zA-Z-][0-9a-zA-Z-]*)(?:\\\\.(?:0|[1-9]\\\\d*|\\\\d*[a-zA-Z-][0-9a-zA-Z-]*))*))\"\n+    );\n+\n+    private static Pattern LEGAL_BUILDSUFFIX_SEMVER = Pattern.compile(\"(?:\\\\+([0-9a-zA-Z-]+(?:\\\\.[0-9a-zA-Z-]+)*))?\");\n+\n+    /**\n+     * Encodes a version string.\n+     */\n+    public static EncodedVersion encodeVersion(String versionString) {\n+        VersionParts versionParts = VersionParts.ofVersion(versionString);\n+\n+        // don't treat non-legal versions further, just mark them as illegal and return\n+        if (legalVersionString(versionParts) == false) {\n+            return new EncodedVersion(new BytesRef(versionString), false, true, 0, 0, 0);", "originalCommit": "8a7b43cadd5bf89d3e6069057290139f17a5bd3f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY3NTAwNw==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461675007", "bodyText": "I made the class package private and the ctor private, hope that fits your suggestion.", "author": "cbuescher", "createdAt": "2020-07-28T15:32:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTE4ODEwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ4OTQyMQ==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462489421", "bodyText": "\ud83d\udc4d  this helps address the concern.", "author": "jtibshirani", "createdAt": "2020-07-29T18:07:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTE4ODEwMg=="}], "type": "inlineReview"}, {"oid": "910616e5ebf560c60e29d42d8b10e53c10781df7", "url": "https://github.com/elastic/elasticsearch/commit/910616e5ebf560c60e29d42d8b10e53c10781df7", "message": "Make string_stats work", "committedDate": "2020-07-28T13:01:32Z", "type": "commit"}, {"oid": "6d71b52424efa5423f9d4603a00706cb34561639", "url": "https://github.com/elastic/elasticsearch/commit/6d71b52424efa5423f9d4603a00706cb34561639", "message": "Merge branch 'master' into add-version-field", "committedDate": "2020-07-28T13:07:03Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTU4NTIzNg==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461585236", "bodyText": "may be worth separating this function into 2 functions: one that just prefix digit group with length and another one extracts main versions?", "author": "mayya-sharipova", "createdAt": "2020-07-28T13:37:00Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.BytesRefBuilder;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Encodes a version string to a {@link BytesRef} that correctly sorts according to software version precedence rules like\n+ * the ones described in Semantiv Versioning (https://semver.org/)\n+ *\n+ * Version strings are considered to consist of three parts:\n+ * <ul>\n+ *  <li> a numeric major.minor.patch part starting the version string (e.g. 1.2.3)\n+ *  <li> an optional \"pre-release\" part that starts with a `-` character and can consist of several alpha-numerical sections\n+ *  separated by dots (e.g. \"-alpha.2.3\")\n+ *  <li> an optional \"build\" part that starts with a `+` character. This will simply be treated as a prefix with no guaranteed ordering,\n+ *  (although the ordering should be alphabetical in most cases).\n+ * </ul>\n+ *\n+ * The version string is encoded such that the ordering works like the following:\n+ * <ul>\n+ *  <li> Major, minor, and patch versions are always compared numerically\n+ *  <li> pre-release version have lower precedence than a normal version. (e.g 1.0.0-alpha &lt; 1.0.0)\n+ *  <li> the precedence for pre-release versions with same main version is calculated comparing each dot separated identifier from\n+ *  left to right. Identifiers consisting of only digits are compared numerically and identifiers with letters or hyphens are compared\n+ *  lexically in ASCII sort order. Numeric identifiers always have lower precedence than non-numeric identifiers.\n+ * </ul>\n+ */\n+class VersionEncoder {\n+\n+    public static final byte NUMERIC_MARKER_BYTE = (byte) 0x01;\n+    public static final byte PRERELESE_SEPARATOR_BYTE = (byte) 0x02;\n+    public static final byte NO_PRERELESE_SEPARATOR_BYTE = (byte) 0x03;\n+\n+    private static final char PRERELESE_SEPARATOR = '-';\n+    private static final char DOT_SEPARATOR = '.';\n+    private static final char BUILD_SEPARATOR = '+';\n+\n+    // Regex to test relaxed Semver Main Version validity. Allows for more or less than three main version parts\n+    private static Pattern LEGAL_MAIN_VERSION_SEMVER = Pattern.compile(\"(0|[1-9]\\\\d*)(\\\\.(0|[1-9]\\\\d*))*\");\n+\n+    private static Pattern LEGAL_PRERELEASE_VERSION_SEMVER = Pattern.compile(\n+        \"(?:-((?:0|[1-9]\\\\d*|\\\\d*[a-zA-Z-][0-9a-zA-Z-]*)(?:\\\\.(?:0|[1-9]\\\\d*|\\\\d*[a-zA-Z-][0-9a-zA-Z-]*))*))\"\n+    );\n+\n+    private static Pattern LEGAL_BUILDSUFFIX_SEMVER = Pattern.compile(\"(?:\\\\+([0-9a-zA-Z-]+(?:\\\\.[0-9a-zA-Z-]+)*))?\");\n+\n+    /**\n+     * Encodes a version string.\n+     */\n+    public static EncodedVersion encodeVersion(String versionString) {\n+        VersionParts versionParts = VersionParts.ofVersion(versionString);\n+\n+        // don't treat non-legal versions further, just mark them as illegal and return\n+        if (legalVersionString(versionParts) == false) {\n+            return new EncodedVersion(new BytesRef(versionString), false, true, 0, 0, 0);\n+        }\n+\n+        BytesRefBuilder encodedBytes = new BytesRefBuilder();\n+        Integer[] mainVersionParts = prefixDigitGroupsWithLength(versionParts.mainVersion, encodedBytes);\n+\n+        if (versionParts.preRelease != null) {\n+            encodedBytes.append(PRERELESE_SEPARATOR_BYTE);  // versions with pre-release part sort before ones without\n+            encodedBytes.append((byte) PRERELESE_SEPARATOR);\n+            String[] preReleaseParts = versionParts.preRelease.substring(1).split(\"\\\\.\");\n+            boolean first = true;\n+            for (String preReleasePart : preReleaseParts) {\n+                if (first == false) {\n+                    encodedBytes.append((byte) DOT_SEPARATOR);\n+                }\n+                boolean isNumeric = preReleasePart.chars().allMatch(x -> Character.isDigit(x));\n+                if (isNumeric) {\n+                    prefixDigitGroupsWithLength(preReleasePart, encodedBytes);", "originalCommit": "6d71b52424efa5423f9d4603a00706cb34561639", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY5ODM5MA==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461698390", "bodyText": "I couldn't find a simple way to split this methodf that wouldn't involve running through the input string at least twice. This way we avoid two passes, but I'm happy for any suggestions how to change this if you have an idea...", "author": "cbuescher", "createdAt": "2020-07-28T16:05:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTU4NTIzNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY3NTkzMQ==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r461675931", "bodyText": "That's quite a clever encoding! Nice work! What I like about it is that it allows the decoding to the original values.\nAnother way to do encoding I was thinking of is to standardize main versions to 3 bytes (1 byte of each component), but standardization would not allow the decoding to the original values.", "author": "mayya-sharipova", "createdAt": "2020-07-28T15:33:24Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.BytesRefBuilder;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Encodes a version string to a {@link BytesRef} that correctly sorts according to software version precedence rules like\n+ * the ones described in Semantiv Versioning (https://semver.org/)\n+ *\n+ * Version strings are considered to consist of three parts:\n+ * <ul>\n+ *  <li> a numeric major.minor.patch part starting the version string (e.g. 1.2.3)\n+ *  <li> an optional \"pre-release\" part that starts with a `-` character and can consist of several alpha-numerical sections\n+ *  separated by dots (e.g. \"-alpha.2.3\")\n+ *  <li> an optional \"build\" part that starts with a `+` character. This will simply be treated as a prefix with no guaranteed ordering,\n+ *  (although the ordering should be alphabetical in most cases).\n+ * </ul>\n+ *\n+ * The version string is encoded such that the ordering works like the following:\n+ * <ul>\n+ *  <li> Major, minor, and patch versions are always compared numerically\n+ *  <li> pre-release version have lower precedence than a normal version. (e.g 1.0.0-alpha &lt; 1.0.0)\n+ *  <li> the precedence for pre-release versions with same main version is calculated comparing each dot separated identifier from\n+ *  left to right. Identifiers consisting of only digits are compared numerically and identifiers with letters or hyphens are compared\n+ *  lexically in ASCII sort order. Numeric identifiers always have lower precedence than non-numeric identifiers.\n+ * </ul>\n+ */\n+class VersionEncoder {\n+\n+    public static final byte NUMERIC_MARKER_BYTE = (byte) 0x01;\n+    public static final byte PRERELESE_SEPARATOR_BYTE = (byte) 0x02;\n+    public static final byte NO_PRERELESE_SEPARATOR_BYTE = (byte) 0x03;\n+\n+    private static final char PRERELESE_SEPARATOR = '-';\n+    private static final char DOT_SEPARATOR = '.';\n+    private static final char BUILD_SEPARATOR = '+';\n+\n+    // Regex to test relaxed Semver Main Version validity. Allows for more or less than three main version parts\n+    private static Pattern LEGAL_MAIN_VERSION_SEMVER = Pattern.compile(\"(0|[1-9]\\\\d*)(\\\\.(0|[1-9]\\\\d*))*\");\n+\n+    private static Pattern LEGAL_PRERELEASE_VERSION_SEMVER = Pattern.compile(\n+        \"(?:-((?:0|[1-9]\\\\d*|\\\\d*[a-zA-Z-][0-9a-zA-Z-]*)(?:\\\\.(?:0|[1-9]\\\\d*|\\\\d*[a-zA-Z-][0-9a-zA-Z-]*))*))\"\n+    );\n+\n+    private static Pattern LEGAL_BUILDSUFFIX_SEMVER = Pattern.compile(\"(?:\\\\+([0-9a-zA-Z-]+(?:\\\\.[0-9a-zA-Z-]+)*))?\");\n+\n+    /**\n+     * Encodes a version string.\n+     */\n+    public static EncodedVersion encodeVersion(String versionString) {\n+        VersionParts versionParts = VersionParts.ofVersion(versionString);\n+\n+        // don't treat non-legal versions further, just mark them as illegal and return\n+        if (legalVersionString(versionParts) == false) {\n+            return new EncodedVersion(new BytesRef(versionString), false, true, 0, 0, 0);\n+        }\n+\n+        BytesRefBuilder encodedBytes = new BytesRefBuilder();\n+        Integer[] mainVersionParts = prefixDigitGroupsWithLength(versionParts.mainVersion, encodedBytes);\n+\n+        if (versionParts.preRelease != null) {\n+            encodedBytes.append(PRERELESE_SEPARATOR_BYTE);  // versions with pre-release part sort before ones without\n+            encodedBytes.append((byte) PRERELESE_SEPARATOR);\n+            String[] preReleaseParts = versionParts.preRelease.substring(1).split(\"\\\\.\");\n+            boolean first = true;\n+            for (String preReleasePart : preReleaseParts) {\n+                if (first == false) {\n+                    encodedBytes.append((byte) DOT_SEPARATOR);\n+                }\n+                boolean isNumeric = preReleasePart.chars().allMatch(x -> Character.isDigit(x));\n+                if (isNumeric) {\n+                    prefixDigitGroupsWithLength(preReleasePart, encodedBytes);\n+                } else {\n+                    encodedBytes.append(new BytesRef(preReleasePart));\n+                }\n+                first = false;\n+            }\n+        } else {\n+            encodedBytes.append(NO_PRERELESE_SEPARATOR_BYTE);\n+        }\n+\n+        if (versionParts.buildSuffix != null) {\n+            encodedBytes.append(new BytesRef(versionParts.buildSuffix));\n+        }\n+        return new EncodedVersion(\n+            encodedBytes.toBytesRef(),\n+            true,\n+            versionParts.preRelease != null,\n+            mainVersionParts[0],\n+            mainVersionParts[1],\n+            mainVersionParts[2]\n+        );\n+    }\n+\n+    private static Integer[] prefixDigitGroupsWithLength(String input, BytesRefBuilder result) {", "originalCommit": "6d71b52424efa5423f9d4603a00706cb34561639", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjMxMDY3MQ==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462310671", "bodyText": "Yes, being able to get back the original values is quite important here, e.g. we need that when needing to display encoded docvalues (e.g. keys for terms aggs where I first encountered that problem). I tried several approaches with encoding main verison parts as bytes (several widths) but they all failed either because bein too restrictive (we also want to allow less or more than 3 main digits, as an extension to strict semver, e.g. \"1.0.14.20201027\") and the range of verison numbers is in theory unlimited. Thats why in the end I prefer this simpler apporoach which can also be used for numeric parts in the pre-release part of the version string.", "author": "cbuescher", "createdAt": "2020-07-29T13:46:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY3NTkzMQ=="}], "type": "inlineReview"}, {"oid": "970085acc0c3cc275c91b66d9881d094456b280e", "url": "https://github.com/elastic/elasticsearch/commit/970085acc0c3cc275c91b66d9881d094456b280e", "message": "Adressing review comments", "committedDate": "2020-07-28T16:27:39Z", "type": "commit"}, {"oid": "bdb89a2b1fa58da41732c5876494b3da23f54eee", "url": "https://github.com/elastic/elasticsearch/commit/bdb89a2b1fa58da41732c5876494b3da23f54eee", "message": "Remove 'store_malformed' option", "committedDate": "2020-07-29T16:11:21Z", "type": "commit"}, {"oid": "4433c5c49123f39806bcc5f43c2bf0c421a04c9e", "url": "https://github.com/elastic/elasticsearch/commit/4433c5c49123f39806bcc5f43c2bf0c421a04c9e", "message": "Add tests for handling empty string", "committedDate": "2020-07-29T17:19:07Z", "type": "forcePushed"}, {"oid": "81bb1146b555f27f8890ee876600e760dc51c963", "url": "https://github.com/elastic/elasticsearch/commit/81bb1146b555f27f8890ee876600e760dc51c963", "message": "Add tests for handling empty string", "committedDate": "2020-07-29T17:25:26Z", "type": "commit"}, {"oid": "81bb1146b555f27f8890ee876600e760dc51c963", "url": "https://github.com/elastic/elasticsearch/commit/81bb1146b555f27f8890ee876600e760dc51c963", "message": "Add tests for handling empty string", "committedDate": "2020-07-29T17:25:26Z", "type": "forcePushed"}, {"oid": "5fcf8a73916f2aa635d5fe9b2a8ea557ad62c9ac", "url": "https://github.com/elastic/elasticsearch/commit/5fcf8a73916f2aa635d5fe9b2a8ea557ad62c9ac", "message": "fix yaml test", "committedDate": "2020-07-30T10:19:09Z", "type": "commit"}, {"oid": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c", "url": "https://github.com/elastic/elasticsearch/commit/1f3c99593c9812bdd9eae80872b5a3a7e8b5652c", "message": "Merge branch 'master' into add-version-field", "committedDate": "2020-07-30T10:19:15Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkwMTg4Nw==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462901887", "bodyText": "Should we index BinaryPoint only when indexOptions() != IndexOptions.NONE (because currently this field will be indexed even when IndexOptions.NONE and stored=true) ?", "author": "mayya-sharipova", "createdAt": "2020-07-30T10:26:40Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();\n+            }\n+        }\n+\n+        if (versionString == null) {\n+            return;\n+        }\n+\n+        EncodedVersion encoding = encodeVersion(versionString);\n+        BytesRef encodedVersion = encoding.bytesRef;\n+        if (fieldType.indexOptions() != IndexOptions.NONE || fieldType.stored()) {\n+            Field field = new Field(fieldType().name(), encodedVersion, fieldType);\n+            context.doc().add(field);\n+            // encode the first 16 bytes as points for efficient range query\n+            byte[] first16bytes = Arrays.copyOfRange(encodedVersion.bytes, encodedVersion.offset, 16);\n+            context.doc().add(new BinaryPoint(fieldType().name(), first16bytes));", "originalCommit": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkwMzI2OQ==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462903269", "bodyText": "Should we create this field only when hasDocValues() == true?", "author": "mayya-sharipova", "createdAt": "2020-07-30T10:29:21Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();\n+            }\n+        }\n+\n+        if (versionString == null) {\n+            return;\n+        }\n+\n+        EncodedVersion encoding = encodeVersion(versionString);\n+        BytesRef encodedVersion = encoding.bytesRef;\n+        if (fieldType.indexOptions() != IndexOptions.NONE || fieldType.stored()) {\n+            Field field = new Field(fieldType().name(), encodedVersion, fieldType);\n+            context.doc().add(field);\n+            // encode the first 16 bytes as points for efficient range query\n+            byte[] first16bytes = Arrays.copyOfRange(encodedVersion.bytes, encodedVersion.offset, 16);\n+            context.doc().add(new BinaryPoint(fieldType().name(), first16bytes));\n+        }\n+        context.doc().add(new SortedSetDocValuesField(fieldType().name(), encodedVersion));", "originalCommit": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkzMDUyNA==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462930524", "bodyText": "Sure. I was also thinking about always setting \"docValue == true\" for this field regardless of the users settings. I think @jpountz suggested this at some point during reviewing the draft, maybe he can restate this opinion here?", "author": "cbuescher", "createdAt": "2020-07-30T11:26:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkwMzI2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzIwMjU1MA==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r477202550", "bodyText": "I updated the PR so we now don't allow disabling doc_values for this specialized field, so it will always be true.", "author": "cbuescher", "createdAt": "2020-08-26T10:35:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkwMzI2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkwMzc1Nw==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462903757", "bodyText": "Should we create all the fields below only when indexOptions() != IndexOptions.NONE  and SortedNumericDocValuesField when hasDocValues() == true?", "author": "mayya-sharipova", "createdAt": "2020-07-30T10:30:15Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();\n+            }\n+        }\n+\n+        if (versionString == null) {\n+            return;\n+        }\n+\n+        EncodedVersion encoding = encodeVersion(versionString);\n+        BytesRef encodedVersion = encoding.bytesRef;\n+        if (fieldType.indexOptions() != IndexOptions.NONE || fieldType.stored()) {\n+            Field field = new Field(fieldType().name(), encodedVersion, fieldType);\n+            context.doc().add(field);\n+            // encode the first 16 bytes as points for efficient range query\n+            byte[] first16bytes = Arrays.copyOfRange(encodedVersion.bytes, encodedVersion.offset, 16);\n+            context.doc().add(new BinaryPoint(fieldType().name(), first16bytes));\n+        }\n+        context.doc().add(new SortedSetDocValuesField(fieldType().name(), encodedVersion));\n+\n+        // add additional information extracted from version string", "originalCommit": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzIwMjg1Mg==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r477202852", "bodyText": "I updated the PR so we now don't allow disabling doc_values or setting specific index options for this specialized field.", "author": "cbuescher", "createdAt": "2020-08-26T10:35:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkwMzc1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkwOTAzOQ==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462909039", "bodyText": "I am wondering if this query still should be considering expensive if with  a binaryPoint query we can efficiently narrow down terms?", "author": "mayya-sharipova", "createdAt": "2020-07-30T10:41:08Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {", "originalCommit": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkxMzgxOA==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462913818", "bodyText": "I was also wondering since lowerTerm and upperTerm represent valid versions can we extract major, minor, patch fields  and use them for querying to further narrow down terms?", "author": "mayya-sharipova", "createdAt": "2020-07-30T10:51:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkwOTAzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkyOTc3Mw==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462929773", "bodyText": "lower and upper don't necessarily represent valid versions, we'd also be able to use non-semver versions that then sort above the valid ones. Major/Minor/Patch might be not available for them.  As for the expensive part, I'm happy to change, I'm not familiar enough with the cost of binaryPoint so I'd follow your judgement or if anyone else has an opinion on this.", "author": "cbuescher", "createdAt": "2020-07-30T11:25:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkwOTAzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkyMzc3Mg==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462923772", "bodyText": "I don't think we should apply this setting here. It's a specialized type so we should make this query fast and/or harmless if it's useful ?", "author": "jimczi", "createdAt": "2020-07-30T11:12:26Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {", "originalCommit": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDk1Mjk1Ng==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r490952956", "bodyText": "Can you remove the check please", "author": "jimczi", "createdAt": "2020-09-18T13:34:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkyMzc3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkzNzI2NQ==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462937265", "bodyText": "For specialized type we're trying to limit the number of options. It's perfectly ok to have a new field with no option at all so I think we should start with a clean state and discuss any addition.", "author": "jimczi", "createdAt": "2020-07-30T11:41:07Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);", "originalCommit": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzAxMjc5MA==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r463012790", "bodyText": "Would that include common options like \"meta\" or \"boost\"? It would certainly simplify things if we would had fixed 'index_options' or 'doc_values'  settings. My impression was that people would like to use this like a keyword field and expect certain basic options.", "author": "cbuescher", "createdAt": "2020-07-30T13:53:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkzNzI2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzIwMzgwMQ==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r477203801", "bodyText": "I updated the PR so the mapper now extends ParametrizedFieldMapper, which limits the number of options. I only added parsing for \"meta\" field for now since we seem to want to support this for all fields.", "author": "cbuescher", "createdAt": "2020-08-26T10:37:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkzNzI2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkzODgxNQ==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462938815", "bodyText": "I'd assume that we are in control and that the index_options are fixed. These options are not relevant in this context imo.", "author": "jimczi", "createdAt": "2020-07-30T11:44:35Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();\n+            }\n+        }\n+\n+        if (versionString == null) {\n+            return;\n+        }\n+\n+        EncodedVersion encoding = encodeVersion(versionString);\n+        BytesRef encodedVersion = encoding.bytesRef;\n+        if (fieldType.indexOptions() != IndexOptions.NONE || fieldType.stored()) {", "originalCommit": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzAxMzcwNQ==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r463013705", "bodyText": "Happy to not allow configurable ' index_options' and e.g. also assume 'doc_values'  are always turned on (if we decide thats where to store the full encoded version)", "author": "cbuescher", "createdAt": "2020-07-30T13:55:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkzODgxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzIwNDA4MA==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r477204080", "bodyText": "index_options are now fixed with a recent update", "author": "cbuescher", "createdAt": "2020-08-26T10:38:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkzODgxNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjk0MTkyMw==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462941923", "bodyText": "I don't see any use of these fields in queries. Is it for future optimizations ? That seems premature, the primary heuristic should be quite fast already.", "author": "jimczi", "createdAt": "2020-07-30T11:51:28Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();\n+            }\n+        }\n+\n+        if (versionString == null) {\n+            return;\n+        }\n+\n+        EncodedVersion encoding = encodeVersion(versionString);\n+        BytesRef encodedVersion = encoding.bytesRef;\n+        if (fieldType.indexOptions() != IndexOptions.NONE || fieldType.stored()) {\n+            Field field = new Field(fieldType().name(), encodedVersion, fieldType);\n+            context.doc().add(field);\n+            // encode the first 16 bytes as points for efficient range query\n+            byte[] first16bytes = Arrays.copyOfRange(encodedVersion.bytes, encodedVersion.offset, 16);\n+            context.doc().add(new BinaryPoint(fieldType().name(), first16bytes));\n+        }\n+        context.doc().add(new SortedSetDocValuesField(fieldType().name(), encodedVersion));\n+\n+        // add additional information extracted from version string\n+        context.doc().add(new Field(prereleaseSubField.name(), encoding.isPreRelease ? \"T\" : \"F\", BooleanFieldMapper.Defaults.FIELD_TYPE));\n+        context.doc().add(new SortedNumericDocValuesField(prereleaseSubField.name(), encoding.isPreRelease ? 1 : 0));\n+\n+        addVersionPartSubfield(context, majorVersionSubField.name(), encoding.major);\n+        addVersionPartSubfield(context, minorVersionSubField.name(), encoding.minor);\n+        addVersionPartSubfield(context, patchVersionSubField.name(), encoding.patch);\n+    }\n+\n+    private void addVersionPartSubfield(ParseContext context, String fieldName, Integer versionPart) {\n+        if (versionPart != null) {\n+            context.doc().addAll(NumberType.INTEGER.createFields(fieldName, versionPart, true, true, false));", "originalCommit": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjk0MjM1NQ==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462942355", "bodyText": "There's also the cost of indexing three more points so I'd lean towards limiting the number of indexed/points fields.", "author": "jimczi", "createdAt": "2020-07-30T11:52:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjk0MTkyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzAxMDM0MA==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r463010340", "bodyText": "This is not aimed at making the range queries faster like in indexing the 16 byte prefix as point. I added these fields because the telemetry team have the use case that they want to filter and aggregate on mayor / minor version (maybe patch), e.g. with histograms or terms aggregations. Think along the lines of \"give me a breakdown of all mayor/minor/patch\" versions running in my cluster. That information would otherwise have to be parsed out again on aggregations e.g. by scripts, so adding these field will make these kind of aggregations faster. I was considering having to switch these additional subfields on with a type parameter so its not done by default.", "author": "cbuescher", "createdAt": "2020-07-30T13:50:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjk0MTkyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzU5OTI1MQ==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r463599251", "bodyText": "Ok thanks for explaining. Although I think we should discuss more alternatives to handle these requirements. Extracting the major/minor/patch shouldn't be considered costly in aggregations for instance. We also have plenty of ways to make the decoding faster if needed.\nQuerying all 0 minor should also  be possible with the full version so I'd prefer to find an alternative that doesn't require 3 additional fields.", "author": "jimczi", "createdAt": "2020-07-31T13:06:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjk0MTkyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjk0OTI1OA==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462949258", "bodyText": "That seems redundant. If I understand correctly, the encoded version is stored in three structures:\n\n\nFully encoded version in Postings\n\n\nThe first 16 bytes of the encoded version in Points\n\n\nFully encoded version in SortedSetDocValues\n\n\nThe main benefit of indexing Points is that you don't need the postings. We can use them as an approximation and rely on the doc values to validate matches in a range query. Prefix, wildcard, regex are more tricky to handle with Points so I guess that is why you also create an indexed Field. However, I think we should only pick one strategy. The current approach is too costly imo, we should control the indexing cost more carefully.", "author": "jimczi", "createdAt": "2020-07-30T12:07:38Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();\n+            }\n+        }\n+\n+        if (versionString == null) {\n+            return;\n+        }\n+\n+        EncodedVersion encoding = encodeVersion(versionString);\n+        BytesRef encodedVersion = encoding.bytesRef;\n+        if (fieldType.indexOptions() != IndexOptions.NONE || fieldType.stored()) {\n+            Field field = new Field(fieldType().name(), encodedVersion, fieldType);", "originalCommit": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjk1NTQ4MQ==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r462955481", "bodyText": "The two queries that you mixed are totally independent so the resulting boolean query is just more costly than a plain TermRangeQuery.\nThe idea behind using a prefix query on Points is that you can use the doc values to validate the matches. You can check how the wildcard field does  since it's very similar. The AutomatonQueryOnBinaryDv leverages the TwoPhaseIterator to only validate documents found by other filter (the point range query approximation).\nAs I said in previous comments, I think we need to make a choice. Relying on Points or Postings is ok but not both.", "author": "jimczi", "createdAt": "2020-07-30T12:19:43Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();", "originalCommit": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzY0MjYxMg==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r463642612", "bodyText": "Thanks, I looked into this and hope I understood things right. I pushed cfe2dba which follows a simiar approach as AutomatonQueryOnBinaryDv but works on SortedSet doc values.", "author": "cbuescher", "createdAt": "2020-07-31T14:25:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjk1NTQ4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzE5OTQyNQ==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r477199425", "bodyText": "After talking again about this I changed the range validation query again in eaa1ef8. Since we also talked about not using Points at all I will use this version when comparing to a solution that doesn't use Points at all (a simple TermRangeQuery)", "author": "cbuescher", "createdAt": "2020-08-26T10:29:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjk1NTQ4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzE3MjE5NA==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r463172194", "bodyText": "Do you need to register this format in NamedWriteableRegistry like we register other format in SearchModule#registerValueFormats?", "author": "mayya-sharipova", "createdAt": "2020-07-30T17:55:35Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,526 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperParsingException;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.TypeParsers;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends FieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+\n+        public static final String NULL_VALUE = null;\n+    }\n+\n+    static class Builder extends FieldMapper.Builder<Builder> {\n+\n+        protected String nullValue = Defaults.NULL_VALUE;\n+\n+        Builder(String name) {\n+            super(name, Defaults.FIELD_TYPE);\n+            builder = this;\n+        }\n+\n+        Builder nullValue(String nullValue) {\n+            this.nullValue = nullValue;\n+            return builder;\n+        }\n+\n+        @Override\n+        public Builder indexOptions(IndexOptions indexOptions) {\n+            throw new MapperParsingException(\"index_options not allowed in field [\" + name + \"] of type [version]\");\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context) {\n+            return new VersionStringFieldType(buildFullName(context), indexed, meta, boost, fieldType);\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type).nullValue(0);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type).nullValue(0);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type).nullValue(0);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldType,\n+                buildFieldType(context),\n+                nullValue,\n+                multiFieldsBuilder.build(this, context),\n+                copyTo,\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+    }\n+\n+    public static class TypeParser implements Mapper.TypeParser {\n+\n+        public TypeParser() {}\n+\n+        @Override\n+        public Mapper.Builder<?> parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {\n+            Builder builder = new Builder(name);\n+            TypeParsers.parseField(builder, name, node, parserContext);\n+            for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {\n+                Map.Entry<String, Object> entry = iterator.next();\n+                String propName = entry.getKey();\n+                Object propNode = entry.getValue();\n+                if (propName.equals(\"null_value\")) {\n+                    if (propNode == null) {\n+                        throw new MapperParsingException(\"Property [null_value] cannot be null.\");\n+                    }\n+                    builder.nullValue(propNode.toString());\n+                    iterator.remove();\n+                }\n+            }\n+            return builder;\n+        }\n+    }\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, boolean isSearchable, Map<String, String> meta, float boost, FieldType fieldType) {\n+            super(name, isSearchable, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+            setBoost(boost);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int flags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), flags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query termQuery = new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,\n+                upperTerm == null ? null : upper,\n+                includeLower,\n+                includeUpper\n+            );\n+\n+            return new BooleanQuery.Builder().add(new BooleanClause(pointPrefixQuery, Occur.MUST))\n+                .add(new BooleanClause(termQuery, Occur.MUST))\n+                .build();\n+        }\n+    }\n+\n+    private String nullValue;\n+    private BooleanFieldMapper prereleaseSubField;\n+    private NumberFieldMapper majorVersionSubField;\n+    private NumberFieldMapper minorVersionSubField;\n+    private NumberFieldMapper patchVersionSubField;\n+\n+    private VersionStringFieldMapper(\n+        String simpleName,\n+        FieldType fieldType,\n+        MappedFieldType mappedFieldType,\n+        String nullValue,\n+        MultiFields multiFields,\n+        CopyTo copyTo,\n+        BooleanFieldMapper preReleaseMapper,\n+        NumberFieldMapper majorVersionMapper,\n+        NumberFieldMapper minorVersionMapper,\n+        NumberFieldMapper patchVersionMapper\n+    ) {\n+        super(simpleName, fieldType, mappedFieldType, multiFields, copyTo);\n+        this.nullValue = nullValue;\n+        this.prereleaseSubField = preReleaseMapper;\n+        this.majorVersionSubField = majorVersionMapper;\n+        this.minorVersionSubField = minorVersionMapper;\n+        this.patchVersionSubField = patchVersionMapper;\n+    }\n+\n+    @Override\n+    public VersionStringFieldType fieldType() {\n+        return (VersionStringFieldType) super.fieldType();\n+    }\n+\n+    @Override\n+    protected String contentType() {\n+        return CONTENT_TYPE;\n+    }\n+\n+    @Override\n+    protected VersionStringFieldMapper clone() {\n+        return (VersionStringFieldMapper) super.clone();\n+    }\n+\n+    @Override\n+    protected void parseCreateField(ParseContext context) throws IOException {\n+        String versionString;\n+        if (context.externalValueSet()) {\n+            versionString = context.externalValue().toString();\n+        } else {\n+            XContentParser parser = context.parser();\n+            if (parser.currentToken() == XContentParser.Token.VALUE_NULL) {\n+                versionString = nullValue;\n+            } else {\n+                versionString = parser.textOrNull();\n+            }\n+        }\n+\n+        if (versionString == null) {\n+            return;\n+        }\n+\n+        EncodedVersion encoding = encodeVersion(versionString);\n+        BytesRef encodedVersion = encoding.bytesRef;\n+        if (fieldType.indexOptions() != IndexOptions.NONE || fieldType.stored()) {\n+            Field field = new Field(fieldType().name(), encodedVersion, fieldType);\n+            context.doc().add(field);\n+            // encode the first 16 bytes as points for efficient range query\n+            byte[] first16bytes = Arrays.copyOfRange(encodedVersion.bytes, encodedVersion.offset, 16);\n+            context.doc().add(new BinaryPoint(fieldType().name(), first16bytes));\n+        }\n+        context.doc().add(new SortedSetDocValuesField(fieldType().name(), encodedVersion));\n+\n+        // add additional information extracted from version string\n+        context.doc().add(new Field(prereleaseSubField.name(), encoding.isPreRelease ? \"T\" : \"F\", BooleanFieldMapper.Defaults.FIELD_TYPE));\n+        context.doc().add(new SortedNumericDocValuesField(prereleaseSubField.name(), encoding.isPreRelease ? 1 : 0));\n+\n+        addVersionPartSubfield(context, majorVersionSubField.name(), encoding.major);\n+        addVersionPartSubfield(context, minorVersionSubField.name(), encoding.minor);\n+        addVersionPartSubfield(context, patchVersionSubField.name(), encoding.patch);\n+    }\n+\n+    private void addVersionPartSubfield(ParseContext context, String fieldName, Integer versionPart) {\n+        if (versionPart != null) {\n+            context.doc().addAll(NumberType.INTEGER.createFields(fieldName, versionPart, true, true, false));\n+        }\n+    }\n+\n+    @Override\n+    protected void mergeOptions(FieldMapper other, List<String> conflicts) {\n+        VersionStringFieldMapper mergeWith = (VersionStringFieldMapper) other;\n+        this.nullValue = mergeWith.nullValue;\n+    }\n+\n+    @Override\n+    protected void doXContentBody(XContentBuilder builder, boolean includeDefaults, Params params) throws IOException {\n+        super.doXContentBody(builder, includeDefaults, params);\n+        if (nullValue != null) {\n+            builder.field(\"null_value\", nullValue);\n+        }\n+    }\n+\n+    @Override\n+    public Iterator<Mapper> iterator() {\n+        List<Mapper> subIterators = new ArrayList<>();\n+        subIterators.add(prereleaseSubField);\n+        subIterators.add(majorVersionSubField);\n+        subIterators.add(minorVersionSubField);\n+        subIterators.add(patchVersionSubField);\n+        @SuppressWarnings(\"unchecked\")\n+        Iterator<Mapper> concat = Iterators.concat(super.iterator(), subIterators.iterator());\n+        return concat;\n+    }\n+\n+    @Override\n+    protected Object parseSourceValue(Object value, String format) {\n+        if (format != null) {\n+            throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] doesn't support formats.\");\n+        }\n+        return value.toString();\n+    }\n+\n+    private static DocValueFormat VERSION_DOCVALUE = new DocValueFormat() {", "originalCommit": "1f3c99593c9812bdd9eae80872b5a3a7e8b5652c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzY1Mzc0NA==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r463653744", "bodyText": "Good point, I guess this hasn't shown up in tests yet because they are mostly single node. I'll see if this would e.g. fail a yaml aggs test. I can probably register this in the plugin.", "author": "cbuescher", "createdAt": "2020-07-31T14:44:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzE3MjE5NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzc5NjgxMw==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r463796813", "bodyText": "I added c70e7c1 to register the format and an IT test that would have caught this when serializing aggregations across nodes. Thanks for catching this!", "author": "cbuescher", "createdAt": "2020-07-31T19:38:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzE3MjE5NA=="}], "type": "inlineReview"}, {"oid": "cfe2dbab69de9fd5e84c46de8a274f69c8514cf9", "url": "https://github.com/elastic/elasticsearch/commit/cfe2dbab69de9fd5e84c46de8a274f69c8514cf9", "message": "Change range query to points approximation and dv validation", "committedDate": "2020-07-31T14:23:04Z", "type": "commit"}, {"oid": "c70e7c1d0d98915ec25d97cba02fb790dbd57c60", "url": "https://github.com/elastic/elasticsearch/commit/c70e7c1d0d98915ec25d97cba02fb790dbd57c60", "message": "Register DocValueFormat via plugin", "committedDate": "2020-07-31T19:36:25Z", "type": "commit"}, {"oid": "e45ef4a468063de43acedb7251be529ade0f2ae5", "url": "https://github.com/elastic/elasticsearch/commit/e45ef4a468063de43acedb7251be529ade0f2ae5", "message": "Merge branch 'master' into add-version-field", "committedDate": "2020-08-17T13:08:34Z", "type": "commit"}, {"oid": "24651d17dbbc252a87eb75c70462b6f699a9b56f", "url": "https://github.com/elastic/elasticsearch/commit/24651d17dbbc252a87eb75c70462b6f699a9b56f", "message": "Merge branch 'master' into add-version-field", "committedDate": "2020-08-20T14:24:15Z", "type": "commit"}, {"oid": "57b040f04cace55f54f3ecf40e37dbbbdb17ac05", "url": "https://github.com/elastic/elasticsearch/commit/57b040f04cace55f54f3ecf40e37dbbbdb17ac05", "message": "Add valueFetcher() method", "committedDate": "2020-08-20T14:36:07Z", "type": "commit"}, {"oid": "c321e0dc4bb7c4124131fb8debcfa59bfe9e48bf", "url": "https://github.com/elastic/elasticsearch/commit/c321e0dc4bb7c4124131fb8debcfa59bfe9e48bf", "message": "Merge branch 'master' of github.com:elastic/elasticsearch into add-version-field", "committedDate": "2020-08-21T09:28:56Z", "type": "commit"}, {"oid": "5b902fb308a8e4c8144891bdb6983fe2b44dabeb", "url": "https://github.com/elastic/elasticsearch/commit/5b902fb308a8e4c8144891bdb6983fe2b44dabeb", "message": "Restrict field options by moving to ParametrizedFieldMapper", "committedDate": "2020-08-21T18:12:47Z", "type": "commit"}, {"oid": "758b83494c7c08d165291556cfa60bb2f6223aed", "url": "https://github.com/elastic/elasticsearch/commit/758b83494c7c08d165291556cfa60bb2f6223aed", "message": "Merge branch 'master' into add-version-field", "committedDate": "2020-08-26T10:20:21Z", "type": "commit"}, {"oid": "eaa1ef8dd3ba0a8f4cd7ec646bf3ebecd726c801", "url": "https://github.com/elastic/elasticsearch/commit/eaa1ef8dd3ba0a8f4cd7ec646bf3ebecd726c801", "message": "Change range query validation part", "committedDate": "2020-08-26T10:26:11Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDAzNDgxMQ==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r480034811", "bodyText": "You don't need to add the validation query if the lower and upper values have less than 17 bytes ?", "author": "jimczi", "createdAt": "2020-08-31T10:25:34Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,483 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.BinaryPoint;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.BooleanClause.Occur;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.ConstantScoreQuery;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery87;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.BooleanFieldMapper;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();\n+\n+        Builder(String name) {\n+            super(name);\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context, FieldType fieldtype) {\n+            return new VersionStringFieldType(buildFullName(context), fieldtype, meta.getValue());\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            FieldType fieldtype = new FieldType(Defaults.FIELD_TYPE);\n+            BooleanFieldMapper.Builder preReleaseSubfield = new BooleanFieldMapper.Builder(name + \".isPreRelease\");\n+            NumberType type = NumberType.INTEGER;\n+            NumberFieldMapper.Builder majorVersionSubField = new NumberFieldMapper.Builder(name + \".major\", type, false, false);\n+            NumberFieldMapper.Builder minorVersionSubField = new NumberFieldMapper.Builder(name + \".minor\", type, false, false);\n+            NumberFieldMapper.Builder patchVersionSubField = new NumberFieldMapper.Builder(name + \".patch\", type, false, false);\n+\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldtype,\n+                buildFieldType(context, fieldtype),\n+                multiFieldsBuilder.build(this, context),\n+                copyTo.build(),\n+                preReleaseSubfield.build(context),\n+                majorVersionSubField.build(context),\n+                minorVersionSubField.build(context),\n+                patchVersionSubField.build(context)\n+            );\n+        }\n+\n+        @Override\n+        protected List<Parameter<?>> getParameters() {\n+            return List.of(meta);\n+        }\n+    }\n+\n+    public static final TypeParser PARSER = new TypeParser((n, c) -> new Builder(n));\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n+            super(name, true, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int syntaxFlags,\n+            int matchFlags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery87 query = new RegexpQuery87(new Term(name(), new BytesRef(value)), syntaxFlags, matchFlags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+            byte[] lowerBytes = lower == null ? MIN_VALUE : Arrays.copyOfRange(lower.bytes, lower.offset, 16);\n+            byte[] upperBytes = upper == null ? MAX_VALUE : Arrays.copyOfRange(upper.bytes, upper.offset, 16);\n+\n+            // point query on the 16byte prefix\n+            Query pointPrefixQuery = BinaryPoint.newRangeQuery(name(), lowerBytes, upperBytes);\n+\n+            Query validationQuery = SortedSetDocValuesField.newSlowRangeQuery(name(), lower, upper, includeLower, includeUpper);", "originalCommit": "eaa1ef8dd3ba0a8f4cd7ec646bf3ebecd726c801", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDAzNTU1MA==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r480035550", "bodyText": "The validation can also be avoided on values that have less than 17 bytes so you'll maybe need a custom validation query ?\nThe slow range query uses ordinals so it's probably not needed ^^", "author": "jimczi", "createdAt": "2020-08-31T10:27:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDAzNDgxMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDE1MzM1Mw==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r480153353", "bodyText": "Good point, I probably still want to use it if includeLower or includeUpper is false since the points query will always contain the edges as far as I've seen from previous tests. I will push an update on this before I continue with testing vs. TermRangeQuery using only postings.", "author": "cbuescher", "createdAt": "2020-08-31T14:04:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDAzNDgxMQ=="}], "type": "inlineReview"}, {"oid": "82a40abaaade4f96bf5bc84b5b37591fa544f770", "url": "https://github.com/elastic/elasticsearch/commit/82a40abaaade4f96bf5bc84b5b37591fa544f770", "message": "Small improvement to range query using points", "committedDate": "2020-08-31T14:06:35Z", "type": "commit"}, {"oid": "dacf8134bbb479673753d06b269cf0503b206de4", "url": "https://github.com/elastic/elasticsearch/commit/dacf8134bbb479673753d06b269cf0503b206de4", "message": "Merge branch 'master' into add-version-field", "committedDate": "2020-08-31T14:42:21Z", "type": "commit"}, {"oid": "e4b0728c0bae90c936bb1dd926d2ec4c6f247b81", "url": "https://github.com/elastic/elasticsearch/commit/e4b0728c0bae90c936bb1dd926d2ec4c6f247b81", "message": "Add helper methods to versions ScriptDocValues to help with version part extraction", "committedDate": "2020-09-02T16:22:31Z", "type": "commit"}, {"oid": "3c72862f77aceecd1648f6c058ac79473db6d4c4", "url": "https://github.com/elastic/elasticsearch/commit/3c72862f77aceecd1648f6c058ac79473db6d4c4", "message": "Merge branch 'master' into add-version-field", "committedDate": "2020-09-02T16:23:05Z", "type": "commit"}, {"oid": "4de9a2ed24d167c83974a2d29a0a0893183fe8be", "url": "https://github.com/elastic/elasticsearch/commit/4de9a2ed24d167c83974a2d29a0a0893183fe8be", "message": "Merge branch 'master' into add-version-field", "committedDate": "2020-09-08T12:23:30Z", "type": "commit"}, {"oid": "6c3266e055fd91ba16d22ecb72b9a5604b1724d3", "url": "https://github.com/elastic/elasticsearch/commit/6c3266e055fd91ba16d22ecb72b9a5604b1724d3", "message": "Removing points and subfields", "committedDate": "2020-09-08T12:36:48Z", "type": "commit"}, {"oid": "b26a3f1864d7f1fa2e9af3e9fced4beb941ab2d0", "url": "https://github.com/elastic/elasticsearch/commit/b26a3f1864d7f1fa2e9af3e9fced4beb941ab2d0", "message": "Add tests for new regex case-insensitivity option", "committedDate": "2020-09-08T14:21:05Z", "type": "commit"}, {"oid": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb", "url": "https://github.com/elastic/elasticsearch/commit/c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb", "message": "Adding docs", "committedDate": "2020-09-09T14:21:09Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzgwNzcyMg==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487807722", "bodyText": "Does this plugin need to implement ActionPlugin? It doesn't look like it provides new actions.", "author": "mayya-sharipova", "createdAt": "2020-09-14T10:23:50Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionFieldPlugin.java", "diffHunk": "@@ -0,0 +1,39 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.elasticsearch.common.io.stream.NamedWriteableRegistry;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.plugins.ActionPlugin;\n+import org.elasticsearch.plugins.MapperPlugin;\n+import org.elasticsearch.plugins.Plugin;\n+import org.elasticsearch.search.DocValueFormat;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+public class VersionFieldPlugin extends Plugin implements ActionPlugin, MapperPlugin {", "originalCommit": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzgyMjI4Mw==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487822283", "bodyText": "I am wondering  if we should also have  a doc_values parameter?\nSince our range query doesn't depend on doc_values anymore, I am thinking may be a user can opt out of indexing doc_values if they don't need sorting, aggregation of this field, and script queries on pre-release, major, minor and patch", "author": "mayya-sharipova", "createdAt": "2020-09-14T10:51:47Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.search.lookup.SearchLookup;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();", "originalCommit": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg4Mjc0MQ==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487882741", "bodyText": "I'm on the fence with this suggestion. I think the specialized sorting is one of the main features for using this field type, so I would assume most users wouldn't want to turn doc_values of. Maybe we can start without this option and add it if this is a really frequent ask (to save on storage spave while willing to pay the loss of functionality here)?", "author": "cbuescher", "createdAt": "2020-09-14T12:45:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzgyMjI4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg2MjM0NA==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487862344", "bodyText": "if we decide to always index a field with doc values, this failIfNoDocValues() check seems unnecessary.", "author": "mayya-sharipova", "createdAt": "2020-09-14T12:10:50Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.search.lookup.SearchLookup;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();\n+\n+        Builder(String name) {\n+            super(name);\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context, FieldType fieldtype) {\n+            return new VersionStringFieldType(buildFullName(context), fieldtype, meta.getValue());\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            FieldType fieldtype = new FieldType(Defaults.FIELD_TYPE);\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldtype,\n+                buildFieldType(context, fieldtype),\n+                multiFieldsBuilder.build(this, context),\n+                copyTo.build()\n+            );\n+        }\n+\n+        @Override\n+        protected List<Parameter<?>> getParameters() {\n+            return List.of(meta);\n+        }\n+    }\n+\n+    public static final TypeParser PARSER = new TypeParser((n, c) -> new Builder(n));\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n+            super(name, true, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int syntaxFlags,\n+            int matchFlags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), syntaxFlags, matchFlags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName, Supplier<SearchLookup> searchLookup) {\n+            failIfNoDocValues();", "originalCommit": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg2NDMxOA==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487864318", "bodyText": "from your last benchmarking tests, rangeQuery doesn't seem to be expensive, so this check to allow expensive queries looks unnecessary to me. WDYT?", "author": "mayya-sharipova", "createdAt": "2020-09-14T12:14:27Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.search.lookup.SearchLookup;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();\n+\n+        Builder(String name) {\n+            super(name);\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context, FieldType fieldtype) {\n+            return new VersionStringFieldType(buildFullName(context), fieldtype, meta.getValue());\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            FieldType fieldtype = new FieldType(Defaults.FIELD_TYPE);\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldtype,\n+                buildFieldType(context, fieldtype),\n+                multiFieldsBuilder.build(this, context),\n+                copyTo.build()\n+            );\n+        }\n+\n+        @Override\n+        protected List<Parameter<?>> getParameters() {\n+            return List.of(meta);\n+        }\n+    }\n+\n+    public static final TypeParser PARSER = new TypeParser((n, c) -> new Builder(n));\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n+            super(name, true, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int syntaxFlags,\n+            int matchFlags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), syntaxFlags, matchFlags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName, Supplier<SearchLookup> searchLookup) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {", "originalCommit": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzkwODI3OQ==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487908279", "bodyText": "While I'm happy removing this check, the same check exists for keyword fields via StringFieldType#rangeQuery() which is also using TermRangeQuery under the hood. While we expect the dictionary size for version fields to be lower, we cannot be sure users are not (by accident) misusing this field to store hundreds of thousands of version strings, in which case performance should be similar to keyword field performance which we currently guard for by checking \"allowExpensiveQueries()\". Wdyt?", "author": "cbuescher", "createdAt": "2020-09-14T13:23:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg2NDMxOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODY1NjAyMg==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r488656022", "bodyText": "Thanks, I am also ok to have this check for consistency with StringFieldType.", "author": "mayya-sharipova", "createdAt": "2020-09-15T13:14:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg2NDMxOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDMzNzI5Ng==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r490337296", "bodyText": "Unlike keyword, range queries are the most important part of this field so I'd prefer that we ignore the allowExpensiveQueries in this field.", "author": "jimczi", "createdAt": "2020-09-17T15:19:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg2NDMxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg2NTExMQ==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487865111", "bodyText": "Doesn't seem that a user has an option not to index a field. So this check looks unnecessary", "author": "mayya-sharipova", "createdAt": "2020-09-14T12:15:56Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.search.lookup.SearchLookup;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();\n+\n+        Builder(String name) {\n+            super(name);\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context, FieldType fieldtype) {\n+            return new VersionStringFieldType(buildFullName(context), fieldtype, meta.getValue());\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            FieldType fieldtype = new FieldType(Defaults.FIELD_TYPE);\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldtype,\n+                buildFieldType(context, fieldtype),\n+                multiFieldsBuilder.build(this, context),\n+                copyTo.build()\n+            );\n+        }\n+\n+        @Override\n+        protected List<Parameter<?>> getParameters() {\n+            return List.of(meta);\n+        }\n+    }\n+\n+    public static final TypeParser PARSER = new TypeParser((n, c) -> new Builder(n));\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n+            super(name, true, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int syntaxFlags,\n+            int matchFlags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), syntaxFlags, matchFlags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName, Supplier<SearchLookup> searchLookup) {\n+            failIfNoDocValues();\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[range] queries on [version] fields cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false.\"\n+                );\n+            }\n+            failIfNotIndexed();", "originalCommit": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg2OTgwNw==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487869807", "bodyText": "nit: \"rexexp\"  -> \"regexp\"", "author": "mayya-sharipova", "createdAt": "2020-09-14T12:24:21Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.search.lookup.SearchLookup;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();\n+\n+        Builder(String name) {\n+            super(name);\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context, FieldType fieldtype) {\n+            return new VersionStringFieldType(buildFullName(context), fieldtype, meta.getValue());\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            FieldType fieldtype = new FieldType(Defaults.FIELD_TYPE);\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldtype,\n+                buildFieldType(context, fieldtype),\n+                multiFieldsBuilder.build(this, context),\n+                copyTo.build()\n+            );\n+        }\n+\n+        @Override\n+        protected List<Parameter<?>> getParameters() {\n+            return List.of(meta);\n+        }\n+    }\n+\n+    public static final TypeParser PARSER = new TypeParser((n, c) -> new Builder(n));\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n+            super(name, true, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            failIfNotIndexed();\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"rexexp\" queries on this field rare enough to brute-force this", "originalCommit": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg4MTIyMQ==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487881221", "bodyText": "For other script doc values, if a document doesn't have a value, we raise an error. I was wondering if we should do the same here, or keyword based fields behave differently?", "author": "mayya-sharipova", "createdAt": "2020-09-14T12:43:08Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionScriptDocValues.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.index.SortedSetDocValues;\n+import org.apache.lucene.util.ArrayUtil;\n+import org.elasticsearch.index.fielddata.ScriptDocValues;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.VersionParts;\n+\n+import java.io.IOException;\n+\n+public final class VersionScriptDocValues extends ScriptDocValues<String> {\n+\n+    private final SortedSetDocValues in;\n+    private long[] ords = new long[0];\n+    private int count;\n+\n+    public VersionScriptDocValues(SortedSetDocValues in) {\n+        this.in = in;\n+    }\n+\n+    @Override\n+    public void setNextDocId(int docId) throws IOException {\n+        count = 0;\n+        if (in.advanceExact(docId)) {\n+            for (long ord = in.nextOrd(); ord != SortedSetDocValues.NO_MORE_ORDS; ord = in.nextOrd()) {\n+                ords = ArrayUtil.grow(ords, count + 1);\n+                ords[count++] = ord;\n+            }\n+        }\n+    }\n+\n+    public String getValue() {\n+        if (count == 0) {", "originalCommit": "c0c39bb74bb7af73c3a9eb102eb20b9f0f8778bb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg5NzAzNg==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r487897036", "bodyText": "Yes, this seems to be the behaviour for doc values on keyword field, so I'm going to switch to raising that error.", "author": "cbuescher", "createdAt": "2020-09-14T13:07:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzg4MTIyMQ=="}], "type": "inlineReview"}, {"oid": "d56499e2dc25ccfd36ca04bcf2b2b41deac96f6a", "url": "https://github.com/elastic/elasticsearch/commit/d56499e2dc25ccfd36ca04bcf2b2b41deac96f6a", "message": "Adressing review comments", "committedDate": "2020-09-14T13:09:03Z", "type": "commit"}, {"oid": "7e2a4f5d424cac715748646d38da41ec626a9f6f", "url": "https://github.com/elastic/elasticsearch/commit/7e2a4f5d424cac715748646d38da41ec626a9f6f", "message": "Merge branch 'master' into add-version-field", "committedDate": "2020-09-14T13:18:05Z", "type": "commit"}, {"oid": "94def2071ce68c386051a03cda6584892226bb14", "url": "https://github.com/elastic/elasticsearch/commit/94def2071ce68c386051a03cda6584892226bb14", "message": "Switch script method from isPreRelease to isRelease", "committedDate": "2020-09-15T12:44:47Z", "type": "commit"}, {"oid": "67df1d387a55c795eaecacb8e49640d3a42d24b1", "url": "https://github.com/elastic/elasticsearch/commit/67df1d387a55c795eaecacb8e49640d3a42d24b1", "message": "Merge branch 'master' into add-version-field", "committedDate": "2020-09-15T12:46:04Z", "type": "commit"}, {"oid": "67df1d387a55c795eaecacb8e49640d3a42d24b1", "url": "https://github.com/elastic/elasticsearch/commit/67df1d387a55c795eaecacb8e49640d3a42d24b1", "message": "Merge branch 'master' into add-version-field", "committedDate": "2020-09-15T12:46:04Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODY4NTMzNw==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r488685337", "bodyText": "new String(new String( -> should there be only a single new String?", "author": "mayya-sharipova", "createdAt": "2020-09-15T13:52:26Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionEncoder.java", "diffHunk": "@@ -0,0 +1,226 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.commons.codec.Charsets;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.BytesRefBuilder;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Encodes a version string to a {@link BytesRef} that correctly sorts according to software version precedence rules like\n+ * the ones described in Semantic Versioning (https://semver.org/)\n+ *\n+ * Version strings are considered to consist of three parts:\n+ * <ul>\n+ *  <li> a numeric major.minor.patch part starting the version string (e.g. 1.2.3)\n+ *  <li> an optional \"pre-release\" part that starts with a `-` character and can consist of several alphanumerical sections\n+ *  separated by dots (e.g. \"-alpha.2.3\")\n+ *  <li> an optional \"build\" part that starts with a `+` character. This will simply be treated as a suffix with ASCII sort order.\n+ * </ul>\n+ *\n+ * The version string is encoded such that the ordering works like the following:\n+ * <ul>\n+ *  <li> Major, minor, and patch versions are always compared numerically\n+ *  <li> pre-release version have lower precedence than a normal version. (e.g 1.0.0-alpha &lt; 1.0.0)\n+ *  <li> the precedence for pre-release versions with same main version is calculated comparing each dot separated identifier from\n+ *  left to right. Identifiers consisting of only digits are compared numerically and identifiers with letters or hyphens are compared\n+ *  lexically in ASCII sort order. Numeric identifiers always have lower precedence than non-numeric identifiers.\n+ * </ul>\n+ */\n+class VersionEncoder {\n+\n+    public static final byte NUMERIC_MARKER_BYTE = (byte) 0x01;\n+    public static final byte PRERELEASE_SEPARATOR_BYTE = (byte) 0x02;\n+    public static final byte NO_PRERELEASE_SEPARATOR_BYTE = (byte) 0x03;\n+\n+    private static final char PRERELEASE_SEPARATOR = '-';\n+    private static final char DOT_SEPARATOR = '.';\n+    private static final char BUILD_SEPARATOR = '+';\n+    private static final String ENCODED_EMPTY_STRING = new String(new String(new byte[] { NO_PRERELEASE_SEPARATOR_BYTE }, Charsets.UTF_8));", "originalCommit": "67df1d387a55c795eaecacb8e49640d3a42d24b1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODY4NjA4OA==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r488686088", "bodyText": "Heck yes!", "author": "cbuescher", "createdAt": "2020-09-15T13:53:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODY4NTMzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODg0ODY2OA==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r488848668", "bodyText": "Do you think we need to add some illegal versions and test that sort ASC will put them at the end?", "author": "mayya-sharipova", "createdAt": "2020-09-15T17:38:01Z", "path": "x-pack/plugin/versionfield/src/test/java/org/elasticsearch/xpack/versionfield/VersionStringFieldTests.java", "diffHunk": "@@ -0,0 +1,498 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.plugins.Plugin;\n+import org.elasticsearch.search.SearchHit;\n+import org.elasticsearch.search.aggregations.AggregationBuilders;\n+import org.elasticsearch.search.aggregations.bucket.terms.Terms;\n+import org.elasticsearch.search.aggregations.bucket.terms.Terms.Bucket;\n+import org.elasticsearch.search.aggregations.metrics.Cardinality;\n+import org.elasticsearch.search.sort.SortOrder;\n+import org.elasticsearch.test.ESSingleNodeTestCase;\n+import org.elasticsearch.xpack.analytics.AnalyticsAggregationBuilders;\n+import org.elasticsearch.xpack.analytics.AnalyticsPlugin;\n+import org.elasticsearch.xpack.analytics.stringstats.InternalStringStats;\n+import org.elasticsearch.xpack.core.LocalStateCompositeXPackPlugin;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class VersionStringFieldTests extends ESSingleNodeTestCase {\n+\n+    @Override\n+    protected Collection<Class<? extends Plugin>> getPlugins() {\n+        return pluginList(VersionFieldPlugin.class, LocalStateCompositeXPackPlugin.class, AnalyticsPlugin.class);\n+    }\n+\n+    public String setUpIndex(String indexName) throws IOException {\n+        createIndex(indexName, Settings.builder().put(\"index.number_of_shards\", 1).build(), \"_doc\", \"version\", \"type=version\");\n+        ensureGreen(indexName);\n+\n+        client().prepareIndex(indexName).setId(\"1\").setSource(jsonBuilder().startObject().field(\"version\", \"11.1.0\").endObject()).get();\n+        client().prepareIndex(indexName).setId(\"2\").setSource(jsonBuilder().startObject().field(\"version\", \"1.0.0\").endObject()).get();\n+        client().prepareIndex(indexName)\n+            .setId(\"3\")\n+            .setSource(jsonBuilder().startObject().field(\"version\", \"1.3.0+build.1234567\").endObject())\n+            .get();\n+        client().prepareIndex(indexName)\n+            .setId(\"4\")\n+            .setSource(jsonBuilder().startObject().field(\"version\", \"2.1.0-alpha.beta\").endObject())\n+            .get();\n+        client().prepareIndex(indexName).setId(\"5\").setSource(jsonBuilder().startObject().field(\"version\", \"2.1.0\").endObject()).get();\n+        client().prepareIndex(indexName).setId(\"6\").setSource(jsonBuilder().startObject().field(\"version\", \"21.11.0\").endObject()).get();\n+        client().admin().indices().prepareRefresh(indexName).get();\n+        return indexName;\n+    }\n+\n+    public void testExactQueries() throws Exception {\n+        String indexName = \"test\";\n+        setUpIndex(indexName);\n+\n+        // match\n+        SearchResponse response = client().prepareSearch(indexName).setQuery(QueryBuilders.matchQuery(\"version\", (\"1.0.0\"))).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.matchQuery(\"version\", \"1.4.0\")).get();\n+        assertEquals(0, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.matchQuery(\"version\", \"1.3.0\")).get();\n+        assertEquals(0, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.matchQuery(\"version\", \"1.3.0+build.1234567\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+\n+        // term\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.termQuery(\"version\", \"1.0.0\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.termQuery(\"version\", \"1.4.0\")).get();\n+        assertEquals(0, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.termQuery(\"version\", \"1.3.0\")).get();\n+        assertEquals(0, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.termQuery(\"version\", \"1.3.0+build.1234567\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+\n+        // terms\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.termsQuery(\"version\", \"1.0.0\", \"1.3.0\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.termsQuery(\"version\", \"1.4.0\", \"1.3.0+build.1234567\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+\n+        // phrase query (just for keyword compatibility)\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.matchPhraseQuery(\"version\", \"2.1.0-alpha.beta\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+    }\n+\n+    public void testRangeQueries() throws Exception {\n+        String indexName = setUpIndex(\"test\");\n+        SearchResponse response = client().prepareSearch(indexName)\n+            .setQuery(QueryBuilders.rangeQuery(\"version\").from(\"1.0.0\").to(\"3.0.0\"))\n+            .get();\n+        assertEquals(4, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.rangeQuery(\"version\").from(\"1.1.0\").to(\"3.0.0\")).get();\n+        assertEquals(3, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName)\n+            .setQuery(QueryBuilders.rangeQuery(\"version\").from(\"0.1.0\").to(\"2.1.0-alpha.beta\"))\n+            .get();\n+        assertEquals(3, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.rangeQuery(\"version\").from(\"2.1.0\").to(\"3.0.0\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.rangeQuery(\"version\").from(\"3.0.0\").to(\"4.0.0\")).get();\n+        assertEquals(0, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName)\n+            .setQuery(QueryBuilders.rangeQuery(\"version\").from(\"1.3.0+build.1234569\").to(\"3.0.0\"))\n+            .get();\n+        assertEquals(2, response.getHits().getTotalHits().value);\n+\n+        // ranges excluding edges\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.rangeQuery(\"version\").from(\"1.0.0\", false).to(\"3.0.0\")).get();\n+        assertEquals(3, response.getHits().getTotalHits().value);\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.rangeQuery(\"version\").from(\"1.0.0\").to(\"2.1.0\", false)).get();\n+        assertEquals(3, response.getHits().getTotalHits().value);\n+\n+        // open ranges\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.rangeQuery(\"version\").from(\"1.4.0\")).get();\n+        assertEquals(4, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.rangeQuery(\"version\").to(\"1.4.0\")).get();\n+        assertEquals(2, response.getHits().getTotalHits().value);\n+    }\n+\n+    public void testPrefixQuery() throws IOException {\n+        String indexName = setUpIndex(\"test\");\n+        // prefix\n+        SearchResponse response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"1\")).get();\n+        assertEquals(3, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"2.1\")).get();\n+        assertEquals(2, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"2.1.0-\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"1.3.0+b\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"2\")).get();\n+        assertEquals(3, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"21\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"21.\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"21.1\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+\n+        response = client().prepareSearch(indexName).setQuery(QueryBuilders.prefixQuery(\"version\", \"21.11\")).get();\n+        assertEquals(1, response.getHits().getTotalHits().value);\n+    }\n+\n+    public void testSort() throws IOException {\n+        String indexName = setUpIndex(\"test\");\n+\n+        // sort based on version field\n+        SearchResponse response = client().prepareSearch(indexName)", "originalCommit": "67df1d387a55c795eaecacb8e49640d3a42d24b1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTUxMzQ5Ng==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r489513496", "bodyText": "Sure can do.", "author": "cbuescher", "createdAt": "2020-09-16T15:08:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODg0ODY2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODk1MTUxOQ==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r488951519", "bodyText": "@cbuescher This is a quite clever way to organize wildcard query!!! Good job here!!!\nFor this particular case of ? case, I think we need to add additional optional automata of PRERELEASE_SEPARATOR_BYTE and NO_PRERELEASE_SEPARATOR_BYTE.\nOtherwise,  a query \"1.2.3??\" can't match  a version like \"1.2.3+b\" or a version like \"1.2.3-a\"", "author": "mayya-sharipova", "createdAt": "2020-09-15T20:24:43Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionFieldWildcardQuery.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.search.AutomatonQuery;\n+import org.apache.lucene.search.WildcardQuery;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.Automata;\n+import org.apache.lucene.util.automaton.Automaton;\n+import org.apache.lucene.util.automaton.Operations;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * A variation of the {@link WildcardQuery} than skips over meta characters introduced using {@link VersionEncoder}.\n+ */\n+class VersionFieldWildcardQuery extends AutomatonQuery {\n+\n+    private static final byte WILDCARD_STRING = '*';\n+\n+    private static final byte WILDCARD_CHAR = '?';\n+\n+    VersionFieldWildcardQuery(Term term) {\n+        super(term, toAutomaton(term), Integer.MAX_VALUE, true);\n+    }\n+\n+    private static Automaton toAutomaton(Term wildcardquery) {\n+        List<Automaton> automata = new ArrayList<>();\n+\n+        BytesRef wildcardText = wildcardquery.bytes();\n+        boolean containsPreReleaseSeparator = false;\n+\n+        for (int i = 0; i < wildcardText.length;) {\n+            final byte c = wildcardText.bytes[wildcardText.offset + i];\n+            int length = Character.charCount(c);\n+\n+            switch (c) {\n+                case WILDCARD_STRING:\n+                    automata.add(Automata.makeAnyString());\n+                    break;\n+                case WILDCARD_CHAR:\n+                    // this should also match leading digits, which have optional leading numeric marker and length bytes\n+                    automata.add(optionalNumericCharPrefix());", "originalCommit": "67df1d387a55c795eaecacb8e49640d3a42d24b1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTU2NTQzMQ==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r489565431", "bodyText": "Great catch, I'll add a test for this and will work on it", "author": "cbuescher", "createdAt": "2020-09-16T16:23:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODk1MTUxOQ=="}], "type": "inlineReview"}, {"oid": "ce5148478d965fc4f3e4a85585301417348b2f26", "url": "https://github.com/elastic/elasticsearch/commit/ce5148478d965fc4f3e4a85585301417348b2f26", "message": "Another review iteration", "committedDate": "2020-09-16T16:57:43Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDMwNjEwNg==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r490306106", "bodyText": "Small comment: I think this check should be put in get(int index) function, as we can call get(int index) function without calling getValue.", "author": "mayya-sharipova", "createdAt": "2020-09-17T14:43:49Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionScriptDocValues.java", "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.index.SortedSetDocValues;\n+import org.apache.lucene.util.ArrayUtil;\n+import org.elasticsearch.index.fielddata.ScriptDocValues;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.VersionParts;\n+\n+import java.io.IOException;\n+\n+public final class VersionScriptDocValues extends ScriptDocValues<String> {\n+\n+    private final SortedSetDocValues in;\n+    private long[] ords = new long[0];\n+    private int count;\n+\n+    public VersionScriptDocValues(SortedSetDocValues in) {\n+        this.in = in;\n+    }\n+\n+    @Override\n+    public void setNextDocId(int docId) throws IOException {\n+        count = 0;\n+        if (in.advanceExact(docId)) {\n+            for (long ord = in.nextOrd(); ord != SortedSetDocValues.NO_MORE_ORDS; ord = in.nextOrd()) {\n+                ords = ArrayUtil.grow(ords, count + 1);\n+                ords[count++] = ord;\n+            }\n+        }\n+    }\n+\n+    public String getValue() {\n+        if (count == 0) {\n+            throw new IllegalStateException(", "originalCommit": "ce5148478d965fc4f3e4a85585301417348b2f26", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDMyMDI0MA==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r490320240", "bodyText": "this check for null for lowerTerm and upperTerm look unnecessary as it is already done above", "author": "mayya-sharipova", "createdAt": "2020-09-17T14:57:13Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,419 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.search.lookup.SearchLookup;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();\n+\n+        Builder(String name) {\n+            super(name);\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context, FieldType fieldtype) {\n+            return new VersionStringFieldType(buildFullName(context), fieldtype, meta.getValue());\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            FieldType fieldtype = new FieldType(Defaults.FIELD_TYPE);\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldtype,\n+                buildFieldType(context, fieldtype),\n+                multiFieldsBuilder.build(this, context),\n+                copyTo.build()\n+            );\n+        }\n+\n+        @Override\n+        protected List<Parameter<?>> getParameters() {\n+            return List.of(meta);\n+        }\n+    }\n+\n+    public static final TypeParser PARSER = new TypeParser((n, c) -> new Builder(n));\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n+            super(name, true, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"regexp\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query regexpQuery(\n+            String value,\n+            int syntaxFlags,\n+            int matchFlags,\n+            int maxDeterminizedStates,\n+            @Nullable MultiTermQuery.RewriteMethod method,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[regexp] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            RegexpQuery query = new RegexpQuery(new Term(name(), new BytesRef(value)), syntaxFlags, matchFlags, maxDeterminizedStates) {\n+\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = compiled.runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+\n+            if (method != null) {\n+                query.setRewriteMethod(method);\n+            }\n+            return query;\n+        }\n+\n+        /**\n+         * We cannot simply use FuzzyQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"fuzzy\" queries on this field rare enough to brute-force this\n+         */\n+        @Override\n+        public Query fuzzyQuery(\n+            Object value,\n+            Fuzziness fuzziness,\n+            int prefixLength,\n+            int maxExpansions,\n+            boolean transpositions,\n+            QueryShardContext context\n+        ) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[fuzzy] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+            return new FuzzyQuery(\n+                new Term(name(), (BytesRef) value),\n+                fuzziness.asDistance(BytesRefs.toString(value)),\n+                prefixLength,\n+                maxExpansions,\n+                transpositions\n+            ) {\n+                @Override\n+                protected TermsEnum getTermsEnum(Terms terms, AttributeSource atts) throws IOException {\n+                    ByteRunAutomaton runAutomaton = getAutomata().runAutomaton;\n+\n+                    return new FilteredTermsEnum(terms.iterator(), false) {\n+\n+                        @Override\n+                        protected AcceptStatus accept(BytesRef term) throws IOException {\n+                            byte[] decoded = VersionEncoder.decodeVersion(term).getBytes(StandardCharsets.UTF_8);\n+                            boolean accepted = runAutomaton.run(decoded, 0, decoded.length);\n+                            if (accepted) {\n+                                return AcceptStatus.YES;\n+                            }\n+                            return AcceptStatus.NO;\n+                        }\n+                    };\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public Query wildcardQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[wildcard] queries cannot be executed when '\" + ALLOW_EXPENSIVE_QUERIES.getKey() + \"' is set to false.\"\n+                );\n+            }\n+\n+            VersionFieldWildcardQuery query = new VersionFieldWildcardQuery(new Term(name(), value));\n+            QueryParsers.setRewriteMethod(query, method);\n+            return query;\n+        }\n+\n+        @Override\n+        protected BytesRef indexedValueForSearch(Object value) {\n+            String valueAsString;\n+            if (value instanceof String) {\n+                valueAsString = (String) value;\n+            } else if (value instanceof BytesRef) {\n+                // encoded string, need to re-encode\n+                valueAsString = ((BytesRef) value).utf8ToString();\n+            } else {\n+                throw new IllegalArgumentException(\"Illegal value type: \" + value.getClass() + \", value: \" + value);\n+            }\n+            return encodeVersion(valueAsString).bytesRef;\n+        }\n+\n+        @Override\n+        public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName, Supplier<SearchLookup> searchLookup) {\n+            return new SortedSetOrdinalsIndexFieldData.Builder(name(), VersionScriptDocValues::new, CoreValuesSourceType.BYTES);\n+        }\n+\n+        @Override\n+        public Object valueForDisplay(Object value) {\n+            if (value == null) {\n+                return null;\n+            }\n+            return VERSION_DOCVALUE.format((BytesRef) value);\n+        }\n+\n+        @Override\n+        public DocValueFormat docValueFormat(@Nullable String format, ZoneId timeZone) {\n+            if (format != null) {\n+                throw new IllegalArgumentException(\"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom formats\");\n+            }\n+            if (timeZone != null) {\n+                throw new IllegalArgumentException(\n+                    \"Field [\" + name() + \"] of type [\" + typeName() + \"] does not support custom time zones\"\n+                );\n+            }\n+            return VERSION_DOCVALUE;\n+        }\n+\n+        @Override\n+        public Query rangeQuery(Object lowerTerm, Object upperTerm, boolean includeLower, boolean includeUpper, QueryShardContext context) {\n+            BytesRef lower = lowerTerm == null ? null : indexedValueForSearch(lowerTerm);\n+            BytesRef upper = upperTerm == null ? null : indexedValueForSearch(upperTerm);\n+\n+            return new TermRangeQuery(\n+                name(),\n+                lowerTerm == null ? null : lower,", "originalCommit": "ce5148478d965fc4f3e4a85585301417348b2f26", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDMyNDQ5MQ==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r490324491", "bodyText": "May be we can add to do for subsequent PRs to optimize these queries", "author": "mayya-sharipova", "createdAt": "2020-09-17T15:02:31Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/VersionStringFieldMapper.java", "diffHunk": "@@ -0,0 +1,419 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.FilteredTermsEnum;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n+import org.apache.lucene.search.DocValuesFieldExistsQuery;\n+import org.apache.lucene.search.FuzzyQuery;\n+import org.apache.lucene.search.MultiTermQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.RegexpQuery;\n+import org.apache.lucene.search.TermRangeQuery;\n+import org.apache.lucene.util.AttributeSource;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.ByteRunAutomaton;\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.collect.Iterators;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lucene.BytesRefs;\n+import org.elasticsearch.common.lucene.Lucene;\n+import org.elasticsearch.common.unit.Fuzziness;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.plain.SortedSetOrdinalsIndexFieldData;\n+import org.elasticsearch.index.mapper.FieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.Mapper;\n+import org.elasticsearch.index.mapper.MapperService;\n+import org.elasticsearch.index.mapper.ParametrizedFieldMapper;\n+import org.elasticsearch.index.mapper.ParseContext;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n+import org.elasticsearch.index.mapper.TermBasedFieldType;\n+import org.elasticsearch.index.mapper.TextSearchInfo;\n+import org.elasticsearch.index.mapper.ValueFetcher;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.index.query.support.QueryParsers;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.search.lookup.SearchLookup;\n+import org.elasticsearch.xpack.versionfield.VersionEncoder.EncodedVersion;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.time.ZoneId;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+\n+import static org.elasticsearch.search.SearchService.ALLOW_EXPENSIVE_QUERIES;\n+import static org.elasticsearch.xpack.versionfield.VersionEncoder.encodeVersion;\n+\n+/**\n+ * A {@link FieldMapper} for indexing fields with version strings.\n+ */\n+public class VersionStringFieldMapper extends ParametrizedFieldMapper {\n+\n+    private static byte[] MIN_VALUE = new byte[16];\n+    private static byte[] MAX_VALUE = new byte[16];\n+    static {\n+        Arrays.fill(MIN_VALUE, (byte) 0);\n+        Arrays.fill(MAX_VALUE, (byte) -1);\n+    }\n+\n+    public static final String CONTENT_TYPE = \"version\";\n+\n+    public static class Defaults {\n+        public static final FieldType FIELD_TYPE = new FieldType();\n+\n+        static {\n+            FIELD_TYPE.setTokenized(false);\n+            FIELD_TYPE.setOmitNorms(true);\n+            FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);\n+            FIELD_TYPE.freeze();\n+        }\n+    }\n+\n+    static class Builder extends ParametrizedFieldMapper.Builder {\n+\n+        private final Parameter<Map<String, String>> meta = Parameter.metaParam();\n+\n+        Builder(String name) {\n+            super(name);\n+        }\n+\n+        private VersionStringFieldType buildFieldType(BuilderContext context, FieldType fieldtype) {\n+            return new VersionStringFieldType(buildFullName(context), fieldtype, meta.getValue());\n+        }\n+\n+        @Override\n+        public VersionStringFieldMapper build(BuilderContext context) {\n+            FieldType fieldtype = new FieldType(Defaults.FIELD_TYPE);\n+            return new VersionStringFieldMapper(\n+                name,\n+                fieldtype,\n+                buildFieldType(context, fieldtype),\n+                multiFieldsBuilder.build(this, context),\n+                copyTo.build()\n+            );\n+        }\n+\n+        @Override\n+        protected List<Parameter<?>> getParameters() {\n+            return List.of(meta);\n+        }\n+    }\n+\n+    public static final TypeParser PARSER = new TypeParser((n, c) -> new Builder(n));\n+\n+    public static final class VersionStringFieldType extends TermBasedFieldType {\n+\n+        public VersionStringFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n+            super(name, true, true, new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n+            setIndexAnalyzer(Lucene.KEYWORD_ANALYZER);\n+        }\n+\n+        @Override\n+        public String typeName() {\n+            return CONTENT_TYPE;\n+        }\n+\n+        @Override\n+        public Query existsQuery(QueryShardContext context) {\n+            return new DocValuesFieldExistsQuery(name());\n+        }\n+\n+        @Override\n+        public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {\n+            if (context.allowExpensiveQueries() == false) {\n+                throw new ElasticsearchException(\n+                    \"[prefix] queries cannot be executed when '\"\n+                        + ALLOW_EXPENSIVE_QUERIES.getKey()\n+                        + \"' is set to false. For optimised prefix queries on text \"\n+                        + \"fields please enable [index_prefixes].\"\n+                );\n+            }\n+            return wildcardQuery(value + \"*\", method, context);\n+        }\n+\n+        /**\n+         * We cannot simply use RegexpQuery directly since we use the encoded terms from the dictionary, but the\n+         * automaton in the query will assume unencoded terms. We are running through all terms, decode them and\n+         * then run them through the automaton manually instead. This is not as efficient as intersecting the original\n+         * Terms with the compiled automaton, but we expect the number of distinct version terms indexed into this field\n+         * to be low enough and the use of \"regexp\" queries on this field rare enough to brute-force this", "originalCommit": "ce5148478d965fc4f3e4a85585301417348b2f26", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDM2OTU4Mg==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r490369582", "bodyText": "I'm not a bit fan of tracking backlog like this in TODOs in code, I'd rather open an issue to investigate improvements when time allows and track it with any other issue we have. Would that be okay for you?", "author": "cbuescher", "createdAt": "2020-09-17T16:04:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDMyNDQ5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDQ2ODQ2Mg==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r490468462", "bodyText": "@cbuescher Thanks, that would be fine.", "author": "mayya-sharipova", "createdAt": "2020-09-17T18:26:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDMyNDQ5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDgwNzkyNA==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r490807924", "bodyText": "I opened #62608 for tracking", "author": "cbuescher", "createdAt": "2020-09-18T09:05:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDMyNDQ5MQ=="}], "type": "inlineReview"}, {"oid": "04ac11d32a63295e9ce6d7bc5dc7afb4a2a70f09", "url": "https://github.com/elastic/elasticsearch/commit/04ac11d32a63295e9ce6d7bc5dc7afb4a2a70f09", "message": "Another round of reviews", "committedDate": "2020-09-17T16:12:41Z", "type": "commit"}, {"oid": "ccebd6f470c99c824a84211ed122ba10f1f9629c", "url": "https://github.com/elastic/elasticsearch/commit/ccebd6f470c99c824a84211ed122ba10f1f9629c", "message": "Moving docs under 'structured'", "committedDate": "2020-09-17T18:10:44Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDk1MzU2OQ==", "url": "https://github.com/elastic/elasticsearch/pull/59773#discussion_r490953569", "bodyText": "This class is not needed anymore ?", "author": "jimczi", "createdAt": "2020-09-18T13:35:42Z", "path": "x-pack/plugin/versionfield/src/main/java/org/elasticsearch/xpack/versionfield/ValidationOnSortedDv.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.versionfield;\n+\n+import org.apache.lucene.index.DocValues;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.SortedSetDocValues;\n+import org.apache.lucene.search.ConstantScoreScorer;\n+import org.apache.lucene.search.ConstantScoreWeight;\n+import org.apache.lucene.search.IndexSearcher;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.search.Scorer;\n+import org.apache.lucene.search.TwoPhaseIterator;\n+import org.apache.lucene.search.Weight;\n+import org.apache.lucene.util.BytesRef;\n+\n+import java.io.IOException;\n+import java.util.Objects;\n+\n+/**\n+ * Query that runs a validation for version ranges across sorted doc values.\n+ * Used in conjunction with more selective query clauses.\n+ */\n+class ValidationOnSortedDv extends Query {", "originalCommit": "ccebd6f470c99c824a84211ed122ba10f1f9629c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "b0abc83a228c5fdffadcddd30db6b6ad0875ce93", "url": "https://github.com/elastic/elasticsearch/commit/b0abc83a228c5fdffadcddd30db6b6ad0875ce93", "message": "Merge branch 'master' into add-version-field", "committedDate": "2020-09-18T14:21:33Z", "type": "commit"}, {"oid": "4c0b1e910c1c9a15b5d17e30b068c802f81bbf21", "url": "https://github.com/elastic/elasticsearch/commit/4c0b1e910c1c9a15b5d17e30b068c802f81bbf21", "message": "iter", "committedDate": "2020-09-18T14:31:38Z", "type": "commit"}, {"oid": "6849550894da2bc41fcd9300fc459ce2f985de4f", "url": "https://github.com/elastic/elasticsearch/commit/6849550894da2bc41fcd9300fc459ce2f985de4f", "message": "Removing specialized script doc values functions", "committedDate": "2020-09-18T14:59:24Z", "type": "commit"}]}