{"pr_number": 62513, "pr_title": "Do not block Translog add on file write", "pr_createdAt": "2020-09-17T01:37:55Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/62513", "timeline": [{"oid": "90dd33a17bb90817626a6e1d3cb513f9cfbcada6", "url": "https://github.com/elastic/elasticsearch/commit/90dd33a17bb90817626a6e1d3cb513f9cfbcada6", "message": "Changes", "committedDate": "2020-09-14T22:48:36Z", "type": "commit"}, {"oid": "019a56a290aecca8a01ef522ba41a4a14e616635", "url": "https://github.com/elastic/elasticsearch/commit/019a56a290aecca8a01ef522ba41a4a14e616635", "message": "Changes", "committedDate": "2020-09-14T22:58:05Z", "type": "commit"}, {"oid": "97b19a4b7b4912d4d364197f32b02da6caaa2c0e", "url": "https://github.com/elastic/elasticsearch/commit/97b19a4b7b4912d4d364197f32b02da6caaa2c0e", "message": "WIP", "committedDate": "2020-09-15T17:24:23Z", "type": "commit"}, {"oid": "fa227d7cfc859f786708078ea93904401fde64d1", "url": "https://github.com/elastic/elasticsearch/commit/fa227d7cfc859f786708078ea93904401fde64d1", "message": "Changes", "committedDate": "2020-09-17T01:36:25Z", "type": "commit"}, {"oid": "67c5f183fa75e7082307a76eda51b761ff89cd81", "url": "https://github.com/elastic/elasticsearch/commit/67c5f183fa75e7082307a76eda51b761ff89cd81", "message": "Forbidden", "committedDate": "2020-09-17T02:16:16Z", "type": "commit"}, {"oid": "77970f72e3cc6fb86a6c4dba431e9806ee1ccf71", "url": "https://github.com/elastic/elasticsearch/commit/77970f72e3cc6fb86a6c4dba431e9806ee1ccf71", "message": "Merge remote-tracking branch 'upstream/master' into translog_less_blocking", "committedDate": "2020-09-17T04:10:38Z", "type": "commit"}, {"oid": "cfb438b9d4d2a36d12bebd56ab9cb0c0c9df42b1", "url": "https://github.com/elastic/elasticsearch/commit/cfb438b9d4d2a36d12bebd56ab9cb0c0c9df42b1", "message": "Changes", "committedDate": "2020-09-17T19:52:18Z", "type": "commit"}, {"oid": "9295d9276ec87cc372365ffa7924cdb6162eee6e", "url": "https://github.com/elastic/elasticsearch/commit/9295d9276ec87cc372365ffa7924cdb6162eee6e", "message": "Merge remote-tracking branch 'upstream/master' into translog_less_blocking", "committedDate": "2020-09-17T20:13:58Z", "type": "commit"}, {"oid": "ea6e609a0002454c8c262c0acd8c8791f1f8c8cc", "url": "https://github.com/elastic/elasticsearch/commit/ea6e609a0002454c8c262c0acd8c8791f1f8c8cc", "message": "Merge remote-tracking branch 'upstream/master' into translog_less_blocking", "committedDate": "2020-09-22T23:39:37Z", "type": "commit"}, {"oid": "8023a859e08e5b1553f26598623204ef553da52d", "url": "https://github.com/elastic/elasticsearch/commit/8023a859e08e5b1553f26598623204ef553da52d", "message": "Merge remote-tracking branch 'upstream/master' into translog_less_blocking", "committedDate": "2020-09-28T15:07:36Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njk3MzgzNQ==", "url": "https://github.com/elastic/elasticsearch/pull/62513#discussion_r496973835", "bodyText": "Can we assert that we are on a write thread to ensure we do not get more buffers than write-threads?", "author": "henningandersen", "createdAt": "2020-09-29T19:09:24Z", "path": "server/src/main/java/org/elasticsearch/common/io/DirectPool.java", "diffHunk": "@@ -0,0 +1,38 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.common.io;\n+\n+import org.elasticsearch.common.unit.ByteSizeValue;\n+\n+import java.nio.ByteBuffer;\n+\n+public class DirectPool {\n+\n+    public static final int BUFFER_SIZE = StrictMath.toIntExact(ByteSizeValue.parseBytesSizeValue(\n+        System.getProperty(\"es.direct.buffer.size\", \"256KB\"), \"es.direct.buffer.size\").getBytes());\n+\n+    private static final ThreadLocal<ByteBuffer> ioBufferPool = ThreadLocal.withInitial(() -> ByteBuffer.allocateDirect(BUFFER_SIZE));\n+\n+    public static ByteBuffer getIoBuffer() {\n+        ByteBuffer ioBuffer = ioBufferPool.get();", "originalCommit": "8023a859e08e5b1553f26598623204ef553da52d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzgxNjYzMg==", "url": "https://github.com/elastic/elasticsearch/pull/62513#discussion_r497816632", "bodyText": "Different threads do flush the translog. Like the FLUSH thread. Or any thread that closes the translog. Or rolls it.", "author": "tbrooks8", "createdAt": "2020-09-30T21:40:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njk3MzgzNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzgzMTM3MQ==", "url": "https://github.com/elastic/elasticsearch/pull/62513#discussion_r497831371", "bodyText": "If we are concerned about the thread local buffer, we can have like a 64KB-256KB buffer for the important threads (FLUSH/WRITE) and use an 8KB buffer for other threads.", "author": "tbrooks8", "createdAt": "2020-09-30T22:15:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njk3MzgzNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQ4NTQwOQ==", "url": "https://github.com/elastic/elasticsearch/pull/62513#discussion_r498485409", "bodyText": "I do like to separate out the flush/write threads. I am equally concerned about the direct memory use and the memory usage. For instance the generic thread pool can be resized and if we are unfortunate, we could leak many direct buffers for the GC to collect.\nSo I would suggest to use a direct byte buffer for the flush/write/system-flush/system-write pools and then use heap based byte buffer for the rest.", "author": "henningandersen", "createdAt": "2020-10-01T20:05:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njk3MzgzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzI1NzMyMg==", "url": "https://github.com/elastic/elasticsearch/pull/62513#discussion_r497257322", "bodyText": "I wonder if we should in this PR keep the buffer size as is, i.e. let FORCE_WRITE_THRESHOLD still be taken from TranslogConfig.getBufferSize().\nHaving up to 4MB of buffer per translog seems like it could add up (much like the previous solution where the buffer size were increased)?", "author": "henningandersen", "createdAt": "2020-09-30T05:50:52Z", "path": "server/src/main/java/org/elasticsearch/index/translog/TranslogWriter.java", "diffHunk": "@@ -48,6 +54,9 @@\n import java.util.function.LongSupplier;\n \n public class TranslogWriter extends BaseTranslogReader implements Closeable {\n+\n+    private static final int FORCE_WRITE_THRESHOLD = 4 * 1024 * 1024;", "originalCommit": "8023a859e08e5b1553f26598623204ef553da52d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzI1OTM2NQ==", "url": "https://github.com/elastic/elasticsearch/pull/62513#discussion_r497259365", "bodyText": "This makes TranslogConfig.getBufferSize unused. I slightly prefer to keep this in TranslogConfig but can be persuaded both ways given that it is not configurable today anyway. But I think we need to either use it or remove the method/field from TranslogConfig.", "author": "henningandersen", "createdAt": "2020-09-30T05:57:24Z", "path": "server/src/main/java/org/elasticsearch/index/translog/Translog.java", "diffHunk": "@@ -506,7 +506,6 @@ TranslogWriter createWriter(long fileGeneration, long initialMinTranslogGen, lon\n                 fileGeneration,\n                 location.resolve(getFilename(fileGeneration)),\n                 getChannelFactory(),\n-                config.getBufferSize(),", "originalCommit": "8023a859e08e5b1553f26598623204ef553da52d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzI3NjMxOA==", "url": "https://github.com/elastic/elasticsearch/pull/62513#discussion_r497276318", "bodyText": "Would we not risk several threads waiting on the writeLock, because they each determine they need to write buffered ops? Not sure it is a big issue in practice. But I wonder if moving the data to write out of the \"main buffer\" and into a \"to-write-buffer\" inside the lock above would help make sure only one of the threads need to do the write (the one moving the buffer over promises to also write).", "author": "henningandersen", "createdAt": "2020-09-30T06:44:23Z", "path": "server/src/main/java/org/elasticsearch/index/translog/TranslogWriter.java", "diffHunk": "@@ -174,34 +177,35 @@ private synchronized void closeWithTragicEvent(final Exception ex) {\n      * @return the location the bytes were written to\n      * @throws IOException if writing to the translog resulted in an I/O exception\n      */\n-    public synchronized Translog.Location add(final BytesReference data, final long seqNo) throws IOException {\n-        ensureOpen();\n-        final long offset = totalOffset;\n-        try {\n-            data.writeTo(outputStream);\n-        } catch (final Exception ex) {\n-            closeWithTragicEvent(ex);\n-            throw ex;\n-        }\n-        totalOffset += data.length();\n+    public Translog.Location add(final ReleasableBytesReference data, final long seqNo) throws IOException {\n+        final Translog.Location location;\n+        final long bytesBufferedAfterAdd;\n+        synchronized (this) {\n+            ensureOpen();\n+            final long offset = totalOffset;\n+            totalOffset += data.length();\n+            bufferedBytes += data.length();\n+            bufferedOps.add(new Operation(seqNo, data.retain()));\n \n-        if (minSeqNo == SequenceNumbers.NO_OPS_PERFORMED) {\n-            assert operationCounter == 0;\n-        }\n-        if (maxSeqNo == SequenceNumbers.NO_OPS_PERFORMED) {\n-            assert operationCounter == 0;\n-        }\n+            assert minSeqNo != SequenceNumbers.NO_OPS_PERFORMED || operationCounter == 0;\n+            assert maxSeqNo != SequenceNumbers.NO_OPS_PERFORMED || operationCounter == 0;\n \n-        minSeqNo = SequenceNumbers.min(minSeqNo, seqNo);\n-        maxSeqNo = SequenceNumbers.max(maxSeqNo, seqNo);\n+            minSeqNo = SequenceNumbers.min(minSeqNo, seqNo);\n+            maxSeqNo = SequenceNumbers.max(maxSeqNo, seqNo);\n \n-        nonFsyncedSequenceNumbers.add(seqNo);\n+            operationCounter++;\n \n-        operationCounter++;\n+            assert assertNoSeqNumberConflict(seqNo, data);\n \n-        assert assertNoSeqNumberConflict(seqNo, data);\n+            location = new Translog.Location(generation, offset, data.length());\n+            bytesBufferedAfterAdd = bufferedBytes;\n+        }\n+\n+        if (bytesBufferedAfterAdd >= FORCE_WRITE_THRESHOLD) {\n+            writeBufferedOps(Long.MAX_VALUE);", "originalCommit": "8023a859e08e5b1553f26598623204ef553da52d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzgxNzgwMg==", "url": "https://github.com/elastic/elasticsearch/pull/62513#discussion_r497817802", "bodyText": "I had intended to move this to a conditional lock in a follow-up, but since you raised the point here I made that change in this PR. The only intention of this work is to flush the translog if it gets too large.", "author": "tbrooks8", "createdAt": "2020-09-30T21:42:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzI3NjMxOA=="}], "type": "inlineReview"}, {"oid": "ebb6e2f5b847133df89a8a692ca2ed5c1ce9d455", "url": "https://github.com/elastic/elasticsearch/commit/ebb6e2f5b847133df89a8a692ca2ed5c1ce9d455", "message": "Merge remote-tracking branch 'upstream/master' into translog_less_blocking", "committedDate": "2020-09-30T18:36:39Z", "type": "commit"}, {"oid": "79b888afca8c9453ce2700ec0578ca0b1a9ef9a2", "url": "https://github.com/elastic/elasticsearch/commit/79b888afca8c9453ce2700ec0578ca0b1a9ef9a2", "message": "Changes", "committedDate": "2020-09-30T21:28:16Z", "type": "commit"}, {"oid": "bfceaced1872f305674a25984dafb2b787b7d57f", "url": "https://github.com/elastic/elasticsearch/commit/bfceaced1872f305674a25984dafb2b787b7d57f", "message": "Changes", "committedDate": "2020-09-30T21:39:19Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQ0MjczNA==", "url": "https://github.com/elastic/elasticsearch/pull/62513#discussion_r498442734", "bodyText": "I would like to limit the max buffer size (also if writing the buffer is slow), perhaps something like this:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        writeBufferedOps(Long.MAX_VALUE, false);\n          \n          \n            \n                        writeBufferedOps(Long.MAX_VALUE, bytesBufferedAfterAdd >= forceWriteThreshold * 2);", "author": "henningandersen", "createdAt": "2020-10-01T18:37:12Z", "path": "server/src/main/java/org/elasticsearch/index/translog/TranslogWriter.java", "diffHunk": "@@ -174,34 +181,35 @@ private synchronized void closeWithTragicEvent(final Exception ex) {\n      * @return the location the bytes were written to\n      * @throws IOException if writing to the translog resulted in an I/O exception\n      */\n-    public synchronized Translog.Location add(final BytesReference data, final long seqNo) throws IOException {\n-        ensureOpen();\n-        final long offset = totalOffset;\n-        try {\n-            data.writeTo(outputStream);\n-        } catch (final Exception ex) {\n-            closeWithTragicEvent(ex);\n-            throw ex;\n-        }\n-        totalOffset += data.length();\n+    public Translog.Location add(final ReleasableBytesReference data, final long seqNo) throws IOException {\n+        final Translog.Location location;\n+        final long bytesBufferedAfterAdd;\n+        synchronized (this) {\n+            ensureOpen();\n+            final long offset = totalOffset;\n+            totalOffset += data.length();\n+            bufferedBytes += data.length();\n+            bufferedOps.add(new Operation(seqNo, data.retain()));\n \n-        if (minSeqNo == SequenceNumbers.NO_OPS_PERFORMED) {\n-            assert operationCounter == 0;\n-        }\n-        if (maxSeqNo == SequenceNumbers.NO_OPS_PERFORMED) {\n-            assert operationCounter == 0;\n-        }\n+            assert minSeqNo != SequenceNumbers.NO_OPS_PERFORMED || operationCounter == 0;\n+            assert maxSeqNo != SequenceNumbers.NO_OPS_PERFORMED || operationCounter == 0;\n+\n+            minSeqNo = SequenceNumbers.min(minSeqNo, seqNo);\n+            maxSeqNo = SequenceNumbers.max(maxSeqNo, seqNo);\n \n-        minSeqNo = SequenceNumbers.min(minSeqNo, seqNo);\n-        maxSeqNo = SequenceNumbers.max(maxSeqNo, seqNo);\n+            operationCounter++;\n \n-        nonFsyncedSequenceNumbers.add(seqNo);\n+            assert assertNoSeqNumberConflict(seqNo, data);\n \n-        operationCounter++;\n+            location = new Translog.Location(generation, offset, data.length());\n+            bytesBufferedAfterAdd = bufferedBytes;\n+        }\n \n-        assert assertNoSeqNumberConflict(seqNo, data);\n+        if (bytesBufferedAfterAdd >= forceWriteThreshold) {\n+            writeBufferedOps(Long.MAX_VALUE, false);", "originalCommit": "bfceaced1872f305674a25984dafb2b787b7d57f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODUwNzg1Mw==", "url": "https://github.com/elastic/elasticsearch/pull/62513#discussion_r498507853", "bodyText": "I did this but 4X. I think there are some better follow-ups we can do (like a metric indicating the TOTAL bytes buffered amount all writers.) But is seems out of scope for this PR. And 4MB still seems reasonable + it gives more headroom for things like PMC documents.", "author": "tbrooks8", "createdAt": "2020-10-01T20:54:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQ0MjczNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQ2MTk3MA==", "url": "https://github.com/elastic/elasticsearch/pull/62513#discussion_r498461970", "bodyText": "nit: I think the synchronized block only need to go around the two new lines?", "author": "henningandersen", "createdAt": "2020-10-01T19:15:49Z", "path": "server/src/main/java/org/elasticsearch/index/translog/TranslogWriter.java", "diffHunk": "@@ -449,8 +532,10 @@ protected final void ensureOpen() {\n     }\n \n     @Override\n-    public final void close() throws IOException {\n+    public final synchronized void close() throws IOException {", "originalCommit": "bfceaced1872f305674a25984dafb2b787b7d57f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQ4MTk5NQ==", "url": "https://github.com/elastic/elasticsearch/pull/62513#discussion_r498481995", "bodyText": "Can we also assert that totalOps == getWrittenOffset()?", "author": "henningandersen", "createdAt": "2020-10-01T19:58:34Z", "path": "server/src/main/java/org/elasticsearch/index/translog/TranslogWriter.java", "diffHunk": "@@ -309,28 +317,34 @@ public long sizeInBytes() {\n     public TranslogReader closeIntoReader() throws IOException {\n         // make sure to acquire the sync lock first, to prevent dead locks with threads calling\n         // syncUpTo() , where the sync lock is acquired first, following by the synchronize(this)\n+        // After the sync lock we acquire the write lock to avoid deadlocks with threads writing where\n+        // the write lock is acquired first followed by synchronize(this).\n         //\n         // Note: While this is not strictly needed as this method is called while blocking all ops on the translog,\n         //       we do this to for correctness and preventing future issues.\n         synchronized (syncLock) {\n-            synchronized (this) {\n-                try {\n-                    sync(); // sync before we close..\n-                } catch (final Exception ex) {\n-                    closeWithTragicEvent(ex);\n-                    throw ex;\n-                }\n-                if (closed.compareAndSet(false, true)) {\n+            try (ReleasableLock toClose = writeLock.acquire()) {\n+                synchronized (this) {\n                     try {\n-                        checkpointChannel.close();\n+                        sync(); // sync before we close..\n                     } catch (final Exception ex) {\n                         closeWithTragicEvent(ex);\n                         throw ex;\n                     }\n-                    return new TranslogReader(getLastSyncedCheckpoint(), channel, path, header);\n-                } else {\n-                    throw new AlreadyClosedException(\"translog [\" + getGeneration() + \"] is already closed (path [\" + path + \"]\",\n+                    // If we reached this point, all of the buffered ops should have been flushed successfully.\n+                    assert bufferedOps.size() == 0;", "originalCommit": "bfceaced1872f305674a25984dafb2b787b7d57f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODUwNzI5NQ==", "url": "https://github.com/elastic/elasticsearch/pull/62513#discussion_r498507295", "bodyText": "I added some assertions here based on the sync snapshot. The sync must also have completed successfully to get here. Written offset is annoying because I throws an IOException.", "author": "tbrooks8", "createdAt": "2020-10-01T20:53:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQ4MTk5NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODYyMzk5Nw==", "url": "https://github.com/elastic/elasticsearch/pull/62513#discussion_r498623997", "bodyText": "I think the added assert is fine. But the main property I were after validating was that the accounting we do for totalOffset in add ends up matching what goes into the file. This new assert does not verify that since the checkpoint is constructed from the totalOffset value.\nWould it be an option to assert based on a method and then catch the IOException in that and return true on exception?", "author": "henningandersen", "createdAt": "2020-10-02T05:31:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQ4MTk5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQ4Mjg3Ng==", "url": "https://github.com/elastic/elasticsearch/pull/62513#discussion_r498482876", "bodyText": "I think the assert on bufferedOps size and totalOps above can also go here?", "author": "henningandersen", "createdAt": "2020-10-01T20:00:24Z", "path": "server/src/main/java/org/elasticsearch/index/translog/TranslogWriter.java", "diffHunk": "@@ -341,15 +355,19 @@ public TranslogReader closeIntoReader() throws IOException {\n     public TranslogSnapshot newSnapshot() {\n         // make sure to acquire the sync lock first, to prevent dead locks with threads calling\n         // syncUpTo() , where the sync lock is acquired first, following by the synchronize(this)\n+        // After the sync lock we acquire the write lock to avoid deadlocks with threads writing where\n+        // the write lock is acquired first followed by synchronize(this).\n         synchronized (syncLock) {\n-            synchronized (this) {\n-                ensureOpen();\n-                try {\n-                    sync();\n-                } catch (IOException e) {\n-                    throw new TranslogException(shardId, \"exception while syncing before creating a snapshot\", e);\n+            try (ReleasableLock toClose = writeLock.acquire()) {\n+                synchronized (this) {\n+                    ensureOpen();\n+                    try {\n+                        sync();\n+                    } catch (IOException e) {\n+                        throw new TranslogException(shardId, \"exception while syncing before creating a snapshot\", e);\n+                    }\n+                    return super.newSnapshot();", "originalCommit": "bfceaced1872f305674a25984dafb2b787b7d57f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODUwNzI4OA==", "url": "https://github.com/elastic/elasticsearch/pull/62513#discussion_r498507288", "bodyText": "I added some assertions here based on the sync snapshot. The sync must also have completed successfully to get here. Written offset is annoying because I throws an IOException.", "author": "tbrooks8", "createdAt": "2020-10-01T20:53:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQ4Mjg3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQ4NzU2NA==", "url": "https://github.com/elastic/elasticsearch/pull/62513#discussion_r498487564", "bodyText": "revert this?", "author": "henningandersen", "createdAt": "2020-10-01T20:10:44Z", "path": "server/src/main/java/org/elasticsearch/index/translog/Translog.java", "diffHunk": "@@ -544,7 +546,8 @@ public Location add(final Operation operation) throws IOException {\n                     throw new IllegalArgumentException(\"Operation term is newer than the current term; \"\n                         + \"current term[\" + current.getPrimaryTerm() + \"], operation term[\" + operation + \"]\");\n                 }\n-                return current.add(bytes, operation.seqNo());\n+                final Location location = current.add(bytes, operation.seqNo());", "originalCommit": "bfceaced1872f305674a25984dafb2b787b7d57f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "9db760a88420d07cba63f178aebbd8282979e5cf", "url": "https://github.com/elastic/elasticsearch/commit/9db760a88420d07cba63f178aebbd8282979e5cf", "message": "Merge remote-tracking branch 'upstream/master' into translog_less_blocking", "committedDate": "2020-10-01T20:22:49Z", "type": "commit"}, {"oid": "ba61c8a69c282065e35cbf8c66590558c5ecbfdb", "url": "https://github.com/elastic/elasticsearch/commit/ba61c8a69c282065e35cbf8c66590558c5ecbfdb", "message": "Changes", "committedDate": "2020-10-01T20:58:21Z", "type": "commit"}, {"oid": "cfa38a51aefdbddbeaa2f867cbdf17da268223a7", "url": "https://github.com/elastic/elasticsearch/commit/cfa38a51aefdbddbeaa2f867cbdf17da268223a7", "message": "Fix test", "committedDate": "2020-10-01T21:52:33Z", "type": "commit"}, {"oid": "520485610a795dc73f842aaae52d660ffa563ad3", "url": "https://github.com/elastic/elasticsearch/commit/520485610a795dc73f842aaae52d660ffa563ad3", "message": "Review", "committedDate": "2020-10-02T16:17:00Z", "type": "commit"}, {"oid": "ed443a25a7f8635604353167d0a21c1a66666cf9", "url": "https://github.com/elastic/elasticsearch/commit/ed443a25a7f8635604353167d0a21c1a66666cf9", "message": "Merge remote-tracking branch 'upstream/master' into translog_less_blocking", "committedDate": "2020-10-02T16:17:12Z", "type": "commit"}, {"oid": "4cc7c9419a1807603bb3cc99a4d8ebe6812b8e03", "url": "https://github.com/elastic/elasticsearch/commit/4cc7c9419a1807603bb3cc99a4d8ebe6812b8e03", "message": "Remove serr", "committedDate": "2020-10-02T16:42:37Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODk3NDU1MA==", "url": "https://github.com/elastic/elasticsearch/pull/62513#discussion_r498974550", "bodyText": "I think we need a latch to ensure that the thread did do the locking and is inside write or force?", "author": "henningandersen", "createdAt": "2020-10-02T18:11:43Z", "path": "server/src/test/java/org/elasticsearch/index/translog/TranslogTests.java", "diffHunk": "@@ -1316,6 +1315,100 @@ public void testTranslogWriter() throws IOException {\n         IOUtils.close(writer);\n     }\n \n+    public void testTranslogWriterDoesNotBlockAddsOnWrite() throws IOException, InterruptedException {\n+        Path tempDir = createTempDir();\n+        System.err.println(tempDir);\n+        final TranslogConfig config = getTranslogConfig(tempDir);\n+        final AtomicBoolean startBlocking = new AtomicBoolean(false);\n+        final CountDownLatch blocker = new CountDownLatch(1);\n+        final Set<Long> persistedSeqNos = new HashSet<>();\n+\n+        final ChannelFactory channelFactory = (file, openOption) -> {\n+            FileChannel delegate = FileChannel.open(file, openOption);\n+            boolean success = false;\n+            try {\n+                // don't do partial writes for checkpoints we rely on the fact that the bytes are written as an atomic operation\n+                final boolean isCkpFile = file.getFileName().toString().endsWith(\".ckp\");\n+\n+                final FileChannel channel;\n+                if (isCkpFile) {\n+                    channel = delegate;\n+                } else {\n+                    channel = new FilterFileChannel(delegate) {\n+\n+                        @Override\n+                        public int write(ByteBuffer src) throws IOException {\n+                            if (startBlocking.get()) {\n+                                try {\n+                                    blocker.await();\n+                                } catch (InterruptedException e) {\n+                                    // Ignore\n+                                }\n+                            }\n+                            return super.write(src);\n+                        }\n+\n+                        @Override\n+                        public void force(boolean metaData) throws IOException {\n+                            if (startBlocking.get()) {\n+                                try {\n+                                    blocker.await();\n+                                } catch (InterruptedException e) {\n+                                    // Ignore\n+                                }\n+                            }\n+                            super.force(metaData);\n+                        }\n+                    };\n+                }\n+                success = true;\n+                return channel;\n+            } finally {\n+                if (success == false) {\n+                    IOUtils.closeWhileHandlingException(delegate);\n+                }\n+            }\n+        };\n+        String translogUUID = Translog.createEmptyTranslog(\n+            config.getTranslogPath(), SequenceNumbers.NO_OPS_PERFORMED, shardId, channelFactory, primaryTerm.get());\n+\n+        try (Translog translog = new Translog(config, translogUUID, new TranslogDeletionPolicy(),\n+            () -> SequenceNumbers.NO_OPS_PERFORMED, primaryTerm::get, persistedSeqNos::add) {\n+            @Override\n+            ChannelFactory getChannelFactory() {\n+                return channelFactory;\n+            }\n+        }) {\n+            try (TranslogWriter writer = translog.createWriter(translog.currentFileGeneration() + 1)) {\n+                byte[] bytes = new byte[4];\n+                ByteArrayDataOutput out = new ByteArrayDataOutput(new byte[4]);\n+                out.writeInt(1);\n+                writer.add(ReleasableBytesReference.wrap(new BytesArray(bytes)), 1);\n+                assertThat(persistedSeqNos, empty());\n+                startBlocking.set(true);\n+                Thread thread = new Thread(() -> {\n+                    try {\n+                        writer.sync();\n+                    } catch (IOException e) {\n+                        throw new AssertionError(e);\n+                    }\n+                });\n+                thread.start();\n+\n+                // Add will not block even though we are currently writing/syncing\n+                writer.add(ReleasableBytesReference.wrap(new BytesArray(bytes)), 2);", "originalCommit": "520485610a795dc73f842aaae52d660ffa563ad3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "d7b8d7e31d0620f511114b58d3d61a0b85dc0dde", "url": "https://github.com/elastic/elasticsearch/commit/d7b8d7e31d0620f511114b58d3d61a0b85dc0dde", "message": "Wait for write", "committedDate": "2020-10-02T18:29:33Z", "type": "commit"}]}