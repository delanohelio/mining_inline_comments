{"pr_number": 51637, "pr_title": "Add cache directory low-level instrumentation ", "pr_createdAt": "2020-01-29T17:19:18Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/51637", "timeline": [{"oid": "409e720e12b8d284d95679518d3b6c1c42d7355a", "url": "https://github.com/elastic/elasticsearch/commit/409e720e12b8d284d95679518d3b6c1c42d7355a", "message": "Add IndexInputStats", "committedDate": "2020-01-29T17:02:25Z", "type": "commit"}, {"oid": "5702eb9b1bbc1bd5c1893412d0471fdf5e64d918", "url": "https://github.com/elastic/elasticsearch/commit/5702eb9b1bbc1bd5c1893412d0471fdf5e64d918", "message": "Merge branch 'feature/searchable-snapshots' into add-instrumentation-step-1", "committedDate": "2020-01-31T11:17:44Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzQyNDAzMg==", "url": "https://github.com/elastic/elasticsearch/pull/51637#discussion_r373424032", "bodyText": "I think we should not count cases where delta == 0 as a seek. I remember seeing some no-op calls to seekInternal() when looking at a separate issue, but I think we can make them have no effect on the underlying stream and therefore shouldn't be counted here.", "author": "DaveCTurner", "createdAt": "2020-01-31T10:58:36Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/IndexInputStats.java", "diffHunk": "@@ -0,0 +1,167 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.searchablesnapshots.cache;\n+\n+import org.elasticsearch.xpack.searchablesnapshots.cache.CacheDirectory.CacheBufferedIndexInput;\n+\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.atomic.LongAdder;\n+import java.util.function.LongConsumer;\n+\n+/**\n+ * {@link IndexInputStats} records stats for a given {@link CacheBufferedIndexInput}.\n+ */\n+public class IndexInputStats {\n+\n+    static final double SEEKING_THRESHOLD = 0.25d;\n+\n+    private final long fileLength;\n+\n+    private final LongAdder opened = new LongAdder();\n+    private final LongAdder closed = new LongAdder();\n+\n+    private final Counter forwardSmallSeeks = new Counter();\n+    private final Counter backwardSmallSeeks = new Counter();\n+\n+    private final Counter forwardLargeSeeks = new Counter();\n+    private final Counter backwardLargeSeeks = new Counter();\n+\n+    private final Counter contiguousReads = new Counter();\n+    private final Counter nonContiguousReads = new Counter();\n+\n+    private final Counter directBytesRead = new Counter();\n+\n+    private final Counter cachedBytesRead = new Counter();\n+    private final Counter cachedBytesWritten = new Counter();\n+\n+    public IndexInputStats(long fileLength) {\n+        this.fileLength = fileLength;\n+    }\n+\n+    public void incrementOpenCount() {\n+        opened.increment();\n+    }\n+\n+    public void incrementCloseCount() {\n+        closed.increment();\n+    }\n+\n+    public void addCachedBytesRead(int bytesRead) {\n+        cachedBytesRead.add(bytesRead);\n+    }\n+\n+    public void addCachedBytesWritten(int bytesWritten) {\n+        cachedBytesWritten.add(bytesWritten);\n+    }\n+\n+    public void addDirectBytesRead(int bytesRead) {\n+        directBytesRead.add(bytesRead);\n+    }\n+\n+    public void incrementBytesRead(long previousPosition, long currentPosition, int bytesRead) {\n+        LongConsumer incBytesRead = (previousPosition == currentPosition) ? contiguousReads::add : nonContiguousReads::add;\n+        incBytesRead.accept(bytesRead);\n+    }\n+\n+    public void incrementSeeks(long currentPosition, long newPosition) {\n+        final long delta = newPosition - currentPosition;\n+        final double threshold = fileLength * SEEKING_THRESHOLD;\n+        LongConsumer incSeekCount;\n+        if (delta >= 0) {", "originalCommit": "409e720e12b8d284d95679518d3b6c1c42d7355a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzQ3NDczNg==", "url": "https://github.com/elastic/elasticsearch/pull/51637#discussion_r373474736", "bodyText": "I agree. I've see, few of them too but running tests in a loop shows much more zero-seeking than I initially thought. I pushed 3f8b3a4 to ignore them.", "author": "tlrx", "createdAt": "2020-01-31T13:19:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzQyNDAzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzQyNTI1MA==", "url": "https://github.com/elastic/elasticsearch/pull/51637#discussion_r373425250", "bodyText": "Should we track the number of times we open an input on the inner Directory (both here and in readDirectly)? This results in a readBlob call which may be charged on a per-request basis.", "author": "DaveCTurner", "createdAt": "2020-01-31T11:01:34Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheDirectory.java", "diffHunk": "@@ -188,33 +206,40 @@ protected void readInternal(final byte[] buffer, final int offset, final int len\n                     if (e instanceof AlreadyClosedException || (e.getCause() != null && e.getCause() instanceof AlreadyClosedException)) {\n                         try {\n                             // cache file was evicted during the range fetching, read bytes directly from source\n-                            bytesRead += readDirectly(pos, pos + len, buffer, off);\n+                            bytesRead = readDirectly(pos, pos + len, buffer, off);\n+                            stats.addDirectBytesRead(bytesRead);\n                             continue;\n                         } catch (Exception inner) {\n                             e.addSuppressed(inner);\n                         }\n                     }\n                     throw new IOException(\"Fail to read data from cache\", e);\n \n+                } finally {\n+                    totalBytesRead += bytesRead;\n                 }\n             }\n-            assert bytesRead == length : \"partial read operation, read [\" + bytesRead + \"] bytes of [\" + length + \"]\";\n+            assert totalBytesRead == length : \"partial read operation, read [\" + totalBytesRead + \"] bytes of [\" + length + \"]\";\n+            stats.incrementBytesRead(lastReadPosition, position, totalBytesRead);\n+            lastReadPosition = position + totalBytesRead;\n         }\n \n         int readCacheFile(FileChannel fc, long end, long position, byte[] buffer, int offset, long length) throws IOException {\n             assert assertFileChannelOpen(fc);\n-            return Channels.readFromFileChannel(fc, position, buffer, offset, Math.toIntExact(Math.min(length, end - position)));\n+            int bytesRead = Channels.readFromFileChannel(fc, position, buffer, offset, Math.toIntExact(Math.min(length, end - position)));\n+            stats.addCachedBytesRead(bytesRead);\n+            return bytesRead;\n         }\n \n         @SuppressForbidden(reason = \"Use positional writes on purpose\")\n         void writeCacheFile(FileChannel fc, long start, long end) throws IOException {\n             assert assertFileChannelOpen(fc);\n             final byte[] copyBuffer = new byte[Math.toIntExact(Math.min(COPY_BUFFER_SIZE, end - start))];\n+            int bytesCopied = 0;\n             try (IndexInput input = in.openInput(cacheFileReference.getFileName(), ioContext)) {", "originalCommit": "409e720e12b8d284d95679518d3b6c1c42d7355a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzQ3NTQ3OQ==", "url": "https://github.com/elastic/elasticsearch/pull/51637#discussion_r373475479", "bodyText": "As it is implemented today, I think it does not result in a readBlob until some bytes are read from the inner IndexInput. But counting the number of times the inner index input is opened is a valuable information so I added an \"inner open\" counter in 208b14f.", "author": "tlrx", "createdAt": "2020-01-31T13:21:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzQyNTI1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzQ3ODk5Mg==", "url": "https://github.com/elastic/elasticsearch/pull/51637#discussion_r373478992", "bodyText": "Oh yes you're absolutely right. To be addressed elsewhere.", "author": "DaveCTurner", "createdAt": "2020-01-31T13:30:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzQyNTI1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzQyODQyMg==", "url": "https://github.com/elastic/elasticsearch/pull/51637#discussion_r373428422", "bodyText": "Also, I think we should add a TRACE-level log recording the specific range we're copying here (and in readDirectly) because I think there will be situations where we need to see the details of the access pattern.", "author": "DaveCTurner", "createdAt": "2020-01-31T11:09:18Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheDirectory.java", "diffHunk": "@@ -188,33 +206,40 @@ protected void readInternal(final byte[] buffer, final int offset, final int len\n                     if (e instanceof AlreadyClosedException || (e.getCause() != null && e.getCause() instanceof AlreadyClosedException)) {\n                         try {\n                             // cache file was evicted during the range fetching, read bytes directly from source\n-                            bytesRead += readDirectly(pos, pos + len, buffer, off);\n+                            bytesRead = readDirectly(pos, pos + len, buffer, off);\n+                            stats.addDirectBytesRead(bytesRead);\n                             continue;\n                         } catch (Exception inner) {\n                             e.addSuppressed(inner);\n                         }\n                     }\n                     throw new IOException(\"Fail to read data from cache\", e);\n \n+                } finally {\n+                    totalBytesRead += bytesRead;\n                 }\n             }\n-            assert bytesRead == length : \"partial read operation, read [\" + bytesRead + \"] bytes of [\" + length + \"]\";\n+            assert totalBytesRead == length : \"partial read operation, read [\" + totalBytesRead + \"] bytes of [\" + length + \"]\";\n+            stats.incrementBytesRead(lastReadPosition, position, totalBytesRead);\n+            lastReadPosition = position + totalBytesRead;\n         }\n \n         int readCacheFile(FileChannel fc, long end, long position, byte[] buffer, int offset, long length) throws IOException {\n             assert assertFileChannelOpen(fc);\n-            return Channels.readFromFileChannel(fc, position, buffer, offset, Math.toIntExact(Math.min(length, end - position)));\n+            int bytesRead = Channels.readFromFileChannel(fc, position, buffer, offset, Math.toIntExact(Math.min(length, end - position)));\n+            stats.addCachedBytesRead(bytesRead);\n+            return bytesRead;\n         }\n \n         @SuppressForbidden(reason = \"Use positional writes on purpose\")\n         void writeCacheFile(FileChannel fc, long start, long end) throws IOException {\n             assert assertFileChannelOpen(fc);\n             final byte[] copyBuffer = new byte[Math.toIntExact(Math.min(COPY_BUFFER_SIZE, end - start))];\n+            int bytesCopied = 0;\n             try (IndexInput input = in.openInput(cacheFileReference.getFileName(), ioContext)) {", "originalCommit": "409e720e12b8d284d95679518d3b6c1c42d7355a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzQ3NTUyNw==", "url": "https://github.com/elastic/elasticsearch/pull/51637#discussion_r373475527", "bodyText": "Added in 208b14f", "author": "tlrx", "createdAt": "2020-01-31T13:21:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzQyODQyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzQzNDc3Ng==", "url": "https://github.com/elastic/elasticsearch/pull/51637#discussion_r373434776", "bodyText": "One of the big open questions about seeking is whether we are seeking forwards in small enough steps that we should have just requested a larger contiguous chunk of the blob up-front. Today the implementation is based on fixed-size chunks, so I think it makes sense to set a fixed-size threshold for what we consider to be a \"large\" seek. I would guess something like 8MB or 16MB would be a good start.\nWe could of course move to a chunk size that is proportional to the size of the underlying file, and in that case it makes more sense for the threshold to be proportional to the file size too.", "author": "DaveCTurner", "createdAt": "2020-01-31T11:26:22Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/IndexInputStats.java", "diffHunk": "@@ -0,0 +1,167 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.searchablesnapshots.cache;\n+\n+import org.elasticsearch.xpack.searchablesnapshots.cache.CacheDirectory.CacheBufferedIndexInput;\n+\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.atomic.LongAdder;\n+import java.util.function.LongConsumer;\n+\n+/**\n+ * {@link IndexInputStats} records stats for a given {@link CacheBufferedIndexInput}.\n+ */\n+public class IndexInputStats {\n+\n+    static final double SEEKING_THRESHOLD = 0.25d;", "originalCommit": "409e720e12b8d284d95679518d3b6c1c42d7355a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzQ3NTc2NA==", "url": "https://github.com/elastic/elasticsearch/pull/51637#discussion_r373475764", "bodyText": "This is a good observation. I pushed 51c4f43 to change the seeking threshold to 8Mb, let me know what you think.", "author": "tlrx", "createdAt": "2020-01-31T13:21:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzQzNDc3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzQ3OTUxOQ==", "url": "https://github.com/elastic/elasticsearch/pull/51637#discussion_r373479519", "bodyText": "\ud83d\udc4d", "author": "DaveCTurner", "createdAt": "2020-01-31T13:31:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzQzNDc3Ng=="}], "type": "inlineReview"}, {"oid": "cba3fc3af84d0f58f9bd69473d70ada39b8fd8ba", "url": "https://github.com/elastic/elasticsearch/commit/cba3fc3af84d0f58f9bd69473d70ada39b8fd8ba", "message": "Fix compilation issues after merging master", "committedDate": "2020-01-31T11:35:15Z", "type": "commit"}, {"oid": "3f8b3a4f7ccfb51c8cea8771d0e3baefd0d2111f", "url": "https://github.com/elastic/elasticsearch/commit/3f8b3a4f7ccfb51c8cea8771d0e3baefd0d2111f", "message": "Ignore seek to same position", "committedDate": "2020-01-31T11:51:46Z", "type": "commit"}, {"oid": "208b14f3161859c6f6d31da70e9499165c12f534", "url": "https://github.com/elastic/elasticsearch/commit/208b14f3161859c6f6d31da70e9499165c12f534", "message": "add innner opening counter + log traces", "committedDate": "2020-01-31T12:42:38Z", "type": "commit"}, {"oid": "51c4f43a5753d38d81beabb83024c9268b99913d", "url": "https://github.com/elastic/elasticsearch/commit/51c4f43a5753d38d81beabb83024c9268b99913d", "message": "Seek threshold in MB", "committedDate": "2020-01-31T13:17:18Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzQ3ODIyNw==", "url": "https://github.com/elastic/elasticsearch/pull/51637#discussion_r373478227", "bodyText": "Ah, I think this will not include the shard ID so we might struggle to interpret the logs when there are lots of shards to search. I think logging cacheFileReference itself gives us everything we need.", "author": "DaveCTurner", "createdAt": "2020-01-31T13:28:23Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheDirectory.java", "diffHunk": "@@ -202,33 +224,43 @@ protected void readInternal(final byte[] buffer, final int offset, final int len\n                     if (e instanceof AlreadyClosedException || (e.getCause() != null && e.getCause() instanceof AlreadyClosedException)) {\n                         try {\n                             // cache file was evicted during the range fetching, read bytes directly from source\n-                            bytesRead += readDirectly(pos, pos + len, buffer, off);\n+                            bytesRead = readDirectly(pos, pos + len, buffer, off);\n                             continue;\n                         } catch (Exception inner) {\n                             e.addSuppressed(inner);\n                         }\n                     }\n                     throw new IOException(\"Fail to read data from cache\", e);\n \n+                } finally {\n+                    totalBytesRead += bytesRead;\n                 }\n             }\n-            assert bytesRead == length : \"partial read operation, read [\" + bytesRead + \"] bytes of [\" + length + \"]\";\n+            assert totalBytesRead == length : \"partial read operation, read [\" + totalBytesRead + \"] bytes of [\" + length + \"]\";\n+            stats.incrementBytesRead(lastReadPosition, position, totalBytesRead);\n+            lastReadPosition = position + totalBytesRead;\n         }\n \n         int readCacheFile(FileChannel fc, long end, long position, byte[] buffer, int offset, long length) throws IOException {\n             assert assertFileChannelOpen(fc);\n-            return Channels.readFromFileChannel(fc, position, buffer, offset, Math.toIntExact(Math.min(length, end - position)));\n+            int bytesRead = Channels.readFromFileChannel(fc, position, buffer, offset, Math.toIntExact(Math.min(length, end - position)));\n+            stats.addCachedBytesRead(bytesRead);\n+            return bytesRead;\n         }\n \n         @SuppressForbidden(reason = \"Use positional writes on purpose\")\n         void writeCacheFile(FileChannel fc, long start, long end) throws IOException {\n             assert assertFileChannelOpen(fc);\n+            final String fileName = cacheFileReference.getFileName();\n             final byte[] copyBuffer = new byte[Math.toIntExact(Math.min(COPY_BUFFER_SIZE, end - start))];\n-            try (IndexInput input = in.openInput(cacheFileReference.getFileName(), ioContext)) {\n+            logger.trace(() -> new ParameterizedMessage(\"writing range [{}-{}] of file [{}] to cache file\", start, end, fileName));", "originalCommit": "51c4f43a5753d38d81beabb83024c9268b99913d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzQ5MTEwNw==", "url": "https://github.com/elastic/elasticsearch/pull/51637#discussion_r373491107", "bodyText": "Makes sense, I pushed 9de8453", "author": "tlrx", "createdAt": "2020-01-31T13:57:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzQ3ODIyNw=="}], "type": "inlineReview"}, {"oid": "9de84533884a13e397406ed16aa5638cccb8ea9a", "url": "https://github.com/elastic/elasticsearch/commit/9de84533884a13e397406ed16aa5638cccb8ea9a", "message": "adapt logging", "committedDate": "2020-01-31T13:53:37Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzQ5MjU3MA==", "url": "https://github.com/elastic/elasticsearch/pull/51637#discussion_r373492570", "bodyText": "Sorry, here too :)", "author": "DaveCTurner", "createdAt": "2020-01-31T14:00:55Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheDirectory.java", "diffHunk": "@@ -279,10 +312,13 @@ public String toString() {\n         }\n \n         private int readDirectly(long start, long end, byte[] buffer, int offset) throws IOException {\n+            final String fileName = cacheFileReference.getFileName();\n             final byte[] copyBuffer = new byte[Math.toIntExact(Math.min(COPY_BUFFER_SIZE, end - start))];\n+            logger.trace(() -> new ParameterizedMessage(\"direct reading of range [{}-{}] from file [{}]\", start, end, fileName));", "originalCommit": "9de84533884a13e397406ed16aa5638cccb8ea9a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzQ5ODg4MQ==", "url": "https://github.com/elastic/elasticsearch/pull/51637#discussion_r373498881", "bodyText": "\ud83d\udc4d", "author": "tlrx", "createdAt": "2020-01-31T14:14:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzQ5MjU3MA=="}], "type": "inlineReview"}, {"oid": "64fe3eb482a6f89ed13c9eaf06886c0682a33ea2", "url": "https://github.com/elastic/elasticsearch/commit/64fe3eb482a6f89ed13c9eaf06886c0682a33ea2", "message": "adapt logging (again)", "committedDate": "2020-01-31T14:13:06Z", "type": "commit"}]}