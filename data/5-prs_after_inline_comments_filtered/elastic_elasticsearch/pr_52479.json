{"pr_number": 52479, "pr_title": "Add Blob Download Retries to GCS Repository", "pr_createdAt": "2020-02-18T14:40:07Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/52479", "timeline": [{"oid": "e6815fa07328e5d68c40f96d099441408c2e6460", "url": "https://github.com/elastic/elasticsearch/commit/e6815fa07328e5d68c40f96d099441408c2e6460", "message": "Add Blob Download Retries to GCS Repository\n\nExactly as #46589 (and kept as close to it as possible code wise so we can dry things up in a follow-up potentially) but for GCS.\n\nCloses #52319", "committedDate": "2020-02-18T14:36:48Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTIxMzU3Mg==", "url": "https://github.com/elastic/elasticsearch/pull/52479#discussion_r381213572", "bodyText": "Maybe only seek if currentOffset > 0L?", "author": "tlrx", "createdAt": "2020-02-19T10:45:27Z", "path": "plugins/repository-gcs/src/main/java/org/elasticsearch/repositories/gcs/GoogleCloudStorageRetryingInputStream.java", "diffHunk": "@@ -0,0 +1,179 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.elasticsearch.repositories.gcs;\n+\n+import com.google.cloud.ReadChannel;\n+import com.google.cloud.storage.BlobId;\n+import com.google.cloud.storage.Storage;\n+import com.google.cloud.storage.StorageException;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.common.SuppressForbidden;\n+import org.elasticsearch.core.internal.io.IOUtils;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.Channels;\n+import java.nio.channels.ReadableByteChannel;\n+import java.nio.file.NoSuchFileException;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+import static java.net.HttpURLConnection.HTTP_NOT_FOUND;\n+\n+/**\n+ * Wrapper around reads from GCS that will retry blob downloads that fail part-way through, resuming from where the failure occurred.\n+ * This should be handled by the SDK but it isn't today. This should be revisited in the future (e.g. before removing\n+ * the {@link org.elasticsearch.Version#V_7_0_0} version constant) and removed if the SDK handles retries itself in the future.\n+ */\n+class GoogleCloudStorageRetryingInputStream extends InputStream {\n+\n+    private static final Logger logger = LogManager.getLogger(GoogleCloudStorageRetryingInputStream.class);\n+\n+    static final int MAX_SUPPRESSED_EXCEPTIONS = 10;\n+\n+    private final Storage client;\n+\n+    private final BlobId blobId;\n+\n+    private final int maxRetries;\n+\n+    private InputStream currentStream;\n+    private int attempt = 1;\n+    private List<StorageException> failures = new ArrayList<>(MAX_SUPPRESSED_EXCEPTIONS);\n+    private long currentOffset;\n+    private boolean closed;\n+\n+    GoogleCloudStorageRetryingInputStream(Storage client, BlobId blobId) throws IOException {\n+        this.client = client;\n+        this.blobId = blobId;\n+        this.maxRetries = client.getOptions().getRetrySettings().getMaxAttempts() + 1;\n+        currentStream = openStream();\n+    }\n+\n+    private InputStream openStream() throws IOException {\n+        try {\n+            final ReadChannel readChannel = SocketAccess.doPrivilegedIOException(() -> client.reader(blobId));\n+            readChannel.seek(currentOffset);", "originalCommit": "e6815fa07328e5d68c40f96d099441408c2e6460", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTIxODc3MQ==", "url": "https://github.com/elastic/elasticsearch/pull/52479#discussion_r381218771", "bodyText": "This doesn't have any IO impact in the SDK (it just sets an long field that is then used when firing off the actual request) so I figured why do 3 lines instead of 1 unless we have to? :)", "author": "original-brownbear", "createdAt": "2020-02-19T10:55:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTIxMzU3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTIyMjI3Mw==", "url": "https://github.com/elastic/elasticsearch/pull/52479#discussion_r381222273", "bodyText": "I figured why do 3 lines instead of 1 unless we have to? :)\n\nI see things differently, why always seek to the beginning when most of the time it's not necessary? :)\nAnyway, it's nitpicking so do as you prefer :)", "author": "tlrx", "createdAt": "2020-02-19T11:02:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTIxMzU3Mg=="}], "type": "inlineReview"}, {"oid": "a976da8a4b90fe35ef6fe07bb9681016fd11ec4b", "url": "https://github.com/elastic/elasticsearch/commit/a976da8a4b90fe35ef6fe07bb9681016fd11ec4b", "message": "Merge remote-tracking branch 'elastic/master' into 52319", "committedDate": "2020-02-19T11:23:39Z", "type": "commit"}, {"oid": "e1108a946e217255630e0623eaab6732563f75f6", "url": "https://github.com/elastic/elasticsearch/commit/e1108a946e217255630e0623eaab6732563f75f6", "message": "CR: don't seek redundantly :)", "committedDate": "2020-02-19T11:24:26Z", "type": "commit"}]}