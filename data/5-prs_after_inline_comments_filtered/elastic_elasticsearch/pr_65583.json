{"pr_number": 65583, "pr_title": "Apply can match phase on coordinator when the min max field data is available at the coordinator.", "pr_createdAt": "2020-11-30T09:58:39Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/65583", "timeline": [{"oid": "fadfbda07b4a86c5d8a28e524c6d57d17119bdc4", "url": "https://github.com/elastic/elasticsearch/commit/fadfbda07b4a86c5d8a28e524c6d57d17119bdc4", "message": "Apply can match phase on coordinator when possible.\n\nThis commit introduces an optimization that allows skipping shardsthat\nare not necessary directly on the coordinator for time based indices.\nThis is possible for frozen and searchable snapshots since those store\ntheir min/max timestamp range in their IndexMetadata (introduced in #65689).\nFor indices that don't have that information available, the behaviour is\nthe sameas it used to be.", "committedDate": "2020-12-09T09:23:46Z", "type": "commit"}, {"oid": "fadfbda07b4a86c5d8a28e524c6d57d17119bdc4", "url": "https://github.com/elastic/elasticsearch/commit/fadfbda07b4a86c5d8a28e524c6d57d17119bdc4", "message": "Apply can match phase on coordinator when possible.\n\nThis commit introduces an optimization that allows skipping shardsthat\nare not necessary directly on the coordinator for time based indices.\nThis is possible for frozen and searchable snapshots since those store\ntheir min/max timestamp range in their IndexMetadata (introduced in #65689).\nFor indices that don't have that information available, the behaviour is\nthe sameas it used to be.", "committedDate": "2020-12-09T09:23:46Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTY5Njk3NQ==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r539696975", "bodyText": "Can you add javadocs ?", "author": "jimczi", "createdAt": "2020-12-09T22:30:17Z", "path": "server/src/main/java/org/elasticsearch/index/query/CoordinatorRewriteContext.java", "diffHunk": "@@ -0,0 +1,74 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.index.query;\n+\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.io.stream.NamedWriteableRegistry;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.mapper.DateFieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+\n+import java.util.function.LongSupplier;\n+", "originalCommit": "fadfbda07b4a86c5d8a28e524c6d57d17119bdc4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTk4ODU2Mw==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r541988563", "bodyText": "Fixed in eada99e", "author": "fcofdez", "createdAt": "2020-12-13T19:28:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTY5Njk3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTcxMTQ0Mg==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r539711442", "bodyText": "What happens if the timestamp field is of type date_nanos ? We cannot compare the raw values since they are stored in a different resolution. Are we missing a conversion here ?", "author": "jimczi", "createdAt": "2020-12-09T22:58:55Z", "path": "server/src/main/java/org/elasticsearch/index/query/RangeQueryBuilder.java", "diffHunk": "@@ -428,6 +429,19 @@ public String getWriteableName() {\n \n     // Overridable for testing only\n     protected MappedFieldType.Relation getRelation(QueryRewriteContext queryRewriteContext) throws IOException {\n+        CoordinatorRewriteContext coordinatorRewriteContext = queryRewriteContext.convertToCoordinatorRewriteContext();\n+        if (coordinatorRewriteContext != null) {\n+            final MappedFieldType fieldType = coordinatorRewriteContext.getFieldType(fieldName);\n+            if (fieldType instanceof DateFieldMapper.DateFieldType) {\n+                final DateFieldMapper.DateFieldType dateFieldType = (DateFieldMapper.DateFieldType) fieldType;\n+                long minTimestamp = coordinatorRewriteContext.getMinTimestamp();\n+                long maxTimestamp = coordinatorRewriteContext.getMaxTimestamp();\n+                DateMathParser dateMathParser = getForceDateParser();\n+                return dateFieldType.isFieldWithinQuery(minTimestamp, maxTimestamp, from, to, includeLower,", "originalCommit": "fadfbda07b4a86c5d8a28e524c6d57d17119bdc4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTk4ODU3MA==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r541988570", "bodyText": "Fixed in eada99e", "author": "fcofdez", "createdAt": "2020-12-13T19:28:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTcxMTQ0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTcxNDQ4Nw==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r539714487", "bodyText": "Should we use the fork utility of the parent class to avoid stack overflow in case lots of shards are skipped ? That's probably not needed but we expect an async action here so better to be safe imo.", "author": "jimczi", "createdAt": "2020-12-09T23:05:22Z", "path": "server/src/main/java/org/elasticsearch/action/search/CanMatchPreFilterSearchPhase.java", "diffHunk": "@@ -118,6 +134,40 @@ protected SearchPhase getNextPhase(SearchPhaseResults<CanMatchResponse> results,\n         return new GroupShardsIterator<>(sortShards(shardsIts, results.minAndMaxes, fieldSort.order()));\n     }\n \n+    @Override\n+    protected void performPhaseOnShard(int shardIndex, SearchShardIterator shardIt, SearchShardTarget shard) {\n+        CoordinatorRewriteContext coordinatorRewriteContext =\n+            coordinatorRewriteContextProvider.getCoordinatorRewriteContext(shardIt.shardId().getIndex());\n+\n+        if (coordinatorRewriteContext == null) {\n+            super.performPhaseOnShard(shardIndex, shardIt, shard);\n+            return;\n+        }\n+\n+        try {\n+            ShardSearchRequest request = buildShardSearchRequest(shardIt, shardIndex);\n+            boolean canMatch = SearchService.queryStillMatchesAfterRewrite(request, coordinatorRewriteContext);\n+\n+            // Trigger the query as there's still a chance that we can skip\n+            // this shard given other query filters that we cannot apply\n+            // in the coordinator\n+            if (canMatch) {\n+                super.performPhaseOnShard(shardIndex, shardIt, shard);\n+                return;\n+            }\n+\n+            CanMatchResponse result = new CanMatchResponse(canMatch, null);\n+            result.setSearchShardTarget(shard == null ? new SearchShardTarget(null, shardIt.shardId(), shardIt.getClusterAlias(),\n+                shardIt.getOriginalIndices()) : shard);\n+            result.setShardIndex(shardIndex);\n+            onShardResult(result, shardIt);", "originalCommit": "fadfbda07b4a86c5d8a28e524c6d57d17119bdc4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTk4ODU0Ng==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r541988546", "bodyText": "Fixed in eada99e", "author": "fcofdez", "createdAt": "2020-12-13T19:28:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTcxNDQ4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDA3NTY2Ng==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r540075666", "bodyText": "I think EMPTY can be meaningfully handled by the can-match handler if there is a timestamp condition. Clearly an edge case, but seems wrong to not handle this?", "author": "henningandersen", "createdAt": "2020-12-10T11:01:35Z", "path": "server/src/main/java/org/elasticsearch/index/shard/IndexLongFieldRange.java", "diffHunk": "@@ -76,6 +76,13 @@ public boolean isComplete() {\n         return shards == null;\n     }\n \n+    /**\n+     * @return whether this range includes information from all shards and can be used meaningfully.\n+     */\n+    public boolean containsAllShardRanges() {\n+        return isComplete() && this != IndexLongFieldRange.EMPTY && this != IndexLongFieldRange.UNKNOWN;", "originalCommit": "fadfbda07b4a86c5d8a28e524c6d57d17119bdc4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDA4NjA2MA==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r540086060", "bodyText": "Can we randomly choose between date and date-nanos?", "author": "henningandersen", "createdAt": "2020-12-10T11:17:51Z", "path": "x-pack/plugin/searchable-snapshots/src/internalClusterTest/java/org/elasticsearch/xpack/searchablesnapshots/SearchableSnapshotsCanMatchOnCoordinatorIntegTests.java", "diffHunk": "@@ -0,0 +1,288 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.searchablesnapshots;\n+\n+import org.elasticsearch.action.admin.indices.recovery.RecoveryResponse;\n+import org.elasticsearch.action.index.IndexRequestBuilder;\n+import org.elasticsearch.action.search.SearchPhaseExecutionException;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.cluster.metadata.DataStream;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.routing.IndexRoutingTable;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeUnit;\n+import org.elasticsearch.common.unit.ByteSizeValue;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.IndexSettings;\n+import org.elasticsearch.index.mapper.DateFieldMapper;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.index.shard.IndexLongFieldRange;\n+import org.elasticsearch.indices.IndicesService;\n+import org.elasticsearch.indices.recovery.RecoveryState;\n+import org.elasticsearch.plugins.Plugin;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.snapshots.SnapshotId;\n+import org.elasticsearch.snapshots.mockstore.MockRepository;\n+import org.elasticsearch.test.ESIntegTestCase;\n+import org.elasticsearch.test.transport.MockTransportService;\n+import org.elasticsearch.xpack.core.searchablesnapshots.MountSearchableSnapshotAction;\n+import org.elasticsearch.xpack.core.searchablesnapshots.MountSearchableSnapshotRequest;\n+import org.elasticsearch.xpack.searchablesnapshots.cache.CacheService;\n+import org.joda.time.Instant;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Locale;\n+\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.INDEX_ROUTING_REQUIRE_GROUP_SETTING;\n+import static org.elasticsearch.index.IndexSettings.INDEX_SOFT_DELETES_SETTING;\n+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.greaterThanOrEqualTo;\n+import static org.hamcrest.Matchers.lessThanOrEqualTo;\n+import static org.hamcrest.Matchers.not;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.hamcrest.Matchers.sameInstance;\n+\n+@ESIntegTestCase.ClusterScope(scope = ESIntegTestCase.Scope.TEST, numDataNodes = 0)\n+public class SearchableSnapshotsCanMatchOnCoordinatorIntegTests extends BaseSearchableSnapshotsIntegTestCase {\n+\n+    @Override\n+    protected Collection<Class<? extends Plugin>> nodePlugins() {\n+        return List.of(LocalStateSearchableSnapshots.class, MockTransportService.TestPlugin.class, MockRepository.Plugin.class);\n+    }\n+\n+    @Override\n+    protected Settings nodeSettings(int nodeOrdinal) {\n+        return Settings.builder()\n+            .put(super.nodeSettings(nodeOrdinal))\n+            // Use an unbound cache so we can recover the searchable snapshot completely all the times\n+            .put(CacheService.SNAPSHOT_CACHE_SIZE_SETTING.getKey(), new ByteSizeValue(Long.MAX_VALUE, ByteSizeUnit.BYTES))\n+            .build();\n+    }\n+\n+    public void testSearchableSnapshotShardsAreSkippedWithoutQueryingAnyNodeWhenTheyAreOutsideOfTheQueryRange() throws Exception {\n+        internalCluster().startMasterOnlyNode();\n+        internalCluster().startCoordinatingOnlyNode(Settings.EMPTY);\n+        final String dataNodeHoldingRegularIndex = internalCluster().startDataOnlyNode();\n+        final String dataNodeHoldingSearchableSnapshot = internalCluster().startDataOnlyNode();\n+        final IndicesService indicesService = internalCluster().getInstance(IndicesService.class, dataNodeHoldingSearchableSnapshot);\n+\n+        final String indexOutsideSearchRange = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        final int indexOutsideSearchRangeShardCount = randomIntBetween(1, 3);\n+        createIndexWithTimestamp(indexOutsideSearchRange, indexOutsideSearchRangeShardCount, Settings.EMPTY);\n+\n+        final String indexWithinSearchRange = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        final int indexWithinSearchRangeShardCount = randomIntBetween(1, 3);\n+        createIndexWithTimestamp(\n+            indexWithinSearchRange,\n+            indexWithinSearchRangeShardCount,\n+            Settings.builder()\n+                .put(INDEX_ROUTING_REQUIRE_GROUP_SETTING.getConcreteSettingForNamespace(\"_name\").getKey(), dataNodeHoldingRegularIndex)\n+                .build()\n+        );\n+\n+        final int totalShards = indexOutsideSearchRangeShardCount + indexWithinSearchRangeShardCount;\n+\n+        indexDocumentsWithTimestampWithinDate(indexOutsideSearchRange, between(0, 1000), \"2020-11-26T%02d:%02d:%02d.%09dZ\");\n+        indexDocumentsWithTimestampWithinDate(indexWithinSearchRange, between(0, 1000), \"2020-11-28T%02d:%02d:%02d.%09dZ\");\n+\n+        final String repositoryName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        createRepository(repositoryName, \"mock\");\n+\n+        final SnapshotId snapshotId = createSnapshot(repositoryName, \"snapshot-1\", List.of(indexOutsideSearchRange)).snapshotId();\n+        assertAcked(client().admin().indices().prepareDelete(indexOutsideSearchRange));\n+\n+        final String searchableSnapshotIndexOutsideSearchRange = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+\n+        // Block the repository for the node holding the searchable snapshot shards\n+        // to delay its restore\n+        blockDataNode(repositoryName, dataNodeHoldingSearchableSnapshot);\n+\n+        // Force the searchable snapshot to be allocated in a particular node\n+        Settings restoredIndexSettings = Settings.builder()\n+            .put(IndexSettings.INDEX_CHECK_ON_STARTUP.getKey(), Boolean.FALSE.toString())\n+            .put(INDEX_ROUTING_REQUIRE_GROUP_SETTING.getConcreteSettingForNamespace(\"_name\").getKey(), dataNodeHoldingSearchableSnapshot)\n+            .build();\n+\n+        final MountSearchableSnapshotRequest mountRequest = new MountSearchableSnapshotRequest(\n+            searchableSnapshotIndexOutsideSearchRange,\n+            repositoryName,\n+            snapshotId.getName(),\n+            indexOutsideSearchRange,\n+            restoredIndexSettings,\n+            Strings.EMPTY_ARRAY,\n+            false\n+        );\n+        client().execute(MountSearchableSnapshotAction.INSTANCE, mountRequest).actionGet();\n+\n+        final IndexMetadata indexMetadata = getIndexMetadata(searchableSnapshotIndexOutsideSearchRange);\n+        assertThat(indexMetadata.getTimestampMillisRange(), equalTo(IndexLongFieldRange.NO_SHARDS));\n+\n+        DateFieldMapper.DateFieldType timestampFieldType = indicesService.getTimestampFieldType(indexMetadata.getIndex());\n+        assertThat(timestampFieldType, nullValue());\n+\n+        final boolean includeIndexCoveringSearchRangeInSearchRequest = randomBoolean();\n+        List<String> indicesToSearch = new ArrayList<>();\n+        if (includeIndexCoveringSearchRangeInSearchRequest) {\n+            indicesToSearch.add(indexWithinSearchRange);\n+        }\n+        indicesToSearch.add(searchableSnapshotIndexOutsideSearchRange);\n+        SearchRequest request = new SearchRequest().indices(indicesToSearch.toArray(new String[0]))\n+            .source(\n+                new SearchSourceBuilder().query(\n+                    QueryBuilders.rangeQuery(DataStream.TimestampField.FIXED_TIMESTAMP_FIELD)\n+                        .from(\"2020-11-28T00:00:00.000000000Z\", true)\n+                        .to(\"2020-11-29T00:00:00.000000000Z\")\n+                )\n+            );\n+\n+        if (includeIndexCoveringSearchRangeInSearchRequest) {\n+            SearchResponse searchResponse = client().search(request).actionGet();\n+\n+            // All the regular index searches succeeded\n+            assertThat(searchResponse.getSuccessfulShards(), equalTo(indexWithinSearchRangeShardCount));\n+            // All the searchable snapshots shard search failed\n+            assertThat(searchResponse.getFailedShards(), equalTo(indexOutsideSearchRangeShardCount));\n+            assertThat(searchResponse.getSkippedShards(), equalTo(0));\n+            assertThat(searchResponse.getTotalShards(), equalTo(totalShards));\n+        } else {\n+            // All shards failed, since all shards are unassigned and the IndexMetadata min/max timestamp\n+            // is not available yet\n+            expectThrows(SearchPhaseExecutionException.class, () -> client().search(request).actionGet());\n+        }\n+\n+        // Allow the searchable snapshots to be finally mounted\n+        unblockNode(repositoryName, dataNodeHoldingSearchableSnapshot);\n+        waitUntilRecoveryIsDone(searchableSnapshotIndexOutsideSearchRange);\n+        ensureGreen(searchableSnapshotIndexOutsideSearchRange);\n+\n+        final IndexMetadata updatedIndexMetadata = getIndexMetadata(searchableSnapshotIndexOutsideSearchRange);\n+        final IndexLongFieldRange updatedTimestampMillisRange = updatedIndexMetadata.getTimestampMillisRange();\n+        assertThat(updatedTimestampMillisRange.isComplete(), equalTo(true));\n+        assertThat(updatedTimestampMillisRange, not(sameInstance(IndexLongFieldRange.EMPTY)));\n+        assertThat(updatedTimestampMillisRange.getMin(), greaterThanOrEqualTo(Instant.parse(\"2020-11-26T00:00:00Z\").getMillis()));\n+        assertThat(updatedTimestampMillisRange.getMax(), lessThanOrEqualTo(Instant.parse(\"2020-11-27T00:00:00Z\").getMillis()));\n+        assertThat(indicesService.getTimestampFieldType(updatedIndexMetadata.getIndex()), notNullValue());\n+\n+        // Stop the node holding the searchable snapshots, and since we defined\n+        // the index allocation criteria to require the searchable snapshot\n+        // index to be allocated in that node, the shards should remain unassigned\n+        internalCluster().stopNode(dataNodeHoldingSearchableSnapshot);\n+        waitUntilAllShardsAreUnassigned(updatedIndexMetadata.getIndex());\n+\n+        if (includeIndexCoveringSearchRangeInSearchRequest) {\n+            SearchResponse newSearchResponse = client().search(request).actionGet();\n+\n+            assertThat(newSearchResponse.getSkippedShards(), equalTo(indexOutsideSearchRangeShardCount));\n+            assertThat(newSearchResponse.getSuccessfulShards(), equalTo(totalShards));\n+            assertThat(newSearchResponse.getFailedShards(), equalTo(0));\n+            assertThat(newSearchResponse.getTotalShards(), equalTo(totalShards));\n+        } else {\n+            if (indexOutsideSearchRangeShardCount == 1) {\n+                expectThrows(SearchPhaseExecutionException.class, () -> client().search(request).actionGet());\n+            } else {\n+                SearchResponse newSearchResponse = client().search(request).actionGet();\n+                // When all shards are skipped, at least one of them should be queried in order to\n+                // provide a proper search response.\n+                assertThat(newSearchResponse.getSkippedShards(), equalTo(indexOutsideSearchRangeShardCount - 1));\n+                assertThat(newSearchResponse.getSuccessfulShards(), equalTo(indexOutsideSearchRangeShardCount - 1));\n+                assertThat(newSearchResponse.getFailedShards(), equalTo(1));\n+                assertThat(newSearchResponse.getTotalShards(), equalTo(indexOutsideSearchRangeShardCount));\n+            }\n+        }\n+    }\n+\n+    private void createIndexWithTimestamp(String indexName, int numShards, Settings extraSettings) throws IOException {\n+        assertAcked(\n+            client().admin()\n+                .indices()\n+                .prepareCreate(indexName)\n+                .setMapping(\n+                    XContentFactory.jsonBuilder()\n+                        .startObject()\n+                        .startObject(\"properties\")\n+                        .startObject(DataStream.TimestampField.FIXED_TIMESTAMP_FIELD)\n+                        .field(\"type\", \"date_nanos\")", "originalCommit": "fadfbda07b4a86c5d8a28e524c6d57d17119bdc4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTk4ODExMg==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r541988112", "bodyText": "Fixed in eada99e", "author": "fcofdez", "createdAt": "2020-12-13T19:25:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDA4NjA2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDA4NzQzMw==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r540087433", "bodyText": "Perhaps also assert that we get the right number of total hits?", "author": "henningandersen", "createdAt": "2020-12-10T11:20:07Z", "path": "x-pack/plugin/searchable-snapshots/src/internalClusterTest/java/org/elasticsearch/xpack/searchablesnapshots/SearchableSnapshotsCanMatchOnCoordinatorIntegTests.java", "diffHunk": "@@ -0,0 +1,288 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.searchablesnapshots;\n+\n+import org.elasticsearch.action.admin.indices.recovery.RecoveryResponse;\n+import org.elasticsearch.action.index.IndexRequestBuilder;\n+import org.elasticsearch.action.search.SearchPhaseExecutionException;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.cluster.metadata.DataStream;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.routing.IndexRoutingTable;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeUnit;\n+import org.elasticsearch.common.unit.ByteSizeValue;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.IndexSettings;\n+import org.elasticsearch.index.mapper.DateFieldMapper;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.index.shard.IndexLongFieldRange;\n+import org.elasticsearch.indices.IndicesService;\n+import org.elasticsearch.indices.recovery.RecoveryState;\n+import org.elasticsearch.plugins.Plugin;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.snapshots.SnapshotId;\n+import org.elasticsearch.snapshots.mockstore.MockRepository;\n+import org.elasticsearch.test.ESIntegTestCase;\n+import org.elasticsearch.test.transport.MockTransportService;\n+import org.elasticsearch.xpack.core.searchablesnapshots.MountSearchableSnapshotAction;\n+import org.elasticsearch.xpack.core.searchablesnapshots.MountSearchableSnapshotRequest;\n+import org.elasticsearch.xpack.searchablesnapshots.cache.CacheService;\n+import org.joda.time.Instant;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Locale;\n+\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.INDEX_ROUTING_REQUIRE_GROUP_SETTING;\n+import static org.elasticsearch.index.IndexSettings.INDEX_SOFT_DELETES_SETTING;\n+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.greaterThanOrEqualTo;\n+import static org.hamcrest.Matchers.lessThanOrEqualTo;\n+import static org.hamcrest.Matchers.not;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.hamcrest.Matchers.sameInstance;\n+\n+@ESIntegTestCase.ClusterScope(scope = ESIntegTestCase.Scope.TEST, numDataNodes = 0)\n+public class SearchableSnapshotsCanMatchOnCoordinatorIntegTests extends BaseSearchableSnapshotsIntegTestCase {\n+\n+    @Override\n+    protected Collection<Class<? extends Plugin>> nodePlugins() {\n+        return List.of(LocalStateSearchableSnapshots.class, MockTransportService.TestPlugin.class, MockRepository.Plugin.class);\n+    }\n+\n+    @Override\n+    protected Settings nodeSettings(int nodeOrdinal) {\n+        return Settings.builder()\n+            .put(super.nodeSettings(nodeOrdinal))\n+            // Use an unbound cache so we can recover the searchable snapshot completely all the times\n+            .put(CacheService.SNAPSHOT_CACHE_SIZE_SETTING.getKey(), new ByteSizeValue(Long.MAX_VALUE, ByteSizeUnit.BYTES))\n+            .build();\n+    }\n+\n+    public void testSearchableSnapshotShardsAreSkippedWithoutQueryingAnyNodeWhenTheyAreOutsideOfTheQueryRange() throws Exception {\n+        internalCluster().startMasterOnlyNode();\n+        internalCluster().startCoordinatingOnlyNode(Settings.EMPTY);\n+        final String dataNodeHoldingRegularIndex = internalCluster().startDataOnlyNode();\n+        final String dataNodeHoldingSearchableSnapshot = internalCluster().startDataOnlyNode();\n+        final IndicesService indicesService = internalCluster().getInstance(IndicesService.class, dataNodeHoldingSearchableSnapshot);\n+\n+        final String indexOutsideSearchRange = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        final int indexOutsideSearchRangeShardCount = randomIntBetween(1, 3);\n+        createIndexWithTimestamp(indexOutsideSearchRange, indexOutsideSearchRangeShardCount, Settings.EMPTY);\n+\n+        final String indexWithinSearchRange = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        final int indexWithinSearchRangeShardCount = randomIntBetween(1, 3);\n+        createIndexWithTimestamp(\n+            indexWithinSearchRange,\n+            indexWithinSearchRangeShardCount,\n+            Settings.builder()\n+                .put(INDEX_ROUTING_REQUIRE_GROUP_SETTING.getConcreteSettingForNamespace(\"_name\").getKey(), dataNodeHoldingRegularIndex)\n+                .build()\n+        );\n+\n+        final int totalShards = indexOutsideSearchRangeShardCount + indexWithinSearchRangeShardCount;\n+\n+        indexDocumentsWithTimestampWithinDate(indexOutsideSearchRange, between(0, 1000), \"2020-11-26T%02d:%02d:%02d.%09dZ\");\n+        indexDocumentsWithTimestampWithinDate(indexWithinSearchRange, between(0, 1000), \"2020-11-28T%02d:%02d:%02d.%09dZ\");\n+\n+        final String repositoryName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        createRepository(repositoryName, \"mock\");\n+\n+        final SnapshotId snapshotId = createSnapshot(repositoryName, \"snapshot-1\", List.of(indexOutsideSearchRange)).snapshotId();\n+        assertAcked(client().admin().indices().prepareDelete(indexOutsideSearchRange));\n+\n+        final String searchableSnapshotIndexOutsideSearchRange = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+\n+        // Block the repository for the node holding the searchable snapshot shards\n+        // to delay its restore\n+        blockDataNode(repositoryName, dataNodeHoldingSearchableSnapshot);\n+\n+        // Force the searchable snapshot to be allocated in a particular node\n+        Settings restoredIndexSettings = Settings.builder()\n+            .put(IndexSettings.INDEX_CHECK_ON_STARTUP.getKey(), Boolean.FALSE.toString())\n+            .put(INDEX_ROUTING_REQUIRE_GROUP_SETTING.getConcreteSettingForNamespace(\"_name\").getKey(), dataNodeHoldingSearchableSnapshot)\n+            .build();\n+\n+        final MountSearchableSnapshotRequest mountRequest = new MountSearchableSnapshotRequest(\n+            searchableSnapshotIndexOutsideSearchRange,\n+            repositoryName,\n+            snapshotId.getName(),\n+            indexOutsideSearchRange,\n+            restoredIndexSettings,\n+            Strings.EMPTY_ARRAY,\n+            false\n+        );\n+        client().execute(MountSearchableSnapshotAction.INSTANCE, mountRequest).actionGet();\n+\n+        final IndexMetadata indexMetadata = getIndexMetadata(searchableSnapshotIndexOutsideSearchRange);\n+        assertThat(indexMetadata.getTimestampMillisRange(), equalTo(IndexLongFieldRange.NO_SHARDS));\n+\n+        DateFieldMapper.DateFieldType timestampFieldType = indicesService.getTimestampFieldType(indexMetadata.getIndex());\n+        assertThat(timestampFieldType, nullValue());\n+\n+        final boolean includeIndexCoveringSearchRangeInSearchRequest = randomBoolean();\n+        List<String> indicesToSearch = new ArrayList<>();\n+        if (includeIndexCoveringSearchRangeInSearchRequest) {\n+            indicesToSearch.add(indexWithinSearchRange);\n+        }\n+        indicesToSearch.add(searchableSnapshotIndexOutsideSearchRange);\n+        SearchRequest request = new SearchRequest().indices(indicesToSearch.toArray(new String[0]))\n+            .source(\n+                new SearchSourceBuilder().query(\n+                    QueryBuilders.rangeQuery(DataStream.TimestampField.FIXED_TIMESTAMP_FIELD)\n+                        .from(\"2020-11-28T00:00:00.000000000Z\", true)\n+                        .to(\"2020-11-29T00:00:00.000000000Z\")\n+                )\n+            );\n+\n+        if (includeIndexCoveringSearchRangeInSearchRequest) {\n+            SearchResponse searchResponse = client().search(request).actionGet();\n+\n+            // All the regular index searches succeeded\n+            assertThat(searchResponse.getSuccessfulShards(), equalTo(indexWithinSearchRangeShardCount));\n+            // All the searchable snapshots shard search failed\n+            assertThat(searchResponse.getFailedShards(), equalTo(indexOutsideSearchRangeShardCount));\n+            assertThat(searchResponse.getSkippedShards(), equalTo(0));\n+            assertThat(searchResponse.getTotalShards(), equalTo(totalShards));\n+        } else {\n+            // All shards failed, since all shards are unassigned and the IndexMetadata min/max timestamp\n+            // is not available yet\n+            expectThrows(SearchPhaseExecutionException.class, () -> client().search(request).actionGet());\n+        }\n+\n+        // Allow the searchable snapshots to be finally mounted\n+        unblockNode(repositoryName, dataNodeHoldingSearchableSnapshot);\n+        waitUntilRecoveryIsDone(searchableSnapshotIndexOutsideSearchRange);\n+        ensureGreen(searchableSnapshotIndexOutsideSearchRange);\n+\n+        final IndexMetadata updatedIndexMetadata = getIndexMetadata(searchableSnapshotIndexOutsideSearchRange);\n+        final IndexLongFieldRange updatedTimestampMillisRange = updatedIndexMetadata.getTimestampMillisRange();\n+        assertThat(updatedTimestampMillisRange.isComplete(), equalTo(true));\n+        assertThat(updatedTimestampMillisRange, not(sameInstance(IndexLongFieldRange.EMPTY)));\n+        assertThat(updatedTimestampMillisRange.getMin(), greaterThanOrEqualTo(Instant.parse(\"2020-11-26T00:00:00Z\").getMillis()));\n+        assertThat(updatedTimestampMillisRange.getMax(), lessThanOrEqualTo(Instant.parse(\"2020-11-27T00:00:00Z\").getMillis()));\n+        assertThat(indicesService.getTimestampFieldType(updatedIndexMetadata.getIndex()), notNullValue());\n+\n+        // Stop the node holding the searchable snapshots, and since we defined\n+        // the index allocation criteria to require the searchable snapshot\n+        // index to be allocated in that node, the shards should remain unassigned\n+        internalCluster().stopNode(dataNodeHoldingSearchableSnapshot);\n+        waitUntilAllShardsAreUnassigned(updatedIndexMetadata.getIndex());\n+\n+        if (includeIndexCoveringSearchRangeInSearchRequest) {\n+            SearchResponse newSearchResponse = client().search(request).actionGet();\n+\n+            assertThat(newSearchResponse.getSkippedShards(), equalTo(indexOutsideSearchRangeShardCount));\n+            assertThat(newSearchResponse.getSuccessfulShards(), equalTo(totalShards));\n+            assertThat(newSearchResponse.getFailedShards(), equalTo(0));\n+            assertThat(newSearchResponse.getTotalShards(), equalTo(totalShards));", "originalCommit": "fadfbda07b4a86c5d8a28e524c6d57d17119bdc4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTk4ODA4Mg==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r541988082", "bodyText": "Fixed in eada99e", "author": "fcofdez", "createdAt": "2020-12-13T19:25:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDA4NzQzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDA4OTgxMg==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r540089812", "bodyText": "I am not sure I get this bit. I would have expected this to simply return a response similar to the case where we include the index covering search range in search request, except the totalShards would be indexOutsideSearchRangeShardCount? It is simply a no hit, since we search a set of indices where no data matches the timestamp criteria.\nNow reading some of the code above I understand this \ud83d\ude42, let us tackle improving this in a follow-up.", "author": "henningandersen", "createdAt": "2020-12-10T11:23:58Z", "path": "x-pack/plugin/searchable-snapshots/src/internalClusterTest/java/org/elasticsearch/xpack/searchablesnapshots/SearchableSnapshotsCanMatchOnCoordinatorIntegTests.java", "diffHunk": "@@ -0,0 +1,288 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.searchablesnapshots;\n+\n+import org.elasticsearch.action.admin.indices.recovery.RecoveryResponse;\n+import org.elasticsearch.action.index.IndexRequestBuilder;\n+import org.elasticsearch.action.search.SearchPhaseExecutionException;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.cluster.metadata.DataStream;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.routing.IndexRoutingTable;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeUnit;\n+import org.elasticsearch.common.unit.ByteSizeValue;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.IndexSettings;\n+import org.elasticsearch.index.mapper.DateFieldMapper;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.index.shard.IndexLongFieldRange;\n+import org.elasticsearch.indices.IndicesService;\n+import org.elasticsearch.indices.recovery.RecoveryState;\n+import org.elasticsearch.plugins.Plugin;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.snapshots.SnapshotId;\n+import org.elasticsearch.snapshots.mockstore.MockRepository;\n+import org.elasticsearch.test.ESIntegTestCase;\n+import org.elasticsearch.test.transport.MockTransportService;\n+import org.elasticsearch.xpack.core.searchablesnapshots.MountSearchableSnapshotAction;\n+import org.elasticsearch.xpack.core.searchablesnapshots.MountSearchableSnapshotRequest;\n+import org.elasticsearch.xpack.searchablesnapshots.cache.CacheService;\n+import org.joda.time.Instant;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Locale;\n+\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.INDEX_ROUTING_REQUIRE_GROUP_SETTING;\n+import static org.elasticsearch.index.IndexSettings.INDEX_SOFT_DELETES_SETTING;\n+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.greaterThanOrEqualTo;\n+import static org.hamcrest.Matchers.lessThanOrEqualTo;\n+import static org.hamcrest.Matchers.not;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.hamcrest.Matchers.sameInstance;\n+\n+@ESIntegTestCase.ClusterScope(scope = ESIntegTestCase.Scope.TEST, numDataNodes = 0)\n+public class SearchableSnapshotsCanMatchOnCoordinatorIntegTests extends BaseSearchableSnapshotsIntegTestCase {\n+\n+    @Override\n+    protected Collection<Class<? extends Plugin>> nodePlugins() {\n+        return List.of(LocalStateSearchableSnapshots.class, MockTransportService.TestPlugin.class, MockRepository.Plugin.class);\n+    }\n+\n+    @Override\n+    protected Settings nodeSettings(int nodeOrdinal) {\n+        return Settings.builder()\n+            .put(super.nodeSettings(nodeOrdinal))\n+            // Use an unbound cache so we can recover the searchable snapshot completely all the times\n+            .put(CacheService.SNAPSHOT_CACHE_SIZE_SETTING.getKey(), new ByteSizeValue(Long.MAX_VALUE, ByteSizeUnit.BYTES))\n+            .build();\n+    }\n+\n+    public void testSearchableSnapshotShardsAreSkippedWithoutQueryingAnyNodeWhenTheyAreOutsideOfTheQueryRange() throws Exception {\n+        internalCluster().startMasterOnlyNode();\n+        internalCluster().startCoordinatingOnlyNode(Settings.EMPTY);\n+        final String dataNodeHoldingRegularIndex = internalCluster().startDataOnlyNode();\n+        final String dataNodeHoldingSearchableSnapshot = internalCluster().startDataOnlyNode();\n+        final IndicesService indicesService = internalCluster().getInstance(IndicesService.class, dataNodeHoldingSearchableSnapshot);\n+\n+        final String indexOutsideSearchRange = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        final int indexOutsideSearchRangeShardCount = randomIntBetween(1, 3);\n+        createIndexWithTimestamp(indexOutsideSearchRange, indexOutsideSearchRangeShardCount, Settings.EMPTY);\n+\n+        final String indexWithinSearchRange = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        final int indexWithinSearchRangeShardCount = randomIntBetween(1, 3);\n+        createIndexWithTimestamp(\n+            indexWithinSearchRange,\n+            indexWithinSearchRangeShardCount,\n+            Settings.builder()\n+                .put(INDEX_ROUTING_REQUIRE_GROUP_SETTING.getConcreteSettingForNamespace(\"_name\").getKey(), dataNodeHoldingRegularIndex)\n+                .build()\n+        );\n+\n+        final int totalShards = indexOutsideSearchRangeShardCount + indexWithinSearchRangeShardCount;\n+\n+        indexDocumentsWithTimestampWithinDate(indexOutsideSearchRange, between(0, 1000), \"2020-11-26T%02d:%02d:%02d.%09dZ\");\n+        indexDocumentsWithTimestampWithinDate(indexWithinSearchRange, between(0, 1000), \"2020-11-28T%02d:%02d:%02d.%09dZ\");\n+\n+        final String repositoryName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        createRepository(repositoryName, \"mock\");\n+\n+        final SnapshotId snapshotId = createSnapshot(repositoryName, \"snapshot-1\", List.of(indexOutsideSearchRange)).snapshotId();\n+        assertAcked(client().admin().indices().prepareDelete(indexOutsideSearchRange));\n+\n+        final String searchableSnapshotIndexOutsideSearchRange = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+\n+        // Block the repository for the node holding the searchable snapshot shards\n+        // to delay its restore\n+        blockDataNode(repositoryName, dataNodeHoldingSearchableSnapshot);\n+\n+        // Force the searchable snapshot to be allocated in a particular node\n+        Settings restoredIndexSettings = Settings.builder()\n+            .put(IndexSettings.INDEX_CHECK_ON_STARTUP.getKey(), Boolean.FALSE.toString())\n+            .put(INDEX_ROUTING_REQUIRE_GROUP_SETTING.getConcreteSettingForNamespace(\"_name\").getKey(), dataNodeHoldingSearchableSnapshot)\n+            .build();\n+\n+        final MountSearchableSnapshotRequest mountRequest = new MountSearchableSnapshotRequest(\n+            searchableSnapshotIndexOutsideSearchRange,\n+            repositoryName,\n+            snapshotId.getName(),\n+            indexOutsideSearchRange,\n+            restoredIndexSettings,\n+            Strings.EMPTY_ARRAY,\n+            false\n+        );\n+        client().execute(MountSearchableSnapshotAction.INSTANCE, mountRequest).actionGet();\n+\n+        final IndexMetadata indexMetadata = getIndexMetadata(searchableSnapshotIndexOutsideSearchRange);\n+        assertThat(indexMetadata.getTimestampMillisRange(), equalTo(IndexLongFieldRange.NO_SHARDS));\n+\n+        DateFieldMapper.DateFieldType timestampFieldType = indicesService.getTimestampFieldType(indexMetadata.getIndex());\n+        assertThat(timestampFieldType, nullValue());\n+\n+        final boolean includeIndexCoveringSearchRangeInSearchRequest = randomBoolean();\n+        List<String> indicesToSearch = new ArrayList<>();\n+        if (includeIndexCoveringSearchRangeInSearchRequest) {\n+            indicesToSearch.add(indexWithinSearchRange);\n+        }\n+        indicesToSearch.add(searchableSnapshotIndexOutsideSearchRange);\n+        SearchRequest request = new SearchRequest().indices(indicesToSearch.toArray(new String[0]))\n+            .source(\n+                new SearchSourceBuilder().query(\n+                    QueryBuilders.rangeQuery(DataStream.TimestampField.FIXED_TIMESTAMP_FIELD)\n+                        .from(\"2020-11-28T00:00:00.000000000Z\", true)\n+                        .to(\"2020-11-29T00:00:00.000000000Z\")\n+                )\n+            );\n+\n+        if (includeIndexCoveringSearchRangeInSearchRequest) {\n+            SearchResponse searchResponse = client().search(request).actionGet();\n+\n+            // All the regular index searches succeeded\n+            assertThat(searchResponse.getSuccessfulShards(), equalTo(indexWithinSearchRangeShardCount));\n+            // All the searchable snapshots shard search failed\n+            assertThat(searchResponse.getFailedShards(), equalTo(indexOutsideSearchRangeShardCount));\n+            assertThat(searchResponse.getSkippedShards(), equalTo(0));\n+            assertThat(searchResponse.getTotalShards(), equalTo(totalShards));\n+        } else {\n+            // All shards failed, since all shards are unassigned and the IndexMetadata min/max timestamp\n+            // is not available yet\n+            expectThrows(SearchPhaseExecutionException.class, () -> client().search(request).actionGet());\n+        }\n+\n+        // Allow the searchable snapshots to be finally mounted\n+        unblockNode(repositoryName, dataNodeHoldingSearchableSnapshot);\n+        waitUntilRecoveryIsDone(searchableSnapshotIndexOutsideSearchRange);\n+        ensureGreen(searchableSnapshotIndexOutsideSearchRange);\n+\n+        final IndexMetadata updatedIndexMetadata = getIndexMetadata(searchableSnapshotIndexOutsideSearchRange);\n+        final IndexLongFieldRange updatedTimestampMillisRange = updatedIndexMetadata.getTimestampMillisRange();\n+        assertThat(updatedTimestampMillisRange.isComplete(), equalTo(true));\n+        assertThat(updatedTimestampMillisRange, not(sameInstance(IndexLongFieldRange.EMPTY)));\n+        assertThat(updatedTimestampMillisRange.getMin(), greaterThanOrEqualTo(Instant.parse(\"2020-11-26T00:00:00Z\").getMillis()));\n+        assertThat(updatedTimestampMillisRange.getMax(), lessThanOrEqualTo(Instant.parse(\"2020-11-27T00:00:00Z\").getMillis()));\n+        assertThat(indicesService.getTimestampFieldType(updatedIndexMetadata.getIndex()), notNullValue());\n+\n+        // Stop the node holding the searchable snapshots, and since we defined\n+        // the index allocation criteria to require the searchable snapshot\n+        // index to be allocated in that node, the shards should remain unassigned\n+        internalCluster().stopNode(dataNodeHoldingSearchableSnapshot);\n+        waitUntilAllShardsAreUnassigned(updatedIndexMetadata.getIndex());\n+\n+        if (includeIndexCoveringSearchRangeInSearchRequest) {\n+            SearchResponse newSearchResponse = client().search(request).actionGet();\n+\n+            assertThat(newSearchResponse.getSkippedShards(), equalTo(indexOutsideSearchRangeShardCount));\n+            assertThat(newSearchResponse.getSuccessfulShards(), equalTo(totalShards));\n+            assertThat(newSearchResponse.getFailedShards(), equalTo(0));\n+            assertThat(newSearchResponse.getTotalShards(), equalTo(totalShards));\n+        } else {\n+            if (indexOutsideSearchRangeShardCount == 1) {", "originalCommit": "fadfbda07b4a86c5d8a28e524c6d57d17119bdc4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTk4ODMwNw==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r541988307", "bodyText": "This is the current search behaviour, we might want to improve that and somehow provide the empty response directly from the coordinator, I'm not sure how involved is that, maybe @jimczi can guide us here?\nSince it seems like if the search include aggregations it should return the empty aggregations as well if I'm not mistaken.", "author": "fcofdez", "createdAt": "2020-12-13T19:26:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDA4OTgxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDA5MzE2Mw==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r540093163", "bodyText": "I understand that this is easy and fine for the existing can-match phase handling, but it could be bad for the coordinator can-match phase handling, since this could trigger an error. I wonder if we can improve this. Definitely OK to do in a follow-up, no need to block merging this PR on that.", "author": "henningandersen", "createdAt": "2020-12-10T11:29:18Z", "path": "server/src/main/java/org/elasticsearch/action/search/CanMatchPreFilterSearchPhase.java", "diffHunk": "@@ -100,7 +106,17 @@ protected SearchPhase getNextPhase(SearchPhaseResults<CanMatchResponse> results,\n         if (cardinality == 0) {\n             // this is a special case where we have no hit but we need to get at least one search response in order\n             // to produce a valid search result with all the aggs etc.\n-            possibleMatches.set(0);\n+            // Since it's possible that some of the shards that we're skipping are\n+            // unavailable, we would try to query the node that at least has some\n+            // shards available in order to produce a valid search result.\n+            int shardIndexToQuery = 0;\n+            for (int i = 0; i < shardsIts.size(); i++) {\n+                if (shardsIts.get(i).size() > 0) {\n+                    shardIndexToQuery = i;\n+                    break;\n+                }\n+            }\n+            possibleMatches.set(shardIndexToQuery);", "originalCommit": "fadfbda07b4a86c5d8a28e524c6d57d17119bdc4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjM4MDQ5Mg==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r542380492", "bodyText": "+1 to address this in a follow up. This is a general problem that we cannot create empty responses in the coordinating node directly.", "author": "jimczi", "createdAt": "2020-12-14T13:25:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDA5MzE2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDA5NDIzNQ==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r540094235", "bodyText": "Can we also do a search against a time-range that covers the unavailable searchable snapshot indices to verify that we in that case get errors out.", "author": "henningandersen", "createdAt": "2020-12-10T11:30:59Z", "path": "x-pack/plugin/searchable-snapshots/src/internalClusterTest/java/org/elasticsearch/xpack/searchablesnapshots/SearchableSnapshotsCanMatchOnCoordinatorIntegTests.java", "diffHunk": "@@ -0,0 +1,288 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.searchablesnapshots;\n+\n+import org.elasticsearch.action.admin.indices.recovery.RecoveryResponse;\n+import org.elasticsearch.action.index.IndexRequestBuilder;\n+import org.elasticsearch.action.search.SearchPhaseExecutionException;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.cluster.metadata.DataStream;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.routing.IndexRoutingTable;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeUnit;\n+import org.elasticsearch.common.unit.ByteSizeValue;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.IndexSettings;\n+import org.elasticsearch.index.mapper.DateFieldMapper;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.index.shard.IndexLongFieldRange;\n+import org.elasticsearch.indices.IndicesService;\n+import org.elasticsearch.indices.recovery.RecoveryState;\n+import org.elasticsearch.plugins.Plugin;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.snapshots.SnapshotId;\n+import org.elasticsearch.snapshots.mockstore.MockRepository;\n+import org.elasticsearch.test.ESIntegTestCase;\n+import org.elasticsearch.test.transport.MockTransportService;\n+import org.elasticsearch.xpack.core.searchablesnapshots.MountSearchableSnapshotAction;\n+import org.elasticsearch.xpack.core.searchablesnapshots.MountSearchableSnapshotRequest;\n+import org.elasticsearch.xpack.searchablesnapshots.cache.CacheService;\n+import org.joda.time.Instant;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Locale;\n+\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.INDEX_ROUTING_REQUIRE_GROUP_SETTING;\n+import static org.elasticsearch.index.IndexSettings.INDEX_SOFT_DELETES_SETTING;\n+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.greaterThanOrEqualTo;\n+import static org.hamcrest.Matchers.lessThanOrEqualTo;\n+import static org.hamcrest.Matchers.not;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.hamcrest.Matchers.sameInstance;\n+\n+@ESIntegTestCase.ClusterScope(scope = ESIntegTestCase.Scope.TEST, numDataNodes = 0)\n+public class SearchableSnapshotsCanMatchOnCoordinatorIntegTests extends BaseSearchableSnapshotsIntegTestCase {\n+\n+    @Override\n+    protected Collection<Class<? extends Plugin>> nodePlugins() {\n+        return List.of(LocalStateSearchableSnapshots.class, MockTransportService.TestPlugin.class, MockRepository.Plugin.class);\n+    }\n+\n+    @Override\n+    protected Settings nodeSettings(int nodeOrdinal) {\n+        return Settings.builder()\n+            .put(super.nodeSettings(nodeOrdinal))\n+            // Use an unbound cache so we can recover the searchable snapshot completely all the times\n+            .put(CacheService.SNAPSHOT_CACHE_SIZE_SETTING.getKey(), new ByteSizeValue(Long.MAX_VALUE, ByteSizeUnit.BYTES))\n+            .build();\n+    }\n+\n+    public void testSearchableSnapshotShardsAreSkippedWithoutQueryingAnyNodeWhenTheyAreOutsideOfTheQueryRange() throws Exception {\n+        internalCluster().startMasterOnlyNode();\n+        internalCluster().startCoordinatingOnlyNode(Settings.EMPTY);\n+        final String dataNodeHoldingRegularIndex = internalCluster().startDataOnlyNode();\n+        final String dataNodeHoldingSearchableSnapshot = internalCluster().startDataOnlyNode();\n+        final IndicesService indicesService = internalCluster().getInstance(IndicesService.class, dataNodeHoldingSearchableSnapshot);\n+\n+        final String indexOutsideSearchRange = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        final int indexOutsideSearchRangeShardCount = randomIntBetween(1, 3);\n+        createIndexWithTimestamp(indexOutsideSearchRange, indexOutsideSearchRangeShardCount, Settings.EMPTY);\n+\n+        final String indexWithinSearchRange = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        final int indexWithinSearchRangeShardCount = randomIntBetween(1, 3);\n+        createIndexWithTimestamp(\n+            indexWithinSearchRange,\n+            indexWithinSearchRangeShardCount,\n+            Settings.builder()\n+                .put(INDEX_ROUTING_REQUIRE_GROUP_SETTING.getConcreteSettingForNamespace(\"_name\").getKey(), dataNodeHoldingRegularIndex)\n+                .build()\n+        );\n+\n+        final int totalShards = indexOutsideSearchRangeShardCount + indexWithinSearchRangeShardCount;\n+\n+        indexDocumentsWithTimestampWithinDate(indexOutsideSearchRange, between(0, 1000), \"2020-11-26T%02d:%02d:%02d.%09dZ\");\n+        indexDocumentsWithTimestampWithinDate(indexWithinSearchRange, between(0, 1000), \"2020-11-28T%02d:%02d:%02d.%09dZ\");\n+\n+        final String repositoryName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        createRepository(repositoryName, \"mock\");\n+\n+        final SnapshotId snapshotId = createSnapshot(repositoryName, \"snapshot-1\", List.of(indexOutsideSearchRange)).snapshotId();\n+        assertAcked(client().admin().indices().prepareDelete(indexOutsideSearchRange));\n+\n+        final String searchableSnapshotIndexOutsideSearchRange = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+\n+        // Block the repository for the node holding the searchable snapshot shards\n+        // to delay its restore\n+        blockDataNode(repositoryName, dataNodeHoldingSearchableSnapshot);\n+\n+        // Force the searchable snapshot to be allocated in a particular node\n+        Settings restoredIndexSettings = Settings.builder()\n+            .put(IndexSettings.INDEX_CHECK_ON_STARTUP.getKey(), Boolean.FALSE.toString())\n+            .put(INDEX_ROUTING_REQUIRE_GROUP_SETTING.getConcreteSettingForNamespace(\"_name\").getKey(), dataNodeHoldingSearchableSnapshot)\n+            .build();\n+\n+        final MountSearchableSnapshotRequest mountRequest = new MountSearchableSnapshotRequest(\n+            searchableSnapshotIndexOutsideSearchRange,\n+            repositoryName,\n+            snapshotId.getName(),\n+            indexOutsideSearchRange,\n+            restoredIndexSettings,\n+            Strings.EMPTY_ARRAY,\n+            false\n+        );\n+        client().execute(MountSearchableSnapshotAction.INSTANCE, mountRequest).actionGet();\n+\n+        final IndexMetadata indexMetadata = getIndexMetadata(searchableSnapshotIndexOutsideSearchRange);\n+        assertThat(indexMetadata.getTimestampMillisRange(), equalTo(IndexLongFieldRange.NO_SHARDS));\n+\n+        DateFieldMapper.DateFieldType timestampFieldType = indicesService.getTimestampFieldType(indexMetadata.getIndex());\n+        assertThat(timestampFieldType, nullValue());\n+\n+        final boolean includeIndexCoveringSearchRangeInSearchRequest = randomBoolean();\n+        List<String> indicesToSearch = new ArrayList<>();\n+        if (includeIndexCoveringSearchRangeInSearchRequest) {\n+            indicesToSearch.add(indexWithinSearchRange);\n+        }\n+        indicesToSearch.add(searchableSnapshotIndexOutsideSearchRange);\n+        SearchRequest request = new SearchRequest().indices(indicesToSearch.toArray(new String[0]))\n+            .source(\n+                new SearchSourceBuilder().query(\n+                    QueryBuilders.rangeQuery(DataStream.TimestampField.FIXED_TIMESTAMP_FIELD)\n+                        .from(\"2020-11-28T00:00:00.000000000Z\", true)\n+                        .to(\"2020-11-29T00:00:00.000000000Z\")\n+                )\n+            );\n+\n+        if (includeIndexCoveringSearchRangeInSearchRequest) {\n+            SearchResponse searchResponse = client().search(request).actionGet();\n+\n+            // All the regular index searches succeeded\n+            assertThat(searchResponse.getSuccessfulShards(), equalTo(indexWithinSearchRangeShardCount));\n+            // All the searchable snapshots shard search failed\n+            assertThat(searchResponse.getFailedShards(), equalTo(indexOutsideSearchRangeShardCount));\n+            assertThat(searchResponse.getSkippedShards(), equalTo(0));\n+            assertThat(searchResponse.getTotalShards(), equalTo(totalShards));\n+        } else {\n+            // All shards failed, since all shards are unassigned and the IndexMetadata min/max timestamp\n+            // is not available yet\n+            expectThrows(SearchPhaseExecutionException.class, () -> client().search(request).actionGet());\n+        }\n+\n+        // Allow the searchable snapshots to be finally mounted\n+        unblockNode(repositoryName, dataNodeHoldingSearchableSnapshot);\n+        waitUntilRecoveryIsDone(searchableSnapshotIndexOutsideSearchRange);\n+        ensureGreen(searchableSnapshotIndexOutsideSearchRange);\n+\n+        final IndexMetadata updatedIndexMetadata = getIndexMetadata(searchableSnapshotIndexOutsideSearchRange);\n+        final IndexLongFieldRange updatedTimestampMillisRange = updatedIndexMetadata.getTimestampMillisRange();\n+        assertThat(updatedTimestampMillisRange.isComplete(), equalTo(true));\n+        assertThat(updatedTimestampMillisRange, not(sameInstance(IndexLongFieldRange.EMPTY)));\n+        assertThat(updatedTimestampMillisRange.getMin(), greaterThanOrEqualTo(Instant.parse(\"2020-11-26T00:00:00Z\").getMillis()));\n+        assertThat(updatedTimestampMillisRange.getMax(), lessThanOrEqualTo(Instant.parse(\"2020-11-27T00:00:00Z\").getMillis()));\n+        assertThat(indicesService.getTimestampFieldType(updatedIndexMetadata.getIndex()), notNullValue());\n+\n+        // Stop the node holding the searchable snapshots, and since we defined\n+        // the index allocation criteria to require the searchable snapshot\n+        // index to be allocated in that node, the shards should remain unassigned\n+        internalCluster().stopNode(dataNodeHoldingSearchableSnapshot);\n+        waitUntilAllShardsAreUnassigned(updatedIndexMetadata.getIndex());\n+\n+        if (includeIndexCoveringSearchRangeInSearchRequest) {\n+            SearchResponse newSearchResponse = client().search(request).actionGet();\n+\n+            assertThat(newSearchResponse.getSkippedShards(), equalTo(indexOutsideSearchRangeShardCount));\n+            assertThat(newSearchResponse.getSuccessfulShards(), equalTo(totalShards));\n+            assertThat(newSearchResponse.getFailedShards(), equalTo(0));\n+            assertThat(newSearchResponse.getTotalShards(), equalTo(totalShards));\n+        } else {\n+            if (indexOutsideSearchRangeShardCount == 1) {\n+                expectThrows(SearchPhaseExecutionException.class, () -> client().search(request).actionGet());\n+            } else {\n+                SearchResponse newSearchResponse = client().search(request).actionGet();\n+                // When all shards are skipped, at least one of them should be queried in order to\n+                // provide a proper search response.\n+                assertThat(newSearchResponse.getSkippedShards(), equalTo(indexOutsideSearchRangeShardCount - 1));\n+                assertThat(newSearchResponse.getSuccessfulShards(), equalTo(indexOutsideSearchRangeShardCount - 1));\n+                assertThat(newSearchResponse.getFailedShards(), equalTo(1));\n+                assertThat(newSearchResponse.getTotalShards(), equalTo(indexOutsideSearchRangeShardCount));\n+            }\n+        }", "originalCommit": "fadfbda07b4a86c5d8a28e524c6d57d17119bdc4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjIyOTk3OA==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r542229978", "bodyText": "That's what we do in https://github.com/elastic/elasticsearch/pull/65583/files#diff-70b2205b5049ff2a1de6ce21392782676a7aea41ae71e35269e1ee9d3a734ba2R164\nIn the first search we verify that when the searchable snapshot indices haven't published its min/max timestamp the search fails.", "author": "fcofdez", "createdAt": "2020-12-14T09:23:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDA5NDIzNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjIzNTcyOQ==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r542235729", "bodyText": "I think that is different. On that line, we verify that when we have no min/max and the shard is unavailable, we error out when searching for data outside the range.\nWhat I am asking for here is to verify that when we have min/max available on the coordinator, we error out if searching for a time-range covering unavailable data. I.e., that the can-match passes the search on to the query phase for the shard.", "author": "henningandersen", "createdAt": "2020-12-14T09:31:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDA5NDIzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDA5NTc5OQ==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r540095799", "bodyText": "nit: just timestampFieldType.", "author": "henningandersen", "createdAt": "2020-12-10T11:33:24Z", "path": "server/src/main/java/org/elasticsearch/index/query/CoordinatorRewriteContext.java", "diffHunk": "@@ -0,0 +1,74 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.index.query;\n+\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.io.stream.NamedWriteableRegistry;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.mapper.DateFieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+\n+import java.util.function.LongSupplier;\n+\n+public class CoordinatorRewriteContext extends QueryRewriteContext {\n+    private final Index index;\n+    private final long minTimestamp;\n+    private final long maxTimestamp;\n+    private final DateFieldMapper.DateFieldType timestampFieldTyped;", "originalCommit": "fadfbda07b4a86c5d8a28e524c6d57d17119bdc4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTk4ODA1MA==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r541988050", "bodyText": "Fixed in eada99e", "author": "fcofdez", "createdAt": "2020-12-13T19:25:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDA5NTc5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDEwMTUyNQ==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r540101525", "bodyText": "Can we also do a search with a time-range that hits none of the shards to verify that we pick a shard routing for an alive node in that case?", "author": "henningandersen", "createdAt": "2020-12-10T11:43:08Z", "path": "x-pack/plugin/searchable-snapshots/src/internalClusterTest/java/org/elasticsearch/xpack/searchablesnapshots/SearchableSnapshotsCanMatchOnCoordinatorIntegTests.java", "diffHunk": "@@ -0,0 +1,288 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.searchablesnapshots;\n+\n+import org.elasticsearch.action.admin.indices.recovery.RecoveryResponse;\n+import org.elasticsearch.action.index.IndexRequestBuilder;\n+import org.elasticsearch.action.search.SearchPhaseExecutionException;\n+import org.elasticsearch.action.search.SearchRequest;\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.cluster.metadata.DataStream;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.routing.IndexRoutingTable;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeUnit;\n+import org.elasticsearch.common.unit.ByteSizeValue;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.IndexSettings;\n+import org.elasticsearch.index.mapper.DateFieldMapper;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.index.shard.IndexLongFieldRange;\n+import org.elasticsearch.indices.IndicesService;\n+import org.elasticsearch.indices.recovery.RecoveryState;\n+import org.elasticsearch.plugins.Plugin;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.snapshots.SnapshotId;\n+import org.elasticsearch.snapshots.mockstore.MockRepository;\n+import org.elasticsearch.test.ESIntegTestCase;\n+import org.elasticsearch.test.transport.MockTransportService;\n+import org.elasticsearch.xpack.core.searchablesnapshots.MountSearchableSnapshotAction;\n+import org.elasticsearch.xpack.core.searchablesnapshots.MountSearchableSnapshotRequest;\n+import org.elasticsearch.xpack.searchablesnapshots.cache.CacheService;\n+import org.joda.time.Instant;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Locale;\n+\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.INDEX_ROUTING_REQUIRE_GROUP_SETTING;\n+import static org.elasticsearch.index.IndexSettings.INDEX_SOFT_DELETES_SETTING;\n+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.greaterThanOrEqualTo;\n+import static org.hamcrest.Matchers.lessThanOrEqualTo;\n+import static org.hamcrest.Matchers.not;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.hamcrest.Matchers.sameInstance;\n+\n+@ESIntegTestCase.ClusterScope(scope = ESIntegTestCase.Scope.TEST, numDataNodes = 0)\n+public class SearchableSnapshotsCanMatchOnCoordinatorIntegTests extends BaseSearchableSnapshotsIntegTestCase {\n+\n+    @Override\n+    protected Collection<Class<? extends Plugin>> nodePlugins() {\n+        return List.of(LocalStateSearchableSnapshots.class, MockTransportService.TestPlugin.class, MockRepository.Plugin.class);\n+    }\n+\n+    @Override\n+    protected Settings nodeSettings(int nodeOrdinal) {\n+        return Settings.builder()\n+            .put(super.nodeSettings(nodeOrdinal))\n+            // Use an unbound cache so we can recover the searchable snapshot completely all the times\n+            .put(CacheService.SNAPSHOT_CACHE_SIZE_SETTING.getKey(), new ByteSizeValue(Long.MAX_VALUE, ByteSizeUnit.BYTES))\n+            .build();\n+    }\n+\n+    public void testSearchableSnapshotShardsAreSkippedWithoutQueryingAnyNodeWhenTheyAreOutsideOfTheQueryRange() throws Exception {\n+        internalCluster().startMasterOnlyNode();\n+        internalCluster().startCoordinatingOnlyNode(Settings.EMPTY);\n+        final String dataNodeHoldingRegularIndex = internalCluster().startDataOnlyNode();\n+        final String dataNodeHoldingSearchableSnapshot = internalCluster().startDataOnlyNode();\n+        final IndicesService indicesService = internalCluster().getInstance(IndicesService.class, dataNodeHoldingSearchableSnapshot);\n+\n+        final String indexOutsideSearchRange = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        final int indexOutsideSearchRangeShardCount = randomIntBetween(1, 3);\n+        createIndexWithTimestamp(indexOutsideSearchRange, indexOutsideSearchRangeShardCount, Settings.EMPTY);\n+\n+        final String indexWithinSearchRange = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        final int indexWithinSearchRangeShardCount = randomIntBetween(1, 3);\n+        createIndexWithTimestamp(\n+            indexWithinSearchRange,\n+            indexWithinSearchRangeShardCount,\n+            Settings.builder()\n+                .put(INDEX_ROUTING_REQUIRE_GROUP_SETTING.getConcreteSettingForNamespace(\"_name\").getKey(), dataNodeHoldingRegularIndex)\n+                .build()\n+        );\n+\n+        final int totalShards = indexOutsideSearchRangeShardCount + indexWithinSearchRangeShardCount;\n+\n+        indexDocumentsWithTimestampWithinDate(indexOutsideSearchRange, between(0, 1000), \"2020-11-26T%02d:%02d:%02d.%09dZ\");\n+        indexDocumentsWithTimestampWithinDate(indexWithinSearchRange, between(0, 1000), \"2020-11-28T%02d:%02d:%02d.%09dZ\");\n+\n+        final String repositoryName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        createRepository(repositoryName, \"mock\");\n+\n+        final SnapshotId snapshotId = createSnapshot(repositoryName, \"snapshot-1\", List.of(indexOutsideSearchRange)).snapshotId();\n+        assertAcked(client().admin().indices().prepareDelete(indexOutsideSearchRange));\n+\n+        final String searchableSnapshotIndexOutsideSearchRange = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+\n+        // Block the repository for the node holding the searchable snapshot shards\n+        // to delay its restore\n+        blockDataNode(repositoryName, dataNodeHoldingSearchableSnapshot);\n+\n+        // Force the searchable snapshot to be allocated in a particular node\n+        Settings restoredIndexSettings = Settings.builder()\n+            .put(IndexSettings.INDEX_CHECK_ON_STARTUP.getKey(), Boolean.FALSE.toString())\n+            .put(INDEX_ROUTING_REQUIRE_GROUP_SETTING.getConcreteSettingForNamespace(\"_name\").getKey(), dataNodeHoldingSearchableSnapshot)\n+            .build();\n+\n+        final MountSearchableSnapshotRequest mountRequest = new MountSearchableSnapshotRequest(\n+            searchableSnapshotIndexOutsideSearchRange,\n+            repositoryName,\n+            snapshotId.getName(),\n+            indexOutsideSearchRange,\n+            restoredIndexSettings,\n+            Strings.EMPTY_ARRAY,\n+            false\n+        );\n+        client().execute(MountSearchableSnapshotAction.INSTANCE, mountRequest).actionGet();\n+\n+        final IndexMetadata indexMetadata = getIndexMetadata(searchableSnapshotIndexOutsideSearchRange);\n+        assertThat(indexMetadata.getTimestampMillisRange(), equalTo(IndexLongFieldRange.NO_SHARDS));\n+\n+        DateFieldMapper.DateFieldType timestampFieldType = indicesService.getTimestampFieldType(indexMetadata.getIndex());\n+        assertThat(timestampFieldType, nullValue());\n+\n+        final boolean includeIndexCoveringSearchRangeInSearchRequest = randomBoolean();\n+        List<String> indicesToSearch = new ArrayList<>();\n+        if (includeIndexCoveringSearchRangeInSearchRequest) {\n+            indicesToSearch.add(indexWithinSearchRange);\n+        }\n+        indicesToSearch.add(searchableSnapshotIndexOutsideSearchRange);\n+        SearchRequest request = new SearchRequest().indices(indicesToSearch.toArray(new String[0]))\n+            .source(\n+                new SearchSourceBuilder().query(\n+                    QueryBuilders.rangeQuery(DataStream.TimestampField.FIXED_TIMESTAMP_FIELD)\n+                        .from(\"2020-11-28T00:00:00.000000000Z\", true)\n+                        .to(\"2020-11-29T00:00:00.000000000Z\")\n+                )\n+            );\n+\n+        if (includeIndexCoveringSearchRangeInSearchRequest) {\n+            SearchResponse searchResponse = client().search(request).actionGet();\n+\n+            // All the regular index searches succeeded\n+            assertThat(searchResponse.getSuccessfulShards(), equalTo(indexWithinSearchRangeShardCount));\n+            // All the searchable snapshots shard search failed\n+            assertThat(searchResponse.getFailedShards(), equalTo(indexOutsideSearchRangeShardCount));\n+            assertThat(searchResponse.getSkippedShards(), equalTo(0));\n+            assertThat(searchResponse.getTotalShards(), equalTo(totalShards));\n+        } else {\n+            // All shards failed, since all shards are unassigned and the IndexMetadata min/max timestamp\n+            // is not available yet\n+            expectThrows(SearchPhaseExecutionException.class, () -> client().search(request).actionGet());\n+        }\n+\n+        // Allow the searchable snapshots to be finally mounted\n+        unblockNode(repositoryName, dataNodeHoldingSearchableSnapshot);\n+        waitUntilRecoveryIsDone(searchableSnapshotIndexOutsideSearchRange);\n+        ensureGreen(searchableSnapshotIndexOutsideSearchRange);\n+\n+        final IndexMetadata updatedIndexMetadata = getIndexMetadata(searchableSnapshotIndexOutsideSearchRange);\n+        final IndexLongFieldRange updatedTimestampMillisRange = updatedIndexMetadata.getTimestampMillisRange();\n+        assertThat(updatedTimestampMillisRange.isComplete(), equalTo(true));\n+        assertThat(updatedTimestampMillisRange, not(sameInstance(IndexLongFieldRange.EMPTY)));\n+        assertThat(updatedTimestampMillisRange.getMin(), greaterThanOrEqualTo(Instant.parse(\"2020-11-26T00:00:00Z\").getMillis()));\n+        assertThat(updatedTimestampMillisRange.getMax(), lessThanOrEqualTo(Instant.parse(\"2020-11-27T00:00:00Z\").getMillis()));\n+        assertThat(indicesService.getTimestampFieldType(updatedIndexMetadata.getIndex()), notNullValue());\n+\n+        // Stop the node holding the searchable snapshots, and since we defined\n+        // the index allocation criteria to require the searchable snapshot\n+        // index to be allocated in that node, the shards should remain unassigned\n+        internalCluster().stopNode(dataNodeHoldingSearchableSnapshot);\n+        waitUntilAllShardsAreUnassigned(updatedIndexMetadata.getIndex());\n+\n+        if (includeIndexCoveringSearchRangeInSearchRequest) {\n+            SearchResponse newSearchResponse = client().search(request).actionGet();\n+\n+            assertThat(newSearchResponse.getSkippedShards(), equalTo(indexOutsideSearchRangeShardCount));\n+            assertThat(newSearchResponse.getSuccessfulShards(), equalTo(totalShards));\n+            assertThat(newSearchResponse.getFailedShards(), equalTo(0));\n+            assertThat(newSearchResponse.getTotalShards(), equalTo(totalShards));\n+        } else {\n+            if (indexOutsideSearchRangeShardCount == 1) {\n+                expectThrows(SearchPhaseExecutionException.class, () -> client().search(request).actionGet());\n+            } else {\n+                SearchResponse newSearchResponse = client().search(request).actionGet();\n+                // When all shards are skipped, at least one of them should be queried in order to\n+                // provide a proper search response.\n+                assertThat(newSearchResponse.getSkippedShards(), equalTo(indexOutsideSearchRangeShardCount - 1));\n+                assertThat(newSearchResponse.getSuccessfulShards(), equalTo(indexOutsideSearchRangeShardCount - 1));\n+                assertThat(newSearchResponse.getFailedShards(), equalTo(1));\n+                assertThat(newSearchResponse.getTotalShards(), equalTo(indexOutsideSearchRangeShardCount));\n+            }\n+        }", "originalCommit": "fadfbda07b4a86c5d8a28e524c6d57d17119bdc4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "eada99ea3b08b21ef9ce5a39e93a305331bf9117", "url": "https://github.com/elastic/elasticsearch/commit/eada99ea3b08b21ef9ce5a39e93a305331bf9117", "message": "Tackle review comments", "committedDate": "2020-12-13T19:17:10Z", "type": "commit"}, {"oid": "e73c6f9dcdc3ba42028c3680c6f4a08a3d3c093f", "url": "https://github.com/elastic/elasticsearch/commit/e73c6f9dcdc3ba42028c3680c6f4a08a3d3c093f", "message": "Merge remote-tracking branch 'origin/master' into apply-can-match-on-coordinator-fresh", "committedDate": "2020-12-13T19:21:58Z", "type": "commit"}, {"oid": "769135f0537dac95210ceaa1f6c2e7864416ad4a", "url": "https://github.com/elastic/elasticsearch/commit/769135f0537dac95210ceaa1f6c2e7864416ad4a", "message": "Add tests to cover more cases", "committedDate": "2020-12-14T10:47:42Z", "type": "commit"}, {"oid": "bbde886e03d272c9b1cacb5df8ff9d51f47d63f6", "url": "https://github.com/elastic/elasticsearch/commit/bbde886e03d272c9b1cacb5df8ff9d51f47d63f6", "message": "Merge remote-tracking branch 'origin/master' into apply-can-match-on-coordinator-fresh", "committedDate": "2020-12-14T10:48:02Z", "type": "commit"}, {"oid": "38715bbed20ecd18d5035caaf76c5151916f0744", "url": "https://github.com/elastic/elasticsearch/commit/38715bbed20ecd18d5035caaf76c5151916f0744", "message": "Handle the case where the shards don't contain any timestamp data", "committedDate": "2020-12-14T11:31:53Z", "type": "commit"}, {"oid": "6c8787e085ff7a5b2f24132db104eeaf0e4f9a47", "url": "https://github.com/elastic/elasticsearch/commit/6c8787e085ff7a5b2f24132db104eeaf0e4f9a47", "message": "Merge remote-tracking branch 'origin/master' into apply-can-match-on-coordinator-fresh", "committedDate": "2020-12-14T11:32:17Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjM4MTE4Nw==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r542381187", "bodyText": "+1 to leave the raw values in the index metadata. We have the mapping for the field now so no need to perform the conversion eagerly ?", "author": "jimczi", "createdAt": "2020-12-14T13:26:22Z", "path": "server/src/main/java/org/elasticsearch/index/query/RangeQueryBuilder.java", "diffHunk": "@@ -428,6 +430,28 @@ public String getWriteableName() {\n \n     // Overridable for testing only\n     protected MappedFieldType.Relation getRelation(QueryRewriteContext queryRewriteContext) throws IOException {\n+        CoordinatorRewriteContext coordinatorRewriteContext = queryRewriteContext.convertToCoordinatorRewriteContext();\n+        if (coordinatorRewriteContext != null) {\n+            final MappedFieldType fieldType = coordinatorRewriteContext.getFieldType(fieldName);\n+            if (fieldType instanceof DateFieldMapper.DateFieldType) {\n+                final DateFieldMapper.DateFieldType dateFieldType = (DateFieldMapper.DateFieldType) fieldType;\n+                if (coordinatorRewriteContext.hasTimestampData() == false) {\n+                    return MappedFieldType.Relation.DISJOINT;\n+                }\n+                long minTimestamp = coordinatorRewriteContext.getMinTimestamp();\n+                long maxTimestamp = coordinatorRewriteContext.getMaxTimestamp();\n+                // IndexMetadata min/max timestamps are stored in milliseconds, we need\n+                // to convert those into Nanoseconds if the field resolution is in nanos\n+                if (dateFieldType.resolution() == DateFieldMapper.Resolution.NANOSECONDS) {", "originalCommit": "6c8787e085ff7a5b2f24132db104eeaf0e4f9a47", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "a3a19dcfc6c8c52d2b9f3f77fd49f797ac9110c1", "url": "https://github.com/elastic/elasticsearch/commit/a3a19dcfc6c8c52d2b9f3f77fd49f797ac9110c1", "message": "Store raw timestamp data in IndexMetadata", "committedDate": "2020-12-14T14:30:47Z", "type": "commit"}, {"oid": "554f5ee93093ac841cfce8811f96def74086ca76", "url": "https://github.com/elastic/elasticsearch/commit/554f5ee93093ac841cfce8811f96def74086ca76", "message": "Fix test", "committedDate": "2020-12-14T14:52:28Z", "type": "commit"}, {"oid": "f86499c91ce38a5985e813b2e0f3b9a6a3e606f2", "url": "https://github.com/elastic/elasticsearch/commit/f86499c91ce38a5985e813b2e0f3b9a6a3e606f2", "message": "Fix another test", "committedDate": "2020-12-14T15:30:33Z", "type": "commit"}, {"oid": "9225d218b596bad3259aeee2a547e640e20eb506", "url": "https://github.com/elastic/elasticsearch/commit/9225d218b596bad3259aeee2a547e640e20eb506", "message": "Merge remote-tracking branch 'origin/master' into apply-can-match-on-coordinator-fresh", "committedDate": "2020-12-14T20:33:08Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjM3Njc3Ng==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r542376776", "bodyText": "Can we add assert false inside this onFailure?", "author": "henningandersen", "createdAt": "2020-12-14T13:19:49Z", "path": "server/src/main/java/org/elasticsearch/action/search/AbstractSearchAsyncAction.java", "diffHunk": "@@ -306,7 +306,7 @@ protected abstract void executePhaseOnShard(SearchShardIterator shardIt,\n                                                 SearchShardTarget shard,\n                                                 SearchActionListener<Result> listener);\n \n-    private void fork(final Runnable runnable) {\n+    protected void fork(final Runnable runnable) {\n         executor.execute(new AbstractRunnable() {\n             @Override\n             public void onFailure(Exception e) {", "originalCommit": "6c8787e085ff7a5b2f24132db104eeaf0e4f9a47", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjgyNTM1NA==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r542825354", "bodyText": "Tackled in bcf5632", "author": "fcofdez", "createdAt": "2020-12-14T21:42:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjM3Njc3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjM4MDM0MA==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r542380340", "bodyText": "This comment seems wrong, they were all skipped?", "author": "henningandersen", "createdAt": "2020-12-14T13:25:06Z", "path": "x-pack/plugin/searchable-snapshots/src/internalClusterTest/java/org/elasticsearch/xpack/searchablesnapshots/SearchableSnapshotsCanMatchOnCoordinatorIntegTests.java", "diffHunk": "@@ -206,6 +206,203 @@ public void testSearchableSnapshotShardsAreSkippedWithoutQueryingAnyNodeWhenThey\n         }\n     }\n \n+    public void testQueryPhaseIsExecutedInAnAvailableNodeWhenAllShardsCanBeSkipped() throws Exception {\n+        internalCluster().startMasterOnlyNode();\n+        internalCluster().startCoordinatingOnlyNode(Settings.EMPTY);\n+        final String dataNodeHoldingRegularIndex = internalCluster().startDataOnlyNode();\n+        final String dataNodeHoldingSearchableSnapshot = internalCluster().startDataOnlyNode();\n+        final IndicesService indicesService = internalCluster().getInstance(IndicesService.class, dataNodeHoldingSearchableSnapshot);\n+\n+        final String indexOutsideSearchRange = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        final int indexOutsideSearchRangeShardCount = randomIntBetween(1, 3);\n+        createIndexWithTimestamp(\n+            indexOutsideSearchRange,\n+            indexOutsideSearchRangeShardCount,\n+            Settings.builder()\n+                .put(INDEX_ROUTING_REQUIRE_GROUP_SETTING.getConcreteSettingForNamespace(\"_name\").getKey(), dataNodeHoldingRegularIndex)\n+                .build()\n+        );\n+\n+        indexDocumentsWithTimestampWithinDate(indexOutsideSearchRange, between(0, 1000), \"2020-11-26T%02d:%02d:%02d.%09dZ\");\n+\n+        final String repositoryName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        createRepository(repositoryName, \"mock\");\n+\n+        final SnapshotId snapshotId = createSnapshot(repositoryName, \"snapshot-1\", List.of(indexOutsideSearchRange)).snapshotId();\n+\n+        final String searchableSnapshotIndexOutsideSearchRange = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+\n+        // Block the repository for the node holding the searchable snapshot shards\n+        // to delay its restore\n+        blockDataNode(repositoryName, dataNodeHoldingSearchableSnapshot);\n+\n+        // Force the searchable snapshot to be allocated in a particular node\n+        Settings restoredIndexSettings = Settings.builder()\n+            .put(IndexSettings.INDEX_CHECK_ON_STARTUP.getKey(), Boolean.FALSE.toString())\n+            .put(INDEX_ROUTING_REQUIRE_GROUP_SETTING.getConcreteSettingForNamespace(\"_name\").getKey(), dataNodeHoldingSearchableSnapshot)\n+            .build();\n+\n+        final MountSearchableSnapshotRequest mountRequest = new MountSearchableSnapshotRequest(\n+            searchableSnapshotIndexOutsideSearchRange,\n+            repositoryName,\n+            snapshotId.getName(),\n+            indexOutsideSearchRange,\n+            restoredIndexSettings,\n+            Strings.EMPTY_ARRAY,\n+            false\n+        );\n+        client().execute(MountSearchableSnapshotAction.INSTANCE, mountRequest).actionGet();\n+        final int searchableSnapshotShardCount = indexOutsideSearchRangeShardCount;\n+\n+        final IndexMetadata indexMetadata = getIndexMetadata(searchableSnapshotIndexOutsideSearchRange);\n+        assertThat(indexMetadata.getTimestampMillisRange(), equalTo(IndexLongFieldRange.NO_SHARDS));\n+\n+        DateFieldMapper.DateFieldType timestampFieldType = indicesService.getTimestampFieldType(indexMetadata.getIndex());\n+        assertThat(timestampFieldType, nullValue());\n+\n+        SearchRequest request = new SearchRequest().indices(indexOutsideSearchRange, searchableSnapshotIndexOutsideSearchRange)\n+            .source(\n+                new SearchSourceBuilder().query(\n+                    QueryBuilders.rangeQuery(DataStream.TimestampField.FIXED_TIMESTAMP_FIELD)\n+                        .from(\"2020-11-28T00:00:00.000000000Z\", true)\n+                        .to(\"2020-11-29T00:00:00.000000000Z\")\n+                )\n+            );\n+\n+        final int totalShards = indexOutsideSearchRangeShardCount + searchableSnapshotShardCount;\n+        SearchResponse searchResponse = client().search(request).actionGet();\n+\n+        // All the regular index searches succeeded\n+        assertThat(searchResponse.getSuccessfulShards(), equalTo(indexOutsideSearchRangeShardCount));\n+        // All the searchable snapshots shard search failed\n+        assertThat(searchResponse.getFailedShards(), equalTo(indexOutsideSearchRangeShardCount));\n+        assertThat(searchResponse.getSkippedShards(), equalTo(searchableSnapshotShardCount));\n+        assertThat(searchResponse.getTotalShards(), equalTo(totalShards));\n+        assertThat(searchResponse.getHits().getTotalHits().value, equalTo(0L));\n+\n+        // Allow the searchable snapshots to be finally mounted\n+        unblockNode(repositoryName, dataNodeHoldingSearchableSnapshot);\n+        waitUntilRecoveryIsDone(searchableSnapshotIndexOutsideSearchRange);\n+        ensureGreen(searchableSnapshotIndexOutsideSearchRange);\n+\n+        final IndexMetadata updatedIndexMetadata = getIndexMetadata(searchableSnapshotIndexOutsideSearchRange);\n+        final IndexLongFieldRange updatedTimestampMillisRange = updatedIndexMetadata.getTimestampMillisRange();\n+        assertThat(updatedTimestampMillisRange.isComplete(), equalTo(true));\n+        assertThat(updatedTimestampMillisRange, not(sameInstance(IndexLongFieldRange.EMPTY)));\n+        assertThat(updatedTimestampMillisRange.getMin(), greaterThanOrEqualTo(Instant.parse(\"2020-11-26T00:00:00Z\").getMillis()));\n+        assertThat(updatedTimestampMillisRange.getMax(), lessThanOrEqualTo(Instant.parse(\"2020-11-27T00:00:00Z\").getMillis()));\n+        assertThat(indicesService.getTimestampFieldType(updatedIndexMetadata.getIndex()), notNullValue());\n+\n+        // Stop the node holding the searchable snapshots, and since we defined\n+        // the index allocation criteria to require the searchable snapshot\n+        // index to be allocated in that node, the shards should remain unassigned\n+        internalCluster().stopNode(dataNodeHoldingSearchableSnapshot);\n+        waitUntilAllShardsAreUnassigned(updatedIndexMetadata.getIndex());\n+\n+        SearchResponse newSearchResponse = client().search(request).actionGet();\n+\n+        // All the regular index searches succeeded\n+        assertThat(newSearchResponse.getSuccessfulShards(), equalTo(totalShards));\n+        // All the searchable snapshots shard search failed", "originalCommit": "769135f0537dac95210ceaa1f6c2e7864416ad4a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjgyNTIzMQ==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r542825231", "bodyText": "Tackled in bcf5632 \ud83e\udd26", "author": "fcofdez", "createdAt": "2020-12-14T21:42:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjM4MDM0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjY5ODM0Nw==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r542698347", "bodyText": "There is logic in AbstractSearchAsyncAction.run for the allowPartialSearchResults=false case that need to only consider shards that cannot be skipped on the coordinator. I wonder if we should tackle that here or in a follow-up?", "author": "henningandersen", "createdAt": "2020-12-14T19:43:15Z", "path": "server/src/main/java/org/elasticsearch/action/search/CanMatchPreFilterSearchPhase.java", "diffHunk": "@@ -118,6 +134,40 @@ protected SearchPhase getNextPhase(SearchPhaseResults<CanMatchResponse> results,\n         return new GroupShardsIterator<>(sortShards(shardsIts, results.minAndMaxes, fieldSort.order()));\n     }\n \n+    @Override\n+    protected void performPhaseOnShard(int shardIndex, SearchShardIterator shardIt, SearchShardTarget shard) {", "originalCommit": "f86499c91ce38a5985e813b2e0f3b9a6a3e606f2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjgxMjY0Nw==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r542812647", "bodyText": "You're right, I totally missed that case. But this is somehow related to the problem when all the shards can be skipped but we still need to execute the query phase in one node in order to generate a valid search response. Maybe we can tackle this in a follow up?", "author": "fcofdez", "createdAt": "2020-12-14T21:30:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjY5ODM0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzEwODM2Ng==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r543108366", "bodyText": "Yes, ok to tackle this in a follow-up. Not sure I see the relationship to the other problem, but I am sure that will be evident in the follow-up.", "author": "henningandersen", "createdAt": "2020-12-15T07:30:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjY5ODM0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjcxMTM0Mw==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r542711343", "bodyText": "I think we need to rename the getTimestampMillisRange method too. I did a very brief check and it does not look like the \"millis\" part is used in cluster state, but would be good if you can take a closer look.", "author": "henningandersen", "createdAt": "2020-12-14T19:55:24Z", "path": "server/src/main/java/org/elasticsearch/index/query/CoordinatorRewriteContextProvider.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.index.query;\n+\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.common.Nullable;\n+import org.elasticsearch.common.io.stream.NamedWriteableRegistry;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.mapper.DateFieldMapper;\n+import org.elasticsearch.index.shard.IndexLongFieldRange;\n+\n+import java.util.function.Function;\n+import java.util.function.LongSupplier;\n+import java.util.function.Supplier;\n+\n+public class CoordinatorRewriteContextProvider {\n+    private final NamedXContentRegistry xContentRegistry;\n+    private final NamedWriteableRegistry writeableRegistry;\n+    private final Client client;\n+    private final LongSupplier nowInMillis;\n+    private final Supplier<ClusterState> clusterStateSupplier;\n+    private final Function<Index, DateFieldMapper.DateFieldType> mappingSupplier;\n+\n+    public CoordinatorRewriteContextProvider(NamedXContentRegistry xContentRegistry,\n+                                             NamedWriteableRegistry writeableRegistry,\n+                                             Client client,\n+                                             LongSupplier nowInMillis,\n+                                             Supplier<ClusterState> clusterStateSupplier,\n+                                             Function<Index, DateFieldMapper.DateFieldType> mappingSupplier) {\n+        this.xContentRegistry = xContentRegistry;\n+        this.writeableRegistry = writeableRegistry;\n+        this.client = client;\n+        this.nowInMillis = nowInMillis;\n+        this.clusterStateSupplier = clusterStateSupplier;\n+        this.mappingSupplier = mappingSupplier;\n+    }\n+\n+    @Nullable\n+    public CoordinatorRewriteContext getCoordinatorRewriteContext(Index index) {\n+        ClusterState clusterState = clusterStateSupplier.get();\n+        IndexMetadata indexMetadata = clusterState.metadata().index(index);\n+\n+        if (indexMetadata == null || indexMetadata.getTimestampMillisRange().containsAllShardRanges() == false) {\n+            return null;\n+        }\n+\n+        DateFieldMapper.DateFieldType dateFieldType = mappingSupplier.apply(index);\n+\n+        if (dateFieldType == null) {\n+            return null;\n+        }\n+\n+        IndexLongFieldRange timestampMillisRange = indexMetadata.getTimestampMillisRange();", "originalCommit": "f86499c91ce38a5985e813b2e0f3b9a6a3e606f2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjgyNDQyNA==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r542824424", "bodyText": "Would you mind if we tackle this in a separate PR? It might introduce too much noise in this one.", "author": "fcofdez", "createdAt": "2020-12-14T21:41:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjcxMTM0Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzEwNzM0MA==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r543107340", "bodyText": "\ud83d\udc4d", "author": "henningandersen", "createdAt": "2020-12-15T07:28:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjcxMTM0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjcxMjc4OQ==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r542712789", "bodyText": "I think we can remove this catch block now.", "author": "henningandersen", "createdAt": "2020-12-14T19:56:49Z", "path": "server/src/main/java/org/elasticsearch/index/shard/IndexShard.java", "diffHunk": "@@ -1738,8 +1738,8 @@ public ShardLongFieldRange getTimestampMillisRange() {\n \n         try {\n             return ShardLongFieldRange.of(\n-                    dateFieldType.resolution().roundDownToMillis(rawTimestampFieldRange.getMin()),\n-                    dateFieldType.resolution().roundUpToMillis(rawTimestampFieldRange.getMax()));\n+                rawTimestampFieldRange.getMin(),\n+                rawTimestampFieldRange.getMax());\n         } catch (IllegalArgumentException e) {", "originalCommit": "f86499c91ce38a5985e813b2e0f3b9a6a3e606f2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjgyNDk2Ng==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r542824966", "bodyText": "Tackled in bcf5632", "author": "fcofdez", "createdAt": "2020-12-14T21:42:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjcxMjc4OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjc1Mjk3OA==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r542752978", "bodyText": "It is not entirely clear to me that doing the rewrite after doing this sort optimization is correct, since rewrites also touch sorts. It looks kind of deliberate that it went after the rewrite originally, but could also be coincidence. I tried digging a bit and did not find a smoking gun, but thought I would raise this anyway.", "author": "henningandersen", "createdAt": "2020-12-14T20:34:35Z", "path": "server/src/main/java/org/elasticsearch/search/SearchService.java", "diffHunk": "@@ -1189,24 +1190,30 @@ private CanMatchResponse canMatch(ShardSearchRequest request, boolean checkRefre\n             try (canMatchSearcher) {\n                 QueryShardContext context = indexService.newQueryShardContext(request.shardId().id(), canMatchSearcher,\n                     request::nowInMillis, request.getClusterAlias(), request.getRuntimeMappings());\n-                Rewriteable.rewrite(request.getRewriteable(), context, false);\n-                final boolean aliasFilterCanMatch = request.getAliasFilter()\n-                    .getQueryBuilder() instanceof MatchNoneQueryBuilder == false;\n                 FieldSortBuilder sortBuilder = FieldSortBuilder.getPrimaryFieldSortOrNull(request.source());", "originalCommit": "9225d218b596bad3259aeee2a547e640e20eb506", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjc5MzYzOA==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r542793638", "bodyText": "That's ok, we extract the min/max value here so the sort rewrite doesn't change anything. However we could first do the rewrite and then extract the min/max values but only if canMatch || hasRefreshPending. Otherwise returning a null min/max value should be ok.", "author": "jimczi", "createdAt": "2020-12-14T21:13:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjc1Mjk3OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjgyNDg4MA==", "url": "https://github.com/elastic/elasticsearch/pull/65583#discussion_r542824880", "bodyText": "Tackled in bcf5632", "author": "fcofdez", "createdAt": "2020-12-14T21:42:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjc1Mjk3OA=="}], "type": "inlineReview"}, {"oid": "bcf5632430a139d1b218253794df8d92b5954ba3", "url": "https://github.com/elastic/elasticsearch/commit/bcf5632430a139d1b218253794df8d92b5954ba3", "message": "Tackle review comments", "committedDate": "2020-12-14T21:40:07Z", "type": "commit"}, {"oid": "3fc820fd0f0036734b9a1b9fdadc6f4c568788ed", "url": "https://github.com/elastic/elasticsearch/commit/3fc820fd0f0036734b9a1b9fdadc6f4c568788ed", "message": "Merge remote-tracking branch 'origin/master' into apply-can-match-on-coordinator-fresh", "committedDate": "2020-12-14T21:40:34Z", "type": "commit"}, {"oid": "ad3f383ebe3319473236d665ca2de5032780e6a3", "url": "https://github.com/elastic/elasticsearch/commit/ad3f383ebe3319473236d665ca2de5032780e6a3", "message": "Merge remote-tracking branch 'origin/master' into apply-can-match-on-coordinator-fresh", "committedDate": "2020-12-14T22:08:35Z", "type": "commit"}]}