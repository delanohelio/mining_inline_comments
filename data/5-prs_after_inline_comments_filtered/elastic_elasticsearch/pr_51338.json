{"pr_number": 51338, "pr_title": "Limit max concurrency of test cluster nodes to a function of max workers", "pr_createdAt": "2020-01-22T22:55:51Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/51338", "timeline": [{"oid": "a4ee178ae73d7468d6e0f4bd5dd726c9a6cc194c", "url": "https://github.com/elastic/elasticsearch/commit/a4ee178ae73d7468d6e0f4bd5dd726c9a6cc194c", "message": "Limit max concurrency of test cluster nodes to a function of max workers\n\nSigned-off-by: Mark Vieira <portugee@gmail.com>", "committedDate": "2020-01-22T22:55:07Z", "type": "commit"}, {"oid": "80f33ff08883f7d8f69e270bb3004498afefe40e", "url": "https://github.com/elastic/elasticsearch/commit/80f33ff08883f7d8f69e270bb3004498afefe40e", "message": "Fix some generic type checking error\n\nSigned-off-by: Mark Vieira <portugee@gmail.com>", "committedDate": "2020-01-22T23:05:23Z", "type": "commit"}, {"oid": "38c8f3eff998e76daab9da45d99b28440bf56169", "url": "https://github.com/elastic/elasticsearch/commit/38c8f3eff998e76daab9da45d99b28440bf56169", "message": "Suppress unchecked cast warning\n\nSigned-off-by: Mark Vieira <portugee@gmail.com>", "committedDate": "2020-01-22T23:22:26Z", "type": "commit"}, {"oid": "96916aeafcc5cbc8b102e31c0baf139fb85f9989", "url": "https://github.com/elastic/elasticsearch/commit/96916aeafcc5cbc8b102e31c0baf139fb85f9989", "message": "Simplify\n\nSigned-off-by: Mark Vieira <portugee@gmail.com>", "committedDate": "2020-01-22T23:27:06Z", "type": "commit"}, {"oid": "8d60aaa2a66cdd6e9c92231cfaa76fbf0358015a", "url": "https://github.com/elastic/elasticsearch/commit/8d60aaa2a66cdd6e9c92231cfaa76fbf0358015a", "message": "Fix checkstyle violations\n\nSigned-off-by: Mark Vieira <portugee@gmail.com>", "committedDate": "2020-01-22T23:37:43Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTk2OTA4Ng==", "url": "https://github.com/elastic/elasticsearch/pull/51338#discussion_r369969086", "bodyText": "It doesn't have many usages, but we should consider DefaultTestClustersTask too in the same way.", "author": "alpar-t", "createdAt": "2020-01-23T07:47:10Z", "path": "buildSrc/src/main/java/org/elasticsearch/gradle/testclusters/RestTestRunnerTask.java", "diffHunk": "@@ -47,4 +57,19 @@ public int getMaxParallelForks() {\n         return clusters;\n     }\n \n+    @Override\n+    @Internal\n+    public List<ResourceLock> getSharedResources() {", "originalCommit": "8d60aaa2a66cdd6e9c92231cfaa76fbf0358015a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDI0Mjk0NA==", "url": "https://github.com/elastic/elasticsearch/pull/51338#discussion_r370242944", "bodyText": "I thought about that, as you say, for now it's only used by Run which will never be run in parallel with another similar task. Because we are overriding an internal method and using all sorts of other nasty internals here I wanted to limit the surface area of this until Gradle supports tasks declaring they use more than 1 lease of a build service.", "author": "mark-vieira", "createdAt": "2020-01-23T17:04:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTk2OTA4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTk2OTUzMQ==", "url": "https://github.com/elastic/elasticsearch/pull/51338#discussion_r369969531", "bodyText": "Maybe this is just me, but this threw me off at first, maybe this would be more straight forward:\n.map(cluster.getNodes().size()).sum()", "author": "alpar-t", "createdAt": "2020-01-23T07:48:39Z", "path": "buildSrc/src/main/java/org/elasticsearch/gradle/testclusters/RestTestRunnerTask.java", "diffHunk": "@@ -47,4 +57,19 @@ public int getMaxParallelForks() {\n         return clusters;\n     }\n \n+    @Override\n+    @Internal\n+    public List<ResourceLock> getSharedResources() {\n+        List<ResourceLock> locks = new ArrayList<>(super.getSharedResources());\n+        BuildServiceRegistryInternal serviceRegistry = getServices().get(BuildServiceRegistryInternal.class);\n+        Provider<TestClustersThrottle> throttleProvider = Boilerplate.getBuildService(serviceRegistry, THROTTLE_SERVICE_NAME);\n+        SharedResource resource = serviceRegistry.forService(throttleProvider);\n+\n+        int nodeCount = (int) clusters.stream().flatMap(cluster -> cluster.getNodes().stream()).count();", "originalCommit": "8d60aaa2a66cdd6e9c92231cfaa76fbf0358015a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDI0OTI1MQ==", "url": "https://github.com/elastic/elasticsearch/pull/51338#discussion_r370249251", "bodyText": "Yes, that's better. Also using mapToInt allows me to ditch the downcast.", "author": "mark-vieira", "createdAt": "2020-01-23T17:16:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTk2OTUzMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTk3NzIxMA==", "url": "https://github.com/elastic/elasticsearch/pull/51338#discussion_r369977210", "bodyText": "I think we set this to half the physical cores in CI, so it may end up lower than it should.\nLooking at some CPU usage graphs will make it  obvious that we are under utilizing.\nUnaffected build times are a good sign trough.\nSince we can't set number of workers in a dynamic way, I think we should keep this code as is\nand stop setting max workers explicitly, I would expect that to work well both for CI and local runs without explicit configuration and with parallel turned on by default.\nOne caveat for running locally is that we would need to add a memory check\nand error out if there isn't enough.  I have 12 threads and 32GB of ram, and can't run a --parallel check without lowering workers. I think we need ~ 3GB for the daemon and ~ an additional 4GB for each worker. The number are based on observations, and the changes in the PR should make them better.\nIn theory, worst case, each worker could be running a test  and half as many nodes may be running, each consuming tests.heap.size (512MB) by default memory so one needs at lest daemon memory + 3/4 * nr of workers GB of memory just to run this. Without taking the OS and OS caches into account.\nIf we consider that ES recommends leaving half as much memory to OS caches, it would  work out  to\ndaemon memory + number of workers GB.  We may want to add some margin there, like 16 GB for other stuff running on the machine, that won't hurt CI since we have plenty of memory there.\nOn a 12 thread CPU, that works out to 12GB or 15 GB RAM free, so in theory I should be able to run ./graldew --parallel check without setting the number of workers with this change, given that after running browsers and developer tools I still have  18GB free.\nThe check may be conditioned on the task graph being big enough so we don't annoy the people to add configuration if they are just looking to run a single test ?\nOr maybe that's all just over-complicating it ?", "author": "alpar-t", "createdAt": "2020-01-23T08:12:46Z", "path": "buildSrc/src/main/java/org/elasticsearch/gradle/testclusters/TestClustersPlugin.java", "diffHunk": "@@ -30,53 +31,50 @@\n import org.gradle.api.invocation.Gradle;\n import org.gradle.api.logging.Logger;\n import org.gradle.api.logging.Logging;\n+import org.gradle.api.provider.Provider;\n import org.gradle.api.tasks.TaskState;\n \n import java.io.File;\n \n public class TestClustersPlugin implements Plugin<Project> {\n \n-    private static final String LIST_TASK_NAME = \"listTestClusters\";\n     public static final String EXTENSION_NAME = \"testClusters\";\n-    private static final String REGISTRY_EXTENSION_NAME = \"testClustersRegistry\";\n+    public static final String THROTTLE_SERVICE_NAME = \"testClustersThrottle\";\n \n+    private static final String LIST_TASK_NAME = \"listTestClusters\";\n+    private static final String REGISTRY_SERVICE_NAME = \"testClustersRegistry\";\n     private static final Logger logger = Logging.getLogger(TestClustersPlugin.class);\n \n-    private ReaperService reaper;\n-\n     @Override\n     public void apply(Project project) {\n         project.getPlugins().apply(DistributionDownloadPlugin.class);\n-\n         project.getRootProject().getPluginManager().apply(ReaperPlugin.class);\n-        reaper = project.getRootProject().getExtensions().getByType(ReaperService.class);\n+\n+        ReaperService reaper = project.getRootProject().getExtensions().getByType(ReaperService.class);\n \n         // enable the DSL to describe clusters\n-        NamedDomainObjectContainer<ElasticsearchCluster> container = createTestClustersContainerExtension(project);\n+        NamedDomainObjectContainer<ElasticsearchCluster> container = createTestClustersContainerExtension(project, reaper);\n \n         // provide a task to be able to list defined clusters.\n         createListClustersTask(project, container);\n \n-        if (project.getRootProject().getExtensions().findByName(REGISTRY_EXTENSION_NAME) == null) {\n-            TestClustersRegistry registry = project.getRootProject()\n-                .getExtensions()\n-                .create(REGISTRY_EXTENSION_NAME, TestClustersRegistry.class);\n-\n-            // When we know what tasks will run, we claim the clusters of those task to differentiate between clusters\n-            // that are defined in the build script and the ones that will actually be used in this invocation of gradle\n-            // we use this information to determine when the last task that required the cluster executed so that we can\n-            // terminate the cluster right away and free up resources.\n-            configureClaimClustersHook(project.getGradle(), registry);\n+        // register cluster registry as a global build service\n+        project.getGradle().getSharedServices().registerIfAbsent(REGISTRY_SERVICE_NAME, TestClustersRegistry.class, spec -> {});\n \n-            // Before each task, we determine if a cluster needs to be started for that task.\n-            configureStartClustersHook(project.getGradle(), registry);\n+        // register throttle so we only run at most max-workers/2 nodes concurrently\n+        project.getGradle()\n+            .getSharedServices()\n+            .registerIfAbsent(\n+                THROTTLE_SERVICE_NAME,\n+                TestClustersThrottle.class,\n+                spec -> spec.getMaxParallelUsages().set(project.getGradle().getStartParameter().getMaxWorkerCount() / 2)", "originalCommit": "8d60aaa2a66cdd6e9c92231cfaa76fbf0358015a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDI0NjgxNA==", "url": "https://github.com/elastic/elasticsearch/pull/51338#discussion_r370246814", "bodyText": "I think we set this to half the physical cores in CI\n\nWe use 32 core machines with max-workers set to 16. Are we certain those are 32 physical cores? Due to all the virtualization involved there I suspect it's impossible to know for sure.\n\nSince we can't set number of workers in a dynamic way, I think we should keep this code as is and stop setting max workers explicitly\n\nI'd like to avoid this as well, but we do other stuff like lower the number of workers when not using a memory-backed workspace directory. So there are other performance impacting factors that affect the level of effective concurrency beyond just CPUs.\n\nI think we need ~ 3GB for the daemon and ~ an additional 4GB for each worker.\n\nOur test workers allocate 512m of ram. Not sure for the test cluster nodes themselves but running half as many of them in parallel as we currently have the potential for now should help here.\n\nOr maybe that's all just over-complicating it ?\n\nMaybe not. We could model available memory as a build service just as we do now CPUs with the throttle. It's a more difficult problem though due to irregularities in how much \"free\" memory is reported by the JVM, other processes running, etc. Gradle tries itself to do this with the daemon and it rarely works properly. I'm apt to see how this works out in practice. I set my max-workers to 6 (physical cores), but as you say, we want to avoid folks having to \"tune\" their settings.", "author": "mark-vieira", "createdAt": "2020-01-23T17:12:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTk3NzIxMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDUwODczMA==", "url": "https://github.com/elastic/elasticsearch/pull/51338#discussion_r370508730", "bodyText": "The CI workers have 16 physical cores with hyperthreading AFAIK\nI'm not sure the IO bottleneck will be hit with this change in place,\nbut it's certainly possible.\nTest Cluster nodes allocate 512m too.\nA memory model would need to account for test runners in addition to ES nodes.\nEnabling parallel without limiting max workers will require some testing, and possibly additional work for sure.\nI think it's fine if we can't account for everything, probably something like producing an error telling people a suggested max workers to put in their config would also be fine ( and we can do that on a some observed CPU to memory ratio ) when running on a non ramdisk. We tune CI separately anyhow and that's unlikely to change, not sure it's worth looking for a one size fits all.", "author": "alpar-t", "createdAt": "2020-01-24T07:58:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTk3NzIxMA=="}], "type": "inlineReview"}, {"oid": "adb2127da1169752f9fb6daf35d99f556a28c9d6", "url": "https://github.com/elastic/elasticsearch/commit/adb2127da1169752f9fb6daf35d99f556a28c9d6", "message": "Simplify expression\n\nSigned-off-by: Mark Vieira <portugee@gmail.com>", "committedDate": "2020-01-23T17:16:25Z", "type": "commit"}]}