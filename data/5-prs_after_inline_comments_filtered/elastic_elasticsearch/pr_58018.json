{"pr_number": 58018, "pr_title": "Sending operations concurrently in peer recovery", "pr_createdAt": "2020-06-12T03:36:07Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/58018", "timeline": [{"oid": "a2103a7861330be4de74fe3496e05927a47cd4ba", "url": "https://github.com/elastic/elasticsearch/commit/a2103a7861330be4de74fe3496e05927a47cd4ba", "message": "Sending operations concurrently in peer recovery", "committedDate": "2020-06-12T03:34:18Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE4OTc0OA==", "url": "https://github.com/elastic/elasticsearch/pull/58018#discussion_r439189748", "bodyText": "I think we should use the WRITE threadpool instead of GENERIC for indexing operations.", "author": "dnhatn", "createdAt": "2020-06-12T03:39:23Z", "path": "server/src/main/java/org/elasticsearch/indices/recovery/PeerRecoveryTargetService.java", "diffHunk": "@@ -119,7 +119,7 @@ public PeerRecoveryTargetService(ThreadPool threadPool, TransportService transpo\n             RecoveryCleanFilesRequest::new, new CleanFilesRequestHandler());\n         transportService.registerRequestHandler(Actions.PREPARE_TRANSLOG, ThreadPool.Names.GENERIC,\n                 RecoveryPrepareForTranslogOperationsRequest::new, new PrepareForTranslogOperationsRequestHandler());\n-        transportService.registerRequestHandler(Actions.TRANSLOG_OPS, ThreadPool.Names.GENERIC, RecoveryTranslogOperationsRequest::new,\n+        transportService.registerRequestHandler(Actions.TRANSLOG_OPS, ThreadPool.Names.WRITE, RecoveryTranslogOperationsRequest::new,", "originalCommit": "a2103a7861330be4de74fe3496e05927a47cd4ba", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDMxNzY0MA==", "url": "https://github.com/elastic/elasticsearch/pull/58018#discussion_r450317640", "bodyText": "I backed out this change in d34db4b. I think we need a separate change for it.", "author": "dnhatn", "createdAt": "2020-07-06T15:52:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE4OTc0OA=="}], "type": "inlineReview"}, {"oid": "7707c3318111b53b310ce782295d049b06a98d71", "url": "https://github.com/elastic/elasticsearch/commit/7707c3318111b53b310ce782295d049b06a98d71", "message": "fix test", "committedDate": "2020-06-12T04:00:20Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTMxMTU5NA==", "url": "https://github.com/elastic/elasticsearch/pull/58018#discussion_r439311594", "bodyText": "I'm not sure I understand how this adds parallelism: If we only have one item here in the chunks list, then the MultiChunkTransfer won't do anything for us will it?", "author": "original-brownbear", "createdAt": "2020-06-12T09:29:27Z", "path": "server/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java", "diffHunk": "@@ -661,106 +655,122 @@ void phase2(\n             throw new IndexShardClosedException(request.shardId());\n         }\n         logger.trace(\"recovery [phase2]: sending transaction log operations (from [\" + startingSeqNo + \"] to [\" + endingSeqNo + \"]\");\n-\n-        final AtomicInteger skippedOps = new AtomicInteger();\n-        final AtomicInteger totalSentOps = new AtomicInteger();\n-        final AtomicInteger lastBatchCount = new AtomicInteger(); // used to estimate the count of the subsequent batch.\n-        final CheckedSupplier<List<Translog.Operation>, IOException> readNextBatch = () -> {\n-            // We need to synchronized Snapshot#next() because it's called by different threads through sendBatch.\n-            // Even though those calls are not concurrent, Snapshot#next() uses non-synchronized state and is not multi-thread-compatible.\n-            synchronized (snapshot) {\n-                final List<Translog.Operation> ops = lastBatchCount.get() > 0 ? new ArrayList<>(lastBatchCount.get()) : new ArrayList<>();\n-                long batchSizeInBytes = 0L;\n-                Translog.Operation operation;\n-                while ((operation = snapshot.next()) != null) {\n-                    if (shard.state() == IndexShardState.CLOSED) {\n-                        throw new IndexShardClosedException(request.shardId());\n-                    }\n-                    cancellableThreads.checkForCancel();\n-                    final long seqNo = operation.seqNo();\n-                    if (seqNo < startingSeqNo || seqNo > endingSeqNo) {\n-                        skippedOps.incrementAndGet();\n-                        continue;\n-                    }\n-                    ops.add(operation);\n-                    batchSizeInBytes += operation.estimateSize();\n-                    totalSentOps.incrementAndGet();\n-\n-                    // check if this request is past bytes threshold, and if so, send it off\n-                    if (batchSizeInBytes >= chunkSizeInBytes) {\n-                        break;\n-                    }\n-                }\n-                lastBatchCount.set(ops.size());\n-                return ops;\n-            }\n-        };\n-\n         final StopWatch stopWatch = new StopWatch().start();\n-        final ActionListener<Long> batchedListener = ActionListener.map(listener,\n-            targetLocalCheckpoint -> {\n-                assert snapshot.totalOperations() == snapshot.skippedOperations() + skippedOps.get() + totalSentOps.get()\n+        final StepListener<Void> sendListener = new StepListener<>();\n+        final OperationBatchSender sender = new OperationBatchSender(startingSeqNo, endingSeqNo, snapshot, maxSeenAutoIdTimestamp,\n+            maxSeqNoOfUpdatesOrDeletes, retentionLeases, mappingVersion, sendListener);\n+        sendListener.whenComplete(\n+            ignored -> {\n+                final long skippedOps = sender.skippedOps.get();\n+                final int totalSentOps = sender.sentOps.get();\n+                final long targetLocalCheckpoint = sender.targetLocalCheckpoint.get();\n+                assert snapshot.totalOperations() == snapshot.skippedOperations() + skippedOps + totalSentOps\n                     : String.format(Locale.ROOT, \"expected total [%d], overridden [%d], skipped [%d], total sent [%d]\",\n-                    snapshot.totalOperations(), snapshot.skippedOperations(), skippedOps.get(), totalSentOps.get());\n+                    snapshot.totalOperations(), snapshot.skippedOperations(), skippedOps, totalSentOps);\n                 stopWatch.stop();\n                 final TimeValue tookTime = stopWatch.totalTime();\n                 logger.trace(\"recovery [phase2]: took [{}]\", tookTime);\n-                return new SendSnapshotResult(targetLocalCheckpoint, totalSentOps.get(), tookTime);\n-            }\n-        );\n+                listener.onResponse(new SendSnapshotResult(targetLocalCheckpoint, totalSentOps, tookTime));\n+            }, listener::onFailure);\n+        sender.start();\n+    }\n \n-        sendBatch(\n-                readNextBatch,\n-                true,\n-                SequenceNumbers.UNASSIGNED_SEQ_NO,\n-                snapshot.totalOperations(),\n-                maxSeenAutoIdTimestamp,\n-                maxSeqNoOfUpdatesOrDeletes,\n-                retentionLeases,\n-                mappingVersion,\n-                batchedListener);\n+    private static class OperationChunkRequest implements MultiChunkTransfer.ChunkRequest {\n+        final List<Translog.Operation> operations;\n+        final boolean lastChunk;\n+\n+        OperationChunkRequest(List<Translog.Operation> operations, boolean lastChunk) {\n+            this.operations = operations;\n+            this.lastChunk = lastChunk;\n+        }\n+\n+        @Override\n+        public boolean lastChunk() {\n+            return lastChunk;\n+        }\n     }\n \n-    private void sendBatch(\n-            final CheckedSupplier<List<Translog.Operation>, IOException> nextBatch,\n-            final boolean firstBatch,\n-            final long targetLocalCheckpoint,\n-            final int totalTranslogOps,\n-            final long maxSeenAutoIdTimestamp,\n-            final long maxSeqNoOfUpdatesOrDeletes,\n-            final RetentionLeases retentionLeases,\n-            final long mappingVersionOnPrimary,\n-            final ActionListener<Long> listener) throws IOException {\n-        assert ThreadPool.assertCurrentMethodIsNotCalledRecursively();\n-        assert Transports.assertNotTransportThread(RecoverySourceHandler.this + \"[send translog]\");\n-        final List<Translog.Operation> operations = nextBatch.get();\n-        // send the leftover operations or if no operations were sent, request the target to respond with its local checkpoint\n-        if (operations.isEmpty() == false || firstBatch) {\n+    private class OperationBatchSender extends MultiChunkTransfer<Translog.Snapshot, OperationChunkRequest> {\n+        private final long startingSeqNo;\n+        private final long endingSeqNo;\n+        private final Translog.Snapshot snapshot;\n+        private final long maxSeenAutoIdTimestamp;\n+        private final long maxSeqNoOfUpdatesOrDeletes;\n+        private final RetentionLeases retentionLeases;\n+        private final long mappingVersion;\n+        private int lastBatchCount = 0; // used to estimate the count of the subsequent batch.\n+        private final AtomicInteger skippedOps = new AtomicInteger();\n+        private final AtomicInteger sentOps = new AtomicInteger();\n+        private final AtomicLong targetLocalCheckpoint = new AtomicLong(SequenceNumbers.NO_OPS_PERFORMED);\n+\n+        OperationBatchSender(long startingSeqNo, long endingSeqNo, Translog.Snapshot snapshot, long maxSeenAutoIdTimestamp,\n+                             long maxSeqNoOfUpdatesOrDeletes, RetentionLeases retentionLeases, long mappingVersion,\n+                             ActionListener<Void> listener) {\n+            super(logger, threadPool.getThreadContext(), listener, maxConcurrentFileChunks, List.of(snapshot));", "originalCommit": "7707c3318111b53b310ce782295d049b06a98d71", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTQyMzE4NQ==", "url": "https://github.com/elastic/elasticsearch/pull/58018#discussion_r439423185", "bodyText": "We have a single snapshot, but we can have multiple batches from it. The MultiChunkTransfer can send multiple batches without waiting for the acknowledges from the receiver.", "author": "dnhatn", "createdAt": "2020-06-12T13:38:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTMxMTU5NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTQzNjk4Nw==", "url": "https://github.com/elastic/elasticsearch/pull/58018#discussion_r439436987", "bodyText": "\ud83e\udd26 right, sorry for the noise :) My memory on this class betrayed me.", "author": "original-brownbear", "createdAt": "2020-06-12T14:00:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTMxMTU5NA=="}], "type": "inlineReview"}, {"oid": "e1332b3df020f3b36cd053cb7eea87c4729d0123", "url": "https://github.com/elastic/elasticsearch/commit/e1332b3df020f3b36cd053cb7eea87c4729d0123", "message": "Merge branch 'master' into send-ops-concurrently", "committedDate": "2020-07-06T14:08:59Z", "type": "commit"}, {"oid": "a28c2e3dbfe6fbd4b9903251a211bf0a1f2e115c", "url": "https://github.com/elastic/elasticsearch/commit/a28c2e3dbfe6fbd4b9903251a211bf0a1f2e115c", "message": "New setting", "committedDate": "2020-07-06T15:46:05Z", "type": "commit"}, {"oid": "d34db4b50754d3676d76995be0b139e6a32ba095", "url": "https://github.com/elastic/elasticsearch/commit/d34db4b50754d3676d76995be0b139e6a32ba095", "message": "Use generic to write operations", "committedDate": "2020-07-06T15:47:02Z", "type": "commit"}, {"oid": "a564188d9869bc211383a926920d5160ccbda7c7", "url": "https://github.com/elastic/elasticsearch/commit/a564188d9869bc211383a926920d5160ccbda7c7", "message": "fix setting", "committedDate": "2020-07-06T15:55:56Z", "type": "commit"}, {"oid": "44f83d6a6b7af1e5e4f646816631c739ea142f71", "url": "https://github.com/elastic/elasticsearch/commit/44f83d6a6b7af1e5e4f646816631c739ea142f71", "message": "reduce random setting upper bound", "committedDate": "2020-07-06T16:08:57Z", "type": "commit"}, {"oid": "1a6b6300f6f12d949958d41b3bd8a46e7ac2eaa3", "url": "https://github.com/elastic/elasticsearch/commit/1a6b6300f6f12d949958d41b3bd8a46e7ac2eaa3", "message": "Merge branch 'master' into send-ops-concurrently", "committedDate": "2020-07-06T18:15:36Z", "type": "commit"}, {"oid": "f0c2d713e69f2616c5b81749f03b8d676f411552", "url": "https://github.com/elastic/elasticsearch/commit/f0c2d713e69f2616c5b81749f03b8d676f411552", "message": "stylecheck", "committedDate": "2020-07-06T18:22:14Z", "type": "commit"}, {"oid": "e4f1fbfed406b007d3cc24b18781ce1b36607120", "url": "https://github.com/elastic/elasticsearch/commit/e4f1fbfed406b007d3cc24b18781ce1b36607120", "message": "rewording", "committedDate": "2020-07-07T14:36:48Z", "type": "commit"}, {"oid": "a7f1df334af59e13dc663aae27318b60de500329", "url": "https://github.com/elastic/elasticsearch/commit/a7f1df334af59e13dc663aae27318b60de500329", "message": "rewording", "committedDate": "2020-07-07T14:44:41Z", "type": "commit"}, {"oid": "50c13f7ffd58174f189d0b1ca54dabf7eebb493d", "url": "https://github.com/elastic/elasticsearch/commit/50c13f7ffd58174f189d0b1ca54dabf7eebb493d", "message": "Merge branch 'master' into send-ops-concurrently", "committedDate": "2020-07-07T14:45:03Z", "type": "commit"}, {"oid": "ef09c18745423d5c5c976ca1bc565380df400a88", "url": "https://github.com/elastic/elasticsearch/commit/ef09c18745423d5c5c976ca1bc565380df400a88", "message": "fix test after removing uid from translog operation", "committedDate": "2020-07-07T16:33:48Z", "type": "commit"}, {"oid": "ff7e57b3326f914ee65b5f6761162cccee9ce2ef", "url": "https://github.com/elastic/elasticsearch/commit/ff7e57b3326f914ee65b5f6761162cccee9ce2ef", "message": "Merge branch 'master' into send-ops-concurrently", "committedDate": "2020-07-07T20:50:07Z", "type": "commit"}]}