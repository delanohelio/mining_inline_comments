{"pr_number": 63031, "pr_title": "Add telemetry for data tiers", "pr_createdAt": "2020-09-29T17:29:02Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/63031", "timeline": [{"oid": "07183618d697c14dc73252644d7f72982e5b332a", "url": "https://github.com/elastic/elasticsearch/commit/07183618d697c14dc73252644d7f72982e5b332a", "message": "Add telemetry for data tiers\n\nThis commit adds telemetry for our data tier formalization. This telemetry helps determine the\ntopology of the cluster with regard to the content, data, hot, warm, & cold tiers/roles.\n\nAn example of the telemetry looks like:\n\n```\nGET /_xpack/usage?human\n{\n  ...\n  \"data_tiers\" : {\n    \"available\" : true,\n    \"enabled\" : true,\n    \"data_warm\" : {\n      ...\n    },\n    \"data\" : {\n      ...\n    },\n    \"data_cold\" : {\n      ...\n    },\n    \"data_content\" : {\n      \"node_count\" : 1,\n      \"index_count\" : 6,\n      \"total_shard_count\" : 6,\n      \"primary_shard_count\" : 6,\n      \"doc_count\" : 71,\n      \"total_size\" : \"59.6kb\",\n      \"total_size_bytes\" : 61110,\n      \"primary_size\" : \"59.6kb\",\n      \"primary_size_bytes\" : 61110,\n      \"primary_shard_size_avg\" : \"9.9kb\",\n      \"primary_shard_size_avg_bytes\" : 10185,\n      \"primary_shard_size_median_bytes\" : \"8kb\",\n      \"primary_shard_size_median_bytes\" : 8254,\n      \"primary_shard_size_mad_bytes\" : \"7.2kb\",\n      \"primary_shard_size_mad_bytes\" : 7391\n    },\n    \"data_hot\" : {\n       ...\n    }\n  }\n}\n```\n\nThe fields are as follows:\n\n- node_count :: number of nodes with this tier/role\n- index_count :: number of indices on this tier\n- total_shard_count :: total number of shards for all nodes in this tier\n- primary_shard_count :: number of primary shards for all nodes in this tier\n- doc_count :: number of documents for all nodes in this tier\n- total_size_bytes :: total number of bytes for all shards for all nodes in this tier\n- primary_size_bytes :: number of bytes for all primary shards on all nodes in this tier\n- primary_shard_size_avg_bytes :: average shard size for primary shard in this tier\n- primary_shard_size_median_bytes :: median shard size for primary shard in this tier\n- primary_shard_size_mad_bytes :: [median absolute deviation](https://en.wikipedia.org/wiki/Median_absolute_deviation) of shard size for primary shard in this tier\n\nRelates to #60848", "committedDate": "2020-09-29T17:22:16Z", "type": "commit"}, {"oid": "b1e0ab290ec58de2cb7021124fa63c3fb15c6f7a", "url": "https://github.com/elastic/elasticsearch/commit/b1e0ab290ec58de2cb7021124fa63c3fb15c6f7a", "message": "Fix docs tests", "committedDate": "2020-09-29T17:46:05Z", "type": "commit"}, {"oid": "b2e2acb2c72d0ba9595e1ea5a41529c80e1cd8c9", "url": "https://github.com/elastic/elasticsearch/commit/b2e2acb2c72d0ba9595e1ea5a41529c80e1cd8c9", "message": "Fix erroneous field names", "committedDate": "2020-09-29T17:46:11Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzMyODc4Nw==", "url": "https://github.com/elastic/elasticsearch/pull/63031#discussion_r497328787", "bodyText": "As said above, I don't think we should mix the data role with the data tiers.", "author": "andreidan", "createdAt": "2020-09-30T08:21:55Z", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/DataTiersUsageTransportAction.java", "diffHunk": "@@ -0,0 +1,146 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.core;\n+\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.admin.cluster.node.stats.NodeStats;\n+import org.elasticsearch.action.admin.cluster.node.stats.NodesStatsResponse;\n+import org.elasticsearch.action.admin.indices.stats.CommonStatsFlags;\n+import org.elasticsearch.action.support.ActionFilters;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.RoutingNode;\n+import org.elasticsearch.cluster.routing.RoutingNodes;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.inject.Inject;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.store.StoreStats;\n+import org.elasticsearch.protocol.xpack.XPackUsageRequest;\n+import org.elasticsearch.search.aggregations.metrics.TDigestState;\n+import org.elasticsearch.tasks.Task;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.transport.TransportService;\n+import org.elasticsearch.xpack.core.action.XPackUsageFeatureAction;\n+import org.elasticsearch.xpack.core.action.XPackUsageFeatureResponse;\n+import org.elasticsearch.xpack.core.action.XPackUsageFeatureTransportAction;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.stream.Collectors;\n+\n+public class DataTiersUsageTransportAction extends XPackUsageFeatureTransportAction {\n+\n+    private final Client client;\n+\n+    @Inject\n+    public DataTiersUsageTransportAction(TransportService transportService, ClusterService clusterService,\n+                                         ThreadPool threadPool, ActionFilters actionFilters,\n+                                         IndexNameExpressionResolver indexNameExpressionResolver, Client client) {\n+        super(XPackUsageFeatureAction.DATA_TIERS.name(), transportService, clusterService,\n+            threadPool, actionFilters, indexNameExpressionResolver);\n+        this.client = client;\n+    }\n+\n+    @Override\n+    protected void masterOperation(Task task, XPackUsageRequest request, ClusterState state,\n+                                   ActionListener<XPackUsageFeatureResponse> listener) {\n+        client.admin().cluster().prepareNodesStats()\n+            .all()\n+            .setIndices(CommonStatsFlags.ALL)\n+            .execute(ActionListener.wrap(nodesStatsResponse -> {\n+                final RoutingNodes routingNodes = state.getRoutingNodes();\n+\n+                // First separate the nodes into separate tiers, note that nodes *may* be duplicated\n+                Map<String, List<NodeStats>> tierSpecificNodeStats = separateTiers(nodesStatsResponse);\n+\n+                // Generate tier specific stats for the nodes\n+                Map<String, DataTiersFeatureSetUsage.TierSpecificStats> tierSpecificStats = tierSpecificNodeStats.entrySet()\n+                    .stream().collect(Collectors.toMap(Map.Entry::getKey, ns -> calculateStats(ns.getValue(), routingNodes)));\n+\n+                listener.onResponse(new XPackUsageFeatureResponse(new DataTiersFeatureSetUsage(tierSpecificStats)));\n+            }, listener::onFailure));\n+    }\n+\n+    private static Map<String, List<NodeStats>> separateTiers(NodesStatsResponse nodesStatsResponse) {\n+        Map<String, List<NodeStats>> responses = new HashMap<>();\n+        DataTier.ALL_DATA_TIERS.forEach(tier ->\n+            responses.put(tier, nodesStatsResponse.getNodes().stream()\n+                .filter(stats -> stats.getNode().getRoles().stream()\n+                    .map(DiscoveryNodeRole::roleName)\n+                    .anyMatch(rn -> rn.equals(tier)))\n+                .collect(Collectors.toList())));\n+        // Also manually add the \"data\" role so we calculate statistics for it\n+        responses.put(DiscoveryNodeRole.DATA_ROLE.roleName(), nodesStatsResponse.getNodes().stream()\n+            .filter(stats -> stats.getNode().getRoles().stream().anyMatch(rn -> rn.equals(DiscoveryNodeRole.DATA_ROLE)))\n+            .collect(Collectors.toList()));", "originalCommit": "b2e2acb2c72d0ba9595e1ea5a41529c80e1cd8c9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzMyOTkzNw==", "url": "https://github.com/elastic/elasticsearch/pull/63031#discussion_r497329937", "bodyText": "shall we unit test these static methods?", "author": "andreidan", "createdAt": "2020-09-30T08:23:51Z", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/DataTiersUsageTransportAction.java", "diffHunk": "@@ -0,0 +1,146 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.core;\n+\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.admin.cluster.node.stats.NodeStats;\n+import org.elasticsearch.action.admin.cluster.node.stats.NodesStatsResponse;\n+import org.elasticsearch.action.admin.indices.stats.CommonStatsFlags;\n+import org.elasticsearch.action.support.ActionFilters;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.RoutingNode;\n+import org.elasticsearch.cluster.routing.RoutingNodes;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.inject.Inject;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.store.StoreStats;\n+import org.elasticsearch.protocol.xpack.XPackUsageRequest;\n+import org.elasticsearch.search.aggregations.metrics.TDigestState;\n+import org.elasticsearch.tasks.Task;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.transport.TransportService;\n+import org.elasticsearch.xpack.core.action.XPackUsageFeatureAction;\n+import org.elasticsearch.xpack.core.action.XPackUsageFeatureResponse;\n+import org.elasticsearch.xpack.core.action.XPackUsageFeatureTransportAction;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.stream.Collectors;\n+\n+public class DataTiersUsageTransportAction extends XPackUsageFeatureTransportAction {\n+\n+    private final Client client;\n+\n+    @Inject\n+    public DataTiersUsageTransportAction(TransportService transportService, ClusterService clusterService,\n+                                         ThreadPool threadPool, ActionFilters actionFilters,\n+                                         IndexNameExpressionResolver indexNameExpressionResolver, Client client) {\n+        super(XPackUsageFeatureAction.DATA_TIERS.name(), transportService, clusterService,\n+            threadPool, actionFilters, indexNameExpressionResolver);\n+        this.client = client;\n+    }\n+\n+    @Override\n+    protected void masterOperation(Task task, XPackUsageRequest request, ClusterState state,\n+                                   ActionListener<XPackUsageFeatureResponse> listener) {\n+        client.admin().cluster().prepareNodesStats()\n+            .all()\n+            .setIndices(CommonStatsFlags.ALL)\n+            .execute(ActionListener.wrap(nodesStatsResponse -> {\n+                final RoutingNodes routingNodes = state.getRoutingNodes();\n+\n+                // First separate the nodes into separate tiers, note that nodes *may* be duplicated\n+                Map<String, List<NodeStats>> tierSpecificNodeStats = separateTiers(nodesStatsResponse);\n+\n+                // Generate tier specific stats for the nodes\n+                Map<String, DataTiersFeatureSetUsage.TierSpecificStats> tierSpecificStats = tierSpecificNodeStats.entrySet()\n+                    .stream().collect(Collectors.toMap(Map.Entry::getKey, ns -> calculateStats(ns.getValue(), routingNodes)));\n+\n+                listener.onResponse(new XPackUsageFeatureResponse(new DataTiersFeatureSetUsage(tierSpecificStats)));\n+            }, listener::onFailure));\n+    }\n+\n+    private static Map<String, List<NodeStats>> separateTiers(NodesStatsResponse nodesStatsResponse) {", "originalCommit": "b2e2acb2c72d0ba9595e1ea5a41529c80e1cd8c9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Nzc4ODEyNA==", "url": "https://github.com/elastic/elasticsearch/pull/63031#discussion_r497788124", "bodyText": "I added a unit test for this one (and the MAD calculation), the larger one would require so much boilerplate and/or mocking as to be pretty useless as a unit test (hence the integration test for it)", "author": "dakrone", "createdAt": "2020-09-30T20:42:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzMyOTkzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzMzMDA4Mw==", "url": "https://github.com/elastic/elasticsearch/pull/63031#discussion_r497330083", "bodyText": "can we please verify this with unit tests?", "author": "andreidan", "createdAt": "2020-09-30T08:24:05Z", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/DataTiersUsageTransportAction.java", "diffHunk": "@@ -0,0 +1,146 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.core;\n+\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.admin.cluster.node.stats.NodeStats;\n+import org.elasticsearch.action.admin.cluster.node.stats.NodesStatsResponse;\n+import org.elasticsearch.action.admin.indices.stats.CommonStatsFlags;\n+import org.elasticsearch.action.support.ActionFilters;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.RoutingNode;\n+import org.elasticsearch.cluster.routing.RoutingNodes;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.inject.Inject;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.store.StoreStats;\n+import org.elasticsearch.protocol.xpack.XPackUsageRequest;\n+import org.elasticsearch.search.aggregations.metrics.TDigestState;\n+import org.elasticsearch.tasks.Task;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.transport.TransportService;\n+import org.elasticsearch.xpack.core.action.XPackUsageFeatureAction;\n+import org.elasticsearch.xpack.core.action.XPackUsageFeatureResponse;\n+import org.elasticsearch.xpack.core.action.XPackUsageFeatureTransportAction;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.stream.Collectors;\n+\n+public class DataTiersUsageTransportAction extends XPackUsageFeatureTransportAction {\n+\n+    private final Client client;\n+\n+    @Inject\n+    public DataTiersUsageTransportAction(TransportService transportService, ClusterService clusterService,\n+                                         ThreadPool threadPool, ActionFilters actionFilters,\n+                                         IndexNameExpressionResolver indexNameExpressionResolver, Client client) {\n+        super(XPackUsageFeatureAction.DATA_TIERS.name(), transportService, clusterService,\n+            threadPool, actionFilters, indexNameExpressionResolver);\n+        this.client = client;\n+    }\n+\n+    @Override\n+    protected void masterOperation(Task task, XPackUsageRequest request, ClusterState state,\n+                                   ActionListener<XPackUsageFeatureResponse> listener) {\n+        client.admin().cluster().prepareNodesStats()\n+            .all()\n+            .setIndices(CommonStatsFlags.ALL)\n+            .execute(ActionListener.wrap(nodesStatsResponse -> {\n+                final RoutingNodes routingNodes = state.getRoutingNodes();\n+\n+                // First separate the nodes into separate tiers, note that nodes *may* be duplicated\n+                Map<String, List<NodeStats>> tierSpecificNodeStats = separateTiers(nodesStatsResponse);\n+\n+                // Generate tier specific stats for the nodes\n+                Map<String, DataTiersFeatureSetUsage.TierSpecificStats> tierSpecificStats = tierSpecificNodeStats.entrySet()\n+                    .stream().collect(Collectors.toMap(Map.Entry::getKey, ns -> calculateStats(ns.getValue(), routingNodes)));\n+\n+                listener.onResponse(new XPackUsageFeatureResponse(new DataTiersFeatureSetUsage(tierSpecificStats)));\n+            }, listener::onFailure));\n+    }\n+\n+    private static Map<String, List<NodeStats>> separateTiers(NodesStatsResponse nodesStatsResponse) {\n+        Map<String, List<NodeStats>> responses = new HashMap<>();\n+        DataTier.ALL_DATA_TIERS.forEach(tier ->\n+            responses.put(tier, nodesStatsResponse.getNodes().stream()\n+                .filter(stats -> stats.getNode().getRoles().stream()\n+                    .map(DiscoveryNodeRole::roleName)\n+                    .anyMatch(rn -> rn.equals(tier)))\n+                .collect(Collectors.toList())));\n+        // Also manually add the \"data\" role so we calculate statistics for it\n+        responses.put(DiscoveryNodeRole.DATA_ROLE.roleName(), nodesStatsResponse.getNodes().stream()\n+            .filter(stats -> stats.getNode().getRoles().stream().anyMatch(rn -> rn.equals(DiscoveryNodeRole.DATA_ROLE)))\n+            .collect(Collectors.toList()));\n+        return responses;\n+    }\n+\n+    private DataTiersFeatureSetUsage.TierSpecificStats calculateStats(List<NodeStats> nodesStats, RoutingNodes routingNodes) {\n+        int nodeCount = 0;\n+        int indexCount = 0;\n+        int totalShardCount = 0;\n+        long totalByteCount = 0;\n+        long docCount = 0;\n+        final AtomicInteger primaryShardCount = new AtomicInteger(0);\n+        final AtomicLong primaryByteCount = new AtomicLong(0);\n+        final TDigestState valueSketch = new TDigestState(1000);\n+        for (NodeStats nodeStats : nodesStats) {\n+            nodeCount++;\n+            totalByteCount += nodeStats.getIndices().getStore().getSizeInBytes();\n+            docCount += nodeStats.getIndices().getDocs().getCount();\n+            String nodeId = nodeStats.getNode().getId();\n+            final RoutingNode node = routingNodes.node(nodeId);\n+            if (node != null) {\n+                totalShardCount += node.shardsWithState(ShardRoutingState.STARTED).size();\n+                Set<Index> indicesOnNode = node.shardsWithState(ShardRoutingState.STARTED).stream()\n+                    .map(ShardRouting::index)\n+                    .collect(Collectors.toSet());\n+                indexCount += indicesOnNode.size();\n+                indicesOnNode.forEach(index -> {\n+                    nodeStats.getIndices().getShardStats(index).stream()\n+                        .filter(shardStats -> shardStats.getPrimary().getStore() != null)\n+                        .forEach(shardStats -> {\n+                            StoreStats primaryStoreStats = shardStats.getPrimary().getStore();\n+                            // If storeStats is null, it means this is not a replica\n+                            primaryShardCount.incrementAndGet();\n+                            long primarySize = primaryStoreStats.getSizeInBytes();\n+                            primaryByteCount.addAndGet(primarySize);\n+                            valueSketch.add(primarySize);\n+                        });\n+                });\n+            }\n+        }\n+        long primaryShardSizeMedian = (long) valueSketch.quantile(0.5);\n+        long primaryShardSizeMAD = computeMedianAbsoluteDeviation(valueSketch);\n+        return new DataTiersFeatureSetUsage.TierSpecificStats(nodeCount, indexCount, totalShardCount, primaryShardCount.get(), docCount,\n+            totalByteCount, primaryByteCount.get(), primaryShardSizeMedian, primaryShardSizeMAD);\n+    }\n+\n+    private static long computeMedianAbsoluteDeviation(TDigestState valuesSketch) {", "originalCommit": "b2e2acb2c72d0ba9595e1ea5a41529c80e1cd8c9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "7b8de38e4c3e5c11bc483291dabba73d311dae42", "url": "https://github.com/elastic/elasticsearch/commit/7b8de38e4c3e5c11bc483291dabba73d311dae42", "message": "Add unit test for computeMedianAbsoluteDeviation", "committedDate": "2020-09-30T20:20:03Z", "type": "commit"}, {"oid": "94267fbe3ff3f658516afdbd2e87b982d74bf2c2", "url": "https://github.com/elastic/elasticsearch/commit/94267fbe3ff3f658516afdbd2e87b982d74bf2c2", "message": "Remove \"data\" from data_tiers, add unit tests for separateTiers", "committedDate": "2020-09-30T20:38:15Z", "type": "commit"}, {"oid": "ff2a6980b039850bff9f8c04a6bd0747bb37552d", "url": "https://github.com/elastic/elasticsearch/commit/ff2a6980b039850bff9f8c04a6bd0747bb37552d", "message": "Merge remote-tracking branch 'origin/master' into dt-add-telemetry", "committedDate": "2020-09-30T20:43:11Z", "type": "commit"}]}