{"pr_number": 55114, "pr_title": "Fix concurrent refresh of tokens", "pr_createdAt": "2020-04-13T13:57:26Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/55114", "timeline": [{"oid": "e5458428127fa19664e6776b6913da3e6b37b512", "url": "https://github.com/elastic/elasticsearch/commit/e5458428127fa19664e6776b6913da3e6b37b512", "message": "cleanup in TokenAuthIntegTests", "committedDate": "2020-04-13T09:47:06Z", "type": "commit"}, {"oid": "8ff5fa69d53adedfc315135cdb9bb3a124f9cb5f", "url": "https://github.com/elastic/elasticsearch/commit/8ff5fa69d53adedfc315135cdb9bb3a124f9cb5f", "message": "Fix concurrent refresh of tokens\n\nOur handling for cncurrent refresh of access tokens suffered from\na race condition where:\n\n1. Thread A has just finished with updating the existing token\ndocument, but hasn't stored the new tokens in a new document\nyet\n2. Thread B attempts to refresh the same token and since the\noriginal token document is marked as refreshed, it decrypts and\ngets the new access token and refresh token and returns that to\nthe caller of the API.\n3. The caller attempts to use the newly refreshed access token\nimmediately and gets an authentcation error since Thread a still\nhasn't finished writing the document.\n\nThis commit changes the behavior so that Thread B, would first try\nto do a Get request for the token document where it expects that\nthe access token it decrypted is stored(with exponential backoff)\nand will not respond until it can verify that it reads it in the\ntokens index. That ensures that we only ever return tokens in a\nresponse if they are already valid and can be used immediately\n\nIt also adjusts\nTokenAuthIntegTests#testRefreshingMultipleTimesWithinWindowSucceeds\nto test authenticating with the tokens each thread receives,\nwhich fails without the fix.\n\nResolves: #54289", "committedDate": "2020-04-13T13:54:35Z", "type": "commit"}, {"oid": "a1828d56c597856db809ff92035f8b23e00e9ad5", "url": "https://github.com/elastic/elasticsearch/commit/a1828d56c597856db809ff92035f8b23e00e9ad5", "message": "fix test", "committedDate": "2020-04-13T15:13:43Z", "type": "commit"}, {"oid": "c62ff216201372444f70bce0ce8f221f5b87c613", "url": "https://github.com/elastic/elasticsearch/commit/c62ff216201372444f70bce0ce8f221f5b87c613", "message": "Merge remote-tracking branch 'origin/master' into concurrent-token-refresh-and-authn", "committedDate": "2020-04-13T15:14:11Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgzNjI5MQ==", "url": "https://github.com/elastic/elasticsearch/pull/55114#discussion_r407836291", "bodyText": "Maybe extract this logic into a consumer? It can be reused for the onReponse part as well.", "author": "ywangd", "createdAt": "2020-04-14T02:56:40Z", "path": "x-pack/plugin/security/src/main/java/org/elasticsearch/xpack/security/authc/TokenService.java", "diffHunk": "@@ -1092,10 +1094,56 @@ void decryptAndReturnSupersedingTokens(String refreshToken, RefreshTokenStatus r\n                 logger.warn(\"Decrypted tokens string is not correctly formatted\");\n                 listener.onFailure(invalidGrantException(\"could not refresh the requested token\"));\n             } else {\n-                listener.onResponse(new Tuple<>(prependVersionAndEncodeAccessToken(refreshTokenStatus.getVersion(), decryptedTokens[0]),\n-                    prependVersionAndEncodeRefreshToken(refreshTokenStatus.getVersion(), decryptedTokens[1])));\n+                // We expect this to protect against race conditions that manifest within few ms\n+                final Iterator<TimeValue> backoff = BackoffPolicy.exponentialBackoff(TimeValue.timeValueMillis(10), 8).iterator();\n+                final String tokenDocId = getTokenDocumentId(hashTokenString(decryptedTokens[0]));\n+                final Consumer<Exception> onFailure = ex ->\n+                    listener.onFailure(traceLog(\"decrypt and get superseding token\", tokenDocId, ex));\n+                getTokenDocAsync(tokenDocId, tokensIndex, new ActionListener<>() {\n+                    @Override\n+                    public void onResponse(GetResponse response) {\n+                        if (response.isExists()) {\n+                            try {\n+                                listener.onResponse(\n+                                    new Tuple<>(prependVersionAndEncodeAccessToken(refreshTokenStatus.getVersion(), decryptedTokens[0]),\n+                                        prependVersionAndEncodeRefreshToken(refreshTokenStatus.getVersion(), decryptedTokens[1])));\n+                            } catch (GeneralSecurityException | IOException e) {\n+                                logger.warn(\"Could not format stored superseding token values\", e);\n+                                onFailure.accept(invalidGrantException(\"could not refresh the requested token\"));\n+                            }\n+                        } else {\n+                            if (backoff.hasNext()) {\n+                                logger.trace(\"could not get token document [{}] that should have been created, retrying\", tokenDocId);\n+                                client.threadPool().schedule(\n+                                    () -> getTokenDocAsync(tokenDocId, tokensIndex, this),\n+                                    backoff.next(), GENERIC);\n+                            } else {\n+                                logger.warn(\"could not get token document [{}] that should have been created after all retries\",\n+                                    tokenDocId);\n+                                onFailure.accept(invalidGrantException(\"could not refresh the requested token\"));\n+                            }\n+                        }\n+                    }\n+\n+                    @Override\n+                    public void onFailure(Exception e) {\n+                        if (isShardNotAvailableException(e)) {\n+                            if (backoff.hasNext()) {\n+                                logger.info(\"could not get token document [{}] that should have been created, retrying\", tokenDocId);\n+                                client.threadPool().schedule(() -> getTokenDocAsync(tokenDocId, tokensIndex, this),\n+                                    backoff.next(), GENERIC);\n+                            } else {\n+                                logger.warn(\"could not get token document [{}] that should have been created after all retries\",\n+                                    tokenDocId);\n+                                onFailure.accept(invalidGrantException(\"could not refresh the requested token\"));\n+                            }", "originalCommit": "c62ff216201372444f70bce0ce8f221f5b87c613", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgzNzM4Mw==", "url": "https://github.com/elastic/elasticsearch/pull/55114#discussion_r407837383", "bodyText": "anot(contccess_token - probably some random extra keystrokes?", "author": "ywangd", "createdAt": "2020-04-14T03:00:15Z", "path": "x-pack/plugin/security/src/test/java/org/elasticsearch/xpack/security/authc/TokenAuthIntegTests.java", "diffHunk": "@@ -387,8 +386,11 @@ public void testRefreshingMultipleTimesWithinWindowSucceeds() throws Exception {\n         }\n         completedLatch.await();\n         assertThat(failed.get(), equalTo(false));\n-        // Assert that we only ever got one access_token/refresh_token pair\n-        assertThat(tokens.stream().distinct().collect(Collectors.toList()).size(), equalTo(1));\n+        // Assert that we only ever got one anot(contccess_token/refresh_token pair", "originalCommit": "c62ff216201372444f70bce0ce8f221f5b87c613", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgzODk2Nw==", "url": "https://github.com/elastic/elasticsearch/pull/55114#discussion_r407838967", "bodyText": "nits: alternatively, maybe we could verify all statuses are OK since getAuthenticationResponseCode always returns OK when no exception is thrown. It feels more precise.", "author": "ywangd", "createdAt": "2020-04-14T03:06:10Z", "path": "x-pack/plugin/security/src/test/java/org/elasticsearch/xpack/security/authc/TokenAuthIntegTests.java", "diffHunk": "@@ -387,8 +386,11 @@ public void testRefreshingMultipleTimesWithinWindowSucceeds() throws Exception {\n         }\n         completedLatch.await();\n         assertThat(failed.get(), equalTo(false));\n-        // Assert that we only ever got one access_token/refresh_token pair\n-        assertThat(tokens.stream().distinct().collect(Collectors.toList()).size(), equalTo(1));\n+        // Assert that we only ever got one anot(contccess_token/refresh_token pair\n+        assertThat((int) tokens.stream().distinct().count(), equalTo(1));\n+        // Assert that all requests from all threads could authenticate at the time they received the access token\n+        // see: https://github.com/elastic/elasticsearch/issues/54289\n+        assertThat(authStatuses, not(hasItem(RestStatus.UNAUTHORIZED)));", "originalCommit": "c62ff216201372444f70bce0ce8f221f5b87c613", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzg1NjY0OA==", "url": "https://github.com/elastic/elasticsearch/pull/55114#discussion_r407856648", "bodyText": "I was thinking in terms of testing for the bug this is solving but these all should be OK so I see your point, will address", "author": "jkakavas", "createdAt": "2020-04-14T04:16:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgzODk2Nw=="}], "type": "inlineReview"}, {"oid": "c7d633039f457c208b350776b5a664f3dc62fc37", "url": "https://github.com/elastic/elasticsearch/commit/c7d633039f457c208b350776b5a664f3dc62fc37", "message": "address feedback", "committedDate": "2020-04-14T06:33:38Z", "type": "commit"}, {"oid": "13c21b2dc478de3227d11064dd174dccc63674ce", "url": "https://github.com/elastic/elasticsearch/commit/13c21b2dc478de3227d11064dd174dccc63674ce", "message": "Merge remote-tracking branch 'origin/master' into concurrent-token-refresh-and-authn", "committedDate": "2020-04-14T06:49:12Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDM4MTQ2OA==", "url": "https://github.com/elastic/elasticsearch/pull/55114#discussion_r414381468", "bodyText": "I think this, and the call above should explicitly not fetch the source since we only care about an exists check.", "author": "tvernum", "createdAt": "2020-04-24T08:10:08Z", "path": "x-pack/plugin/security/src/main/java/org/elasticsearch/xpack/security/authc/TokenService.java", "diffHunk": "@@ -1092,10 +1095,51 @@ void decryptAndReturnSupersedingTokens(String refreshToken, RefreshTokenStatus r\n                 logger.warn(\"Decrypted tokens string is not correctly formatted\");\n                 listener.onFailure(invalidGrantException(\"could not refresh the requested token\"));\n             } else {\n-                listener.onResponse(new Tuple<>(prependVersionAndEncodeAccessToken(refreshTokenStatus.getVersion(), decryptedTokens[0]),\n-                    prependVersionAndEncodeRefreshToken(refreshTokenStatus.getVersion(), decryptedTokens[1])));\n+                // We expect this to protect against race conditions that manifest within few ms\n+                final Iterator<TimeValue> backoff = BackoffPolicy.exponentialBackoff(TimeValue.timeValueMillis(10), 8).iterator();\n+                final String tokenDocId = getTokenDocumentId(hashTokenString(decryptedTokens[0]));\n+                final Consumer<Exception> onFailure = ex ->\n+                    listener.onFailure(traceLog(\"decrypt and get superseding token\", tokenDocId, ex));\n+                final Consumer<ActionListener<GetResponse>> maybeRetryGet = actionListener -> {\n+                    if (backoff.hasNext()) {\n+                        logger.info(\"could not get token document [{}] that should have been created, retrying\", tokenDocId);\n+                        client.threadPool().schedule(\n+                            () -> getTokenDocAsync(tokenDocId, tokensIndex, actionListener),\n+                            backoff.next(), GENERIC);\n+                    } else {\n+                        logger.warn(\"could not get token document [{}] that should have been created after all retries\",\n+                            tokenDocId);\n+                        onFailure.accept(invalidGrantException(\"could not refresh the requested token\"));\n+                    }\n+                };\n+                getTokenDocAsync(tokenDocId, tokensIndex, new ActionListener<>() {", "originalCommit": "13c21b2dc478de3227d11064dd174dccc63674ce", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQwMjAxNw==", "url": "https://github.com/elastic/elasticsearch/pull/55114#discussion_r414402017", "bodyText": "Yes, agreed ! Thanks", "author": "jkakavas", "createdAt": "2020-04-24T08:42:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDM4MTQ2OA=="}], "type": "inlineReview"}, {"oid": "9c0f8a00052f5a462d40bc447edfc97e9abf7681", "url": "https://github.com/elastic/elasticsearch/commit/9c0f8a00052f5a462d40bc447edfc97e9abf7681", "message": "Fetch source only when needed", "committedDate": "2020-04-24T08:49:17Z", "type": "commit"}, {"oid": "d937a8fcba7a749fe43695faf263431fa53c6d80", "url": "https://github.com/elastic/elasticsearch/commit/d937a8fcba7a749fe43695faf263431fa53c6d80", "message": "Merge remote-tracking branch 'origin/master' into concurrent-token-refresh-and-authn", "committedDate": "2020-04-24T08:49:22Z", "type": "commit"}]}