{"pr_number": 62480, "pr_title": "Introduce a sparse HyperLogLogPlusPlus class for cloning and serializing low cardinality buckets", "pr_createdAt": "2020-09-16T15:50:59Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/62480", "timeline": [{"oid": "d94d26c8312332b239f91fed929098a2af3b9cb6", "url": "https://github.com/elastic/elasticsearch/commit/d94d26c8312332b239f91fed929098a2af3b9cb6", "message": "Introduce a sparse HyperLogLogPlusPlus class for cloning and serializing low cardinality buckets", "committedDate": "2020-09-16T15:38:50Z", "type": "commit"}, {"oid": "7e488006a90ec6e62a807772ee19f7b18b281ac5", "url": "https://github.com/elastic/elasticsearch/commit/7e488006a90ec6e62a807772ee19f7b18b281ac5", "message": "unused imports", "committedDate": "2020-09-16T15:50:41Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTU1MTYxNw==", "url": "https://github.com/elastic/elasticsearch/pull/62480#discussion_r489551617", "bodyText": "This means that as soon as you reduce you allocate the whole array, even if the cardinality is still small.", "author": "nik9000", "createdAt": "2020-09-16T16:00:59Z", "path": "server/src/main/java/org/elasticsearch/search/aggregations/metrics/InternalCardinality.java", "diffHunk": "@@ -78,34 +78,30 @@ public long getValue() {\n         return counts == null ? 0 : counts.cardinality(0);\n     }\n \n-    public HyperLogLogPlusPlus getCounts() {\n+    public AbstractHyperLogLogPlusPlus getCounts() {\n         return counts;\n     }\n \n     @Override\n     public InternalAggregation reduce(List<InternalAggregation> aggregations, ReduceContext reduceContext) {\n-        InternalCardinality reduced = null;\n+        HyperLogLogPlusPlus reduced = null;\n         for (InternalAggregation aggregation : aggregations) {\n             final InternalCardinality cardinality = (InternalCardinality) aggregation;\n             if (cardinality.counts != null) {\n                 if (reduced == null) {\n-                    reduced = new InternalCardinality(name, new HyperLogLogPlusPlus(cardinality.counts.precision(),\n-                            BigArrays.NON_RECYCLING_INSTANCE, 1), getMetadata());\n+                    reduced = new HyperLogLogPlusPlus(cardinality.counts.precision(),\n+                        BigArrays.NON_RECYCLING_INSTANCE, 1);", "originalCommit": "7e488006a90ec6e62a807772ee19f7b18b281ac5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTU1OTY4MA==", "url": "https://github.com/elastic/elasticsearch/pull/62480#discussion_r489559680", "bodyText": "Yes, the reduce phase is in the expensive object because the sparse does not know how to merge. Note it does not check for duplicates so it is not design for reduce, next iteration.", "author": "iverase", "createdAt": "2020-09-16T16:13:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTU1MTYxNw=="}], "type": "inlineReview"}, {"oid": "1e6f650de7bbdc8831684b1d23108e0401d1a8d0", "url": "https://github.com/elastic/elasticsearch/commit/1e6f650de7bbdc8831684b1d23108e0401d1a8d0", "message": "xpack compile error", "committedDate": "2020-09-16T16:08:35Z", "type": "commit"}, {"oid": "296658011bc37e85c134e91575aaaa629059eaa8", "url": "https://github.com/elastic/elasticsearch/commit/296658011bc37e85c134e91575aaaa629059eaa8", "message": "checkstyle", "committedDate": "2020-09-16T16:39:34Z", "type": "commit"}, {"oid": "1702c0a40789f50e409c592d7072f6606c40adc4", "url": "https://github.com/elastic/elasticsearch/commit/1702c0a40789f50e409c592d7072f6606c40adc4", "message": "add test for new class", "committedDate": "2020-09-16T17:44:27Z", "type": "commit"}]}