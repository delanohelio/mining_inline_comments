{"pr_number": 55952, "pr_title": "Searchable Snapshots should respect max_restore_bytes_per_sec", "pr_createdAt": "2020-04-29T15:43:15Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/55952", "timeline": [{"oid": "06ec9424b659acfc185cc58f2ba388331061d762", "url": "https://github.com/elastic/elasticsearch/commit/06ec9424b659acfc185cc58f2ba388331061d762", "message": "Searchable Snapshots should respect repository's max_restore_bytes_per_sec", "committedDate": "2020-04-29T15:37:02Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTk2MTYzMg==", "url": "https://github.com/elastic/elasticsearch/pull/55952#discussion_r419961632", "bodyText": "I was slightly concerned that this may not be robust if CI is having a particularly slow day, but I see that we make similar assertions in other places without issues.", "author": "DaveCTurner", "createdAt": "2020-05-05T08:59:44Z", "path": "x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/xpack/searchablesnapshots/SearchableSnapshotsIntegTests.java", "diffHunk": "@@ -292,6 +299,82 @@ public void testCanMountSnapshotTakenWhileConcurrentlyIndexing() throws Exceptio\n         ensureGreen(restoredIndexName);\n     }\n \n+    public void testMaxRestoreBytesPerSecIsUsed() throws Exception {\n+        final String repositoryName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        final Settings.Builder repositorySettings = Settings.builder().put(\"location\", randomRepoPath());\n+        final boolean useRateLimits = randomBoolean();\n+        if (useRateLimits) {\n+            repositorySettings.put(\"max_restore_bytes_per_sec\", new ByteSizeValue(10, ByteSizeUnit.KB));\n+        } else {\n+            repositorySettings.put(\"max_restore_bytes_per_sec\", ByteSizeValue.ZERO);\n+        }\n+        assertAcked(\n+            client().admin().cluster().preparePutRepository(repositoryName).setType(FsRepository.TYPE).setSettings(repositorySettings)\n+        );\n+\n+        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        assertAcked(\n+            prepareCreate(\n+                indexName,\n+                Settings.builder()\n+                    .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, between(1, 3))\n+                    .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)\n+                    .put(INDEX_SOFT_DELETES_SETTING.getKey(), true)\n+            )\n+        );\n+        final int nbDocs = between(10, 50);\n+        indexRandom(\n+            true,\n+            false,\n+            IntStream.range(0, nbDocs)\n+                .mapToObj(i -> client().prepareIndex(indexName).setSource(\"foo\", randomBoolean() ? \"bar\" : \"baz\"))\n+                .collect(Collectors.toList())\n+        );\n+        refresh(indexName);\n+\n+        final String restoredIndexName = randomBoolean() ? indexName : randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        final String snapshotName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        CreateSnapshotResponse createSnapshotResponse = client().admin()\n+            .cluster()\n+            .prepareCreateSnapshot(repositoryName, snapshotName)\n+            .setWaitForCompletion(true)\n+            .get();\n+        final SnapshotInfo snapshotInfo = createSnapshotResponse.getSnapshotInfo();\n+        assertThat(snapshotInfo.successfulShards(), greaterThan(0));\n+        assertThat(snapshotInfo.successfulShards(), equalTo(snapshotInfo.totalShards()));\n+\n+        assertAcked(client().admin().indices().prepareDelete(indexName));\n+\n+        logger.info(\"--> restoring index [{}] using rate limits [{}]\", restoredIndexName, useRateLimits);\n+        final MountSearchableSnapshotRequest mount = new MountSearchableSnapshotRequest(\n+            restoredIndexName,\n+            repositoryName,\n+            snapshotName,\n+            indexName,\n+            Settings.builder().put(IndexSettings.INDEX_CHECK_ON_STARTUP.getKey(), Boolean.FALSE.toString()).build(),\n+            Strings.EMPTY_ARRAY,\n+            true\n+        );\n+\n+        final RestoreSnapshotResponse restore = client().execute(MountSearchableSnapshotAction.INSTANCE, mount).get();\n+        assertThat(restore.getRestoreInfo().failedShards(), equalTo(0));\n+        ensureGreen(restoredIndexName);\n+\n+        assertHitCount(client().prepareSearch(restoredIndexName).setSize(0).get(), nbDocs);\n+\n+        final Index restoredIndex = resolveIndex(restoredIndexName);\n+        for (String node : internalCluster().getNodeNames()) {\n+            final IndicesService service = internalCluster().getInstance(IndicesService.class, node);\n+            if (service != null && service.hasIndex(restoredIndex)) {\n+                final RepositoriesService repositoriesService = internalCluster().getInstance(RepositoriesService.class, node);\n+                assertThat(\n+                    repositoriesService.repository(repositoryName).getRestoreThrottleTimeInNanos(),\n+                    useRateLimits ? greaterThan(0L) : equalTo(0L)", "originalCommit": "06ec9424b659acfc185cc58f2ba388331061d762", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDAxMjgyOA==", "url": "https://github.com/elastic/elasticsearch/pull/55952#discussion_r420012828", "bodyText": "I think that it should be OK: the test explicitly sets a max_restore_bytes_per_sec equal to 0 (and not the default 40MB value) when it does not use rate limits. This way the rate limiter is not used at all and we can assert that the restore throttle time is 0.", "author": "tlrx", "createdAt": "2020-05-05T10:34:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTk2MTYzMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDAxODUwOQ==", "url": "https://github.com/elastic/elasticsearch/pull/55952#discussion_r420018509", "bodyText": "I meant the other case - if rate limiting is requested but CI runs so slowly that it's never throttled \ud83d\ude04 But yes, looks to be fine in practice.", "author": "DaveCTurner", "createdAt": "2020-05-05T10:46:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTk2MTYzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTk2Mjc1Ng==", "url": "https://github.com/elastic/elasticsearch/pull/55952#discussion_r419962756", "bodyText": "It's a bit strange to require callers to make sure to apply this rate limiting, rather than having the repository create a blob container that already includes this. But I don't see an easy way to push this down to the blob container level either, so I'm not asking for any changes here.", "author": "DaveCTurner", "createdAt": "2020-05-05T09:01:43Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -444,7 +446,17 @@ public static Directory create(\n         );\n \n         final LazyInitializable<BlobContainer, RuntimeException> lazyBlobContainer = new LazyInitializable<>(\n-            () -> blobStoreRepository.shardContainer(indexId, shardPath.getShardId().id())\n+            () -> new FilterBlobContainer(blobStoreRepository.shardContainer(indexId, shardPath.getShardId().id())) {", "originalCommit": "06ec9424b659acfc185cc58f2ba388331061d762", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDAxMjc4NQ==", "url": "https://github.com/elastic/elasticsearch/pull/55952#discussion_r420012785", "bodyText": "I agree. I admit I'm also confused that max_restore_bytes_per_sec is in fact a limitation of the reading throughput from the repository rather than a writing throughput to the local disk. I'd expect the restore process to use a RateLimitedIndexOutput or something like that.", "author": "tlrx", "createdAt": "2020-05-05T10:34:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTk2Mjc1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTk2NDc5Ng==", "url": "https://github.com/elastic/elasticsearch/pull/55952#discussion_r419964796", "bodyText": "Does this mean that child blob containers will not be rate-limited? I think we need that too?", "author": "DaveCTurner", "createdAt": "2020-05-05T09:05:32Z", "path": "server/src/main/java/org/elasticsearch/common/blobstore/support/FilterBlobContainer.java", "diffHunk": "@@ -0,0 +1,95 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.common.blobstore.support;\n+\n+import org.elasticsearch.common.blobstore.BlobContainer;\n+import org.elasticsearch.common.blobstore.BlobMetadata;\n+import org.elasticsearch.common.blobstore.BlobPath;\n+import org.elasticsearch.common.blobstore.DeleteResult;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+\n+public class FilterBlobContainer implements BlobContainer {\n+\n+    private final BlobContainer delegate;\n+\n+    public FilterBlobContainer(BlobContainer delegate) {\n+        this.delegate = Objects.requireNonNull(delegate);\n+    }\n+\n+    @Override\n+    public BlobPath path() {\n+        return delegate.path();\n+    }\n+\n+    @Override\n+    public InputStream readBlob(String blobName) throws IOException {\n+        return delegate.readBlob(blobName);\n+    }\n+\n+    @Override\n+    public InputStream readBlob(String blobName, long position, long length) throws IOException {\n+        return delegate.readBlob(blobName, position, length);\n+    }\n+\n+    @Override\n+    public long readBlobPreferredLength() {\n+        return delegate.readBlobPreferredLength();\n+    }\n+\n+    @Override\n+    public void writeBlob(String blobName, InputStream inputStream, long blobSize, boolean failIfAlreadyExists) throws IOException {\n+        delegate.writeBlob(blobName, inputStream, blobSize, failIfAlreadyExists);\n+    }\n+\n+    @Override\n+    public void writeBlobAtomic(String blobName, InputStream inputStream, long blobSize, boolean failIfAlreadyExists) throws IOException {\n+        delegate.writeBlobAtomic(blobName, inputStream, blobSize, failIfAlreadyExists);\n+    }\n+\n+    @Override\n+    public DeleteResult delete() throws IOException {\n+        return delegate.delete();\n+    }\n+\n+    @Override\n+    public void deleteBlobsIgnoringIfNotExists(List<String> blobNames) throws IOException {\n+        delegate.deleteBlobsIgnoringIfNotExists(blobNames);\n+    }\n+\n+    @Override\n+    public Map<String, BlobMetadata> listBlobs() throws IOException {\n+        return delegate.listBlobs();\n+    }\n+\n+    @Override\n+    public Map<String, BlobContainer> children() throws IOException {\n+        return delegate.children();", "originalCommit": "06ec9424b659acfc185cc58f2ba388331061d762", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDAxMzExOQ==", "url": "https://github.com/elastic/elasticsearch/pull/55952#discussion_r420013119", "bodyText": "This method is only used for blob deletions, but I agree we should also limit them. I pushed 0048485", "author": "tlrx", "createdAt": "2020-05-05T10:35:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTk2NDc5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDAyMTU1Mw==", "url": "https://github.com/elastic/elasticsearch/pull/55952#discussion_r420021553", "bodyText": "Oh yes you're absolutely right, TIL.", "author": "DaveCTurner", "createdAt": "2020-05-05T10:51:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTk2NDc5Ng=="}], "type": "inlineReview"}, {"oid": "004848579944d1b615719e985e45db48f9687970", "url": "https://github.com/elastic/elasticsearch/commit/004848579944d1b615719e985e45db48f9687970", "message": "also wrap children", "committedDate": "2020-05-05T10:34:41Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDAxOTIyMg==", "url": "https://github.com/elastic/elasticsearch/pull/55952#discussion_r420019222", "bodyText": "Suggest alternative name and renaming the parameter too:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                protected abstract BlobContainer delegateChildren(BlobContainer children);\n          \n          \n            \n                protected abstract BlobContainer wrapChild(BlobContainer child);", "author": "DaveCTurner", "createdAt": "2020-05-05T10:47:20Z", "path": "server/src/main/java/org/elasticsearch/common/blobstore/support/FilterBlobContainer.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.common.blobstore.support;\n+\n+import org.elasticsearch.common.blobstore.BlobContainer;\n+import org.elasticsearch.common.blobstore.BlobMetadata;\n+import org.elasticsearch.common.blobstore.BlobPath;\n+import org.elasticsearch.common.blobstore.DeleteResult;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public abstract class FilterBlobContainer implements BlobContainer {\n+\n+    private final BlobContainer delegate;\n+\n+    public FilterBlobContainer(BlobContainer delegate) {\n+        this.delegate = Objects.requireNonNull(delegate);\n+    }\n+\n+    protected abstract BlobContainer delegateChildren(BlobContainer children);", "originalCommit": "004848579944d1b615719e985e45db48f9687970", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "84904de5e6e81fee196180fd67e12270f884e36c", "url": "https://github.com/elastic/elasticsearch/commit/84904de5e6e81fee196180fd67e12270f884e36c", "message": "rename", "committedDate": "2020-05-05T11:22:53Z", "type": "commit"}, {"oid": "4ba36eba8fddf699ea9b66054789be9d65488971", "url": "https://github.com/elastic/elasticsearch/commit/4ba36eba8fddf699ea9b66054789be9d65488971", "message": "Merge branch 'master' into respect-max-restore-bytes-per-sec", "committedDate": "2020-05-05T11:24:55Z", "type": "commit"}, {"oid": "0e9a28dbb9b07161208205eb76bdbf8442878525", "url": "https://github.com/elastic/elasticsearch/commit/0e9a28dbb9b07161208205eb76bdbf8442878525", "message": "fix checkstyle", "committedDate": "2020-05-05T11:47:02Z", "type": "commit"}]}