{"pr_number": 57627, "pr_title": "Remove deprecated wrapper from scripted_metric", "pr_createdAt": "2020-06-03T21:11:15Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/57627", "timeline": [{"oid": "518ac0c66ccfc69b4c8a4973b35942ba055e8316", "url": "https://github.com/elastic/elasticsearch/commit/518ac0c66ccfc69b4c8a4973b35942ba055e8316", "message": "Remove deprecated wrapped from scripted_metric\n\nThis removes the deprecated `asMultiBucketAggregator` wrapper from\n`scripted_metric`. Unlike most other such removals, this isn't likely to\nsave much memory. But it does make the internals of the aggregator\nslightly less twisted.\n\nRelates to #56487", "committedDate": "2020-06-03T20:59:58Z", "type": "commit"}, {"oid": "22828cc7f0f3de81766bd749adda1cf236a6883d", "url": "https://github.com/elastic/elasticsearch/commit/22828cc7f0f3de81766bd749adda1cf236a6883d", "message": "Merge branch 'master' into scripted_metric_mem", "committedDate": "2020-06-03T21:26:14Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU4MTk3OA==", "url": "https://github.com/elastic/elasticsearch/pull/57627#discussion_r435581978", "bodyText": "haha", "author": "talevy", "createdAt": "2020-06-04T22:14:09Z", "path": "server/src/main/java/org/elasticsearch/search/aggregations/metrics/ScriptedMetricAggregator.java", "diffHunk": "@@ -23,38 +23,66 @@\n import org.apache.lucene.search.Scorable;\n import org.apache.lucene.search.ScoreMode;\n import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lease.Releasables;\n import org.elasticsearch.common.util.CollectionUtils;\n+import org.elasticsearch.common.util.ObjectArray;\n import org.elasticsearch.script.Script;\n import org.elasticsearch.script.ScriptedMetricAggContexts;\n+import org.elasticsearch.script.ScriptedMetricAggContexts.MapScript;\n import org.elasticsearch.search.aggregations.Aggregator;\n import org.elasticsearch.search.aggregations.InternalAggregation;\n import org.elasticsearch.search.aggregations.LeafBucketCollector;\n import org.elasticsearch.search.aggregations.LeafBucketCollectorBase;\n import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.search.lookup.SearchLookup;\n \n import java.io.IOException;\n+import java.util.HashMap;\n import java.util.Map;\n \n class ScriptedMetricAggregator extends MetricsAggregator {\n+    /**\n+     * Estimated cost to maintain a bucket. Since this aggregator uses\n+     * untracked java collections for its state it is going to both be\n+     * much \"heavier\" than a normal metric aggregator and not going to be\n+     * tracked by the circuit breakers properly. This is sad. So we pick a big\n+     * number and estimate that each bucket costs that. It could be wildly\n+     * inaccurate. We're sort of hoping that the real memory breaker saves\n+     * us here. Or that folks just don't use the aggregation.", "originalCommit": "22828cc7f0f3de81766bd749adda1cf236a6883d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU4MjA4NQ==", "url": "https://github.com/elastic/elasticsearch/pull/57627#discussion_r435582085", "bodyText": "what made you choose this number beyond just \"make it large\"?", "author": "talevy", "createdAt": "2020-06-04T22:14:25Z", "path": "server/src/main/java/org/elasticsearch/search/aggregations/metrics/ScriptedMetricAggregator.java", "diffHunk": "@@ -23,38 +23,66 @@\n import org.apache.lucene.search.Scorable;\n import org.apache.lucene.search.ScoreMode;\n import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.lease.Releasables;\n import org.elasticsearch.common.util.CollectionUtils;\n+import org.elasticsearch.common.util.ObjectArray;\n import org.elasticsearch.script.Script;\n import org.elasticsearch.script.ScriptedMetricAggContexts;\n+import org.elasticsearch.script.ScriptedMetricAggContexts.MapScript;\n import org.elasticsearch.search.aggregations.Aggregator;\n import org.elasticsearch.search.aggregations.InternalAggregation;\n import org.elasticsearch.search.aggregations.LeafBucketCollector;\n import org.elasticsearch.search.aggregations.LeafBucketCollectorBase;\n import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.search.lookup.SearchLookup;\n \n import java.io.IOException;\n+import java.util.HashMap;\n import java.util.Map;\n \n class ScriptedMetricAggregator extends MetricsAggregator {\n+    /**\n+     * Estimated cost to maintain a bucket. Since this aggregator uses\n+     * untracked java collections for its state it is going to both be\n+     * much \"heavier\" than a normal metric aggregator and not going to be\n+     * tracked by the circuit breakers properly. This is sad. So we pick a big\n+     * number and estimate that each bucket costs that. It could be wildly\n+     * inaccurate. We're sort of hoping that the real memory breaker saves\n+     * us here. Or that folks just don't use the aggregation.\n+     */\n+    private static final long BUCKET_COST_ESTIMATE = 1024 * 5;", "originalCommit": "22828cc7f0f3de81766bd749adda1cf236a6883d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTk2ODAwNg==", "url": "https://github.com/elastic/elasticsearch/pull/57627#discussion_r435968006", "bodyText": "Drive-by comment: I wonder if it would make sense to expose this as a configurable option for advanced users?  (perhaps in a followup PR)\nReasoning being that we can't figure it out easily, it's already an advanced agg, so a user might actually be able to give us a reasonable estimate.  And if they don't set it, we fall back to Big Number.\nDunno, might be a terrible idea :)", "author": "polyfractal", "createdAt": "2020-06-05T14:41:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU4MjA4NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTk5MDQ4Nw==", "url": "https://github.com/elastic/elasticsearch/pull/57627#discussion_r435990487", "bodyText": "The number is the original default \"weight\" of an aggregator. So it is basically what we used to have. I didn't want to just set it to the default weight because it doesn't really have anything to do with it. Other than it is what we were using.\nMaking it configurable is certainly interesting! I don't folks are going to have a good idea of what to set it to without having done some java hacking though. We try not to leak stuff like that to our users. OTOH scripted_metric is pretty bonkers so if we are going to leak that sort of thing anywhere, here is it.", "author": "nik9000", "createdAt": "2020-06-05T15:17:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU4MjA4NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAxNDgxMg==", "url": "https://github.com/elastic/elasticsearch/pull/57627#discussion_r436014812", "bodyText": "Yeah I don't feel super great about the idea either.  But then again, we're essentially allowing a user to write a custom map-reduce job that runs on ES, so exposing this kind of accounting isn't too crazy in that context.\nThere's probably a case for forcing the user to estimate it too, since I've definitely seen very bad scripts knock over clusters before (maps holding high cardinality IDs, etc).  I think that's probably a bridge too far, alas :)", "author": "polyfractal", "createdAt": "2020-06-05T15:57:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU4MjA4NQ=="}], "type": "inlineReview"}]}