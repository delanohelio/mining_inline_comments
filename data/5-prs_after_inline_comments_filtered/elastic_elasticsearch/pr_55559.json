{"pr_number": 55559, "pr_title": "Optimize date_histograms across daylight savings time", "pr_createdAt": "2020-04-21T22:28:26Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/55559", "timeline": [{"oid": "c230cf89efdd967aa8dc1cd072fab8ac06c303f1", "url": "https://github.com/elastic/elasticsearch/commit/c230cf89efdd967aa8dc1cd072fab8ac06c303f1", "message": "Take that Rounding!", "committedDate": "2020-04-17T21:42:37Z", "type": "commit"}, {"oid": "971b473c59aeb22ba3bf478e421ab2314e9b4aac", "url": "https://github.com/elastic/elasticsearch/commit/971b473c59aeb22ba3bf478e421ab2314e9b4aac", "message": "This time for sure", "committedDate": "2020-04-18T18:13:32Z", "type": "commit"}, {"oid": "41a7699790f37ede26cd9b7c65f8adc8039d3f8e", "url": "https://github.com/elastic/elasticsearch/commit/41a7699790f37ede26cd9b7c65f8adc8039d3f8e", "message": "Fix quarter of year", "committedDate": "2020-04-18T19:00:18Z", "type": "commit"}, {"oid": "308a4589ce86c3bf40c6de2c2e45ceb3dbba02c5", "url": "https://github.com/elastic/elasticsearch/commit/308a4589ce86c3bf40c6de2c2e45ceb3dbba02c5", "message": "Benchmark", "committedDate": "2020-04-18T20:39:19Z", "type": "commit"}, {"oid": "b33d546c83d492a77e12e335f2c6fbb451b2a76e", "url": "https://github.com/elastic/elasticsearch/commit/b33d546c83d492a77e12e335f2c6fbb451b2a76e", "message": "Try", "committedDate": "2020-04-19T15:07:23Z", "type": "commit"}, {"oid": "bd18c2a8deaf51480733b51fb0a641e867fc5543", "url": "https://github.com/elastic/elasticsearch/commit/bd18c2a8deaf51480733b51fb0a641e867fc5543", "message": "WIP", "committedDate": "2020-04-20T17:11:03Z", "type": "commit"}, {"oid": "35c6ef4dd20421d9376187d6d5724be9a0218a81", "url": "https://github.com/elastic/elasticsearch/commit/35c6ef4dd20421d9376187d6d5724be9a0218a81", "message": "Moar", "committedDate": "2020-04-20T18:21:27Z", "type": "commit"}, {"oid": "bb01ea90ede493b1e9a66c7da04870a4000b8409", "url": "https://github.com/elastic/elasticsearch/commit/bb01ea90ede493b1e9a66c7da04870a4000b8409", "message": "All", "committedDate": "2020-04-20T18:38:04Z", "type": "commit"}, {"oid": "acf1971a7c194cd4299fd69d61aabe7b0added56", "url": "https://github.com/elastic/elasticsearch/commit/acf1971a7c194cd4299fd69d61aabe7b0added56", "message": "Check this", "committedDate": "2020-04-20T19:33:30Z", "type": "commit"}, {"oid": "e242a3da04fda35aeba1ac54e6c7894110341dcc", "url": "https://github.com/elastic/elasticsearch/commit/e242a3da04fda35aeba1ac54e6c7894110341dcc", "message": "UTC?", "committedDate": "2020-04-20T20:36:29Z", "type": "commit"}, {"oid": "8ef7fb727a4b42f12611d3ed6ff5225bd780d460", "url": "https://github.com/elastic/elasticsearch/commit/8ef7fb727a4b42f12611d3ed6ff5225bd780d460", "message": "WIP", "committedDate": "2020-04-21T12:59:37Z", "type": "commit"}, {"oid": "d65b447506cd6d32bc034f2c114bc5a3e4e6257f", "url": "https://github.com/elastic/elasticsearch/commit/d65b447506cd6d32bc034f2c114bc5a3e4e6257f", "message": "WIP", "committedDate": "2020-04-21T14:36:34Z", "type": "commit"}, {"oid": "b8eefdab2ebb8237bcf204883ebe6381be6974cd", "url": "https://github.com/elastic/elasticsearch/commit/b8eefdab2ebb8237bcf204883ebe6381be6974cd", "message": "Spotless", "committedDate": "2020-04-21T14:53:29Z", "type": "commit"}, {"oid": "27089f025a3c30ea69b35e3a9bbc997f2c571d11", "url": "https://github.com/elastic/elasticsearch/commit/27089f025a3c30ea69b35e3a9bbc997f2c571d11", "message": "Better!", "committedDate": "2020-04-21T19:35:02Z", "type": "commit"}, {"oid": "0951db5d749769cf0cced6293d36e84050c670d4", "url": "https://github.com/elastic/elasticsearch/commit/0951db5d749769cf0cced6293d36e84050c670d4", "message": "Words", "committedDate": "2020-04-21T20:12:25Z", "type": "commit"}, {"oid": "2a2440445337a9247b67b57d6ebfabcbbdd61a48", "url": "https://github.com/elastic/elasticsearch/commit/2a2440445337a9247b67b57d6ebfabcbbdd61a48", "message": "JMH", "committedDate": "2020-04-21T20:17:22Z", "type": "commit"}, {"oid": "c99ea8973dfc4c19d626555e1e84e3c5f7f03683", "url": "https://github.com/elastic/elasticsearch/commit/c99ea8973dfc4c19d626555e1e84e3c5f7f03683", "message": "JMH2", "committedDate": "2020-04-21T21:47:51Z", "type": "commit"}, {"oid": "cf5c5e9e31ce1e7f1c654174e60e3523fb2cfa22", "url": "https://github.com/elastic/elasticsearch/commit/cf5c5e9e31ce1e7f1c654174e60e3523fb2cfa22", "message": "Words", "committedDate": "2020-04-21T22:26:30Z", "type": "commit"}, {"oid": "6be2d0681aabd102170b78a1a70d5336b7d485e9", "url": "https://github.com/elastic/elasticsearch/commit/6be2d0681aabd102170b78a1a70d5336b7d485e9", "message": "Merge branch 'master' into tz_round", "committedDate": "2020-04-21T22:30:11Z", "type": "commit"}, {"oid": "49a60e5d9311b240e422179621c20d118f6add39", "url": "https://github.com/elastic/elasticsearch/commit/49a60e5d9311b240e422179621c20d118f6add39", "message": "Revert extra", "committedDate": "2020-04-21T22:32:12Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjUzNTU0OQ==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r412535549", "bodyText": "@DaveCTurner this bit is for you!", "author": "nik9000", "createdAt": "2020-04-21T22:30:14Z", "path": "server/src/main/java/org/elasticsearch/common/LocalTimeOffset.java", "diffHunk": "@@ -0,0 +1,661 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.common;\n+\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.ZoneId;\n+import java.time.ZoneOffset;\n+import java.time.zone.ZoneOffsetTransition;\n+import java.time.zone.ZoneOffsetTransitionRule;\n+import java.time.zone.ZoneRules;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Locale;", "originalCommit": "cf5c5e9e31ce1e7f1c654174e60e3523fb2cfa22", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjUzNzEzNw==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r412537137", "bodyText": "@not-napoleon this bit is for you!", "author": "nik9000", "createdAt": "2020-04-21T22:33:38Z", "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregationSupplier.java", "diffHunk": "@@ -19,6 +19,7 @@\n \n package org.elasticsearch.search.aggregations.bucket.histogram;\n \n+import org.apache.lucene.index.IndexReader;", "originalCommit": "6be2d0681aabd102170b78a1a70d5336b7d485e9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjUzNzk1Nw==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r412537957", "bodyText": "Now that I look at the search index to run the agg I index the dates as well as make doc values for them. This makes this field not really useful any more.", "author": "nik9000", "createdAt": "2020-04-21T22:35:36Z", "path": "server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregatorTests.java", "diffHunk": "@@ -50,7 +50,6 @@\n public class DateHistogramAggregatorTests extends AggregatorTestCase {\n \n     private static final String DATE_FIELD = \"date\";\n-    private static final String INSTANT_FIELD = \"instant\";", "originalCommit": "6be2d0681aabd102170b78a1a70d5336b7d485e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzAwNjY0Mg==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r413006642", "bodyText": "Do we still have tests that demonstrate correctness when only using doc values?", "author": "not-napoleon", "createdAt": "2020-04-22T13:57:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjUzNzk1Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzAyOTExNg==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r413029116", "bodyText": "Good call! I think I removed those tests on accident. I'll have a go at adding theme back.", "author": "nik9000", "createdAt": "2020-04-22T14:25:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjUzNzk1Nw=="}], "type": "inlineReview"}, {"oid": "706007e9c48c8a98b06f61b258cfd2eee8701263", "url": "https://github.com/elastic/elasticsearch/commit/706007e9c48c8a98b06f61b258cfd2eee8701263", "message": "Words", "committedDate": "2020-04-21T22:47:59Z", "type": "commit"}, {"oid": "1185b465c7e5c52818349b7bb515b3361ea2dd24", "url": "https://github.com/elastic/elasticsearch/commit/1185b465c7e5c52818349b7bb515b3361ea2dd24", "message": "Unused import", "committedDate": "2020-04-21T22:51:30Z", "type": "commit"}, {"oid": "3a6b46ec88bde6c3f1f2bcbb96d849281e864cd5", "url": "https://github.com/elastic/elasticsearch/commit/3a6b46ec88bde6c3f1f2bcbb96d849281e864cd5", "message": "Explain", "committedDate": "2020-04-21T23:21:35Z", "type": "commit"}, {"oid": "9ccecd72a01ffbae05cc0db601da8105184e9f3e", "url": "https://github.com/elastic/elasticsearch/commit/9ccecd72a01ffbae05cc0db601da8105184e9f3e", "message": "Checkstyle", "committedDate": "2020-04-21T23:28:14Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc1MjIwNA==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r412752204", "bodyText": "nanoseconds don't seem handy for the output and I wonder whether it makes sense to switch to microseconds here? Especially when count is set to 1000000 the score is quite high.", "author": "danielmitterdorfer", "createdAt": "2020-04-22T07:49:06Z", "path": "benchmarks/src/main/java/org/elasticsearch/common/RoundingBenchmark.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.common;\n+\n+import org.elasticsearch.common.time.DateFormatter;\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Fork;\n+import org.openjdk.jmh.annotations.Measurement;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.OutputTimeUnit;\n+import org.openjdk.jmh.annotations.Param;\n+import org.openjdk.jmh.annotations.Scope;\n+import org.openjdk.jmh.annotations.Setup;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.Warmup;\n+\n+import java.time.ZoneId;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Supplier;\n+\n+@Fork(1)\n+@Warmup(iterations = 5)\n+@Measurement(iterations = 3)\n+@BenchmarkMode(Mode.AverageTime)\n+@OutputTimeUnit(TimeUnit.NANOSECONDS)", "originalCommit": "9ccecd72a01ffbae05cc0db601da8105184e9f3e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjk3MzA4MA==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r412973080", "bodyText": "Thanks so much for reviewing so quickly! Some of this stuff I just copied from another benchmark to get started and never thought to play with.\nThe count is interesting - it is nice to be able to see a count of 1, just to know how much overhead I'm adding on to one off rounds. So NANOSECONDS is sort of a better report for those rounds. But I'll play with bumping it!", "author": "nik9000", "createdAt": "2020-04-22T13:17:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc1MjIwNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc1NDE4MQ==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r412754181", "bodyText": "All these numbers seem pretty low? I suggest at least two forks, 10 iterations for warmup and 5 for measurement. Here is an example from a benchmark run that I did where you can see that the score varies quite a bit after warmup:\n# Run progress: 91.41% complete, ETA 00:02:17\n# Fork: 1 of 1\n# Warmup Iteration   1: 14309725.186 ns/op\n# Warmup Iteration   2: 9710448.427 ns/op\n# Warmup Iteration   3: 9633859.654 ns/op\n# Warmup Iteration   4: 9712434.864 ns/op\n# Warmup Iteration   5: 9721697.184 ns/op\nIteration   1: 9706033.942 ns/op4m 34s]\n                 \u00b7gc.alloc.rate:      1.154 MB/sec\n                 \u00b7gc.alloc.rate.norm: 17564.231 B/op\n                 \u00b7gc.count:           \u2248 0 counts\n\nIteration   2: 9776863.388 ns/op4m 36s]\n                 \u00b7gc.alloc.rate:      1.144 MB/sec\n                 \u00b7gc.alloc.rate.norm: 17564.272 B/op\n                 \u00b7gc.count:           \u2248 0 counts\n\nIteration   3: 9703990.712 ns/op\n                 \u00b7gc.alloc.rate:      1.154 MB/sec\n                 \u00b7gc.alloc.rate.norm: 17564.231 B/op\n                 \u00b7gc.count:           \u2248 0 counts", "author": "danielmitterdorfer", "createdAt": "2020-04-22T07:51:47Z", "path": "benchmarks/src/main/java/org/elasticsearch/common/RoundingBenchmark.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.common;\n+\n+import org.elasticsearch.common.time.DateFormatter;\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Fork;\n+import org.openjdk.jmh.annotations.Measurement;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.OutputTimeUnit;\n+import org.openjdk.jmh.annotations.Param;\n+import org.openjdk.jmh.annotations.Scope;\n+import org.openjdk.jmh.annotations.Setup;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.Warmup;\n+\n+import java.time.ZoneId;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Supplier;\n+\n+@Fork(1)\n+@Warmup(iterations = 5)\n+@Measurement(iterations = 3)", "originalCommit": "9ccecd72a01ffbae05cc0db601da8105184e9f3e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjk4MDc1NQ==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r412980755", "bodyText": "I'm happy to pick those numbers up. They do seems to reduce variance a fair bit.", "author": "nik9000", "createdAt": "2020-04-22T13:26:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc1NDE4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc2MDU1NA==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r412760554", "bodyText": "It's safer here to sink it into a blackhole instead to reduce the potential for compiler tricks.", "author": "danielmitterdorfer", "createdAt": "2020-04-22T08:01:01Z", "path": "benchmarks/src/main/java/org/elasticsearch/common/RoundingBenchmark.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.common;\n+\n+import org.elasticsearch.common.time.DateFormatter;\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Fork;\n+import org.openjdk.jmh.annotations.Measurement;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.OutputTimeUnit;\n+import org.openjdk.jmh.annotations.Param;\n+import org.openjdk.jmh.annotations.Scope;\n+import org.openjdk.jmh.annotations.Setup;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.Warmup;\n+\n+import java.time.ZoneId;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Supplier;\n+\n+@Fork(1)\n+@Warmup(iterations = 5)\n+@Measurement(iterations = 3)\n+@BenchmarkMode(Mode.AverageTime)\n+@OutputTimeUnit(TimeUnit.NANOSECONDS)\n+@State(Scope.Benchmark)\n+public class RoundingBenchmark {\n+    private static final DateFormatter FORMATTER = DateFormatter.forPattern(\"date_optional_time\");\n+\n+    @Param({\n+        \"2000-01-01 to 2020-01-01\", // A super long range\n+        \"2000-10-01 to 2000-11-01\", // A whole month which is pretty believable\n+        \"2000-10-29 to 2000-10-30\", // A date right around daylight savings time.\n+        \"2000-06-01 to 2000-06-02\"  // A date fully in one time zone. Should be much faster than above.\n+    })\n+    public String range;\n+\n+    @Param({ \"java time\", \"es\" })\n+    public String rounder;\n+\n+    @Param({ \"UTC\", \"America/New_York\" })\n+    public String zone;\n+\n+    @Param({ \"MONTH_OF_YEAR\", \"HOUR_OF_DAY\" })\n+    public String timeUnit;\n+\n+    @Param({ \"1\", \"1000000\" })\n+    public int count;\n+\n+    private long min;\n+    private long max;\n+    private long[] dates;\n+    private Supplier<Rounding.Prepared> rounderBuilder;\n+\n+    @Setup\n+    public void buildDates() {\n+        String[] r = range.split(\" to \");\n+        min = FORMATTER.parseMillis(r[0]);\n+        max = FORMATTER.parseMillis(r[1]);\n+        dates = new long[count];\n+        long date = min;\n+        long diff = (max - min) / dates.length;\n+        for (int i = 0; i < dates.length; i++) {\n+            if (date >= max) {\n+                throw new IllegalStateException(\"made a bad date [\" + date + \"]\");\n+            }\n+            dates[i] = date;\n+            date += diff;\n+        }\n+        Rounding rounding = Rounding.builder(Rounding.DateTimeUnit.valueOf(timeUnit)).timeZone(ZoneId.of(zone)).build();\n+        switch (rounder) {\n+            case \"java time\":\n+                rounderBuilder = rounding::prepareJavaTime;\n+                break;\n+            case \"es\":\n+                rounderBuilder = () -> rounding.prepare(min, max);\n+                break;\n+            default:\n+                throw new IllegalArgumentException(\"Expectd rounder to be [java time] or [es]\");\n+        }\n+    }\n+\n+    @Benchmark\n+    public long round() {\n+        long sum = 0;\n+        Rounding.Prepared rounder = rounderBuilder.get();\n+        for (int i = 0; i < dates.length; i++) {\n+            sum += rounder.round(dates[i]);", "originalCommit": "9ccecd72a01ffbae05cc0db601da8105184e9f3e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjk4MzI5OA==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r412983298", "bodyText": "I started with that and found that it added pretty significant overhead, smearing out some of differences. When I removed it the differences became more \"sharp\". I think this sort of thing is a safe way to work around the compiler tricks. -prof=perfasm seems to bear that out, but computers are tricky.", "author": "nik9000", "createdAt": "2020-04-22T13:29:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc2MDU1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzAwMTM0MQ==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r413001341", "bodyText": "The thing is that with the current code it might be able to do loop unrolling (but then: I did not have a look at the assembler code yet).", "author": "danielmitterdorfer", "createdAt": "2020-04-22T13:51:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc2MDU1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzAxODg1NQ==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r413018855", "bodyText": "My first instinct is that loop unrolling wouldn't bother me too much. I'm not really trying to measure the iteration, just the round calls. If loop unrolling let it optimize the round in fun ways that might make it less valid. This is called in a fairly tight loop in production too. Not this tight. And not one the JVM would be able to unroll though.....", "author": "nik9000", "createdAt": "2020-04-22T14:12:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc2MDU1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDYzNDEyMA==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r420634120", "bodyText": "I ran the microbenchmarks again once with your implementation and once with a cheaper version of Blackhole (calling a method that is not inlined) and there are cases where the score is vastly different, e.g.:\nsum (your approach):\nBenchmark                                                               (count)                   (range)  (rounder)     (timeUnit)            (zone)  Mode  Cnt            Score            Error   Units\nRoundingBenchmark.round                                               100000000  2000-06-01 to 2000-06-02  java time    HOUR_OF_DAY               UTC  avgt   10   5468296772.000 \u00b1   13822182.335   ns/op\nRoundingBenchmark.round                                               100000000  2000-06-01 to 2000-06-02         es    HOUR_OF_DAY               UTC  avgt   10    949419080.100 \u00b1    2728670.015   ns/op\nRoundingBenchmark.round                                               100000000  2000-06-01 to 2000-06-02  java time    HOUR_OF_DAY  America/New_York  avgt   10  13193144584.600 \u00b1   86152570.014   ns/op\nRoundingBenchmark.round                                               100000000  2000-06-01 to 2000-06-02         es    HOUR_OF_DAY  America/New_York  avgt   10    947821052.350 \u00b1    6119635.225   ns/op\n\ndon't inline:\nBenchmark                                                               (count)                   (range)  (rounder)     (timeUnit)            (zone)  Mode  Cnt            Score            Error   Units\nRoundingBenchmark.round                                               100000000  2000-06-01 to 2000-06-02  java time    HOUR_OF_DAY               UTC  avgt   10   5559418450.700 \u00b1    3268596.659   ns/op\nRoundingBenchmark.round                                               100000000  2000-06-01 to 2000-06-02         es    HOUR_OF_DAY               UTC  avgt   10   1363302403.000 \u00b1   16780559.912   ns/op\nRoundingBenchmark.round                                               100000000  2000-06-01 to 2000-06-02  java time    HOUR_OF_DAY  America/New_York  avgt   10  13554514668.900 \u00b1   25928733.412   ns/op\nRoundingBenchmark.round                                               100000000  2000-06-01 to 2000-06-02         es    HOUR_OF_DAY  America/New_York  avgt   10   1354972403.700 \u00b1   15574272.765   ns/op\n\nThis means that in some cases your microbenchmark implementation shows numbers that are e.g. in the last case in the table above ~ 1.4 times faster than they are if we don't inline which is more likely in production code. We do see a significant speedup compared to the original implementation in both microbenchmark approaches anyway so I think the actual change makes sense. It's just that the change is probably slightly less pronounced in practice than the microbenchmarks indicate.", "author": "danielmitterdorfer", "createdAt": "2020-05-06T08:45:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc2MDU1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDc0ODgyMg==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r420748822", "bodyText": "Blackhole it is then! I'll make the change. I had thought that the synchronization overhead that Blackhole adds was sort of unrealistic. And it might be, but it is more realistic than sum.", "author": "nik9000", "createdAt": "2020-05-06T12:25:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc2MDU1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDc1MDU0Nw==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r420750547", "bodyText": "s/synchronization/volatile/", "author": "nik9000", "createdAt": "2020-05-06T12:28:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc2MDU1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc2MDYyNA==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r412760624", "bodyText": "It's safer here to sink it into a blackhole instead to reduce the potential for compiler tricks.", "author": "danielmitterdorfer", "createdAt": "2020-04-22T08:01:05Z", "path": "benchmarks/src/main/java/org/elasticsearch/common/RoundingBenchmark.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.common;\n+\n+import org.elasticsearch.common.time.DateFormatter;\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Fork;\n+import org.openjdk.jmh.annotations.Measurement;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.OutputTimeUnit;\n+import org.openjdk.jmh.annotations.Param;\n+import org.openjdk.jmh.annotations.Scope;\n+import org.openjdk.jmh.annotations.Setup;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.Warmup;\n+\n+import java.time.ZoneId;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Supplier;\n+\n+@Fork(1)\n+@Warmup(iterations = 5)\n+@Measurement(iterations = 3)\n+@BenchmarkMode(Mode.AverageTime)\n+@OutputTimeUnit(TimeUnit.NANOSECONDS)\n+@State(Scope.Benchmark)\n+public class RoundingBenchmark {\n+    private static final DateFormatter FORMATTER = DateFormatter.forPattern(\"date_optional_time\");\n+\n+    @Param({\n+        \"2000-01-01 to 2020-01-01\", // A super long range\n+        \"2000-10-01 to 2000-11-01\", // A whole month which is pretty believable\n+        \"2000-10-29 to 2000-10-30\", // A date right around daylight savings time.\n+        \"2000-06-01 to 2000-06-02\"  // A date fully in one time zone. Should be much faster than above.\n+    })\n+    public String range;\n+\n+    @Param({ \"java time\", \"es\" })\n+    public String rounder;\n+\n+    @Param({ \"UTC\", \"America/New_York\" })\n+    public String zone;\n+\n+    @Param({ \"MONTH_OF_YEAR\", \"HOUR_OF_DAY\" })\n+    public String timeUnit;\n+\n+    @Param({ \"1\", \"1000000\" })\n+    public int count;\n+\n+    private long min;\n+    private long max;\n+    private long[] dates;\n+    private Supplier<Rounding.Prepared> rounderBuilder;\n+\n+    @Setup\n+    public void buildDates() {\n+        String[] r = range.split(\" to \");\n+        min = FORMATTER.parseMillis(r[0]);\n+        max = FORMATTER.parseMillis(r[1]);\n+        dates = new long[count];\n+        long date = min;\n+        long diff = (max - min) / dates.length;\n+        for (int i = 0; i < dates.length; i++) {\n+            if (date >= max) {\n+                throw new IllegalStateException(\"made a bad date [\" + date + \"]\");\n+            }\n+            dates[i] = date;\n+            date += diff;\n+        }\n+        Rounding rounding = Rounding.builder(Rounding.DateTimeUnit.valueOf(timeUnit)).timeZone(ZoneId.of(zone)).build();\n+        switch (rounder) {\n+            case \"java time\":\n+                rounderBuilder = rounding::prepareJavaTime;\n+                break;\n+            case \"es\":\n+                rounderBuilder = () -> rounding.prepare(min, max);\n+                break;\n+            default:\n+                throw new IllegalArgumentException(\"Expectd rounder to be [java time] or [es]\");\n+        }\n+    }\n+\n+    @Benchmark\n+    public long round() {\n+        long sum = 0;\n+        Rounding.Prepared rounder = rounderBuilder.get();\n+        for (int i = 0; i < dates.length; i++) {\n+            sum += rounder.round(dates[i]);\n+        }\n+        return sum;\n+    }\n+\n+    @Benchmark\n+    public long nextRoundingValue() {\n+        long sum = 0;\n+        Rounding.Prepared rounder = rounderBuilder.get();\n+        for (int i = 0; i < dates.length; i++) {\n+            sum += rounder.nextRoundingValue(dates[i]);", "originalCommit": "9ccecd72a01ffbae05cc0db601da8105184e9f3e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDgzOTIxNg==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r414839216", "bodyText": "I talked with @danielmitterdorfer about this. The blackhole adds quite a bit of overhead for such fast methods. Something like 10%. Which makes it harder to see things make the thing faster. On the other hand, the JVM can totally unroll this loop. And in production it (mostly) can't because these will be coming from Lucene.", "author": "nik9000", "createdAt": "2020-04-24T20:20:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjc2MDYyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg0OTYwOQ==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r412849609", "bodyText": "It's also likely completely invalid; surely we'll have abolished DST at some point in the next 2500 years? \ud83d\ude01\nHow well are we testing the case where we hit this limit?", "author": "DaveCTurner", "createdAt": "2020-04-22T10:06:44Z", "path": "server/src/main/java/org/elasticsearch/common/LocalTimeOffset.java", "diffHunk": "@@ -0,0 +1,679 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.common;\n+\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.ZoneId;\n+import java.time.zone.ZoneOffsetTransition;\n+import java.time.zone.ZoneOffsetTransitionRule;\n+import java.time.zone.ZoneRules;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Locale;\n+\n+/**\n+ * Converts utc into local time and back again.\n+ * <p>\n+ * \"Local time\" is defined by some time zone, specifically and {@link ZoneId}.\n+ * At any point in time a particular time zone is at some offset from from\n+ * utc. So converting from utc is as simple as adding the offset.\n+ * <p>\n+ * Getting from local time back to utc is harder. Most local times happen once.\n+ * But some local times happen twice. And some don't happen at all. Take, for\n+ * example, the time in my house. Most days I don't touch my clocks and I'm a\n+ * constant offset from UTC. But once in the fall at 2am I roll my clock back.\n+ * So at 5am utc my clocks say 1am. Then at 6am utc my clocks say 1am AGAIN.\n+ * I do similarly terrifying things again in the spring when I skip my clocks\n+ * straight from 1:59am to 3am.\n+ * <p>\n+ * So there are three methods to convert from local time back to utc,\n+ * {@link #localToUtc(long, Strategy)}, {@link #localToSensibleUtc(long)} and\n+ * {@link #localToUtcInThisOffset(long)}. They are all unique and frightening.\n+ */\n+public abstract class LocalTimeOffset {\n+    /**\n+     * Lookup offsets for a provided zone. This <strong>can</strong> fail if\n+     * there are many transitions and the provided lookup would be very large.\n+     *\n+     * @return a {@linkplain Lookup} or {@code null} if none could be built \n+     */\n+    public static Lookup lookup(ZoneId zone, long minUtcMillis, long maxUtcMillis) {\n+        if (minUtcMillis > maxUtcMillis) {\n+            throw new IllegalArgumentException(\"[\" + minUtcMillis + \"] must be <= [\" + maxUtcMillis + \"]\");\n+        }\n+        ZoneRules rules = zone.getRules();\n+        {\n+            LocalTimeOffset fixed = checkForFixedZone(zone, rules);\n+            if (fixed != null) {\n+                return new FixedLookup(zone, fixed);\n+            }\n+        }\n+        List<ZoneOffsetTransition> transitions = collectTransitions(zone, rules, minUtcMillis, maxUtcMillis);\n+        if (transitions == null) {\n+            // The range is too large for us to pre-build all the offsets\n+            return null;\n+        }\n+        if (transitions.size() < 3) {\n+            /*\n+             * Its actually quite common that there are *very* few transitions.\n+             * This case where there are only two transitions covers an entire\n+             * year of data! In any case, it is slightly faster to do the\n+             * \"simpler\" thing and compare the start times instead of perform\n+             * a binary search when there are so few offsets to look at.\n+             */\n+            return new LinkedListLookup(zone, minUtcMillis, maxUtcMillis, transitions);\n+        }\n+        return new TransitionArrayLookup(zone, minUtcMillis, maxUtcMillis, transitions);\n+    }\n+\n+    /**\n+     * Lookup offsets without any known min or max time. This will generally\n+     * fail if the provided zone isn't fixed.\n+     *\n+     * @return a lookup function of {@code null} if none could be built \n+     */\n+    public static LocalTimeOffset lookupFixedOffset(ZoneId zone) {\n+        return checkForFixedZone(zone, zone.getRules());\n+    }\n+\n+    private final long millis;\n+\n+    private LocalTimeOffset(long millis) {\n+        this.millis = millis;\n+    }\n+\n+    /**\n+     * Convert a time in utc into a the local time at this offset.\n+     */\n+    public final long utcToLocalTime(long utcMillis) {\n+        return utcMillis + millis;\n+    }\n+\n+    /**\n+     * Convert a time in local millis to utc millis using <strong>this</strong> offset.\n+     * <p>\n+     * <strong>Important:</strong> Callers will rarely want to <strong>force</strong>\n+     * using this offset and are instead instead interested in picking an appropriate\n+     * offset for some local time that they have rounded down. In that case use\n+     * {@link #localToSensibleUtc(long)} or {@link #localToUtc(long, Strategy)}.\n+     */\n+    public final long localToUtcInThisOffset(long localMillis) {\n+        return localMillis - millis;\n+    }\n+\n+    /**\n+     * Convert a local time that occurs during this offset or a previous\n+     * offset to utc, providing a strategy for how to resolve \"funny\" cases.\n+     * You can use this if you've converted from utc to local, rounded down,\n+     * and then want to convert back to utc and you need fine control over\n+     * how to handle the \"funny\" edges.\n+     * <p>\n+     * This will not help you if you must convert a local time that you've\n+     * rounded <strong>up</strong>. For that you are on your own. May God\n+     * have mercy on your soul.\n+     */\n+    public abstract long localToUtc(long localMillis, Strategy strat);\n+    public interface Strategy {\n+        /**\n+         * Handle a local time that never actually happened because a \"gap\"\n+         * jumped over it. This happens in many time zones when folks wind\n+         * their clocks forwards in the spring.\n+         *\n+         * @return the time in utc representing the local time\n+         */\n+        long inGap(long localMillis, Gap gap);\n+        /**\n+         * Handle a local time that happened before the start of a gap.\n+         *\n+         * @return the time in utc representing the local time\n+         */\n+        long beforeGap(long localMillis, Gap gap);\n+        /**\n+         * Handle a local time that happened twice because an \"overlap\"\n+         * jumped behind it. This happens in many time zones when folks wind\n+         * their clocks back in the fall.\n+         *\n+         * @return the time in utc representing the local time\n+         */\n+        long inOverlap(long localMillis, Overlap overlap);\n+        /**\n+         * Handle a local time that happened before the start of an overlap.\n+         *\n+         * @return the time in utc representing the local time\n+         */\n+        long beforeOverlap(long localMillis, Overlap overlap);\n+    }\n+\n+    /**\n+     * Map a local time that occurs during this offset or a previous offset\n+     * to a utc time . You can use this if you've converted from utc to local,\n+     * rounded down, and then want to convert back to utc but you don't really\n+     * care about how to resolve \"funny\" edge cases. This resolves them\n+     * <em>fairly</em> sanely.\n+     * <p>\n+     * If a local time occurred twice then returns the time in utc that the\n+     * clocks first showed that time. If a local time never occurred then\n+     * returns the utc time where the clock jumped over that time. If a local\n+     * time occurs before a gap or overlap then uses the offset to convert it.\n+     * This is all sensible but it may not be right for you.\n+     */\n+    public final long localToSensibleUtc(long localMillis) {\n+        return localToUtc(localMillis, SENSIBLE_STRAT);\n+    }\n+    private static final Strategy SENSIBLE_STRAT = new Strategy() {\n+        @Override\n+        public long inGap(long localMillis, Gap gap) {\n+            return gap.startUtcMillis();\n+        }\n+\n+        public long beforeGap(long localMillis, Gap gap) {\n+            return gap.previous().localToUtc(localMillis, SENSIBLE_STRAT);\n+        };\n+\n+        @Override\n+        public long inOverlap(long localMillis, Overlap overlap) {\n+            return overlap.previous().localToUtc(localMillis, SENSIBLE_STRAT);\n+        }\n+\n+        public long beforeOverlap(long localMillis, Overlap overlap) {\n+            return overlap.previous().localToUtc(localMillis, SENSIBLE_STRAT);\n+        };\n+    };\n+\n+    /**\n+     * Does this offset contain the provided time?\n+     */\n+    protected abstract boolean containsUtcMillis(long utcMillis);\n+\n+    /**\n+     * Find the offset containing the provided time, first checking this\n+     * offset, then its previous offset, the than one's previous offset, etc.\n+     */\n+    protected abstract LocalTimeOffset offsetContaining(long utcMillis);\n+\n+    @Override\n+    public String toString() {\n+        return toString(millis);\n+    }\n+    protected abstract String toString(long millis);\n+\n+    /**\n+     * How to get instances of {@link LocalTimeOffset}.\n+     */\n+    public abstract static class Lookup {\n+        /**\n+         * Lookup the offset at the provided millis in utc.\n+         */\n+        public abstract LocalTimeOffset lookup(long utcMillis);\n+\n+        /**\n+         * If the offset for a range is constant then return it, otherwise\n+         * return {@code null}.\n+         */\n+        public abstract LocalTimeOffset fixedInRange(long minUtcMillis, long maxUtcMillis);\n+\n+        /**\n+         * The number of offsets in the lookup. Package private for testing.\n+         */\n+        abstract int size();\n+    }\n+\n+    private static class NoPrevious extends LocalTimeOffset {\n+        NoPrevious(long millis) {\n+            super(millis);\n+        }\n+\n+        @Override\n+        public long localToUtc(long localMillis, Strategy strat) {\n+            return localToUtcInThisOffset(localMillis);\n+        }\n+\n+        @Override\n+        protected boolean containsUtcMillis(long utcMillis) {\n+            return true;\n+        }\n+\n+        @Override\n+        protected LocalTimeOffset offsetContaining(long utcMillis) {\n+            /*\n+             * Since there isn't a previous offset this offset *must* contain\n+             * the provided time.\n+             */\n+            return this;\n+        }\n+\n+        @Override\n+        protected String toString(long millis) {\n+            return Long.toString(millis);\n+        }\n+    }\n+\n+    public abstract static class Transition extends LocalTimeOffset {\n+        private final LocalTimeOffset previous;\n+        private final long startUtcMillis;\n+\n+        private Transition(long millis, LocalTimeOffset previous, long startUtcMillis) {\n+            super(millis);\n+            this.previous = previous;\n+            this.startUtcMillis = startUtcMillis;\n+        }\n+\n+        /**\n+         * The offset before the this one.\n+         */\n+        public LocalTimeOffset previous() {\n+            return previous;\n+        }\n+\n+        @Override\n+        protected final boolean containsUtcMillis(long utcMillis) {\n+            return utcMillis >= startUtcMillis;\n+        }\n+\n+        @Override\n+        protected final LocalTimeOffset offsetContaining(long utcMillis) {\n+            if (containsUtcMillis(utcMillis)) {\n+                return this;\n+            }\n+            return previous.offsetContaining(utcMillis);\n+        }\n+\n+        /**\n+         * The time that this offset started in milliseconds since epoch.\n+         */\n+        public long startUtcMillis() {\n+            return startUtcMillis;\n+        }\n+    }\n+\n+    public static class Gap extends Transition {\n+        private final long firstMissingLocalTime;\n+        private final long firstLocalTimeAfterGap;\n+\n+        private Gap(long millis, LocalTimeOffset previous, long startUtcMillis, long firstMissingLocalTime, long firstLocalTimeAfterGap) {\n+            super(millis, previous, startUtcMillis);\n+            this.firstMissingLocalTime = firstMissingLocalTime;\n+            this.firstLocalTimeAfterGap = firstLocalTimeAfterGap;\n+            assert firstMissingLocalTime < firstLocalTimeAfterGap;\n+        }\n+\n+        @Override\n+        public long localToUtc(long localMillis, Strategy strat) {\n+            if (localMillis >= firstLocalTimeAfterGap) {\n+                return localToUtcInThisOffset(localMillis);\n+            }\n+            if (localMillis >= firstMissingLocalTime) {\n+                return strat.inGap(localMillis, this);\n+            }\n+            return strat.beforeGap(localMillis, this);\n+        }\n+\n+        /**\n+         * The first time that is missing from the local time because of this gap.\n+         */\n+        public long firstMissingLocalTime() {\n+            return firstMissingLocalTime;\n+        }\n+\n+        @Override\n+        protected String toString(long millis) {\n+            return \"Gap of \" + millis + \"@\" + Instant.ofEpochMilli(startUtcMillis());\n+        }\n+    }\n+\n+    public static class Overlap extends Transition {\n+        private final long firstOverlappingLocalTime;\n+        private final long firstNonOverlappingLocalTime;\n+\n+        private Overlap(long millis, LocalTimeOffset previous, long startUtcMillis,\n+                long firstOverlappingLocalTime, long firstNonOverlappingLocalTime) {\n+            super(millis, previous, startUtcMillis);\n+            this.firstOverlappingLocalTime = firstOverlappingLocalTime;\n+            this.firstNonOverlappingLocalTime = firstNonOverlappingLocalTime;\n+            assert firstOverlappingLocalTime < firstNonOverlappingLocalTime;\n+        }\n+\n+        @Override\n+        public long localToUtc(long localMillis, Strategy strat) {\n+            if (localMillis >= firstNonOverlappingLocalTime) {\n+                return localToUtcInThisOffset(localMillis);\n+            }\n+            if (localMillis >= firstOverlappingLocalTime) {\n+                return strat.inOverlap(localMillis, this);\n+            }\n+            return strat.beforeOverlap(localMillis, this);\n+        }\n+\n+        /**\n+         * The first local time after the overlap stops.\n+         */\n+        public long firstNonOverlappingLocalTime() {\n+            return firstNonOverlappingLocalTime;\n+        }\n+\n+        /**\n+         * The first local time to be appear twice.\n+         */\n+        public long firstOverlappingLocalTime() {\n+            return firstOverlappingLocalTime;\n+        }\n+\n+        @Override\n+        protected String toString(long millis) {\n+            return \"Overlap of \" + millis + \"@\" + Instant.ofEpochMilli(startUtcMillis());\n+        }\n+    }\n+\n+    private static class FixedLookup extends Lookup {\n+        private final ZoneId zone;\n+        private final LocalTimeOffset fixed;\n+\n+        private FixedLookup(ZoneId zone, LocalTimeOffset fixed) {\n+            this.zone = zone;\n+            this.fixed = fixed;\n+        }\n+\n+        @Override\n+        public LocalTimeOffset lookup(long utcMillis) {\n+            return fixed;\n+        }\n+\n+        @Override\n+        public LocalTimeOffset fixedInRange(long minUtcMillis, long maxUtcMillis) {\n+            return fixed;\n+        }\n+\n+        @Override\n+        int size() {\n+            return 1;\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return String.format(Locale.ROOT, \"FixedLookup[for %s at %s]\", zone, fixed);\n+        }\n+    }\n+\n+    /**\n+     * Looks up transitions by checking whether the date is after the start\n+     * of each transition. Simple so fast for small numbers of transitions.\n+     */\n+    private static class LinkedListLookup extends AbstractManyTransitionsLookup {\n+        private final LocalTimeOffset lastOffset;\n+        private final int size;\n+\n+        LinkedListLookup(ZoneId zone, long minUtcMillis, long maxUtcMillis, List<ZoneOffsetTransition> transitions) {\n+            super(zone, minUtcMillis, maxUtcMillis);\n+            int size = 1;\n+            LocalTimeOffset last = buildNoPrevious(transitions.get(0));\n+            for (ZoneOffsetTransition t : transitions) {\n+                last = buildTransition(t, last);\n+                size++;\n+            }\n+            this.lastOffset = last;\n+            this.size = size;\n+        }\n+\n+        @Override\n+        public LocalTimeOffset innerLookup(long utcMillis) {\n+            return lastOffset.offsetContaining(utcMillis);\n+        }\n+\n+        @Override\n+        int size() {\n+            return size;\n+        }\n+    }\n+\n+    /**\n+     * Builds an array that can be {@link Arrays#binarySearch(long[], long)}ed\n+     * for the daylight savings time transitions.\n+     */\n+    private static class TransitionArrayLookup extends AbstractManyTransitionsLookup {\n+        private final LocalTimeOffset[] offsets;\n+        private final long[] transitionOutUtcMillis;\n+\n+        private TransitionArrayLookup(ZoneId zone, long minUtcMillis, long maxUtcMillis, List<ZoneOffsetTransition> transitions) {\n+            super(zone, minUtcMillis, maxUtcMillis);\n+            this.offsets = new LocalTimeOffset[transitions.size() + 1];\n+            this.transitionOutUtcMillis = new long[transitions.size()];\n+            this.offsets[0] = buildNoPrevious(transitions.get(0));\n+            int i = 0;\n+            for (ZoneOffsetTransition t : transitions) {\n+                Transition transition = buildTransition(t, this.offsets[i]);\n+                transitionOutUtcMillis[i] = transition.startUtcMillis();\n+                i++;\n+                this.offsets[i] = transition;\n+            }\n+        }\n+\n+        @Override\n+        protected LocalTimeOffset innerLookup(long utcMillis) {\n+            int index = Arrays.binarySearch(transitionOutUtcMillis, utcMillis);\n+            if (index < 0) {\n+                /*\n+                 * We're mostly not going to find the exact offset. Instead we'll\n+                 * end up at the \"insertion point\" for the utcMillis. We have no\n+                 * plans to insert utcMillis in the array, but the offset that\n+                 * contains utcMillis happens to be \"insertion point\" - 1.\n+                 */\n+                index = -index - 1;\n+            } else {\n+                index++;\n+            }\n+            assert index < offsets.length : \"binarySearch did something weird\";\n+            return offsets[index];\n+        }\n+\n+        @Override\n+        int size() {\n+            return offsets.length;\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return String.format(Locale.ROOT, \"TransitionArrayLookup[for %s between %s and %s]\",\n+                    zone, Instant.ofEpochMilli(minUtcMillis), Instant.ofEpochMilli(maxUtcMillis));\n+        }\n+    }\n+\n+    private abstract static class AbstractManyTransitionsLookup extends Lookup {\n+        protected final ZoneId zone;\n+        protected final long minUtcMillis;\n+        protected final long maxUtcMillis;\n+\n+        AbstractManyTransitionsLookup(ZoneId zone, long minUtcMillis, long maxUtcMillis) {\n+            this.zone = zone;\n+            this.minUtcMillis = minUtcMillis;\n+            this.maxUtcMillis = maxUtcMillis;\n+        }\n+\n+        @Override\n+        public final LocalTimeOffset lookup(long utcMillis) {\n+            assert utcMillis >= minUtcMillis;\n+            assert utcMillis <= maxUtcMillis;\n+            return innerLookup(utcMillis);\n+        }\n+\n+        protected abstract LocalTimeOffset innerLookup(long utcMillis);\n+\n+        @Override\n+        public final LocalTimeOffset fixedInRange(long minUtcMillis, long maxUtcMillis) {\n+            LocalTimeOffset offset = lookup(maxUtcMillis);\n+            return offset.containsUtcMillis(minUtcMillis) ? offset : null;\n+        }\n+\n+        protected static NoPrevious buildNoPrevious(ZoneOffsetTransition transition) {\n+            return new NoPrevious(transition.getOffsetBefore().getTotalSeconds() * 1000);\n+        }\n+\n+        protected static Transition buildTransition(ZoneOffsetTransition transition, LocalTimeOffset previous) {\n+            long utcStart = transition.toEpochSecond() * 1000;\n+            long offsetBeforeMillis = transition.getOffsetBefore().getTotalSeconds() * 1000;\n+            long offsetAfterMillis = transition.getOffsetAfter().getTotalSeconds() * 1000;\n+            if (transition.isGap()) {\n+                long firstMissingLocalTime = utcStart + offsetBeforeMillis;\n+                long firstLocalTimeAfterGap = utcStart + offsetAfterMillis;\n+                return new Gap(offsetAfterMillis, previous, utcStart, firstMissingLocalTime, firstLocalTimeAfterGap);\n+            }\n+            long firstOverlappingLocalTime = utcStart + offsetAfterMillis;\n+            long firstNonOverlappingLocalTime = utcStart + offsetBeforeMillis;\n+            return new Overlap(offsetAfterMillis, previous, utcStart, firstOverlappingLocalTime, firstNonOverlappingLocalTime);\n+        }\n+    }\n+\n+    private static LocalTimeOffset checkForFixedZone(ZoneId zone, ZoneRules rules) {\n+        if (false == rules.isFixedOffset()) {\n+            return null;\n+        }\n+        LocalTimeOffset fixedTransition = new NoPrevious(rules.getOffset(Instant.EPOCH).getTotalSeconds() * 1000);\n+        return fixedTransition;\n+    }\n+\n+    /**\n+     * The maximum number of {@link ZoneOffsetTransition} to collect before\n+     * giving up because the date range will be \"too big\". I picked this number\n+     * fairly arbitrarily with the following goals:\n+     * <ol>\n+     * <li>Don't let {@code lookup(Long.MIN_VALUE, Long.MAX_VALUE)} consume all\n+     *     the memory in the JVM.\n+     * <li>It should be much larger than the number of offsets I'm bound to\n+     *     collect.\n+     * </ol>\n+     * {@code 5_000} collects about 2_500 years worth offsets which feels like\n+     * quite a few!", "originalCommit": "9ccecd72a01ffbae05cc0db601da8105184e9f3e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzAyMjM2Nw==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r413022367", "bodyText": "It's also likely completely invalid; surely we'll have abolished DST at some point in the next 2500 years? grin\n\nGosh I hope so!\n\nHow well are we testing the case where we hit this limit?\n\nWe test the simple case of not having a lookup and it is simple. We test the more complex side - what we do when we don't have a lookup - in a way that isn't super satisfying now that I think about it. We build something with a limit a useful lookup and then build a second version forcing the java.time implementation and \"duel\" them. I do think it'd be worth preparing a couple of roundings with stupidly large ranges and checking a few things about them. At this point I'd be ok with spot checking a few roundings and smashing a bunch of random dates at it to make sure it doesn't crash.", "author": "nik9000", "createdAt": "2020-04-22T14:16:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg0OTYwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzE5MDcyNQ==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r413190725", "bodyText": "I pushed some test cases with explicit far future dates.", "author": "nik9000", "createdAt": "2020-04-22T17:48:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg0OTYwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg1Mzg0Nw==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r412853847", "bodyText": "It'd be cute to use TimeValue.timeValueDays(7).millis() instead of the comment, and similarly below.", "author": "DaveCTurner", "createdAt": "2020-04-22T10:13:00Z", "path": "server/src/main/java/org/elasticsearch/common/Rounding.java", "diffHunk": "@@ -46,58 +48,94 @@\n import java.util.Objects;\n \n /**\n- * A strategy for rounding date/time based values.\n- *\n+ * A strategy for rounding milliseconds since epoch.\n+ * <p>\n  * There are two implementations for rounding.\n- * The first one requires a date time unit and rounds to the supplied date time unit (i.e. quarter of year, day of month)\n- * The second one allows you to specify an interval to round to\n+ * The first one requires a date time unit and rounds to the supplied date time unit (i.e. quarter of year, day of month).\n+ * The second one allows you to specify an interval to round to.\n+ * <p>\n+ * See <a href=\"https://davecturner.github.io/2019/04/14/timezone-rounding.html\">this</a>\n+ * blog for some background reading. Its super interesting and the links are\n+ * a comedy gold mine. If you like time zones. Or hate them.\n  */\n public abstract class Rounding implements Writeable {\n-\n     public enum DateTimeUnit {\n         WEEK_OF_WEEKYEAR((byte) 1, IsoFields.WEEK_OF_WEEK_BASED_YEAR) {\n             long roundFloor(long utcMillis) {\n                 return DateUtils.roundWeekOfWeekYear(utcMillis);\n             }\n+\n+            @Override\n+            long extraLocalOffsetLookup() {\n+                return 604800000L; // 7 days worth of a milliseconds ", "originalCommit": "9ccecd72a01ffbae05cc0db601da8105184e9f3e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzAyMjQ3OQ==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r413022479", "bodyText": "\ud83d\udc4d", "author": "nik9000", "createdAt": "2020-04-22T14:16:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg1Mzg0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg2MjE4Nw==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r412862187", "bodyText": "\"sensible\" feels like the wrong word for timezone code. Suggest inlining this, it's only called once, and moving SENSIBLE_STRAT to a field of ToMidnightRounding, maybe renaming to MIDNIGHT_STRATEGY or similar.", "author": "DaveCTurner", "createdAt": "2020-04-22T10:26:10Z", "path": "server/src/main/java/org/elasticsearch/common/LocalTimeOffset.java", "diffHunk": "@@ -0,0 +1,679 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.common;\n+\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.ZoneId;\n+import java.time.zone.ZoneOffsetTransition;\n+import java.time.zone.ZoneOffsetTransitionRule;\n+import java.time.zone.ZoneRules;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Locale;\n+\n+/**\n+ * Converts utc into local time and back again.\n+ * <p>\n+ * \"Local time\" is defined by some time zone, specifically and {@link ZoneId}.\n+ * At any point in time a particular time zone is at some offset from from\n+ * utc. So converting from utc is as simple as adding the offset.\n+ * <p>\n+ * Getting from local time back to utc is harder. Most local times happen once.\n+ * But some local times happen twice. And some don't happen at all. Take, for\n+ * example, the time in my house. Most days I don't touch my clocks and I'm a\n+ * constant offset from UTC. But once in the fall at 2am I roll my clock back.\n+ * So at 5am utc my clocks say 1am. Then at 6am utc my clocks say 1am AGAIN.\n+ * I do similarly terrifying things again in the spring when I skip my clocks\n+ * straight from 1:59am to 3am.\n+ * <p>\n+ * So there are three methods to convert from local time back to utc,\n+ * {@link #localToUtc(long, Strategy)}, {@link #localToSensibleUtc(long)} and\n+ * {@link #localToUtcInThisOffset(long)}. They are all unique and frightening.\n+ */\n+public abstract class LocalTimeOffset {\n+    /**\n+     * Lookup offsets for a provided zone. This <strong>can</strong> fail if\n+     * there are many transitions and the provided lookup would be very large.\n+     *\n+     * @return a {@linkplain Lookup} or {@code null} if none could be built \n+     */\n+    public static Lookup lookup(ZoneId zone, long minUtcMillis, long maxUtcMillis) {\n+        if (minUtcMillis > maxUtcMillis) {\n+            throw new IllegalArgumentException(\"[\" + minUtcMillis + \"] must be <= [\" + maxUtcMillis + \"]\");\n+        }\n+        ZoneRules rules = zone.getRules();\n+        {\n+            LocalTimeOffset fixed = checkForFixedZone(zone, rules);\n+            if (fixed != null) {\n+                return new FixedLookup(zone, fixed);\n+            }\n+        }\n+        List<ZoneOffsetTransition> transitions = collectTransitions(zone, rules, minUtcMillis, maxUtcMillis);\n+        if (transitions == null) {\n+            // The range is too large for us to pre-build all the offsets\n+            return null;\n+        }\n+        if (transitions.size() < 3) {\n+            /*\n+             * Its actually quite common that there are *very* few transitions.\n+             * This case where there are only two transitions covers an entire\n+             * year of data! In any case, it is slightly faster to do the\n+             * \"simpler\" thing and compare the start times instead of perform\n+             * a binary search when there are so few offsets to look at.\n+             */\n+            return new LinkedListLookup(zone, minUtcMillis, maxUtcMillis, transitions);\n+        }\n+        return new TransitionArrayLookup(zone, minUtcMillis, maxUtcMillis, transitions);\n+    }\n+\n+    /**\n+     * Lookup offsets without any known min or max time. This will generally\n+     * fail if the provided zone isn't fixed.\n+     *\n+     * @return a lookup function of {@code null} if none could be built \n+     */\n+    public static LocalTimeOffset lookupFixedOffset(ZoneId zone) {\n+        return checkForFixedZone(zone, zone.getRules());\n+    }\n+\n+    private final long millis;\n+\n+    private LocalTimeOffset(long millis) {\n+        this.millis = millis;\n+    }\n+\n+    /**\n+     * Convert a time in utc into a the local time at this offset.\n+     */\n+    public final long utcToLocalTime(long utcMillis) {\n+        return utcMillis + millis;\n+    }\n+\n+    /**\n+     * Convert a time in local millis to utc millis using <strong>this</strong> offset.\n+     * <p>\n+     * <strong>Important:</strong> Callers will rarely want to <strong>force</strong>\n+     * using this offset and are instead instead interested in picking an appropriate\n+     * offset for some local time that they have rounded down. In that case use\n+     * {@link #localToSensibleUtc(long)} or {@link #localToUtc(long, Strategy)}.\n+     */\n+    public final long localToUtcInThisOffset(long localMillis) {\n+        return localMillis - millis;\n+    }\n+\n+    /**\n+     * Convert a local time that occurs during this offset or a previous\n+     * offset to utc, providing a strategy for how to resolve \"funny\" cases.\n+     * You can use this if you've converted from utc to local, rounded down,\n+     * and then want to convert back to utc and you need fine control over\n+     * how to handle the \"funny\" edges.\n+     * <p>\n+     * This will not help you if you must convert a local time that you've\n+     * rounded <strong>up</strong>. For that you are on your own. May God\n+     * have mercy on your soul.\n+     */\n+    public abstract long localToUtc(long localMillis, Strategy strat);\n+    public interface Strategy {\n+        /**\n+         * Handle a local time that never actually happened because a \"gap\"\n+         * jumped over it. This happens in many time zones when folks wind\n+         * their clocks forwards in the spring.\n+         *\n+         * @return the time in utc representing the local time\n+         */\n+        long inGap(long localMillis, Gap gap);\n+        /**\n+         * Handle a local time that happened before the start of a gap.\n+         *\n+         * @return the time in utc representing the local time\n+         */\n+        long beforeGap(long localMillis, Gap gap);\n+        /**\n+         * Handle a local time that happened twice because an \"overlap\"\n+         * jumped behind it. This happens in many time zones when folks wind\n+         * their clocks back in the fall.\n+         *\n+         * @return the time in utc representing the local time\n+         */\n+        long inOverlap(long localMillis, Overlap overlap);\n+        /**\n+         * Handle a local time that happened before the start of an overlap.\n+         *\n+         * @return the time in utc representing the local time\n+         */\n+        long beforeOverlap(long localMillis, Overlap overlap);\n+    }\n+\n+    /**\n+     * Map a local time that occurs during this offset or a previous offset\n+     * to a utc time . You can use this if you've converted from utc to local,\n+     * rounded down, and then want to convert back to utc but you don't really\n+     * care about how to resolve \"funny\" edge cases. This resolves them\n+     * <em>fairly</em> sanely.\n+     * <p>\n+     * If a local time occurred twice then returns the time in utc that the\n+     * clocks first showed that time. If a local time never occurred then\n+     * returns the utc time where the clock jumped over that time. If a local\n+     * time occurs before a gap or overlap then uses the offset to convert it.\n+     * This is all sensible but it may not be right for you.\n+     */\n+    public final long localToSensibleUtc(long localMillis) {", "originalCommit": "9ccecd72a01ffbae05cc0db601da8105184e9f3e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzAyNjgxNw==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r413026817", "bodyText": "I liked having it on LocalOffset so I could test it without going through everything in Rounding and I think it'll take me a day or so to come around to removing it. Let me think on it!\nIf I don't end up moving it MIDNIGHT doesn't feel like the right name for it because it produces values that make some sense outside of the context of a local midnight. But, yeah, it probably does make sense to move it. I just have to admit that to myself.", "author": "nik9000", "createdAt": "2020-04-22T14:22:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg2MjE4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzE5MDQ4OQ==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r413190489", "bodyText": "I've inlined the method into the rounding.", "author": "nik9000", "createdAt": "2020-04-22T17:48:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg2MjE4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg2NjAwNw==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r412866007", "bodyText": "Do you need to special-case this here? We handle the more general case that the zone is fixed in the given range in the caller.", "author": "DaveCTurner", "createdAt": "2020-04-22T10:32:06Z", "path": "server/src/main/java/org/elasticsearch/common/LocalTimeOffset.java", "diffHunk": "@@ -0,0 +1,679 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.common;\n+\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.ZoneId;\n+import java.time.zone.ZoneOffsetTransition;\n+import java.time.zone.ZoneOffsetTransitionRule;\n+import java.time.zone.ZoneRules;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Locale;\n+\n+/**\n+ * Converts utc into local time and back again.\n+ * <p>\n+ * \"Local time\" is defined by some time zone, specifically and {@link ZoneId}.\n+ * At any point in time a particular time zone is at some offset from from\n+ * utc. So converting from utc is as simple as adding the offset.\n+ * <p>\n+ * Getting from local time back to utc is harder. Most local times happen once.\n+ * But some local times happen twice. And some don't happen at all. Take, for\n+ * example, the time in my house. Most days I don't touch my clocks and I'm a\n+ * constant offset from UTC. But once in the fall at 2am I roll my clock back.\n+ * So at 5am utc my clocks say 1am. Then at 6am utc my clocks say 1am AGAIN.\n+ * I do similarly terrifying things again in the spring when I skip my clocks\n+ * straight from 1:59am to 3am.\n+ * <p>\n+ * So there are three methods to convert from local time back to utc,\n+ * {@link #localToUtc(long, Strategy)}, {@link #localToSensibleUtc(long)} and\n+ * {@link #localToUtcInThisOffset(long)}. They are all unique and frightening.\n+ */\n+public abstract class LocalTimeOffset {\n+    /**\n+     * Lookup offsets for a provided zone. This <strong>can</strong> fail if\n+     * there are many transitions and the provided lookup would be very large.\n+     *\n+     * @return a {@linkplain Lookup} or {@code null} if none could be built \n+     */\n+    public static Lookup lookup(ZoneId zone, long minUtcMillis, long maxUtcMillis) {\n+        if (minUtcMillis > maxUtcMillis) {\n+            throw new IllegalArgumentException(\"[\" + minUtcMillis + \"] must be <= [\" + maxUtcMillis + \"]\");\n+        }\n+        ZoneRules rules = zone.getRules();\n+        {\n+            LocalTimeOffset fixed = checkForFixedZone(zone, rules);\n+            if (fixed != null) {\n+                return new FixedLookup(zone, fixed);", "originalCommit": "9ccecd72a01ffbae05cc0db601da8105184e9f3e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzAyNzM3Mw==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r413027373", "bodyText": "I'm not sure! I added that when I first wrote the class because it felt nice to get the simple stuff out of the way but I'll see!", "author": "nik9000", "createdAt": "2020-04-22T14:23:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg2NjAwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzA4ODg2NA==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r413088864", "bodyText": "Thinking about caching - if we end up applying caching I'd want to apply it below this. In other words, the special case is useful for caching because we don't want to try an cache fixed zones.", "author": "nik9000", "createdAt": "2020-04-22T15:34:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg2NjAwNw=="}], "type": "inlineReview"}, {"oid": "587605da6d74b8b776dd83f8d988399ff88dede2", "url": "https://github.com/elastic/elasticsearch/commit/587605da6d74b8b776dd83f8d988399ff88dede2", "message": "Default forks?", "committedDate": "2020-04-22T13:22:24Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjk5NzI4Mw==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r412997283", "bodyText": "Nit: can this be private?", "author": "not-napoleon", "createdAt": "2020-04-22T13:46:52Z", "path": "server/src/main/java/org/elasticsearch/search/aggregations/support/CoreValuesSourceType.java", "diffHunk": "@@ -232,7 +239,45 @@ public ValuesSource getScript(AggregationScript.LeafFactory script, ValueType sc\n \n         @Override\n         public ValuesSource getField(FieldContext fieldContext, AggregationScript.LeafFactory script) {\n-            return NUMERIC.getField(fieldContext, script);\n+            ValuesSource.Numeric dataSource = fieldData(fieldContext);\n+            if (script != null) {\n+                // Value script case\n+                return new ValuesSource.Numeric.WithScript(dataSource, script);\n+            }\n+            return dataSource;\n+        }\n+\n+        ValuesSource.Numeric fieldData(FieldContext fieldContext) {", "originalCommit": "9ccecd72a01ffbae05cc0db601da8105184e9f3e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzA3NTg3Mg==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r413075872", "bodyText": "\ud83d\udc4d", "author": "nik9000", "createdAt": "2020-04-22T15:19:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjk5NzI4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjk5OTY2Nw==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r412999667", "bodyText": "Maybe a comment here that about what conditions are required to apply the optimziation?", "author": "not-napoleon", "createdAt": "2020-04-22T13:49:37Z", "path": "server/src/main/java/org/elasticsearch/search/aggregations/support/CoreValuesSourceType.java", "diffHunk": "@@ -232,7 +239,45 @@ public ValuesSource getScript(AggregationScript.LeafFactory script, ValueType sc\n \n         @Override\n         public ValuesSource getField(FieldContext fieldContext, AggregationScript.LeafFactory script) {\n-            return NUMERIC.getField(fieldContext, script);\n+            ValuesSource.Numeric dataSource = fieldData(fieldContext);\n+            if (script != null) {\n+                // Value script case\n+                return new ValuesSource.Numeric.WithScript(dataSource, script);\n+            }\n+            return dataSource;\n+        }\n+\n+        ValuesSource.Numeric fieldData(FieldContext fieldContext) {\n+            if ((fieldContext.indexFieldData() instanceof IndexNumericFieldData) == false) {\n+                throw new IllegalArgumentException(\"Expected numeric type on field [\" + fieldContext.field() +\n+                    \"], but got [\" + fieldContext.fieldType().typeName() + \"]\");\n+            }\n+            if (fieldContext.fieldType().indexOptions() == IndexOptions.NONE", "originalCommit": "9ccecd72a01ffbae05cc0db601da8105184e9f3e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzA1MDc5NA==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r413050794", "bodyText": "\ud83d\udc4d", "author": "nik9000", "createdAt": "2020-04-22T14:50:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjk5OTY2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzAwNTE4OQ==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r413005189", "bodyText": "I think the anonymous class is fine for now, but adds to my growing belief that. dates should have their own ValuesSource.  IDK, need to think about it more.", "author": "not-napoleon", "createdAt": "2020-04-22T13:56:13Z", "path": "server/src/main/java/org/elasticsearch/search/aggregations/support/CoreValuesSourceType.java", "diffHunk": "@@ -232,7 +239,45 @@ public ValuesSource getScript(AggregationScript.LeafFactory script, ValueType sc\n \n         @Override\n         public ValuesSource getField(FieldContext fieldContext, AggregationScript.LeafFactory script) {\n-            return NUMERIC.getField(fieldContext, script);\n+            ValuesSource.Numeric dataSource = fieldData(fieldContext);\n+            if (script != null) {\n+                // Value script case\n+                return new ValuesSource.Numeric.WithScript(dataSource, script);\n+            }\n+            return dataSource;\n+        }\n+\n+        ValuesSource.Numeric fieldData(FieldContext fieldContext) {\n+            if ((fieldContext.indexFieldData() instanceof IndexNumericFieldData) == false) {\n+                throw new IllegalArgumentException(\"Expected numeric type on field [\" + fieldContext.field() +\n+                    \"], but got [\" + fieldContext.fieldType().typeName() + \"]\");\n+            }\n+            if (fieldContext.fieldType().indexOptions() == IndexOptions.NONE\n+                    || fieldContext.fieldType() instanceof DateFieldType == false) {\n+                return new ValuesSource.Numeric.FieldData((IndexNumericFieldData) fieldContext.indexFieldData());\n+            }\n+            return new ValuesSource.Numeric.FieldData((IndexNumericFieldData) fieldContext.indexFieldData()) {", "originalCommit": "9ccecd72a01ffbae05cc0db601da8105184e9f3e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzAwOTcyMg==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r413009722", "bodyText": "Maybe I just haven't had enough coffee, but it's not clear to me why we can't just pass in the already prepared rounding, instead of passing in the reader and doing the prepare call here.  We have a roundingPreparer method on the base ValuesSource class, so we shouldn't need to cast before calling.", "author": "not-napoleon", "createdAt": "2020-04-22T14:01:35Z", "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregator.java", "diffHunk": "@@ -63,22 +67,22 @@\n \n     private final LongHash bucketOrds;\n \n-    DateHistogramAggregator(String name, AggregatorFactories factories, Rounding rounding, Rounding shardRounding,\n+    DateHistogramAggregator(String name, AggregatorFactories factories, Rounding rounding, Rounding shardRounding, IndexReader reader,\n             BucketOrder order, boolean keyed,\n-            long minDocCount, @Nullable ExtendedBounds extendedBounds, @Nullable ValuesSource.Numeric valuesSource,\n+            long minDocCount, @Nullable ExtendedBounds extendedBounds, @Nullable ValuesSource valuesSource,\n             DocValueFormat formatter, SearchContext aggregationContext,\n             Aggregator parent, Map<String, Object> metadata) throws IOException {\n \n         super(name, factories, aggregationContext, parent, metadata);\n         this.rounding = rounding;\n-        this.shardRounding = shardRounding;\n         this.order = order;\n         order.validate(this);\n         this.keyed = keyed;\n         this.minDocCount = minDocCount;\n         this.extendedBounds = extendedBounds;\n-        this.valuesSource = valuesSource;\n+        this.valuesSource = (ValuesSource.Numeric) valuesSource;\n         this.formatter = formatter;\n+        this.preparedRounding = reader == null ? null : this.valuesSource.roundingPreparer(reader).apply(shardRounding);", "originalCommit": "9ccecd72a01ffbae05cc0db601da8105184e9f3e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzA3NjAyMw==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r413076023", "bodyText": "Fixed!", "author": "nik9000", "createdAt": "2020-04-22T15:19:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzAwOTcyMg=="}], "type": "inlineReview"}, {"oid": "8fbeb0b298f301038ee2a2ce1b3e1dfd30890960", "url": "https://github.com/elastic/elasticsearch/commit/8fbeb0b298f301038ee2a2ce1b3e1dfd30890960", "message": "More clear", "committedDate": "2020-04-22T14:39:34Z", "type": "commit"}, {"oid": "dcc3b5b3a68d1ea63b6901ae671c6a4c9f088e7a", "url": "https://github.com/elastic/elasticsearch/commit/dcc3b5b3a68d1ea63b6901ae671c6a4c9f088e7a", "message": "Preserve test without searchable field", "committedDate": "2020-04-22T14:39:41Z", "type": "commit"}, {"oid": "f646f233ee24070007945cb599e0fe97a41a10c5", "url": "https://github.com/elastic/elasticsearch/commit/f646f233ee24070007945cb599e0fe97a41a10c5", "message": "Prepare rounding in factory", "committedDate": "2020-04-22T14:45:23Z", "type": "commit"}, {"oid": "587a6cdcb0f202a17799d4d62caefd693ed17c34", "url": "https://github.com/elastic/elasticsearch/commit/587a6cdcb0f202a17799d4d62caefd693ed17c34", "message": "Comment on why optimization can't work here", "committedDate": "2020-04-22T14:49:29Z", "type": "commit"}, {"oid": "22239668ebedcbc2b08012e4fdcc9bff70c242d2", "url": "https://github.com/elastic/elasticsearch/commit/22239668ebedcbc2b08012e4fdcc9bff70c242d2", "message": "line length", "committedDate": "2020-04-22T14:50:27Z", "type": "commit"}, {"oid": "c07350143d4b705c85381ee2e3c35bebda0025ed", "url": "https://github.com/elastic/elasticsearch/commit/c07350143d4b705c85381ee2e3c35bebda0025ed", "message": "Different counts", "committedDate": "2020-04-22T15:03:46Z", "type": "commit"}, {"oid": "b53b59dce418b3c6acb741974a9b1f9ab4929f63", "url": "https://github.com/elastic/elasticsearch/commit/b53b59dce418b3c6acb741974a9b1f9ab4929f63", "message": "Private!", "committedDate": "2020-04-22T15:18:22Z", "type": "commit"}, {"oid": "5ba5dc7da64e74d80c1084384e3efc793ed65f98", "url": "https://github.com/elastic/elasticsearch/commit/5ba5dc7da64e74d80c1084384e3efc793ed65f98", "message": "Tests in the future!", "committedDate": "2020-04-22T15:30:04Z", "type": "commit"}, {"oid": "dd0d16e482b6e91c6fef4919c0e5a01912c387e1", "url": "https://github.com/elastic/elasticsearch/commit/dd0d16e482b6e91c6fef4919c0e5a01912c387e1", "message": "Nothing is sensible", "committedDate": "2020-04-22T15:44:39Z", "type": "commit"}, {"oid": "c8fcdd010cf0b1f453e653537930943c76385998", "url": "https://github.com/elastic/elasticsearch/commit/c8fcdd010cf0b1f453e653537930943c76385998", "message": "Merge branch 'master' into tz_round", "committedDate": "2020-04-22T16:22:07Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzg0MDU0OA==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r413840548", "bodyText": "After sleeping on it, I've come to think that having the default here is wrong.  I think we should either make this abstract and require each specific ValuesSource to specify if they round or not, or at a minimum make the default to throw and let ValuesSources that support rounding override it.  Otherwise, people writing new ValuesSources need to know that if they aren't going to support rounding, they need to have an override, which is counter intuitive IMHO.", "author": "not-napoleon", "createdAt": "2020-04-23T14:24:18Z", "path": "server/src/main/java/org/elasticsearch/search/aggregations/support/ValuesSource.java", "diffHunk": "@@ -74,6 +77,16 @@ public boolean needsScores() {\n         return false;\n     }\n \n+    /**\n+     * Build a function prepares rounding values to be called many times.\n+     * <p>\n+     * This returns a {@linkplain Function} because auto date histogram will\n+     * need to call it many times over the course of running the aggregation.\n+     */\n+    public Function<Rounding, Rounding.Prepared> roundingPreparer(IndexReader reader) throws IOException {", "originalCommit": "c8fcdd010cf0b1f453e653537930943c76385998", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzkxMDgwNg==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r413910806", "bodyText": "I like abstract pretty well. A similar thing has been bothering me that I think this'll solve. I'll ping you when I've pushed something.", "author": "nik9000", "createdAt": "2020-04-23T15:46:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzg0MDU0OA=="}], "type": "inlineReview"}, {"oid": "b3538a146bbbba57b4cdb705d403bf13e900a0f1", "url": "https://github.com/elastic/elasticsearch/commit/b3538a146bbbba57b4cdb705d403bf13e900a0f1", "message": "Merge branch 'master' into tz_round", "committedDate": "2020-04-23T15:56:50Z", "type": "commit"}, {"oid": "675fc07e51687fa7bcbb9714149e978c3c455a95", "url": "https://github.com/elastic/elasticsearch/commit/675fc07e51687fa7bcbb9714149e978c3c455a95", "message": "abstract", "committedDate": "2020-04-23T16:15:29Z", "type": "commit"}, {"oid": "28a10abe1b826141db1e9c7d0e529c98694496db", "url": "https://github.com/elastic/elasticsearch/commit/28a10abe1b826141db1e9c7d0e529c98694496db", "message": "tMerge branch 'master' into tz_round", "committedDate": "2020-04-24T14:11:46Z", "type": "commit"}, {"oid": "ede9cbc8e1b748c0ed1b563b887ff70b555020b7", "url": "https://github.com/elastic/elasticsearch/commit/ede9cbc8e1b748c0ed1b563b887ff70b555020b7", "message": "Merge branch 'master' into tz_round", "committedDate": "2020-04-28T14:18:06Z", "type": "commit"}, {"oid": "8e52138b68ce17f25044645fbdf5eb4d526921cf", "url": "https://github.com/elastic/elasticsearch/commit/8e52138b68ce17f25044645fbdf5eb4d526921cf", "message": "Merge branch 'master' into tz_round", "committedDate": "2020-04-28T18:34:22Z", "type": "commit"}, {"oid": "44424ea98300fef5eb9b863f7577572cc8a1fef2", "url": "https://github.com/elastic/elasticsearch/commit/44424ea98300fef5eb9b863f7577572cc8a1fef2", "message": "Fix merge mistake", "committedDate": "2020-04-28T22:06:45Z", "type": "commit"}, {"oid": "83e9ecc5a615f5e36a44138175bc81cb004fd026", "url": "https://github.com/elastic/elasticsearch/commit/83e9ecc5a615f5e36a44138175bc81cb004fd026", "message": "Merge branch 'master' into tz_round", "committedDate": "2020-04-29T14:52:59Z", "type": "commit"}, {"oid": "7551cbc93a90fbdfc1b8a85f7a3bc407ece13707", "url": "https://github.com/elastic/elasticsearch/commit/7551cbc93a90fbdfc1b8a85f7a3bc407ece13707", "message": "Merge branch 'master' into tz_round", "committedDate": "2020-04-29T15:23:43Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzU0MjMxMw==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r417542313", "bodyText": "I merged #55687 to wire AutoDateHistogram up to the ValuesSourceRegistry.", "author": "not-napoleon", "createdAt": "2020-04-29T18:59:43Z", "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/AutoDateHistogramAggregatorFactory.java", "diffHunk": "@@ -76,15 +77,16 @@ protected Aggregator doCreateInternal(ValuesSource valuesSource,\n             throw new AggregationExecutionException(\"Registry miss-match - expected AutoDateHistogramAggregationSupplier, found [\" +\n                 aggregatorSupplier.getClass().toString() + \"]\");\n         }\n-        return ((AutoDateHistogramAggregatorSupplier) aggregatorSupplier).build(name, factories, numBuckets, roundingInfos, valuesSource,\n-            config.format(), searchContext, parent, metadata);\n+        return ((AutoDateHistogramAggregatorSupplier) aggregatorSupplier).build(name, factories, numBuckets, roundingInfos,\n+            // TODO once auto date histo is plugged into the ValuesSource refactoring use the date values source", "originalCommit": "7551cbc93a90fbdfc1b8a85f7a3bc407ece13707", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTE2NjI3Mw==", "url": "https://github.com/elastic/elasticsearch/pull/55559#discussion_r419166273", "bodyText": "Thanks! I'll see about getting that in a follow up change.", "author": "nik9000", "createdAt": "2020-05-03T21:57:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzU0MjMxMw=="}], "type": "inlineReview"}, {"oid": "986afab9e090c8e5ac3a9a1e4933239742e570ec", "url": "https://github.com/elastic/elasticsearch/commit/986afab9e090c8e5ac3a9a1e4933239742e570ec", "message": "Merge branch 'master' into tz_round", "committedDate": "2020-05-06T12:24:42Z", "type": "commit"}, {"oid": "9d5c1c510bc3764d0a80116695bcbe3af7c424b8", "url": "https://github.com/elastic/elasticsearch/commit/9d5c1c510bc3764d0a80116695bcbe3af7c424b8", "message": "Blackhole", "committedDate": "2020-05-06T12:32:18Z", "type": "commit"}, {"oid": "83e72eda6ab615aeeb91c406701d0790c893f43e", "url": "https://github.com/elastic/elasticsearch/commit/83e72eda6ab615aeeb91c406701d0790c893f43e", "message": "Merge branch 'master' into tz_round", "committedDate": "2020-05-06T21:15:39Z", "type": "commit"}]}