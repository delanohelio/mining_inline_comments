{"pr_number": 56072, "pr_title": "Avoid copying file chunks in peer covery", "pr_createdAt": "2020-05-01T20:35:53Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/56072", "timeline": [{"oid": "d793485b9e374feb523c99d4e07240f5934b3ef2", "url": "https://github.com/elastic/elasticsearch/commit/d793485b9e374feb523c99d4e07240f5934b3ef2", "message": "Avoid copying file chunks in peer covery", "committedDate": "2020-05-01T20:32:04Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODc0MjI4NQ==", "url": "https://github.com/elastic/elasticsearch/pull/56072#discussion_r418742285", "bodyText": "NIT: I guess technically if lastChunk == true we could just not add the buffer back to the queue and just use () -> {} here? (not sure it matters much but for 500k buffers it might be worth it?)", "author": "original-brownbear", "createdAt": "2020-05-01T21:18:28Z", "path": "server/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java", "diffHunk": "@@ -868,12 +878,14 @@ public void close() throws IOException {\n                 protected FileChunk nextChunkRequest(StoreFileMetadata md) throws IOException {\n                     assert Transports.assertNotTransportThread(\"read file chunk\");\n                     cancellableThreads.checkForCancel();\n+                    final byte[] buffer = Objects.requireNonNullElseGet(buffers.pollFirst(), () -> new byte[chunkSizeInBytes]);\n                     final int bytesRead = currentInput.read(buffer);\n                     if (bytesRead == -1) {\n                         throw new CorruptIndexException(\"file truncated; length=\" + md.length() + \" offset=\" + offset, md.name());\n                     }\n                     final boolean lastChunk = offset + bytesRead == md.length();\n-                    final FileChunk chunk = new FileChunk(md, new BytesArray(buffer, 0, bytesRead), offset, lastChunk);\n+                    final FileChunk chunk = new FileChunk(md, new BytesArray(buffer, 0, bytesRead), offset, lastChunk,\n+                        () -> buffers.addFirst(buffer));", "originalCommit": "d793485b9e374feb523c99d4e07240f5934b3ef2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODc2MDM2OQ==", "url": "https://github.com/elastic/elasticsearch/pull/56072#discussion_r418760369", "bodyText": "I think we still need to add the buffer back because the flag lastChunk is for each file while the buffers are used for multiple files.", "author": "dnhatn", "createdAt": "2020-05-01T22:15:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODc0MjI4NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODk1NTY2MQ==", "url": "https://github.com/elastic/elasticsearch/pull/56072#discussion_r418955661", "bodyText": "Right \ud83e\udd26 => nevermind :)", "author": "original-brownbear", "createdAt": "2020-05-02T12:53:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODc0MjI4NQ=="}], "type": "inlineReview"}]}