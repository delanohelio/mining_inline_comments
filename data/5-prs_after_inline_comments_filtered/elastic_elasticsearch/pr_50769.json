{"pr_number": 50769, "pr_title": "Do not force refresh when write indexing buffer", "pr_createdAt": "2020-01-08T22:59:50Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/50769", "timeline": [{"oid": "2f1f61e596513cba72e904a267e3c1b3f166c561", "url": "https://github.com/elastic/elasticsearch/commit/2f1f61e596513cba72e904a267e3c1b3f166c561", "message": "Do not force refresh when write indexing buffer", "committedDate": "2020-01-08T22:20:37Z", "type": "commit"}, {"oid": "2261b3f32e9165209ffd711bde3a8815d735de1d", "url": "https://github.com/elastic/elasticsearch/commit/2261b3f32e9165209ffd711bde3a8815d735de1d", "message": "Merge branch 'master' into indexing-memory", "committedDate": "2020-01-08T23:03:03Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDQ4NzQyMQ==", "url": "https://github.com/elastic/elasticsearch/pull/50769#discussion_r364487421", "bodyText": "I only added this new test. Other tests are unchanged.", "author": "dnhatn", "createdAt": "2020-01-08T23:04:01Z", "path": "server/src/test/java/org/elasticsearch/indices/IndexingMemoryControllerTests.java", "diffHunk": "@@ -346,117 +328,83 @@ public void testThrottling() throws Exception {\n         controller.forceCheck();\n         controller.assertNotThrottled(shard0);\n         controller.assertNotThrottled(shard1);\n+        closeShards(shard0, shard1);\n     }\n \n-    // #10312\n-    public void testDeletesAloneCanTriggerRefresh() throws Exception {\n-        createIndex(\"index\",\n-                    Settings.builder().put(\"index.number_of_shards\", 1)\n-                                      .put(\"index.number_of_replicas\", 0)\n-                                      .put(\"index.refresh_interval\", -1)\n-                                      .build());\n-        ensureGreen();\n-\n-        IndicesService indicesService = getInstanceFromNode(IndicesService.class);\n-        IndexService indexService = indicesService.indexService(resolveIndex(\"index\"));\n-        IndexShard shard = indexService.getShardOrNull(0);\n-        assertNotNull(shard);\n-\n-        for (int i = 0; i < 100; i++) {\n-            String id = Integer.toString(i);\n-            client().prepareIndex(\"index\").setId(id).setSource(\"field\", \"value\").get();\n-        }\n-\n-        // Force merge so we know all merges are done before we start deleting:\n-        ForceMergeResponse r = client().admin().indices().prepareForceMerge().setMaxNumSegments(1).execute().actionGet();\n-        assertNoFailures(r);\n-\n-        // Make a shell of an IMC to check up on indexing buffer usage:\n-        Settings settings = Settings.builder().put(\"indices.memory.index_buffer_size\", \"1kb\").build();\n+    EngineConfig configWithRefreshListener(EngineConfig config, ReferenceManager.RefreshListener listener) {\n+        final List<ReferenceManager.RefreshListener> internalRefreshListener = new ArrayList<>(config.getInternalRefreshListener());;\n+        internalRefreshListener.add(listener);\n+        return new EngineConfig(config.getShardId(), config.getAllocationId(), config.getThreadPool(),\n+            config.getIndexSettings(), config.getWarmer(), config.getStore(), config.getMergePolicy(), config.getAnalyzer(),\n+            config.getSimilarity(), new CodecService(null, logger), config.getEventListener(), config.getQueryCache(),\n+            config.getQueryCachingPolicy(), config.getTranslogConfig(), config.getFlushMergesAfter(),\n+            config.getExternalRefreshListener(), internalRefreshListener, config.getIndexSort(),\n+            config.getCircuitBreakerService(), config.getGlobalCheckpointSupplier(), config.retentionLeasesSupplier(),\n+            config.getPrimaryTermSupplier(), config.getTombstoneDocSupplier());\n+    }\n \n-        // TODO: would be cleaner if I could pass this 1kb setting to the single node this test created....\n-        IndexingMemoryController imc = new IndexingMemoryController(settings, null, null) {\n+    public void testSkipRefreshIfShardIsRefreshingAlready() throws Exception {", "originalCommit": "2261b3f32e9165209ffd711bde3a8815d735de1d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "e6839093339bc1b9ca15b174adec03486d3c1ac2", "url": "https://github.com/elastic/elasticsearch/commit/e6839093339bc1b9ca15b174adec03486d3c1ac2", "message": "do not check for rejected", "committedDate": "2020-01-09T02:51:38Z", "type": "commit"}, {"oid": "f0a05f98d63cac908023df9c91955a84a55e39f1", "url": "https://github.com/elastic/elasticsearch/commit/f0a05f98d63cac908023df9c91955a84a55e39f1", "message": "Merge branch 'master' into indexing-memory", "committedDate": "2020-01-09T02:52:48Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDYyMTQ1OQ==", "url": "https://github.com/elastic/elasticsearch/pull/50769#discussion_r364621459", "bodyText": "nit: I prefer to find the stats object to assert on first and then assert to ensure we get a NPE if stats for some reason do not contain \"refresh\" rather than pass the test.", "author": "henningandersen", "createdAt": "2020-01-09T08:58:57Z", "path": "server/src/test/java/org/elasticsearch/indices/IndexingMemoryControllerTests.java", "diffHunk": "@@ -346,117 +328,81 @@ public void testThrottling() throws Exception {\n         controller.forceCheck();\n         controller.assertNotThrottled(shard0);\n         controller.assertNotThrottled(shard1);\n+        closeShards(shard0, shard1);\n     }\n \n-    // #10312\n-    public void testDeletesAloneCanTriggerRefresh() throws Exception {\n-        createIndex(\"index\",\n-                    Settings.builder().put(\"index.number_of_shards\", 1)\n-                                      .put(\"index.number_of_replicas\", 0)\n-                                      .put(\"index.refresh_interval\", -1)\n-                                      .build());\n-        ensureGreen();\n-\n-        IndicesService indicesService = getInstanceFromNode(IndicesService.class);\n-        IndexService indexService = indicesService.indexService(resolveIndex(\"index\"));\n-        IndexShard shard = indexService.getShardOrNull(0);\n-        assertNotNull(shard);\n-\n-        for (int i = 0; i < 100; i++) {\n-            String id = Integer.toString(i);\n-            client().prepareIndex(\"index\").setId(id).setSource(\"field\", \"value\").get();\n-        }\n-\n-        // Force merge so we know all merges are done before we start deleting:\n-        ForceMergeResponse r = client().admin().indices().prepareForceMerge().setMaxNumSegments(1).execute().actionGet();\n-        assertNoFailures(r);\n-\n-        // Make a shell of an IMC to check up on indexing buffer usage:\n-        Settings settings = Settings.builder().put(\"indices.memory.index_buffer_size\", \"1kb\").build();\n+    EngineConfig configWithRefreshListener(EngineConfig config, ReferenceManager.RefreshListener listener) {\n+        final List<ReferenceManager.RefreshListener> internalRefreshListener = new ArrayList<>(config.getInternalRefreshListener());;\n+        internalRefreshListener.add(listener);\n+        return new EngineConfig(config.getShardId(), config.getAllocationId(), config.getThreadPool(),\n+            config.getIndexSettings(), config.getWarmer(), config.getStore(), config.getMergePolicy(), config.getAnalyzer(),\n+            config.getSimilarity(), new CodecService(null, logger), config.getEventListener(), config.getQueryCache(),\n+            config.getQueryCachingPolicy(), config.getTranslogConfig(), config.getFlushMergesAfter(),\n+            config.getExternalRefreshListener(), internalRefreshListener, config.getIndexSort(),\n+            config.getCircuitBreakerService(), config.getGlobalCheckpointSupplier(), config.retentionLeasesSupplier(),\n+            config.getPrimaryTermSupplier(), config.getTombstoneDocSupplier());\n+    }\n \n-        // TODO: would be cleaner if I could pass this 1kb setting to the single node this test created....\n-        IndexingMemoryController imc = new IndexingMemoryController(settings, null, null) {\n+    public void testSkipRefreshIfShardIsRefreshingAlready() throws Exception {\n+        SetOnce<CountDownLatch> refreshLatch = new SetOnce<>();\n+        ReferenceManager.RefreshListener refreshListener = new ReferenceManager.RefreshListener() {\n             @Override\n-            protected List<IndexShard> availableShards() {\n-                return Collections.singletonList(shard);\n+            public void beforeRefresh() {\n+                if (refreshLatch.get() != null) {\n+                    try {\n+                        refreshLatch.get().await();\n+                    } catch (InterruptedException e) {\n+                        throw new AssertionError(e);\n+                    }\n+                }\n             }\n \n             @Override\n-            protected long getIndexBufferRAMBytesUsed(IndexShard shard) {\n-                return shard.getIndexBufferRAMBytesUsed();\n-            }\n+            public void afterRefresh(boolean didRefresh) {\n \n+            }\n+        };\n+        IndexShard shard = newStartedShard(randomBoolean(), Settings.EMPTY,\n+            config -> new InternalEngine(configWithRefreshListener(config, refreshListener)));\n+        refreshLatch.set(new CountDownLatch(1)); // block refresh\n+        final RefreshStats refreshStats = shard.refreshStats();\n+        final IndexingMemoryController controller = new IndexingMemoryController(\n+            Settings.builder().put(\"indices.memory.interval\", \"200h\") // disable it\n+                .put(\"indices.memory.index_buffer_size\", \"1024b\").build(),\n+            threadPool,\n+            Collections.singleton(shard)) {\n             @Override\n-            protected void writeIndexingBufferAsync(IndexShard shard) {\n-                // just do it sync'd for this test\n-                shard.writeIndexingBuffer();\n+            protected long getIndexBufferRAMBytesUsed(IndexShard shard) {\n+                return randomLongBetween(1025, 10 * 1024 * 1024);\n             }\n \n             @Override\n-            protected Cancellable scheduleTask(ThreadPool threadPool) {\n-                return null;\n+            protected long getShardWritingBytes(IndexShard shard) {\n+                return 0L;\n             }\n         };\n-\n-        for (int i = 0; i < 100; i++) {\n-            String id = Integer.toString(i);\n-            client().prepareDelete(\"index\", id).get();\n+        int iterations = randomIntBetween(10, 100);\n+        for (int i = 0; i < iterations; i++) {\n+            controller.forceCheck();\n         }\n-\n-        final long indexingBufferBytes1 = shard.getIndexBufferRAMBytesUsed();\n-\n-        imc.forceCheck();\n-\n-        // We must assertBusy because the writeIndexingBufferAsync is done in background (REFRESH) thread pool:\n         assertBusy(() -> {\n-            try (Engine.Searcher s2 = shard.acquireSearcher(\"index\")) {\n-                // 100 buffered deletes will easily exceed our 1 KB indexing buffer so it should trigger a write:\n-                final long indexingBufferBytes2 = shard.getIndexBufferRAMBytesUsed();\n-                assertTrue(indexingBufferBytes2 < indexingBufferBytes1);\n+            for (ThreadPoolStats.Stats stats : threadPool.stats()) {", "originalCommit": "f0a05f98d63cac908023df9c91955a84a55e39f1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDg4MzUxMw==", "url": "https://github.com/elastic/elasticsearch/pull/50769#discussion_r364883513", "bodyText": "++. Adjusted in 7475515.", "author": "dnhatn", "createdAt": "2020-01-09T18:04:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDYyMTQ1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDYyOTA5NQ==", "url": "https://github.com/elastic/elasticsearch/pull/50769#discussion_r364629095", "bodyText": "I think there is a (very small) risk that the IndexingMemoryController created by the node was triggered on one  of the deletes and that this causes the writeIndexingBuffer/refresh call triggered here to return immediately. It does take a lot of bad circumstances though (of which the heap size alone will likely prevent this), but I still think we should address it. Maybe the TODO above is doable if this test is moved to its own class? Or we could simply add a node-setting that essentially disables it by setting the limit very high?", "author": "henningandersen", "createdAt": "2020-01-09T09:17:04Z", "path": "server/src/test/java/org/elasticsearch/indices/IndexingMemoryControllerIT.java", "diffHunk": "@@ -0,0 +1,163 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.elasticsearch.indices;\n+\n+import org.apache.lucene.index.DirectoryReader;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.admin.indices.forcemerge.ForceMergeResponse;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.common.CheckedFunction;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.xcontent.XContentType;\n+import org.elasticsearch.index.IndexService;\n+import org.elasticsearch.index.engine.Engine;\n+import org.elasticsearch.index.shard.IndexShard;\n+import org.elasticsearch.index.shard.IndexShardIT;\n+import org.elasticsearch.index.shard.IndexShardTestCase;\n+import org.elasticsearch.indices.breaker.NoneCircuitBreakerService;\n+import org.elasticsearch.indices.recovery.RecoveryState;\n+import org.elasticsearch.test.ESSingleNodeTestCase;\n+import org.elasticsearch.threadpool.Scheduler.Cancellable;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static java.util.Collections.emptyMap;\n+import static java.util.Collections.emptySet;\n+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;\n+\n+public class IndexingMemoryControllerIT extends ESSingleNodeTestCase {\n+\n+    // #10312\n+    public void testDeletesAloneCanTriggerRefresh() throws Exception {\n+        createIndex(\"index\",\n+                    Settings.builder().put(\"index.number_of_shards\", 1)\n+                                      .put(\"index.number_of_replicas\", 0)\n+                                      .put(\"index.refresh_interval\", -1)\n+                                      .build());\n+        ensureGreen();\n+\n+        IndicesService indicesService = getInstanceFromNode(IndicesService.class);\n+        IndexService indexService = indicesService.indexService(resolveIndex(\"index\"));\n+        IndexShard shard = indexService.getShardOrNull(0);\n+        assertNotNull(shard);\n+\n+        for (int i = 0; i < 100; i++) {\n+            String id = Integer.toString(i);\n+            client().prepareIndex(\"index\").setId(id).setSource(\"field\", \"value\").get();\n+        }\n+\n+        // Force merge so we know all merges are done before we start deleting:\n+        ForceMergeResponse r = client().admin().indices().prepareForceMerge().setMaxNumSegments(1).execute().actionGet();\n+        assertNoFailures(r);\n+\n+        // Make a shell of an IMC to check up on indexing buffer usage:\n+        Settings settings = Settings.builder().put(\"indices.memory.index_buffer_size\", \"1kb\").build();\n+\n+        // TODO: would be cleaner if I could pass this 1kb setting to the single node this test created....\n+        IndexingMemoryController imc = new IndexingMemoryController(settings, null, null) {\n+            @Override\n+            protected List<IndexShard> availableShards() {\n+                return Collections.singletonList(shard);\n+            }\n+\n+            @Override\n+            protected long getIndexBufferRAMBytesUsed(IndexShard shard) {\n+                return shard.getIndexBufferRAMBytesUsed();\n+            }\n+\n+            @Override\n+            protected void writeIndexingBufferAsync(IndexShard shard) {\n+                // just do it sync'd for this test\n+                shard.writeIndexingBuffer();\n+            }\n+\n+            @Override\n+            protected Cancellable scheduleTask(ThreadPool threadPool) {\n+                return null;\n+            }\n+        };\n+\n+        for (int i = 0; i < 100; i++) {\n+            String id = Integer.toString(i);\n+            client().prepareDelete(\"index\", id).get();\n+        }\n+\n+        final long indexingBufferBytes1 = shard.getIndexBufferRAMBytesUsed();\n+\n+        imc.forceCheck();", "originalCommit": "f0a05f98d63cac908023df9c91955a84a55e39f1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDg4MzkwMA==", "url": "https://github.com/elastic/elasticsearch/pull/50769#discussion_r364883900", "bodyText": "Good point. I pushed 4d04e97.", "author": "dnhatn", "createdAt": "2020-01-09T18:05:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDYyOTA5NQ=="}], "type": "inlineReview"}, {"oid": "747551513e5712883168a48d4916d2ec6e4202e7", "url": "https://github.com/elastic/elasticsearch/commit/747551513e5712883168a48d4916d2ec6e4202e7", "message": "ensure refresh threadpool stats exist", "committedDate": "2020-01-09T13:52:11Z", "type": "commit"}, {"oid": "4d04e97c214626fd184de151d6fe36949e0267cb", "url": "https://github.com/elastic/elasticsearch/commit/4d04e97c214626fd184de151d6fe36949e0267cb", "message": "arrange tests", "committedDate": "2020-01-09T17:58:04Z", "type": "commit"}]}