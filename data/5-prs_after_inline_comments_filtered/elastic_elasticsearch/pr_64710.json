{"pr_number": 64710, "pr_title": "Protect replicated data streams against local rollovers", "pr_createdAt": "2020-11-06T13:45:29Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/64710", "timeline": [{"oid": "f0d907627fcdb28f4e2654ae3bde2559c68402e3", "url": "https://github.com/elastic/elasticsearch/commit/f0d907627fcdb28f4e2654ae3bde2559c68402e3", "message": "Added test that fails now, but tests that rolling over a data stream that follows a remote data stream fails.", "committedDate": "2020-11-06T11:20:49Z", "type": "commit"}, {"oid": "10d7ffcb67bde9df9284f81962919f9b82e35372", "url": "https://github.com/elastic/elasticsearch/commit/10d7ffcb67bde9df9284f81962919f9b82e35372", "message": "Added replicate flag to data stream and promote data stream api.", "committedDate": "2020-11-06T13:11:43Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODc2MTY2Nw==", "url": "https://github.com/elastic/elasticsearch/pull/64710#discussion_r518761667", "bodyText": "Should we embed this in the unfollow api? I'm not sure, because that api is centered around unfollowing a regular index and this operation is different and that would add ambiguity to the unfollow api. However the argument can also be made in reverse, in that this is a related operation.", "author": "martijnvg", "createdAt": "2020-11-06T13:48:17Z", "path": "x-pack/plugin/data-streams/src/main/java/org/elasticsearch/xpack/datastreams/action/PromoteDataStreamTransportAction.java", "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.datastreams.action;\n+\n+import org.elasticsearch.ResourceNotFoundException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.support.ActionFilters;\n+import org.elasticsearch.action.support.master.AcknowledgedResponse;\n+import org.elasticsearch.action.support.master.AcknowledgedTransportMasterNodeAction;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.ClusterStateUpdateTask;\n+import org.elasticsearch.cluster.block.ClusterBlockException;\n+import org.elasticsearch.cluster.block.ClusterBlockLevel;\n+import org.elasticsearch.cluster.metadata.DataStream;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.inject.Inject;\n+import org.elasticsearch.tasks.Task;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.transport.TransportService;\n+import org.elasticsearch.xpack.core.action.PromoteDataStreamAction;\n+\n+public class PromoteDataStreamTransportAction extends AcknowledgedTransportMasterNodeAction<PromoteDataStreamAction.Request> {\n+\n+    @Inject\n+    public PromoteDataStreamTransportAction(\n+        TransportService transportService,\n+        ClusterService clusterService,\n+        ThreadPool threadPool,\n+        ActionFilters actionFilters,\n+        IndexNameExpressionResolver indexNameExpressionResolver\n+    ) {\n+        super(\n+            PromoteDataStreamAction.NAME,\n+            transportService,\n+            clusterService,\n+            threadPool,\n+            actionFilters,\n+            PromoteDataStreamAction.Request::new,\n+            indexNameExpressionResolver,\n+            ThreadPool.Names.SAME\n+        );\n+    }\n+\n+    @Override\n+    protected void masterOperation(\n+        Task task,\n+        PromoteDataStreamAction.Request request,\n+        ClusterState state,\n+        ActionListener<AcknowledgedResponse> listener\n+    ) throws Exception {\n+        clusterService.submitStateUpdateTask(\n+            \"promote-data-stream [\" + request.getName() + \"]\",\n+            new ClusterStateUpdateTask(Priority.HIGH, request.masterNodeTimeout()) {\n+\n+                @Override\n+                public void onFailure(String source, Exception e) {\n+                    listener.onFailure(e);\n+                }\n+\n+                @Override\n+                public ClusterState execute(ClusterState currentState) {\n+                    return promoteDataStream(currentState, request);\n+                }\n+\n+                @Override\n+                public void clusterStateProcessed(String source, ClusterState oldState, ClusterState newState) {\n+                    listener.onResponse(AcknowledgedResponse.TRUE);\n+                }\n+            }\n+        );\n+    }\n+\n+    static ClusterState promoteDataStream(ClusterState currentState, PromoteDataStreamAction.Request request) {\n+        DataStream dataStream = currentState.getMetadata().dataStreams().get(request.getName());\n+        if (dataStream == null) {\n+            throw new ResourceNotFoundException(\"data stream [\" + request.getName() + \"] does not exist\");\n+        }\n+\n+        DataStream promotedDataStream = dataStream.promoteDataStream();", "originalCommit": "10d7ffcb67bde9df9284f81962919f9b82e35372", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "5514ae8b518154cdf3461c123a4f3bdebab2b9de", "url": "https://github.com/elastic/elasticsearch/commit/5514ae8b518154cdf3461c123a4f3bdebab2b9de", "message": "Merge remote-tracking branch 'es/master' into ccr_data_stream_support_part_2", "committedDate": "2020-11-09T09:59:11Z", "type": "commit"}, {"oid": "461773d173af213c29ac1ff0ff8aacf3f6885295", "url": "https://github.com/elastic/elasticsearch/commit/461773d173af213c29ac1ff0ff8aacf3f6885295", "message": "fix precommit", "committedDate": "2020-11-09T10:02:31Z", "type": "commit"}, {"oid": "ef71529aca1040848f71f0aefe5673749dcb40ec", "url": "https://github.com/elastic/elasticsearch/commit/ef71529aca1040848f71f0aefe5673749dcb40ec", "message": "nit", "committedDate": "2020-11-09T10:02:59Z", "type": "commit"}, {"oid": "72379300c9cce1f7567f04521bd1bc8e75ef95e4", "url": "https://github.com/elastic/elasticsearch/commit/72379300c9cce1f7567f04521bd1bc8e75ef95e4", "message": "fixed tests", "committedDate": "2020-11-09T13:25:19Z", "type": "commit"}, {"oid": "e9b6627aad502aa554775e5095ea6b624f2d6e3e", "url": "https://github.com/elastic/elasticsearch/commit/e9b6627aad502aa554775e5095ea6b624f2d6e3e", "message": "fixed tests", "committedDate": "2020-11-09T16:38:17Z", "type": "commit"}, {"oid": "e031d72b214e2cda485b4dcd2c302734fcb60b86", "url": "https://github.com/elastic/elasticsearch/commit/e031d72b214e2cda485b4dcd2c302734fcb60b86", "message": "fixed npe", "committedDate": "2020-11-09T18:05:03Z", "type": "commit"}, {"oid": "b1c57d14292fc645aaefdc74ff9e17818d6f2d3f", "url": "https://github.com/elastic/elasticsearch/commit/b1c57d14292fc645aaefdc74ff9e17818d6f2d3f", "message": "Merge remote-tracking branch 'es/master' into ccr_data_stream_support_part_2", "committedDate": "2020-11-10T08:38:46Z", "type": "commit"}, {"oid": "0c22ce149d4b8f83771c806ddd1d6a4fbfaa670d", "url": "https://github.com/elastic/elasticsearch/commit/0c22ce149d4b8f83771c806ddd1d6a4fbfaa670d", "message": "fixed test", "committedDate": "2020-11-10T09:04:12Z", "type": "commit"}, {"oid": "73877d6b182b53025057bb7f8da74f14d7343444", "url": "https://github.com/elastic/elasticsearch/commit/73877d6b182b53025057bb7f8da74f14d7343444", "message": "Merge remote-tracking branch 'es/master' into ccr_data_stream_support_part_2", "committedDate": "2020-11-12T10:23:19Z", "type": "commit"}, {"oid": "5cbaf3d7c8d292a38acc084864c4e5242438b7de", "url": "https://github.com/elastic/elasticsearch/commit/5cbaf3d7c8d292a38acc084864c4e5242438b7de", "message": "Merge remote-tracking branch 'es/master' into ccr_data_stream_support_part_2", "committedDate": "2020-11-16T10:00:41Z", "type": "commit"}, {"oid": "c9d410fb1b0ce936e8419450353b4321835dda4d", "url": "https://github.com/elastic/elasticsearch/commit/c9d410fb1b0ce936e8419450353b4321835dda4d", "message": "Merge remote-tracking branch 'es/master' into ccr_data_stream_support_part_2", "committedDate": "2020-11-16T14:21:54Z", "type": "commit"}, {"oid": "5efa94385e06dbe070be1dd0b4b8a746093750f1", "url": "https://github.com/elastic/elasticsearch/commit/5efa94385e06dbe070be1dd0b4b8a746093750f1", "message": "added ccr bi-directional test with data streams", "committedDate": "2020-11-17T13:47:58Z", "type": "commit"}, {"oid": "312a788e3d432e39024383d0ad40c79abec9838c", "url": "https://github.com/elastic/elasticsearch/commit/312a788e3d432e39024383d0ad40c79abec9838c", "message": "Merge remote-tracking branch 'es/master' into ccr_data_stream_support_part_2", "committedDate": "2020-11-17T13:48:23Z", "type": "commit"}, {"oid": "56074c3120a7a4e32f81fd52f942b1d9ea305991", "url": "https://github.com/elastic/elasticsearch/commit/56074c3120a7a4e32f81fd52f942b1d9ea305991", "message": "added docs", "committedDate": "2020-11-19T10:11:32Z", "type": "commit"}, {"oid": "57941acc3bf5ba8326cc9663a9d9139af8eeb90d", "url": "https://github.com/elastic/elasticsearch/commit/57941acc3bf5ba8326cc9663a9d9139af8eeb90d", "message": "Merge remote-tracking branch 'es/master' into ccr_data_stream_support_part_2", "committedDate": "2020-11-20T12:14:57Z", "type": "commit"}, {"oid": "1b49909dde0a427072660a9af133115426adce11", "url": "https://github.com/elastic/elasticsearch/commit/1b49909dde0a427072660a9af133115426adce11", "message": "Added a test, which verifies that an alias in follow cluster can't be rolled over.", "committedDate": "2020-11-23T10:26:39Z", "type": "commit"}, {"oid": "5700b679d56f4b4a2563eb74702ea491c6b89dca", "url": "https://github.com/elastic/elasticsearch/commit/5700b679d56f4b4a2563eb74702ea491c6b89dca", "message": "Merge remote-tracking branch 'es/master' into ccr_data_stream_support_part_2", "committedDate": "2020-11-23T10:27:14Z", "type": "commit"}, {"oid": "5528da438e4a5075e055523307353a68094f0965", "url": "https://github.com/elastic/elasticsearch/commit/5528da438e4a5075e055523307353a68094f0965", "message": "fix checkstyle", "committedDate": "2020-11-23T10:33:23Z", "type": "commit"}, {"oid": "a21454e2ef70c5437ae2a10d81570a7abfb72592", "url": "https://github.com/elastic/elasticsearch/commit/a21454e2ef70c5437ae2a10d81570a7abfb72592", "message": "added rest spec and renamed rest action", "committedDate": "2020-11-23T10:47:43Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTkwODM0Mg==", "url": "https://github.com/elastic/elasticsearch/pull/64710#discussion_r529908342", "bodyText": "Should we have a separate method that ensures this datastream can be rolled over instead?", "author": "dnhatn", "createdAt": "2020-11-24T21:56:46Z", "path": "server/src/main/java/org/elasticsearch/action/admin/indices/rollover/MetadataRolloverService.java", "diffHunk": "@@ -148,6 +149,7 @@ private RolloverResult rolloverDataStream(ClusterState currentState, IndexAbstra\n         final DataStream ds = dataStream.getDataStream();\n         final IndexMetadata originalWriteIndex = dataStream.getWriteIndex();\n         final String newWriteIndexName = DataStream.getDefaultBackingIndexName(ds.getName(), ds.getGeneration() + 1);\n+        ds.rollover(new Index(newWriteIndexName, \"uuid\")); // just for validation", "originalCommit": "a21454e2ef70c5437ae2a10d81570a7abfb72592", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDI2NTA2Ng==", "url": "https://github.com/elastic/elasticsearch/pull/64710#discussion_r530265066", "bodyText": "I think that this is what happens in this rolloverDataStream(...) method. Anything before the if statement is for validating purposes and after the if statement is for actually performing the rollover (the DataStream#rollover(...) method is then also invoked). I just added the DataStream#rollover(...) invocation here, so that validation that is in this method is also performed when just validating the rollover.", "author": "martijnvg", "createdAt": "2020-11-25T10:27:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTkwODM0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTkxMDM5NA==", "url": "https://github.com/elastic/elasticsearch/pull/64710#discussion_r529910394", "bodyText": "Should we name this \"allowRollover\" or \"followed\"? I am okay with \"replicated\" if you prefer.", "author": "dnhatn", "createdAt": "2020-11-24T21:58:44Z", "path": "server/src/main/java/org/elasticsearch/cluster/metadata/DataStream.java", "diffHunk": "@@ -44,26 +44,29 @@\n \n     public static final String BACKING_INDEX_PREFIX = \".ds-\";\n     public static final Version HIDDEN_VERSION = Version.V_7_11_0;\n+    public static final Version REPLICATED_VERSION = Version.V_8_0_0;\n \n     private final String name;\n     private final TimestampField timeStampField;\n     private final List<Index> indices;\n     private final long generation;\n     private final Map<String, Object> metadata;\n     private final boolean hidden;\n+    private final boolean replicated;", "originalCommit": "a21454e2ef70c5437ae2a10d81570a7abfb72592", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDI2Nzg1Ng==", "url": "https://github.com/elastic/elasticsearch/pull/64710#discussion_r530267856", "bodyText": "Maybe something that indicates whether a data stream can be rolled over is a better name. I will think about this.", "author": "martijnvg", "createdAt": "2020-11-25T10:31:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTkxMDM5NA=="}], "type": "inlineReview"}, {"oid": "ef26773e6713eadb03cc781278b4e0ef8b31f763", "url": "https://github.com/elastic/elasticsearch/commit/ef26773e6713eadb03cc781278b4e0ef8b31f763", "message": "Merge remote-tracking branch 'es/master' into ccr_data_stream_support_part_2", "committedDate": "2020-12-02T09:56:15Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzIxMDMyMg==", "url": "https://github.com/elastic/elasticsearch/pull/64710#discussion_r537210322", "bodyText": "@martijnvg Sorry, I think I didn't explain well my concern about supporting bi-directional replication. What I meant was JasonZ's blog. In his setup, we can send the same indexing request (uses the same write alias) to either cluster. In this test, we use different data streams for indexing requests. That means users can't simply reroute all indexing to a single cluster when another is not available.", "author": "dnhatn", "createdAt": "2020-12-07T03:42:14Z", "path": "x-pack/plugin/ccr/qa/multi-cluster/src/test/java/org/elasticsearch/xpack/ccr/AutoFollowIT.java", "diffHunk": "@@ -347,13 +321,369 @@ public void testDataStreams_autoFollowAfterDataStreamCreated() throws Exception\n         }\n     }\n \n+    public void testRolloverDataStreamInFollowClusterForbidden() throws Exception {\n+        if (\"follow\".equals(targetCluster) == false) {\n+            return;\n+        }\n+\n+        final int numDocs = 64;\n+        final String dataStreamName = \"logs-tomcat-prod\";\n+\n+        int initialNumberOfSuccessfulFollowedIndices = getNumberOfSuccessfulFollowedIndices();\n+\n+        // Create auto follow pattern\n+        createAutoFollowPattern(client(), \"test_pattern\", \"logs-*\", \"leader_cluster\");\n+\n+        // Create data stream and ensure that is is auto followed\n+        {\n+            try (RestClient leaderClient = buildLeaderClient()) {\n+                for (int i = 0; i < numDocs; i++) {\n+                    Request indexRequest = new Request(\"POST\", \"/\" + dataStreamName + \"/_doc\");\n+                    indexRequest.addParameter(\"refresh\", \"true\");\n+                    indexRequest.setJsonEntity(\"{\\\"@timestamp\\\": \\\"\" + DATE_FORMAT.format(new Date()) + \"\\\",\\\"message\\\":\\\"abc\\\"}\");\n+                    assertOK(leaderClient.performRequest(indexRequest));\n+                }\n+                verifyDataStream(leaderClient, dataStreamName, backingIndexName(dataStreamName, 1));\n+                verifyDocuments(leaderClient, dataStreamName, numDocs);\n+            }\n+            assertBusy(() -> {\n+                assertThat(getNumberOfSuccessfulFollowedIndices(), equalTo(initialNumberOfSuccessfulFollowedIndices + 1));\n+                verifyDataStream(client(), dataStreamName, backingIndexName(dataStreamName, 1));\n+                ensureYellow(dataStreamName);\n+                verifyDocuments(client(), dataStreamName, numDocs);\n+            });\n+        }\n+\n+        // Rollover in leader cluster and ensure second backing index is replicated:\n+        {\n+            try (RestClient leaderClient = buildLeaderClient()) {\n+                Request rolloverRequest = new Request(\"POST\", \"/\" +  dataStreamName + \"/_rollover\");\n+                assertOK(leaderClient.performRequest(rolloverRequest));\n+                verifyDataStream(leaderClient, dataStreamName, backingIndexName(dataStreamName, 1), backingIndexName(dataStreamName, 2));\n+\n+                Request indexRequest = new Request(\"POST\", \"/\" + dataStreamName + \"/_doc\");\n+                indexRequest.addParameter(\"refresh\", \"true\");\n+                indexRequest.setJsonEntity(\"{\\\"@timestamp\\\": \\\"\" + DATE_FORMAT.format(new Date()) + \"\\\",\\\"message\\\":\\\"abc\\\"}\");\n+                assertOK(leaderClient.performRequest(indexRequest));\n+                verifyDocuments(leaderClient, dataStreamName, numDocs + 1);\n+            }\n+            assertBusy(() -> {\n+                assertThat(getNumberOfSuccessfulFollowedIndices(), equalTo(initialNumberOfSuccessfulFollowedIndices + 2));\n+                verifyDataStream(client(), dataStreamName, backingIndexName(dataStreamName, 1), backingIndexName(dataStreamName, 2));\n+                ensureYellow(dataStreamName);\n+                verifyDocuments(client(), dataStreamName, numDocs + 1);\n+            });\n+        }\n+\n+        // Try rollover in follow cluster\n+        {\n+            Request rolloverRequest1 = new Request(\"POST\", \"/\" +  dataStreamName + \"/_rollover\");\n+            Exception e = expectThrows(ResponseException.class, () -> client().performRequest(rolloverRequest1));\n+            assertThat(e.getMessage(), containsString(\"data stream [\" + dataStreamName + \"] cannot be rolled over, \" +\n+                \"because it is a replicated data stream\"));\n+            verifyDataStream(client(), dataStreamName, backingIndexName(dataStreamName, 1), backingIndexName(dataStreamName, 2));\n+\n+            // Unfollow .ds-logs-tomcat-prod-000001\n+            pauseFollow(backingIndexName(dataStreamName, 1));\n+            closeIndex(backingIndexName(dataStreamName, 1));\n+            unfollow(backingIndexName(dataStreamName, 1));\n+\n+            // Try again\n+            Request rolloverRequest2 = new Request(\"POST\", \"/\" +  dataStreamName + \"/_rollover\");\n+            e = expectThrows(ResponseException.class, () -> client().performRequest(rolloverRequest2));\n+            assertThat(e.getMessage(), containsString(\"data stream [\" + dataStreamName + \"] cannot be rolled over, \" +\n+                \"because it is a replicated data stream\"));\n+            verifyDataStream(client(), dataStreamName, backingIndexName(dataStreamName, 1), backingIndexName(dataStreamName, 2));\n+\n+            // Promote local data stream\n+            Request promoteRequest = new Request(\"POST\", \"/_data_stream/_promote/\" + dataStreamName);\n+            assertOK(client().performRequest(promoteRequest));\n+\n+            // Try again and now the rollover should be successful because local data stream is now :\n+            Request rolloverRequest3 = new Request(\"POST\", \"/\" +  dataStreamName + \"/_rollover\");\n+            assertOK(client().performRequest(rolloverRequest3));\n+            verifyDataStream(client(), dataStreamName, backingIndexName(dataStreamName, 1), backingIndexName(dataStreamName, 2),\n+                backingIndexName(dataStreamName, 3));\n+\n+            // TODO: verify that following a backing index for logs-tomcat-prod data stream in remote cluster fails,\n+            // because local data stream isn't a replicated data stream anymore.\n+\n+            // Unfollow .ds-logs-tomcat-prod-000002,\n+            // which is now possible because this index can now be closed as it is no longer the write index.\n+            pauseFollow(backingIndexName(dataStreamName, 2));\n+            closeIndex(backingIndexName(dataStreamName, 2));\n+            unfollow(backingIndexName(dataStreamName, 2));\n+        }\n+        // Cleanup:\n+        {\n+            deleteAutoFollowPattern(\"test_pattern\");\n+            deleteDataStream(dataStreamName);\n+        }\n+    }\n+\n+    public void testRolloverAliasInFollowClusterForbidden() throws Exception {\n+        if (\"follow\".equals(targetCluster) == false) {\n+            return;\n+        }\n+\n+        final int numDocs = 64;\n+        final String aliasName = \"log-tomcat-prod\";\n+\n+        int initialNumberOfSuccessfulFollowedIndices = getNumberOfSuccessfulFollowedIndices();\n+\n+        // Create auto follow pattern\n+        createAutoFollowPattern(client(), \"test_pattern\", \"log-*\", \"leader_cluster\");\n+\n+        // Create leader index and write alias:\n+        {\n+            try (RestClient leaderClient = buildLeaderClient()) {\n+                Request createFirstIndexRequest = new Request(\"PUT\", \"/\" + aliasName + \"-000001\");\n+                createFirstIndexRequest.setJsonEntity(\"{\\\"aliases\\\": {\\\"\" + aliasName + \"\\\":{\\\"is_write_index\\\":true}}}\");\n+                leaderClient.performRequest(createFirstIndexRequest);\n+\n+                for (int i = 0; i < numDocs; i++) {\n+                    Request indexRequest = new Request(\"POST\", \"/\" + aliasName + \"/_doc\");\n+                    indexRequest.addParameter(\"refresh\", \"true\");\n+                    indexRequest.setJsonEntity(\"{\\\"@timestamp\\\": \\\"\" + DATE_FORMAT.format(new Date()) + \"\\\",\\\"message\\\":\\\"abc\\\"}\");\n+                    assertOK(leaderClient.performRequest(indexRequest));\n+                }\n+                verifyAlias(leaderClient, aliasName, true, aliasName + \"-000001\");\n+                verifyDocuments(leaderClient, aliasName, numDocs);\n+            }\n+            assertBusy(() -> {\n+                assertThat(getNumberOfSuccessfulFollowedIndices(), equalTo(initialNumberOfSuccessfulFollowedIndices + 1));\n+                verifyAlias(client(), aliasName, false, aliasName + \"-000001\");\n+                ensureYellow(aliasName);\n+                verifyDocuments(client(), aliasName, numDocs);\n+            });\n+        }\n+\n+        // Rollover in leader cluster and ensure second backing index is replicated:\n+        {\n+            try (RestClient leaderClient = buildLeaderClient()) {\n+                Request rolloverRequest = new Request(\"POST\", \"/\" +  aliasName + \"/_rollover\");\n+                assertOK(leaderClient.performRequest(rolloverRequest));\n+                verifyAlias(leaderClient, aliasName, true, aliasName + \"-000002\", aliasName + \"-000001\");\n+\n+                Request indexRequest = new Request(\"POST\", \"/\" + aliasName + \"/_doc\");\n+                indexRequest.addParameter(\"refresh\", \"true\");\n+                indexRequest.setJsonEntity(\"{\\\"@timestamp\\\": \\\"\" + DATE_FORMAT.format(new Date()) + \"\\\",\\\"message\\\":\\\"abc\\\"}\");\n+                assertOK(leaderClient.performRequest(indexRequest));\n+                verifyDocuments(leaderClient, aliasName, numDocs + 1);\n+            }\n+            assertBusy(() -> {\n+                assertThat(getNumberOfSuccessfulFollowedIndices(), equalTo(initialNumberOfSuccessfulFollowedIndices + 2));\n+                verifyAlias(client(), aliasName, false, aliasName + \"-000002\", aliasName + \"-000001\");\n+                ensureYellow(aliasName);\n+                verifyDocuments(client(), aliasName, numDocs + 1);\n+            });\n+        }\n+\n+        // Try rollover in follow cluster, this should fail, because is_write_index property of an alias isn't\n+        // replicated to follow cluster.\n+        {\n+            Request rolloverRequest1 = new Request(\"POST\", \"/\" +  aliasName + \"/_rollover\");\n+            Exception e = expectThrows(ResponseException.class, () -> client().performRequest(rolloverRequest1));\n+            assertThat(e.getMessage(), containsString(\"rollover target [\" + aliasName + \"] does not point to a write index\"));\n+            verifyAlias(client(), aliasName, false, aliasName + \"-000002\", aliasName + \"-000001\");\n+        }\n+        // Cleanup:\n+        {\n+            deleteAutoFollowPattern(\"test_pattern\");\n+        }\n+    }\n+\n+    private static void verifyAlias(RestClient client,\n+                                    String aliasName,\n+                                    boolean checkWriteIndex,\n+                                    String... otherIndices) throws IOException {\n+        Request getAliasRequest = new Request(\"GET\", \"/_alias/\" + aliasName);\n+        Map<?, ?> responseBody = toMap(client.performRequest(getAliasRequest));\n+        if (checkWriteIndex) {\n+            assertThat(ObjectPath.eval(otherIndices[0] + \".aliases.\" + aliasName + \".is_write_index\", responseBody), is(true));\n+        }\n+        for (String otherIndex : otherIndices) {\n+            assertThat(ObjectPath.eval(otherIndex + \".aliases.\" + aliasName, responseBody), notNullValue());\n+        }\n+    }\n+\n+    public void testDataStreamsBiDirectionalReplication() throws Exception {", "originalCommit": "ef26773e6713eadb03cc781278b4e0ef8b31f763", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzM2ODczMQ==", "url": "https://github.com/elastic/elasticsearch/pull/64710#discussion_r537368731", "bodyText": "Currently an alias can't point to a data stream or its backing indices. So the test can't completely follow the bi directional scenario. I did add a few logs-http* searches to mimic reading from a logs-http alias, as best effort replacement for the fact aliases can't point to data streams.\nWe're planning to add alias support to data streams. These aliases would only be able point to data streams and not to a data stream's backing indices, other indices or other aliases. Like aliases defined on indices, aliases on data stream could also have a write flag, which indicates to which data stream write requests are redirected to. I will add a TODO here, that these searches on logs-http* pattern should be replaced with searches and writes via aliases when alias support for data streams has landed.", "author": "martijnvg", "createdAt": "2020-12-07T09:50:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzIxMDMyMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzU5NzgzMQ==", "url": "https://github.com/elastic/elasticsearch/pull/64710#discussion_r537597831", "bodyText": "We're planning to add alias support to data streams.\n\nThanks for explaning + adding the TODO.", "author": "dnhatn", "createdAt": "2020-12-07T15:30:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzIxMDMyMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDEzNjQzMg==", "url": "https://github.com/elastic/elasticsearch/pull/64710#discussion_r540136432", "bodyText": "@dnhatn I've opened: #66163", "author": "martijnvg", "createdAt": "2020-12-10T12:39:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzIxMDMyMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDE2Nzk0Mg==", "url": "https://github.com/elastic/elasticsearch/pull/64710#discussion_r540167942", "bodyText": "Thanks @martijnvg.", "author": "dnhatn", "createdAt": "2020-12-10T13:28:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzIxMDMyMg=="}], "type": "inlineReview"}, {"oid": "5051eafaa1d01eb80f8d329788124a83ed5709d5", "url": "https://github.com/elastic/elasticsearch/commit/5051eafaa1d01eb80f8d329788124a83ed5709d5", "message": "Merge remote-tracking branch 'es/master' into ccr_data_stream_support_part_2", "committedDate": "2020-12-07T09:03:35Z", "type": "commit"}, {"oid": "676c7a8e04a6af4bdfa3a30fc4bd2214fb3f0dec", "url": "https://github.com/elastic/elasticsearch/commit/676c7a8e04a6af4bdfa3a30fc4bd2214fb3f0dec", "message": "added TODOs", "committedDate": "2020-12-07T09:56:24Z", "type": "commit"}, {"oid": "8e21fc79bd213a5a50f0c9d92060f412c6b32069", "url": "https://github.com/elastic/elasticsearch/commit/8e21fc79bd213a5a50f0c9d92060f412c6b32069", "message": "varify", "committedDate": "2020-12-07T10:08:07Z", "type": "commit"}, {"oid": "9c7a0715e3cf348000265bc2d16215d01c3d3a27", "url": "https://github.com/elastic/elasticsearch/commit/9c7a0715e3cf348000265bc2d16215d01c3d3a27", "message": "mark promote ds api as non operator api", "committedDate": "2020-12-07T14:13:33Z", "type": "commit"}, {"oid": "23c59b8b57ce9d970c029a9abfdfdfa85b0e25a1", "url": "https://github.com/elastic/elasticsearch/commit/23c59b8b57ce9d970c029a9abfdfdfa85b0e25a1", "message": "Merge remote-tracking branch 'es/master' into ccr_data_stream_support_part_2", "committedDate": "2020-12-08T06:36:03Z", "type": "commit"}, {"oid": "a80f77706c4d89c57af2cd2c7a59af148de8434c", "url": "https://github.com/elastic/elasticsearch/commit/a80f77706c4d89c57af2cd2c7a59af148de8434c", "message": "fixed typo", "committedDate": "2020-12-08T06:38:19Z", "type": "commit"}]}