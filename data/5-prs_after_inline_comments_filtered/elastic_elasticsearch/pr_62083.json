{"pr_number": 62083, "pr_title": "QueryPhaseResultConsumer to call notifyPartialReduce", "pr_createdAt": "2020-09-08T10:03:42Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/62083", "timeline": [{"oid": "1600aeeba40fcb286ac5c0903ad02ea1ccfef08a", "url": "https://github.com/elastic/elasticsearch/commit/1600aeeba40fcb286ac5c0903ad02ea1ccfef08a", "message": "QueryPhaseResultConsumer to call notifyPartialReduce\n\nAs part of #60275 QueryPhaseResultConsumer ended up calling SearchProgressListener#onPartialReduce directly instead of notifyPartialReduce. That means we don't catch exceptions that may occur while executing the progress listener callback.\n\nThis commit fix the call and adds a test for this scenario.", "committedDate": "2020-09-08T10:02:31Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDgyNjg2MQ==", "url": "https://github.com/elastic/elasticsearch/pull/62083#discussion_r484826861", "bodyText": "should it be assertNull(onPartialMergeFailure.get()) instead ?", "author": "jimczi", "createdAt": "2020-09-08T10:51:25Z", "path": "server/src/test/java/org/elasticsearch/action/search/QueryPhaseResultConsumerTests.java", "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.action.search;\n+\n+import org.apache.lucene.search.ScoreDoc;\n+import org.apache.lucene.search.TopDocs;\n+import org.apache.lucene.search.TotalHits;\n+import org.elasticsearch.action.OriginalIndices;\n+import org.elasticsearch.common.io.stream.DelayableWriteable;\n+import org.elasticsearch.common.lucene.search.TopDocsAndMaxScore;\n+import org.elasticsearch.common.util.BigArrays;\n+import org.elasticsearch.common.util.concurrent.EsExecutors;\n+import org.elasticsearch.common.util.concurrent.EsThreadPoolExecutor;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.SearchShardTarget;\n+import org.elasticsearch.search.aggregations.InternalAggregation;\n+import org.elasticsearch.search.aggregations.InternalAggregations;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.query.QuerySearchResult;\n+import org.elasticsearch.test.ESTestCase;\n+import org.elasticsearch.threadpool.TestThreadPool;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.junit.After;\n+import org.junit.Before;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+public class QueryPhaseResultConsumerTests extends ESTestCase {\n+\n+    private SearchPhaseController searchPhaseController;\n+    private ThreadPool threadPool;\n+    private EsThreadPoolExecutor executor;\n+\n+    @Before\n+    public void setup() {\n+        searchPhaseController = new SearchPhaseController(writableRegistry(),\n+            s -> new InternalAggregation.ReduceContextBuilder() {\n+                @Override\n+                public InternalAggregation.ReduceContext forPartialReduction() {\n+                    return InternalAggregation.ReduceContext.forPartialReduction(\n+                        BigArrays.NON_RECYCLING_INSTANCE, null, () -> PipelineAggregator.PipelineTree.EMPTY);\n+                }\n+\n+                public InternalAggregation.ReduceContext forFinalReduction() {\n+                    return InternalAggregation.ReduceContext.forFinalReduction(\n+                        BigArrays.NON_RECYCLING_INSTANCE, null, b -> {}, PipelineAggregator.PipelineTree.EMPTY);\n+                };\n+            });\n+        threadPool = new TestThreadPool(SearchPhaseControllerTests.class.getName());\n+        executor = EsExecutors.newFixed(\"test\", 1, 10,\n+            EsExecutors.daemonThreadFactory(\"test\"), threadPool.getThreadContext(), randomBoolean());\n+\n+    }\n+\n+    @After\n+    public void cleanup() {\n+        executor.shutdownNow();\n+        terminate(threadPool);\n+    }\n+\n+    public void testProgressListenerExceptionsAreCaught() throws Exception {\n+\n+        ThrowingSearchProgressListener searchProgressListener = new ThrowingSearchProgressListener();\n+\n+        List<SearchShard> searchShards = new ArrayList<>();\n+        for (int i = 0; i < 10; i++) {\n+            searchShards.add(new SearchShard(null, new ShardId(\"index\", \"uuid\", i)));\n+        }\n+        searchProgressListener.notifyListShards(searchShards, Collections.emptyList(), SearchResponse.Clusters.EMPTY, false);\n+\n+        SearchRequest searchRequest = new SearchRequest(\"index\");\n+        searchRequest.setBatchedReduceSize(2);\n+        AtomicReference<Exception> onPartialMergeFailure = new AtomicReference<>();\n+        QueryPhaseResultConsumer queryPhaseResultConsumer = new QueryPhaseResultConsumer(searchRequest, executor, searchPhaseController,\n+            searchProgressListener, writableRegistry(), 10, e -> onPartialMergeFailure.accumulateAndGet(e, (prev, curr) -> {\n+                curr.addSuppressed(prev);\n+                return curr;\n+            }));\n+\n+        CountDownLatch partialReduceLatch = new CountDownLatch(10);\n+\n+        for (int i = 0; i < 10; i++) {\n+            SearchShardTarget searchShardTarget = new SearchShardTarget(\"node\", new ShardId(\"index\", \"uuid\", i),\n+                null, OriginalIndices.NONE);\n+            QuerySearchResult querySearchResult = new QuerySearchResult();\n+            TopDocs topDocs = new TopDocs(new TotalHits(0, TotalHits.Relation.EQUAL_TO), new ScoreDoc[0]);\n+            querySearchResult.topDocs(new TopDocsAndMaxScore(topDocs, Float.NaN), new DocValueFormat[0]);\n+            querySearchResult.setSearchShardTarget(searchShardTarget);\n+            querySearchResult.setShardIndex(i);\n+            queryPhaseResultConsumer.consumeResult(querySearchResult, partialReduceLatch::countDown);\n+        }\n+\n+        assertEquals(10, searchProgressListener.onQueryResult.get());\n+        assertTrue(partialReduceLatch.await(10, TimeUnit.SECONDS));\n+        if (onPartialMergeFailure.get() != null) {\n+            throw onPartialMergeFailure.get();", "originalCommit": "1600aeeba40fcb286ac5c0903ad02ea1ccfef08a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDg1MDUyNQ==", "url": "https://github.com/elastic/elasticsearch/pull/62083#discussion_r484850525", "bodyText": "yea that's ok too, I just needed to see the stacktrace when this happened :)", "author": "javanna", "createdAt": "2020-09-08T11:39:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDgyNjg2MQ=="}], "type": "inlineReview"}, {"oid": "6ffe81e455f01d9153f653d763cd5d9751a0b9f6", "url": "https://github.com/elastic/elasticsearch/commit/6ffe81e455f01d9153f653d763cd5d9751a0b9f6", "message": "iter", "committedDate": "2020-09-08T11:46:49Z", "type": "commit"}]}