{"pr_number": 57573, "pr_title": "Add memory tracking to queued write operations", "pr_createdAt": "2020-06-03T00:53:53Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/57573", "timeline": [{"oid": "d7265e6b396779670383976b98f25a2987dcc5cd", "url": "https://github.com/elastic/elasticsearch/commit/d7265e6b396779670383976b98f25a2987dcc5cd", "message": "Add post indexing hooks", "committedDate": "2020-04-13T21:53:10Z", "type": "commit"}, {"oid": "0a782cd30cc2e32e54d8452323133672fa091d74", "url": "https://github.com/elastic/elasticsearch/commit/0a782cd30cc2e32e54d8452323133672fa091d74", "message": "Add post indexing hooks", "committedDate": "2020-04-13T22:42:00Z", "type": "commit"}, {"oid": "84279ee0629822a5fa9cdf8b61040ce8ee2196a8", "url": "https://github.com/elastic/elasticsearch/commit/84279ee0629822a5fa9cdf8b61040ce8ee2196a8", "message": "Changes", "committedDate": "2020-04-13T22:58:20Z", "type": "commit"}, {"oid": "9ba9a1a9aa21ee9548347cd33159ec7adb878e44", "url": "https://github.com/elastic/elasticsearch/commit/9ba9a1a9aa21ee9548347cd33159ec7adb878e44", "message": "Merge remote-tracking branch 'upstream/master' into indexing_memory_queue", "committedDate": "2020-04-16T16:02:46Z", "type": "commit"}, {"oid": "c9ad59c3a518bce7e3f80d69c285fe2cb31cd213", "url": "https://github.com/elastic/elasticsearch/commit/c9ad59c3a518bce7e3f80d69c285fe2cb31cd213", "message": "Changes", "committedDate": "2020-04-16T20:30:46Z", "type": "commit"}, {"oid": "d0e108183420a1bb95883c586af426a9868b8293", "url": "https://github.com/elastic/elasticsearch/commit/d0e108183420a1bb95883c586af426a9868b8293", "message": "Add tests", "committedDate": "2020-04-17T00:30:48Z", "type": "commit"}, {"oid": "8a0a56081a8a1af15c9d1c9307c32af0f71209eb", "url": "https://github.com/elastic/elasticsearch/commit/8a0a56081a8a1af15c9d1c9307c32af0f71209eb", "message": "Changes", "committedDate": "2020-04-17T00:38:24Z", "type": "commit"}, {"oid": "08810d6c73f03a52fb257f3e94181fe029105d84", "url": "https://github.com/elastic/elasticsearch/commit/08810d6c73f03a52fb257f3e94181fe029105d84", "message": "Merge remote-tracking branch 'upstream/master' into indexing_memory_queue", "committedDate": "2020-04-29T19:48:15Z", "type": "commit"}, {"oid": "b0a6568e55a553dde1e3b70085814f86fc2f762f", "url": "https://github.com/elastic/elasticsearch/commit/b0a6568e55a553dde1e3b70085814f86fc2f762f", "message": "Changes", "committedDate": "2020-04-29T23:47:04Z", "type": "commit"}, {"oid": "dcfb545eda063dc9306e9c47376c20760855c828", "url": "https://github.com/elastic/elasticsearch/commit/dcfb545eda063dc9306e9c47376c20760855c828", "message": "Changes", "committedDate": "2020-04-30T00:01:37Z", "type": "commit"}, {"oid": "bdf3bd663fdda50de901142592e0706080f6268c", "url": "https://github.com/elastic/elasticsearch/commit/bdf3bd663fdda50de901142592e0706080f6268c", "message": "Merge remote-tracking branch 'upstream/master' into indexing_memory_queue", "committedDate": "2020-05-12T17:44:17Z", "type": "commit"}, {"oid": "755a6cbd6f0be54917e66cc7fca76217870597dd", "url": "https://github.com/elastic/elasticsearch/commit/755a6cbd6f0be54917e66cc7fca76217870597dd", "message": "Move", "committedDate": "2020-05-12T18:47:09Z", "type": "commit"}, {"oid": "a6bf50ebd82cfb67aa1129e1cb64b914bc4f192d", "url": "https://github.com/elastic/elasticsearch/commit/a6bf50ebd82cfb67aa1129e1cb64b914bc4f192d", "message": "Merge remote-tracking branch 'upstream/master' into indexing_memory_queue", "committedDate": "2020-05-12T19:22:40Z", "type": "commit"}, {"oid": "c54ba33cecbf89583caae5d86010769060a21831", "url": "https://github.com/elastic/elasticsearch/commit/c54ba33cecbf89583caae5d86010769060a21831", "message": "Merge remote-tracking branch 'upstream/master' into indexing_memory_queue", "committedDate": "2020-05-13T15:34:41Z", "type": "commit"}, {"oid": "2ccb5b6070bb1c11bbf5b68ddda0405529a43efd", "url": "https://github.com/elastic/elasticsearch/commit/2ccb5b6070bb1c11bbf5b68ddda0405529a43efd", "message": "Changes", "committedDate": "2020-05-13T21:48:44Z", "type": "commit"}, {"oid": "524b965161b7d76ac698c10d0d5d9cad3b256662", "url": "https://github.com/elastic/elasticsearch/commit/524b965161b7d76ac698c10d0d5d9cad3b256662", "message": "Remove", "committedDate": "2020-05-13T21:50:45Z", "type": "commit"}, {"oid": "de3bed7a2dd45cc3cf9af4a28f72faf9881360e5", "url": "https://github.com/elastic/elasticsearch/commit/de3bed7a2dd45cc3cf9af4a28f72faf9881360e5", "message": "Merge remote-tracking branch 'upstream/master' into indexing_memory_queue", "committedDate": "2020-05-19T18:06:18Z", "type": "commit"}, {"oid": "a9afc77d8f0f3c512ba6dd35ef3f88fdb6b6ccdc", "url": "https://github.com/elastic/elasticsearch/commit/a9afc77d8f0f3c512ba6dd35ef3f88fdb6b6ccdc", "message": "WIP", "committedDate": "2020-05-19T19:19:57Z", "type": "commit"}, {"oid": "832dec023f53482336ab9454c29d7635b8daf9d8", "url": "https://github.com/elastic/elasticsearch/commit/832dec023f53482336ab9454c29d7635b8daf9d8", "message": "Changes", "committedDate": "2020-05-19T19:39:03Z", "type": "commit"}, {"oid": "275df87635615769bffd679825a77ffc8e6d24f3", "url": "https://github.com/elastic/elasticsearch/commit/275df87635615769bffd679825a77ffc8e6d24f3", "message": "WIP", "committedDate": "2020-05-19T19:50:34Z", "type": "commit"}, {"oid": "87af5561c04854509d74660d79037615d1870dc4", "url": "https://github.com/elastic/elasticsearch/commit/87af5561c04854509d74660d79037615d1870dc4", "message": "Changes", "committedDate": "2020-05-19T20:18:43Z", "type": "commit"}, {"oid": "a15fcece388c32b6f53fc697fd176f073b0392c2", "url": "https://github.com/elastic/elasticsearch/commit/a15fcece388c32b6f53fc697fd176f073b0392c2", "message": "Merge remote-tracking branch 'upstream/master' into indexing_memory_queue2", "committedDate": "2020-05-26T20:51:31Z", "type": "commit"}, {"oid": "185c24cf85126e3f714c179788f6d281a19571d9", "url": "https://github.com/elastic/elasticsearch/commit/185c24cf85126e3f714c179788f6d281a19571d9", "message": "Changes", "committedDate": "2020-05-26T22:18:22Z", "type": "commit"}, {"oid": "f9723be2eed9509bed42b8456d3ec0b65ed875a6", "url": "https://github.com/elastic/elasticsearch/commit/f9723be2eed9509bed42b8456d3ec0b65ed875a6", "message": "Merge remote-tracking branch 'upstream/master' into indexing_memory_queue2", "committedDate": "2020-05-27T17:16:09Z", "type": "commit"}, {"oid": "7160c1eb2b4d87ed1ad2517c78cf880d84af1dc6", "url": "https://github.com/elastic/elasticsearch/commit/7160c1eb2b4d87ed1ad2517c78cf880d84af1dc6", "message": "Merge remote-tracking branch 'upstream/master' into indexing_memory_queue2", "committedDate": "2020-05-29T16:14:29Z", "type": "commit"}, {"oid": "eaa6eaadef67ed1fdfdf2030c233d7a032f36495", "url": "https://github.com/elastic/elasticsearch/commit/eaa6eaadef67ed1fdfdf2030c233d7a032f36495", "message": "Change", "committedDate": "2020-05-29T21:40:30Z", "type": "commit"}, {"oid": "718e343e4a50aa3aae8eaae526043fcee455e153", "url": "https://github.com/elastic/elasticsearch/commit/718e343e4a50aa3aae8eaae526043fcee455e153", "message": "Changes", "committedDate": "2020-05-29T22:28:47Z", "type": "commit"}, {"oid": "668715ea626a8aec3583b5460995f5128a155ba4", "url": "https://github.com/elastic/elasticsearch/commit/668715ea626a8aec3583b5460995f5128a155ba4", "message": "WIP", "committedDate": "2020-05-29T23:04:37Z", "type": "commit"}, {"oid": "fa52955a4a8458bcda4f70cc91afbb1e2e38d1b3", "url": "https://github.com/elastic/elasticsearch/commit/fa52955a4a8458bcda4f70cc91afbb1e2e38d1b3", "message": "Merge remote-tracking branch 'upstream/master' into indexing_memory_queue2_only_stats", "committedDate": "2020-06-01T22:59:28Z", "type": "commit"}, {"oid": "bc76b9a1c9cc890ca9441e73ef5ae6e73e66242c", "url": "https://github.com/elastic/elasticsearch/commit/bc76b9a1c9cc890ca9441e73ef5ae6e73e66242c", "message": "Changes", "committedDate": "2020-06-03T00:26:04Z", "type": "commit"}, {"oid": "96157138f1fcc41be4f64256a1b48eb2cfbee2e2", "url": "https://github.com/elastic/elasticsearch/commit/96157138f1fcc41be4f64256a1b48eb2cfbee2e2", "message": "Merge remote-tracking branch 'upstream/master' into indexing_memory_queue2_only_stats", "committedDate": "2020-06-03T00:26:14Z", "type": "commit"}, {"oid": "2b581b547921cc7bfc9b29ce8d6e9751a4d7d3ea", "url": "https://github.com/elastic/elasticsearch/commit/2b581b547921cc7bfc9b29ce8d6e9751a4d7d3ea", "message": "Changes", "committedDate": "2020-06-03T00:49:50Z", "type": "commit"}, {"oid": "d5aaf0e220ac8b717f8cbbd8f9a5cd095ed38ab8", "url": "https://github.com/elastic/elasticsearch/commit/d5aaf0e220ac8b717f8cbbd8f9a5cd095ed38ab8", "message": "Delete", "committedDate": "2020-06-03T01:04:05Z", "type": "commit"}, {"oid": "777569a12a1f7c5dc5cc69216767c9d9c53c34e5", "url": "https://github.com/elastic/elasticsearch/commit/777569a12a1f7c5dc5cc69216767c9d9c53c34e5", "message": "Move", "committedDate": "2020-06-03T01:21:47Z", "type": "commit"}, {"oid": "31459dcb2cdf23dd2a03228601feb2ae56dfdb9b", "url": "https://github.com/elastic/elasticsearch/commit/31459dcb2cdf23dd2a03228601feb2ae56dfdb9b", "message": "Change", "committedDate": "2020-06-03T01:36:34Z", "type": "commit"}, {"oid": "903ed490304aa6b853deb542ffec14bc3b3146f7", "url": "https://github.com/elastic/elasticsearch/commit/903ed490304aa6b853deb542ffec14bc3b3146f7", "message": "Change", "committedDate": "2020-06-03T02:06:02Z", "type": "commit"}, {"oid": "18a62cbf78eaa992cb00343a050bb0510dddc520", "url": "https://github.com/elastic/elasticsearch/commit/18a62cbf78eaa992cb00343a050bb0510dddc520", "message": "Merge remote-tracking branch 'upstream/master' into indexing_memory_queue2_only_stats", "committedDate": "2020-06-03T16:24:55Z", "type": "commit"}, {"oid": "dfe5e8e71f026f029cc9f047ff2d657f69eb7ca5", "url": "https://github.com/elastic/elasticsearch/commit/dfe5e8e71f026f029cc9f047ff2d657f69eb7ca5", "message": "Changes", "committedDate": "2020-06-03T17:05:51Z", "type": "commit"}, {"oid": "7708977b9e9c8cec44ebc7cb541637b725536155", "url": "https://github.com/elastic/elasticsearch/commit/7708977b9e9c8cec44ebc7cb541637b725536155", "message": "Tests", "committedDate": "2020-06-03T21:00:40Z", "type": "commit"}, {"oid": "26dcf334ff8b26e02a56d16f6574f2b20545b4d1", "url": "https://github.com/elastic/elasticsearch/commit/26dcf334ff8b26e02a56d16f6574f2b20545b4d1", "message": "Merge remote-tracking branch 'upstream/master' into indexing_memory_queue2_only_stats", "committedDate": "2020-06-03T21:44:24Z", "type": "commit"}, {"oid": "5295df9ac235e37c3b36970edff4d5df2e675aae", "url": "https://github.com/elastic/elasticsearch/commit/5295df9ac235e37c3b36970edff4d5df2e675aae", "message": "Changes", "committedDate": "2020-06-03T21:46:24Z", "type": "commit"}, {"oid": "2227059ff6e0d8f3e3d8f98f86098635ba90fb9b", "url": "https://github.com/elastic/elasticsearch/commit/2227059ff6e0d8f3e3d8f98f86098635ba90fb9b", "message": "Mute tests", "committedDate": "2020-06-03T21:59:30Z", "type": "commit"}, {"oid": "1e421f08dab1cea387cbfb91464ac9705973d918", "url": "https://github.com/elastic/elasticsearch/commit/1e421f08dab1cea387cbfb91464ac9705973d918", "message": "Changes", "committedDate": "2020-06-04T01:38:27Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTg5MDM3Nw==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r435890377", "bodyText": "how do we protect from double-accounting the bulk request / bulk shard requests after it has run through the ingestService?\nAlso, in  case where we forward the bulk request (see forwardIngestRequest), we can probably stop accounting for the bytes of the  original bulk request as soon as the request is sent.", "author": "ywelsch", "createdAt": "2020-06-05T12:33:08Z", "path": "server/src/main/java/org/elasticsearch/action/bulk/TransportBulkAction.java", "diffHunk": "@@ -699,7 +715,7 @@ public void onFailure(Exception e) {\n \n                                 @Override\n                                 protected void doRun() throws Exception {\n-                                    doExecute(task, bulkRequest, actionListener);\n+                                    doDispatchedExecute(task, bulkRequest, actionListener);", "originalCommit": "1e421f08dab1cea387cbfb91464ac9705973d918", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA1OTkwOQ==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r437059909", "bodyText": "We avoid double accounting because on callback we call doInternalExecute vs. doExecute. doInternalExecute does not account.\n\nAlso, in case where we forward the bulk request (see forwardIngestRequest), we can probably stop accounting for the bytes of the original bulk request as soon as the request is sent.\n\nI'm not sure I understand the logic here. How is this different than the node acting as coordinator node for a normal indexing request? Once we forward a request to a primary we are done until we have to forward the response.", "author": "tbrooks8", "createdAt": "2020-06-08T23:43:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTg5MDM3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzM4OTYwNQ==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r437389605", "bodyText": "I'm not sure I understand the logic here. How is this different than the node acting as coordinator node for a normal indexing request? Once we forward a request to a primary we are done until we have to forward the response.\n\nIn this case where we forward the bulk request to another ingest node, we're actually not holding onto the request bytes anymore (as there is no retry mechanism at this level), so we could in theory stop accounting for it. I'm not sure yet though if this optimization is relevant at this point, or whether we want to make this more resilient and introduce retries at this level as well.", "author": "ywelsch", "createdAt": "2020-06-09T12:55:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTg5MDM3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc5NjU2MQ==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r437796561", "bodyText": "Sure, but we are stilling holding the bytes. Particularly if we are doing the \"unsafe\" thing at the http level.\nWe could not mark the bytes at the TransportBulkAction level if you prefer. For example, we still would mark the coordinating bytes at the TransportShardBulkAction level. Or we could just mark bytes for actual ingest work. And then unmark when we are done (they will be marked again once we become the coordinating node).", "author": "tbrooks8", "createdAt": "2020-06-10T00:36:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTg5MDM3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzk1NzI3Ng==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r437957276", "bodyText": "I prefer the extra marking (i.e. err on the side of overaccounting instead of underaccounting). If we don't mark at the TransportBulkAction level, then we won't account for requests that are waiting on auto-index creations or local ingest pipeline transformations. Let's keep this as is for now.", "author": "ywelsch", "createdAt": "2020-06-10T08:37:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTg5MDM3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTg5NDg3OA==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r435894878", "bodyText": "we need to take forceExecutionOnPrimary into account here, right?", "author": "ywelsch", "createdAt": "2020-06-05T12:41:59Z", "path": "server/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java", "diffHunk": "@@ -273,12 +275,31 @@ boolean isRetryableClusterBlockException(final Throwable e) {\n     }\n \n     protected void handleOperationRequest(final Request request, final TransportChannel channel, Task task) {\n-        execute(task, request, new ChannelActionListener<>(channel, actionName, request));\n+        Releasable releasable = checkOperationLimits(request);\n+        ActionListener<Response> listener =\n+            ActionListener.runAfter(new ChannelActionListener<>(channel, actionName, request), releasable::close);\n+        execute(task, request, listener);\n+    }\n+\n+    protected Releasable checkOperationLimits(final Request request) {\n+        return () -> {};\n     }\n \n     protected void handlePrimaryRequest(final ConcreteShardRequest<Request> request, final TransportChannel channel, final Task task) {\n-        new AsyncPrimaryAction(\n-            request, new ChannelActionListener<>(channel, transportPrimaryAction, request), (ReplicationTask) task).run();\n+        Releasable releasable = checkPrimaryLimits(request.getRequest());\n+        ActionListener<Response> listener =\n+            ActionListener.runAfter(new ChannelActionListener<>(channel, transportPrimaryAction, request), releasable::close);\n+\n+        threadPool.executor(executor).execute(new ActionRunnable<>(listener) {", "originalCommit": "1e421f08dab1cea387cbfb91464ac9705973d918", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTg5NjIwMA==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r435896200", "bodyText": "not needed at this point", "author": "ywelsch", "createdAt": "2020-06-05T12:44:26Z", "path": "server/src/main/java/org/elasticsearch/common/breaker/CircuitBreaker.java", "diffHunk": "@@ -60,6 +60,8 @@\n      * segments.\n      */\n     String ACCOUNTING = \"accounting\";\n+    // TODO: Description\n+    String INDEXING = \"indexing\";", "originalCommit": "1e421f08dab1cea387cbfb91464ac9705973d918", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTg5OTQ2Mw==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r435899463", "bodyText": "Why is using forceExecutionOnPrimary still necessary here?", "author": "ywelsch", "createdAt": "2020-06-05T12:50:37Z", "path": "server/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java", "diffHunk": "@@ -160,11 +161,11 @@ protected TransportReplicationAction(Settings settings, String actionName, Trans\n \n         transportService.registerRequestHandler(actionName, ThreadPool.Names.SAME, requestReader, this::handleOperationRequest);\n \n-        transportService.registerRequestHandler(transportPrimaryAction, executor, forceExecutionOnPrimary, true,\n+        transportService.registerRequestHandler(transportPrimaryAction, ThreadPool.Names.SAME, forceExecutionOnPrimary, true,", "originalCommit": "1e421f08dab1cea387cbfb91464ac9705973d918", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTkwMTYwNw==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r435901607", "bodyText": "why are we passing SAME upwards here? Isn't TRA already executing the actions under SAME?\nWhy are we doing similar kind of manual dispatch logic that already exists in TRA? I think I'm missing something here", "author": "ywelsch", "createdAt": "2020-06-05T12:54:30Z", "path": "server/src/main/java/org/elasticsearch/action/support/replication/TransportWriteAction.java", "diffHunk": "@@ -57,12 +60,50 @@\n             Response extends ReplicationResponse & WriteResponse\n         > extends TransportReplicationAction<Request, ReplicaRequest, Response> {\n \n+    private final WriteMemoryLimits writeMemoryLimits;\n+    private final String executor;\n+\n     protected TransportWriteAction(Settings settings, String actionName, TransportService transportService,\n                                    ClusterService clusterService, IndicesService indicesService, ThreadPool threadPool,\n                                    ShardStateAction shardStateAction, ActionFilters actionFilters, Writeable.Reader<Request> request,\n-                                   Writeable.Reader<ReplicaRequest> replicaRequest, String executor, boolean forceExecutionOnPrimary) {\n+                                   Writeable.Reader<ReplicaRequest> replicaRequest, String executor, boolean forceExecutionOnPrimary,\n+                                   WriteMemoryLimits writeMemoryLimits) {\n         super(settings, actionName, transportService, clusterService, indicesService, threadPool, shardStateAction, actionFilters,\n-              request, replicaRequest, executor, true, forceExecutionOnPrimary);\n+            request, replicaRequest, ThreadPool.Names.SAME, true, forceExecutionOnPrimary);", "originalCommit": "1e421f08dab1cea387cbfb91464ac9705973d918", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA2MDA5Mg==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r437060092", "bodyText": "This was a mistake. We are passing the SAME up because TransportWriteAction is where we dispatch. I have fixed it now.", "author": "tbrooks8", "createdAt": "2020-06-08T23:44:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTkwMTYwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTkwMTk5Mw==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r435901993", "bodyText": "Should this be TransportChannel.class?", "author": "ywelsch", "createdAt": "2020-06-05T12:55:11Z", "path": "server/src/main/java/org/elasticsearch/transport/TransportChannel.java", "diffHunk": "@@ -28,6 +32,8 @@\n  */\n public interface TransportChannel {\n \n+    Logger logger = LogManager.getLogger(ChannelActionListener.class);", "originalCommit": "1e421f08dab1cea387cbfb91464ac9705973d918", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTkwMzc0OQ==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r435903749", "bodyText": "No directly relevant to this PR, but I think we could implement Lucene's Accountable on DocWriteRequest, and possibly get a more accurate estimate with its helpers.", "author": "ywelsch", "createdAt": "2020-06-05T12:58:34Z", "path": "server/src/main/java/org/elasticsearch/action/DocWriteRequest.java", "diffHunk": "@@ -256,4 +257,20 @@ static ActionRequestValidationException validateSeqNoBasedCASParams(\n \n         return validationException;\n     }\n+\n+    static long writeSizeInBytes(Stream<DocWriteRequest<?>> requestStream) {", "originalCommit": "1e421f08dab1cea387cbfb91464ac9705973d918", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODczOTU0NQ==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r438739545", "bodyText": "I wonder if getting a more precise estimate out should be part of this PR or a follow-up? I would think the end-goal need to include a more precise estimate and we need to examine the overhead of calculating that?", "author": "henningandersen", "createdAt": "2020-06-11T12:15:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTkwMzc0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODg1NzcyNA==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r438857724", "bodyText": "Just to clarify what I meant here (@henningandersen asked), I was refering to utility methods such as RamUsageEstimator.shallowSizeOfInstance and others here that can give a more accurate estimate of how much memory an object is actually taking up.", "author": "ywelsch", "createdAt": "2020-06-11T15:10:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTkwMzc0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDg1NTc1Mw==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r440855753", "bodyText": "I think we can do this in a follow-up", "author": "ywelsch", "createdAt": "2020-06-16T13:37:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTkwMzc0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDc1MjA3OQ==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r444752079", "bodyText": "Is this method still useful now that we use the accountable interface? Let's have BulkShardRequest implement Accountable as well, and then use that directly instead of this method", "author": "ywelsch", "createdAt": "2020-06-24T09:05:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTkwMzc0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTkwNzg1NA==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r435907854", "bodyText": "worth noting that for users of the REST API (including our client such as beats, logstash, etc.) there's now a chance that they get a ESRejectedExecution at the full bulk level, not only at the bulk shard item level. We'll need to double-check that this is properly handled. I'm also wondering if we want to directly fork to the write thread pool at this point, or whether we want to keep executing on the http thread (as we used to) or transport thread (as we also used to).\nFinally, the threadpool change in IngestService.executeBulkRequest is no longer necessary if we go with this change here, as we are already on the write thread pool.", "author": "ywelsch", "createdAt": "2020-06-05T13:05:56Z", "path": "server/src/main/java/org/elasticsearch/action/bulk/TransportBulkAction.java", "diffHunk": "@@ -155,6 +158,18 @@ public static IndexRequest getIndexWriteRequest(DocWriteRequest docWriteRequest)\n \n     @Override\n     protected void doExecute(Task task, BulkRequest bulkRequest, ActionListener<BulkResponse> listener) {\n+        long indexingBytes = DocWriteRequest.writeSizeInBytes(bulkRequest.requests.stream());\n+        final Releasable releasable = writeMemoryLimits.markCoordinatingOperationStarted(indexingBytes);\n+        final ActionListener<BulkResponse> releasingListener = ActionListener.runAfter(listener, releasable::close);\n+        threadPool.executor(ThreadPool.Names.WRITE).execute(new ActionRunnable<>(releasingListener) {", "originalCommit": "1e421f08dab1cea387cbfb91464ac9705973d918", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA2MDIyMA==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r437060220", "bodyText": "I backed out the dispatching. I tend to think we do not need to dispatch in the coordinating only case.", "author": "tbrooks8", "createdAt": "2020-06-08T23:44:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTkwNzg1NA=="}], "type": "inlineReview"}, {"oid": "44552036afcc70f3991828d9fb5532de475589a7", "url": "https://github.com/elastic/elasticsearch/commit/44552036afcc70f3991828d9fb5532de475589a7", "message": "Merge remote-tracking branch 'upstream/master' into indexing_memory_queue2_only_stats", "committedDate": "2020-06-08T23:29:21Z", "type": "commit"}, {"oid": "d461c36e07ee613580ab6a430d96769eb00c7c6a", "url": "https://github.com/elastic/elasticsearch/commit/d461c36e07ee613580ab6a430d96769eb00c7c6a", "message": "WIP", "committedDate": "2020-06-09T00:12:14Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzM2ODA0OQ==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r437368049", "bodyText": "why is this test deactivated?", "author": "ywelsch", "createdAt": "2020-06-09T12:24:29Z", "path": "server/src/internalClusterTest/java/org/elasticsearch/action/admin/cluster/node/tasks/TaskStorageRetryIT.java", "diffHunk": "@@ -41,6 +42,7 @@\n  * Makes sure that tasks that attempt to store themselves on completion retry if\n  * they don't succeed at first.\n  */\n+@LuceneTestCase.AwaitsFix(bugUrl = \"\")", "originalCommit": "d461c36e07ee613580ab6a430d96769eb00c7c6a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzM2ODIxMg==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r437368212", "bodyText": "why is this test deactivated?", "author": "ywelsch", "createdAt": "2020-06-09T12:24:39Z", "path": "server/src/internalClusterTest/java/org/elasticsearch/action/bulk/BulkProcessorRetryIT.java", "diffHunk": "@@ -40,6 +41,7 @@\n import static org.hamcrest.Matchers.lessThan;\n import static org.hamcrest.Matchers.lessThanOrEqualTo;\n \n+@LuceneTestCase.AwaitsFix(bugUrl = \"\")", "originalCommit": "d461c36e07ee613580ab6a430d96769eb00c7c6a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzM3OTI0Nw==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r437379247", "bodyText": "This method name reads a bit funky", "author": "ywelsch", "createdAt": "2020-06-09T12:38:32Z", "path": "server/src/main/java/org/elasticsearch/action/bulk/TransportShardBulkAction.java", "diffHunk": "@@ -110,7 +112,17 @@ protected BulkShardResponse newResponseInstance(StreamInput in) throws IOExcepti\n     }\n \n     @Override\n-    protected void shardOperationOnPrimary(BulkShardRequest request, IndexShard primary,\n+    protected boolean coordinatingBytesNeedAccounted(BulkShardRequest request) {", "originalCommit": "d461c36e07ee613580ab6a430d96769eb00c7c6a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzM4NDEwNw==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r437384107", "bodyText": "what if shardOperationOnReplica throws an exception? We're not releasing the releasable then?", "author": "ywelsch", "createdAt": "2020-06-09T12:46:30Z", "path": "server/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java", "diffHunk": "@@ -531,30 +552,28 @@ public RetryOnReplicaException(StreamInput in) throws IOException {\n \n         @Override\n         public void onResponse(Releasable releasable) {\n-            try {\n-                assert replica.getActiveOperationsCount() != 0 : \"must perform shard operation under a permit\";\n-                final ReplicaResult replicaResult = shardOperationOnReplica(replicaRequest.getRequest(), replica);\n+            assert replica.getActiveOperationsCount() != 0 : \"must perform shard operation under a permit\";\n+            shardOperationOnReplica(replicaRequest.getRequest(), replica, ActionListener.wrap((replicaResult) ->", "originalCommit": "d461c36e07ee613580ab6a430d96769eb00c7c6a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzM4NTUzMw==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r437385533", "bodyText": "This will call writeMemoryLimits.markPrimaryOperationStarted(0) for those actions where we possibly don't want to do accounting (and breaking) for. I wonder if this will lead to confusion, and we might start rejecting requests later when size = 0 but we are already above whatever memory threshold we define.", "author": "ywelsch", "createdAt": "2020-06-09T12:48:52Z", "path": "server/src/main/java/org/elasticsearch/action/support/replication/TransportWriteAction.java", "diffHunk": "@@ -57,12 +60,52 @@\n             Response extends ReplicationResponse & WriteResponse\n         > extends TransportReplicationAction<Request, ReplicaRequest, Response> {\n \n+    private final boolean forceExecutionOnPrimary;\n+    private final WriteMemoryLimits writeMemoryLimits;\n+    private final String executor;\n+\n     protected TransportWriteAction(Settings settings, String actionName, TransportService transportService,\n                                    ClusterService clusterService, IndicesService indicesService, ThreadPool threadPool,\n                                    ShardStateAction shardStateAction, ActionFilters actionFilters, Writeable.Reader<Request> request,\n-                                   Writeable.Reader<ReplicaRequest> replicaRequest, String executor, boolean forceExecutionOnPrimary) {\n+                                   Writeable.Reader<ReplicaRequest> replicaRequest, String executor, boolean forceExecutionOnPrimary,\n+                                   WriteMemoryLimits writeMemoryLimits) {\n         super(settings, actionName, transportService, clusterService, indicesService, threadPool, shardStateAction, actionFilters,\n-              request, replicaRequest, executor, true, forceExecutionOnPrimary);\n+            request, replicaRequest, ThreadPool.Names.SAME, true, forceExecutionOnPrimary);\n+        this.executor = executor;\n+        this.forceExecutionOnPrimary = forceExecutionOnPrimary;\n+        this.writeMemoryLimits = writeMemoryLimits;\n+    }\n+\n+    @Override\n+    protected Releasable checkOperationLimits(Request request) {\n+        if (coordinatingBytesNeedAccounted(request)) {\n+            long operationSizeInBytes = primaryOperationSize(request);\n+            return writeMemoryLimits.markCoordinatingOperationStarted(operationSizeInBytes);\n+        } else {\n+            return () -> {};\n+        }\n+    }\n+\n+    protected boolean coordinatingBytesNeedAccounted(Request request) {\n+        return false;\n+    }\n+\n+    @Override\n+    protected Releasable checkPrimaryLimits(Request request) {\n+        return writeMemoryLimits.markPrimaryOperationStarted(primaryOperationSize(request));\n+    }\n+\n+    protected long primaryOperationSize(Request request) {\n+        return 0;", "originalCommit": "d461c36e07ee613580ab6a430d96769eb00c7c6a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc5NTcxNg==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r437795716", "bodyText": "I thought we want to account some for every op? I understand that we might need special logic to allow things when we implement rejections.", "author": "tbrooks8", "createdAt": "2020-06-10T00:32:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzM4NTUzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzk1NDk4Mw==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r437954983", "bodyText": "ok, let's move this discussion to a follow-up PR where we introduce rejections. I'm mostly worried that we would forget about the callers that are using 0", "author": "ywelsch", "createdAt": "2020-06-10T08:34:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzM4NTUzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzM4NjAzOA==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r437386038", "bodyText": "add a comment here to SAME that we are manually dispatching here.", "author": "ywelsch", "createdAt": "2020-06-09T12:49:40Z", "path": "server/src/main/java/org/elasticsearch/action/support/replication/TransportWriteAction.java", "diffHunk": "@@ -57,12 +60,52 @@\n             Response extends ReplicationResponse & WriteResponse\n         > extends TransportReplicationAction<Request, ReplicaRequest, Response> {\n \n+    private final boolean forceExecutionOnPrimary;\n+    private final WriteMemoryLimits writeMemoryLimits;\n+    private final String executor;\n+\n     protected TransportWriteAction(Settings settings, String actionName, TransportService transportService,\n                                    ClusterService clusterService, IndicesService indicesService, ThreadPool threadPool,\n                                    ShardStateAction shardStateAction, ActionFilters actionFilters, Writeable.Reader<Request> request,\n-                                   Writeable.Reader<ReplicaRequest> replicaRequest, String executor, boolean forceExecutionOnPrimary) {\n+                                   Writeable.Reader<ReplicaRequest> replicaRequest, String executor, boolean forceExecutionOnPrimary,\n+                                   WriteMemoryLimits writeMemoryLimits) {\n         super(settings, actionName, transportService, clusterService, indicesService, threadPool, shardStateAction, actionFilters,\n-              request, replicaRequest, executor, true, forceExecutionOnPrimary);\n+            request, replicaRequest, ThreadPool.Names.SAME, true, forceExecutionOnPrimary);", "originalCommit": "d461c36e07ee613580ab6a430d96769eb00c7c6a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "0cbd78af02782c1221733d32636e5d096ecd7490", "url": "https://github.com/elastic/elasticsearch/commit/0cbd78af02782c1221733d32636e5d096ecd7490", "message": "Merge remote-tracking branch 'upstream/master' into indexing_memory_queue2_only_stats", "committedDate": "2020-06-09T23:54:34Z", "type": "commit"}, {"oid": "f06985626cd0f60f9c155e26a75d7969127ff059", "url": "https://github.com/elastic/elasticsearch/commit/f06985626cd0f60f9c155e26a75d7969127ff059", "message": "Changes", "committedDate": "2020-06-10T00:32:07Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODA1MDEwMg==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r438050102", "bodyText": "doInternalExecute throws exceptions, which would lead to \"leaked\" memory in the tracker.", "author": "henningandersen", "createdAt": "2020-06-10T11:24:35Z", "path": "server/src/main/java/org/elasticsearch/action/bulk/TransportBulkAction.java", "diffHunk": "@@ -155,6 +158,13 @@ public static IndexRequest getIndexWriteRequest(DocWriteRequest docWriteRequest)\n \n     @Override\n     protected void doExecute(Task task, BulkRequest bulkRequest, ActionListener<BulkResponse> listener) {\n+        long indexingBytes = DocWriteRequest.writeSizeInBytes(bulkRequest.requests.stream());\n+        final Releasable releasable = writeMemoryLimits.markCoordinatingOperationStarted(indexingBytes);\n+        final ActionListener<BulkResponse> releasingListener = ActionListener.runAfter(listener, releasable::close);\n+        doInternalExecute(task, bulkRequest, releasingListener);", "originalCommit": "f06985626cd0f60f9c155e26a75d7969127ff059", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODA2MjgzOQ==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r438062839", "bodyText": "I think I would prefer to not have this and instead rely on the task to tell us if this request originated on this node or not (i.e., is task.getParentTaskId().getNodeId().equals(localNodeId) == true). We could assert that if it is local, the parent task must be the bulk action.\nI wonder if you made the experiment and came to the conclusion that it would not work out?", "author": "henningandersen", "createdAt": "2020-06-10T11:51:04Z", "path": "server/src/main/java/org/elasticsearch/action/bulk/BulkShardRequest.java", "diffHunk": "@@ -31,10 +31,12 @@\n import java.io.IOException;\n import java.util.HashSet;\n import java.util.Set;\n+import java.util.concurrent.atomic.AtomicBoolean;\n \n public class BulkShardRequest extends ReplicatedWriteRequest<BulkShardRequest> {\n \n-    private BulkItemRequest[] items;\n+    private final AtomicBoolean bytesAccounted = new AtomicBoolean(false);", "originalCommit": "f06985626cd0f60f9c155e26a75d7969127ff059", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTIwMDM0NA==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r439200344", "bodyText": "I'll look at this tomorrow. The primary reason I did not do it that way is if a request was sent to another node and then relocated back to the coordinating node it would not be accounted. But that does not really matter with the current design.", "author": "tbrooks8", "createdAt": "2020-06-12T04:28:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODA2MjgzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODc4MDczNQ==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r438780735", "bodyText": "This looks unused.", "author": "henningandersen", "createdAt": "2020-06-11T13:29:20Z", "path": "server/src/main/java/org/elasticsearch/action/bulk/TransportShardBulkAction.java", "diffHunk": "@@ -483,4 +507,10 @@ private static BulkItemResponse processUpdateResponse(final UpdateRequest update\n         }\n         return result;\n     }\n+\n+    private static long operationSizeInBytes(BulkItemRequest[] items) {", "originalCommit": "f06985626cd0f60f9c155e26a75d7969127ff059", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODg2MjkxMg==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r438862912", "bodyText": "nit: not that it matters a lot, but I think runBefore is more logical in that we release the memory before responding.", "author": "henningandersen", "createdAt": "2020-06-11T15:17:49Z", "path": "server/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java", "diffHunk": "@@ -489,10 +508,21 @@ public void runPostReplicaActions(ActionListener<Void> listener) {\n         }\n     }\n \n-    protected void handleReplicaRequest(final ConcreteReplicaRequest<ReplicaRequest> replicaRequest,\n-                                        final TransportChannel channel, final Task task) {\n-        new AsyncReplicaAction(\n-            replicaRequest, new ChannelActionListener<>(channel, transportReplicaAction, replicaRequest), (ReplicationTask) task).run();\n+    protected void handleReplicaRequest(final ConcreteReplicaRequest<ReplicaRequest> replicaRequest, final TransportChannel channel,\n+                                        final Task task) {\n+        Releasable releasable = checkReplicaLimits(replicaRequest.getRequest());\n+        ActionListener<ReplicaResponse> listener =\n+            ActionListener.runAfter(new ChannelActionListener<>(channel, transportReplicaAction, replicaRequest), releasable::close);", "originalCommit": "f06985626cd0f60f9c155e26a75d7969127ff059", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODkxMDQ4Nw==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r438910487", "bodyText": "I think we need to also check if we already accounted for the bytes here, since the request would normally arrive in the operation phase and then afterwards the primary phase is executed locally?", "author": "henningandersen", "createdAt": "2020-06-11T16:18:38Z", "path": "server/src/main/java/org/elasticsearch/action/support/replication/TransportWriteAction.java", "diffHunk": "@@ -57,12 +60,54 @@\n             Response extends ReplicationResponse & WriteResponse\n         > extends TransportReplicationAction<Request, ReplicaRequest, Response> {\n \n+    private final boolean forceExecutionOnPrimary;\n+    private final WriteMemoryLimits writeMemoryLimits;\n+    private final String executor;\n+\n     protected TransportWriteAction(Settings settings, String actionName, TransportService transportService,\n                                    ClusterService clusterService, IndicesService indicesService, ThreadPool threadPool,\n                                    ShardStateAction shardStateAction, ActionFilters actionFilters, Writeable.Reader<Request> request,\n-                                   Writeable.Reader<ReplicaRequest> replicaRequest, String executor, boolean forceExecutionOnPrimary) {\n+                                   Writeable.Reader<ReplicaRequest> replicaRequest, String executor, boolean forceExecutionOnPrimary,\n+                                   WriteMemoryLimits writeMemoryLimits) {\n+        // We pass ThreadPool.Names.SAME to the super class as we control the dispatching to the\n+        // ThreadPool.Names.WRITE thread pool in this class.\n         super(settings, actionName, transportService, clusterService, indicesService, threadPool, shardStateAction, actionFilters,\n-              request, replicaRequest, executor, true, forceExecutionOnPrimary);\n+            request, replicaRequest, ThreadPool.Names.SAME, true, forceExecutionOnPrimary);\n+        this.executor = executor;\n+        this.forceExecutionOnPrimary = forceExecutionOnPrimary;\n+        this.writeMemoryLimits = writeMemoryLimits;\n+    }\n+\n+    @Override\n+    protected Releasable checkOperationLimits(Request request) {\n+        if (shouldMarkCoordinatingBytes(request)) {\n+            long operationSizeInBytes = primaryOperationSize(request);\n+            return writeMemoryLimits.markCoordinatingOperationStarted(operationSizeInBytes);\n+        } else {\n+            return () -> {};\n+        }\n+    }\n+\n+    protected boolean shouldMarkCoordinatingBytes(Request request) {\n+        return true;\n+    }\n+\n+    @Override\n+    protected Releasable checkPrimaryLimits(Request request) {\n+        return writeMemoryLimits.markPrimaryOperationStarted(primaryOperationSize(request));", "originalCommit": "f06985626cd0f60f9c155e26a75d7969127ff059", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE2MzMxNQ==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r439163315", "bodyText": "This PR accounts coordinating and primary work under different metrics.", "author": "tbrooks8", "createdAt": "2020-06-12T01:43:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODkxMDQ4Nw=="}], "type": "inlineReview"}, {"oid": "da1540960ed855352555f3b6883bae271a6f38e3", "url": "https://github.com/elastic/elasticsearch/commit/da1540960ed855352555f3b6883bae271a6f38e3", "message": "Changes", "committedDate": "2020-06-11T23:30:28Z", "type": "commit"}, {"oid": "90eee725012ad7dbb425b3c77cd496a6ca5046fb", "url": "https://github.com/elastic/elasticsearch/commit/90eee725012ad7dbb425b3c77cd496a6ca5046fb", "message": "Merge remote-tracking branch 'upstream/master' into indexing_memory_queue2_only_stats", "committedDate": "2020-06-11T23:50:08Z", "type": "commit"}, {"oid": "ded75bbd45a3c165c0d0cbe8b4401ae571f72abd", "url": "https://github.com/elastic/elasticsearch/commit/ded75bbd45a3c165c0d0cbe8b4401ae571f72abd", "message": "Merge remote-tracking branch 'upstream/master' into indexing_memory_queue2_only_stats", "committedDate": "2020-06-15T19:59:20Z", "type": "commit"}, {"oid": "bda0bc6c6792722b92cdd61895b339d6acb1e019", "url": "https://github.com/elastic/elasticsearch/commit/bda0bc6c6792722b92cdd61895b339d6acb1e019", "message": "Changes", "committedDate": "2020-06-16T00:03:33Z", "type": "commit"}, {"oid": "3733dfc36e924c3cdcb11ecc2092d99ef519e0d4", "url": "https://github.com/elastic/elasticsearch/commit/3733dfc36e924c3cdcb11ecc2092d99ef519e0d4", "message": "Compile", "committedDate": "2020-06-16T00:16:29Z", "type": "commit"}, {"oid": "e1470244f7420174b255eafa67279d11d357f1a0", "url": "https://github.com/elastic/elasticsearch/commit/e1470244f7420174b255eafa67279d11d357f1a0", "message": "Runbefore", "committedDate": "2020-06-16T03:47:47Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDg1ODI1Nw==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r440858257", "bodyText": "Shouldn't this be the default implementation in TransportWriteAction? Is there still a need to override this method here?", "author": "ywelsch", "createdAt": "2020-06-16T13:40:53Z", "path": "server/src/main/java/org/elasticsearch/action/bulk/TransportShardBulkAction.java", "diffHunk": "@@ -110,7 +112,12 @@ protected BulkShardResponse newResponseInstance(StreamInput in) throws IOExcepti\n     }\n \n     @Override\n-    protected void shardOperationOnPrimary(BulkShardRequest request, IndexShard primary,\n+    protected boolean shouldMarkCoordinatingBytes(BulkShardRequest request) {\n+        return request.getParentTask().getNodeId().equals(clusterService.localNode().getId()) == false;", "originalCommit": "e1470244f7420174b255eafa67279d11d357f1a0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDg3MDA4OQ==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r440870089", "bodyText": "The parent task is currently set in the constructor of the ReroutePhase, which I find to be a bit of an odd place (probably to handle odd callers into this class). If we're going to rely on the parent task being correctly set, I wonder if we should make sure that TransportReplication is correctly setting this again whenever it resends the request to another node. I see some calls to transportService.sendRequest in TransportReplicationAction where this is not done (should prefer to use transportService.sendChildRequest throughout this class instead).\nWe should also assert in TransportBulkAction that task != null when setting the parent task of the bulkShardRequest there.", "author": "ywelsch", "createdAt": "2020-06-16T13:56:11Z", "path": "server/src/main/java/org/elasticsearch/action/bulk/TransportShardBulkAction.java", "diffHunk": "@@ -110,7 +112,12 @@ protected BulkShardResponse newResponseInstance(StreamInput in) throws IOExcepti\n     }\n \n     @Override\n-    protected void shardOperationOnPrimary(BulkShardRequest request, IndexShard primary,\n+    protected boolean shouldMarkCoordinatingBytes(BulkShardRequest request) {\n+        return request.getParentTask().getNodeId().equals(clusterService.localNode().getId()) == false;", "originalCommit": "e1470244f7420174b255eafa67279d11d357f1a0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "05d2f1f6d6aae588ae86d8bc1695d00b6fa01762", "url": "https://github.com/elastic/elasticsearch/commit/05d2f1f6d6aae588ae86d8bc1695d00b6fa01762", "message": "Merge remote-tracking branch 'upstream/master' into indexing_memory_queue2_only_stats", "committedDate": "2020-06-16T20:42:15Z", "type": "commit"}, {"oid": "7267ba917efc089a5f866a931492dda7ee0a6ebb", "url": "https://github.com/elastic/elasticsearch/commit/7267ba917efc089a5f866a931492dda7ee0a6ebb", "message": "Changes", "committedDate": "2020-06-16T21:24:54Z", "type": "commit"}, {"oid": "36d7cc0cbe5b04e4bf193c7f70143a9dbdf80f0a", "url": "https://github.com/elastic/elasticsearch/commit/36d7cc0cbe5b04e4bf193c7f70143a9dbdf80f0a", "message": "Merge remote-tracking branch 'upstream/master' into indexing_memory_queue2_only_stats", "committedDate": "2020-06-16T21:52:28Z", "type": "commit"}, {"oid": "f34aac68c02f6368f1821d025ebb556498c9ded2", "url": "https://github.com/elastic/elasticsearch/commit/f34aac68c02f6368f1821d025ebb556498c9ded2", "message": "Merge remote-tracking branch 'upstream/master' into indexing_memory_queue2_only_stats", "committedDate": "2020-06-17T22:00:16Z", "type": "commit"}, {"oid": "eb8fd4294c918d0448da7c00c20903a8cb16ee30", "url": "https://github.com/elastic/elasticsearch/commit/eb8fd4294c918d0448da7c00c20903a8cb16ee30", "message": "Changes", "committedDate": "2020-06-18T00:13:50Z", "type": "commit"}, {"oid": "ab2f9c2f7405cdfae79839e4de02478fdb075e6a", "url": "https://github.com/elastic/elasticsearch/commit/ab2f9c2f7405cdfae79839e4de02478fdb075e6a", "message": "NPE", "committedDate": "2020-06-18T00:54:15Z", "type": "commit"}, {"oid": "6fd1cfadcaf3b7abc522b03b6c4e8aadde764801", "url": "https://github.com/elastic/elasticsearch/commit/6fd1cfadcaf3b7abc522b03b6c4e8aadde764801", "message": "Merge remote-tracking branch 'upstream/master' into indexing_memory_queue2_only_stats", "committedDate": "2020-06-18T04:12:11Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjI5MTYyNA==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r442291624", "bodyText": "Use RamUsageEstimator.sizeOf(String)? It even covers 0 :)", "author": "ywelsch", "createdAt": "2020-06-18T14:57:05Z", "path": "server/src/main/java/org/elasticsearch/action/delete/DeleteRequest.java", "diffHunk": "@@ -247,4 +250,9 @@ public void writeTo(StreamOutput out) throws IOException {\n     public String toString() {\n         return \"delete {[\" + index + \"][\" + id + \"]}\";\n     }\n+\n+    @Override\n+    public long ramBytesUsed() {\n+        return SHALLOW_SIZE + (id == null ? 0 : (2 * id.length()));", "originalCommit": "6fd1cfadcaf3b7abc522b03b6c4e8aadde764801", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjI5MzMxMQ==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r442293311", "bodyText": "Should BulkRequest implement Accountable as well?", "author": "ywelsch", "createdAt": "2020-06-18T14:59:23Z", "path": "server/src/main/java/org/elasticsearch/action/bulk/TransportBulkAction.java", "diffHunk": "@@ -158,6 +161,17 @@ public static IndexRequest getIndexWriteRequest(DocWriteRequest docWriteRequest)\n \n     @Override\n     protected void doExecute(Task task, BulkRequest bulkRequest, ActionListener<BulkResponse> listener) {\n+        long indexingBytes = DocWriteRequest.writeSizeInBytes(bulkRequest.requests.stream());", "originalCommit": "6fd1cfadcaf3b7abc522b03b6c4e8aadde764801", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "7f6c0334879072df1a24e311d24500fe772cf23e", "url": "https://github.com/elastic/elasticsearch/commit/7f6c0334879072df1a24e311d24500fe772cf23e", "message": "Changes", "committedDate": "2020-06-18T16:34:31Z", "type": "commit"}, {"oid": "7dc01ea7b2647bf8b2c294698659c2847bced1e7", "url": "https://github.com/elastic/elasticsearch/commit/7dc01ea7b2647bf8b2c294698659c2847bced1e7", "message": "Merge remote-tracking branch 'upstream/master' into indexing_memory_queue2_only_stats", "committedDate": "2020-06-23T16:23:50Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDc1MzcwOA==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r444753708", "bodyText": "Let's add some assertions to our test infra (InternalTestCluster) that the bytes here at the end  of the test are always 0, similar to assertNoPendingIndexOperations.", "author": "ywelsch", "createdAt": "2020-06-24T09:08:11Z", "path": "server/src/main/java/org/elasticsearch/action/bulk/WriteMemoryLimits.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.action.bulk;\n+\n+import org.elasticsearch.common.lease.Releasable;\n+\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+public class WriteMemoryLimits {\n+\n+    // A heuristic for the bytes overhead of a single write operation\n+    public static final int WRITE_REQUEST_BYTES_OVERHEAD = 1024;\n+\n+    private final AtomicLong coordinatingBytes = new AtomicLong(0);\n+    private final AtomicLong primaryBytes = new AtomicLong(0);\n+    private final AtomicLong replicaBytes = new AtomicLong(0);", "originalCommit": "7dc01ea7b2647bf8b2c294698659c2847bced1e7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDc3MjA5NQ==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r444772095", "bodyText": "I would prefer to remove this overhead and instead make both BulkShardRequest and BulkItemRequest` accountable too.\nThis turns the tracking into the semi-exact request bytes that have not yet been responded to by this node.", "author": "henningandersen", "createdAt": "2020-06-24T09:40:10Z", "path": "server/src/main/java/org/elasticsearch/action/bulk/WriteMemoryLimits.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.action.bulk;\n+\n+import org.elasticsearch.common.lease.Releasable;\n+\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+public class WriteMemoryLimits {\n+\n+    // A heuristic for the bytes overhead of a single write operation\n+    public static final int WRITE_REQUEST_BYTES_OVERHEAD = 1024;", "originalCommit": "7dc01ea7b2647bf8b2c294698659c2847bced1e7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDc4MDExMw==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r444780113", "bodyText": "Use runBefore here too?", "author": "henningandersen", "createdAt": "2020-06-24T09:53:43Z", "path": "server/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java", "diffHunk": "@@ -272,13 +273,31 @@ boolean isRetryableClusterBlockException(final Throwable e) {\n         return false;\n     }\n \n-    protected void handleOperationRequest(final Request request, final TransportChannel channel, Task task) {\n-        execute(task, request, new ChannelActionListener<>(channel, actionName, request));\n+    private void handleOperationRequest(final Request request, final TransportChannel channel, Task task) {\n+        Releasable releasable = checkOperationLimits(request);\n+        ActionListener<Response> listener =\n+            ActionListener.runAfter(new ChannelActionListener<>(channel, actionName, request), releasable::close);", "originalCommit": "7dc01ea7b2647bf8b2c294698659c2847bced1e7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDc4NTA2Mg==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r444785062", "bodyText": "I think we can remove this catch block now? shardOperationOnReplica should never fail with an exception, only case is if the listener fails, which we are asserting against in completeWith.", "author": "henningandersen", "createdAt": "2020-06-24T10:02:46Z", "path": "server/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java", "diffHunk": "@@ -531,27 +561,30 @@ public RetryOnReplicaException(StreamInput in) throws IOException {\n \n         @Override\n         public void onResponse(Releasable releasable) {\n+            assert replica.getActiveOperationsCount() != 0 : \"must perform shard operation under a permit\";\n             try {\n-                assert replica.getActiveOperationsCount() != 0 : \"must perform shard operation under a permit\";\n-                final ReplicaResult replicaResult = shardOperationOnReplica(replicaRequest.getRequest(), replica);\n-                replicaResult.runPostReplicaActions(\n-                    ActionListener.wrap(r -> {\n-                        final TransportReplicationAction.ReplicaResponse response =\n-                            new ReplicaResponse(replica.getLocalCheckpoint(), replica.getLastSyncedGlobalCheckpoint());\n-                        releasable.close(); // release shard operation lock before responding to caller\n-                        if (logger.isTraceEnabled()) {\n-                            logger.trace(\"action [{}] completed on shard [{}] for request [{}]\", transportReplicaAction,\n-                                replicaRequest.getRequest().shardId(),\n-                                replicaRequest.getRequest());\n-                        }\n-                        setPhase(task, \"finished\");\n-                        onCompletionListener.onResponse(response);\n-                    }, e -> {\n-                        Releasables.closeWhileHandlingException(releasable); // release shard operation lock before responding to caller\n-                        this.responseWithFailure(e);\n-                    })\n-                );\n-            } catch (final Exception e) {\n+                shardOperationOnReplica(replicaRequest.getRequest(), replica, ActionListener.wrap((replicaResult) ->\n+                    replicaResult.runPostReplicaActions(\n+                        ActionListener.wrap(r -> {\n+                            final ReplicaResponse response =\n+                                new ReplicaResponse(replica.getLocalCheckpoint(), replica.getLastSyncedGlobalCheckpoint());\n+                            releasable.close(); // release shard operation lock before responding to caller\n+                            if (logger.isTraceEnabled()) {\n+                                logger.trace(\"action [{}] completed on shard [{}] for request [{}]\", transportReplicaAction,\n+                                    replicaRequest.getRequest().shardId(),\n+                                    replicaRequest.getRequest());\n+                            }\n+                            setPhase(task, \"finished\");\n+                            onCompletionListener.onResponse(response);\n+                        }, e -> {\n+                            Releasables.closeWhileHandlingException(releasable); // release shard operation lock before responding to caller\n+                            responseWithFailure(e);\n+                        })\n+                    ), e -> {\n+                    Releasables.closeWhileHandlingException(releasable); // release shard operation lock before responding to caller\n+                    AsyncReplicaAction.this.onFailure(e);\n+                }));\n+            } catch (Exception e) {", "originalCommit": "7dc01ea7b2647bf8b2c294698659c2847bced1e7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDc5MTA1OQ==", "url": "https://github.com/elastic/elasticsearch/pull/57573#discussion_r444791059", "bodyText": "Maybe add a couple of assertions to demonstrate that we do get some byte-size out like bulkRequestSize > totalRequestSize and totalRequestSize > 80 * 4 or similar? I think all assertions here would otherwise succeed if ramBytesUsed() returns 0.", "author": "henningandersen", "createdAt": "2020-06-24T10:14:11Z", "path": "server/src/internalClusterTest/java/org/elasticsearch/action/bulk/WriteMemoryLimitsIT.java", "diffHunk": "@@ -0,0 +1,203 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.elasticsearch.action.bulk;\n+\n+import org.elasticsearch.action.ActionFuture;\n+import org.elasticsearch.action.admin.indices.stats.IndicesStatsResponse;\n+import org.elasticsearch.action.admin.indices.stats.ShardStats;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.plugins.Plugin;\n+import org.elasticsearch.test.ESIntegTestCase;\n+import org.elasticsearch.test.InternalSettingsPlugin;\n+import org.elasticsearch.test.transport.MockTransportService;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.transport.TransportService;\n+\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.stream.Stream;\n+\n+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;\n+\n+@ESIntegTestCase.ClusterScope(scope = ESIntegTestCase.Scope.SUITE, numDataNodes = 2)\n+public class WriteMemoryLimitsIT extends ESIntegTestCase {\n+\n+    @Override\n+    protected Settings nodeSettings(int nodeOrdinal) {\n+        return Settings.builder()\n+            .put(super.nodeSettings(nodeOrdinal))\n+            // Need at least two threads because we are going to block one\n+            .put(\"thread_pool.write.size\", 2)\n+            .build();\n+    }\n+\n+    @Override\n+    protected Collection<Class<? extends Plugin>> nodePlugins() {\n+        return Arrays.asList(MockTransportService.TestPlugin.class, InternalSettingsPlugin.class);\n+    }\n+\n+    @Override\n+    protected int numberOfReplicas() {\n+        return 1;\n+    }\n+\n+    @Override\n+    protected int numberOfShards() {\n+        return 1;\n+    }\n+\n+    public void testWriteBytesAreIncremented() throws Exception {\n+        final String index = \"test\";\n+        assertAcked(prepareCreate(index, Settings.builder()\n+            .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 1)\n+            .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 1)));\n+        ensureGreen(index);\n+\n+        IndicesStatsResponse response = client().admin().indices().prepareStats(index).get();\n+        String primaryId = Stream.of(response.getShards())\n+            .map(ShardStats::getShardRouting)\n+            .filter(ShardRouting::primary)\n+            .findAny()\n+            .get()\n+            .currentNodeId();\n+        String replicaId = Stream.of(response.getShards())\n+            .map(ShardStats::getShardRouting)\n+            .filter(sr -> sr.primary() == false)\n+            .findAny()\n+            .get()\n+            .currentNodeId();\n+        String primaryName = client().admin().cluster().prepareState().get().getState().nodes().get(primaryId).getName();\n+        String replicaName = client().admin().cluster().prepareState().get().getState().nodes().get(replicaId).getName();\n+\n+        final CountDownLatch replicationSendPointReached = new CountDownLatch(1);\n+        final CountDownLatch latchBlockingReplicationSend = new CountDownLatch(1);\n+        final CountDownLatch newActionsSendPointReached = new CountDownLatch(2);\n+        final CountDownLatch latchBlockingReplication = new CountDownLatch(1);\n+\n+        TransportService primaryService = internalCluster().getInstance(TransportService.class, primaryName);\n+        final MockTransportService primaryTransportService = (MockTransportService) primaryService;\n+        TransportService replicaService = internalCluster().getInstance(TransportService.class, replicaName);\n+        final MockTransportService replicaTransportService = (MockTransportService) replicaService;\n+\n+        primaryTransportService.addSendBehavior((connection, requestId, action, request, options) -> {\n+            if (action.equals(TransportShardBulkAction.ACTION_NAME + \"[r]\")) {\n+                try {\n+                    replicationSendPointReached.countDown();\n+                    latchBlockingReplicationSend.await();\n+                } catch (InterruptedException e) {\n+                    throw new IllegalStateException(e);\n+                }\n+            }\n+            connection.sendRequest(requestId, action, request, options);\n+        });\n+\n+        final BulkRequest bulkRequest = new BulkRequest();\n+        int totalRequestSize = 0;\n+        for (int i = 0; i < 80; ++i) {\n+            IndexRequest request = new IndexRequest(index).id(UUIDs.base64UUID())\n+                .source(Collections.singletonMap(\"key\", randomAlphaOfLength(50)));\n+            totalRequestSize += request.ramBytesUsed();\n+            bulkRequest.add(request);\n+        }\n+\n+        final long bulkRequestSize = bulkRequest.ramBytesUsed() + WriteMemoryLimits.WRITE_REQUEST_BYTES_OVERHEAD;\n+        final long bulkShardRequestSize = totalRequestSize + WriteMemoryLimits.WRITE_REQUEST_BYTES_OVERHEAD;\n+", "originalCommit": "7dc01ea7b2647bf8b2c294698659c2847bced1e7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "62944558eba671e729e4b8cec8a793d15c70a7d4", "url": "https://github.com/elastic/elasticsearch/commit/62944558eba671e729e4b8cec8a793d15c70a7d4", "message": "Merge remote-tracking branch 'upstream/master' into indexing_memory_queue2_only_stats", "committedDate": "2020-06-24T16:54:01Z", "type": "commit"}, {"oid": "f2a6c778656ac0377b9aee7990003a52bbeba966", "url": "https://github.com/elastic/elasticsearch/commit/f2a6c778656ac0377b9aee7990003a52bbeba966", "message": "Changes", "committedDate": "2020-06-24T22:33:54Z", "type": "commit"}]}