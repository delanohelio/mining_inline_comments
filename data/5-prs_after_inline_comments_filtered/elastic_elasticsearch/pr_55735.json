{"pr_number": 55735, "pr_title": "[ML] Allow a certain number of ill-formatted rows when delimited format is specified", "pr_createdAt": "2020-04-24T16:54:56Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/55735", "timeline": [{"oid": "bb31b13ba7a177a8602f1d7612b285e4923433cf", "url": "https://github.com/elastic/elasticsearch/commit/bb31b13ba7a177a8602f1d7612b285e4923433cf", "message": "[ML] Allow a certain number of ill-formatted rows when format is specified", "committedDate": "2020-04-24T16:49:08Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDcyMzM3Nw==", "url": "https://github.com/elastic/elasticsearch/pull/55735#discussion_r414723377", "bodyText": "I am willing to change this number. Though i do think we should have some static limit as it could break the automatic header row check if too many rows are poorly formatted.", "author": "benwtrent", "createdAt": "2020-04-24T16:56:54Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/filestructurefinder/DelimitedFileStructureFinderFactory.java", "diffHunk": "@@ -14,6 +14,7 @@\n \n public class DelimitedFileStructureFinderFactory implements FileStructureFinderFactory {\n \n+    static final double DEFAULT_BAD_ROWS_PERCENTAGE = 0.10d;", "originalCommit": "bb31b13ba7a177a8602f1d7612b285e4923433cf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDc0ODU3Mg==", "url": "https://github.com/elastic/elasticsearch/pull/55735#discussion_r414748572", "bodyText": "That's ok for me. There has to be some default and maybe in the future that setting will become user-configurable...", "author": "przemekwitek", "createdAt": "2020-04-24T17:38:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDcyMzM3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDcyMzc4OQ==", "url": "https://github.com/elastic/elasticsearch/pull/55735#discussion_r414723789", "bodyText": "I think we should have wiggle room here as well. Because the user supplying these fields implies they expect it to be delimited.", "author": "benwtrent", "createdAt": "2020-04-24T16:57:41Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/filestructurefinder/FileStructureFinderManager.java", "diffHunk": "@@ -474,14 +474,17 @@ FileStructureFinder makeBestStructureFinder(List<String> explanation, String sam\n         Character quote = overrides.getQuote();\n         Boolean shouldTrimFields = overrides.getShouldTrimFields();\n         List<FileStructureFinderFactory> factories;\n+        double allowedFractionOfBadLines = 0.0;\n         if (delimiter != null) {\n+            allowedFractionOfBadLines = DelimitedFileStructureFinderFactory.DEFAULT_BAD_ROWS_PERCENTAGE;\n \n             // If a precise delimiter is specified, we only need one structure finder\n             // factory, and we'll tolerate as little as one column in the input\n             factories = Collections.singletonList(new DelimitedFileStructureFinderFactory(delimiter, (quote == null) ? '\"' : quote, 1,\n                 (shouldTrimFields == null) ? (delimiter == '|') : shouldTrimFields));\n \n         } else if (quote != null || shouldTrimFields != null) {\n+            allowedFractionOfBadLines = DelimitedFileStructureFinderFactory.DEFAULT_BAD_ROWS_PERCENTAGE;", "originalCommit": "bb31b13ba7a177a8602f1d7612b285e4923433cf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTAwNDY4Mg==", "url": "https://github.com/elastic/elasticsearch/pull/55735#discussion_r415004682", "bodyText": "If we do it here then we should also do it for the else branch below if format has been overridden to delimited.  (The easiest way to do this might be to change the condition above to else if (quote != null || shouldTrimFields != null || overrides.getFormat() == Format.DELIMITED).)\nThis does cause more problems though, for example, if a file has 12 semi-colons on all lines and 3 commas on 90% of lines we'll say it's CSV because we check that first.  It's probably OK, but we may want to tolerate fewer mismatches in this branch than the branch where the exact delimiter was specified.  (See my other comment about naming the constant.)", "author": "droberts195", "createdAt": "2020-04-25T07:30:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDcyMzc4OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDczNzc4OQ==", "url": "https://github.com/elastic/elasticsearch/pull/55735#discussion_r414737789", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                 * @param allowedFractionOfBadLines How many lines of the passed sample are allowed to be considered \"bad\".\n          \n          \n            \n                 * @param allowedFractionOfBadLines How many lines (provided as a fraction from interval [0, 1]) of the passed sample are allowed to be considered \"bad\".", "author": "przemekwitek", "createdAt": "2020-04-24T17:20:47Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/filestructurefinder/FileStructureFinderFactory.java", "diffHunk": "@@ -25,10 +25,11 @@\n      * @param explanation List of reasons for making decisions.  May contain items when passed and new reasons\n      *                    can be appended by this method.\n      * @param sample A sample from the file to be ingested.\n+     * @param allowedFractionOfBadLines How many lines of the passed sample are allowed to be considered \"bad\".", "originalCommit": "bb31b13ba7a177a8602f1d7612b285e4923433cf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDc0NDA5NQ==", "url": "https://github.com/elastic/elasticsearch/pull/55735#discussion_r414744095", "bodyText": "So in your solution the size of the first row determines what is \"normal\", right?\nIf the first row has 5 fields and the rest of the rows have 6 fields each, the file will be rejected even though there is only one \"odd\" row?\nI guess that's ok (it makes the code simpler) but wanted to make sure it is a conscious decision.", "author": "przemekwitek", "createdAt": "2020-04-24T17:30:52Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/filestructurefinder/DelimitedFileStructureFinder.java", "diffHunk": "@@ -529,16 +536,25 @@ static boolean canCreateFromSample(List<String> explanation, String sample, int\n                         --fieldsInThisRow;\n                     }\n \n-                    if (fieldsInLastRow != fieldsInFirstRow) {\n-                        explanation.add(\"Not \" + formatName + \" because row [\" + (numberOfRows - 1) +\n-                            \"] has a different number of fields to the first row: [\" + fieldsInFirstRow + \"] and [\" +\n-                            fieldsInLastRow + \"]\");\n-                        return false;\n+                    if (fieldsInThisRow != fieldsInFirstRow) {", "originalCommit": "bb31b13ba7a177a8602f1d7612b285e4923433cf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDc1MzA3Ng==", "url": "https://github.com/elastic/elasticsearch/pull/55735#discussion_r414753076", "bodyText": "Delimited parsing needs some sort of anchor to determine where things stand. The first row is usually a nice one as many files contain their header info.\nI am not sure if we should anchor towards the first row or not, but that is how it was before my change :).", "author": "benwtrent", "createdAt": "2020-04-24T17:45:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDc0NDA5NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTU4ODQ4OQ==", "url": "https://github.com/elastic/elasticsearch/pull/55735#discussion_r415588489", "bodyText": "I think it's OK for this iteration, but remember before this change every single row had to have the same number of fields, so the fact that the code achieved this by anchoring to the number of fields in the first row was an implementation detail.  After this change it becomes the externally visible policy.  But since it would complicate things a lot to change that and the new way of doing things is more tolerant than the old way, let's leave this as-is and see how many people cannot analyze a file because the first row has a different number of fields.", "author": "droberts195", "createdAt": "2020-04-27T07:49:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDc0NDA5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDc0NDgyOA==", "url": "https://github.com/elastic/elasticsearch/pull/55735#discussion_r414744828", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                    \"Not {} because more than {} rows did not have the same number of fields as the first row({}). Bad rows {}\",\n          \n          \n            \n                                    \"Not {} because more than {} rows did not have the same number of fields as the first row ({}). Bad rows {}\",", "author": "przemekwitek", "createdAt": "2020-04-24T17:31:56Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/filestructurefinder/DelimitedFileStructureFinder.java", "diffHunk": "@@ -529,16 +536,25 @@ static boolean canCreateFromSample(List<String> explanation, String sample, int\n                         --fieldsInThisRow;\n                     }\n \n-                    if (fieldsInLastRow != fieldsInFirstRow) {\n-                        explanation.add(\"Not \" + formatName + \" because row [\" + (numberOfRows - 1) +\n-                            \"] has a different number of fields to the first row: [\" + fieldsInFirstRow + \"] and [\" +\n-                            fieldsInLastRow + \"]\");\n-                        return false;\n+                    if (fieldsInThisRow != fieldsInFirstRow) {\n+                        illFormattedRows.add(fieldsInFirstRow);\n+                        continue;\n                     }\n \n                     fieldsInLastRow = fieldsInThisRow;\n                 }\n \n+                // We should only allow a certain percentage of ill formatted rows\n+                // as it may effects our sample sizing and down stream processing\n+                if (illFormattedRows.size() > (allowedFractionOfBadLines * numberOfRows) ) {\n+                    explanation.add(new ParameterizedMessage(\n+                        \"Not {} because more than {} rows did not have the same number of fields as the first row({}). Bad rows {}\",", "originalCommit": "bb31b13ba7a177a8602f1d7612b285e4923433cf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTU3NDg4OA==", "url": "https://github.com/elastic/elasticsearch/pull/55735#discussion_r415574888", "bodyText": "The message should be adjusted to take account of short-circuiting in the loop above, for example:\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                    \"Not {} because more than {} rows did not have the same number of fields as the first row({}). Bad rows {}\",\n          \n          \n            \n                                    \"Not {} because {} or more rows did not have the same number of fields as the first row ({}). Bad rows {}\",", "author": "droberts195", "createdAt": "2020-04-27T07:27:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDc0NDgyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDc0ODEzNQ==", "url": "https://github.com/elastic/elasticsearch/pull/55735#discussion_r414748135", "bodyText": "I would rename it to sth resembling the allowedFractionOfBadLines parameter in the interface, e.g.: DEFAULT_ALLOWED_FRACTION_OF_BAD_LINES.\nAlso I'd consider employing the word \"max\": maxAllowedFractionOfBadLines but I do not feel very strongly about it.", "author": "przemekwitek", "createdAt": "2020-04-24T17:37:40Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/filestructurefinder/DelimitedFileStructureFinderFactory.java", "diffHunk": "@@ -14,6 +14,7 @@\n \n public class DelimitedFileStructureFinderFactory implements FileStructureFinderFactory {\n \n+    static final double DEFAULT_BAD_ROWS_PERCENTAGE = 0.10d;", "originalCommit": "bb31b13ba7a177a8602f1d7612b285e4923433cf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTAwNjMzMQ==", "url": "https://github.com/elastic/elasticsearch/pull/55735#discussion_r415006331", "bodyText": "I would have two constants here, one for the case where we have been told the exact delimiter and one where we have been told it's delimited but not the exact delimiter.\nI also agree that it would be better to use FRACTION instead of PERCENTAGE as the value is not a percentage.\nHow about:\n    static final double DELIMITER_OVERRIDDEN_ALLOWED_FRACTION_OF_BAD_LINES = 0.10;\n    static final double FORMAT_OVERRIDDEN_ALLOWED_FRACTION_OF_BAD_LINES = 0.05;", "author": "droberts195", "createdAt": "2020-04-25T07:41:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDc0ODEzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTU3MzA5OA==", "url": "https://github.com/elastic/elasticsearch/pull/55735#discussion_r415573098", "bodyText": "I think it should round up so that if the number of rows is small there's still a tolerance\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            if (illFormattedRows.size() > (allowedFractionOfBadLines * numberOfRows) ) {\n          \n          \n            \n                            if (illFormattedRows.size() > Math.ceil(allowedFractionOfBadLines * numberOfRows) ) {\n          \n      \n    \n    \n  \n\nBut also, this needs to short-circuit.  Imagine we have been told to analyse 50000 lines that are not delimited.  With this change the code is now going to analyse all 50000 for all 4 default delimiters before ruling out the delimited formats.  And then it's going to provide 4 explanations each listing 49999 line numbers.  Therefore I think that:\n\nThis test needs to be inside the loop above, and break when the condition fails\nThe explanation message that lists bad rows needs to be rephrased to take this into account (see my other comment)", "author": "droberts195", "createdAt": "2020-04-27T07:24:50Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/filestructurefinder/DelimitedFileStructureFinder.java", "diffHunk": "@@ -529,16 +536,25 @@ static boolean canCreateFromSample(List<String> explanation, String sample, int\n                         --fieldsInThisRow;\n                     }\n \n-                    if (fieldsInLastRow != fieldsInFirstRow) {\n-                        explanation.add(\"Not \" + formatName + \" because row [\" + (numberOfRows - 1) +\n-                            \"] has a different number of fields to the first row: [\" + fieldsInFirstRow + \"] and [\" +\n-                            fieldsInLastRow + \"]\");\n-                        return false;\n+                    if (fieldsInThisRow != fieldsInFirstRow) {\n+                        illFormattedRows.add(fieldsInFirstRow);\n+                        continue;\n                     }\n \n                     fieldsInLastRow = fieldsInThisRow;\n                 }\n \n+                // We should only allow a certain percentage of ill formatted rows\n+                // as it may effects our sample sizing and down stream processing\n+                if (illFormattedRows.size() > (allowedFractionOfBadLines * numberOfRows) ) {", "originalCommit": "bb31b13ba7a177a8602f1d7612b285e4923433cf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTU3ODUyNA==", "url": "https://github.com/elastic/elasticsearch/pull/55735#discussion_r415578524", "bodyText": "Given the way this is used later we need the bad row number.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                    illFormattedRows.add(fieldsInFirstRow);\n          \n          \n            \n                                    illFormattedRows.add(numberOfRows - 1);\n          \n      \n    \n    \n  \n\nnumberOfRows - 1 is based on how it was printed in the old explanation.", "author": "droberts195", "createdAt": "2020-04-27T07:34:00Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/filestructurefinder/DelimitedFileStructureFinder.java", "diffHunk": "@@ -529,16 +536,25 @@ static boolean canCreateFromSample(List<String> explanation, String sample, int\n                         --fieldsInThisRow;\n                     }\n \n-                    if (fieldsInLastRow != fieldsInFirstRow) {\n-                        explanation.add(\"Not \" + formatName + \" because row [\" + (numberOfRows - 1) +\n-                            \"] has a different number of fields to the first row: [\" + fieldsInFirstRow + \"] and [\" +\n-                            fieldsInLastRow + \"]\");\n-                        return false;\n+                    if (fieldsInThisRow != fieldsInFirstRow) {\n+                        illFormattedRows.add(fieldsInFirstRow);", "originalCommit": "bb31b13ba7a177a8602f1d7612b285e4923433cf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "0cd2d28eaddb43ba4dce7fda3a886189aff2b48f", "url": "https://github.com/elastic/elasticsearch/commit/0cd2d28eaddb43ba4dce7fda3a886189aff2b48f", "message": "addressing PR comments", "committedDate": "2020-04-27T15:06:50Z", "type": "commit"}, {"oid": "9ed2baa6f42da97701d23987dadeeed9a3228f7c", "url": "https://github.com/elastic/elasticsearch/commit/9ed2baa6f42da97701d23987dadeeed9a3228f7c", "message": "Merge branch 'master' into feature/ml-fsf-allow-lenient-delim-parsing-when-specified", "committedDate": "2020-04-27T15:31:37Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTk2NTcwNg==", "url": "https://github.com/elastic/elasticsearch/pull/55735#discussion_r415965706", "bodyText": "This highlights an interesting dilemma.  In this test it's obvious that the bad row is really bad and should be ignored.  But what if the bad row was this?\n2018-05-17T13:41:34\\n\n\nThen a human interpreting the file would probably say that the row just had an empty message, and should be processed as such.\nI think it would be interesting to look at the specific examples of where people have complained that we couldn't import their CSV files and see if the \"bad\" rows in the real-world examples fall into the category of unusably bad or just missing the last field.  Missing any field other than the last would fall into the category of unusably bad because it would mess up field mapping type analysis.\nThe decision of whether or not we ignore the bad rows should be documented in https://www.elastic.co/guide/en/elasticsearch/reference/master/ml-find-file-structure.html.  Probably the best place to do this is in the description of the delimiter override, where we can tell people that by explicitly specifying the delimiter we're slightly tolerant of bad lines and what happens to the bad lines.", "author": "droberts195", "createdAt": "2020-04-27T16:32:13Z", "path": "x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/filestructurefinder/DelimitedFileStructureFinderTests.java", "diffHunk": "@@ -65,14 +65,57 @@ public void testCreateConfigsGivenCompleteCsv() throws Exception {\n         assertEquals(Collections.singletonList(\"ISO8601\"), structure.getJodaTimestampFormats());\n     }\n \n+    public void testCreateConfigsGivenIncompleteCsv() throws Exception {\n+        String sample = \"time,message\\n\" +\n+            \"2018-05-17T13:41:23,hello\\n\" +\n+            \"2018-05-17T13:41:25,hello\\n\" +\n+            \"2018-05-17T13:41:26,hello\\n\" +\n+            \"2018-05-17T13:41:27,hello\\n\" +\n+            \"2018-05-17T13:41:28,hello\\n\" +\n+            \"2018-05-17T13:41:29,hello\\n\" +\n+            \"2018-05-17T13:41:30,hello\\n\" +\n+            \"2018-05-17T13:41:31,hello\\n\" +\n+            \"2018-05-17T13:41:32,hello\\n\" +\n+            \"badrow\\n\" +", "originalCommit": "9ed2baa6f42da97701d23987dadeeed9a3228f7c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjAwMDM4Nw==", "url": "https://github.com/elastic/elasticsearch/pull/55735#discussion_r416000387", "bodyText": "Examples we have are:\n\nelastic/kibana#31065 - summary rows => inappropriate to include\nelastic/kibana#60196 (comment) - missing last column => would be good to include\n\nSo one of each \ud83e\udd26\nSo for this PR it's probably best that the bad rows get ignored from the analysis.  But we need to document that, as people will be losing data.  Also, what does the end-to-end experience look like, including file import?  Does the CSV ingest processor report errors for the bad rows that get propagated back to the file data visualizer?  I guess even in the long run if it's impossible to configure the CSV ingest processor to treat missing trailing columns as empty then we'll always have to ignore rows with fewer fields than the header row.", "author": "droberts195", "createdAt": "2020-04-27T17:19:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTk2NTcwNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjA2NDkxMQ==", "url": "https://github.com/elastic/elasticsearch/pull/55735#discussion_r416064911", "bodyText": "I will verify the following, but my gut is that these should be the actions on our two scenarios:\n\n\nmissing a value in the middle: this could probably end up causing an ingest failure. I am pretty sure the UI shows what the bulk ingest failures were, and these usually say \"field foo could not be mapped to type bar\".\n\n\nmissing value at the end: Doc should import fully without issues as there will be no mapping conflicts. The field is just null or missing from the resulting doc. Zero data loss.", "author": "benwtrent", "createdAt": "2020-04-27T18:50:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTk2NTcwNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjYzNzA0Mw==", "url": "https://github.com/elastic/elasticsearch/pull/55735#discussion_r416637043", "bodyText": "Here is how a truly bad row is handled:\n\nHere is a row that is simply missing the last field:\n{\n        \"_index\" : \"fooo\",\n        \"_id\" : \"sG0QwXEBJGToJIFIoH8F\",\n        \"_score\" : 1.0,\n        \"_source\" : {\n          \"@timestamp\" : \"2018-05-17T13:41:35.000-04:00\",\n          \"time\" : \"2018-05-17T13:41:35\",\n          \"message\" : \"2018-05-17T13:41:35\"\n        }\n      },\n\nI think this is an artifact of:\n{\n      \"csv\": {\n        \"field\": \"message\",\n        \"target_fields\": [\n          \"time\",\n          \"message\"\n        ],\n        \"ignore_missing\": false\n      }\n    },\n\nSince the header field name was the same as the source field of message.\nHere is what it would look like when the missing column is not called message\nProcessor\n{\n      \"csv\": {\n        \"field\": \"message\",\n        \"target_fields\": [\n          \"time\",\n          \"text\"\n        ],\n        \"ignore_missing\": false\n      }\n    },\n\nResulting doc\n{\n        \"_index\" : \"asdf\",\n        \"_id\" : \"Pm0VwXEBJGToJIFIEoAX\",\n        \"_score\" : 1.0,\n        \"_source\" : {\n          \"@timestamp\" : \"2018-05-17T13:41:35.000-04:00\",\n          \"time\" : \"2018-05-17T13:41:35\"\n        }\n      },", "author": "benwtrent", "createdAt": "2020-04-28T14:00:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTk2NTcwNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjY0NzczOA==", "url": "https://github.com/elastic/elasticsearch/pull/55735#discussion_r416647738", "bodyText": "OK that's interesting.  So you get past the CSV processor if you have fewer columns in a row than you have header columns.  After that the document may or may not get ingested depending on whether fields clash with subsequent processors.  So badrow cannot be parsed as a date, but if the first column had been a keyword field rather than a date then that would have gone through.\nI think this actually isn't too bad.  If we deduce mappings based on the rows containing all the header fields, and then others get ingested or not depending on how unexpectedly different they were.", "author": "droberts195", "createdAt": "2020-04-28T14:13:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTk2NTcwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTk3NjY1Mw==", "url": "https://github.com/elastic/elasticsearch/pull/55735#discussion_r415976653", "bodyText": "To prove the last line (and maybe the bad line depending on the decision from my other comment) get included, it would be good to assert on the value of structure.getNumMessagesAnalyzed() here.  It should be 10 if the bad line gets excluded and 11 if it gets included.\nI actually don't understand how we're getting past the check at https://github.com/super-csv/super-csv/blob/208d3082cd5cdab39da8873cf741f8b672d1af5b/super-csv/src/main/java/org/supercsv/util/Util.java#L122-L128 which we call from \n  \n    \n      elasticsearch/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/filestructurefinder/DelimitedFileStructureFinder.java\n    \n    \n        Lines 84 to 85\n      in\n      9521e4f\n    \n    \n    \n    \n\n        \n          \n           Util.filterListToMap(sampleRecord, columnNames, \n        \n\n        \n          \n               trimFields ? row.stream().map(field -> (field == null) ? null : field.trim()).collect(Collectors.toList()) : row); \n        \n    \n  \n\n when we hit the bad row.  SuperCSV throws an exception here, which I would have thought would terminate the analysis, so this may be a sign of some other bug that's existed for a long time or it may be working for some reason I don't understand.", "author": "droberts195", "createdAt": "2020-04-27T16:46:33Z", "path": "x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/filestructurefinder/DelimitedFileStructureFinderTests.java", "diffHunk": "@@ -65,14 +65,57 @@ public void testCreateConfigsGivenCompleteCsv() throws Exception {\n         assertEquals(Collections.singletonList(\"ISO8601\"), structure.getJodaTimestampFormats());\n     }\n \n+    public void testCreateConfigsGivenIncompleteCsv() throws Exception {\n+        String sample = \"time,message\\n\" +\n+            \"2018-05-17T13:41:23,hello\\n\" +\n+            \"2018-05-17T13:41:25,hello\\n\" +\n+            \"2018-05-17T13:41:26,hello\\n\" +\n+            \"2018-05-17T13:41:27,hello\\n\" +\n+            \"2018-05-17T13:41:28,hello\\n\" +\n+            \"2018-05-17T13:41:29,hello\\n\" +\n+            \"2018-05-17T13:41:30,hello\\n\" +\n+            \"2018-05-17T13:41:31,hello\\n\" +\n+            \"2018-05-17T13:41:32,hello\\n\" +\n+            \"badrow\\n\" +\n+            \"2018-05-17T13:41:33,hello again\\n\";\n+        assertTrue(\"assertion failed. Explanation \" + explanation,\n+            csvFactory.canCreateFromSample(explanation, sample, 0.10));\n+\n+        String charset = randomFrom(POSSIBLE_CHARSETS);\n+        Boolean hasByteOrderMarker = randomHasByteOrderMarker(charset);\n+        FileStructureFinder structureFinder = csvFactory.createFromSample(explanation, sample, charset, hasByteOrderMarker,\n+            FileStructureFinderManager.DEFAULT_LINE_MERGE_SIZE_LIMIT, FileStructureOverrides.EMPTY_OVERRIDES, NOOP_TIMEOUT_CHECKER);\n+\n+\n+        FileStructure structure = structureFinder.getStructure();\n+\n+        assertEquals(FileStructure.Format.DELIMITED, structure.getFormat());\n+        assertEquals(charset, structure.getCharset());\n+        if (hasByteOrderMarker == null) {\n+            assertNull(structure.getHasByteOrderMarker());\n+        } else {\n+            assertEquals(hasByteOrderMarker, structure.getHasByteOrderMarker());\n+        }\n+        assertEquals(\"^\\\"?time\\\"?,\\\"?message\\\"?\", structure.getExcludeLinesPattern());\n+        assertEquals(\"time\", structure.getTimestampField());\n+        assertEquals(Collections.singletonList(\"ISO8601\"), structure.getJodaTimestampFormats());\n+        assertEquals(Arrays.asList(\"time\", \"message\"), structure.getColumnNames());\n+        assertEquals(Character.valueOf(','), structure.getDelimiter());\n+        assertEquals(Character.valueOf('\"'), structure.getQuote());\n+        assertTrue(structure.getHasHeaderRow());\n+        assertNull(structure.getMultilineStartPattern());\n+        assertNull(structure.getShouldTrimFields());\n+        assertNull(structure.getGrokPattern());", "originalCommit": "9ed2baa6f42da97701d23987dadeeed9a3228f7c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjA2NjYwNw==", "url": "https://github.com/elastic/elasticsearch/pull/55735#discussion_r416066607", "bodyText": "See: \n  \n    \n      elasticsearch/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/filestructurefinder/DelimitedFileStructureFinder.java\n    \n    \n        Lines 83 to 88\n      in\n      9ed2baa\n    \n    \n    \n    \n\n        \n          \n           // Indicates an illformatted row. We allow a certain number of these \n        \n\n        \n          \n           if (row.size() != columnNames.length) { \n        \n\n        \n          \n               prevMessageEndLineNumber = lineNumber; \n        \n\n        \n          \n               continue; \n        \n\n        \n          \n           } \n        \n\n        \n          \n           Map<String, String> sampleRecord = new LinkedHashMap<>();", "author": "benwtrent", "createdAt": "2020-04-27T18:53:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTk3NjY1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTk4OTM2Nw==", "url": "https://github.com/elastic/elasticsearch/pull/55735#discussion_r415989367", "bodyText": "I think there's a problem here that I didn't think of when I suggested to move the check inside the loop.\nIf the bad row comes very early on then this will trigger when the overall proportion of bad lines in the file is within the tolerance.\nYou should be able to reproduce this by making your bad row the second non-header row in your test case.  At the point it occurs 50% of rows will be bad.\nSo, we need a formula that will short-circuit as soon as it's impossible for the overall percentage to be within the tolerance (which will be on the first bad row in the no overrides case) but not sooner.  Unfortunately we don't know the number of CSV rows for sure because some could be multi-line.  Assuming worst case, let's make the formula work on the basis that every subsequent sample line is one row, and they're all good.  That leads to:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                    if (illFormattedRows.size() > Math.ceil(allowedFractionOfBadLines * numberOfRows)) {\n          \n          \n            \n                                    if (illFormattedRows.size() > Math.ceil(allowedFractionOfBadLines * (numberOfRows + numberOfLinesInSample - csvReader.getLineNumber()))) {\n          \n      \n    \n    \n  \n\nThere might be an off-by-one error in that formula depending on exactly what csvReader.getLineNumber() after reading a row.\nThe next problem is that numberOfLinesInSample isn't known in this method.  FileStructureFinderManager.sampleFile() knows it, so you could change that to return it and pass it through to the canCreate___ methods, or maybe there is somewhere else it's more convenient to get it from.", "author": "droberts195", "createdAt": "2020-04-27T17:03:25Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/filestructurefinder/DelimitedFileStructureFinder.java", "diffHunk": "@@ -529,11 +535,22 @@ static boolean canCreateFromSample(List<String> explanation, String sample, int\n                         --fieldsInThisRow;\n                     }\n \n-                    if (fieldsInLastRow != fieldsInFirstRow) {\n-                        explanation.add(\"Not \" + formatName + \" because row [\" + (numberOfRows - 1) +\n-                            \"] has a different number of fields to the first row: [\" + fieldsInFirstRow + \"] and [\" +\n-                            fieldsInLastRow + \"]\");\n-                        return false;\n+                    // TODO: might be good one day to gather a distribution of the most common field counts\n+                    // But, this would require iterating (or at least sampling) all the lines.\n+                    if (fieldsInThisRow != fieldsInFirstRow) {\n+                        illFormattedRows.add(numberOfRows - 1);\n+                        // We should only allow a certain percentage of ill formatted rows\n+                        // as it may effects our sample sizing and down stream processing\n+                        if (illFormattedRows.size() > Math.ceil(allowedFractionOfBadLines * numberOfRows)) {", "originalCommit": "9ed2baa6f42da97701d23987dadeeed9a3228f7c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjA2NzM5MQ==", "url": "https://github.com/elastic/elasticsearch/pull/55735#discussion_r416067391", "bodyText": "AGH! You are right. Need to adjust", "author": "benwtrent", "createdAt": "2020-04-27T18:54:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTk4OTM2Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjY0Nzk5MA==", "url": "https://github.com/elastic/elasticsearch/pull/55735#discussion_r416647990", "bodyText": "@droberts195 looking at the delimited factory. I don't see lineMergeSizeLimit used at all. And following what is done in FileStructureFinderManager.sampleFile it SEEMS to simply read lines and split...which is the same thing that is done in \n  \n    \n      elasticsearch/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/filestructurefinder/DelimitedFileStructureFinder.java\n    \n    \n        Lines 495 to 502\n      in\n      257b9a6\n    \n    \n    \n    \n\n        \n          \n           String[] sampleLines = sample.split(\"\\n\"); \n        \n\n        \n          \n           for (String sampleLine : sampleLines) { \n        \n\n        \n          \n               if (lineHasUnescapedQuote(sampleLine, csvPreference)) { \n        \n\n        \n          \n                   explanation.add(\"Not \" + formatName + \n        \n\n        \n          \n                       \" because a line has an unescaped quote that is not at the beginning or end of a field: [\" + sampleLine + \"]\"); \n        \n\n        \n          \n                   return false; \n        \n\n        \n          \n               } \n        \n\n        \n          \n           } \n        \n    \n  \n\n\nI might could use sampleLines.length as an approximation.", "author": "benwtrent", "createdAt": "2020-04-28T14:14:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTk4OTM2Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzI0MDI4Ng==", "url": "https://github.com/elastic/elasticsearch/pull/55735#discussion_r417240286", "bodyText": "looking at the delimited factory. I don't see lineMergeSizeLimit used at all\n\nGood point, that's a bug.  It can be fixed by changing DelimitedFileStructureFinderFactory.createFromSample to this:\n        CsvPreference adjustedCsvPreference = new CsvPreference.Builder(csvPreference).maxLinesPerRow(lineMergeSizeLimit).build();\n        return DelimitedFileStructureFinder.makeDelimitedFileStructureFinder(explanation, sample, charsetName, hasByteOrderMarker,\n            adjustedCsvPreference, trimFields, overrides, timeoutChecker);\n\nThat can be done in this PR or a subsequent one, as the problem is independent of the main change of this PR.\n\nI might could use sampleLines.length as an approximation.\n\nYes, true, I missed that.", "author": "droberts195", "createdAt": "2020-04-29T11:19:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTk4OTM2Nw=="}], "type": "inlineReview"}, {"oid": "bf49f1bf9537acf4453cc59a5ec54312f33c96ce", "url": "https://github.com/elastic/elasticsearch/commit/bf49f1bf9537acf4453cc59a5ec54312f33c96ce", "message": "more accurately detect bad rows", "committedDate": "2020-04-28T15:10:18Z", "type": "commit"}, {"oid": "0cbadec1118c2665b7777e324247ea54b612833a", "url": "https://github.com/elastic/elasticsearch/commit/0cbadec1118c2665b7777e324247ea54b612833a", "message": "Merge remote-tracking branch 'upstream/master' into feature/ml-fsf-allow-lenient-delim-parsing-when-specified", "committedDate": "2020-04-28T15:10:30Z", "type": "commit"}, {"oid": "b4d1f068a0ad464d1ca60fd5a23abbb878338168", "url": "https://github.com/elastic/elasticsearch/commit/b4d1f068a0ad464d1ca60fd5a23abbb878338168", "message": "Merge branch 'feature/ml-fsf-allow-lenient-delim-parsing-when-specified' of github.com:benwtrent/elasticsearch into feature/ml-fsf-allow-lenient-delim-parsing-when-specified", "committedDate": "2020-04-28T15:25:24Z", "type": "commit"}, {"oid": "5b8c4cfca55707c3b405d3fb4761d01721ac71ee", "url": "https://github.com/elastic/elasticsearch/commit/5b8c4cfca55707c3b405d3fb4761d01721ac71ee", "message": "fixing comments", "committedDate": "2020-04-28T15:27:34Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzI0NDQ1Mg==", "url": "https://github.com/elastic/elasticsearch/pull/55735#discussion_r417244452", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                    // `getLineNumber` is a current count of lines, regardless of row count\n          \n          \n            \n                                    // `getLineNumber` is a current count of lines, regardless of row count, so\n          \n          \n            \n                                    // this formula is just an approximation, but gets more accurate the further\n          \n          \n            \n                                    // through the sample you are.", "author": "droberts195", "createdAt": "2020-04-29T11:28:14Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/filestructurefinder/DelimitedFileStructureFinder.java", "diffHunk": "@@ -529,11 +536,25 @@ static boolean canCreateFromSample(List<String> explanation, String sample, int\n                         --fieldsInThisRow;\n                     }\n \n-                    if (fieldsInLastRow != fieldsInFirstRow) {\n-                        explanation.add(\"Not \" + formatName + \" because row [\" + (numberOfRows - 1) +\n-                            \"] has a different number of fields to the first row: [\" + fieldsInFirstRow + \"] and [\" +\n-                            fieldsInLastRow + \"]\");\n-                        return false;\n+                    // TODO: might be good one day to gather a distribution of the most common field counts\n+                    // But, this would require iterating (or at least sampling) all the lines.\n+                    if (fieldsInThisRow != fieldsInFirstRow) {\n+                        illFormattedRows.add(numberOfRows - 1);\n+                        // This calculation is complicated by the possibility of multi-lined CSV columns\n+                        // `getLineNumber` is a current count of lines, regardless of row count", "originalCommit": "5b8c4cfca55707c3b405d3fb4761d01721ac71ee", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "f7b65b58dc0c0457217fef558f47b680dfde0daa", "url": "https://github.com/elastic/elasticsearch/commit/f7b65b58dc0c0457217fef558f47b680dfde0daa", "message": "Update x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/filestructurefinder/DelimitedFileStructureFinder.java\n\nCo-Authored-By: David Roberts <dave.roberts@elastic.co>", "committedDate": "2020-04-29T11:51:13Z", "type": "commit"}, {"oid": "ed6d2d66bae173de23173f88292fb8efe42dd509", "url": "https://github.com/elastic/elasticsearch/commit/ed6d2d66bae173de23173f88292fb8efe42dd509", "message": "Merge branch 'master' into feature/ml-fsf-allow-lenient-delim-parsing-when-specified", "committedDate": "2020-04-29T12:08:17Z", "type": "commit"}]}