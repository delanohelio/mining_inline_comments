{"pr_number": 59175, "pr_title": "Adds hard_bounds to histogram aggregations", "pr_createdAt": "2020-07-07T16:37:03Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/59175", "timeline": [{"oid": "5f63ab88ac8b4d46a35eb675ab4c1c1ae131555a", "url": "https://github.com/elastic/elasticsearch/commit/5f63ab88ac8b4d46a35eb675ab4c1c1ae131555a", "message": "Adds hard_bounds to histogram aggregations\n\nAdds a hard_bounds parameter to explicitly limit the buckets that a histogram\ncan generate. This is especially useful in case of open ended ranges that can\nproduce a very large number of buckets.\n\nCloses #50109", "committedDate": "2020-07-07T15:48:26Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTU4MDY1OQ==", "url": "https://github.com/elastic/elasticsearch/pull/59175#discussion_r451580659", "bodyText": "You'll change this after the backport, I presume?", "author": "not-napoleon", "createdAt": "2020-07-08T14:17:34Z", "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregationBuilder.java", "diffHunk": "@@ -139,7 +145,10 @@ public DateHistogramAggregationBuilder(StreamInput in) throws IOException {\n         minDocCount = in.readVLong();\n         dateHistogramInterval = new DateIntervalWrapper(in);\n         offset = in.readLong();\n-        extendedBounds = in.readOptionalWriteable(ExtendedBounds::new);\n+        extendedBounds = in.readOptionalWriteable(LongBounds::new);\n+        if (in.getVersion().onOrAfter(Version.V_8_0_0)) {", "originalCommit": "5f63ab88ac8b4d46a35eb675ab4c1c1ae131555a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgwMDAzNA==", "url": "https://github.com/elastic/elasticsearch/pull/59175#discussion_r453800034", "bodyText": "Yes, that's just until backport.", "author": "imotov", "createdAt": "2020-07-13T17:08:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTU4MDY1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTU4MTUyOQ==", "url": "https://github.com/elastic/elasticsearch/pull/59175#discussion_r451581529", "bodyText": "Why do we not allow setting the bounds to null?  It's not a required parameter.", "author": "not-napoleon", "createdAt": "2020-07-08T14:18:38Z", "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregationBuilder.java", "diffHunk": "@@ -281,20 +293,35 @@ public static long parseStringOffset(String offset) {\n     }\n \n     /** Return extended bounds for this histogram, or {@code null} if none are set. */\n-    public ExtendedBounds extendedBounds() {\n+    public LongBounds extendedBounds() {\n         return extendedBounds;\n     }\n \n     /** Set extended bounds on this histogram, so that buckets would also be\n      *  generated on intervals that did not match any documents. */\n-    public DateHistogramAggregationBuilder extendedBounds(ExtendedBounds extendedBounds) {\n+    public DateHistogramAggregationBuilder extendedBounds(LongBounds extendedBounds) {\n         if (extendedBounds == null) {\n             throw new IllegalArgumentException(\"[extendedBounds] must not be null: [\" + name + \"]\");\n         }\n         this.extendedBounds = extendedBounds;\n         return this;\n     }\n \n+\n+    /** Return hard bounds for this histogram, or {@code null} if none are set. */\n+    public LongBounds hardBounds() {\n+        return hardBounds;\n+    }\n+\n+    /** Set hard bounds on this histogram, specifying boundaries outside which buckets cannot be created. */\n+    public DateHistogramAggregationBuilder hardBounds(LongBounds hardBounds) {\n+        if (hardBounds == null) {\n+            throw new IllegalArgumentException(\"[hardBounds] must not be null: [\" + name + \"]\");", "originalCommit": "5f63ab88ac8b4d46a35eb675ab4c1c1ae131555a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgwMTE2Nw==", "url": "https://github.com/elastic/elasticsearch/pull/59175#discussion_r453801167", "bodyText": "This is consistent with all other optional parameters in this builder like order or externed_bounds.", "author": "imotov", "createdAt": "2020-07-13T17:10:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTU4MTUyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTcyMjIyMg==", "url": "https://github.com/elastic/elasticsearch/pull/59175#discussion_r451722222", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                        final long effectiveFrom = hardBounds != null && hardBounds.getMin() != null ?\n          \n          \n            \n                                        final long effectiveFrom = (hardBounds != null && hardBounds.getMin() != null) ?\n          \n      \n    \n    \n  \n\nNit, but I hate having to think about the operator precedence of ?:", "author": "not-napoleon", "createdAt": "2020-07-08T17:48:50Z", "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/DateRangeHistogramAggregator.java", "diffHunk": "@@ -140,9 +146,13 @@ public void collect(int doc, long owningBucketOrd) throws IOException {\n                             // The encoding should ensure that this assert is always true.\n                             assert from >= previousFrom : \"Start of range not >= previous start\";\n                             final Long to = (Long) range.getTo();\n-                            final long startKey = preparedRounding.round(from);\n-                            final long endKey = preparedRounding.round(to);\n-                            for (long  key = startKey > previousKey ? startKey : previousKey; key <= endKey;\n+                            final long effectiveFrom = hardBounds != null && hardBounds.getMin() != null ?", "originalCommit": "5f63ab88ac8b4d46a35eb675ab4c1c1ae131555a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTcyMjY4OA==", "url": "https://github.com/elastic/elasticsearch/pull/59175#discussion_r451722688", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                        final long effectiveTo = hardBounds != null && hardBounds.getMax() != null ?\n          \n          \n            \n                                        final long effectiveTo = (hardBounds != null && hardBounds.getMax() != null) ?\n          \n      \n    \n    \n  \n\nSame.", "author": "not-napoleon", "createdAt": "2020-07-08T17:49:39Z", "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/DateRangeHistogramAggregator.java", "diffHunk": "@@ -140,9 +146,13 @@ public void collect(int doc, long owningBucketOrd) throws IOException {\n                             // The encoding should ensure that this assert is always true.\n                             assert from >= previousFrom : \"Start of range not >= previous start\";\n                             final Long to = (Long) range.getTo();\n-                            final long startKey = preparedRounding.round(from);\n-                            final long endKey = preparedRounding.round(to);\n-                            for (long  key = startKey > previousKey ? startKey : previousKey; key <= endKey;\n+                            final long effectiveFrom = hardBounds != null && hardBounds.getMin() != null ?\n+                                max(from, hardBounds.getMin()) : from;\n+                            final long effectiveTo = hardBounds != null && hardBounds.getMax() != null ?", "originalCommit": "5f63ab88ac8b4d46a35eb675ab4c1c1ae131555a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTcyNzExNQ==", "url": "https://github.com/elastic/elasticsearch/pull/59175#discussion_r451727115", "bodyText": "Am I correct that there's no common interface between DoubleBound and LongBound because we'd have to autobox in the collection loop?  If so, maybe let's just leave a comment to that effect and maybe link the two in Javadoc, so there's at least something indicating there are two implementations here.", "author": "not-napoleon", "createdAt": "2020-07-08T17:56:47Z", "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/DoubleBounds.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.search.aggregations.bucket.histogram;\n+\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.InstantiatingObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentFragment;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+\n+import java.io.IOException;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.optionalConstructorArg;\n+\n+public class DoubleBounds implements ToXContentFragment, Writeable {", "originalCommit": "5f63ab88ac8b4d46a35eb675ab4c1c1ae131555a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgxOTIxMA==", "url": "https://github.com/elastic/elasticsearch/pull/59175#discussion_r453819210", "bodyText": "I am not sure I follow. Where do you expect them to intersect?", "author": "imotov", "createdAt": "2020-07-13T17:40:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTcyNzExNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTczMzEwNA==", "url": "https://github.com/elastic/elasticsearch/pull/59175#discussion_r451733104", "bodyText": "Should we convert minBound and maxBound into a DoubleBounds instance? if not, should probably just leave a comment that it's done this way for legacy reasons, not out of any specific need.", "author": "not-napoleon", "createdAt": "2020-07-08T18:07:24Z", "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/HistogramAggregationBuilder.java", "diffHunk": "@@ -87,6 +91,7 @@ public static void registerAggregators(ValuesSourceRegistry.Builder builder) {\n     private double offset = 0;\n     private double minBound = Double.POSITIVE_INFINITY;\n     private double maxBound = Double.NEGATIVE_INFINITY;\n+    private DoubleBounds hardBounds;", "originalCommit": "5f63ab88ac8b4d46a35eb675ab4c1c1ae131555a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgxODQxMA==", "url": "https://github.com/elastic/elasticsearch/pull/59175#discussion_r453818410", "bodyText": "I would like to refactor minBounds and maxBounds in a follow up PR. I just didn't feel like making this one more complicated than necessary. I will add TODO comment.", "author": "imotov", "createdAt": "2020-07-13T17:39:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTczMzEwNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTczNTE2OA==", "url": "https://github.com/elastic/elasticsearch/pull/59175#discussion_r451735168", "bodyText": "time seems like a confusing name for this parameter.  Maybe just value like the double version uses?", "author": "not-napoleon", "createdAt": "2020-07-08T18:11:19Z", "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/LongBounds.java", "diffHunk": "@@ -218,6 +215,16 @@ public Long getMax() {\n         return max;\n     }\n \n+    public boolean contain(long time) {", "originalCommit": "5f63ab88ac8b4d46a35eb675ab4c1c1ae131555a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTczOTA2OQ==", "url": "https://github.com/elastic/elasticsearch/pull/59175#discussion_r451739069", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                        final double effectiveFrom = hardBounds != null && hardBounds.getMin() != null ?\n          \n          \n            \n                                        final double effectiveFrom = (hardBounds != null && hardBounds.getMin() != null) ?\n          \n      \n    \n    \n  \n\nAs above.", "author": "not-napoleon", "createdAt": "2020-07-08T18:18:27Z", "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/RangeHistogramAggregator.java", "diffHunk": "@@ -108,9 +110,13 @@ public void collect(int doc, long owningBucketOrd) throws IOException {\n                             // The encoding should ensure that this assert is always true.\n                             assert from >= previousFrom : \"Start of range not >= previous start\";\n                             final Double to = rangeType.doubleValue(range.getTo());\n-                            final double startKey = Math.floor((from - offset) / interval);\n-                            final double endKey = Math.floor((to - offset) / interval);\n-                            for (double  key = startKey > previousKey ? startKey : previousKey; key <= endKey; key++) {\n+                            final double effectiveFrom = hardBounds != null && hardBounds.getMin() != null ?", "originalCommit": "5f63ab88ac8b4d46a35eb675ab4c1c1ae131555a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTczOTMyMQ==", "url": "https://github.com/elastic/elasticsearch/pull/59175#discussion_r451739321", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                        final double effectiveTo = hardBounds != null && hardBounds.getMax() != null ?\n          \n          \n            \n                                        final double effectiveTo = (hardBounds != null && hardBounds.getMax() != null) ?", "author": "not-napoleon", "createdAt": "2020-07-08T18:18:58Z", "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/RangeHistogramAggregator.java", "diffHunk": "@@ -108,9 +110,13 @@ public void collect(int doc, long owningBucketOrd) throws IOException {\n                             // The encoding should ensure that this assert is always true.\n                             assert from >= previousFrom : \"Start of range not >= previous start\";\n                             final Double to = rangeType.doubleValue(range.getTo());\n-                            final double startKey = Math.floor((from - offset) / interval);\n-                            final double endKey = Math.floor((to - offset) / interval);\n-                            for (double  key = startKey > previousKey ? startKey : previousKey; key <= endKey; key++) {\n+                            final double effectiveFrom = hardBounds != null && hardBounds.getMin() != null ?\n+                                Double.max(from, hardBounds.getMin()) : from;\n+                            final double effectiveTo = hardBounds != null && hardBounds.getMax() != null ?", "originalCommit": "5f63ab88ac8b4d46a35eb675ab4c1c1ae131555a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTc0NTkzNQ==", "url": "https://github.com/elastic/elasticsearch/pull/59175#discussion_r451745935", "bodyText": "I think it would be good to have a test for hard bounds exactly equal to extended bounds.  That's a bit of an edge case, and we want to make sure it doesn't break down the line.", "author": "not-napoleon", "createdAt": "2020-07-08T18:30:42Z", "path": "server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/DateRangeHistogramAggregatorTests.java", "diffHunk": "@@ -658,6 +660,118 @@ public void testWithinQuery() throws Exception {\n         );\n     }\n \n+    public void testHardBounds() throws Exception {\n+        RangeFieldMapper.Range range1 = new RangeFieldMapper.Range(RangeType.DATE, asLong(\"2019-08-02T02:15:00\"),\n+            asLong(\"2019-08-02T05:45:00\"), true, true);\n+        RangeFieldMapper.Range range2 = new RangeFieldMapper.Range(RangeType.DATE, asLong(\"2019-08-02T05:15:00\"),\n+            asLong(\"2019-08-02T17:45:00\"), true, true);\n+\n+        testCase(\n+            Queries.newMatchAllQuery(),\n+            builder -> builder.calendarInterval(DateHistogramInterval.HOUR).hardBounds(\n+                new LongBounds(\"2019-08-02T03:00:00\", \"2019-08-02T10:00:00\")),\n+            writer -> {\n+                writer.addDocument(singleton(new BinaryDocValuesField(FIELD_NAME, RangeType.DATE.encodeRanges(singleton(range1)))));\n+                writer.addDocument(singleton(new BinaryDocValuesField(FIELD_NAME, RangeType.DATE.encodeRanges(singleton(range2)))));\n+            },\n+            histo -> {\n+                assertEquals(8, histo.getBuckets().size());\n+\n+                assertEquals(asZDT(\"2019-08-02T03:00:00\"), histo.getBuckets().get(0).getKey());\n+                assertEquals(1, histo.getBuckets().get(0).getDocCount());\n+\n+                assertEquals(asZDT(\"2019-08-02T05:00:00\"), histo.getBuckets().get(2).getKey());\n+                assertEquals(2, histo.getBuckets().get(2).getDocCount());\n+\n+                assertEquals(asZDT(\"2019-08-02T10:00:00\"), histo.getBuckets().get(7).getKey());\n+                assertEquals(1, histo.getBuckets().get(7).getDocCount());\n+\n+                assertTrue(AggregationInspectionHelper.hasValue(histo));\n+            }\n+        );\n+    }\n+    public void testHardBoundsWithOpenRanges() throws Exception {\n+        RangeFieldMapper.Range range1 = new RangeFieldMapper.Range(RangeType.DATE, Long.MIN_VALUE,\n+            asLong(\"2019-08-02T05:45:00\"), true, true);\n+        RangeFieldMapper.Range range2 = new RangeFieldMapper.Range(RangeType.DATE, asLong(\"2019-08-02T05:15:00\"),\n+            Long.MAX_VALUE, true, true);\n+\n+        testCase(\n+            Queries.newMatchAllQuery(),\n+            builder -> builder.calendarInterval(DateHistogramInterval.HOUR).hardBounds(\n+                new LongBounds(\"2019-08-02T03:00:00\", \"2019-08-02T10:00:00\")),\n+            writer -> {\n+                writer.addDocument(singleton(new BinaryDocValuesField(FIELD_NAME, RangeType.DATE.encodeRanges(singleton(range1)))));\n+                writer.addDocument(singleton(new BinaryDocValuesField(FIELD_NAME, RangeType.DATE.encodeRanges(singleton(range2)))));\n+            },\n+            histo -> {\n+                assertEquals(8, histo.getBuckets().size());\n+\n+                assertEquals(asZDT(\"2019-08-02T03:00:00\"), histo.getBuckets().get(0).getKey());\n+                assertEquals(1, histo.getBuckets().get(0).getDocCount());\n+\n+                assertEquals(asZDT(\"2019-08-02T05:00:00\"), histo.getBuckets().get(2).getKey());\n+                assertEquals(2, histo.getBuckets().get(2).getDocCount());\n+\n+                assertEquals(asZDT(\"2019-08-02T10:00:00\"), histo.getBuckets().get(7).getKey());\n+                assertEquals(1, histo.getBuckets().get(7).getDocCount());\n+\n+                assertTrue(AggregationInspectionHelper.hasValue(histo));\n+            }\n+        );\n+    }\n+\n+    public void testBothBounds() throws Exception {\n+        RangeFieldMapper.Range range1 = new RangeFieldMapper.Range(RangeType.DATE, asLong(\"2019-08-02T02:15:00\"),\n+            asLong(\"2019-08-02T05:45:00\"), true, true);\n+        RangeFieldMapper.Range range2 = new RangeFieldMapper.Range(RangeType.DATE, asLong(\"2019-08-02T05:15:00\"),\n+            asLong(\"2019-08-02T17:45:00\"), true, true);\n+\n+        testCase(\n+            Queries.newMatchAllQuery(),\n+            builder -> builder.calendarInterval(DateHistogramInterval.HOUR)\n+                .hardBounds(new LongBounds(\"2019-08-02T00:00:00\", \"2019-08-02T10:00:00\"))\n+                .extendedBounds(new LongBounds(\"2019-08-02T01:00:00\", \"2019-08-02T08:00:00\")),\n+            writer -> {\n+                writer.addDocument(singleton(new BinaryDocValuesField(FIELD_NAME, RangeType.DATE.encodeRanges(singleton(range1)))));\n+                writer.addDocument(singleton(new BinaryDocValuesField(FIELD_NAME, RangeType.DATE.encodeRanges(singleton(range2)))));\n+            },\n+            histo -> {\n+                assertEquals(10, histo.getBuckets().size());\n+\n+                assertEquals(asZDT(\"2019-08-02T01:00:00\"), histo.getBuckets().get(0).getKey());\n+                assertEquals(0, histo.getBuckets().get(0).getDocCount());\n+\n+                assertEquals(asZDT(\"2019-08-02T02:00:00\"), histo.getBuckets().get(1).getKey());\n+                assertEquals(1, histo.getBuckets().get(1).getDocCount());\n+\n+                assertEquals(asZDT(\"2019-08-02T10:00:00\"), histo.getBuckets().get(9).getKey());\n+                assertEquals(1, histo.getBuckets().get(9).getDocCount());\n+\n+                assertTrue(AggregationInspectionHelper.hasValue(histo));\n+            }\n+        );\n+    }\n+\n+    public void testOverlappingBounds() throws Exception {", "originalCommit": "5f63ab88ac8b4d46a35eb675ab4c1c1ae131555a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "5f0b7ad2d242adb28e448f133dd203245e32af37", "url": "https://github.com/elastic/elasticsearch/commit/5f0b7ad2d242adb28e448f133dd203245e32af37", "message": "Update server/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/DateRangeHistogramAggregator.java\n\nCo-authored-by: Mark Tozzi <mark.tozzi@gmail.com>", "committedDate": "2020-07-13T17:32:58Z", "type": "commit"}, {"oid": "f656c754b158a05a0885da5ce0e80d6522aafdf4", "url": "https://github.com/elastic/elasticsearch/commit/f656c754b158a05a0885da5ce0e80d6522aafdf4", "message": "Update server/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/DateRangeHistogramAggregator.java\n\nCo-authored-by: Mark Tozzi <mark.tozzi@gmail.com>", "committedDate": "2020-07-13T17:33:08Z", "type": "commit"}, {"oid": "986d62fc15d9a65da8a5b24686a0fa4114f13ff6", "url": "https://github.com/elastic/elasticsearch/commit/986d62fc15d9a65da8a5b24686a0fa4114f13ff6", "message": "Update server/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/RangeHistogramAggregator.java\n\nCo-authored-by: Mark Tozzi <mark.tozzi@gmail.com>", "committedDate": "2020-07-13T17:41:59Z", "type": "commit"}, {"oid": "491fa7b9c4423b648f32f94a33d02959c41b78cc", "url": "https://github.com/elastic/elasticsearch/commit/491fa7b9c4423b648f32f94a33d02959c41b78cc", "message": "Update server/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/RangeHistogramAggregator.java\n\nCo-authored-by: Mark Tozzi <mark.tozzi@gmail.com>", "committedDate": "2020-07-13T17:42:06Z", "type": "commit"}, {"oid": "724261851fd234978e4d6f94e28af24b0795787e", "url": "https://github.com/elastic/elasticsearch/commit/724261851fd234978e4d6f94e28af24b0795787e", "message": "Address review comments", "committedDate": "2020-07-13T18:08:35Z", "type": "commit"}, {"oid": "18c8af59eb0a9ecf0e52685a6cfdb16ba12caf7b", "url": "https://github.com/elastic/elasticsearch/commit/18c8af59eb0a9ecf0e52685a6cfdb16ba12caf7b", "message": "Merge remote-tracking branch 'elastic/master' into issue-50109-add-restrictive-bounds", "committedDate": "2020-07-13T18:59:41Z", "type": "commit"}, {"oid": "fbd8a60b4745538c77910d46d31f992a00081026", "url": "https://github.com/elastic/elasticsearch/commit/fbd8a60b4745538c77910d46d31f992a00081026", "message": "Fix HistoBackedHistogramAggregator after merge", "committedDate": "2020-07-13T19:00:15Z", "type": "commit"}]}