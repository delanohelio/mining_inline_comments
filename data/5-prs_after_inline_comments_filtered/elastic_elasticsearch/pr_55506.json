{"pr_number": 55506, "pr_title": "Use streaming reads for GCS", "pr_createdAt": "2020-04-21T08:38:34Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/55506", "timeline": [{"oid": "2097f2bcfa333a7154ebb59c4ed63f08ce85f406", "url": "https://github.com/elastic/elasticsearch/commit/2097f2bcfa333a7154ebb59c4ed63f08ce85f406", "message": "Use streaming reads for GCS", "committedDate": "2020-04-21T08:30:43Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTk5NTc3OA==", "url": "https://github.com/elastic/elasticsearch/pull/55506#discussion_r411995778", "bodyText": "NIT: get.getRequestHeaders().setRange(\"bytes=\" + Math.addExact(start, currentOffset) + \"-\" + end);", "author": "original-brownbear", "createdAt": "2020-04-21T08:47:49Z", "path": "plugins/repository-gcs/src/main/java/org/elasticsearch/repositories/gcs/GoogleCloudStorageRetryingInputStream.java", "diffHunk": "@@ -51,111 +56,141 @@\n     static final int MAX_SUPPRESSED_EXCEPTIONS = 10;\n \n     private final Storage client;\n+    private final com.google.api.services.storage.Storage storage;\n \n     private final BlobId blobId;\n \n     private final long start;\n-    private final long length;\n+    private final long end;\n \n-    private final int maxRetries;\n+    private final int maxAttempts;\n \n     private InputStream currentStream;\n     private int attempt = 1;\n     private List<StorageException> failures = new ArrayList<>(MAX_SUPPRESSED_EXCEPTIONS);\n     private long currentOffset;\n     private boolean closed;\n \n-    GoogleCloudStorageRetryingInputStream(Storage client, BlobId blobId, long start, long length) throws IOException {\n+    GoogleCloudStorageRetryingInputStream(Storage client, BlobId blobId) throws IOException {\n+        this(client, blobId, 0, Long.MAX_VALUE - 1);\n+    }\n+\n+    // both start and end are inclusive bounds, following the definition in https://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.35\n+    GoogleCloudStorageRetryingInputStream(Storage client, BlobId blobId, long start, long end) throws IOException {\n+        if (start < 0L) {\n+            throw new IllegalArgumentException(\"start must be non-negative\");\n+        }\n+        if (end < start || end == Long.MAX_VALUE) {\n+            throw new IllegalArgumentException(\"end must be >= start and not Long.MAX_VALUE\");\n+        }\n         this.client = client;\n         this.blobId = blobId;\n         this.start = start;\n-        this.length = length;\n-        this.maxRetries = client.getOptions().getRetrySettings().getMaxAttempts() + 1;\n+        this.end = end;\n+        this.maxAttempts = client.getOptions().getRetrySettings().getMaxAttempts();\n+        SpecialPermission.check();\n+        storage = getStorage(client);\n         currentStream = openStream();\n     }\n \n-    private static final int DEFAULT_CHUNK_SIZE = 2 * 1024 * 1024;\n+    @SuppressForbidden(reason = \"need access to storage client\")\n+    private static com.google.api.services.storage.Storage getStorage(Storage client) {\n+        return AccessController.doPrivileged((PrivilegedAction<com.google.api.services.storage.Storage>) () -> {\n+            assert client.getOptions().getRpc() instanceof HttpStorageRpc;\n+            assert Stream.of(client.getOptions().getRpc().getClass().getDeclaredFields()).anyMatch(f -> f.getName().equals(\"storage\"));\n+            try {\n+                final Field storageField = client.getOptions().getRpc().getClass().getDeclaredField(\"storage\");\n+                storageField.setAccessible(true);\n+                return (com.google.api.services.storage.Storage) storageField.get(client.getOptions().getRpc());\n+            } catch (Exception e) {\n+                throw new IllegalStateException(\"storage could not be set up\", e);\n+            }\n+        });\n+    }\n \n     private InputStream openStream() throws IOException {\n         try {\n-            final ReadChannel readChannel = SocketAccess.doPrivilegedIOException(() -> client.reader(blobId));\n-            final long end = start + length < 0L ? Long.MAX_VALUE : start + length; // inclusive\n-            final SeekableByteChannel adaptedChannel = new SeekableByteChannel() {\n-\n-                long position;\n-\n-                @SuppressForbidden(reason = \"Channel is based of a socket not a file\")\n-                @Override\n-                public int read(ByteBuffer dst) throws IOException {\n-                    final long remainingBytesToRead = end - position;\n-                    assert remainingBytesToRead >= 0L;\n-                    // The SDK uses the maximum between chunk size and dst.remaining() to determine fetch size\n-                    // We can be smarter here and only fetch what's needed when we know the length\n-                    if (remainingBytesToRead < DEFAULT_CHUNK_SIZE) {\n-                        readChannel.setChunkSize(Math.toIntExact(remainingBytesToRead));\n-                    }\n-                    if (remainingBytesToRead < dst.remaining()) {\n-                        dst.limit(dst.position() + Math.toIntExact(remainingBytesToRead));\n-                    }\n-                    try {\n-                        int read = SocketAccess.doPrivilegedIOException(() -> readChannel.read(dst));\n-                        if (read > 0) {\n-                            position += read;\n-                        }\n-                        return read;\n-                    } catch (StorageException e) {\n-                        if (e.getCode() == HTTP_NOT_FOUND) {\n-                            throw new NoSuchFileException(\"Blob object [\" + blobId.getName() + \"] not found: \" + e.getMessage());\n+            try {\n+                return RetryHelper.runWithRetries(() -> {\n+                        try {\n+                            return SocketAccess.doPrivilegedIOException(() -> {\n+                                final Get get = storage.objects().get(blobId.getBucket(), blobId.getName());\n+                                get.setReturnRawInputStream(true);\n+\n+                                if (currentOffset > 0 || start > 0 || end < Long.MAX_VALUE - 1) {\n+                                    StringBuilder rangeHeader = new StringBuilder();\n+                                    rangeHeader.append(\"bytes=\").append(Math.addExact(start, currentOffset)).append(\"-\").append(end);\n+                                    get.getRequestHeaders().setRange(rangeHeader.toString());", "originalCommit": "2097f2bcfa333a7154ebb59c4ed63f08ce85f406", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "87ff1caae178ac1bcc7266d2c27ddd4de24aa6d1", "url": "https://github.com/elastic/elasticsearch/commit/87ff1caae178ac1bcc7266d2c27ddd4de24aa6d1", "message": "shorter", "committedDate": "2020-04-21T09:58:09Z", "type": "commit"}, {"oid": "44efd55a0ea42aa2bbb8cb845fc1164b1a7b5064", "url": "https://github.com/elastic/elasticsearch/commit/44efd55a0ea42aa2bbb8cb845fc1164b1a7b5064", "message": "Merge remote-tracking branch 'elastic/master' into gcs-read", "committedDate": "2020-04-21T10:00:45Z", "type": "commit"}, {"oid": "64819adbd29b7b9a24b3b44cc17c0347c01eb235", "url": "https://github.com/elastic/elasticsearch/commit/64819adbd29b7b9a24b3b44cc17c0347c01eb235", "message": "remove test mute", "committedDate": "2020-04-21T10:02:10Z", "type": "commit"}]}