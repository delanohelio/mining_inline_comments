{"pr_number": 65933, "pr_title": "Autoscaling proactive storage decider", "pr_createdAt": "2020-12-07T11:30:53Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/65933", "timeline": [{"oid": "6a022338b839e8c9becc728e5f8a771353075603", "url": "https://github.com/elastic/elasticsearch/commit/6a022338b839e8c9becc728e5f8a771353075603", "message": "Autoscaling proactive storage decider\n\nThe proactive storage decider looks at past indexing in data streams and\ncalculates a required capacity that ensures that the set of nodes\ngoverned by the policy can handle adding a similar amount of data. The\ntime looked back is called the forecast window and defaults to 30\nminutes.\n\nThis initial version only ensures that enough storage is available for\nprimaries.", "committedDate": "2020-12-07T11:29:17Z", "type": "commit"}, {"oid": "248fc67a03f2c7466a036d99ab1f96ae4b4f3809", "url": "https://github.com/elastic/elasticsearch/commit/248fc67a03f2c7466a036d99ab1f96ae4b4f3809", "message": "More testing", "committedDate": "2020-12-07T17:12:53Z", "type": "commit"}, {"oid": "4b17f585af0a864eef86b06f88b237b6fad20b5d", "url": "https://github.com/elastic/elasticsearch/commit/4b17f585af0a864eef86b06f88b237b6fad20b5d", "message": "spotless", "committedDate": "2020-12-07T17:14:34Z", "type": "commit"}, {"oid": "b70728b951b499066a3fe9e7d24451f9ccf75af7", "url": "https://github.com/elastic/elasticsearch/commit/b70728b951b499066a3fe9e7d24451f9ccf75af7", "message": "Merge remote-tracking branch 'origin/master' into enhance_autoscaling_proactive_storage_decider_pr", "committedDate": "2020-12-07T17:14:54Z", "type": "commit"}, {"oid": "55485f613e6b329c52cbcf7fdb2be6819325c436", "url": "https://github.com/elastic/elasticsearch/commit/55485f613e6b329c52cbcf7fdb2be6819325c436", "message": "nicer", "committedDate": "2020-12-07T17:16:13Z", "type": "commit"}, {"oid": "b7eae203ad7460fbafa67202e95eb4b78b56b388", "url": "https://github.com/elastic/elasticsearch/commit/b7eae203ad7460fbafa67202e95eb4b78b56b388", "message": "checkstyle", "committedDate": "2020-12-08T17:57:07Z", "type": "commit"}, {"oid": "018a89bd4ae9dd809220751df4915799200e85f8", "url": "https://github.com/elastic/elasticsearch/commit/018a89bd4ae9dd809220751df4915799200e85f8", "message": "Merge remote-tracking branch 'origin/master' into enhance_autoscaling_proactive_storage_decider_pr", "committedDate": "2020-12-10T12:37:47Z", "type": "commit"}, {"oid": "741acc4cffca8b3adf0961c62b0c6c23a741fa33", "url": "https://github.com/elastic/elasticsearch/commit/741acc4cffca8b3adf0961c62b0c6c23a741fa33", "message": "Fix NPE", "committedDate": "2020-12-10T12:38:07Z", "type": "commit"}, {"oid": "047beae9d180348eb7198b573388b3cc701735a5", "url": "https://github.com/elastic/elasticsearch/commit/047beae9d180348eb7198b573388b3cc701735a5", "message": "Merge remote-tracking branch 'origin/master' into enhance_autoscaling_proactive_storage_decider_pr", "committedDate": "2020-12-13T21:22:30Z", "type": "commit"}, {"oid": "8a7d7e05e601b4b4c1d749023dc4144a8807a1e7", "url": "https://github.com/elastic/elasticsearch/commit/8a7d7e05e601b4b4c1d749023dc4144a8807a1e7", "message": "fix compilation", "committedDate": "2020-12-13T21:29:40Z", "type": "commit"}, {"oid": "0a79b75a43f88649d7c4294d8b01004db9544be2", "url": "https://github.com/elastic/elasticsearch/commit/0a79b75a43f88649d7c4294d8b01004db9544be2", "message": "Message and variable names.", "committedDate": "2020-12-14T07:46:27Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE3NTMxNQ==", "url": "https://github.com/elastic/elasticsearch/pull/65933#discussion_r542175315", "bodyText": "I started on this, but decided that it will be less friendly to the reviewers to do this up front than to leave it for a follow-up. I will move this class to a top-level class as well as move the associated tests to a new AllocationStateTests in a follow-up.", "author": "henningandersen", "createdAt": "2020-12-14T07:52:19Z", "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "diffHunk": "@@ -114,14 +125,16 @@ static boolean isDiskOnlyNoDecision(Decision decision) {\n         return nos.size() == 1 && DiskThresholdDecider.NAME.equals(nos.get(0).label());\n     }\n \n-    static class AllocationState {\n+    // todo: move this to top level class.", "originalCommit": "8a7d7e05e601b4b4c1d749023dc4144a8807a1e7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzA0MTMwMw==", "url": "https://github.com/elastic/elasticsearch/pull/65933#discussion_r543041303", "bodyText": "I should have thought of this during the review for the reactive storage decider.\nThe DiskThresholdSettings constructor registers a cluster settings updated consumer. This means that we do not necessarily get an atomic view of the disk threshold settings. For example, on lines \n  \n    \n      elasticsearch/x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java\n    \n    \n        Lines 303 to 304\n      in\n      047beae\n    \n    \n    \n    \n\n        \n          \n           diskThresholdSettings.getFreeBytesThresholdHigh().getBytes(), \n        \n\n        \n          \n           thresholdFromPercentage(diskThresholdSettings.getFreeDiskThresholdHigh(), diskUsage) \n        \n    \n  \n\n, we could get an inconsitent view if an update is applied in between those lines.\nI think that we can address this in a follow up as a bug, but I want to highlight the issue here.", "author": "jasontedor", "createdAt": "2020-12-15T04:40:53Z", "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ProactiveStorageDeciderService.java", "diffHunk": "@@ -0,0 +1,181 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.autoscaling.storage;\n+\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.allocation.DiskThresholdSettings;\n+import org.elasticsearch.cluster.routing.allocation.decider.AllocationDeciders;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingCapacity;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderContext;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderResult;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderService;\n+import org.elasticsearch.xpack.core.DataTier;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Objects;\n+\n+public class ProactiveStorageDeciderService implements AutoscalingDeciderService {\n+    public static final String NAME = \"proactive_storage\";\n+    public static final Setting<TimeValue> FORECAST_WINDOW = Setting.timeSetting(\"forecast_window\", TimeValue.timeValueMinutes(30));\n+\n+    private final DiskThresholdSettings diskThresholdSettings;\n+    private final AllocationDeciders allocationDeciders;\n+\n+    public ProactiveStorageDeciderService(Settings settings, ClusterSettings clusterSettings, AllocationDeciders allocationDeciders) {\n+        this.diskThresholdSettings = new DiskThresholdSettings(settings, clusterSettings);", "originalCommit": "8a7d7e05e601b4b4c1d749023dc4144a8807a1e7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzE1OTg0Ng==", "url": "https://github.com/elastic/elasticsearch/pull/65933#discussion_r543159846", "bodyText": "This is a good point and unfortunately, it ties deeper than the calculation you highlight there. We also implicitly use the disk threshold settings on the disk decider and risk similar issues there, at least when called from autoscaling. Also, the DiskThresholdMonitor can experience similar inconsistent views. I would also prefer to tackle this in a follow-up.", "author": "henningandersen", "createdAt": "2020-12-15T08:56:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzA0MTMwMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI2NTc4NA==", "url": "https://github.com/elastic/elasticsearch/pull/65933#discussion_r543265784", "bodyText": "Yup, totally fine with a follow up, recognizing it's not a small issue.", "author": "jasontedor", "createdAt": "2020-12-15T11:30:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzA0MTMwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzA0MTYyNg==", "url": "https://github.com/elastic/elasticsearch/pull/65933#discussion_r543041626", "bodyText": "I can't remember if we discussed this or not, should this apply to the data_content role?", "author": "jasontedor", "createdAt": "2020-12-15T04:41:46Z", "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ProactiveStorageDeciderService.java", "diffHunk": "@@ -0,0 +1,181 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.autoscaling.storage;\n+\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.allocation.DiskThresholdSettings;\n+import org.elasticsearch.cluster.routing.allocation.decider.AllocationDeciders;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingCapacity;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderContext;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderResult;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderService;\n+import org.elasticsearch.xpack.core.DataTier;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Objects;\n+\n+public class ProactiveStorageDeciderService implements AutoscalingDeciderService {\n+    public static final String NAME = \"proactive_storage\";\n+    public static final Setting<TimeValue> FORECAST_WINDOW = Setting.timeSetting(\"forecast_window\", TimeValue.timeValueMinutes(30));\n+\n+    private final DiskThresholdSettings diskThresholdSettings;\n+    private final AllocationDeciders allocationDeciders;\n+\n+    public ProactiveStorageDeciderService(Settings settings, ClusterSettings clusterSettings, AllocationDeciders allocationDeciders) {\n+        this.diskThresholdSettings = new DiskThresholdSettings(settings, clusterSettings);\n+        this.allocationDeciders = allocationDeciders;\n+    }\n+\n+    @Override\n+    public String name() {\n+        return NAME;\n+    }\n+\n+    @Override\n+    public List<DiscoveryNodeRole> roles() {\n+        return List.of(DiscoveryNodeRole.DATA_ROLE, DataTier.DATA_HOT_NODE_ROLE);", "originalCommit": "8a7d7e05e601b4b4c1d749023dc4144a8807a1e7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzE0NjA0NQ==", "url": "https://github.com/elastic/elasticsearch/pull/65933#discussion_r543146045", "bodyText": "I do not recall discussing this in particular. I believe we originally talked about this for time-based data mostly. This PR only implements forecasting for data streams.\nForecasting non-time-based data would likely require a vastly different PR keeping track of space usage over time of indices.\nI would be inclined to leave this enabled for hot role only for now at least, though I should be interested in whether above matches your reasoning.", "author": "henningandersen", "createdAt": "2020-12-15T08:36:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzA0MTYyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI2NjA1Mw==", "url": "https://github.com/elastic/elasticsearch/pull/65933#discussion_r543266053", "bodyText": "That lines up with my thinking.", "author": "jasontedor", "createdAt": "2020-12-15T11:31:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzA0MTYyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzA0MzkwMw==", "url": "https://github.com/elastic/elasticsearch/pull/65933#discussion_r543043903", "bodyText": "diff --git a/x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java b/x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java\nindex dc51b345dea..dfaca13f559 100644\n--- a/x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java\n+++ b/x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java\n@@ -464,8 +464,8 @@ public class ReactiveStorageDeciderService implements AutoscalingDeciderService\n                 Set<Boolean> inNodes = state.getRoutingTable()\n                     .allShards(indexMetadata.getIndex().getName())\n                     .stream()\n-                    .filter(s -> s.currentNodeId() != null)\n                     .map(ShardRouting::currentNodeId)\n+                    .filter(Objects::nonNull)\n                     .map(nodeIds::contains)\n                     .collect(Collectors.toSet());\n                 if (inNodes.contains(false)) {", "author": "jasontedor", "createdAt": "2020-12-15T04:48:40Z", "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "diffHunk": "@@ -302,7 +316,224 @@ private long thresholdFromPercentage(Double percentage, DiskUsage diskUsage) {\n         }\n \n         Stream<RoutingNode> nodesInTier(RoutingNodes routingNodes) {\n-            return nodes.stream().map(n -> routingNodes.node(n.getId()));\n+            return nodeIds.stream().map(n -> routingNodes.node(n));\n+        }\n+\n+        private static class SingleForecast {\n+            private final Map<IndexMetadata, Long> additionalIndices;\n+            private final DataStream updatedDataStream;\n+\n+            private SingleForecast(Map<IndexMetadata, Long> additionalIndices, DataStream updatedDataStream) {\n+                this.additionalIndices = additionalIndices;\n+                this.updatedDataStream = updatedDataStream;\n+            }\n+\n+            public void applyRouting(RoutingTable.Builder routing) {\n+                additionalIndices.keySet().forEach(routing::addAsNew);\n+            }\n+\n+            public void applyMetadata(Metadata.Builder metadataBuilder) {\n+                additionalIndices.keySet().forEach(imd -> metadataBuilder.put(imd, false));\n+                metadataBuilder.put(updatedDataStream);\n+            }\n+\n+            public void applySize(ImmutableOpenMap.Builder<String, Long> builder, RoutingTable updatedRoutingTable) {\n+                for (Map.Entry<IndexMetadata, Long> entry : additionalIndices.entrySet()) {\n+                    List<ShardRouting> shardRoutings = updatedRoutingTable.allShards(entry.getKey().getIndex().getName());\n+                    long size = entry.getValue() / shardRoutings.size();\n+                    shardRoutings.forEach(s -> builder.put(ClusterInfo.shardIdentifierFromRouting(s), size));\n+                }\n+            }\n+        }\n+\n+        public AllocationState forecast(long forecastWindow, long now) {\n+            if (forecastWindow == 0) {\n+                return this;\n+            }\n+            // for now we only look at data-streams. We might want to also detect alias based time-based indices.\n+            DataStreamMetadata dataStreamMetadata = state.metadata().custom(DataStreamMetadata.TYPE);\n+            if (dataStreamMetadata == null) {\n+                return this;\n+            }\n+            List<SingleForecast> singleForecasts = dataStreamMetadata.dataStreams()\n+                .keySet()\n+                .stream()\n+                .map(state.metadata().getIndicesLookup()::get)\n+                .map(IndexAbstraction.DataStream.class::cast)\n+                .map(ds -> forecast(ds, forecastWindow, now))\n+                .filter(Objects::nonNull)\n+                .collect(Collectors.toList());\n+            if (singleForecasts.isEmpty()) {\n+                return this;\n+            }\n+            Metadata.Builder metadataBuilder = Metadata.builder(state.metadata());\n+            RoutingTable.Builder routingTableBuilder = RoutingTable.builder(state.routingTable());\n+            ImmutableOpenMap.Builder<String, Long> sizeBuilder = ImmutableOpenMap.builder();\n+            singleForecasts.forEach(p -> p.applyMetadata(metadataBuilder));\n+            singleForecasts.forEach(p -> p.applyRouting(routingTableBuilder));\n+            RoutingTable routingTable = routingTableBuilder.build();\n+            singleForecasts.forEach(p -> p.applySize(sizeBuilder, routingTable));\n+            ClusterState forecastClusterState = ClusterState.builder(state).metadata(metadataBuilder).routingTable(routingTable).build();\n+            ClusterInfo forecastInfo = new ExtendedClusterInfo(sizeBuilder.build(), AllocationState.this.info);\n+\n+            return new AllocationState(forecastClusterState, allocationDeciders, diskThresholdSettings, forecastInfo, shardSizeInfo, nodes);\n+        }\n+\n+        private SingleForecast forecast(IndexAbstraction.DataStream stream, long forecastWindow, long now) {\n+            List<IndexMetadata> indices = stream.getIndices();\n+            if (dataStreamAllocatedToNodes(indices) == false) return null;\n+            long minCreationDate = Long.MAX_VALUE;\n+            long totalSize = 0;\n+            int count = 0;\n+            while (count < indices.size()) {\n+                ++count;\n+                IndexMetadata indexMetadata = indices.get(indices.size() - count);\n+                long creationDate = indexMetadata.getCreationDate();\n+                if (creationDate < 0) {\n+                    return null;\n+                }\n+                minCreationDate = Math.min(minCreationDate, creationDate);\n+                totalSize += state.getRoutingTable().allShards(indexMetadata.getIndex().getName()).stream().mapToLong(this::sizeOf).sum();\n+                // we terminate loop after collecting data to ensure we consider at least the forecast window (and likely some more).\n+                if (creationDate <= now - forecastWindow) {\n+                    break;\n+                }\n+            }\n+\n+            if (totalSize == 0) {\n+                return null;\n+            }\n+\n+            long avgSize = (totalSize - 1) / count + 1;\n+\n+            long actualWindow = now - minCreationDate;\n+            if (actualWindow == 0) {\n+                return null;\n+            }\n+\n+            // rather than simulate rollover, we copy the index meta data and do minimal adjustments.\n+            long scaledTotalSize;\n+            int numberNewIndices;\n+            if (actualWindow > forecastWindow) {\n+                scaledTotalSize = BigInteger.valueOf(totalSize)\n+                    .multiply(BigInteger.valueOf(forecastWindow))\n+                    .divide(BigInteger.valueOf(actualWindow))\n+                    .longValueExact();\n+                numberNewIndices = (int) Math.min((scaledTotalSize - 1) / avgSize + 1, indices.size());\n+                if (scaledTotalSize == 0) {\n+                    return null;\n+                }\n+            } else {\n+                numberNewIndices = count;\n+                scaledTotalSize = totalSize;\n+            }\n+\n+            IndexMetadata writeIndex = stream.getWriteIndex();\n+\n+            Map<IndexMetadata, Long> newIndices = new HashMap<>();\n+            DataStream dataStream = stream.getDataStream();\n+            for (int i = 0; i < numberNewIndices; ++i) {\n+                final String newWriteIndexName = DataStream.getDefaultBackingIndexName(\n+                    dataStream.getName(),\n+                    dataStream.getGeneration() + 1\n+                );\n+                IndexMetadata newIndex = IndexMetadata.builder(writeIndex)\n+                    .index(newWriteIndexName)\n+                    .settings(\n+                        Settings.builder().put(writeIndex.getSettings()).put(IndexMetadata.SETTING_INDEX_UUID, UUIDs.randomBase64UUID())\n+                    )\n+                    .build();\n+                long size = Math.min(avgSize, scaledTotalSize - (avgSize * i));\n+                assert size > 0;\n+                newIndices.put(newIndex, size);\n+                dataStream = dataStream.rollover(newIndex.getIndex());\n+            }\n+\n+            return new SingleForecast(newIndices, dataStream);\n+        }\n+\n+        /**\n+         * Check that at least one shard is on the set of nodes. If they are all unallocated, we do not want to make any prediction to not\n+         * hit the wrong policy.\n+         * @param indices the indices of the data stream, in original order from data stream meta.\n+         * @return true if the first allocated index is allocated only to the set of nodes.\n+         */\n+        private boolean dataStreamAllocatedToNodes(List<IndexMetadata> indices) {\n+            for (int i = 0; i < indices.size(); ++i) {\n+                IndexMetadata indexMetadata = indices.get(indices.size() - i - 1);\n+                Set<Boolean> inNodes = state.getRoutingTable()\n+                    .allShards(indexMetadata.getIndex().getName())\n+                    .stream()\n+                    .filter(s -> s.currentNodeId() != null)\n+                    .map(ShardRouting::currentNodeId)", "originalCommit": "8a7d7e05e601b4b4c1d749023dc4144a8807a1e7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzEzOTYyNQ==", "url": "https://github.com/elastic/elasticsearch/pull/65933#discussion_r543139625", "bodyText": "\ud83e\udd26 , done here: 96dc77d", "author": "henningandersen", "createdAt": "2020-12-15T08:26:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzA0MzkwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzA0NjQ5Ng==", "url": "https://github.com/elastic/elasticsearch/pull/65933#discussion_r543046496", "bodyText": "I don't understand the minus one in the numerator, nor the plus one. I guess that totalSize / count would be the average size, but that (totalSize - 1) / count + 1 is not, so what is it and can we use a better nam than avgSize?", "author": "jasontedor", "createdAt": "2020-12-15T04:56:49Z", "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "diffHunk": "@@ -302,7 +316,224 @@ private long thresholdFromPercentage(Double percentage, DiskUsage diskUsage) {\n         }\n \n         Stream<RoutingNode> nodesInTier(RoutingNodes routingNodes) {\n-            return nodes.stream().map(n -> routingNodes.node(n.getId()));\n+            return nodeIds.stream().map(n -> routingNodes.node(n));\n+        }\n+\n+        private static class SingleForecast {\n+            private final Map<IndexMetadata, Long> additionalIndices;\n+            private final DataStream updatedDataStream;\n+\n+            private SingleForecast(Map<IndexMetadata, Long> additionalIndices, DataStream updatedDataStream) {\n+                this.additionalIndices = additionalIndices;\n+                this.updatedDataStream = updatedDataStream;\n+            }\n+\n+            public void applyRouting(RoutingTable.Builder routing) {\n+                additionalIndices.keySet().forEach(routing::addAsNew);\n+            }\n+\n+            public void applyMetadata(Metadata.Builder metadataBuilder) {\n+                additionalIndices.keySet().forEach(imd -> metadataBuilder.put(imd, false));\n+                metadataBuilder.put(updatedDataStream);\n+            }\n+\n+            public void applySize(ImmutableOpenMap.Builder<String, Long> builder, RoutingTable updatedRoutingTable) {\n+                for (Map.Entry<IndexMetadata, Long> entry : additionalIndices.entrySet()) {\n+                    List<ShardRouting> shardRoutings = updatedRoutingTable.allShards(entry.getKey().getIndex().getName());\n+                    long size = entry.getValue() / shardRoutings.size();\n+                    shardRoutings.forEach(s -> builder.put(ClusterInfo.shardIdentifierFromRouting(s), size));\n+                }\n+            }\n+        }\n+\n+        public AllocationState forecast(long forecastWindow, long now) {\n+            if (forecastWindow == 0) {\n+                return this;\n+            }\n+            // for now we only look at data-streams. We might want to also detect alias based time-based indices.\n+            DataStreamMetadata dataStreamMetadata = state.metadata().custom(DataStreamMetadata.TYPE);\n+            if (dataStreamMetadata == null) {\n+                return this;\n+            }\n+            List<SingleForecast> singleForecasts = dataStreamMetadata.dataStreams()\n+                .keySet()\n+                .stream()\n+                .map(state.metadata().getIndicesLookup()::get)\n+                .map(IndexAbstraction.DataStream.class::cast)\n+                .map(ds -> forecast(ds, forecastWindow, now))\n+                .filter(Objects::nonNull)\n+                .collect(Collectors.toList());\n+            if (singleForecasts.isEmpty()) {\n+                return this;\n+            }\n+            Metadata.Builder metadataBuilder = Metadata.builder(state.metadata());\n+            RoutingTable.Builder routingTableBuilder = RoutingTable.builder(state.routingTable());\n+            ImmutableOpenMap.Builder<String, Long> sizeBuilder = ImmutableOpenMap.builder();\n+            singleForecasts.forEach(p -> p.applyMetadata(metadataBuilder));\n+            singleForecasts.forEach(p -> p.applyRouting(routingTableBuilder));\n+            RoutingTable routingTable = routingTableBuilder.build();\n+            singleForecasts.forEach(p -> p.applySize(sizeBuilder, routingTable));\n+            ClusterState forecastClusterState = ClusterState.builder(state).metadata(metadataBuilder).routingTable(routingTable).build();\n+            ClusterInfo forecastInfo = new ExtendedClusterInfo(sizeBuilder.build(), AllocationState.this.info);\n+\n+            return new AllocationState(forecastClusterState, allocationDeciders, diskThresholdSettings, forecastInfo, shardSizeInfo, nodes);\n+        }\n+\n+        private SingleForecast forecast(IndexAbstraction.DataStream stream, long forecastWindow, long now) {\n+            List<IndexMetadata> indices = stream.getIndices();\n+            if (dataStreamAllocatedToNodes(indices) == false) return null;\n+            long minCreationDate = Long.MAX_VALUE;\n+            long totalSize = 0;\n+            int count = 0;\n+            while (count < indices.size()) {\n+                ++count;\n+                IndexMetadata indexMetadata = indices.get(indices.size() - count);\n+                long creationDate = indexMetadata.getCreationDate();\n+                if (creationDate < 0) {\n+                    return null;\n+                }\n+                minCreationDate = Math.min(minCreationDate, creationDate);\n+                totalSize += state.getRoutingTable().allShards(indexMetadata.getIndex().getName()).stream().mapToLong(this::sizeOf).sum();\n+                // we terminate loop after collecting data to ensure we consider at least the forecast window (and likely some more).\n+                if (creationDate <= now - forecastWindow) {\n+                    break;\n+                }\n+            }\n+\n+            if (totalSize == 0) {\n+                return null;\n+            }\n+\n+            long avgSize = (totalSize - 1) / count + 1;", "originalCommit": "8a7d7e05e601b4b4c1d749023dc4144a8807a1e7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzE0MDc3MQ==", "url": "https://github.com/elastic/elasticsearch/pull/65933#discussion_r543140771", "bodyText": "It is the rounded up averageSize. I renamed it to avgSizeCeil and added a couple of comments here: 39e87c9", "author": "henningandersen", "createdAt": "2020-12-15T08:28:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzA0NjQ5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzA0NzEyNw==", "url": "https://github.com/elastic/elasticsearch/pull/65933#discussion_r543047127", "bodyText": "Same naming problem as in the reactive storage decdier PR.", "author": "jasontedor", "createdAt": "2020-12-15T04:58:43Z", "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ProactiveStorageDeciderService.java", "diffHunk": "@@ -0,0 +1,181 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.autoscaling.storage;\n+\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.allocation.DiskThresholdSettings;\n+import org.elasticsearch.cluster.routing.allocation.decider.AllocationDeciders;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingCapacity;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderContext;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderResult;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderService;\n+import org.elasticsearch.xpack.core.DataTier;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Objects;\n+\n+public class ProactiveStorageDeciderService implements AutoscalingDeciderService {\n+    public static final String NAME = \"proactive_storage\";\n+    public static final Setting<TimeValue> FORECAST_WINDOW = Setting.timeSetting(\"forecast_window\", TimeValue.timeValueMinutes(30));\n+\n+    private final DiskThresholdSettings diskThresholdSettings;\n+    private final AllocationDeciders allocationDeciders;\n+\n+    public ProactiveStorageDeciderService(Settings settings, ClusterSettings clusterSettings, AllocationDeciders allocationDeciders) {\n+        this.diskThresholdSettings = new DiskThresholdSettings(settings, clusterSettings);\n+        this.allocationDeciders = allocationDeciders;\n+    }\n+\n+    @Override\n+    public String name() {\n+        return NAME;\n+    }\n+\n+    @Override\n+    public List<DiscoveryNodeRole> roles() {\n+        return List.of(DiscoveryNodeRole.DATA_ROLE, DataTier.DATA_HOT_NODE_ROLE);\n+    }\n+\n+    @Override\n+    public AutoscalingDeciderResult scale(Settings configuration, AutoscalingDeciderContext context) {\n+        AutoscalingCapacity autoscalingCapacity = context.currentCapacity();\n+        if (autoscalingCapacity == null || autoscalingCapacity.total().storage() == null) {\n+            return new AutoscalingDeciderResult(\n+                null,\n+                new ReactiveStorageDeciderService.ReactiveReason(\"current capacity not available\", -1, -1)\n+            );\n+        }\n+\n+        ReactiveStorageDeciderService.AllocationState allocationState = new ReactiveStorageDeciderService.AllocationState(\n+            context,\n+            diskThresholdSettings,\n+            allocationDeciders\n+        );\n+        long unassignedBeforeForecast = allocationState.storagePreventsAllocation();\n+        assert unassignedBeforeForecast >= 0;\n+\n+        TimeValue forecastWindow = FORECAST_WINDOW.get(configuration);\n+        allocationState = allocationState.forecast(forecastWindow.millis(), System.currentTimeMillis());\n+\n+        long unassigned = allocationState.storagePreventsAllocation();\n+        long assigned = allocationState.storagePreventsRemainOrMove();\n+        long maxShard = allocationState.maxShardSize();\n+        assert assigned >= 0;\n+        assert unassigned >= unassignedBeforeForecast;\n+        assert maxShard >= 0;", "originalCommit": "8a7d7e05e601b4b4c1d749023dc4144a8807a1e7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzEyODczMQ==", "url": "https://github.com/elastic/elasticsearch/pull/65933#discussion_r543128731", "bodyText": "Sorry, I had made that change but forgot to push it...", "author": "henningandersen", "createdAt": "2020-12-15T08:08:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzA0NzEyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzE0MjQ5MQ==", "url": "https://github.com/elastic/elasticsearch/pull/65933#discussion_r543142491", "bodyText": "Done in two commits: 0a79b75 and 232f250", "author": "henningandersen", "createdAt": "2020-12-15T08:30:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzA0NzEyNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzA0NzY2MQ==", "url": "https://github.com/elastic/elasticsearch/pull/65933#discussion_r543047661", "bodyText": "Rather than reassinging a local variable (\ud83d\ude45\u200d\u2640\ufe0f), how about creating a new local variable named allocationStateAfterForecast and using that for the rest of the method?", "author": "jasontedor", "createdAt": "2020-12-15T05:00:15Z", "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ProactiveStorageDeciderService.java", "diffHunk": "@@ -0,0 +1,181 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.autoscaling.storage;\n+\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.allocation.DiskThresholdSettings;\n+import org.elasticsearch.cluster.routing.allocation.decider.AllocationDeciders;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingCapacity;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderContext;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderResult;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderService;\n+import org.elasticsearch.xpack.core.DataTier;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Objects;\n+\n+public class ProactiveStorageDeciderService implements AutoscalingDeciderService {\n+    public static final String NAME = \"proactive_storage\";\n+    public static final Setting<TimeValue> FORECAST_WINDOW = Setting.timeSetting(\"forecast_window\", TimeValue.timeValueMinutes(30));\n+\n+    private final DiskThresholdSettings diskThresholdSettings;\n+    private final AllocationDeciders allocationDeciders;\n+\n+    public ProactiveStorageDeciderService(Settings settings, ClusterSettings clusterSettings, AllocationDeciders allocationDeciders) {\n+        this.diskThresholdSettings = new DiskThresholdSettings(settings, clusterSettings);\n+        this.allocationDeciders = allocationDeciders;\n+    }\n+\n+    @Override\n+    public String name() {\n+        return NAME;\n+    }\n+\n+    @Override\n+    public List<DiscoveryNodeRole> roles() {\n+        return List.of(DiscoveryNodeRole.DATA_ROLE, DataTier.DATA_HOT_NODE_ROLE);\n+    }\n+\n+    @Override\n+    public AutoscalingDeciderResult scale(Settings configuration, AutoscalingDeciderContext context) {\n+        AutoscalingCapacity autoscalingCapacity = context.currentCapacity();\n+        if (autoscalingCapacity == null || autoscalingCapacity.total().storage() == null) {\n+            return new AutoscalingDeciderResult(\n+                null,\n+                new ReactiveStorageDeciderService.ReactiveReason(\"current capacity not available\", -1, -1)\n+            );\n+        }\n+\n+        ReactiveStorageDeciderService.AllocationState allocationState = new ReactiveStorageDeciderService.AllocationState(\n+            context,\n+            diskThresholdSettings,\n+            allocationDeciders\n+        );\n+        long unassignedBeforeForecast = allocationState.storagePreventsAllocation();\n+        assert unassignedBeforeForecast >= 0;\n+\n+        TimeValue forecastWindow = FORECAST_WINDOW.get(configuration);\n+        allocationState = allocationState.forecast(forecastWindow.millis(), System.currentTimeMillis());", "originalCommit": "8a7d7e05e601b4b4c1d749023dc4144a8807a1e7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzE0MTE1Mw==", "url": "https://github.com/elastic/elasticsearch/pull/65933#discussion_r543141153", "bodyText": "ok, done in 232f250", "author": "henningandersen", "createdAt": "2020-12-15T08:28:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzA0NzY2MQ=="}], "type": "inlineReview"}, {"oid": "39e87c930f4226698a265e056d74cf6236afd145", "url": "https://github.com/elastic/elasticsearch/commit/39e87c930f4226698a265e056d74cf6236afd145", "message": "Clarify rounding", "committedDate": "2020-12-15T08:07:26Z", "type": "commit"}, {"oid": "232f250fbfe2481d4b8bbf70ddf7484d2ce32bc6", "url": "https://github.com/elastic/elasticsearch/commit/232f250fbfe2481d4b8bbf70ddf7484d2ce32bc6", "message": "allocationStateAfterForecast plus one more bytes.", "committedDate": "2020-12-15T08:11:23Z", "type": "commit"}, {"oid": "96dc77d1736d25df895bc9e835b1424bf42b7cc1", "url": "https://github.com/elastic/elasticsearch/commit/96dc77d1736d25df895bc9e835b1424bf42b7cc1", "message": "stream filter order.", "committedDate": "2020-12-15T08:16:58Z", "type": "commit"}, {"oid": "d4650aad9a09d9c88bf11c4bb80ecc40826b2339", "url": "https://github.com/elastic/elasticsearch/commit/d4650aad9a09d9c88bf11c4bb80ecc40826b2339", "message": "Merge remote-tracking branch 'origin/master' into enhance_autoscaling_proactive_storage_decider_pr", "committedDate": "2020-12-15T08:22:06Z", "type": "commit"}, {"oid": "c08b97f98af467e0899914c0aec0cc57e136af04", "url": "https://github.com/elastic/elasticsearch/commit/c08b97f98af467e0899914c0aec0cc57e136af04", "message": "spotless", "committedDate": "2020-12-15T08:23:49Z", "type": "commit"}, {"oid": "efc0be3b42711a9f101ce1a89d9d3ffa2a48a9e9", "url": "https://github.com/elastic/elasticsearch/commit/efc0be3b42711a9f101ce1a89d9d3ffa2a48a9e9", "message": "Fix build.", "committedDate": "2020-12-15T08:58:48Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI2NzMwNw==", "url": "https://github.com/elastic/elasticsearch/pull/65933#discussion_r543267307", "bodyText": "Okay, thanks for clarifying. Let me roll up my sleeves and read it again. \ud83d\ude07", "author": "jasontedor", "createdAt": "2020-12-15T11:33:31Z", "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "diffHunk": "@@ -302,7 +316,226 @@ private long thresholdFromPercentage(Double percentage, DiskUsage diskUsage) {\n         }\n \n         Stream<RoutingNode> nodesInTier(RoutingNodes routingNodes) {\n-            return nodes.stream().map(n -> routingNodes.node(n.getId()));\n+            return nodeIds.stream().map(n -> routingNodes.node(n));\n+        }\n+\n+        private static class SingleForecast {\n+            private final Map<IndexMetadata, Long> additionalIndices;\n+            private final DataStream updatedDataStream;\n+\n+            private SingleForecast(Map<IndexMetadata, Long> additionalIndices, DataStream updatedDataStream) {\n+                this.additionalIndices = additionalIndices;\n+                this.updatedDataStream = updatedDataStream;\n+            }\n+\n+            public void applyRouting(RoutingTable.Builder routing) {\n+                additionalIndices.keySet().forEach(routing::addAsNew);\n+            }\n+\n+            public void applyMetadata(Metadata.Builder metadataBuilder) {\n+                additionalIndices.keySet().forEach(imd -> metadataBuilder.put(imd, false));\n+                metadataBuilder.put(updatedDataStream);\n+            }\n+\n+            public void applySize(ImmutableOpenMap.Builder<String, Long> builder, RoutingTable updatedRoutingTable) {\n+                for (Map.Entry<IndexMetadata, Long> entry : additionalIndices.entrySet()) {\n+                    List<ShardRouting> shardRoutings = updatedRoutingTable.allShards(entry.getKey().getIndex().getName());\n+                    long size = entry.getValue() / shardRoutings.size();\n+                    shardRoutings.forEach(s -> builder.put(ClusterInfo.shardIdentifierFromRouting(s), size));\n+                }\n+            }\n+        }\n+\n+        public AllocationState forecast(long forecastWindow, long now) {\n+            if (forecastWindow == 0) {\n+                return this;\n+            }\n+            // for now we only look at data-streams. We might want to also detect alias based time-based indices.\n+            DataStreamMetadata dataStreamMetadata = state.metadata().custom(DataStreamMetadata.TYPE);\n+            if (dataStreamMetadata == null) {\n+                return this;\n+            }\n+            List<SingleForecast> singleForecasts = dataStreamMetadata.dataStreams()\n+                .keySet()\n+                .stream()\n+                .map(state.metadata().getIndicesLookup()::get)\n+                .map(IndexAbstraction.DataStream.class::cast)\n+                .map(ds -> forecast(ds, forecastWindow, now))\n+                .filter(Objects::nonNull)\n+                .collect(Collectors.toList());\n+            if (singleForecasts.isEmpty()) {\n+                return this;\n+            }\n+            Metadata.Builder metadataBuilder = Metadata.builder(state.metadata());\n+            RoutingTable.Builder routingTableBuilder = RoutingTable.builder(state.routingTable());\n+            ImmutableOpenMap.Builder<String, Long> sizeBuilder = ImmutableOpenMap.builder();\n+            singleForecasts.forEach(p -> p.applyMetadata(metadataBuilder));\n+            singleForecasts.forEach(p -> p.applyRouting(routingTableBuilder));\n+            RoutingTable routingTable = routingTableBuilder.build();\n+            singleForecasts.forEach(p -> p.applySize(sizeBuilder, routingTable));\n+            ClusterState forecastClusterState = ClusterState.builder(state).metadata(metadataBuilder).routingTable(routingTable).build();\n+            ClusterInfo forecastInfo = new ExtendedClusterInfo(sizeBuilder.build(), AllocationState.this.info);\n+\n+            return new AllocationState(forecastClusterState, allocationDeciders, diskThresholdSettings, forecastInfo, shardSizeInfo, nodes);\n+        }\n+\n+        private SingleForecast forecast(IndexAbstraction.DataStream stream, long forecastWindow, long now) {\n+            List<IndexMetadata> indices = stream.getIndices();\n+            if (dataStreamAllocatedToNodes(indices) == false) return null;\n+            long minCreationDate = Long.MAX_VALUE;\n+            long totalSize = 0;\n+            int count = 0;\n+            while (count < indices.size()) {\n+                ++count;\n+                IndexMetadata indexMetadata = indices.get(indices.size() - count);\n+                long creationDate = indexMetadata.getCreationDate();\n+                if (creationDate < 0) {\n+                    return null;\n+                }\n+                minCreationDate = Math.min(minCreationDate, creationDate);\n+                totalSize += state.getRoutingTable().allShards(indexMetadata.getIndex().getName()).stream().mapToLong(this::sizeOf).sum();\n+                // we terminate loop after collecting data to ensure we consider at least the forecast window (and likely some more).\n+                if (creationDate <= now - forecastWindow) {\n+                    break;\n+                }\n+            }\n+\n+            if (totalSize == 0) {\n+                return null;\n+            }\n+\n+            // round up\n+            long avgSizeCeil = (totalSize - 1) / count + 1;", "originalCommit": "efc0be3b42711a9f101ce1a89d9d3ffa2a48a9e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQwOTY0NQ==", "url": "https://github.com/elastic/elasticsearch/pull/65933#discussion_r543409645", "bodyText": "Oops, that was meant to be a comment from a couple of hours ago letting you know that I was re-reviewing, it wasn't meant to be submitted as part of the review (single comment versus review comment). Oh well!", "author": "jasontedor", "createdAt": "2020-12-15T14:47:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI2NzMwNw=="}], "type": "inlineReview"}]}