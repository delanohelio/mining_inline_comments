{"pr_number": 58994, "pr_title": "Fix TODO about Spurious FAILED Snapshots", "pr_createdAt": "2020-07-03T07:50:15Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/58994", "timeline": [{"oid": "749b4f1ca851d361e0342bc1ff7315bc7fdf54ab", "url": "https://github.com/elastic/elasticsearch/commit/749b4f1ca851d361e0342bc1ff7315bc7fdf54ab", "message": "Fix TODO about Spurious FAILED Snapshots\n\nThere is no point in writing out snapshots that contain no data that can be restored\nwhatsoever. It may have made sense to do so in the past when there was an `INIT` snapshot\nstep that wrote data to the repository that would've other become unreferenced, but in the\ncurrent day state machine without the `INIT` step there is no point in doing so.", "committedDate": "2020-07-03T07:50:05Z", "type": "commit"}, {"oid": "749b4f1ca851d361e0342bc1ff7315bc7fdf54ab", "url": "https://github.com/elastic/elasticsearch/commit/749b4f1ca851d361e0342bc1ff7315bc7fdf54ab", "message": "Fix TODO about Spurious FAILED Snapshots\n\nThere is no point in writing out snapshots that contain no data that can be restored\nwhatsoever. It may have made sense to do so in the past when there was an `INIT` snapshot\nstep that wrote data to the repository that would've other become unreferenced, but in the\ncurrent day state machine without the `INIT` step there is no point in doing so.", "committedDate": "2020-07-03T07:50:05Z", "type": "forcePushed"}, {"oid": "6841b41a6732b4976ae675347b556f113b9e9377", "url": "https://github.com/elastic/elasticsearch/commit/6841b41a6732b4976ae675347b556f113b9e9377", "message": "Merge remote-tracking branch 'elastic/master' into remove-snapshot-spurious-failed", "committedDate": "2020-07-03T08:15:29Z", "type": "commit"}, {"oid": "73cb8ecc84367b57b4a10a8e2a064b7444ca2155", "url": "https://github.com/elastic/elasticsearch/commit/73cb8ecc84367b57b4a10a8e2a064b7444ca2155", "message": "fix SLM tests", "committedDate": "2020-07-03T08:19:55Z", "type": "commit"}, {"oid": "3d84d5eb834daa196acca6300366250d79d84156", "url": "https://github.com/elastic/elasticsearch/commit/3d84d5eb834daa196acca6300366250d79d84156", "message": "fix test", "committedDate": "2020-07-03T09:04:15Z", "type": "commit"}, {"oid": "e604ccffcc9ea911721c2fc8d00dd231e7770cde", "url": "https://github.com/elastic/elasticsearch/commit/e604ccffcc9ea911721c2fc8d00dd231e7770cde", "message": "Merge remote-tracking branch 'elastic/master' into remove-snapshot-spurious-failed", "committedDate": "2020-07-03T15:21:20Z", "type": "commit"}, {"oid": "67f81a25713d50d71362f02d05faea12713e782c", "url": "https://github.com/elastic/elasticsearch/commit/67f81a25713d50d71362f02d05faea12713e782c", "message": "fix test", "committedDate": "2020-07-03T15:29:15Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDAzNDIyNg==", "url": "https://github.com/elastic/elasticsearch/pull/58994#discussion_r450034226", "bodyText": "space missing.", "author": "ywelsch", "createdAt": "2020-07-06T07:31:41Z", "path": "server/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java", "diffHunk": "@@ -244,21 +244,16 @@ public ClusterState execute(ClusterState currentState) {\n                         }\n                     }\n                     if (missing.isEmpty() == false) {\n-                        // TODO: We should just throw here instead of creating a FAILED and hence useless snapshot in the repository\n-                        newEntry = new SnapshotsInProgress.Entry(\n-                                new Snapshot(repositoryName, snapshotId), request.includeGlobalState(), false,\n-                                State.FAILED, indexIds, dataStreams, threadPool.absoluteTimeInMillis(), repositoryData.getGenId(), shards,\n-                                \"Indices don't have primary shards \" + missing, userMeta, version);\n+                        throw new SnapshotException(\n+                            new Snapshot(repositoryName, snapshotId),\"Indices don't have primary shards \" + missing);", "originalCommit": "67f81a25713d50d71362f02d05faea12713e782c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDAzNjUwOA==", "url": "https://github.com/elastic/elasticsearch/pull/58994#discussion_r450036508", "bodyText": "While this test used the old behavior to get a failed snapshot, it is still a useful test for listing good and bad snapshots, no?", "author": "ywelsch", "createdAt": "2020-07-06T07:36:23Z", "path": "server/src/internalClusterTest/java/org/elasticsearch/snapshots/SharedClusterSnapshotRestoreIT.java", "diffHunk": "@@ -3346,77 +3342,6 @@ public void testSnapshotSucceedsAfterSnapshotFailure() throws Exception {\n         assertEquals(SnapshotState.SUCCESS, getSnapshotsResponse.getSnapshots(\"test-repo-2\").get(0).state());\n     }\n \n-    public void testSnapshotStatusOnFailedIndex() throws Exception {", "originalCommit": "67f81a25713d50d71362f02d05faea12713e782c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDA2MzEwMg==", "url": "https://github.com/elastic/elasticsearch/pull/58994#discussion_r450063102", "bodyText": "I guess the problem I had was that there was no way of creating a FAILED snapshot any longer and the whole premise of this test was to check that the status of a FAILED snapshot is returned properly from APIs.\nThen again, as with the SLM test that I removed, let me see if I can create a BwC test for this by manipulating RepositoryData :)", "author": "original-brownbear", "createdAt": "2020-07-06T08:27:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDAzNjUwOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQyODYxNw==", "url": "https://github.com/elastic/elasticsearch/pull/58994#discussion_r451428617", "bodyText": "Alright, brought this back in a much simplified way to make sure we continue to be able to read the FAILED state. I think that's all we need here. Reading failed shard state we test in all kinds of places where we deal with PARTIAL snapshots so I think just faking a 0 shards, failed snapshot here is good enough.", "author": "original-brownbear", "createdAt": "2020-07-08T10:02:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDAzNjUwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDAzNzQ2Mg==", "url": "https://github.com/elastic/elasticsearch/pull/58994#discussion_r450037462", "bodyText": "final SnapshotException ... and then assertNotNull() in the next line", "author": "ywelsch", "createdAt": "2020-07-06T07:38:12Z", "path": "server/src/test/java/org/elasticsearch/snapshots/SnapshotResiliencyTests.java", "diffHunk": "@@ -397,9 +401,22 @@ public void testSnapshotWithNodeDisconnects() {\n             } else if (randomBoolean()) {\n                 scheduleNow(() -> testClusterNodes.clearNetworkDisruptions());\n             }\n+        }, e -> {\n+            if (partial == false) {\n+                final Throwable unwrapped =", "originalCommit": "67f81a25713d50d71362f02d05faea12713e782c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQyNzczNA==", "url": "https://github.com/elastic/elasticsearch/pull/58994#discussion_r451427734", "bodyText": "Done :)", "author": "original-brownbear", "createdAt": "2020-07-08T10:01:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDAzNzQ2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDAzODQ2MA==", "url": "https://github.com/elastic/elasticsearch/pull/58994#discussion_r450038460", "bodyText": "should we still test this scenario? Can folks disable partial snapshots on SLM?", "author": "ywelsch", "createdAt": "2020-07-06T07:40:11Z", "path": "x-pack/plugin/ilm/src/test/java/org/elasticsearch/xpack/slm/SLMSnapshotBlockingIntegTests.java", "diffHunk": "@@ -257,26 +257,17 @@ public void testRetentionWhileSnapshotInProgress() throws Exception {\n         }\n     }\n \n-    public void testBasicFailureRetention() throws Exception {", "originalCommit": "67f81a25713d50d71362f02d05faea12713e782c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDA2MTA1NA==", "url": "https://github.com/elastic/elasticsearch/pull/58994#discussion_r450061054", "bodyText": "I don't think we have to, there's no more FAILED state snapshots being created in the repo with this change (not you oculd only ever get a FAILED snapshot if partial was turned off in the first place). We could force the creation of a FAILED snapshot as a BWC test maybe by manually messing with the RepositoryData (come to think of it ... I'll do that, otherwise we lose coverage for a BwC scenario).", "author": "original-brownbear", "createdAt": "2020-07-06T08:23:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDAzODQ2MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDI5MDAxMg==", "url": "https://github.com/elastic/elasticsearch/pull/58994#discussion_r450290012", "bodyText": "This needs some trickier tests it turns out but is well worth it given how SLM low-level manages these snapshot states. I opened #59082 to enable the necessary test infrastructure.", "author": "original-brownbear", "createdAt": "2020-07-06T15:10:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDAzODQ2MA=="}], "type": "inlineReview"}, {"oid": "e1c204b09a499c7e1f6b5d3e8cedf139cbe30d49", "url": "https://github.com/elastic/elasticsearch/commit/e1c204b09a499c7e1f6b5d3e8cedf139cbe30d49", "message": "Merge remote-tracking branch 'elastic/master' into remove-snapshot-spurious-failed", "committedDate": "2020-07-06T08:19:12Z", "type": "commit"}, {"oid": "4936738af6cafb6c2e7d6251fcb99045d898dd15", "url": "https://github.com/elastic/elasticsearch/commit/4936738af6cafb6c2e7d6251fcb99045d898dd15", "message": "CR: small points", "committedDate": "2020-07-06T08:28:09Z", "type": "commit"}, {"oid": "a5761b184843f6904f748aa9bc444adfc1b1f2cd", "url": "https://github.com/elastic/elasticsearch/commit/a5761b184843f6904f748aa9bc444adfc1b1f2cd", "message": "Merge remote-tracking branch 'elastic/master' into remove-snapshot-spurious-failed", "committedDate": "2020-07-06T13:11:11Z", "type": "commit"}, {"oid": "f4839471e4e8e5359ca38d9afaa1c2efcd40bc6f", "url": "https://github.com/elastic/elasticsearch/commit/f4839471e4e8e5359ca38d9afaa1c2efcd40bc6f", "message": "bring back one test", "committedDate": "2020-07-06T13:45:32Z", "type": "commit"}, {"oid": "43f11ceeee90ada04613836a0192ce3d9bc4e275", "url": "https://github.com/elastic/elasticsearch/commit/43f11ceeee90ada04613836a0192ce3d9bc4e275", "message": "bck", "committedDate": "2020-07-06T13:51:54Z", "type": "commit"}, {"oid": "7a3162bbc82ead5a61c3f255427e7adf2baec232", "url": "https://github.com/elastic/elasticsearch/commit/7a3162bbc82ead5a61c3f255427e7adf2baec232", "message": "Merge remote-tracking branch 'elastic/master' into remove-snapshot-spurious-failed", "committedDate": "2020-07-08T09:00:02Z", "type": "commit"}, {"oid": "a1e46118799ff10019110b6e6ece119ce9575257", "url": "https://github.com/elastic/elasticsearch/commit/a1e46118799ff10019110b6e6ece119ce9575257", "message": "test with fake failed snapshot", "committedDate": "2020-07-08T09:54:17Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQyOTE4MA==", "url": "https://github.com/elastic/elasticsearch/pull/58994#discussion_r451429180", "bodyText": "Faking the FAILED snapshot with the right metadata so that SLM picks it up here now. It's a bit of a corner case since we won't be creating any new FAILED snapshots but probably nice to have this tested to make sure that in rolling upgrade scenarios FAILED snapshots are getting cleaned up eventually.", "author": "original-brownbear", "createdAt": "2020-07-08T10:03:51Z", "path": "x-pack/plugin/ilm/src/test/java/org/elasticsearch/xpack/slm/SLMSnapshotBlockingIntegTests.java", "diffHunk": "@@ -274,27 +274,33 @@ private void testUnsuccessfulSnapshotRetention(boolean partialSuccess) throws Ex\n         // Create a failed snapshot\n         AtomicReference<String> failedSnapshotName = new AtomicReference<>();\n         {\n-            logger.info(\"-->  stopping random data node, which should cause shards to go missing\");\n-            internalCluster().stopRandomDataNode();\n-            assertBusy(() ->\n-                    assertEquals(ClusterHealthStatus.RED, client().admin().cluster().prepareHealth().get().getStatus()),\n-                30, TimeUnit.SECONDS);\n-\n-            final String masterNode = blockMasterFromFinalizingSnapshotOnIndexFile(REPO);\n-\n-            logger.info(\"-->  start snapshot\");\n-            ActionFuture<ExecuteSnapshotLifecycleAction.Response> snapshotFuture = client()\n-                .execute(ExecuteSnapshotLifecycleAction.INSTANCE, new ExecuteSnapshotLifecycleAction.Request(policyId));\n-\n-            logger.info(\"--> waiting for block to kick in on \" + masterNode);\n-            waitForBlock(masterNode, REPO, TimeValue.timeValueSeconds(60));\n-\n-            logger.info(\"-->  stopping master node\");\n-            internalCluster().stopCurrentMasterNode();\n-\n-            logger.info(\"-->  wait until the snapshot is done\");\n-            failedSnapshotName.set(snapshotFuture.get().getSnapshotName());\n-            assertNotNull(failedSnapshotName.get());\n+            if (partialSuccess) {\n+                logger.info(\"-->  stopping random data node, which should cause shards to go missing\");\n+                internalCluster().stopRandomDataNode();\n+                assertBusy(() -> assertEquals(ClusterHealthStatus.RED, client().admin().cluster().prepareHealth().get().getStatus()),\n+                        30, TimeUnit.SECONDS);\n+\n+                final String masterNode = blockMasterFromFinalizingSnapshotOnIndexFile(REPO);\n+\n+                logger.info(\"-->  start snapshot\");\n+                ActionFuture<ExecuteSnapshotLifecycleAction.Response> snapshotFuture = client()\n+                        .execute(ExecuteSnapshotLifecycleAction.INSTANCE, new ExecuteSnapshotLifecycleAction.Request(policyId));\n+\n+                logger.info(\"--> waiting for block to kick in on \" + masterNode);\n+                waitForBlock(masterNode, REPO, TimeValue.timeValueSeconds(60));\n+\n+                logger.info(\"-->  stopping master node\");\n+                internalCluster().stopCurrentMasterNode();\n+\n+                logger.info(\"-->  wait until the snapshot is done\");\n+                failedSnapshotName.set(snapshotFuture.get().getSnapshotName());\n+                assertNotNull(failedSnapshotName.get());\n+            } else {\n+                final String snapshotName = \"failed-snapshot-1\";", "originalCommit": "a1e46118799ff10019110b6e6ece119ce9575257", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "828b5ae33d652c8794e119c91d56133c29044628", "url": "https://github.com/elastic/elasticsearch/commit/828b5ae33d652c8794e119c91d56133c29044628", "message": "whitespace", "committedDate": "2020-07-08T10:04:50Z", "type": "commit"}]}