{"pr_number": 53583, "pr_title": "add nori_number token filter in analysis-nori", "pr_createdAt": "2020-03-15T14:40:00Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/53583", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5MTQyMg==", "url": "https://github.com/elastic/elasticsearch/pull/53583#discussion_r395291422", "bodyText": "Can you add a small test for the new discard_punctuation option of the tokenizer ?", "author": "jimczi", "createdAt": "2020-03-19T20:10:31Z", "path": "plugins/analysis-nori/src/test/java/org/elasticsearch/index/analysis/NoriAnalysisTests.java", "diffHunk": "@@ -159,6 +162,20 @@ public void testNoriReadingForm() throws IOException {\n         assertTokenStreamContents(stream, new String[] {\"\ud5a5\uac00\"});\n     }\n \n+    public void testNoriNumber() throws IOException {\n+        Settings settings = Settings.builder()\n+            .put(IndexMetaData.SETTING_VERSION_CREATED, Version.CURRENT)\n+            .put(Environment.PATH_HOME_SETTING.getKey(), createTempDir().toString())\n+            .put(\"index.analysis.filter.my_filter.type\", \"nori_number\")\n+            .build();\n+        TestAnalysis analysis = AnalysisTestsHelper.createTestAnalysisFromSettings(settings, new AnalysisNoriPlugin());\n+        TokenFilterFactory factory = analysis.tokenFilter.get(\"my_filter\");\n+        Tokenizer tokenizer = new KoreanTokenizer();\n+        tokenizer.setReader(new StringReader(\"\uc624\ub298 \uc2ed\ub9cc\uc774\ucc9c\uc624\ubc31\uc6d0\uc9dc\ub9ac \uc640\uc778 \uad6c\uc785\"));\n+        TokenStream stream = factory.create(tokenizer);\n+        assertTokenStreamContents(stream, new String[] {\"\uc624\ub298\", \"102500\", \"\uc6d0\", \"\uc9dc\ub9ac\", \"\uc640\uc778\", \"\uad6c\uc785\"});\n+    }\n+", "originalCommit": "82191a3032f19729807dd2377af70a5c8272b0a4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTgyNTA5MQ==", "url": "https://github.com/elastic/elasticsearch/pull/53583#discussion_r395825091", "bodyText": "Done!", "author": "danmuzi", "createdAt": "2020-03-20T18:39:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5MTQyMg=="}], "type": "inlineReview"}, {"oid": "b6221c5748099e6902e2ad91c5207ab5ac2005b3", "url": "https://github.com/elastic/elasticsearch/commit/b6221c5748099e6902e2ad91c5207ab5ac2005b3", "message": "add nori_number token filter", "committedDate": "2020-03-23T17:06:45Z", "type": "commit"}, {"oid": "d6dbe514fa70c8278f180a3a602a75601d588d39", "url": "https://github.com/elastic/elasticsearch/commit/d6dbe514fa70c8278f180a3a602a75601d588d39", "message": "add discard_punctuation option in nori_tokenizer", "committedDate": "2020-03-23T17:06:45Z", "type": "commit"}, {"oid": "9bd0ebe9ab119a49f6a829d308d8238d24050ea2", "url": "https://github.com/elastic/elasticsearch/commit/9bd0ebe9ab119a49f6a829d308d8238d24050ea2", "message": "add description about using discard_punctuation in nori_number", "committedDate": "2020-03-23T17:06:45Z", "type": "commit"}, {"oid": "6ed33a19b7a9f5e4c6dc9b628cf2f6202113c25d", "url": "https://github.com/elastic/elasticsearch/commit/6ed33a19b7a9f5e4c6dc9b628cf2f6202113c25d", "message": "add note in asciidoc and test cases for discard_punctuation", "committedDate": "2020-03-23T17:06:45Z", "type": "commit"}, {"oid": "1a4367ea993cfc34d7d034e03c5b9cb80790fe3c", "url": "https://github.com/elastic/elasticsearch/commit/1a4367ea993cfc34d7d034e03c5b9cb80790fe3c", "message": "fix wrong indentation in nori_number test", "committedDate": "2020-03-23T17:06:45Z", "type": "commit"}, {"oid": "1a4367ea993cfc34d7d034e03c5b9cb80790fe3c", "url": "https://github.com/elastic/elasticsearch/commit/1a4367ea993cfc34d7d034e03c5b9cb80790fe3c", "message": "fix wrong indentation in nori_number test", "committedDate": "2020-03-23T17:06:45Z", "type": "forcePushed"}]}