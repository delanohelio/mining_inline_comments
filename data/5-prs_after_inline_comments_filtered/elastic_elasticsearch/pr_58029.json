{"pr_number": 58029, "pr_title": "Account for remaining recovery in disk allocator", "pr_createdAt": "2020-06-12T09:35:58Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/58029", "timeline": [{"oid": "8a13a4d5bf1eb35b9a4be51cf0fa0b286af76668", "url": "https://github.com/elastic/elasticsearch/commit/8a13a4d5bf1eb35b9a4be51cf0fa0b286af76668", "message": "Account for remaining recovery in disk allocator\n\nToday the disk-based shard allocator accounts for incoming shards by\nsubtracting the estimated size of the incoming shard from the free space on the\nnode. This is an overly conservative estimate if the incoming shard has almost\nfinished its recovery since in that case it is already consuming most of the\ndisk space it needs.\n\nThis change adds to the shard stats a measure of how much larger each store is\nexpected to grow, computed from the ongoing recovery, and uses this to account\nfor the disk usage of incoming shards more accurately.", "committedDate": "2020-06-12T09:31:53Z", "type": "commit"}, {"oid": "4a6a7cc083e744897a58b57f0425e6f6970f082b", "url": "https://github.com/elastic/elasticsearch/commit/4a6a7cc083e744897a58b57f0425e6f6970f082b", "message": "Fix up tests", "committedDate": "2020-06-12T11:19:05Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTQxODgxNw==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r439418817", "bodyText": "use writeMap?", "author": "ywelsch", "createdAt": "2020-06-12T13:29:49Z", "path": "server/src/main/java/org/elasticsearch/cluster/ClusterInfo.java", "diffHunk": "@@ -109,6 +127,14 @@ public void writeTo(StreamOutput out) throws IOException {\n             c.key.writeTo(out);\n             out.writeString(c.value);\n         }\n+\n+        if (out.getVersion().onOrAfter(StoreStats.RESERVED_BYTES_VERSION)) {\n+            out.writeVInt(this.reservedSpace.size());", "originalCommit": "4a6a7cc083e744897a58b57f0425e6f6970f082b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA2NjM1Mw==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r440066353", "bodyText": "An ImmutableOpenMap isn't a Map \ud83d\ude22", "author": "DaveCTurner", "createdAt": "2020-06-15T10:02:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTQxODgxNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTQzMzU5Ng==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r439433596", "bodyText": "can we avoid going under the global mutex here? Perhaps by adding a method to recoveryState (which has its own synchronization).", "author": "ywelsch", "createdAt": "2020-06-12T13:56:10Z", "path": "server/src/main/java/org/elasticsearch/index/shard/IndexShard.java", "diffHunk": "@@ -1004,8 +1004,24 @@ public GetStats getStats() {\n     }\n \n     public StoreStats storeStats() {\n+        final LongSupplier remainingRecoveryBytesSupplier;\n+        synchronized (mutex) {", "originalCommit": "4a6a7cc083e744897a58b57f0425e6f6970f082b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA2OTE4Ng==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r440069186", "bodyText": "recoveryState is nonvolatile and assigned under mutex so I think we cannot avoid synchronising on mutex here. Note that we do almost no work under the mutex itself. Would you rather make recoveryState volatile?", "author": "DaveCTurner", "createdAt": "2020-06-15T10:07:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTQzMzU5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA3NDE4Mw==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r440074183", "bodyText": "yeah, I'd prefer that. I'm scared of stats calls going under this mutex, as we currently do some heavy operations under that mutex (e.g. flush on closing), which ofc we should not.", "author": "ywelsch", "createdAt": "2020-06-15T10:16:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTQzMzU5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA3NjEyNA==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r440076124", "bodyText": "Ok I pushed a5275ed", "author": "DaveCTurner", "createdAt": "2020-06-15T10:20:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTQzMzU5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTQzNTU1Mw==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r439435553", "bodyText": "why 0 here instead of UNKNOWN_RESERVED_BYTES?", "author": "ywelsch", "createdAt": "2020-06-12T13:58:34Z", "path": "server/src/main/java/org/elasticsearch/index/shard/IndexShard.java", "diffHunk": "@@ -1004,8 +1004,24 @@ public GetStats getStats() {\n     }\n \n     public StoreStats storeStats() {\n+        final LongSupplier remainingRecoveryBytesSupplier;\n+        synchronized (mutex) {\n+            if (recoveryState == null) {\n+                remainingRecoveryBytesSupplier = () -> 0L;", "originalCommit": "4a6a7cc083e744897a58b57f0425e6f6970f082b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA2ODEwMA==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r440068100", "bodyText": "Ah you're right, this indicates that recovery hasn't started, not that no recovery is required. I pushed 6a7060c.", "author": "DaveCTurner", "createdAt": "2020-06-15T10:05:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTQzNTU1Mw=="}], "type": "inlineReview"}, {"oid": "a0e9452aa390e45cbcd7380480a68de9bb1529f9", "url": "https://github.com/elastic/elasticsearch/commit/a0e9452aa390e45cbcd7380480a68de9bb1529f9", "message": "Tidy", "committedDate": "2020-06-15T09:59:08Z", "type": "commit"}, {"oid": "6a7060c3d7d79adedf06d3058c41b7da62e0a56c", "url": "https://github.com/elastic/elasticsearch/commit/6a7060c3d7d79adedf06d3058c41b7da62e0a56c", "message": "UNKNOWN before marked as recovering", "committedDate": "2020-06-15T10:03:48Z", "type": "commit"}, {"oid": "a5275ed96d0e07dec02a7c5d5e0ecb990f872fd1", "url": "https://github.com/elastic/elasticsearch/commit/a5275ed96d0e07dec02a7c5d5e0ecb990f872fd1", "message": "Volatile, no mutex", "committedDate": "2020-06-15T10:20:02Z", "type": "commit"}, {"oid": "50495f2a200517141b8da43af85f2113a19229f2", "url": "https://github.com/elastic/elasticsearch/commit/50495f2a200517141b8da43af85f2113a19229f2", "message": "Always use getIndex().bytesStillToRecover() ignoring stage", "committedDate": "2020-06-15T10:38:02Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA2MDY1NA==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r440060654", "bodyText": "Is there an added race condition risk here? In that we risk using a cluster-info combined of an old reserved space and a new shard-sizes for making decisions and thus could be either under or over-estimating the usage?\nI think it would be nicer to encapsulate the two in one object that is then assigned once to a volatile field.", "author": "henningandersen", "createdAt": "2020-06-15T09:52:06Z", "path": "server/src/main/java/org/elasticsearch/cluster/InternalClusterInfoService.java", "diffHunk": "@@ -318,15 +323,21 @@ public void onFailure(Exception e) {\n             }\n         });\n \n-        final CountDownLatch indicesLatch = updateIndicesStats(new ActionListener<IndicesStatsResponse>() {\n+        final CountDownLatch indicesLatch = updateIndicesStats(new ActionListener<>() {\n             @Override\n             public void onResponse(IndicesStatsResponse indicesStatsResponse) {\n-                ShardStats[] stats = indicesStatsResponse.getShards();\n-                ImmutableOpenMap.Builder<String, Long> newShardSizes = ImmutableOpenMap.builder();\n-                ImmutableOpenMap.Builder<ShardRouting, String> newShardRoutingToDataPath = ImmutableOpenMap.builder();\n-                buildShardLevelInfo(logger, stats, newShardSizes, newShardRoutingToDataPath);\n-                shardSizes = newShardSizes.build();\n-                shardRoutingToDataPath = newShardRoutingToDataPath.build();\n+                final ShardStats[] stats = indicesStatsResponse.getShards();\n+                final ImmutableOpenMap.Builder<String, Long> shardSizeByIdentifierBuilder = ImmutableOpenMap.builder();\n+                final ImmutableOpenMap.Builder<ShardRouting, String> dataPathByShardRoutingBuilder = ImmutableOpenMap.builder();\n+                final Map<ClusterInfo.NodeAndPath, ClusterInfo.ReservedSpace.Builder> reservedSpaceBuilders = new HashMap<>();\n+                buildShardLevelInfo(logger, stats, shardSizeByIdentifierBuilder, dataPathByShardRoutingBuilder, reservedSpaceBuilders);\n+\n+                final ImmutableOpenMap.Builder<ClusterInfo.NodeAndPath, ClusterInfo.ReservedSpace> rsrvdSpace = ImmutableOpenMap.builder();\n+                reservedSpaceBuilders.forEach((nodeAndPath, builder) -> rsrvdSpace.put(nodeAndPath, builder.build()));\n+\n+                shardSizes = shardSizeByIdentifierBuilder.build();\n+                shardRoutingToDataPath = dataPathByShardRoutingBuilder.build();\n+                reservedSpace = rsrvdSpace.build();", "originalCommit": "4a6a7cc083e744897a58b57f0425e6f6970f082b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA5NzY4OA==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r440097688", "bodyText": "Race conditions abound here. We're also relying on the disk usage from the nodes stats which may be received at a completely different time, we don't synchronise the collection of stats on the nodes themselves either, and the store size comes from a cached value anyway. I adjusted this bit of code in 9639659 but that's certainly not a complete fix.", "author": "DaveCTurner", "createdAt": "2020-06-15T11:03:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA2MDY1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDY3ODE0MQ==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r444678141", "bodyText": "Agreed and thanks for the change, looks good.", "author": "henningandersen", "createdAt": "2020-06-24T06:44:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA2MDY1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA2NTgwMg==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r440065802", "bodyText": "I would have thought this should merge the contents to accommodate for all shards on a specific NodePath rather than only the first encountered? Or am I missing something?", "author": "henningandersen", "createdAt": "2020-06-15T10:01:08Z", "path": "server/src/main/java/org/elasticsearch/cluster/InternalClusterInfoService.java", "diffHunk": "@@ -383,16 +395,28 @@ public void addListener(Consumer<ClusterInfo> clusterInfoConsumer) {\n         listeners.add(clusterInfoConsumer);\n     }\n \n-    static void buildShardLevelInfo(Logger logger, ShardStats[] stats, ImmutableOpenMap.Builder<String, Long> newShardSizes,\n-                                    ImmutableOpenMap.Builder<ShardRouting, String> newShardRoutingToDataPath) {\n+    static void buildShardLevelInfo(Logger logger, ShardStats[] stats, ImmutableOpenMap.Builder<String, Long> shardSizes,\n+                                    ImmutableOpenMap.Builder<ShardRouting, String> newShardRoutingToDataPath,\n+                                    Map<ClusterInfo.NodeAndPath, ClusterInfo.ReservedSpace.Builder> reservedSpaceByShard) {\n         for (ShardStats s : stats) {\n-            newShardRoutingToDataPath.put(s.getShardRouting(), s.getDataPath());\n-            long size = s.getStats().getStore().sizeInBytes();\n-            String sid = ClusterInfo.shardIdentifierFromRouting(s.getShardRouting());\n+            final ShardRouting shardRouting = s.getShardRouting();\n+            newShardRoutingToDataPath.put(shardRouting, s.getDataPath());\n+\n+            final StoreStats storeStats = s.getStats().getStore();\n+            final long size = storeStats.sizeInBytes();\n+            final long reserved = storeStats.getReservedSize().getBytes();\n+\n+            final String shardIdentifier = ClusterInfo.shardIdentifierFromRouting(shardRouting);\n             if (logger.isTraceEnabled()) {\n-                logger.trace(\"shard: {} size: {}\", sid, size);\n+                logger.trace(\"shard: {} size: {} reserved: {}\", shardIdentifier, size, reserved);\n+            }\n+            shardSizes.put(shardIdentifier, size);\n+\n+            if (reserved != StoreStats.UNKNOWN_RESERVED_BYTES) {\n+                reservedSpaceByShard.computeIfAbsent(", "originalCommit": "4a6a7cc083e744897a58b57f0425e6f6970f082b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA5ODEzNA==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r440098134", "bodyText": "am I missing something?\n\nPossibly a closing bracket \ud83d\ude01 We compute a new builder if absent, but then .add() the stats to the builder for each relevant shard.", "author": "DaveCTurner", "createdAt": "2020-06-15T11:04:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA2NTgwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDY3NjczMA==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r444676730", "bodyText": "I see it now ! Thanks.\nnit: maybe put the .add part on the next line.", "author": "henningandersen", "createdAt": "2020-06-24T06:40:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA2NTgwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDczMjkxMg==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r444732912", "bodyText": "Sure, I introduced an intermediate variable in bf9faca.", "author": "DaveCTurner", "createdAt": "2020-06-24T08:32:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA2NTgwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA2OTUyMQ==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r440069521", "bodyText": "AFAICS this compensation affects two functionalities:\n\nTriggering a reroute when going under low threshold\nAuto-releasing indices when disk usage goes below high threshold.\n\nI think 1) is fine, but I am a bit concerned about 2), since the primary reason we only release when under high threshold is to have some hysteresis to not trigger flood-stage on/off rapidly. I think I would prefer to do the auto-release based on the non-compensated number (just like we move to flood-stage based on that), but am curious on your thoughts on this.", "author": "henningandersen", "createdAt": "2020-06-15T10:07:46Z", "path": "server/src/main/java/org/elasticsearch/cluster/routing/allocation/DiskThresholdMonitor.java", "diffHunk": "@@ -140,6 +140,10 @@ public void onNewInfo(ClusterInfo info) {\n             final DiskUsage usage = entry.value;\n             final RoutingNode routingNode = routingNodes.node(node);\n \n+            final long reservedSpace = info.getReservedSpace(usage.getNodeId(), usage.getPath()).getTotal();\n+            final DiskUsage usageWithReservedSpace = new DiskUsage(usage.getNodeId(), usage.getNodeName(), usage.getPath(),", "originalCommit": "4a6a7cc083e744897a58b57f0425e6f6970f082b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDIwMDcxNA==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r440200714", "bodyText": "Yes, this is a good point. I'll work on addressing that.", "author": "DaveCTurner", "createdAt": "2020-06-15T14:05:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA2OTUyMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjA4Njc4NA==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r442086784", "bodyText": "I'm no longer sure about this. The compensated disk usage is never less than the non-compensated one, so auto-releasing based on the compensated number has more hysteresis than today's behaviour. Is the additional hysteresis the thing that concerns you @henningandersen or has one of us got our logic backwards?", "author": "DaveCTurner", "createdAt": "2020-06-18T09:16:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA2OTUyMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDY3NTE5OA==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r444675198", "bodyText": "Yes, that is my concern. Something cured the situation (deleted index, moved shards etc.), but due to an otherwise unrelated recovery, we would keep halting indexing until that recovery is done. I would prefer to resume indexing (i.e., release the block) and then perhaps later find out that we need to halt it again. If cluster is truly full, we will get to that point, but if it is has enough space, we are likely to cure it before hitting the flood stage again anyway.\nI think the additional hysteresis is unnecessary. AFAIK, we have not seen that the block was flapping too frequently and using the non-compensated number, we would simply keep the behavior unmodified from this PR.", "author": "henningandersen", "createdAt": "2020-06-24T06:36:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA2OTUyMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDczNDk3OQ==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r444734979", "bodyText": "I see, right. I don't think the additional hysteresis would be much of a problem in practice (if you hit the flood-stage watermark you already lost) and continuing to recover onto a node that's breached the flood-stage watermark is likely the real bug here. However it turns out not to add too much complexity so I adjusted this in d8afaf3.", "author": "DaveCTurner", "createdAt": "2020-06-24T08:36:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA2OTUyMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA3ODU3Ng==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r440078576", "bodyText": "Not sure I understand why this needs to be in a finally?", "author": "henningandersen", "createdAt": "2020-06-15T10:25:05Z", "path": "server/src/main/java/org/elasticsearch/index/shard/StoreRecovery.java", "diffHunk": "@@ -403,13 +404,15 @@ private void internalRecoverFromStore(IndexShard indexShard) throws IndexShardRe\n                     writeEmptyRetentionLeasesFile(indexShard);\n                 }\n                 // since we recover from local, just fill the files and size\n+                final RecoveryState.Index index = recoveryState.getIndex();\n                 try {\n-                    final RecoveryState.Index index = recoveryState.getIndex();\n                     if (si != null) {\n                         addRecoveredFileDetails(si, store, index);\n                     }\n                 } catch (IOException e) {\n                     logger.debug(\"failed to list file details\", e);\n+                } finally {", "originalCommit": "6a7060c3d7d79adedf06d3058c41b7da62e0a56c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDEwMjY3OQ==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r440102679", "bodyText": "IIRC an IOException here can happen if force-allocating a stale primary, but is not fatal. I didn't investigate further since it doesn't really matter for our purposes: we reuse all the local files anyway so the reserved space is zero.", "author": "DaveCTurner", "createdAt": "2020-06-15T11:14:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA3ODU3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDY2NzI3MA==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r444667270", "bodyText": "Still not sure why the finally block is necessary, since the catch clause for IOException does not rethrow?\nIt seems illogical that in this block a finally block is necessary, whereas in the next block it is not?\nI mean it will work fine either way... So feel free to disregard this if you prefer.", "author": "henningandersen", "createdAt": "2020-06-24T06:16:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA3ODU3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDczMzM0OA==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r444733348", "bodyText": "Oh, I see now. Fixed in cf23d43.", "author": "DaveCTurner", "createdAt": "2020-06-24T08:33:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA3ODU3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA4Nzc2OQ==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r440087769", "bodyText": "We count reserved space as only the space for the original files in phase 1 of recovery. This makes us slightly more optimistic than desired, in that any changes coming in after getting the original file list are not accounted for as reserved. For instance in cases like described in #58011.\nI wonder if it (for recoveries and relocations) was more precise to adjust by adding (primarySize - alreadyRecovered) - or just (primarySize - replicaSize), where we track each replica individually? This unfortunately does not give us snapshot, which the presented mechanism does, i.e. , we probably need both.", "author": "henningandersen", "createdAt": "2020-06-15T10:43:11Z", "path": "server/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java", "diffHunk": "@@ -98,9 +99,16 @@ public DiskThresholdDecider(Settings settings, ClusterSettings clusterSettings)\n      */\n     public static long sizeOfRelocatingShards(RoutingNode node, boolean subtractShardsMovingAway, String dataPath, ClusterInfo clusterInfo,\n                                               Metadata metadata, RoutingTable routingTable) {\n-        long totalSize = 0L;\n-\n-        for (ShardRouting routing : node.shardsWithState(ShardRoutingState.INITIALIZING)) {\n+        // Account for reserved space wherever it is available\n+        final ClusterInfo.ReservedSpace reservedSpace = clusterInfo.getReservedSpace(node.nodeId(), dataPath);\n+        long totalSize = reservedSpace.getTotal();", "originalCommit": "a5275ed96d0e07dec02a7c5d5e0ecb990f872fd1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDIxMzk1Mw==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r440213953", "bodyText": "We discussed this via another channel. The idea to use (primarySize - replicaSize) does not work well in the partial recovery case, since we do not remove existing files on the target until the end of phase 1.\nI think the replacement here is good enough.", "author": "henningandersen", "createdAt": "2020-06-15T14:24:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA4Nzc2OQ=="}], "type": "inlineReview"}, {"oid": "b89a56770caa137261dd7f5e03336b7b22af2012", "url": "https://github.com/elastic/elasticsearch/commit/b89a56770caa137261dd7f5e03336b7b22af2012", "message": "Don't mention nodes in cluster stats docs", "committedDate": "2020-06-15T10:50:08Z", "type": "commit"}, {"oid": "9639659aa690679fa4f181885724a7dfd35b32e6", "url": "https://github.com/elastic/elasticsearch/commit/9639659aa690679fa4f181885724a7dfd35b32e6", "message": "Atomically summarise indices stats", "committedDate": "2020-06-15T10:58:37Z", "type": "commit"}, {"oid": "76d65541f3d767396a43a90e18570e6470dd697f", "url": "https://github.com/elastic/elasticsearch/commit/76d65541f3d767396a43a90e18570e6470dd697f", "message": "Merge branch 'master' into 2020-06-12-reserve-bytes-in-store-stats", "committedDate": "2020-06-18T08:34:12Z", "type": "commit"}, {"oid": "669e4e5af7b41c3a6f240cd2e7d0c4525bc86e8c", "url": "https://github.com/elastic/elasticsearch/commit/669e4e5af7b41c3a6f240cd2e7d0c4525bc86e8c", "message": "Add skip to REST tests", "committedDate": "2020-06-18T08:37:13Z", "type": "commit"}, {"oid": "77cdf89b2a4d959e73c62dcf6aced3782938ec57", "url": "https://github.com/elastic/elasticsearch/commit/77cdf89b2a4d959e73c62dcf6aced3782938ec57", "message": "Strengthen auto-release test to show reserved space affects release", "committedDate": "2020-06-18T09:32:52Z", "type": "commit"}, {"oid": "5cad0a5f7b952499ab9af2318cef2835861a561c", "url": "https://github.com/elastic/elasticsearch/commit/5cad0a5f7b952499ab9af2318cef2835861a561c", "message": "Merge branch 'master' into 2020-06-12-reserve-bytes-in-store-stats", "committedDate": "2020-06-24T08:00:48Z", "type": "commit"}, {"oid": "bf9faca0d0d6a8859c821f165847267f66153d6a", "url": "https://github.com/elastic/elasticsearch/commit/bf9faca0d0d6a8859c821f165847267f66153d6a", "message": "Clarify", "committedDate": "2020-06-24T08:02:19Z", "type": "commit"}, {"oid": "cf23d43f59fb1330fd0ab791e3f772654b6825f1", "url": "https://github.com/elastic/elasticsearch/commit/cf23d43f59fb1330fd0ab791e3f772654b6825f1", "message": "No finally needed", "committedDate": "2020-06-24T08:03:05Z", "type": "commit"}, {"oid": "d8afaf36f6d723a485c39dd53c26a3d3dbdcf7cf", "url": "https://github.com/elastic/elasticsearch/commit/d8afaf36f6d723a485c39dd53c26a3d3dbdcf7cf", "message": "Ignore reserved space when releasing index block", "committedDate": "2020-06-24T08:28:03Z", "type": "commit"}, {"oid": "4e75e1ff2f96e1b8096276bd2369b436eab8d36b", "url": "https://github.com/elastic/elasticsearch/commit/4e75e1ff2f96e1b8096276bd2369b436eab8d36b", "message": "Negate skip", "committedDate": "2020-06-24T08:55:12Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDgxOTg1Mw==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r444819853", "bodyText": "add comment here // single volatile read", "author": "ywelsch", "createdAt": "2020-06-24T11:12:48Z", "path": "server/src/main/java/org/elasticsearch/cluster/InternalClusterInfoService.java", "diffHunk": "@@ -200,7 +201,9 @@ public void clusterChanged(ClusterChangedEvent event) {\n \n     @Override\n     public ClusterInfo getClusterInfo() {\n-        return new ClusterInfo(leastAvailableSpaceUsages, mostAvailableSpaceUsages, shardSizes, shardRoutingToDataPath);\n+        final IndicesStatsSummary indicesStatsSummary = this.indicesStatsSummary;", "originalCommit": "4e75e1ff2f96e1b8096276bd2369b436eab8d36b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDgyOTkyMA==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r444829920", "bodyText": "\ud83d\udc4d 78d353e", "author": "DaveCTurner", "createdAt": "2020-06-24T11:34:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDgxOTg1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDgyMjIyNA==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r444822224", "bodyText": "Can you move the creation of this object to the place where it's first used? Or should we  alternatively call the other usage instead usageWithoutReservedSpace to make it clearer  when we are using one vs the other", "author": "ywelsch", "createdAt": "2020-06-24T11:17:49Z", "path": "server/src/main/java/org/elasticsearch/cluster/routing/allocation/DiskThresholdMonitor.java", "diffHunk": "@@ -140,6 +140,10 @@ public void onNewInfo(ClusterInfo info) {\n             final DiskUsage usage = entry.value;\n             final RoutingNode routingNode = routingNodes.node(node);\n \n+            final long reservedSpace = info.getReservedSpace(usage.getNodeId(), usage.getPath()).getTotal();\n+            final DiskUsage usageWithReservedSpace = new DiskUsage(usage.getNodeId(), usage.getNodeName(), usage.getPath(),", "originalCommit": "4e75e1ff2f96e1b8096276bd2369b436eab8d36b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDgyOTg3MA==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r444829870", "bodyText": "I tried renaming it but I found that harder to distinguish (usageWithoutReservedSpace and usageWithReservedSpace are pretty similar to the eye). Moved the construction lower down in 56ecdb7.", "author": "DaveCTurner", "createdAt": "2020-06-24T11:34:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDgyMjIyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDgyMzM0Nw==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r444823347", "bodyText": "Control flow is  a bit crazy in this method now. Any thoughts on simplifying it?", "author": "ywelsch", "createdAt": "2020-06-24T11:20:13Z", "path": "server/src/main/java/org/elasticsearch/cluster/routing/allocation/DiskThresholdMonitor.java", "diffHunk": "@@ -158,18 +162,26 @@ public void onNewInfo(ClusterInfo info) {\n                 logger.warn(\"flood stage disk watermark [{}] exceeded on {}, all indices on this node will be marked read-only\",\n                     diskThresholdSettings.describeFloodStageThreshold(), usage);\n \n-            } else if (usage.getFreeBytes() < diskThresholdSettings.getFreeBytesThresholdHigh().getBytes() ||\n-                usage.getFreeDiskAsPercentage() < diskThresholdSettings.getFreeDiskThresholdHigh()) {\n+                continue;", "originalCommit": "4e75e1ff2f96e1b8096276bd2369b436eab8d36b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDgzMzAzNw==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r444833037", "bodyText": "Yes, I was considering introducing an explicit state machine for each node as I have always found this logic a little hard to follow. Not convinced it's worth it, I think the tests have pretty good coverage.", "author": "DaveCTurner", "createdAt": "2020-06-24T11:40:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDgyMzM0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDgzNjAwMw==", "url": "https://github.com/elastic/elasticsearch/pull/58029#discussion_r444836003", "bodyText": "ok, the tests are a good argument. Let's proceed as is then", "author": "ywelsch", "createdAt": "2020-06-24T11:46:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDgyMzM0Nw=="}], "type": "inlineReview"}, {"oid": "78d353e035146eb1f25c58ace0cff6548a3c83ca", "url": "https://github.com/elastic/elasticsearch/commit/78d353e035146eb1f25c58ace0cff6548a3c83ca", "message": "single volatile read", "committedDate": "2020-06-24T11:29:12Z", "type": "commit"}, {"oid": "56ecdb71c243a9fdac03826d8c5b210ccb18d23b", "url": "https://github.com/elastic/elasticsearch/commit/56ecdb71c243a9fdac03826d8c5b210ccb18d23b", "message": "Construct usageWithReservedSpace later", "committedDate": "2020-06-24T11:33:06Z", "type": "commit"}, {"oid": "62a19449a57413c5bae4b1c6af0cc121081041ee", "url": "https://github.com/elastic/elasticsearch/commit/62a19449a57413c5bae4b1c6af0cc121081041ee", "message": "Merge branch 'master' into 2020-06-12-reserve-bytes-in-store-stats", "committedDate": "2020-06-29T12:05:07Z", "type": "commit"}, {"oid": "6cee87b760a2338472b2272c1263cfdd2676888d", "url": "https://github.com/elastic/elasticsearch/commit/6cee87b760a2338472b2272c1263cfdd2676888d", "message": "Ignore reserved bytes in aggregations if unknown", "committedDate": "2020-06-29T12:11:35Z", "type": "commit"}, {"oid": "29fb53054a50239af44a6b20d052e60a12660277", "url": "https://github.com/elastic/elasticsearch/commit/29fb53054a50239af44a6b20d052e60a12660277", "message": "Fix up test", "committedDate": "2020-06-29T13:39:37Z", "type": "commit"}, {"oid": "02c983d5c753d45792feabb9d9119d11ff75aa7c", "url": "https://github.com/elastic/elasticsearch/commit/02c983d5c753d45792feabb9d9119d11ff75aa7c", "message": "Merge branch 'master' into 2020-06-12-reserve-bytes-in-store-stats", "committedDate": "2020-06-30T14:13:16Z", "type": "commit"}, {"oid": "578500212f1ecda341d54967388115ccdc164ec7", "url": "https://github.com/elastic/elasticsearch/commit/578500212f1ecda341d54967388115ccdc164ec7", "message": "Omniscience", "committedDate": "2020-06-30T14:13:41Z", "type": "commit"}]}