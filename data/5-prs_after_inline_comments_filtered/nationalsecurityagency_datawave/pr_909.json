{"pr_number": 909, "pr_title": "fixes #858 repost", "pr_createdAt": "2020-08-31T12:19:51Z", "pr_url": "https://github.com/NationalSecurityAgency/datawave/pull/909", "timeline": [{"oid": "84ddeefe1e3915fd252efadfa66dd146227288dc", "url": "https://github.com/NationalSecurityAgency/datawave/commit/84ddeefe1e3915fd252efadfa66dd146227288dc", "message": "fixes #858 Add EventFieldIterator to merge values with tf iterator for document ranges", "committedDate": "2020-08-24T19:34:06Z", "type": "commit"}, {"oid": "0f9a3c84d1d7b0b5896e62b15a3afbb2751f5b0c", "url": "https://github.com/NationalSecurityAgency/datawave/commit/0f9a3c84d1d7b0b5896e62b15a3afbb2751f5b0c", "message": "fixes #858 Add normalize support for EventFieldIterator", "committedDate": "2020-08-27T13:13:09Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI0MDA0NQ==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r480240045", "bodyText": "How do we know everything in the document was pulled as a result of this aggregator?", "author": "ivakegg", "createdAt": "2020-08-31T16:20:03Z", "path": "warehouse/query-core/src/main/java/datawave/query/jexl/functions/EventFieldAggregator.java", "diffHunk": "@@ -0,0 +1,67 @@\n+package datawave.query.jexl.functions;\n+\n+import datawave.query.attributes.Attribute;\n+import datawave.query.attributes.AttributeFactory;\n+import datawave.query.attributes.Document;\n+import datawave.query.predicate.EventDataQueryFilter;\n+import datawave.query.tld.TLD;\n+import datawave.query.util.Tuple2;\n+import org.apache.accumulo.core.data.ArrayByteSequence;\n+import org.apache.accumulo.core.data.ByteSequence;\n+import org.apache.accumulo.core.data.Key;\n+import org.apache.accumulo.core.data.Value;\n+import org.apache.accumulo.core.iterators.SortedKeyValueIterator;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+\n+public class EventFieldAggregator extends IdentityAggregator {\n+    public EventFieldAggregator(String field, EventDataQueryFilter filter, int maxNextCount) {\n+        super(Collections.singleton(field), filter, maxNextCount);\n+    }\n+    \n+    @Override\n+    protected Tuple2<String,String> parserFieldNameValue(Key topKey) {\n+        String cq = topKey.getColumnQualifier().toString();\n+        int nullIndex1 = cq.indexOf('\\u0000');\n+        String field = cq.substring(0, nullIndex1);\n+        String value = cq.substring(nullIndex1 + 1);\n+        return new Tuple2<>(field, value);\n+    }\n+    \n+    @Override\n+    protected ByteSequence parseFieldNameValue(ByteSequence cf, ByteSequence cq) {\n+        ArrayList<Integer> nulls = TLD.instancesOf(0, cq, 1);\n+        final int startFv = nulls.get(0) + 1;\n+        final int stopFn = nulls.get(0);\n+        \n+        byte[] fnFv = new byte[cq.length()];\n+        System.arraycopy(cq.getBackingArray(), 0, fnFv, 0, stopFn);\n+        System.arraycopy(cq.getBackingArray(), startFv, fnFv, stopFn + 1, cq.length() - startFv);\n+        \n+        return new ArrayByteSequence(fnFv);\n+    }\n+    \n+    @Override\n+    protected ByteSequence getPointerData(Key key) {\n+        return key.getColumnFamilyData();\n+    }\n+    \n+    @Override\n+    protected ByteSequence parsePointer(ByteSequence columnFamily) {\n+        return columnFamily;\n+    }\n+    \n+    @Override\n+    public Key apply(SortedKeyValueIterator<Key,Value> itr, Document doc, AttributeFactory attrs) throws IOException {\n+        Key result = super.apply(itr, doc, attrs);\n+        \n+        // for each thing in the doc, mark it as to-keep false because it will ultimately come from the document aggregation, otherwise there will be duplicates\n+        for (Attribute<?> attr : doc.getDictionary().values()) {\n+            attr.setToKeep(false);", "originalCommit": "0f9a3c84d1d7b0b5896e62b15a3afbb2751f5b0c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTA5MjY1NQ==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r481092655", "bodyText": "that's fair, I will create a new document that I pass to apply() then merge it into doc.", "author": "FineAndDandy", "createdAt": "2020-09-01T12:16:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI0MDA0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI0MDg1NA==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r480240854", "bodyText": "Hard coded 1 hour... hmm....", "author": "ivakegg", "createdAt": "2020-08-31T16:21:23Z", "path": "warehouse/query-core/src/main/java/datawave/query/iterator/logic/EventFieldNormalizingIterator.java", "diffHunk": "@@ -0,0 +1,248 @@\n+package datawave.query.iterator.logic;\n+\n+import com.google.common.cache.CacheBuilder;\n+import com.google.common.cache.CacheLoader;\n+import com.google.common.cache.LoadingCache;\n+import datawave.data.type.NoOpType;\n+import datawave.data.type.Type;\n+import datawave.query.jexl.JexlASTHelper;\n+import datawave.query.util.Tuple1;\n+import datawave.query.util.Tuple2;\n+import datawave.query.util.TypeMetadata;\n+import org.apache.accumulo.core.data.ByteSequence;\n+import org.apache.accumulo.core.data.Key;\n+import org.apache.accumulo.core.data.PartialKey;\n+import org.apache.accumulo.core.data.Range;\n+import org.apache.accumulo.core.data.Value;\n+import org.apache.accumulo.core.iterators.IteratorEnvironment;\n+import org.apache.accumulo.core.iterators.SortedKeyValueIterator;\n+import org.apache.hadoop.io.Text;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.NoSuchElementException;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * Iterator expects Event Key/Value pairs and will filter to only matching field and apply normalizations. This will result in one Key generated per normalizer\n+ * applied to a field\n+ */\n+public class EventFieldNormalizingIterator implements SortedKeyValueIterator<Key,Value> {\n+    // speedy cache loading for types, duplicated from AttributeFactory with caching of types rather than classes\n+    protected static LoadingCache<String,Type<?>> typeCache = CacheBuilder.newBuilder().maximumSize(128).expireAfterAccess(1, TimeUnit.HOURS)\n+                    .build(new CacheLoader<String,Type<?>>() {", "originalCommit": "0f9a3c84d1d7b0b5896e62b15a3afbb2751f5b0c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTA5MzEzOQ==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r481093139", "bodyText": "This is the same hard coded value as the AttributeFactory cache.", "author": "FineAndDandy", "createdAt": "2020-09-01T12:17:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI0MDg1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI3Mjc5OA==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r480272798", "bodyText": "It seems to me that we are doing a lot of work to try and keep things sorted when all we are doing is aggregating these into a Document.  Would a better approach be to modify the aggregator to simply do the normalization?", "author": "ivakegg", "createdAt": "2020-08-31T17:18:46Z", "path": "warehouse/query-core/src/main/java/datawave/query/iterator/logic/EventFieldNormalizingIterator.java", "diffHunk": "@@ -0,0 +1,248 @@\n+package datawave.query.iterator.logic;\n+\n+import com.google.common.cache.CacheBuilder;\n+import com.google.common.cache.CacheLoader;\n+import com.google.common.cache.LoadingCache;\n+import datawave.data.type.NoOpType;\n+import datawave.data.type.Type;\n+import datawave.query.jexl.JexlASTHelper;\n+import datawave.query.util.Tuple1;\n+import datawave.query.util.Tuple2;\n+import datawave.query.util.TypeMetadata;\n+import org.apache.accumulo.core.data.ByteSequence;\n+import org.apache.accumulo.core.data.Key;\n+import org.apache.accumulo.core.data.PartialKey;\n+import org.apache.accumulo.core.data.Range;\n+import org.apache.accumulo.core.data.Value;\n+import org.apache.accumulo.core.iterators.IteratorEnvironment;\n+import org.apache.accumulo.core.iterators.SortedKeyValueIterator;\n+import org.apache.hadoop.io.Text;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.NoSuchElementException;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * Iterator expects Event Key/Value pairs and will filter to only matching field and apply normalizations. This will result in one Key generated per normalizer\n+ * applied to a field\n+ */\n+public class EventFieldNormalizingIterator implements SortedKeyValueIterator<Key,Value> {", "originalCommit": "0f9a3c84d1d7b0b5896e62b15a3afbb2751f5b0c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTA5NDE3OA==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r481094178", "bodyText": "I originally started there, but because it has a 1:many relationship due to normalizers it was going to require interface changes to IdentityAggregator. We can still go with that if you prefer.", "author": "FineAndDandy", "createdAt": "2020-09-01T12:19:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI3Mjc5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTExNDc0Mg==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r481114742", "bodyText": "If it makes the code simpler, then I am all for it.  We have added several new classes here whereas an api change and one simpler extension would be easier to understand and maintain.  I guess the question is how many other places will this affect my changing the interface to return 1:many relationships.", "author": "ivakegg", "createdAt": "2020-09-01T12:54:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI3Mjc5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTEyNTEyNg==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r481125126", "bodyText": "It requires changing the parserFieldValues() to return a list rather than a single value, then updating all current methods to return singletons.", "author": "FineAndDandy", "createdAt": "2020-09-01T13:10:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI3Mjc5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTA2MDY3OQ==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r481060679", "bodyText": "Should be compareTo() < 0", "author": "apmoriarty", "createdAt": "2020-09-01T11:14:48Z", "path": "warehouse/query-core/src/main/java/datawave/query/iterator/EventFieldIterator.java", "diffHunk": "@@ -0,0 +1,163 @@\n+package datawave.query.iterator;\n+\n+import datawave.data.type.NoOpType;\n+import datawave.query.attributes.AttributeFactory;\n+import datawave.query.attributes.Document;\n+import datawave.query.iterator.logic.EventFieldNormalizingIterator;\n+import datawave.query.jexl.functions.IdentityAggregator;\n+import datawave.query.util.TypeMetadata;\n+import org.apache.accumulo.core.data.Key;\n+import org.apache.accumulo.core.data.Range;\n+import org.apache.accumulo.core.data.Value;\n+import org.apache.accumulo.core.iterators.SortedKeyValueIterator;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.Collections;\n+\n+/**\n+ * Iterate over a document range aggregating fields in their normalized form.\n+ */\n+public class EventFieldIterator implements NestedIterator<Key> {\n+    private final Range range;\n+    private final SortedKeyValueIterator<Key,Value> source;\n+    private final String field;\n+    private final AttributeFactory attributeFactory;\n+    private final TypeMetadata typeMetadata;\n+    private final IdentityAggregator aggregator;\n+    private Key key;\n+    private Document document;\n+    private boolean initialized = false;\n+    private EventFieldNormalizingIterator normalizingIterator;\n+    \n+    public EventFieldIterator(Range range, SortedKeyValueIterator<Key,Value> source, String field, AttributeFactory attributeFactory,\n+                    TypeMetadata typeMetadata, IdentityAggregator aggregator) {\n+        this.range = range;\n+        this.source = source;\n+        this.field = field;\n+        this.attributeFactory = attributeFactory;\n+        this.typeMetadata = typeMetadata;\n+        this.aggregator = aggregator;\n+    }\n+    \n+    @Override\n+    public void initialize() {\n+        // no-op\n+    }\n+    \n+    @Override\n+    public Key move(Key minimum) {\n+        // simple sanity check that is free\n+        if (!range.contains(minimum)) {\n+            return null;\n+        }\n+        \n+        // test current source key to determine state\n+        if (!source.hasTop()) {\n+            // no key can match the underlying source is empty\n+            return null;\n+        }\n+        \n+        Key top = source.getTopKey();\n+        \n+        if (minimum.compareTo(top) < -1) {", "originalCommit": "0f9a3c84d1d7b0b5896e62b15a3afbb2751f5b0c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTA5NDQyMQ==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r481094421", "bodyText": "yep", "author": "FineAndDandy", "createdAt": "2020-09-01T12:19:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTA2MDY3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTA2MjQzNg==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r481062436", "bodyText": "the consistency in these two constructors is killing me.", "author": "apmoriarty", "createdAt": "2020-09-01T11:18:14Z", "path": "warehouse/query-core/src/main/java/datawave/query/iterator/logic/EventFieldNormalizingIterator.java", "diffHunk": "@@ -0,0 +1,248 @@\n+package datawave.query.iterator.logic;\n+\n+import com.google.common.cache.CacheBuilder;\n+import com.google.common.cache.CacheLoader;\n+import com.google.common.cache.LoadingCache;\n+import datawave.data.type.NoOpType;\n+import datawave.data.type.Type;\n+import datawave.query.jexl.JexlASTHelper;\n+import datawave.query.util.Tuple1;\n+import datawave.query.util.Tuple2;\n+import datawave.query.util.TypeMetadata;\n+import org.apache.accumulo.core.data.ByteSequence;\n+import org.apache.accumulo.core.data.Key;\n+import org.apache.accumulo.core.data.PartialKey;\n+import org.apache.accumulo.core.data.Range;\n+import org.apache.accumulo.core.data.Value;\n+import org.apache.accumulo.core.iterators.IteratorEnvironment;\n+import org.apache.accumulo.core.iterators.SortedKeyValueIterator;\n+import org.apache.hadoop.io.Text;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.NoSuchElementException;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * Iterator expects Event Key/Value pairs and will filter to only matching field and apply normalizations. This will result in one Key generated per normalizer\n+ * applied to a field\n+ */\n+public class EventFieldNormalizingIterator implements SortedKeyValueIterator<Key,Value> {\n+    // speedy cache loading for types, duplicated from AttributeFactory with caching of types rather than classes\n+    protected static LoadingCache<String,Type<?>> typeCache = CacheBuilder.newBuilder().maximumSize(128).expireAfterAccess(1, TimeUnit.HOURS)\n+                    .build(new CacheLoader<String,Type<?>>() {\n+                        @Override\n+                        public Type<?> load(String clazz) throws Exception {\n+                            Class<?> c = Class.forName(clazz);\n+                            return (Type<?>) c.newInstance();\n+                        }\n+                    });\n+    \n+    private final String field;\n+    private final TypeMetadata typeMetadata;\n+    \n+    private SortedKeyValueIterator<Key,Value> delegate;\n+    private IteratorEnvironment environment;\n+    \n+    // sorted cache for normalized key/value pairs sorted by Key\n+    private SortedSet<Tuple2<Key,Value>> sorted = new TreeSet<>(Comparator.comparing(Tuple1::first));\n+    private String defaultTypeClass = NoOpType.class.getName();\n+    \n+    private boolean initialized = false;\n+    \n+    public EventFieldNormalizingIterator(String field, SortedKeyValueIterator<Key,Value> delegate, TypeMetadata typeMetadata, String defaultTypeClass) {\n+        this.field = field;\n+        this.delegate = delegate;\n+        this.typeMetadata = typeMetadata;\n+        this.defaultTypeClass = defaultTypeClass;\n+    }\n+    ", "originalCommit": "0f9a3c84d1d7b0b5896e62b15a3afbb2751f5b0c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "46772adfeb1b4aba9430ddd9e8d19cf754db823b", "url": "https://github.com/NationalSecurityAgency/datawave/commit/46772adfeb1b4aba9430ddd9e8d19cf754db823b", "message": "fixes #858 Remove EventFieldNormalizingIterator and push functionality into EventFieldAggregator", "committedDate": "2020-09-01T17:41:56Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjk3NDk0Ng==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r482974946", "bodyText": "be -> been", "author": "ivakegg", "createdAt": "2020-09-03T13:25:05Z", "path": "warehouse/query-core/src/main/java/datawave/query/iterator/EventFieldIterator.java", "diffHunk": "@@ -0,0 +1,176 @@\n+package datawave.query.iterator;\n+\n+import datawave.query.attributes.AttributeFactory;\n+import datawave.query.attributes.Document;\n+import datawave.query.jexl.JexlASTHelper;\n+import datawave.query.jexl.functions.IdentityAggregator;\n+import org.apache.accumulo.core.data.Key;\n+import org.apache.accumulo.core.data.Range;\n+import org.apache.accumulo.core.data.Value;\n+import org.apache.accumulo.core.iterators.SortedKeyValueIterator;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.Collections;\n+\n+/**\n+ * Iterate over a document range aggregating fields in their normalized form.\n+ */\n+public class EventFieldIterator implements NestedIterator<Key> {\n+    private final Range range;\n+    private final SortedKeyValueIterator<Key,Value> source;\n+    private final String field;\n+    private final IdentityAggregator aggregator;\n+    private final AttributeFactory attributeFactory;\n+    private Key key;\n+    private Document document;\n+    private boolean initialized = false;\n+    \n+    public EventFieldIterator(Range range, SortedKeyValueIterator<Key,Value> source, String field, AttributeFactory attributeFactory,\n+                    IdentityAggregator aggregator) {\n+        this.range = range;\n+        this.source = source;\n+        this.field = field;\n+        this.attributeFactory = attributeFactory;\n+        this.aggregator = aggregator;\n+    }\n+    \n+    @Override\n+    public void initialize() {\n+        // no-op\n+    }\n+    \n+    @Override\n+    public Key move(Key minimum) {\n+        // simple sanity check that is free\n+        if (!range.contains(minimum)) {\n+            return null;\n+        }\n+        \n+        // test current source key to determine state\n+        if (!source.hasTop()) {\n+            // no key can match the underlying source is empty\n+            return null;\n+        }\n+        \n+        Key top = source.getTopKey();\n+        \n+        if (minimum.compareTo(top) < 0) {\n+            throw new IllegalStateException(\"cannot move iterator backwards to \" + minimum);\n+        }\n+        \n+        // update the range to start a minimum\n+        Range newRange = new Range(minimum, true, range.getEndKey(), range.isEndKeyInclusive());\n+        \n+        try {\n+            if (!initialized) {\n+                init(newRange);\n+            } else {\n+                // just seek\n+                source.seek(newRange, Collections.emptyList(), false);\n+                getNext();\n+            }\n+        } catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+        \n+        return next();\n+    }\n+    \n+    @Override\n+    public Collection<NestedIterator<Key>> leaves() {\n+        return Collections.emptySet();\n+    }\n+    \n+    @Override\n+    public Collection<NestedIterator<Key>> children() {\n+        return Collections.emptySet();\n+    }\n+    \n+    @Override\n+    public Document document() {\n+        return document;\n+    }\n+    \n+    @Override\n+    public boolean isContextRequired() {\n+        return false;\n+    }\n+    \n+    @Override\n+    public void setContext(Key context) {\n+        // no-op\n+    }\n+    \n+    @Override\n+    public boolean hasNext() {\n+        // do the actual seeking now if it hasn't be done yet", "originalCommit": "46772adfeb1b4aba9430ddd9e8d19cf754db823b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjI5Mzg3NA==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r492293874", "bodyText": "got it", "author": "FineAndDandy", "createdAt": "2020-09-21T19:24:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjk3NDk0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjk3OTI4Mw==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r482979283", "bodyText": "The valid bytes in cf.getBackingArray() only go through cf.length().  The backing array could be longer.", "author": "ivakegg", "createdAt": "2020-09-03T13:30:58Z", "path": "warehouse/query-core/src/main/java/datawave/query/jexl/functions/EventFieldAggregator.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package datawave.query.jexl.functions;\n+\n+import com.google.common.cache.CacheBuilder;\n+import com.google.common.cache.CacheLoader;\n+import com.google.common.cache.LoadingCache;\n+import datawave.data.type.Type;\n+import datawave.query.attributes.Attribute;\n+import datawave.query.attributes.AttributeFactory;\n+import datawave.query.attributes.Document;\n+import datawave.query.predicate.EventDataQueryFilter;\n+import datawave.query.tld.TLD;\n+import datawave.query.util.Tuple2;\n+import datawave.query.util.TypeMetadata;\n+import org.apache.accumulo.core.data.ArrayByteSequence;\n+import org.apache.accumulo.core.data.ByteSequence;\n+import org.apache.accumulo.core.data.Key;\n+import org.apache.accumulo.core.data.Value;\n+import org.apache.accumulo.core.iterators.SortedKeyValueIterator;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+\n+public class EventFieldAggregator extends IdentityAggregator {\n+    // speedy cache loading for types, duplicated from AttributeFactory with caching of types rather than classes\n+    protected static LoadingCache<String,Type<?>> typeCache = CacheBuilder.newBuilder().maximumSize(128).expireAfterAccess(1, TimeUnit.HOURS)\n+                    .build(new CacheLoader<String,Type<?>>() {\n+                        @Override\n+                        public Type<?> load(String clazz) throws Exception {\n+                            Class<?> c = Class.forName(clazz);\n+                            return (Type<?>) c.newInstance();\n+                        }\n+                    });\n+    \n+    private TypeMetadata typeMetadata;\n+    private String defaultTypeClass;\n+    \n+    public EventFieldAggregator(String field, EventDataQueryFilter filter, int maxNextCount, TypeMetadata typeMetadata, String defaultTypeClass) {\n+        super(Collections.singleton(field), filter, maxNextCount);\n+        \n+        this.typeMetadata = typeMetadata;\n+        this.defaultTypeClass = defaultTypeClass;\n+    }\n+    \n+    @Override\n+    protected List<Tuple2<String,String>> parserFieldNameValue(Key topKey) {\n+        String cq = topKey.getColumnQualifier().toString();\n+        int nullIndex1 = cq.indexOf('\\u0000');\n+        String field = cq.substring(0, nullIndex1);\n+        String value = cq.substring(nullIndex1 + 1);\n+        \n+        int dataTypeEnd = -1;\n+        ByteSequence cf = topKey.getColumnFamilyData();\n+        for (int i = 0; i < cf.getBackingArray().length; i++) {", "originalCommit": "46772adfeb1b4aba9430ddd9e8d19cf754db823b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjI5NDEyMQ==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r492294121", "bodyText": "good catch", "author": "FineAndDandy", "createdAt": "2020-09-21T19:24:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjk3OTI4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjk4ODAxNg==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r482988016", "bodyText": "Seems to me this whole method could be replaced with simply returning cq.  If you need a copy of the bytes then return new ArrayByteSequence(Arrays.copyOf(cq.getBackingArray(), cq.length()), 0, cq.length()).", "author": "ivakegg", "createdAt": "2020-09-03T13:43:49Z", "path": "warehouse/query-core/src/main/java/datawave/query/jexl/functions/EventFieldAggregator.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package datawave.query.jexl.functions;\n+\n+import com.google.common.cache.CacheBuilder;\n+import com.google.common.cache.CacheLoader;\n+import com.google.common.cache.LoadingCache;\n+import datawave.data.type.Type;\n+import datawave.query.attributes.Attribute;\n+import datawave.query.attributes.AttributeFactory;\n+import datawave.query.attributes.Document;\n+import datawave.query.predicate.EventDataQueryFilter;\n+import datawave.query.tld.TLD;\n+import datawave.query.util.Tuple2;\n+import datawave.query.util.TypeMetadata;\n+import org.apache.accumulo.core.data.ArrayByteSequence;\n+import org.apache.accumulo.core.data.ByteSequence;\n+import org.apache.accumulo.core.data.Key;\n+import org.apache.accumulo.core.data.Value;\n+import org.apache.accumulo.core.iterators.SortedKeyValueIterator;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+\n+public class EventFieldAggregator extends IdentityAggregator {\n+    // speedy cache loading for types, duplicated from AttributeFactory with caching of types rather than classes\n+    protected static LoadingCache<String,Type<?>> typeCache = CacheBuilder.newBuilder().maximumSize(128).expireAfterAccess(1, TimeUnit.HOURS)\n+                    .build(new CacheLoader<String,Type<?>>() {\n+                        @Override\n+                        public Type<?> load(String clazz) throws Exception {\n+                            Class<?> c = Class.forName(clazz);\n+                            return (Type<?>) c.newInstance();\n+                        }\n+                    });\n+    \n+    private TypeMetadata typeMetadata;\n+    private String defaultTypeClass;\n+    \n+    public EventFieldAggregator(String field, EventDataQueryFilter filter, int maxNextCount, TypeMetadata typeMetadata, String defaultTypeClass) {\n+        super(Collections.singleton(field), filter, maxNextCount);\n+        \n+        this.typeMetadata = typeMetadata;\n+        this.defaultTypeClass = defaultTypeClass;\n+    }\n+    \n+    @Override\n+    protected List<Tuple2<String,String>> parserFieldNameValue(Key topKey) {\n+        String cq = topKey.getColumnQualifier().toString();\n+        int nullIndex1 = cq.indexOf('\\u0000');\n+        String field = cq.substring(0, nullIndex1);\n+        String value = cq.substring(nullIndex1 + 1);\n+        \n+        int dataTypeEnd = -1;\n+        ByteSequence cf = topKey.getColumnFamilyData();\n+        for (int i = 0; i < cf.getBackingArray().length; i++) {\n+            if (cf.byteAt(i) == '\\u0000') {\n+                dataTypeEnd = i;\n+            }\n+        }\n+        \n+        if (dataTypeEnd <= 0) {\n+            throw new RuntimeException(\"malformed key, cannot parse data type from event\");\n+        }\n+        \n+        String dataType = cf.subSequence(0, dataTypeEnd).toString();\n+        \n+        Set<String> normalizedValues = getNormalizedValues(dataType, field, value);\n+        List<Tuple2<String,String>> fieldValuePairs = new ArrayList<>(normalizedValues.size());\n+        for (String normalizedValue : normalizedValues) {\n+            fieldValuePairs.add(new Tuple2<>(field, normalizedValue));\n+        }\n+        \n+        return fieldValuePairs;\n+    }\n+    \n+    @Override\n+    protected ByteSequence parseFieldNameValue(ByteSequence cf, ByteSequence cq) {\n+        ArrayList<Integer> nulls = TLD.instancesOf(0, cq, 1);", "originalCommit": "46772adfeb1b4aba9430ddd9e8d19cf754db823b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjI5NTMxMg==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r492295312", "bodyText": "you are right, there is no reason to do this. I don't think there is any reason not to just return the cq.", "author": "FineAndDandy", "createdAt": "2020-09-21T19:27:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjk4ODAxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjk5Mzc1OQ==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r482993759", "bodyText": "This is not actually doing any sorting.", "author": "ivakegg", "createdAt": "2020-09-03T13:51:42Z", "path": "warehouse/query-core/src/main/java/datawave/query/jexl/functions/EventFieldAggregator.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package datawave.query.jexl.functions;\n+\n+import com.google.common.cache.CacheBuilder;\n+import com.google.common.cache.CacheLoader;\n+import com.google.common.cache.LoadingCache;\n+import datawave.data.type.Type;\n+import datawave.query.attributes.Attribute;\n+import datawave.query.attributes.AttributeFactory;\n+import datawave.query.attributes.Document;\n+import datawave.query.predicate.EventDataQueryFilter;\n+import datawave.query.tld.TLD;\n+import datawave.query.util.Tuple2;\n+import datawave.query.util.TypeMetadata;\n+import org.apache.accumulo.core.data.ArrayByteSequence;\n+import org.apache.accumulo.core.data.ByteSequence;\n+import org.apache.accumulo.core.data.Key;\n+import org.apache.accumulo.core.data.Value;\n+import org.apache.accumulo.core.iterators.SortedKeyValueIterator;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+\n+public class EventFieldAggregator extends IdentityAggregator {\n+    // speedy cache loading for types, duplicated from AttributeFactory with caching of types rather than classes\n+    protected static LoadingCache<String,Type<?>> typeCache = CacheBuilder.newBuilder().maximumSize(128).expireAfterAccess(1, TimeUnit.HOURS)\n+                    .build(new CacheLoader<String,Type<?>>() {\n+                        @Override\n+                        public Type<?> load(String clazz) throws Exception {\n+                            Class<?> c = Class.forName(clazz);\n+                            return (Type<?>) c.newInstance();\n+                        }\n+                    });\n+    \n+    private TypeMetadata typeMetadata;\n+    private String defaultTypeClass;\n+    \n+    public EventFieldAggregator(String field, EventDataQueryFilter filter, int maxNextCount, TypeMetadata typeMetadata, String defaultTypeClass) {\n+        super(Collections.singleton(field), filter, maxNextCount);\n+        \n+        this.typeMetadata = typeMetadata;\n+        this.defaultTypeClass = defaultTypeClass;\n+    }\n+    \n+    @Override\n+    protected List<Tuple2<String,String>> parserFieldNameValue(Key topKey) {\n+        String cq = topKey.getColumnQualifier().toString();\n+        int nullIndex1 = cq.indexOf('\\u0000');\n+        String field = cq.substring(0, nullIndex1);\n+        String value = cq.substring(nullIndex1 + 1);\n+        \n+        int dataTypeEnd = -1;\n+        ByteSequence cf = topKey.getColumnFamilyData();\n+        for (int i = 0; i < cf.getBackingArray().length; i++) {\n+            if (cf.byteAt(i) == '\\u0000') {\n+                dataTypeEnd = i;\n+            }\n+        }\n+        \n+        if (dataTypeEnd <= 0) {\n+            throw new RuntimeException(\"malformed key, cannot parse data type from event\");\n+        }\n+        \n+        String dataType = cf.subSequence(0, dataTypeEnd).toString();\n+        \n+        Set<String> normalizedValues = getNormalizedValues(dataType, field, value);\n+        List<Tuple2<String,String>> fieldValuePairs = new ArrayList<>(normalizedValues.size());\n+        for (String normalizedValue : normalizedValues) {\n+            fieldValuePairs.add(new Tuple2<>(field, normalizedValue));\n+        }\n+        \n+        return fieldValuePairs;\n+    }\n+    \n+    @Override\n+    protected ByteSequence parseFieldNameValue(ByteSequence cf, ByteSequence cq) {\n+        ArrayList<Integer> nulls = TLD.instancesOf(0, cq, 1);\n+        final int startFv = nulls.get(0) + 1;\n+        final int stopFn = nulls.get(0);\n+        \n+        byte[] fnFv = new byte[cq.length()];\n+        System.arraycopy(cq.getBackingArray(), 0, fnFv, 0, stopFn);\n+        System.arraycopy(cq.getBackingArray(), startFv, fnFv, stopFn + 1, cq.length() - startFv);\n+        \n+        return new ArrayByteSequence(fnFv);\n+    }\n+    \n+    @Override\n+    protected ByteSequence getPointerData(Key key) {\n+        return key.getColumnFamilyData();\n+    }\n+    \n+    @Override\n+    protected ByteSequence parsePointer(ByteSequence columnFamily) {\n+        return columnFamily;\n+    }\n+    \n+    @Override\n+    public Key apply(SortedKeyValueIterator<Key,Value> itr, Document doc, AttributeFactory attrs) throws IOException {\n+        Document d = new Document();\n+        Key result = super.apply(itr, d, attrs);\n+        \n+        // for each thing in the doc, mark it as to-keep false because it will ultimately come from the document aggregation, otherwise there will be duplicates\n+        for (Attribute<?> attr : d.getDictionary().values()) {\n+            attr.setToKeep(false);\n+        }\n+        \n+        doc.putAll(d, false);\n+        \n+        return result;\n+    }\n+    \n+    private Set<String> getNormalizedValues(String dataType, String fieldName, String fieldValue) {\n+        Set<String> normalizedValues = new HashSet<>();\n+        \n+        // fetch all Types for the field/dataType combination\n+        Collection<String> typeClasses = typeMetadata.getTypeMetadata(fieldName, dataType);\n+        \n+        // if its not found add the default\n+        if (typeClasses.size() == 0) {\n+            typeClasses.add(defaultTypeClass);\n+        }\n+        \n+        // transform the key for each type and add it to sorted", "originalCommit": "46772adfeb1b4aba9430ddd9e8d19cf754db823b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjI5NTczMA==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r492295730", "bodyText": "fixed docs", "author": "FineAndDandy", "createdAt": "2020-09-21T19:27:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjk5Mzc1OQ=="}], "type": "inlineReview"}, {"oid": "c0979add93eaae8791ff33814d35b4c528b706ac", "url": "https://github.com/NationalSecurityAgency/datawave/commit/c0979add93eaae8791ff33814d35b4c528b706ac", "message": "fixes #858 Update comments and simplify parseFieldNameValue()", "committedDate": "2020-09-21T19:44:54Z", "type": "commit"}, {"oid": "2d34b0b293a14406a7d5dd87494da44c06a99c64", "url": "https://github.com/NationalSecurityAgency/datawave/commit/2d34b0b293a14406a7d5dd87494da44c06a99c64", "message": "Merge branch 'release/version2.9' into 858", "committedDate": "2020-10-22T18:12:55Z", "type": "commit"}, {"oid": "0f240ddf5159aa30581635576ba223807f58ea2f", "url": "https://github.com/NationalSecurityAgency/datawave/commit/0f240ddf5159aa30581635576ba223807f58ea2f", "message": "Merge branch 'release/version3.2' into 858", "committedDate": "2021-02-24T13:01:27Z", "type": "commit"}, {"oid": "0198b02b93b7eb7f8f515d2c2bd45c5ffb2e6097", "url": "https://github.com/NationalSecurityAgency/datawave/commit/0198b02b93b7eb7f8f515d2c2bd45c5ffb2e6097", "message": "fixes #858: Copy map into modifiable HashSet add minor efficiency", "committedDate": "2021-02-24T14:39:46Z", "type": "commit"}, {"oid": "79a40342ebfe032bd680c075ed379f84973d048c", "url": "https://github.com/NationalSecurityAgency/datawave/commit/79a40342ebfe032bd680c075ed379f84973d048c", "message": "Merge branch 'release/version3.2' into 858", "committedDate": "2021-03-09T14:33:59Z", "type": "commit"}, {"oid": "19e62ea56e0c5891628489cd59dcf3a582f93598", "url": "https://github.com/NationalSecurityAgency/datawave/commit/19e62ea56e0c5891628489cd59dcf3a582f93598", "message": "Merge branch 'release/version3.2' into 858", "committedDate": "2021-03-09T18:50:37Z", "type": "commit"}, {"oid": "a55adb7db28e854ce4e209c6780fc45e83f9ae8d", "url": "https://github.com/NationalSecurityAgency/datawave/commit/a55adb7db28e854ce4e209c6780fc45e83f9ae8d", "message": "Merge branch 'release/version3.2' into 858", "committedDate": "2021-03-10T13:11:45Z", "type": "commit"}, {"oid": "441b369adfc3fd5bbbcd4885b9d336b93a23530a", "url": "https://github.com/NationalSecurityAgency/datawave/commit/441b369adfc3fd5bbbcd4885b9d336b93a23530a", "message": "fixes #858: spotbugs fix", "committedDate": "2021-03-10T16:26:38Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5MjM4NjI0Mw==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r592386243", "bodyText": "I think this is making an assumption about how we create UIDs.  If we turned on the timestamp portion of the UID then this would break or if we decide to substitute an alternate UID mechanism as it is currently pluggable.  Can we simply look for the last dot and strip that off?", "author": "ivakegg", "createdAt": "2021-03-11T14:05:03Z", "path": "warehouse/query-core/src/main/java/datawave/query/jexl/functions/TLDEventFieldAggregator.java", "diffHunk": "@@ -0,0 +1,34 @@\n+package datawave.query.jexl.functions;\n+\n+import datawave.query.predicate.EventDataQueryFilter;\n+import datawave.query.tld.TLD;\n+import datawave.query.util.TypeMetadata;\n+import org.apache.accumulo.core.data.ByteSequence;\n+\n+import java.util.ArrayList;\n+\n+public class TLDEventFieldAggregator extends EventFieldAggregator {\n+    public TLDEventFieldAggregator(String field, EventDataQueryFilter filter, int maxNextCount, TypeMetadata typeMetadata, String defaultTypeClass) {\n+        super(field, filter, maxNextCount, typeMetadata, defaultTypeClass);\n+    }\n+    \n+    @Override\n+    protected ByteSequence parsePointer(ByteSequence columnFamily) {\n+        // find the null between the dataType and Uid\n+        ArrayList<Integer> nulls = TLD.instancesOf(0, columnFamily, 1);\n+        final int start = nulls.get(0) + 1;\n+        \n+        // uid is from the null byte to the end of the cf\n+        ByteSequence uid = columnFamily.subSequence(start, columnFamily.length());\n+        \n+        // find the end of the tld if it exists\n+        ArrayList<Integer> dots = TLD.instancesOf('.', uid);\n+        if (dots.size() > 2) {\n+            // reduce to the TLD\n+            return columnFamily.subSequence(0, start + dots.get(2));", "originalCommit": "441b369adfc3fd5bbbcd4885b9d336b93a23530a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5MjM5ODE5Ng==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r592398196", "bodyText": "What if there's more than one dot, for example uid.1.1.2", "author": "apmoriarty", "createdAt": "2021-03-11T14:19:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5MjM4NjI0Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5MjUyOTMxOA==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r592529318", "bodyText": "I updated the code to use UID to get the base UID", "author": "FineAndDandy", "createdAt": "2021-03-11T16:51:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5MjM4NjI0Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5MjUyOTY5MA==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r592529690", "bodyText": "Generally this query logic is probably not configured right if the UID scheme changes", "author": "FineAndDandy", "createdAt": "2021-03-11T16:52:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5MjM4NjI0Mw=="}], "type": "inlineReview"}, {"oid": "7d3d25df5154fc8738b9901ea09c77e3eca2602a", "url": "https://github.com/NationalSecurityAgency/datawave/commit/7d3d25df5154fc8738b9901ea09c77e3eca2602a", "message": "fixes #858: Use UID to parse base UID", "committedDate": "2021-03-11T16:49:10Z", "type": "commit"}, {"oid": "2fa97d2969b96ea66d4d203928916b4d5323344c", "url": "https://github.com/NationalSecurityAgency/datawave/commit/2fa97d2969b96ea66d4d203928916b4d5323344c", "message": "Merge branch 'release/version3.2' into 858", "committedDate": "2021-03-17T12:18:55Z", "type": "commit"}, {"oid": "ba0b3fe659c5d5915b9b58b0098651f331975392", "url": "https://github.com/NationalSecurityAgency/datawave/commit/ba0b3fe659c5d5915b9b58b0098651f331975392", "message": "Merge branch 'release/version3.2' into 858", "committedDate": "2021-03-17T13:38:48Z", "type": "commit"}]}