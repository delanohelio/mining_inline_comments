{"pr_number": 14461, "pr_title": "Support compression for PageFile", "pr_createdAt": "2020-04-29T21:10:44Z", "pr_url": "https://github.com/prestodb/presto/pull/14461", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzcwMjk2NA==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r417702964", "bodyText": "Throwing an error as default behaviour caused test failures: com.facebook.presto.spi.PrestoException: GZIP compression is not supported with PAGEFILE   because these tests use GZIP as default file compression method.  For unsupported HiveCompressionCodec,  should the default behaviour be no compression or SNAPPY rather than throwing an error?", "author": "viczhang861", "createdAt": "2020-04-30T01:20:12Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/pagefile/PageFileWriterFactory.java", "diffHunk": "@@ -104,6 +111,43 @@ public static void createEmptyPageFile(\n         }\n     }\n \n+    public static HiveCompressionCodec getCompressionCodec(String compression)\n+    {\n+        try {\n+            return HiveCompressionCodec.valueOf(compression);\n+        }\n+        catch (IllegalArgumentException | NullPointerException e) {\n+            throw new PrestoException(GENERIC_INTERNAL_ERROR, format(\"Unrecognized compression name %s\", compression), e);\n+        }\n+    }\n+\n+    public static PagesSerde createPagesSerdeForPageFile(BlockEncodingSerde blockEncodingSerde, HiveCompressionCodec compressionCodec)\n+    {\n+        if (!compressionCodec.isSupportedStorageFormat(PAGEFILE)) {\n+            throw new PrestoException(\n+                    GENERIC_USER_ERROR,\n+                    format(\"%s compression is not supported for %s\", compressionCodec.name(), PAGEFILE.getOutputFormat()));\n+        }\n+\n+        PageCompressor pageCompressor = null;\n+        PageDecompressor pageDecompressor = null;\n+\n+        switch (compressionCodec) {\n+            case NONE:\n+                break;\n+            case SNAPPY:\n+                pageCompressor = new BasicPageCompressor(new SnappyCompressor());\n+                pageDecompressor = new BasicPageDecompressor(new SnappyDecompressor());\n+                break;\n+            default:", "originalCommit": "c1e4d77ea3007200bb8e5029a42b9d312c7c51cb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI3MzM5OA==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r418273398", "bodyText": "Let's throw an error. Also it feels like it should be simple to implement GZIP, since it is our default for now. That would prevent us from fixing all the failing tests due to that.", "author": "arhimondr", "createdAt": "2020-04-30T20:35:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzcwMjk2NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM5NTI5NA==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r418395294", "bodyText": "This seems a good solution to not changing the default setting for hive.compression-codec", "author": "viczhang861", "createdAt": "2020-05-01T02:58:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzcwMjk2NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODQwNTk3Ng==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r418405976", "bodyText": "May be you should have a separate compression config for pageFileStorage, that way you can have your own default. It would also allow you to configure on clusters without touching compression for other storage.", "author": "jainxrohit", "createdAt": "2020-05-01T03:56:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzcwMjk2NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODUyNjg4NA==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r418526884", "bodyText": "May be you should have a separate compression config for pageFileStorage, that way you can have your own default. It would also allow you to configure on clusters without touching compression for other storage.\n\ncc @arhimondr This is also a good solution. Is there a need to support GZIP for page file?", "author": "viczhang861", "createdAt": "2020-05-01T12:47:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzcwMjk2NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODU0NDUwMg==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r418544502", "bodyText": "In practice the pagefile format is going to be used only for temporary tables. There's a configuration property for temporary tables already: https://github.com/prestodb/presto/blob/master/presto-hive/src/main/java/com/facebook/presto/hive/HiveClientConfig.java#L158. Exploding properties is generally not desirable, as it makes the configuration process not straightforward. Unless there's a clear justification for adding more properties I would suggest to restrain from it.\n@viczhang861 If you think that implementing GZIP will take too much time feel free not to do this. I just thought that it might be a simple change.", "author": "arhimondr", "createdAt": "2020-05-01T13:39:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzcwMjk2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI1OTc1OA==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r418259758", "bodyText": "private final", "author": "arhimondr", "createdAt": "2020-04-30T20:09:17Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/pagefile/BasicPageCompressor.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.pagefile;\n+\n+import com.facebook.presto.spi.page.PageCompressor;\n+import io.airlift.compress.Compressor;\n+\n+import java.nio.ByteBuffer;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+public class BasicPageCompressor\n+        implements PageCompressor\n+{\n+    Compressor compressor;", "originalCommit": "49d41f18d205ab4b4764b28f4dd6cccfe4ab7abc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI2MDA1NA==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r418260054", "bodyText": "It is just an adapter for aircompressor. How about calling it AirliftCompressorAdapter?", "author": "arhimondr", "createdAt": "2020-04-30T20:09:49Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/pagefile/BasicPageCompressor.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.pagefile;\n+\n+import com.facebook.presto.spi.page.PageCompressor;\n+import io.airlift.compress.Compressor;\n+\n+import java.nio.ByteBuffer;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+public class BasicPageCompressor", "originalCommit": "49d41f18d205ab4b4764b28f4dd6cccfe4ab7abc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI2MDEzOQ==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r418260139", "bodyText": "private final", "author": "arhimondr", "createdAt": "2020-04-30T20:09:59Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/pagefile/BasicPageDecompressor.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.pagefile;\n+\n+import com.facebook.presto.spi.page.PageDecompressor;\n+import io.airlift.compress.Decompressor;\n+\n+import java.nio.ByteBuffer;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+public class BasicPageDecompressor\n+        implements PageDecompressor\n+{\n+    Decompressor decompressor;", "originalCommit": "49d41f18d205ab4b4764b28f4dd6cccfe4ab7abc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI2MDIxMw==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r418260213", "bodyText": "It is just an adapter for aircompressor. How about calling it AirliftDecompressorAdapter?", "author": "arhimondr", "createdAt": "2020-04-30T20:10:09Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/pagefile/BasicPageDecompressor.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.pagefile;\n+\n+import com.facebook.presto.spi.page.PageDecompressor;\n+import io.airlift.compress.Decompressor;\n+\n+import java.nio.ByteBuffer;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+public class BasicPageDecompressor", "originalCommit": "49d41f18d205ab4b4764b28f4dd6cccfe4ab7abc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI2NDE5Mw==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r418264193", "bodyText": "Why do we have to reset it here? Is it because the standard, GZIP compression is not supported? How hard is it to simply support it?", "author": "arhimondr", "createdAt": "2020-04-30T20:17:56Z", "path": "presto-hive/src/test/java/com/facebook/presto/hive/TestHiveIntegrationSmokeTest.java", "diffHunk": "@@ -4884,7 +4921,13 @@ private static ConnectorSession getConnectorSession(Session session)\n     private void testWithAllStorageFormats(BiConsumer<Session, HiveStorageFormat> test)\n     {\n         for (HiveStorageFormat storageFormat : HiveStorageFormat.values()) {\n-            test.accept(getSession(), storageFormat);\n+            Session session = getSession();\n+            if (storageFormat == PAGEFILE) {\n+                session = Session.builder(getSession())\n+                        .setCatalogSessionProperty(catalog, \"compression_codec\", \"SNAPPY\")", "originalCommit": "49d41f18d205ab4b4764b28f4dd6cccfe4ab7abc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI2NDY0MA==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r418264640", "bodyText": "I wonder if it makes sense to support one more compression codec. Generally speaking both LZ4 and SNAPPY are pretty close in their compression characteristics.", "author": "arhimondr", "createdAt": "2020-04-30T20:18:45Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveCompressionCodec.java", "diffHunk": "@@ -24,13 +24,15 @@\n \n import static com.facebook.presto.hive.HiveStorageFormat.DWRF;\n import static com.facebook.presto.hive.HiveStorageFormat.ORC;\n+import static com.facebook.presto.hive.HiveStorageFormat.PAGEFILE;\n import static java.util.Objects.requireNonNull;\n \n public enum HiveCompressionCodec\n {\n     NONE(null, CompressionKind.NONE, CompressionCodecName.UNCOMPRESSED, f -> true),\n     SNAPPY(SnappyCodec.class, CompressionKind.SNAPPY, CompressionCodecName.SNAPPY, f -> true),\n-    GZIP(GzipCodec.class, CompressionKind.ZLIB, CompressionCodecName.GZIP, f -> true),\n+    LZ4(null, CompressionKind.NONE, null, f -> f == PAGEFILE),", "originalCommit": "49d41f18d205ab4b4764b28f4dd6cccfe4ab7abc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM2ODU0NA==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r418368544", "bodyText": "Why do we need another compression? ZSTD with lower levels should be able to achieve comparable speed with much better compression.", "author": "jainxrohit", "createdAt": "2020-05-01T00:54:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI2NDY0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM3MTAzOQ==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r418371039", "bodyText": "We use LZ4 for shuffle. Because we care performance more rather than storage saving. The temp tables are short-living.", "author": "highker", "createdAt": "2020-05-01T01:04:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI2NDY0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM3MjI0MA==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r418372240", "bodyText": "How about not using any compression?", "author": "jainxrohit", "createdAt": "2020-05-01T01:09:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI2NDY0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM3MzQyMQ==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r418373421", "bodyText": "That is also considered in our exchange client buffer; if after compression we find the size is larger than the original bytes, we will send the original bytes. The flag is located in the header of a serialized page. Check PagesSerde.", "author": "highker", "createdAt": "2020-05-01T01:15:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI2NDY0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM5MzIyMA==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r418393220", "bodyText": "We use LZ4 for shuffle. Because we care performance more rather than storage saving. The temp tables are short-living.\n\nRight, that's why I added LZ4 option. I am thinking about adding ZSTD too, but I haven't done any benchmark on real queries yet. In my impression, SNAPPY and LZ4 are faster.", "author": "viczhang861", "createdAt": "2020-05-01T02:47:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI2NDY0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODQwNjMzMQ==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r418406331", "bodyText": "SNAPPY and LZ4 are indeed faster for text data. But I think with the combination of no compression + ZSTD level 1 should be good enough. Needs to be experimented for our data.", "author": "jainxrohit", "createdAt": "2020-05-01T03:58:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI2NDY0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTUzMDc5MA==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r419530790", "bodyText": "SNAPPY and LZ4 are faster, but provide lower level of compression. My question is why do we need both, LZ4 and SNAPPY? SNAPPY and LZ4 are very similar characteristics wise. I wonder if it makes sense to leave only SNAPPY for now, as it already exist and supported by all storage formats.", "author": "arhimondr", "createdAt": "2020-05-04T15:40:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI2NDY0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI2NjgwNw==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r418266807", "bodyText": "#size could be called before writeData . The size should be pre-computed", "author": "arhimondr", "createdAt": "2020-04-30T20:23:05Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/pagefile/PageFileFooterOutput.java", "diffHunk": "@@ -13,45 +13,67 @@\n  */\n package com.facebook.presto.hive.pagefile;\n \n+import com.facebook.presto.hive.HiveCompressionCodec;\n import com.facebook.presto.orc.stream.DataOutput;\n import com.google.common.collect.ImmutableList;\n+import io.airlift.slice.Slice;\n import io.airlift.slice.SliceOutput;\n \n import java.util.List;\n \n import static io.airlift.slice.SizeOf.SIZE_OF_INT;\n import static io.airlift.slice.SizeOf.SIZE_OF_LONG;\n+import static io.airlift.slice.Slices.utf8Slice;\n import static java.lang.Math.toIntExact;\n import static java.util.Objects.requireNonNull;\n \n public class PageFileFooterOutput\n         implements DataOutput\n {\n     public static final int FOOTER_LENGTH_IN_BYTES = SIZE_OF_INT;\n+\n     private final List<Long> stripeOffsets;\n+    private final HiveCompressionCodec compressionCodec;\n+    private long size;\n \n-    public PageFileFooterOutput(List<Long> stripeOffsets)\n+    public PageFileFooterOutput(List<Long> stripeOffsets, HiveCompressionCodec compressionCodec)\n     {\n         this.stripeOffsets = ImmutableList.copyOf(requireNonNull(stripeOffsets, \"stripeOffsets is null\"));\n+        this.compressionCodec = requireNonNull(compressionCodec, \"compressionCodec is null\");\n     }\n \n     @Override\n     public long size()\n     {\n-        return SIZE_OF_LONG * stripeOffsets.size() + FOOTER_LENGTH_IN_BYTES;\n+        return size;", "originalCommit": "49d41f18d205ab4b4764b28f4dd6cccfe4ab7abc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI2NzA5Ng==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r418267096", "bodyText": "Writing a string here makes it harder to pre-compute the footer size. What do you think about writing an integer instead of a string?", "author": "arhimondr", "createdAt": "2020-04-30T20:23:40Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/pagefile/PageFileFooterOutput.java", "diffHunk": "@@ -13,45 +13,67 @@\n  */\n package com.facebook.presto.hive.pagefile;\n \n+import com.facebook.presto.hive.HiveCompressionCodec;\n import com.facebook.presto.orc.stream.DataOutput;\n import com.google.common.collect.ImmutableList;\n+import io.airlift.slice.Slice;\n import io.airlift.slice.SliceOutput;\n \n import java.util.List;\n \n import static io.airlift.slice.SizeOf.SIZE_OF_INT;\n import static io.airlift.slice.SizeOf.SIZE_OF_LONG;\n+import static io.airlift.slice.Slices.utf8Slice;\n import static java.lang.Math.toIntExact;\n import static java.util.Objects.requireNonNull;\n \n public class PageFileFooterOutput\n         implements DataOutput\n {\n     public static final int FOOTER_LENGTH_IN_BYTES = SIZE_OF_INT;\n+\n     private final List<Long> stripeOffsets;\n+    private final HiveCompressionCodec compressionCodec;\n+    private long size;\n \n-    public PageFileFooterOutput(List<Long> stripeOffsets)\n+    public PageFileFooterOutput(List<Long> stripeOffsets, HiveCompressionCodec compressionCodec)\n     {\n         this.stripeOffsets = ImmutableList.copyOf(requireNonNull(stripeOffsets, \"stripeOffsets is null\"));\n+        this.compressionCodec = requireNonNull(compressionCodec, \"compressionCodec is null\");\n     }\n \n     @Override\n     public long size()\n     {\n-        return SIZE_OF_LONG * stripeOffsets.size() + FOOTER_LENGTH_IN_BYTES;\n+        return size;\n     }\n \n     @Override\n     public void writeData(SliceOutput sliceOutput)\n     {\n-        for (long offset : stripeOffsets) {\n-            sliceOutput.writeLong(offset);\n+        if (!stripeOffsets.isEmpty()) {\n+            // write compression information\n+            Slice compressionSlice = utf8Slice(compressionCodec.name());\n+            sliceOutput.writeInt(compressionSlice.length());\n+            size += SIZE_OF_INT;\n+            sliceOutput.writeBytes(compressionSlice);", "originalCommit": "49d41f18d205ab4b4764b28f4dd6cccfe4ab7abc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTQ4NzI4MA==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r419487280", "bodyText": "Code is refactored to precompute size.\nJust in case page formate could be a permanent storage in the future,  having a string name makes it self-explanatory and backward compatible if new enum name is added into HiveCompressionCodec", "author": "viczhang861", "createdAt": "2020-05-04T14:39:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI2NzA5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI2OTU2NQ==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r418269565", "bodyText": "Let's move it to the ConfigurationUtils.", "author": "arhimondr", "createdAt": "2020-04-30T20:28:25Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/pagefile/PageFileWriter.java", "diffHunk": "@@ -32,19 +33,21 @@\n public class PageFileWriter\n         implements HiveFileWriter\n {\n+    public static final String PAGE_FILE_COMPRESS = \"pagefile.output.compress\";", "originalCommit": "49d41f18d205ab4b4764b28f4dd6cccfe4ab7abc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI2OTcyMA==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r418269720", "bodyText": "Also maybe PAGE_FILE_COMPRESSION = \"pagefile.output.compression\"?", "author": "arhimondr", "createdAt": "2020-04-30T20:28:47Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/pagefile/PageFileWriter.java", "diffHunk": "@@ -32,19 +33,21 @@\n public class PageFileWriter\n         implements HiveFileWriter\n {\n+    public static final String PAGE_FILE_COMPRESS = \"pagefile.output.compress\";", "originalCommit": "49d41f18d205ab4b4764b28f4dd6cccfe4ab7abc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI3MjM1Mg==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r418272352", "bodyText": "For this class I would simply inline the HiveCompressionCodec.valueOf(compression). Incorrect compression set in the configuration is a programming error. Simple IllegalArgumentException thrown by the valueOf should be fine.\nIt has to be handled more carefully when reading the file, and decoding the compression stored in the footer. But in that case the exception should be EXTERNAL, and not INTERNAL.", "author": "arhimondr", "createdAt": "2020-04-30T20:33:42Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/pagefile/PageFileWriterFactory.java", "diffHunk": "@@ -104,6 +113,47 @@ public static void createEmptyPageFile(\n         }\n     }\n \n+    public static HiveCompressionCodec getCompressionCodec(String compression)", "originalCommit": "49d41f18d205ab4b4764b28f4dd6cccfe4ab7abc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "7ac51d34ca169eb63212f6fbcf75066d89ef2406", "url": "https://github.com/prestodb/presto/commit/7ac51d34ca169eb63212f6fbcf75066d89ef2406", "message": "Add adapters for PageCompressor and PageDecompressor", "committedDate": "2020-04-30T22:42:48Z", "type": "commit"}, {"oid": "fc8af192592bde5f6abecf5a8d9f1943b16726a5", "url": "https://github.com/prestodb/presto/commit/fc8af192592bde5f6abecf5a8d9f1943b16726a5", "message": "Add PageFile compression in HiveFileFormatBenchmark", "committedDate": "2020-05-02T01:11:42Z", "type": "forcePushed"}, {"oid": "0be185e22c65b399d73137ccc8802956aeef0a15", "url": "https://github.com/prestodb/presto/commit/0be185e22c65b399d73137ccc8802956aeef0a15", "message": "Support page compression in PageFileWriter", "committedDate": "2020-05-02T05:19:29Z", "type": "commit"}, {"oid": "d2950f2856a9b8d1760333bf89c3bd80cffbf01a", "url": "https://github.com/prestodb/presto/commit/d2950f2856a9b8d1760333bf89c3bd80cffbf01a", "message": "Add LZ4 compression in HiveCompressionCodec\n\nLz4 compression is only used for PageFile format.", "committedDate": "2020-05-02T05:19:38Z", "type": "commit"}, {"oid": "6bf8bedf02869f5f41c2d3114d7a4133a314cf40", "url": "https://github.com/prestodb/presto/commit/6bf8bedf02869f5f41c2d3114d7a4133a314cf40", "message": "Add PageFile compression in HiveFileFormatBenchmark", "committedDate": "2020-05-02T05:21:41Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTUzMjk3Nw==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r419532977", "bodyText": "Why do we need a special exception? Why not simply PrestoException?", "author": "arhimondr", "createdAt": "2020-05-04T15:43:20Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/pagefile/PageFileCorruptionException.java", "diffHunk": "@@ -0,0 +1,32 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.pagefile;\n+\n+import java.io.IOException;\n+\n+import static java.lang.String.format;\n+\n+public class PageFileCorruptionException", "originalCommit": "6bf8bedf02869f5f41c2d3114d7a4133a314cf40", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTY3NDc3MQ==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r419674771", "bodyText": "Similar as RcFileCorruptionException to make it clear,  do you prefer to throw HIVE_BAD_DATA error directly?", "author": "viczhang861", "createdAt": "2020-05-04T19:29:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTUzMjk3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTUzNDU0Nw==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r419534547", "bodyText": "else if (footerOffset > 0) { is not needed", "author": "arhimondr", "createdAt": "2020-05-04T15:45:31Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/pagefile/PageFileFooterReader.java", "diffHunk": "@@ -48,24 +54,46 @@ public PageFileFooterReader(\n         int footerSize = Slices.wrappedBuffer(buffer, buffer.length - FOOTER_LENGTH_IN_BYTES, FOOTER_LENGTH_IN_BYTES).getInt(0);\n \n         footerOffset = fileSize - footerSize;\n+        HiveCompressionCodec compression;\n         if (footerOffset < 0) {\n-            throw new IOException(\"Malformed PageFile format, incorrect footer length.\");\n+            throw new PageFileCorruptionException(\"Malformed PageFile format, incorrect footer length.\");\n         }\n         else if (footerOffset > 0) {", "originalCommit": "6bf8bedf02869f5f41c2d3114d7a4133a314cf40", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTYxODg0MQ==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r419618841", "bodyText": "else if (footerOffset > 0) { is not needed\n\nThis is needed because for empty file, ,footerOffset = 0", "author": "viczhang861", "createdAt": "2020-05-04T17:54:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTUzNDU0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTYzOTIxNw==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r419639217", "bodyText": "Oh, right. Nevermind then.", "author": "arhimondr", "createdAt": "2020-05-04T18:28:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTUzNDU0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTUzNjQyOA==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r419536428", "bodyText": "Why not to throw this exception directly?", "author": "arhimondr", "createdAt": "2020-05-04T15:48:14Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/pagefile/PageFilePageSourceFactory.java", "diffHunk": "@@ -93,7 +88,25 @@ public PageFilePageSourceFactory(\n             throw new PrestoException(HIVE_CANNOT_OPEN_SPLIT, splitError(e, path, start, length), e);\n         }\n \n-        return Optional.of(pageFilePageSource);\n+        try {\n+            PageFilePageSource pageFilePageSource = new PageFilePageSource(inputStream, start, length, fileSize, blockEncodingSerde, columns);\n+            return Optional.of(pageFilePageSource);\n+        }\n+        catch (Throwable e) {\n+            try {\n+                inputStream.close();\n+            }\n+            catch (IOException ignored) {\n+            }\n+            if (e instanceof PrestoException) {\n+                throw (PrestoException) e;\n+            }\n+            String message = splitError(e, path, start, length);\n+            if (e instanceof PageFileCorruptionException) {\n+                throw new PrestoException(HIVE_BAD_DATA, message, e);", "originalCommit": "6bf8bedf02869f5f41c2d3114d7a4133a314cf40", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTUzNzE1Mg==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r419537152", "bodyText": "IllegalArgumentException", "author": "arhimondr", "createdAt": "2020-05-04T15:49:18Z", "path": "presto-orc/src/main/java/com/facebook/presto/orc/zlib/DeflateCompressor.java", "diffHunk": "@@ -60,6 +60,30 @@ public int compress(byte[] input, int inputOffset, int inputLength, byte[] outpu\n     @Override\n     public void compress(ByteBuffer input, ByteBuffer output)\n     {\n-        throw new UnsupportedOperationException(\"Compression of byte buffer not supported for deflate\");\n+        if (input.isDirect() || output.isDirect()) {\n+            throw new UnsupportedOperationException(\"Compression of direct byte buffer not supported\");", "originalCommit": "6bf8bedf02869f5f41c2d3114d7a4133a314cf40", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTUzNzU2MA==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r419537560", "bodyText": "This branch is not needed", "author": "arhimondr", "createdAt": "2020-05-04T15:49:50Z", "path": "presto-orc/src/main/java/com/facebook/presto/orc/zlib/DeflateCompressor.java", "diffHunk": "@@ -60,6 +60,30 @@ public int compress(byte[] input, int inputOffset, int inputLength, byte[] outpu\n     @Override\n     public void compress(ByteBuffer input, ByteBuffer output)\n     {\n-        throw new UnsupportedOperationException(\"Compression of byte buffer not supported for deflate\");\n+        if (input.isDirect() || output.isDirect()) {\n+            throw new UnsupportedOperationException(\"Compression of direct byte buffer not supported\");\n+        }\n+        byte[] inputArray;\n+        int inputOffset;\n+        if (input.hasArray()) {\n+            inputArray = input.array();\n+            inputOffset = input.arrayOffset() + input.position();\n+        }\n+        else {", "originalCommit": "6bf8bedf02869f5f41c2d3114d7a4133a314cf40", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTUzNzkyOA==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r419537928", "bodyText": "this branch is not needed", "author": "arhimondr", "createdAt": "2020-05-04T15:50:25Z", "path": "presto-orc/src/main/java/com/facebook/presto/orc/zlib/DeflateCompressor.java", "diffHunk": "@@ -60,6 +60,30 @@ public int compress(byte[] input, int inputOffset, int inputLength, byte[] outpu\n     @Override\n     public void compress(ByteBuffer input, ByteBuffer output)\n     {\n-        throw new UnsupportedOperationException(\"Compression of byte buffer not supported for deflate\");\n+        if (input.isDirect() || output.isDirect()) {\n+            throw new UnsupportedOperationException(\"Compression of direct byte buffer not supported\");\n+        }\n+        byte[] inputArray;\n+        int inputOffset;\n+        if (input.hasArray()) {\n+            inputArray = input.array();\n+            inputOffset = input.arrayOffset() + input.position();\n+        }\n+        else {\n+            throw new IllegalArgumentException(\"Unsupported input ByteBuffer implementation \" + input.getClass().getName());\n+        }\n+\n+        byte[] outputArray;\n+        int outputOffset;\n+        if (output.hasArray()) {\n+            outputArray = output.array();\n+            outputOffset = output.arrayOffset() + output.position();\n+        }\n+        else {", "originalCommit": "6bf8bedf02869f5f41c2d3114d7a4133a314cf40", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTUzOTAxOA==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r419539018", "bodyText": "IllegalArgumentException?", "author": "arhimondr", "createdAt": "2020-05-04T15:51:57Z", "path": "presto-orc/src/main/java/com/facebook/presto/orc/zlib/InflateDecompressor.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.orc.zlib;\n+\n+import io.airlift.compress.Decompressor;\n+import io.airlift.compress.MalformedInputException;\n+\n+import java.nio.ByteBuffer;\n+import java.util.zip.DataFormatException;\n+import java.util.zip.Inflater;\n+\n+public class InflateDecompressor\n+        implements Decompressor\n+{\n+    @Override\n+    public int decompress(byte[] input, int inputOffset, int inputLength, byte[] output, int outputOffset, int maxOutputLength)\n+            throws MalformedInputException\n+    {\n+        Inflater inflater = new Inflater(true);\n+        inflater.setInput(input, inputOffset, inputLength);\n+        int uncompressedLength = 0;\n+        try {\n+            uncompressedLength = inflater.inflate(output, outputOffset, maxOutputLength);\n+            if (!inflater.finished()) {\n+                throw new IllegalStateException(\"maxCompressedLength formula is incorrect, because deflate produced more data\");", "originalCommit": "6bf8bedf02869f5f41c2d3114d7a4133a314cf40", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTUzOTIyNQ==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r419539225", "bodyText": "IllegalArgumentException", "author": "arhimondr", "createdAt": "2020-05-04T15:52:17Z", "path": "presto-orc/src/main/java/com/facebook/presto/orc/zlib/InflateDecompressor.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.orc.zlib;\n+\n+import io.airlift.compress.Decompressor;\n+import io.airlift.compress.MalformedInputException;\n+\n+import java.nio.ByteBuffer;\n+import java.util.zip.DataFormatException;\n+import java.util.zip.Inflater;\n+\n+public class InflateDecompressor\n+        implements Decompressor\n+{\n+    @Override\n+    public int decompress(byte[] input, int inputOffset, int inputLength, byte[] output, int outputOffset, int maxOutputLength)\n+            throws MalformedInputException\n+    {\n+        Inflater inflater = new Inflater(true);\n+        inflater.setInput(input, inputOffset, inputLength);\n+        int uncompressedLength = 0;\n+        try {\n+            uncompressedLength = inflater.inflate(output, outputOffset, maxOutputLength);\n+            if (!inflater.finished()) {\n+                throw new IllegalStateException(\"maxCompressedLength formula is incorrect, because deflate produced more data\");\n+            }\n+        }\n+        catch (DataFormatException e) {\n+            throw new MalformedInputException(inputOffset, e.getMessage());\n+        }\n+        finally {\n+            inflater.end();\n+        }\n+        return uncompressedLength;\n+    }\n+\n+    @Override\n+    public void decompress(ByteBuffer input, ByteBuffer output)\n+            throws MalformedInputException\n+    {\n+        if (input.isDirect() || output.isDirect()) {\n+            throw new UnsupportedOperationException(\"Decompression of direct byte buffer not supported\");", "originalCommit": "6bf8bedf02869f5f41c2d3114d7a4133a314cf40", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTUzOTMzOQ==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r419539339", "bodyText": "remove", "author": "arhimondr", "createdAt": "2020-05-04T15:52:28Z", "path": "presto-orc/src/main/java/com/facebook/presto/orc/zlib/InflateDecompressor.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.orc.zlib;\n+\n+import io.airlift.compress.Decompressor;\n+import io.airlift.compress.MalformedInputException;\n+\n+import java.nio.ByteBuffer;\n+import java.util.zip.DataFormatException;\n+import java.util.zip.Inflater;\n+\n+public class InflateDecompressor\n+        implements Decompressor\n+{\n+    @Override\n+    public int decompress(byte[] input, int inputOffset, int inputLength, byte[] output, int outputOffset, int maxOutputLength)\n+            throws MalformedInputException\n+    {\n+        Inflater inflater = new Inflater(true);\n+        inflater.setInput(input, inputOffset, inputLength);\n+        int uncompressedLength = 0;\n+        try {\n+            uncompressedLength = inflater.inflate(output, outputOffset, maxOutputLength);\n+            if (!inflater.finished()) {\n+                throw new IllegalStateException(\"maxCompressedLength formula is incorrect, because deflate produced more data\");\n+            }\n+        }\n+        catch (DataFormatException e) {\n+            throw new MalformedInputException(inputOffset, e.getMessage());\n+        }\n+        finally {\n+            inflater.end();\n+        }\n+        return uncompressedLength;\n+    }\n+\n+    @Override\n+    public void decompress(ByteBuffer input, ByteBuffer output)\n+            throws MalformedInputException\n+    {\n+        if (input.isDirect() || output.isDirect()) {\n+            throw new UnsupportedOperationException(\"Decompression of direct byte buffer not supported\");\n+        }\n+        byte[] inputArray;\n+        int inputOffset;\n+        if (input.hasArray()) {\n+            inputArray = input.array();\n+            inputOffset = input.arrayOffset() + input.position();\n+        }\n+        else {", "originalCommit": "6bf8bedf02869f5f41c2d3114d7a4133a314cf40", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTUzOTQ3OA==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r419539478", "bodyText": "remove", "author": "arhimondr", "createdAt": "2020-05-04T15:52:39Z", "path": "presto-orc/src/main/java/com/facebook/presto/orc/zlib/InflateDecompressor.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.orc.zlib;\n+\n+import io.airlift.compress.Decompressor;\n+import io.airlift.compress.MalformedInputException;\n+\n+import java.nio.ByteBuffer;\n+import java.util.zip.DataFormatException;\n+import java.util.zip.Inflater;\n+\n+public class InflateDecompressor\n+        implements Decompressor\n+{\n+    @Override\n+    public int decompress(byte[] input, int inputOffset, int inputLength, byte[] output, int outputOffset, int maxOutputLength)\n+            throws MalformedInputException\n+    {\n+        Inflater inflater = new Inflater(true);\n+        inflater.setInput(input, inputOffset, inputLength);\n+        int uncompressedLength = 0;\n+        try {\n+            uncompressedLength = inflater.inflate(output, outputOffset, maxOutputLength);\n+            if (!inflater.finished()) {\n+                throw new IllegalStateException(\"maxCompressedLength formula is incorrect, because deflate produced more data\");\n+            }\n+        }\n+        catch (DataFormatException e) {\n+            throw new MalformedInputException(inputOffset, e.getMessage());\n+        }\n+        finally {\n+            inflater.end();\n+        }\n+        return uncompressedLength;\n+    }\n+\n+    @Override\n+    public void decompress(ByteBuffer input, ByteBuffer output)\n+            throws MalformedInputException\n+    {\n+        if (input.isDirect() || output.isDirect()) {\n+            throw new UnsupportedOperationException(\"Decompression of direct byte buffer not supported\");\n+        }\n+        byte[] inputArray;\n+        int inputOffset;\n+        if (input.hasArray()) {\n+            inputArray = input.array();\n+            inputOffset = input.arrayOffset() + input.position();\n+        }\n+        else {\n+            throw new IllegalArgumentException(\"Unsupported input ByteBuffer implementation \" + input.getClass().getName());\n+        }\n+\n+        byte[] outputArray;\n+        int outputOffset;\n+        if (output.hasArray()) {\n+            outputArray = output.array();\n+            outputOffset = output.arrayOffset() + output.position();\n+        }\n+        else {", "originalCommit": "6bf8bedf02869f5f41c2d3114d7a4133a314cf40", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTUzOTc3Mw==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r419539773", "bodyText": "check for hasArray here", "author": "arhimondr", "createdAt": "2020-05-04T15:53:05Z", "path": "presto-orc/src/main/java/com/facebook/presto/orc/zlib/DeflateCompressor.java", "diffHunk": "@@ -60,6 +60,30 @@ public int compress(byte[] input, int inputOffset, int inputLength, byte[] outpu\n     @Override\n     public void compress(ByteBuffer input, ByteBuffer output)\n     {\n-        throw new UnsupportedOperationException(\"Compression of byte buffer not supported for deflate\");\n+        if (input.isDirect() || output.isDirect()) {", "originalCommit": "6bf8bedf02869f5f41c2d3114d7a4133a314cf40", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTUzOTk4MA==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r419539980", "bodyText": "check for hasArray here", "author": "arhimondr", "createdAt": "2020-05-04T15:53:21Z", "path": "presto-orc/src/main/java/com/facebook/presto/orc/zlib/InflateDecompressor.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.orc.zlib;\n+\n+import io.airlift.compress.Decompressor;\n+import io.airlift.compress.MalformedInputException;\n+\n+import java.nio.ByteBuffer;\n+import java.util.zip.DataFormatException;\n+import java.util.zip.Inflater;\n+\n+public class InflateDecompressor\n+        implements Decompressor\n+{\n+    @Override\n+    public int decompress(byte[] input, int inputOffset, int inputLength, byte[] output, int outputOffset, int maxOutputLength)\n+            throws MalformedInputException\n+    {\n+        Inflater inflater = new Inflater(true);\n+        inflater.setInput(input, inputOffset, inputLength);\n+        int uncompressedLength = 0;\n+        try {\n+            uncompressedLength = inflater.inflate(output, outputOffset, maxOutputLength);\n+            if (!inflater.finished()) {\n+                throw new IllegalStateException(\"maxCompressedLength formula is incorrect, because deflate produced more data\");\n+            }\n+        }\n+        catch (DataFormatException e) {\n+            throw new MalformedInputException(inputOffset, e.getMessage());\n+        }\n+        finally {\n+            inflater.end();\n+        }\n+        return uncompressedLength;\n+    }\n+\n+    @Override\n+    public void decompress(ByteBuffer input, ByteBuffer output)\n+            throws MalformedInputException\n+    {\n+        if (input.isDirect() || output.isDirect()) {", "originalCommit": "6bf8bedf02869f5f41c2d3114d7a4133a314cf40", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "bfb29ff0a722a1033f57c92c7d4c12b6f9805f18", "url": "https://github.com/prestodb/presto/commit/bfb29ff0a722a1033f57c92c7d4c12b6f9805f18", "message": "Add PageFile compression in HiveFileFormatBenchmark", "committedDate": "2020-05-04T20:09:04Z", "type": "forcePushed"}, {"oid": "954903a9efd38328bb3a7d320a5ed7d97aa8aba2", "url": "https://github.com/prestodb/presto/commit/954903a9efd38328bb3a7d320a5ed7d97aa8aba2", "message": "Implement Decompressor using zlib\n\nTo support GZIP HiveCompressionCodec for PageFile.", "committedDate": "2020-05-05T01:19:20Z", "type": "commit"}, {"oid": "95d530bfd95513115864f0b7d988bd11d0536841", "url": "https://github.com/prestodb/presto/commit/95d530bfd95513115864f0b7d988bd11d0536841", "message": "Add compression information in PageFile footer", "committedDate": "2020-05-05T01:19:27Z", "type": "commit"}, {"oid": "222f79cf5314ea7152cde7abecfac752dd792df8", "url": "https://github.com/prestodb/presto/commit/222f79cf5314ea7152cde7abecfac752dd792df8", "message": "Add PageFile compression in HiveFileFormatBenchmark", "committedDate": "2020-05-05T01:19:27Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDE2MjY0Mg==", "url": "https://github.com/prestodb/presto/pull/14461#discussion_r420162642", "bodyText": "propagateIfPossible", "author": "arhimondr", "createdAt": "2020-05-05T14:40:48Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/pagefile/PageFilePageSourceFactory.java", "diffHunk": "@@ -93,7 +87,21 @@ public PageFilePageSourceFactory(\n             throw new PrestoException(HIVE_CANNOT_OPEN_SPLIT, splitError(e, path, start, length), e);\n         }\n \n-        return Optional.of(pageFilePageSource);\n+        try {\n+            PageFilePageSource pageFilePageSource = new PageFilePageSource(inputStream, start, length, fileSize, blockEncodingSerde, columns);\n+            return Optional.of(pageFilePageSource);\n+        }\n+        catch (Throwable e) {\n+            try {\n+                inputStream.close();\n+            }\n+            catch (IOException ignored) {\n+            }\n+            if (e instanceof PrestoException) {", "originalCommit": "222f79cf5314ea7152cde7abecfac752dd792df8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "5b47518a20b7b78423ba4b36a5d9fb69fb11441c", "url": "https://github.com/prestodb/presto/commit/5b47518a20b7b78423ba4b36a5d9fb69fb11441c", "message": "Support reading compressed PageFile format", "committedDate": "2020-05-05T15:40:56Z", "type": "commit"}, {"oid": "b3538011ee9f26970dfc96db065f23d841d4a27f", "url": "https://github.com/prestodb/presto/commit/b3538011ee9f26970dfc96db065f23d841d4a27f", "message": "Add PageFile compression in HiveFileFormatBenchmark", "committedDate": "2020-05-05T15:41:01Z", "type": "commit"}, {"oid": "b3538011ee9f26970dfc96db065f23d841d4a27f", "url": "https://github.com/prestodb/presto/commit/b3538011ee9f26970dfc96db065f23d841d4a27f", "message": "Add PageFile compression in HiveFileFormatBenchmark", "committedDate": "2020-05-05T15:41:01Z", "type": "forcePushed"}]}