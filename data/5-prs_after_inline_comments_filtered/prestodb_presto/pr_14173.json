{"pr_number": 14173, "pr_title": "Optimize initial batch size for scan", "pr_createdAt": "2020-02-27T08:44:04Z", "pr_url": "https://github.com/prestodb/presto/pull/14173", "timeline": [{"oid": "89c6e85e2456df944a89671d064365392440d66a", "url": "https://github.com/prestodb/presto/commit/89c6e85e2456df944a89671d064365392440d66a", "message": "Optimize initial batch size for scan\n\nWhen all columns are of fixed width types, we can accurately estimate the\nsize of each row and calculate maximum number of rows that fit under\nhive.orc.max-read-block-size. This allows scan to produce full size pages\nfrom the start and avoids inefficiencies associated with processing small\npages.", "committedDate": "2020-02-27T08:44:22Z", "type": "forcePushed"}, {"oid": "6652e62df958ed175ef733011c1048381d06a6ee", "url": "https://github.com/prestodb/presto/commit/6652e62df958ed175ef733011c1048381d06a6ee", "message": "Optimize initial batch size for scan\n\nWhen all columns are of fixed width types, we can accurately estimate the\nsize of each row and calculate maximum number of rows that fit under\nhive.orc.max-read-block-size. This allows scan to produce full size pages\nfrom the start and avoids inefficiencies associated with processing small\npages.", "committedDate": "2020-02-27T14:59:11Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTg5MTg2Nw==", "url": "https://github.com/prestodb/presto/pull/14173#discussion_r389891867", "bodyText": "Shall we add a new static helper for protected void adjustMaxBatchSize(long averageRowBytes) so we can reuse the code?", "author": "highker", "createdAt": "2020-03-09T18:49:20Z", "path": "presto-orc/src/main/java/com/facebook/presto/orc/AbstractOrcRecordReader.java", "diffHunk": "@@ -237,7 +247,17 @@ public AbstractOrcRecordReader(\n \n         maxBytesPerCell = new long[streamReaders.length];\n \n-        nextBatchSize = initialBatchSize;\n+        if (onlyFixedWidthColumns) {\n+            if (totalFixedWidth == 0) {\n+                nextBatchSize = MAX_BATCH_SIZE;\n+            }\n+            else {\n+                nextBatchSize = toIntExact(min(MAX_BATCH_SIZE, max(1, maxBlockBytes / totalFixedWidth)));", "originalCommit": "6652e62df958ed175ef733011c1048381d06a6ee", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTg5NTE1Mg==", "url": "https://github.com/prestodb/presto/pull/14173#discussion_r389895152", "bodyText": "Shall we move this logic out of this loop and move it closer to where it is used? Given it's in the constructor, having two for loops shouldn't be a performance concern. It will be clearer to separate the logic. Or, it could be even better to move the logic into another help like adjustMaxBatchSizeBasedOnTypes (something like this name).", "author": "highker", "createdAt": "2020-03-09T18:55:23Z", "path": "presto-orc/src/main/java/com/facebook/presto/orc/AbstractOrcRecordReader.java", "diffHunk": "@@ -154,14 +155,23 @@ public AbstractOrcRecordReader(\n \n         // reduce the included columns to the set that is also present\n         ImmutableSet.Builder<Integer> presentColumns = ImmutableSet.builder();\n-        ImmutableMap.Builder<Integer, Type> presentColumnsAndTypes = ImmutableMap.builder();\n         OrcType root = types.get(0);\n+        boolean onlyFixedWidthColumns = true;\n+        int totalFixedWidth = 0;\n         for (Map.Entry<Integer, Type> entry : includedColumns.entrySet()) {\n             // an old file can have less columns since columns can be added\n             // after the file was written\n             if (entry.getKey() >= 0 && entry.getKey() < root.getFieldCount()) {\n                 presentColumns.add(entry.getKey());\n-                presentColumnsAndTypes.put(entry.getKey(), entry.getValue());\n+\n+                Type type = entry.getValue();", "originalCommit": "6652e62df958ed175ef733011c1048381d06a6ee", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "712a3bee5913b8c4ab403afc22877f143fad813b", "url": "https://github.com/prestodb/presto/commit/712a3bee5913b8c4ab403afc22877f143fad813b", "message": "Optimize initial batch size for scan\n\nWhen all columns are of fixed width types, we can accurately estimate the\nsize of each row and calculate maximum number of rows that fit under\nhive.orc.max-read-block-size. This allows scan to produce full size pages\nfrom the start and avoids inefficiencies associated with processing small\npages.", "committedDate": "2020-03-10T10:54:20Z", "type": "commit"}, {"oid": "712a3bee5913b8c4ab403afc22877f143fad813b", "url": "https://github.com/prestodb/presto/commit/712a3bee5913b8c4ab403afc22877f143fad813b", "message": "Optimize initial batch size for scan\n\nWhen all columns are of fixed width types, we can accurately estimate the\nsize of each row and calculate maximum number of rows that fit under\nhive.orc.max-read-block-size. This allows scan to produce full size pages\nfrom the start and avoids inefficiencies associated with processing small\npages.", "committedDate": "2020-03-10T10:54:20Z", "type": "forcePushed"}]}