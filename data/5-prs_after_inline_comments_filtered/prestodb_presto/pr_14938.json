{"pr_number": 14938, "pr_title": "Collect shuffle statistics in Presto on Spark", "pr_createdAt": "2020-07-31T04:02:37Z", "pr_url": "https://github.com/prestodb/presto/pull/14938", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzc5NzYyNw==", "url": "https://github.com/prestodb/presto/pull/14938#discussion_r463797627", "bodyText": "Why break here? Is it supposed to process next element in List ?", "author": "viczhang861", "createdAt": "2020-07-31T19:40:58Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkShufflePageInput.java", "diffHunk": "@@ -0,0 +1,178 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.common.Page;\n+import com.facebook.presto.common.PageBuilder;\n+import com.facebook.presto.common.block.BlockBuilder;\n+import com.facebook.presto.common.type.Type;\n+import com.facebook.presto.spark.classloader_interface.MutablePartitionId;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkMutableRow;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkShuffleStats;\n+import com.google.common.collect.ImmutableList;\n+import io.airlift.slice.BasicSliceInput;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.SliceOutput;\n+import org.apache.spark.util.CollectionAccumulator;\n+import scala.Tuple2;\n+import scala.collection.Iterator;\n+\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+\n+import static com.facebook.presto.spark.classloader_interface.PrestoSparkShuffleStats.Operation.READ;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkShufflePageInput\n+        implements PrestoSparkPageInput\n+{\n+    private static final int TARGET_SIZE = 1024 * 1024;\n+    private static final int BUFFER_SIZE = (int) (TARGET_SIZE * 1.2f);\n+    private static final int MAX_ROWS_PER_PAGE = 20_000;\n+\n+    private final List<Type> types;\n+    private final List<PrestoSparkShuffleInput> shuffleInputs;\n+    private final int taskId;\n+    private final CollectionAccumulator<PrestoSparkShuffleStats> shuffleStatsCollector;\n+\n+    @GuardedBy(\"this\")\n+    private int currentIteratorIndex;\n+    @GuardedBy(\"this\")\n+    private final Stats stats = new Stats();\n+\n+    public PrestoSparkShufflePageInput(\n+            List<Type> types,\n+            List<PrestoSparkShuffleInput> shuffleInputs,\n+            int taskId,\n+            CollectionAccumulator<PrestoSparkShuffleStats> shuffleStatsCollector)\n+    {\n+        this.types = ImmutableList.copyOf(requireNonNull(types, \"types is null\"));\n+        this.shuffleInputs = ImmutableList.copyOf(requireNonNull(shuffleInputs, \"shuffleInputs is null\"));\n+        this.taskId = taskId;\n+        this.shuffleStatsCollector = requireNonNull(shuffleStatsCollector, \"shuffleStatsCollector is null\");\n+    }\n+\n+    @Override\n+    public Page getNextPage()\n+    {\n+        SliceOutput output = new DynamicSliceOutput(types.isEmpty() ? 0 : BUFFER_SIZE);\n+        int rowCount = 0;\n+        synchronized (this) {\n+            while (currentIteratorIndex < shuffleInputs.size()) {\n+                PrestoSparkShuffleInput input = shuffleInputs.get(currentIteratorIndex);\n+                Iterator<Tuple2<MutablePartitionId, PrestoSparkMutableRow>> iterator = input.getIterator();\n+                long processedBytes = 0;\n+                long start = System.currentTimeMillis();\n+                while (iterator.hasNext() && output.size() <= TARGET_SIZE && rowCount <= MAX_ROWS_PER_PAGE) {\n+                    PrestoSparkMutableRow row = iterator.next()._2;\n+                    if (row.getBuffer() != null) {\n+                        ByteBuffer buffer = row.getBuffer();\n+                        output.writeBytes(buffer.array(), buffer.arrayOffset() + buffer.position(), buffer.remaining());\n+                        processedBytes += buffer.remaining();\n+                    }\n+                    else if (row.getArray() != null) {\n+                        output.writeBytes(row.getArray(), row.getOffset(), row.getLength());\n+                        processedBytes += row.getLength();\n+                    }\n+                    else {\n+                        throw new IllegalArgumentException(\"Unexpected PrestoSparkMutableRow: 'buffer' and 'array' fields are both null\");\n+                    }\n+                    rowCount++;\n+                }\n+                long end = System.currentTimeMillis();\n+                stats.accumulate(rowCount, processedBytes, end - start);\n+                if (!iterator.hasNext()) {\n+                    PrestoSparkShuffleStats shuffleStats = new PrestoSparkShuffleStats(\n+                            input.getFragmentId(),\n+                            taskId,\n+                            READ,\n+                            stats.getProcessedRows(),\n+                            stats.getProcessedBytes(),\n+                            stats.getElapsedWallTimeMills());\n+                    shuffleStatsCollector.add(shuffleStats);\n+                    stats.reset();\n+                    currentIteratorIndex++;\n+                }\n+                else {", "originalCommit": "30e34cb69e102a1d4f335222c4044a1113b25c6e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTg3MzgwMw==", "url": "https://github.com/prestodb/presto/pull/14938#discussion_r465873803", "bodyText": "The condition of the upper loop (that reads the data) is: iterator.hasNext() && output.size() <= TARGET_SIZE && rowCount <= MAX_ROWS_PER_PAGE meaning \"keep reading data until the iterator is not empty and the threshold per page is not crossed\". If the upper loop finishes it means either of two conditions:\n\nThe current iterator has no more data\nThe buffer is full\n\nFor the first condition we transition to the second iterator. And while we do that - we log statistics for the first (there's 1 iterator per input fragment).\nFor the second condition we need to end the loop, as we've read the whole page.", "author": "arhimondr", "createdAt": "2020-08-05T17:03:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzc5NzYyNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzgwMjA4OQ==", "url": "https://github.com/prestodb/presto/pull/14938#discussion_r463802089", "bodyText": "Initialize to 0?", "author": "viczhang861", "createdAt": "2020-07-31T19:51:52Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java", "diffHunk": "@@ -775,6 +795,64 @@ private void queryCompletedEvent(Optional<ExecutionFailureInfo> failureInfo)\n             queryInfoOutputPath.ifPresent(path -> writeQueryInfo(path, queryInfo, queryInfoJsonCodec));\n         }\n \n+        private void processShuffleStats()\n+        {\n+            List<PrestoSparkShuffleStats> statsList = new ArrayList<>(shuffleStatsCollector.value());\n+            Map<ShuffleStatsKey, List<PrestoSparkShuffleStats>> statsMap = new HashMap<>();\n+            Set<Integer> fragments = new HashSet<>();\n+            for (PrestoSparkShuffleStats stats : statsList) {\n+                ShuffleStatsKey key = new ShuffleStatsKey(stats.getFragmentId(), stats.getOperation());\n+                statsMap.computeIfAbsent(key, (ignored) -> new ArrayList<>()).add(stats);\n+                fragments.add(stats.getFragmentId());\n+            }\n+            List<Integer> sortedFragments = new ArrayList<>(fragments);\n+            sortedFragments.sort(null);\n+            log.info(\"Shuffle statistics summary:\");\n+            for (Integer fragment : sortedFragments) {\n+                List<PrestoSparkShuffleStats> readStatistics = statsMap.get(new ShuffleStatsKey(fragment, READ));\n+                if (readStatistics != null) {\n+                    logShuffleStatsSummary(fragment, READ, readStatistics);\n+                }\n+                List<PrestoSparkShuffleStats> writeStatistics = statsMap.get(new ShuffleStatsKey(fragment, WRITE));\n+                if (writeStatistics != null) {\n+                    logShuffleStatsSummary(fragment, WRITE, writeStatistics);\n+                }\n+            }\n+        }\n+\n+        private void logShuffleStatsSummary(int fragmentId, Operation operation, List<PrestoSparkShuffleStats> statsList)\n+        {\n+            long totalProcessedRows = 0;\n+            long totalProcessedBytes = 0;\n+            long totalElapsedWallTimeMills = 0;\n+            for (PrestoSparkShuffleStats stats : statsList) {\n+                totalProcessedRows += stats.getProcessedRows();\n+                totalProcessedBytes += stats.getProcessedBytes();\n+                totalElapsedWallTimeMills += stats.getElapsedWallTimeMills();\n+            }\n+            long totalElapsedWallTimeSeconds = totalElapsedWallTimeMills / 1000;\n+            long rowsPerSecond = totalProcessedRows;", "originalCommit": "30e34cb69e102a1d4f335222c4044a1113b25c6e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTg3NDIwNw==", "url": "https://github.com/prestodb/presto/pull/14938#discussion_r465874207", "bodyText": "That's what I had initially. But if the elapsed time is below 1s the output will contain weird 0rows/s that is confusing. It is better to display <total_rows>rows/s in this case that I find less confusing.", "author": "arhimondr", "createdAt": "2020-08-05T17:04:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzgwMjA4OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzgwMjI3OQ==", "url": "https://github.com/prestodb/presto/pull/14938#discussion_r463802279", "bodyText": "just like long averageRowSize = 0", "author": "viczhang861", "createdAt": "2020-07-31T19:52:26Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java", "diffHunk": "@@ -775,6 +795,64 @@ private void queryCompletedEvent(Optional<ExecutionFailureInfo> failureInfo)\n             queryInfoOutputPath.ifPresent(path -> writeQueryInfo(path, queryInfo, queryInfoJsonCodec));\n         }\n \n+        private void processShuffleStats()\n+        {\n+            List<PrestoSparkShuffleStats> statsList = new ArrayList<>(shuffleStatsCollector.value());\n+            Map<ShuffleStatsKey, List<PrestoSparkShuffleStats>> statsMap = new HashMap<>();\n+            Set<Integer> fragments = new HashSet<>();\n+            for (PrestoSparkShuffleStats stats : statsList) {\n+                ShuffleStatsKey key = new ShuffleStatsKey(stats.getFragmentId(), stats.getOperation());\n+                statsMap.computeIfAbsent(key, (ignored) -> new ArrayList<>()).add(stats);\n+                fragments.add(stats.getFragmentId());\n+            }\n+            List<Integer> sortedFragments = new ArrayList<>(fragments);\n+            sortedFragments.sort(null);\n+            log.info(\"Shuffle statistics summary:\");\n+            for (Integer fragment : sortedFragments) {\n+                List<PrestoSparkShuffleStats> readStatistics = statsMap.get(new ShuffleStatsKey(fragment, READ));\n+                if (readStatistics != null) {\n+                    logShuffleStatsSummary(fragment, READ, readStatistics);\n+                }\n+                List<PrestoSparkShuffleStats> writeStatistics = statsMap.get(new ShuffleStatsKey(fragment, WRITE));\n+                if (writeStatistics != null) {\n+                    logShuffleStatsSummary(fragment, WRITE, writeStatistics);\n+                }\n+            }\n+        }\n+\n+        private void logShuffleStatsSummary(int fragmentId, Operation operation, List<PrestoSparkShuffleStats> statsList)\n+        {\n+            long totalProcessedRows = 0;\n+            long totalProcessedBytes = 0;\n+            long totalElapsedWallTimeMills = 0;\n+            for (PrestoSparkShuffleStats stats : statsList) {\n+                totalProcessedRows += stats.getProcessedRows();\n+                totalProcessedBytes += stats.getProcessedBytes();\n+                totalElapsedWallTimeMills += stats.getElapsedWallTimeMills();\n+            }\n+            long totalElapsedWallTimeSeconds = totalElapsedWallTimeMills / 1000;\n+            long rowsPerSecond = totalProcessedRows;\n+            long bytesPerSecond = totalProcessedBytes;", "originalCommit": "30e34cb69e102a1d4f335222c4044a1113b25c6e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTg3NDI2OQ==", "url": "https://github.com/prestodb/presto/pull/14938#discussion_r465874269", "bodyText": "ditto", "author": "arhimondr", "createdAt": "2020-08-05T17:04:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzgwMjI3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzgwMjczOQ==", "url": "https://github.com/prestodb/presto/pull/14938#discussion_r463802739", "bodyText": "nit. %s rows/s Missing space?", "author": "viczhang861", "createdAt": "2020-07-31T19:53:30Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java", "diffHunk": "@@ -775,6 +795,64 @@ private void queryCompletedEvent(Optional<ExecutionFailureInfo> failureInfo)\n             queryInfoOutputPath.ifPresent(path -> writeQueryInfo(path, queryInfo, queryInfoJsonCodec));\n         }\n \n+        private void processShuffleStats()\n+        {\n+            List<PrestoSparkShuffleStats> statsList = new ArrayList<>(shuffleStatsCollector.value());\n+            Map<ShuffleStatsKey, List<PrestoSparkShuffleStats>> statsMap = new HashMap<>();\n+            Set<Integer> fragments = new HashSet<>();\n+            for (PrestoSparkShuffleStats stats : statsList) {\n+                ShuffleStatsKey key = new ShuffleStatsKey(stats.getFragmentId(), stats.getOperation());\n+                statsMap.computeIfAbsent(key, (ignored) -> new ArrayList<>()).add(stats);\n+                fragments.add(stats.getFragmentId());\n+            }\n+            List<Integer> sortedFragments = new ArrayList<>(fragments);\n+            sortedFragments.sort(null);\n+            log.info(\"Shuffle statistics summary:\");\n+            for (Integer fragment : sortedFragments) {\n+                List<PrestoSparkShuffleStats> readStatistics = statsMap.get(new ShuffleStatsKey(fragment, READ));\n+                if (readStatistics != null) {\n+                    logShuffleStatsSummary(fragment, READ, readStatistics);\n+                }\n+                List<PrestoSparkShuffleStats> writeStatistics = statsMap.get(new ShuffleStatsKey(fragment, WRITE));\n+                if (writeStatistics != null) {\n+                    logShuffleStatsSummary(fragment, WRITE, writeStatistics);\n+                }\n+            }\n+        }\n+\n+        private void logShuffleStatsSummary(int fragmentId, Operation operation, List<PrestoSparkShuffleStats> statsList)\n+        {\n+            long totalProcessedRows = 0;\n+            long totalProcessedBytes = 0;\n+            long totalElapsedWallTimeMills = 0;\n+            for (PrestoSparkShuffleStats stats : statsList) {\n+                totalProcessedRows += stats.getProcessedRows();\n+                totalProcessedBytes += stats.getProcessedBytes();\n+                totalElapsedWallTimeMills += stats.getElapsedWallTimeMills();\n+            }\n+            long totalElapsedWallTimeSeconds = totalElapsedWallTimeMills / 1000;\n+            long rowsPerSecond = totalProcessedRows;\n+            long bytesPerSecond = totalProcessedBytes;\n+            if (totalElapsedWallTimeSeconds > 0) {\n+                rowsPerSecond = totalProcessedRows / totalElapsedWallTimeSeconds;\n+                bytesPerSecond = totalProcessedBytes / totalElapsedWallTimeSeconds;\n+            }\n+            long averageRowSize = 0;\n+            if (totalProcessedRows > 0) {\n+                averageRowSize = totalProcessedBytes / totalProcessedRows;\n+            }\n+            log.info(\n+                    \"Fragment: %s, Operation: %s, Rows: %s, Size: %s, Avg Row Size: %s, Time: %s, %srows/s, %s/s\",", "originalCommit": "30e34cb69e102a1d4f335222c4044a1113b25c6e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTg3NDcxNg==", "url": "https://github.com/prestodb/presto/pull/14938#discussion_r465874716", "bodyText": "This is same as 60.55kB/s. We print it without a space. Same for rows/s -> 2000rows/s", "author": "arhimondr", "createdAt": "2020-08-05T17:04:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzgwMjczOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzgwMzE3MA==", "url": "https://github.com/prestodb/presto/pull/14938#discussion_r463803170", "bodyText": "I would prefer just operation.toString()", "author": "viczhang861", "createdAt": "2020-07-31T19:54:33Z", "path": "presto-spark-classloader-interface/src/main/java/com/facebook/presto/spark/classloader_interface/PrestoSparkShuffleStats.java", "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.classloader_interface;\n+\n+import java.io.Serializable;\n+\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+import static org.spark_project.guava.base.Preconditions.checkArgument;\n+\n+public class PrestoSparkShuffleStats\n+        implements Serializable\n+{\n+    private final int fragmentId;\n+    private final int taskId;\n+    private final Operation operation;\n+    private final long processedRows;\n+    private final long processedBytes;\n+    private final long elapsedWallTimeMills;\n+\n+    public PrestoSparkShuffleStats(\n+            int fragmentId,\n+            int taskId,\n+            Operation operation,\n+            long processedRows,\n+            long processedBytes,\n+            long elapsedWallTimeMills)\n+    {\n+        this.fragmentId = fragmentId;\n+        this.taskId = taskId;\n+        this.operation = requireNonNull(operation, \"operation is null\");\n+        checkArgument(processedRows >= 0, \"processedRows must be greater than or equal to zero: %s\", processedRows);\n+        this.processedRows = processedRows;\n+        checkArgument(processedBytes >= 0, \"processedBytes must be greater than or equal to zero: %s\", processedBytes);\n+        this.processedBytes = processedBytes;\n+        checkArgument(elapsedWallTimeMills >= 0, \"elapsedWallTimeMills must be greater than or equal to zero: %s\", elapsedWallTimeMills);\n+        this.elapsedWallTimeMills = elapsedWallTimeMills;\n+    }\n+\n+    public int getFragmentId()\n+    {\n+        return fragmentId;\n+    }\n+\n+    public int getTaskId()\n+    {\n+        return taskId;\n+    }\n+\n+    public Operation getOperation()\n+    {\n+        return operation;\n+    }\n+\n+    public long getProcessedRows()\n+    {\n+        return processedRows;\n+    }\n+\n+    public long getProcessedBytes()\n+    {\n+        return processedBytes;\n+    }\n+\n+    public long getElapsedWallTimeMills()\n+    {\n+        return elapsedWallTimeMills;\n+    }\n+\n+    public enum Operation\n+    {\n+        READ,\n+        WRITE\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+        // readable summary to be displayed at the Spark web interface\n+        return format(\n+                \"%s.%s:%s:%sM:%sMB:%smin\",\n+                fragmentId,\n+                taskId,\n+                operation.toString().charAt(0),", "originalCommit": "30e34cb69e102a1d4f335222c4044a1113b25c6e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzgyNDQ2NQ==", "url": "https://github.com/prestodb/presto/pull/14938#discussion_r463824465", "bodyText": "No worry, spark accumulator will list all taskIds up to thousands, it is better to keep it short.", "author": "viczhang861", "createdAt": "2020-07-31T20:38:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzgwMzE3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzkyNDIwOA==", "url": "https://github.com/prestodb/presto/pull/14938#discussion_r463924208", "bodyText": "curious why 20_000 will be better than 10_000 ? ;)", "author": "wenleix", "createdAt": "2020-08-01T05:12:43Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkMutableRowPageInput.java", "diffHunk": "@@ -39,7 +40,7 @@\n {\n     private static final int TARGET_SIZE = 1024 * 1024;\n     private static final int BUFFER_SIZE = (int) (TARGET_SIZE * 1.2f);\n-    private static final int MAX_ROWS_PER_ZERO_COLUMN_PAGE = 10_000;\n+    private static final int MAX_ROWS_PER_PAGE = 20_000;", "originalCommit": "01150a40b55d9b4fae67182e176bafcf0f7b8ec4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTg3ODAxMw==", "url": "https://github.com/prestodb/presto/pull/14938#discussion_r465878013", "bodyText": "I'm going to use if for both now, zero columns an non zero columns pages. 20_000 seem to be better (e.g.: for a single bigint column page the size will be ~160kb instead of 80kb). We usually try to keep the page size above 100kb.", "author": "arhimondr", "createdAt": "2020-08-05T17:10:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzkyNDIwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzkyNTIwMg==", "url": "https://github.com/prestodb/presto/pull/14938#discussion_r463925202", "bodyText": "Note this means when one remote source is consumed, we will return (instead of try to fill TARGET_SIZE or MAX_ROWS_PER_PAGE). Curious if there is any reason for this? :)\n(the code has the same semantic than before)", "author": "wenleix", "createdAt": "2020-08-01T05:24:56Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkMutableRowPageInput.java", "diffHunk": "@@ -108,23 +76,34 @@ else if (row.getArray() != null) {\n                     }\n                     rowCount++;\n                 }\n-                else {\n+                if (!iterator.hasNext()) {\n                     currentIteratorIndex++;\n                 }\n+                else {\n+                    break;", "originalCommit": "01150a40b55d9b4fae67182e176bafcf0f7b8ec4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDE0Nzk2Mg==", "url": "https://github.com/prestodb/presto/pull/14938#discussion_r464147962", "bodyText": "I see,  it will be easier to understand using\nif (output.size() > TARGET_SIZE || rowCount > MAX_ROWS_PER_PAGE) { break;} else { // stats update }", "author": "viczhang861", "createdAt": "2020-08-03T01:02:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzkyNTIwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTg3OTk4OA==", "url": "https://github.com/prestodb/presto/pull/14938#discussion_r465879988", "bodyText": "Explained it here:\n#14938 (comment)\n\nI see, it will be easier to understand using\n\nIf feels like this is about the same. In the first place we check if the iterator is done, so we need to start a new one. In the second we check if the buffer is full. I would prefer to keep it the current way.", "author": "arhimondr", "createdAt": "2020-08-05T17:14:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzkyNTIwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDE0MzgyNQ==", "url": "https://github.com/prestodb/presto/pull/14938#discussion_r464143825", "bodyText": "\ud83d\udc4d", "author": "wenleix", "createdAt": "2020-08-03T00:33:43Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRemoteSourceFactory.java", "diffHunk": "@@ -36,26 +34,26 @@\n         implements RemoteSourceFactory\n {\n     private final PagesSerde pagesSerde;\n-    private final Map<PlanNodeId, List<scala.collection.Iterator<Tuple2<MutablePartitionId, PrestoSparkMutableRow>>>> rowInputsMap;\n+    private final Map<PlanNodeId, List<PrestoSparkShuffleInput>> shuffleInputsMap;\n     private final Map<PlanNodeId, List<java.util.Iterator<PrestoSparkSerializedPage>>> pageInputsMap;\n \n     public PrestoSparkRemoteSourceFactory(\n             PagesSerde pagesSerde,\n-            Map<PlanNodeId, List<scala.collection.Iterator<Tuple2<MutablePartitionId, PrestoSparkMutableRow>>>> rowInputsMap,\n+            Map<PlanNodeId, List<PrestoSparkShuffleInput>> shuffleInputsMap,\n             Map<PlanNodeId, List<java.util.Iterator<PrestoSparkSerializedPage>>> pageInputsMap)\n     {\n         this.pagesSerde = requireNonNull(pagesSerde, \"pagesSerde is null\");\n-        this.rowInputsMap = requireNonNull(rowInputsMap, \"rowInputs is null\");\n-        this.pageInputsMap = requireNonNull(pageInputsMap, \"pageInputs is null\");\n+        this.shuffleInputsMap = ImmutableMap.copyOf(requireNonNull(shuffleInputsMap, \"shuffleInputsMap is null\"));", "originalCommit": "fa0cb41297ab1d85ab32ad7658698643bb1f4a5c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDE0NDI5NQ==", "url": "https://github.com/prestodb/presto/pull/14938#discussion_r464144295", "bodyText": "What about name the class name as ShuffleStats?", "author": "wenleix", "createdAt": "2020-08-03T00:36:39Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkShufflePageInput.java", "diffHunk": "@@ -43,15 +46,25 @@\n     private static final int MAX_ROWS_PER_PAGE = 20_000;\n \n     private final List<Type> types;\n-    @GuardedBy(\"this\")\n     private final List<PrestoSparkShuffleInput> shuffleInputs;\n+    private final int taskId;\n+    private final CollectionAccumulator<PrestoSparkShuffleStats> shuffleStatsCollector;\n+\n     @GuardedBy(\"this\")\n     private int currentIteratorIndex;\n+    @GuardedBy(\"this\")\n+    private final Stats stats = new Stats();", "originalCommit": "30e34cb69e102a1d4f335222c4044a1113b25c6e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDE0NDcwNw==", "url": "https://github.com/prestodb/presto/pull/14938#discussion_r464144707", "bodyText": "Curious why return buffer.remaining() (as compared with buffer.size()?  Will buffer.remaining() change during object lifetime? Maybe add a comment ?", "author": "wenleix", "createdAt": "2020-08-03T00:39:33Z", "path": "presto-spark-classloader-interface/src/main/java/com/facebook/presto/spark/classloader_interface/PrestoSparkMutableRow.java", "diffHunk": "@@ -109,4 +111,17 @@ private static RuntimeException serializationNotSupportedException()\n         // During shuffle rows are always serialized with PrestoSparkShuffleSerializer.\n         return new UnsupportedOperationException(\"PrestoSparkUnsafeRow is not expected to be serialized with Kryo or standard Java serialization\");\n     }\n+\n+    @Override\n+    public long getRowCount()\n+    {\n+        return 1;\n+    }\n+\n+    @Override\n+    public long getSize()\n+    {\n+        checkState(buffer != null, \"buffer is expected to be not null\");\n+        return buffer.remaining();", "originalCommit": "30e34cb69e102a1d4f335222c4044a1113b25c6e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTg4MDc2Ng==", "url": "https://github.com/prestodb/presto/pull/14938#discussion_r465880766", "bodyText": "Yes. Basically we change the pointers as we advance the iterator, but we don't change the buffer itself. The entire buffer contains many rows (~1mb).", "author": "arhimondr", "createdAt": "2020-08-05T17:15:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDE0NDcwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDE0NTAxNg==", "url": "https://github.com/prestodb/presto/pull/14938#discussion_r464145016", "bodyText": "for \"%sM\", how many digits will be there ? What about something like \"%.1fM:%.1MB\" (or %.2M..)", "author": "wenleix", "createdAt": "2020-08-03T00:41:58Z", "path": "presto-spark-classloader-interface/src/main/java/com/facebook/presto/spark/classloader_interface/PrestoSparkShuffleStats.java", "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.classloader_interface;\n+\n+import java.io.Serializable;\n+\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+import static org.spark_project.guava.base.Preconditions.checkArgument;\n+\n+public class PrestoSparkShuffleStats\n+        implements Serializable\n+{\n+    private final int fragmentId;\n+    private final int taskId;\n+    private final Operation operation;\n+    private final long processedRows;\n+    private final long processedBytes;\n+    private final long elapsedWallTimeMills;\n+\n+    public PrestoSparkShuffleStats(\n+            int fragmentId,\n+            int taskId,\n+            Operation operation,\n+            long processedRows,\n+            long processedBytes,\n+            long elapsedWallTimeMills)\n+    {\n+        this.fragmentId = fragmentId;\n+        this.taskId = taskId;\n+        this.operation = requireNonNull(operation, \"operation is null\");\n+        checkArgument(processedRows >= 0, \"processedRows must be greater than or equal to zero: %s\", processedRows);\n+        this.processedRows = processedRows;\n+        checkArgument(processedBytes >= 0, \"processedBytes must be greater than or equal to zero: %s\", processedBytes);\n+        this.processedBytes = processedBytes;\n+        checkArgument(elapsedWallTimeMills >= 0, \"elapsedWallTimeMills must be greater than or equal to zero: %s\", elapsedWallTimeMills);\n+        this.elapsedWallTimeMills = elapsedWallTimeMills;\n+    }\n+\n+    public int getFragmentId()\n+    {\n+        return fragmentId;\n+    }\n+\n+    public int getTaskId()\n+    {\n+        return taskId;\n+    }\n+\n+    public Operation getOperation()\n+    {\n+        return operation;\n+    }\n+\n+    public long getProcessedRows()\n+    {\n+        return processedRows;\n+    }\n+\n+    public long getProcessedBytes()\n+    {\n+        return processedBytes;\n+    }\n+\n+    public long getElapsedWallTimeMills()\n+    {\n+        return elapsedWallTimeMills;\n+    }\n+\n+    public enum Operation\n+    {\n+        READ,\n+        WRITE\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+        // readable summary to be displayed at the Spark web interface\n+        return format(\n+                \"%s.%s:%s:%sM:%sMB:%smin\",", "originalCommit": "30e34cb69e102a1d4f335222c4044a1113b25c6e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTg4MTA0NQ==", "url": "https://github.com/prestodb/presto/pull/14938#discussion_r465881045", "bodyText": "This is just for megabytes. It is not a special formatting marker.", "author": "arhimondr", "createdAt": "2020-08-05T17:15:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDE0NTAxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDE0NTY2Ng==", "url": "https://github.com/prestodb/presto/pull/14938#discussion_r464145666", "bodyText": "so essentially we will also aggregate over all the shuffle stats on driver and print it out :). Do we need to display ShuffleStats on Spark Web UI as well?", "author": "wenleix", "createdAt": "2020-08-03T00:47:19Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java", "diffHunk": "@@ -775,6 +795,64 @@ private void queryCompletedEvent(Optional<ExecutionFailureInfo> failureInfo)\n             queryInfoOutputPath.ifPresent(path -> writeQueryInfo(path, queryInfo, queryInfoJsonCodec));\n         }\n \n+        private void processShuffleStats()", "originalCommit": "30e34cb69e102a1d4f335222c4044a1113b25c6e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTg4MTQzMw==", "url": "https://github.com/prestodb/presto/pull/14938#discussion_r465881433", "bodyText": "I thought it might be convenient if we want to figure out what were the shuffle speed of some particular task.", "author": "arhimondr", "createdAt": "2020-08-05T17:16:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDE0NTY2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDE0NTk1Mg==", "url": "https://github.com/prestodb/presto/pull/14938#discussion_r464145952", "bodyText": "Another way to do this is to make statsMap a TreeMap so the result can be traversed in a ordered way \ud83d\ude04 . You can keep the current way.", "author": "wenleix", "createdAt": "2020-08-03T00:49:35Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java", "diffHunk": "@@ -775,6 +795,64 @@ private void queryCompletedEvent(Optional<ExecutionFailureInfo> failureInfo)\n             queryInfoOutputPath.ifPresent(path -> writeQueryInfo(path, queryInfo, queryInfoJsonCodec));\n         }\n \n+        private void processShuffleStats()\n+        {\n+            List<PrestoSparkShuffleStats> statsList = new ArrayList<>(shuffleStatsCollector.value());\n+            Map<ShuffleStatsKey, List<PrestoSparkShuffleStats>> statsMap = new HashMap<>();\n+            Set<Integer> fragments = new HashSet<>();\n+            for (PrestoSparkShuffleStats stats : statsList) {\n+                ShuffleStatsKey key = new ShuffleStatsKey(stats.getFragmentId(), stats.getOperation());\n+                statsMap.computeIfAbsent(key, (ignored) -> new ArrayList<>()).add(stats);\n+                fragments.add(stats.getFragmentId());\n+            }\n+            List<Integer> sortedFragments = new ArrayList<>(fragments);", "originalCommit": "30e34cb69e102a1d4f335222c4044a1113b25c6e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTg4NjIzMg==", "url": "https://github.com/prestodb/presto/pull/14938#discussion_r465886232", "bodyText": "Yeah, the code with TreeMap is much simpler =) My bad =)", "author": "arhimondr", "createdAt": "2020-08-05T17:25:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDE0NTk1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDE0NjIyOQ==", "url": "https://github.com/prestodb/presto/pull/14938#discussion_r464146229", "bodyText": "what about just do something like\nrowsPerSecond = (long) (totalProcessedRows * 1000.0 / totalElapsedWallTimeMills)\nbytesPerSecond = ...\n\n?", "author": "wenleix", "createdAt": "2020-08-03T00:51:38Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java", "diffHunk": "@@ -775,6 +795,64 @@ private void queryCompletedEvent(Optional<ExecutionFailureInfo> failureInfo)\n             queryInfoOutputPath.ifPresent(path -> writeQueryInfo(path, queryInfo, queryInfoJsonCodec));\n         }\n \n+        private void processShuffleStats()\n+        {\n+            List<PrestoSparkShuffleStats> statsList = new ArrayList<>(shuffleStatsCollector.value());\n+            Map<ShuffleStatsKey, List<PrestoSparkShuffleStats>> statsMap = new HashMap<>();\n+            Set<Integer> fragments = new HashSet<>();\n+            for (PrestoSparkShuffleStats stats : statsList) {\n+                ShuffleStatsKey key = new ShuffleStatsKey(stats.getFragmentId(), stats.getOperation());\n+                statsMap.computeIfAbsent(key, (ignored) -> new ArrayList<>()).add(stats);\n+                fragments.add(stats.getFragmentId());\n+            }\n+            List<Integer> sortedFragments = new ArrayList<>(fragments);\n+            sortedFragments.sort(null);\n+            log.info(\"Shuffle statistics summary:\");\n+            for (Integer fragment : sortedFragments) {\n+                List<PrestoSparkShuffleStats> readStatistics = statsMap.get(new ShuffleStatsKey(fragment, READ));\n+                if (readStatistics != null) {\n+                    logShuffleStatsSummary(fragment, READ, readStatistics);\n+                }\n+                List<PrestoSparkShuffleStats> writeStatistics = statsMap.get(new ShuffleStatsKey(fragment, WRITE));\n+                if (writeStatistics != null) {\n+                    logShuffleStatsSummary(fragment, WRITE, writeStatistics);\n+                }\n+            }\n+        }\n+\n+        private void logShuffleStatsSummary(int fragmentId, Operation operation, List<PrestoSparkShuffleStats> statsList)\n+        {\n+            long totalProcessedRows = 0;\n+            long totalProcessedBytes = 0;\n+            long totalElapsedWallTimeMills = 0;\n+            for (PrestoSparkShuffleStats stats : statsList) {\n+                totalProcessedRows += stats.getProcessedRows();\n+                totalProcessedBytes += stats.getProcessedBytes();\n+                totalElapsedWallTimeMills += stats.getElapsedWallTimeMills();\n+            }\n+            long totalElapsedWallTimeSeconds = totalElapsedWallTimeMills / 1000;\n+            long rowsPerSecond = totalProcessedRows;\n+            long bytesPerSecond = totalProcessedBytes;\n+            if (totalElapsedWallTimeSeconds > 0) {", "originalCommit": "30e34cb69e102a1d4f335222c4044a1113b25c6e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTg4NzIzMw==", "url": "https://github.com/prestodb/presto/pull/14938#discussion_r465887233", "bodyText": "That's just a matter of taste I believe.\nPersonally I find messages like these confusing:\nTotal rows 1, rows per second: 1_000_000.\nI would rather prefer to see something like Total rows 1, rows per second: 1 (although this isn't very mathematically correct).\nWhat do you think?", "author": "arhimondr", "createdAt": "2020-08-05T17:26:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDE0NjIyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDE0NjM5Nw==", "url": "https://github.com/prestodb/presto/pull/14938#discussion_r464146397", "bodyText": "hmmm.. if it's just for logging purpose, it can be double right? (instead of long) , so we don't need to worry about whether totalElapsedWallTimeSeconds becomes 0 when the total time is less than 1 second.", "author": "wenleix", "createdAt": "2020-08-03T00:52:41Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java", "diffHunk": "@@ -775,6 +795,64 @@ private void queryCompletedEvent(Optional<ExecutionFailureInfo> failureInfo)\n             queryInfoOutputPath.ifPresent(path -> writeQueryInfo(path, queryInfo, queryInfoJsonCodec));\n         }\n \n+        private void processShuffleStats()\n+        {\n+            List<PrestoSparkShuffleStats> statsList = new ArrayList<>(shuffleStatsCollector.value());\n+            Map<ShuffleStatsKey, List<PrestoSparkShuffleStats>> statsMap = new HashMap<>();\n+            Set<Integer> fragments = new HashSet<>();\n+            for (PrestoSparkShuffleStats stats : statsList) {\n+                ShuffleStatsKey key = new ShuffleStatsKey(stats.getFragmentId(), stats.getOperation());\n+                statsMap.computeIfAbsent(key, (ignored) -> new ArrayList<>()).add(stats);\n+                fragments.add(stats.getFragmentId());\n+            }\n+            List<Integer> sortedFragments = new ArrayList<>(fragments);\n+            sortedFragments.sort(null);\n+            log.info(\"Shuffle statistics summary:\");\n+            for (Integer fragment : sortedFragments) {\n+                List<PrestoSparkShuffleStats> readStatistics = statsMap.get(new ShuffleStatsKey(fragment, READ));\n+                if (readStatistics != null) {\n+                    logShuffleStatsSummary(fragment, READ, readStatistics);\n+                }\n+                List<PrestoSparkShuffleStats> writeStatistics = statsMap.get(new ShuffleStatsKey(fragment, WRITE));\n+                if (writeStatistics != null) {\n+                    logShuffleStatsSummary(fragment, WRITE, writeStatistics);\n+                }\n+            }\n+        }\n+\n+        private void logShuffleStatsSummary(int fragmentId, Operation operation, List<PrestoSparkShuffleStats> statsList)\n+        {\n+            long totalProcessedRows = 0;\n+            long totalProcessedBytes = 0;\n+            long totalElapsedWallTimeMills = 0;\n+            for (PrestoSparkShuffleStats stats : statsList) {\n+                totalProcessedRows += stats.getProcessedRows();\n+                totalProcessedBytes += stats.getProcessedBytes();\n+                totalElapsedWallTimeMills += stats.getElapsedWallTimeMills();\n+            }\n+            long totalElapsedWallTimeSeconds = totalElapsedWallTimeMills / 1000;", "originalCommit": "30e34cb69e102a1d4f335222c4044a1113b25c6e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTg4NzY0OQ==", "url": "https://github.com/prestodb/presto/pull/14938#discussion_r465887649", "bodyText": "Then we might either end up with NaN or 1_000_000+++ rows/second that I personally find a little confusing. But I don't have a strong opinion here.", "author": "arhimondr", "createdAt": "2020-08-05T17:27:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDE0NjM5Nw=="}], "type": "inlineReview"}, {"oid": "cb5cb2b3063148a47c24a3bfff47774d2662d931", "url": "https://github.com/prestodb/presto/commit/cb5cb2b3063148a47c24a3bfff47774d2662d931", "message": "Refactor PrestoSparkMutableRowPageInput\n\nConsolidate zero column and non zero column rows read under the same branch", "committedDate": "2020-08-05T16:49:21Z", "type": "commit"}, {"oid": "570d9cac7eb8b7eb93268ab0f5c15fd783cd43d8", "url": "https://github.com/prestodb/presto/commit/570d9cac7eb8b7eb93268ab0f5c15fd783cd43d8", "message": "Propagate fragment id to PrestoSparkShufflePageInput", "committedDate": "2020-08-05T16:49:21Z", "type": "commit"}, {"oid": "e07af30abbd36bd41c79cfef44274bb2782b5610", "url": "https://github.com/prestodb/presto/commit/e07af30abbd36bd41c79cfef44274bb2782b5610", "message": "Collect shuffle statistics in Presto on Spark", "committedDate": "2020-08-05T17:31:15Z", "type": "commit"}, {"oid": "e07af30abbd36bd41c79cfef44274bb2782b5610", "url": "https://github.com/prestodb/presto/commit/e07af30abbd36bd41c79cfef44274bb2782b5610", "message": "Collect shuffle statistics in Presto on Spark", "committedDate": "2020-08-05T17:31:15Z", "type": "forcePushed"}]}