{"pr_number": 14119, "pr_title": "Add KHyperLogLog type and UDF", "pr_createdAt": "2020-02-20T01:56:33Z", "pr_url": "https://github.com/prestodb/presto/pull/14119", "timeline": [{"oid": "3dae6e97cc6d87558ce1854b99ade079e3cdc511", "url": "https://github.com/prestodb/presto/commit/3dae6e97cc6d87558ce1854b99ade079e3cdc511", "message": "Merge branch 'master' of github.com:mcorreaiz/presto", "committedDate": "2020-02-21T21:37:58Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk0MDAxNA==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r382940014", "bodyText": "This takes in a vararg, so you can group the scalars and aggregates in one line", "author": "tdcmeehan", "createdAt": "2020-02-22T20:40:28Z", "path": "presto-main/src/main/java/com/facebook/presto/metadata/BuiltInFunctionNamespaceManager.java", "diffHunk": "@@ -670,6 +674,10 @@ public BuiltInFunctionNamespaceManager(\n                 .aggregate(BuildSetDigestAggregation.class)\n                 .scalars(SetDigestFunctions.class)\n                 .scalars(SetDigestOperators.class)\n+                .aggregates(MergeKHyperLogLogAggregation.class)", "originalCommit": "10eed0c050d85b68972b40e12ea43456f88e6f44", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk0MDExMg==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r382940112", "bodyText": "Can you explain the purpose of this refactoring?", "author": "tdcmeehan", "createdAt": "2020-02-22T20:41:48Z", "path": "presto-main/src/main/java/com/facebook/presto/type/TypeRegistry.java", "diffHunk": "@@ -169,6 +170,40 @@ public TypeRegistry(Set<Type> types, FeaturesConfig featuresConfig)\n                 .build(CacheLoader.from(this::instantiateParametricType));\n     }\n \n+    private static Type getCommonSuperTypeForDecimal(DecimalType firstType, DecimalType secondType)", "originalCommit": "10eed0c050d85b68972b40e12ea43456f88e6f44", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ2MzM3NA==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r383463374", "bodyText": "I ran an automatic refactor on IntelliJ complying to Airlift style, and this change was made. Should I revert?", "author": "mcorreaiz", "createdAt": "2020-02-24T19:21:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk0MDExMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQ4NjkwNg==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r387486906", "bodyText": "Yes, please revert the unrelated change", "author": "tdcmeehan", "createdAt": "2020-03-04T07:24:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk0MDExMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk0MDEyNA==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r382940124", "bodyText": "You can leave the set digest position how it was", "author": "tdcmeehan", "createdAt": "2020-02-22T20:42:03Z", "path": "presto-main/src/main/java/com/facebook/presto/type/TypeRegistry.java", "diffHunk": "@@ -464,11 +476,12 @@ public void addParametricType(ParametricType parametricType)\n                     case StandardTypes.TIMESTAMP:\n                     case StandardTypes.TIMESTAMP_WITH_TIME_ZONE:\n                     case StandardTypes.HYPER_LOG_LOG:\n-                    case SetDigestType.NAME:\n                     case StandardTypes.P4_HYPER_LOG_LOG:\n                     case StandardTypes.JSON:\n                     case StandardTypes.INTERVAL_YEAR_TO_MONTH:\n                     case StandardTypes.INTERVAL_DAY_TO_SECOND:\n+                    case SetDigestType.NAME:", "originalCommit": "10eed0c050d85b68972b40e12ea43456f88e6f44", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk0MDE1NQ==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r382940155", "bodyText": "I would call this kyperloglog_agg", "author": "tdcmeehan", "createdAt": "2020-02-22T20:42:41Z", "path": "presto-main/src/main/java/com/facebook/presto/type/khyperloglog/BuildKHyperLogLogAggregation.java", "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.facebook.presto.type.khyperloglog;\n+\n+import com.facebook.presto.spi.block.BlockBuilder;\n+import com.facebook.presto.spi.function.AggregationFunction;\n+import com.facebook.presto.spi.function.AggregationState;\n+import com.facebook.presto.spi.function.CombineFunction;\n+import com.facebook.presto.spi.function.InputFunction;\n+import com.facebook.presto.spi.function.LiteralParameters;\n+import com.facebook.presto.spi.function.OutputFunction;\n+import com.facebook.presto.spi.function.SqlType;\n+import com.facebook.presto.spi.type.StandardTypes;\n+import io.airlift.slice.Murmur3Hash128;\n+import io.airlift.slice.Slice;\n+\n+@AggregationFunction(\"make_khyperloglog\")", "originalCommit": "10eed0c050d85b68972b40e12ea43456f88e6f44", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk0MDY4OA==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r382940688", "bodyText": "Have you considered xxhash?", "author": "tdcmeehan", "createdAt": "2020-02-22T20:51:40Z", "path": "presto-main/src/main/java/com/facebook/presto/type/khyperloglog/BuildKHyperLogLogAggregation.java", "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.facebook.presto.type.khyperloglog;\n+\n+import com.facebook.presto.spi.block.BlockBuilder;\n+import com.facebook.presto.spi.function.AggregationFunction;\n+import com.facebook.presto.spi.function.AggregationState;\n+import com.facebook.presto.spi.function.CombineFunction;\n+import com.facebook.presto.spi.function.InputFunction;\n+import com.facebook.presto.spi.function.LiteralParameters;\n+import com.facebook.presto.spi.function.OutputFunction;\n+import com.facebook.presto.spi.function.SqlType;\n+import com.facebook.presto.spi.type.StandardTypes;\n+import io.airlift.slice.Murmur3Hash128;\n+import io.airlift.slice.Slice;\n+\n+@AggregationFunction(\"make_khyperloglog\")\n+public final class BuildKHyperLogLogAggregation\n+{\n+    private static final KHyperLogLogStateSerializer SERIALIZER = new KHyperLogLogStateSerializer();\n+\n+    private BuildKHyperLogLogAggregation() {}\n+\n+    @InputFunction\n+    public static void input(@AggregationState KHyperLogLogState state, @SqlType(StandardTypes.BIGINT) long value, @SqlType(StandardTypes.BIGINT) long uii)\n+    {\n+        if (state.getKHLL() == null) {\n+            state.setKHLL(new KHyperLogLog());\n+        }\n+        state.getKHLL().add(value, uii);\n+    }\n+\n+    @InputFunction\n+    @LiteralParameters(\"x\")\n+    public static void input(@AggregationState KHyperLogLogState state, @SqlType(\"varchar(x)\") Slice value, @SqlType(StandardTypes.BIGINT) long uii)\n+    {\n+        if (state.getKHLL() == null) {\n+            state.setKHLL(new KHyperLogLog());\n+        }\n+        state.getKHLL().add(value, uii);\n+    }\n+\n+    @InputFunction\n+    public static void input(@AggregationState KHyperLogLogState state, @SqlType(StandardTypes.DOUBLE) double value, @SqlType(StandardTypes.BIGINT) long uii)\n+    {\n+        input(state, Double.doubleToLongBits(value), uii);\n+    }\n+\n+    @InputFunction\n+    @LiteralParameters(\"x\")\n+    public static void input(@AggregationState KHyperLogLogState state, @SqlType(StandardTypes.BIGINT) long value, @SqlType(\"varchar(x)\") Slice uii)\n+    {\n+        input(state, value, Murmur3Hash128.hash64(uii));\n+    }\n+\n+    @InputFunction\n+    @LiteralParameters({\"x\", \"y\"})\n+    public static void input(@AggregationState KHyperLogLogState state, @SqlType(\"varchar(x)\") Slice value, @SqlType(\"varchar(y)\") Slice uii)\n+    {\n+        input(state, value, Murmur3Hash128.hash64(uii));", "originalCommit": "10eed0c050d85b68972b40e12ea43456f88e6f44", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ1Njg2Nw==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r383456867", "bodyText": "I had not, but makes absolute sense.", "author": "mcorreaiz", "createdAt": "2020-02-24T19:08:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk0MDY4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzUxMTgwOQ==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r383511809", "bodyText": "I had not, but makes sense.", "author": "mcorreaiz", "createdAt": "2020-02-24T21:01:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk0MDY4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk0MTA5OQ==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r382941099", "bodyText": "For the serialization format, I would consider first serializing the total bytes for all of the HLLs, then serializing the minhashSize, then serializing a vector of individual HLL lengths.  That way you can allocate one large Slice for the entire block of memory with all of the HLLs fitting contiguously, and then iterate over the vector of individual lengths to create slices on this slab of memory for each individual HLL.  It should speed of the serialization/deserialization.", "author": "tdcmeehan", "createdAt": "2020-02-22T20:59:01Z", "path": "presto-main/src/main/java/com/facebook/presto/type/khyperloglog/KHyperLogLog.java", "diffHunk": "@@ -0,0 +1,285 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.facebook.presto.type.khyperloglog;\n+\n+import com.facebook.airlift.stats.cardinality.HyperLogLog;\n+import com.google.common.collect.Sets;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Murmur3Hash128;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import io.airlift.slice.SliceOutput;\n+import io.airlift.slice.Slices;\n+import it.unimi.dsi.fastutil.longs.Long2ObjectRBTreeMap;\n+import it.unimi.dsi.fastutil.longs.Long2ObjectSortedMap;\n+import it.unimi.dsi.fastutil.longs.LongBidirectionalIterator;\n+import it.unimi.dsi.fastutil.longs.LongRBTreeSet;\n+import it.unimi.dsi.fastutil.longs.LongSortedSet;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.Map;\n+import java.util.TreeMap;\n+import java.util.stream.LongStream;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static io.airlift.slice.SizeOf.SIZE_OF_BYTE;\n+import static io.airlift.slice.SizeOf.SIZE_OF_INT;\n+import static io.airlift.slice.SizeOf.SIZE_OF_LONG;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * For reference on KHyperLogLog, see \"KHyperLogLog: Estimating Reidentifiability and\n+ * Joinability of Large Data at Scale\" by Chia et al., 2019.\n+ */\n+public class KHyperLogLog\n+{\n+    public static final int DEFAULT_HLL_BUCKETS = 256;\n+    public static final int DEFAULT_MAX_SIZE = 4096;\n+    private static final byte UNCOMPRESSED_FORMAT = 1;\n+    private static final long HASH_OUTPUT_HALF_RANGE = Long.MAX_VALUE;\n+    private static final int SIZE_OF_KHYPERLOGLOG = ClassLayout.parseClass(KHyperLogLog.class).instanceSize();\n+    private static final int SIZE_OF_RBTREEMAP = ClassLayout.parseClass(Long2ObjectRBTreeMap.class).instanceSize();\n+\n+    private final Long2ObjectSortedMap<HyperLogLog> minhash;\n+    private final int maxSize;\n+    private final int hllBuckets;\n+\n+    public KHyperLogLog()\n+    {\n+        this(DEFAULT_MAX_SIZE, DEFAULT_HLL_BUCKETS, new Long2ObjectRBTreeMap<>());\n+    }\n+\n+    public KHyperLogLog(int maxSize, int hllBuckets)\n+    {\n+        this(maxSize, hllBuckets, new Long2ObjectRBTreeMap<>());\n+    }\n+\n+    public KHyperLogLog(int maxSize, int hllBuckets, Long2ObjectSortedMap<HyperLogLog> minhash)\n+    {\n+        this.maxSize = maxSize;\n+        this.hllBuckets = hllBuckets;\n+        this.minhash = requireNonNull(minhash, \"minhash is null\");\n+    }\n+\n+    public static KHyperLogLog newInstance(Slice serialized)\n+    {\n+        requireNonNull(serialized, \"serialized is null\");\n+        SliceInput input = serialized.getInput();\n+        checkArgument(input.readByte() == UNCOMPRESSED_FORMAT, \"Unexpected version\");\n+\n+        int maxSize = input.readInt();\n+        int hllBuckets = input.readInt();\n+        int minhashSize = input.readInt();\n+\n+        Long2ObjectRBTreeMap<HyperLogLog> minhash = new Long2ObjectRBTreeMap<>();\n+        // The values are stored after the keys\n+        SliceInput valuesInput = serialized.getInput();\n+        valuesInput.setPosition(input.position() + minhashSize * SIZE_OF_LONG);\n+\n+        int hllLength;\n+        Slice serializedHll;\n+        for (int i = 0; i < minhashSize; i++) {\n+            hllLength = valuesInput.readInt();", "originalCommit": "10eed0c050d85b68972b40e12ea43456f88e6f44", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk0MTE5Ng==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r382941196", "bodyText": "You can also deserialize the vector of HLL lengths in one shot via:\nint[] values = ...\nvaluesInput.readBytes(wrappedIntArray(values))", "author": "tdcmeehan", "createdAt": "2020-02-22T21:00:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk0MTA5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk0MTQ0Mw==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r382941443", "bodyText": "This will end up promoting the primitive longs into java.lang.Long, let's find a way that avoids this.", "author": "tdcmeehan", "createdAt": "2020-02-22T21:04:06Z", "path": "presto-main/src/main/java/com/facebook/presto/type/khyperloglog/KHyperLogLog.java", "diffHunk": "@@ -0,0 +1,285 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.facebook.presto.type.khyperloglog;\n+\n+import com.facebook.airlift.stats.cardinality.HyperLogLog;\n+import com.google.common.collect.Sets;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Murmur3Hash128;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import io.airlift.slice.SliceOutput;\n+import io.airlift.slice.Slices;\n+import it.unimi.dsi.fastutil.longs.Long2ObjectRBTreeMap;\n+import it.unimi.dsi.fastutil.longs.Long2ObjectSortedMap;\n+import it.unimi.dsi.fastutil.longs.LongBidirectionalIterator;\n+import it.unimi.dsi.fastutil.longs.LongRBTreeSet;\n+import it.unimi.dsi.fastutil.longs.LongSortedSet;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.Map;\n+import java.util.TreeMap;\n+import java.util.stream.LongStream;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static io.airlift.slice.SizeOf.SIZE_OF_BYTE;\n+import static io.airlift.slice.SizeOf.SIZE_OF_INT;\n+import static io.airlift.slice.SizeOf.SIZE_OF_LONG;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * For reference on KHyperLogLog, see \"KHyperLogLog: Estimating Reidentifiability and\n+ * Joinability of Large Data at Scale\" by Chia et al., 2019.\n+ */\n+public class KHyperLogLog\n+{\n+    public static final int DEFAULT_HLL_BUCKETS = 256;\n+    public static final int DEFAULT_MAX_SIZE = 4096;\n+    private static final byte UNCOMPRESSED_FORMAT = 1;\n+    private static final long HASH_OUTPUT_HALF_RANGE = Long.MAX_VALUE;\n+    private static final int SIZE_OF_KHYPERLOGLOG = ClassLayout.parseClass(KHyperLogLog.class).instanceSize();\n+    private static final int SIZE_OF_RBTREEMAP = ClassLayout.parseClass(Long2ObjectRBTreeMap.class).instanceSize();\n+\n+    private final Long2ObjectSortedMap<HyperLogLog> minhash;\n+    private final int maxSize;\n+    private final int hllBuckets;\n+\n+    public KHyperLogLog()\n+    {\n+        this(DEFAULT_MAX_SIZE, DEFAULT_HLL_BUCKETS, new Long2ObjectRBTreeMap<>());\n+    }\n+\n+    public KHyperLogLog(int maxSize, int hllBuckets)\n+    {\n+        this(maxSize, hllBuckets, new Long2ObjectRBTreeMap<>());\n+    }\n+\n+    public KHyperLogLog(int maxSize, int hllBuckets, Long2ObjectSortedMap<HyperLogLog> minhash)\n+    {\n+        this.maxSize = maxSize;\n+        this.hllBuckets = hllBuckets;\n+        this.minhash = requireNonNull(minhash, \"minhash is null\");\n+    }\n+\n+    public static KHyperLogLog newInstance(Slice serialized)\n+    {\n+        requireNonNull(serialized, \"serialized is null\");\n+        SliceInput input = serialized.getInput();\n+        checkArgument(input.readByte() == UNCOMPRESSED_FORMAT, \"Unexpected version\");\n+\n+        int maxSize = input.readInt();\n+        int hllBuckets = input.readInt();\n+        int minhashSize = input.readInt();\n+\n+        Long2ObjectRBTreeMap<HyperLogLog> minhash = new Long2ObjectRBTreeMap<>();\n+        // The values are stored after the keys\n+        SliceInput valuesInput = serialized.getInput();\n+        valuesInput.setPosition(input.position() + minhashSize * SIZE_OF_LONG);\n+\n+        int hllLength;\n+        Slice serializedHll;\n+        for (int i = 0; i < minhashSize; i++) {\n+            hllLength = valuesInput.readInt();\n+            serializedHll = Slices.allocate(hllLength);\n+            valuesInput.readBytes(serializedHll, hllLength);\n+            minhash.put(input.readLong(), HyperLogLog.newInstance(serializedHll));\n+        }\n+\n+        return new KHyperLogLog(maxSize, hllBuckets, minhash);\n+    }\n+\n+    public static long exactIntersectionCardinality(KHyperLogLog a, KHyperLogLog b)\n+    {\n+        checkState(a.isExact(), \"exact intersection cannot operate on approximate sets\");\n+        checkArgument(b.isExact(), \"exact intersection cannot operate on approximate sets\");\n+\n+        return Sets.intersection(a.minhash.keySet(), b.minhash.keySet()).size();\n+    }\n+\n+    public static double jaccardIndex(KHyperLogLog a, KHyperLogLog b)\n+    {\n+        int sizeOfSmallerSet = Math.min(a.minhash.size(), b.minhash.size());\n+        LongSortedSet minUnion = new LongRBTreeSet(a.minhash.keySet());\n+        minUnion.addAll(b.minhash.keySet());\n+\n+        int intersection = 0;\n+        int i = 0;\n+        for (long key : minUnion) {", "originalCommit": "10eed0c050d85b68972b40e12ea43456f88e6f44", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU1NTgwOA==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r383555808", "bodyText": "Changed implementation to follow mergeWith style.", "author": "mcorreaiz", "createdAt": "2020-02-24T22:35:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk0MTQ0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk0MTQ5NA==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r382941494", "bodyText": "Let's add a version byte in case we change our mind on the serialization format", "author": "tdcmeehan", "createdAt": "2020-02-22T21:05:03Z", "path": "presto-main/src/main/java/com/facebook/presto/type/khyperloglog/KHyperLogLog.java", "diffHunk": "@@ -0,0 +1,285 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.facebook.presto.type.khyperloglog;\n+\n+import com.facebook.airlift.stats.cardinality.HyperLogLog;\n+import com.google.common.collect.Sets;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Murmur3Hash128;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import io.airlift.slice.SliceOutput;\n+import io.airlift.slice.Slices;\n+import it.unimi.dsi.fastutil.longs.Long2ObjectRBTreeMap;\n+import it.unimi.dsi.fastutil.longs.Long2ObjectSortedMap;\n+import it.unimi.dsi.fastutil.longs.LongBidirectionalIterator;\n+import it.unimi.dsi.fastutil.longs.LongRBTreeSet;\n+import it.unimi.dsi.fastutil.longs.LongSortedSet;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.Map;\n+import java.util.TreeMap;\n+import java.util.stream.LongStream;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static io.airlift.slice.SizeOf.SIZE_OF_BYTE;\n+import static io.airlift.slice.SizeOf.SIZE_OF_INT;\n+import static io.airlift.slice.SizeOf.SIZE_OF_LONG;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * For reference on KHyperLogLog, see \"KHyperLogLog: Estimating Reidentifiability and\n+ * Joinability of Large Data at Scale\" by Chia et al., 2019.\n+ */\n+public class KHyperLogLog\n+{\n+    public static final int DEFAULT_HLL_BUCKETS = 256;\n+    public static final int DEFAULT_MAX_SIZE = 4096;\n+    private static final byte UNCOMPRESSED_FORMAT = 1;\n+    private static final long HASH_OUTPUT_HALF_RANGE = Long.MAX_VALUE;\n+    private static final int SIZE_OF_KHYPERLOGLOG = ClassLayout.parseClass(KHyperLogLog.class).instanceSize();\n+    private static final int SIZE_OF_RBTREEMAP = ClassLayout.parseClass(Long2ObjectRBTreeMap.class).instanceSize();\n+\n+    private final Long2ObjectSortedMap<HyperLogLog> minhash;\n+    private final int maxSize;\n+    private final int hllBuckets;\n+\n+    public KHyperLogLog()\n+    {\n+        this(DEFAULT_MAX_SIZE, DEFAULT_HLL_BUCKETS, new Long2ObjectRBTreeMap<>());\n+    }\n+\n+    public KHyperLogLog(int maxSize, int hllBuckets)\n+    {\n+        this(maxSize, hllBuckets, new Long2ObjectRBTreeMap<>());\n+    }\n+\n+    public KHyperLogLog(int maxSize, int hllBuckets, Long2ObjectSortedMap<HyperLogLog> minhash)\n+    {\n+        this.maxSize = maxSize;\n+        this.hllBuckets = hllBuckets;\n+        this.minhash = requireNonNull(minhash, \"minhash is null\");\n+    }\n+\n+    public static KHyperLogLog newInstance(Slice serialized)\n+    {\n+        requireNonNull(serialized, \"serialized is null\");\n+        SliceInput input = serialized.getInput();\n+        checkArgument(input.readByte() == UNCOMPRESSED_FORMAT, \"Unexpected version\");\n+\n+        int maxSize = input.readInt();\n+        int hllBuckets = input.readInt();\n+        int minhashSize = input.readInt();\n+\n+        Long2ObjectRBTreeMap<HyperLogLog> minhash = new Long2ObjectRBTreeMap<>();\n+        // The values are stored after the keys\n+        SliceInput valuesInput = serialized.getInput();\n+        valuesInput.setPosition(input.position() + minhashSize * SIZE_OF_LONG);\n+\n+        int hllLength;\n+        Slice serializedHll;\n+        for (int i = 0; i < minhashSize; i++) {\n+            hllLength = valuesInput.readInt();\n+            serializedHll = Slices.allocate(hllLength);\n+            valuesInput.readBytes(serializedHll, hllLength);\n+            minhash.put(input.readLong(), HyperLogLog.newInstance(serializedHll));\n+        }\n+\n+        return new KHyperLogLog(maxSize, hllBuckets, minhash);\n+    }\n+\n+    public static long exactIntersectionCardinality(KHyperLogLog a, KHyperLogLog b)\n+    {\n+        checkState(a.isExact(), \"exact intersection cannot operate on approximate sets\");\n+        checkArgument(b.isExact(), \"exact intersection cannot operate on approximate sets\");\n+\n+        return Sets.intersection(a.minhash.keySet(), b.minhash.keySet()).size();\n+    }\n+\n+    public static double jaccardIndex(KHyperLogLog a, KHyperLogLog b)\n+    {\n+        int sizeOfSmallerSet = Math.min(a.minhash.size(), b.minhash.size());\n+        LongSortedSet minUnion = new LongRBTreeSet(a.minhash.keySet());\n+        minUnion.addAll(b.minhash.keySet());\n+\n+        int intersection = 0;\n+        int i = 0;\n+        for (long key : minUnion) {\n+            if (a.minhash.containsKey(key) && b.minhash.containsKey(key)) {\n+                intersection++;\n+            }\n+            i++;\n+            if (i >= sizeOfSmallerSet) {\n+                break;\n+            }\n+        }\n+        return intersection / (double) sizeOfSmallerSet;\n+    }\n+\n+    public static KHyperLogLog merge(KHyperLogLog khll1, KHyperLogLog khll2)\n+    {\n+        /*\n+        Return the one with smallest K so resolution is not lost. This loss would happen in the case\n+        one merged a smaller KHLL into a bigger one because the former's minhash struct won't\n+        cover all of the latter's minhash space.\n+         */\n+        if (khll1.maxSize <= khll2.maxSize) {\n+            return khll1.mergeWith(khll2);\n+        }\n+        return khll2.mergeWith(khll1);\n+    }\n+\n+    public boolean isExact()\n+    {\n+        return minhash.size() < maxSize;\n+    }\n+\n+    public long getMinhashSize()\n+    {\n+        return minhash.size();\n+    }\n+\n+    public Slice serialize()\n+    {\n+        try (SliceOutput output = new DynamicSliceOutput(estimatedSerializedSize())) {\n+            output.appendByte(UNCOMPRESSED_FORMAT);", "originalCommit": "10eed0c050d85b68972b40e12ea43456f88e6f44", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk0MTUxMw==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r382941513", "bodyText": "As we discussed, we want to try to compute this as we go rather than in this method.", "author": "tdcmeehan", "createdAt": "2020-02-22T21:05:36Z", "path": "presto-main/src/main/java/com/facebook/presto/type/khyperloglog/KHyperLogLog.java", "diffHunk": "@@ -0,0 +1,285 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.facebook.presto.type.khyperloglog;\n+\n+import com.facebook.airlift.stats.cardinality.HyperLogLog;\n+import com.google.common.collect.Sets;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Murmur3Hash128;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import io.airlift.slice.SliceOutput;\n+import io.airlift.slice.Slices;\n+import it.unimi.dsi.fastutil.longs.Long2ObjectRBTreeMap;\n+import it.unimi.dsi.fastutil.longs.Long2ObjectSortedMap;\n+import it.unimi.dsi.fastutil.longs.LongBidirectionalIterator;\n+import it.unimi.dsi.fastutil.longs.LongRBTreeSet;\n+import it.unimi.dsi.fastutil.longs.LongSortedSet;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.Map;\n+import java.util.TreeMap;\n+import java.util.stream.LongStream;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static io.airlift.slice.SizeOf.SIZE_OF_BYTE;\n+import static io.airlift.slice.SizeOf.SIZE_OF_INT;\n+import static io.airlift.slice.SizeOf.SIZE_OF_LONG;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * For reference on KHyperLogLog, see \"KHyperLogLog: Estimating Reidentifiability and\n+ * Joinability of Large Data at Scale\" by Chia et al., 2019.\n+ */\n+public class KHyperLogLog\n+{\n+    public static final int DEFAULT_HLL_BUCKETS = 256;\n+    public static final int DEFAULT_MAX_SIZE = 4096;\n+    private static final byte UNCOMPRESSED_FORMAT = 1;\n+    private static final long HASH_OUTPUT_HALF_RANGE = Long.MAX_VALUE;\n+    private static final int SIZE_OF_KHYPERLOGLOG = ClassLayout.parseClass(KHyperLogLog.class).instanceSize();\n+    private static final int SIZE_OF_RBTREEMAP = ClassLayout.parseClass(Long2ObjectRBTreeMap.class).instanceSize();\n+\n+    private final Long2ObjectSortedMap<HyperLogLog> minhash;\n+    private final int maxSize;\n+    private final int hllBuckets;\n+\n+    public KHyperLogLog()\n+    {\n+        this(DEFAULT_MAX_SIZE, DEFAULT_HLL_BUCKETS, new Long2ObjectRBTreeMap<>());\n+    }\n+\n+    public KHyperLogLog(int maxSize, int hllBuckets)\n+    {\n+        this(maxSize, hllBuckets, new Long2ObjectRBTreeMap<>());\n+    }\n+\n+    public KHyperLogLog(int maxSize, int hllBuckets, Long2ObjectSortedMap<HyperLogLog> minhash)\n+    {\n+        this.maxSize = maxSize;\n+        this.hllBuckets = hllBuckets;\n+        this.minhash = requireNonNull(minhash, \"minhash is null\");\n+    }\n+\n+    public static KHyperLogLog newInstance(Slice serialized)\n+    {\n+        requireNonNull(serialized, \"serialized is null\");\n+        SliceInput input = serialized.getInput();\n+        checkArgument(input.readByte() == UNCOMPRESSED_FORMAT, \"Unexpected version\");\n+\n+        int maxSize = input.readInt();\n+        int hllBuckets = input.readInt();\n+        int minhashSize = input.readInt();\n+\n+        Long2ObjectRBTreeMap<HyperLogLog> minhash = new Long2ObjectRBTreeMap<>();\n+        // The values are stored after the keys\n+        SliceInput valuesInput = serialized.getInput();\n+        valuesInput.setPosition(input.position() + minhashSize * SIZE_OF_LONG);\n+\n+        int hllLength;\n+        Slice serializedHll;\n+        for (int i = 0; i < minhashSize; i++) {\n+            hllLength = valuesInput.readInt();\n+            serializedHll = Slices.allocate(hllLength);\n+            valuesInput.readBytes(serializedHll, hllLength);\n+            minhash.put(input.readLong(), HyperLogLog.newInstance(serializedHll));\n+        }\n+\n+        return new KHyperLogLog(maxSize, hllBuckets, minhash);\n+    }\n+\n+    public static long exactIntersectionCardinality(KHyperLogLog a, KHyperLogLog b)\n+    {\n+        checkState(a.isExact(), \"exact intersection cannot operate on approximate sets\");\n+        checkArgument(b.isExact(), \"exact intersection cannot operate on approximate sets\");\n+\n+        return Sets.intersection(a.minhash.keySet(), b.minhash.keySet()).size();\n+    }\n+\n+    public static double jaccardIndex(KHyperLogLog a, KHyperLogLog b)\n+    {\n+        int sizeOfSmallerSet = Math.min(a.minhash.size(), b.minhash.size());\n+        LongSortedSet minUnion = new LongRBTreeSet(a.minhash.keySet());\n+        minUnion.addAll(b.minhash.keySet());\n+\n+        int intersection = 0;\n+        int i = 0;\n+        for (long key : minUnion) {\n+            if (a.minhash.containsKey(key) && b.minhash.containsKey(key)) {\n+                intersection++;\n+            }\n+            i++;\n+            if (i >= sizeOfSmallerSet) {\n+                break;\n+            }\n+        }\n+        return intersection / (double) sizeOfSmallerSet;\n+    }\n+\n+    public static KHyperLogLog merge(KHyperLogLog khll1, KHyperLogLog khll2)\n+    {\n+        /*\n+        Return the one with smallest K so resolution is not lost. This loss would happen in the case\n+        one merged a smaller KHLL into a bigger one because the former's minhash struct won't\n+        cover all of the latter's minhash space.\n+         */\n+        if (khll1.maxSize <= khll2.maxSize) {\n+            return khll1.mergeWith(khll2);\n+        }\n+        return khll2.mergeWith(khll1);\n+    }\n+\n+    public boolean isExact()\n+    {\n+        return minhash.size() < maxSize;\n+    }\n+\n+    public long getMinhashSize()\n+    {\n+        return minhash.size();\n+    }\n+\n+    public Slice serialize()\n+    {\n+        try (SliceOutput output = new DynamicSliceOutput(estimatedSerializedSize())) {\n+            output.appendByte(UNCOMPRESSED_FORMAT);\n+            output.appendInt(maxSize);\n+            output.appendInt(hllBuckets);\n+            output.appendInt(minhash.size());\n+            for (long key : minhash.keySet()) {\n+                output.appendLong(key);\n+            }\n+            Slice serializedHll;\n+            for (HyperLogLog hll : minhash.values()) {\n+                serializedHll = hll.serialize();\n+                output.appendInt(serializedHll.length());\n+                output.appendBytes(serializedHll);\n+            }\n+\n+            return output.slice();\n+        }\n+        catch (IOException e) {\n+            throw new UncheckedIOException(e);\n+        }\n+    }\n+\n+    public int estimatedInMemorySize()\n+    {\n+        return SIZE_OF_KHYPERLOGLOG +\n+                SIZE_OF_RBTREEMAP +\n+                minhash.size() * SIZE_OF_LONG +\n+                minhash.values().stream().mapToInt(HyperLogLog::estimatedInMemorySize).sum();", "originalCommit": "10eed0c050d85b68972b40e12ea43456f88e6f44", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzUxNjAyMg==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r383516022", "bodyText": "Right, that's being implemented. Will be included in upcoming version", "author": "mcorreaiz", "createdAt": "2020-02-24T21:10:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk0MTUxMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk0MTYxMg==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r382941612", "bodyText": "Let's find a way to do this without boxed types", "author": "tdcmeehan", "createdAt": "2020-02-22T21:07:09Z", "path": "presto-main/src/main/java/com/facebook/presto/type/khyperloglog/KHyperLogLog.java", "diffHunk": "@@ -0,0 +1,285 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.facebook.presto.type.khyperloglog;\n+\n+import com.facebook.airlift.stats.cardinality.HyperLogLog;\n+import com.google.common.collect.Sets;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Murmur3Hash128;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import io.airlift.slice.SliceOutput;\n+import io.airlift.slice.Slices;\n+import it.unimi.dsi.fastutil.longs.Long2ObjectRBTreeMap;\n+import it.unimi.dsi.fastutil.longs.Long2ObjectSortedMap;\n+import it.unimi.dsi.fastutil.longs.LongBidirectionalIterator;\n+import it.unimi.dsi.fastutil.longs.LongRBTreeSet;\n+import it.unimi.dsi.fastutil.longs.LongSortedSet;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.Map;\n+import java.util.TreeMap;\n+import java.util.stream.LongStream;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static io.airlift.slice.SizeOf.SIZE_OF_BYTE;\n+import static io.airlift.slice.SizeOf.SIZE_OF_INT;\n+import static io.airlift.slice.SizeOf.SIZE_OF_LONG;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * For reference on KHyperLogLog, see \"KHyperLogLog: Estimating Reidentifiability and\n+ * Joinability of Large Data at Scale\" by Chia et al., 2019.\n+ */\n+public class KHyperLogLog\n+{\n+    public static final int DEFAULT_HLL_BUCKETS = 256;\n+    public static final int DEFAULT_MAX_SIZE = 4096;\n+    private static final byte UNCOMPRESSED_FORMAT = 1;\n+    private static final long HASH_OUTPUT_HALF_RANGE = Long.MAX_VALUE;\n+    private static final int SIZE_OF_KHYPERLOGLOG = ClassLayout.parseClass(KHyperLogLog.class).instanceSize();\n+    private static final int SIZE_OF_RBTREEMAP = ClassLayout.parseClass(Long2ObjectRBTreeMap.class).instanceSize();\n+\n+    private final Long2ObjectSortedMap<HyperLogLog> minhash;\n+    private final int maxSize;\n+    private final int hllBuckets;\n+\n+    public KHyperLogLog()\n+    {\n+        this(DEFAULT_MAX_SIZE, DEFAULT_HLL_BUCKETS, new Long2ObjectRBTreeMap<>());\n+    }\n+\n+    public KHyperLogLog(int maxSize, int hllBuckets)\n+    {\n+        this(maxSize, hllBuckets, new Long2ObjectRBTreeMap<>());\n+    }\n+\n+    public KHyperLogLog(int maxSize, int hllBuckets, Long2ObjectSortedMap<HyperLogLog> minhash)\n+    {\n+        this.maxSize = maxSize;\n+        this.hllBuckets = hllBuckets;\n+        this.minhash = requireNonNull(minhash, \"minhash is null\");\n+    }\n+\n+    public static KHyperLogLog newInstance(Slice serialized)\n+    {\n+        requireNonNull(serialized, \"serialized is null\");\n+        SliceInput input = serialized.getInput();\n+        checkArgument(input.readByte() == UNCOMPRESSED_FORMAT, \"Unexpected version\");\n+\n+        int maxSize = input.readInt();\n+        int hllBuckets = input.readInt();\n+        int minhashSize = input.readInt();\n+\n+        Long2ObjectRBTreeMap<HyperLogLog> minhash = new Long2ObjectRBTreeMap<>();\n+        // The values are stored after the keys\n+        SliceInput valuesInput = serialized.getInput();\n+        valuesInput.setPosition(input.position() + minhashSize * SIZE_OF_LONG);\n+\n+        int hllLength;\n+        Slice serializedHll;\n+        for (int i = 0; i < minhashSize; i++) {\n+            hllLength = valuesInput.readInt();\n+            serializedHll = Slices.allocate(hllLength);\n+            valuesInput.readBytes(serializedHll, hllLength);\n+            minhash.put(input.readLong(), HyperLogLog.newInstance(serializedHll));\n+        }\n+\n+        return new KHyperLogLog(maxSize, hllBuckets, minhash);\n+    }\n+\n+    public static long exactIntersectionCardinality(KHyperLogLog a, KHyperLogLog b)\n+    {\n+        checkState(a.isExact(), \"exact intersection cannot operate on approximate sets\");\n+        checkArgument(b.isExact(), \"exact intersection cannot operate on approximate sets\");\n+\n+        return Sets.intersection(a.minhash.keySet(), b.minhash.keySet()).size();\n+    }\n+\n+    public static double jaccardIndex(KHyperLogLog a, KHyperLogLog b)\n+    {\n+        int sizeOfSmallerSet = Math.min(a.minhash.size(), b.minhash.size());\n+        LongSortedSet minUnion = new LongRBTreeSet(a.minhash.keySet());\n+        minUnion.addAll(b.minhash.keySet());\n+\n+        int intersection = 0;\n+        int i = 0;\n+        for (long key : minUnion) {\n+            if (a.minhash.containsKey(key) && b.minhash.containsKey(key)) {\n+                intersection++;\n+            }\n+            i++;\n+            if (i >= sizeOfSmallerSet) {\n+                break;\n+            }\n+        }\n+        return intersection / (double) sizeOfSmallerSet;\n+    }\n+\n+    public static KHyperLogLog merge(KHyperLogLog khll1, KHyperLogLog khll2)\n+    {\n+        /*\n+        Return the one with smallest K so resolution is not lost. This loss would happen in the case\n+        one merged a smaller KHLL into a bigger one because the former's minhash struct won't\n+        cover all of the latter's minhash space.\n+         */\n+        if (khll1.maxSize <= khll2.maxSize) {\n+            return khll1.mergeWith(khll2);\n+        }\n+        return khll2.mergeWith(khll1);\n+    }\n+\n+    public boolean isExact()\n+    {\n+        return minhash.size() < maxSize;\n+    }\n+\n+    public long getMinhashSize()\n+    {\n+        return minhash.size();\n+    }\n+\n+    public Slice serialize()\n+    {\n+        try (SliceOutput output = new DynamicSliceOutput(estimatedSerializedSize())) {\n+            output.appendByte(UNCOMPRESSED_FORMAT);\n+            output.appendInt(maxSize);\n+            output.appendInt(hllBuckets);\n+            output.appendInt(minhash.size());\n+            for (long key : minhash.keySet()) {\n+                output.appendLong(key);\n+            }\n+            Slice serializedHll;\n+            for (HyperLogLog hll : minhash.values()) {\n+                serializedHll = hll.serialize();\n+                output.appendInt(serializedHll.length());\n+                output.appendBytes(serializedHll);\n+            }\n+\n+            return output.slice();\n+        }\n+        catch (IOException e) {\n+            throw new UncheckedIOException(e);\n+        }\n+    }\n+\n+    public int estimatedInMemorySize()\n+    {\n+        return SIZE_OF_KHYPERLOGLOG +\n+                SIZE_OF_RBTREEMAP +\n+                minhash.size() * SIZE_OF_LONG +\n+                minhash.values().stream().mapToInt(HyperLogLog::estimatedInMemorySize).sum();\n+    }\n+\n+    public int estimatedSerializedSize()\n+    {\n+        return SIZE_OF_BYTE +\n+                3 * SIZE_OF_INT +\n+                minhash.size() * (SIZE_OF_LONG + SIZE_OF_INT) +\n+                minhash.values().stream().mapToInt(HyperLogLog::estimatedSerializedSize).sum();\n+    }\n+\n+    public void add(long value, long uii)\n+    {\n+        update(Murmur3Hash128.hash64(value), uii);\n+    }\n+\n+    public void add(Slice value, long uii)\n+    {\n+        update(Murmur3Hash128.hash64(value), uii);\n+    }\n+\n+    private void update(long hash, long uii)\n+    {\n+        if (minhash.containsKey(hash)) {\n+            minhash.get(hash).add(uii);\n+        }\n+        else if (isExact() || hash < minhash.lastLongKey()) {\n+            HyperLogLog hll = HyperLogLog.newInstance(hllBuckets);\n+            hll.add(uii);\n+            minhash.put(hash, hll);\n+            removeOverflowEntries();\n+        }\n+    }\n+\n+    public long cardinality()\n+    {\n+        if (isExact()) {\n+            return minhash.size();\n+        }\n+\n+        // Intuition is: get the stored hashes' density, and extrapolate to the whole Hash output range.\n+        // Since Hash output range (2^64) cannot be stored in long type, I use half of the range\n+        // via Long.MAX_VALUE and also divide the hash values' density by 2. The \"-1\" is bias correction\n+        // detailed in \"On Synopses for Distinct-Value Estimation Under Multiset Operations\" by Beyer et. al.\n+        long hashesRange = minhash.lastLongKey() - Long.MIN_VALUE;\n+        double halfDensity = Long.divideUnsigned(hashesRange, minhash.size()) / 2D;\n+        return (long) (HASH_OUTPUT_HALF_RANGE / halfDensity);\n+    }\n+\n+    public KHyperLogLog mergeWith(KHyperLogLog other)\n+    {\n+        LongBidirectionalIterator iterator = other.minhash.keySet().iterator();\n+        while (iterator.hasNext()) {\n+            long key = iterator.nextLong();\n+            if (minhash.containsKey(key)) {\n+                minhash.get(key).mergeWith(other.minhash.get(key));\n+            }\n+            else {\n+                minhash.put(key, other.minhash.get(key));\n+            }\n+        }\n+        removeOverflowEntries();\n+        return this;\n+    }\n+\n+    public double reidentificationPotential(long threshold)\n+    {\n+        int highlyUniqueValues = 0;\n+        for (HyperLogLog hll : minhash.values()) {\n+            if (hll.cardinality() <= threshold) {\n+                highlyUniqueValues++;\n+            }\n+        }\n+        return (double) highlyUniqueValues / minhash.size();\n+    }\n+\n+    public Map<Long, Double> uniquenessDistribution()\n+    {\n+        return uniquenessDistribution(minhash.size());\n+    }\n+\n+    public Map<Long, Double> uniquenessDistribution(long histogramSize)", "originalCommit": "10eed0c050d85b68972b40e12ea43456f88e6f44", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU3MDIyMA==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r383570220", "bodyText": "Using fastutil Long2DoubleMap", "author": "mcorreaiz", "createdAt": "2020-02-24T23:13:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk0MTYxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQ4Nzc2OQ==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r387487769", "bodyText": "You can just have one method which takes in the memory size in bytes.  We can pass in the negative value to subtract and positive value to add.", "author": "tdcmeehan", "createdAt": "2020-03-04T07:26:40Z", "path": "presto-main/src/main/java/com/facebook/presto/type/khyperloglog/KHyperLogLog.java", "diffHunk": "@@ -0,0 +1,351 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.facebook.presto.type.khyperloglog;\n+\n+import com.facebook.airlift.stats.cardinality.HyperLogLog;\n+import com.google.common.collect.Sets;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Murmur3Hash128;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import io.airlift.slice.SliceOutput;\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import it.unimi.dsi.fastutil.longs.Long2DoubleMap;\n+import it.unimi.dsi.fastutil.longs.Long2DoubleOpenHashMap;\n+import it.unimi.dsi.fastutil.longs.Long2ObjectRBTreeMap;\n+import it.unimi.dsi.fastutil.longs.Long2ObjectSortedMap;\n+import it.unimi.dsi.fastutil.longs.LongIterator;\n+import it.unimi.dsi.fastutil.longs.LongRBTreeSet;\n+import it.unimi.dsi.fastutil.longs.LongSortedSet;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.PrimitiveIterator;\n+import java.util.stream.LongStream;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static io.airlift.slice.SizeOf.SIZE_OF_BYTE;\n+import static io.airlift.slice.SizeOf.SIZE_OF_INT;\n+import static io.airlift.slice.SizeOf.SIZE_OF_LONG;\n+import static io.airlift.slice.Slices.wrappedIntArray;\n+import static io.airlift.slice.Slices.wrappedLongArray;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * For reference on KHyperLogLog, see \"KHyperLogLog: Estimating Reidentifiability and\n+ * Joinability of Large Data at Scale\" by Chia et al., 2019.\n+ */\n+public class KHyperLogLog\n+{\n+    public static final int DEFAULT_HLL_BUCKETS = 256;\n+    public static final int DEFAULT_MAX_SIZE = 4096;\n+    private static final byte VERSION_BYTE = 1;\n+    private static final long HASH_OUTPUT_HALF_RANGE = Long.MAX_VALUE;\n+    private static final int SIZE_OF_KHYPERLOGLOG = ClassLayout.parseClass(KHyperLogLog.class).instanceSize();\n+    private static final int SIZE_OF_RBTREEMAP = ClassLayout.parseClass(Long2ObjectRBTreeMap.class).instanceSize();\n+\n+    private final Long2ObjectSortedMap<HyperLogLog> minhash;\n+    private final int maxSize;\n+    private final int hllBuckets;\n+\n+    private int hllsTotalEstimatedInMemorySize;\n+    private int hllsTotalEstimatedSerializedSize;\n+\n+    public KHyperLogLog()\n+    {\n+        this(DEFAULT_MAX_SIZE, DEFAULT_HLL_BUCKETS, new Long2ObjectRBTreeMap<>());\n+    }\n+\n+    public KHyperLogLog(int maxSize, int hllBuckets)\n+    {\n+        this(maxSize, hllBuckets, new Long2ObjectRBTreeMap<>());\n+    }\n+\n+    public KHyperLogLog(int maxSize, int hllBuckets, Long2ObjectSortedMap<HyperLogLog> minhash)\n+    {\n+        this.maxSize = maxSize;\n+        this.hllBuckets = hllBuckets;\n+        this.minhash = requireNonNull(minhash, \"minhash is null\");\n+        hllsTotalEstimatedInMemorySize = 0;\n+        hllsTotalEstimatedSerializedSize = 0;\n+\n+        for (HyperLogLog hll : minhash.values()) {\n+            increaseTotalHllSize(hll);\n+        }\n+    }\n+\n+    public static KHyperLogLog newInstance(Slice serialized)\n+    {\n+        requireNonNull(serialized, \"serialized is null\");\n+        SliceInput input = serialized.getInput();\n+        checkArgument(input.readByte() == VERSION_BYTE, \"Unexpected version\");\n+        Long2ObjectRBTreeMap<HyperLogLog> minhash = new Long2ObjectRBTreeMap<>();\n+\n+        int maxSize = input.readInt();\n+        int hllBuckets = input.readInt();\n+        int minhashSize = input.readInt();\n+        int totalHllSize = input.readInt();\n+\n+        int[] hllSizes = new int[minhashSize];\n+        long[] keys = new long[minhashSize];\n+        input.readBytes(wrappedIntArray(hllSizes));\n+        input.readBytes(wrappedLongArray(keys));\n+\n+        Slice allSerializedHlls = input.readSlice(totalHllSize);\n+\n+        int hllLength;\n+        int index = 0;\n+        Slice serializedHll;\n+        for (int i = 0; i < minhashSize; i++) {\n+            hllLength = hllSizes[i];\n+            serializedHll = allSerializedHlls.slice(index, hllLength);\n+            index += hllLength;\n+            minhash.put(keys[i], HyperLogLog.newInstance(serializedHll));\n+        }\n+\n+        return new KHyperLogLog(maxSize, hllBuckets, minhash);\n+    }\n+\n+    public Slice serialize()\n+    {\n+        try (SliceOutput output = new DynamicSliceOutput(estimatedSerializedSize())) {\n+            Slice serializedHll;\n+            List<Slice> hllSlices = new ArrayList<>();\n+            IntList hllSizes = new IntArrayList();\n+            int totalHllSize = 0;\n+\n+            for (HyperLogLog hll : minhash.values()) {\n+                serializedHll = hll.serialize();\n+                hllSlices.add(serializedHll);\n+                totalHllSize += serializedHll.length();\n+                hllSizes.add(serializedHll.length());\n+            }\n+\n+            Slice hashesSlice = wrappedLongArray(minhash.keySet().toLongArray());\n+            Slice hllSizesSlice = wrappedIntArray(hllSizes.toIntArray());\n+\n+            output.appendByte(VERSION_BYTE);\n+            output.appendInt(maxSize);\n+            output.appendInt(hllBuckets);\n+            output.appendInt(minhash.size());\n+            output.appendInt(totalHllSize);\n+            output.appendBytes(hllSizesSlice);\n+            output.appendBytes(hashesSlice);\n+            for (Slice hllSlice : hllSlices) {\n+                output.appendBytes(hllSlice);\n+            }\n+\n+            return output.slice();\n+        }\n+        catch (IOException e) {\n+            throw new UncheckedIOException(e);\n+        }\n+    }\n+\n+    public static long exactIntersectionCardinality(KHyperLogLog a, KHyperLogLog b)\n+    {\n+        checkState(a.isExact(), \"exact intersection cannot operate on approximate sets\");\n+        checkArgument(b.isExact(), \"exact intersection cannot operate on approximate sets\");\n+\n+        return Sets.intersection(a.minhash.keySet(), b.minhash.keySet()).size();\n+    }\n+\n+    public static double jaccardIndex(KHyperLogLog a, KHyperLogLog b)\n+    {\n+        int sizeOfSmallerSet = Math.min(a.minhash.size(), b.minhash.size());\n+        LongSortedSet minUnion = new LongRBTreeSet(a.minhash.keySet());\n+        minUnion.addAll(b.minhash.keySet());\n+\n+        int intersection = 0;\n+        int i = 0;\n+\n+        LongIterator iterator = minUnion.iterator();\n+        while (iterator.hasNext()) {\n+            long key = iterator.nextLong();\n+            if (a.minhash.containsKey(key) && b.minhash.containsKey(key)) {\n+                intersection++;\n+            }\n+            i++;\n+            if (i >= sizeOfSmallerSet) {\n+                break;\n+            }\n+        }\n+        return intersection / (double) sizeOfSmallerSet;\n+    }\n+\n+    public static KHyperLogLog merge(KHyperLogLog khll1, KHyperLogLog khll2)\n+    {\n+        /*\n+        Return the one with smallest K so resolution is not lost. This loss would happen in the case\n+        one merged a smaller KHLL into a bigger one because the former's minhash struct won't\n+        cover all of the latter's minhash space.\n+         */\n+        if (khll1.maxSize <= khll2.maxSize) {\n+            return khll1.mergeWith(khll2);\n+        }\n+        return khll2.mergeWith(khll1);\n+    }\n+\n+    public boolean isExact()\n+    {\n+        return minhash.size() < maxSize;\n+    }\n+\n+    public long getMinhashSize()\n+    {\n+        return minhash.size();\n+    }\n+\n+    public int estimatedInMemorySize()\n+    {\n+        return SIZE_OF_KHYPERLOGLOG +\n+                SIZE_OF_RBTREEMAP +\n+                minhash.size() * SIZE_OF_LONG +\n+                hllsTotalEstimatedInMemorySize * SIZE_OF_BYTE;\n+    }\n+\n+    public int estimatedSerializedSize()\n+    {\n+        return SIZE_OF_BYTE +\n+                4 * SIZE_OF_INT +\n+                minhash.size() * (SIZE_OF_LONG + SIZE_OF_INT) +\n+                hllsTotalEstimatedSerializedSize * SIZE_OF_BYTE;\n+    }\n+\n+    public void add(long value, long uii)\n+    {\n+        update(Murmur3Hash128.hash64(value), uii);\n+    }\n+\n+    public void add(Slice value, long uii)\n+    {\n+        update(Murmur3Hash128.hash64(value), uii);\n+    }\n+\n+    private void update(long hash, long uii)\n+    {\n+        if (!(minhash.containsKey(hash) || isExact() || hash < minhash.lastLongKey())) {\n+            return;\n+        }\n+\n+        HyperLogLog hll = minhash.computeIfAbsent(hash, k -> {\n+            HyperLogLog newHll = HyperLogLog.newInstance(hllBuckets);\n+            increaseTotalHllSize(newHll);\n+            return newHll;\n+        });\n+\n+        decreaseTotalHllSize(hll);\n+        hll.add(uii);\n+        increaseTotalHllSize(hll);\n+\n+        removeOverflowEntries();\n+    }\n+\n+    public long cardinality()\n+    {\n+        if (isExact()) {\n+            return minhash.size();\n+        }\n+\n+        // Intuition is: get the stored hashes' density, and extrapolate to the whole Hash output range.\n+        // Since Hash output range (2^64) cannot be stored in long type, I use half of the range\n+        // via Long.MAX_VALUE and also divide the hash values' density by 2. The \"-1\" is bias correction\n+        // detailed in \"On Synopses for Distinct-Value Estimation Under Multiset Operations\" by Beyer et. al.\n+        long hashesRange = minhash.lastLongKey() - Long.MIN_VALUE;\n+        double halfDensity = Long.divideUnsigned(hashesRange, minhash.size()) / 2D;\n+        return (long) (HASH_OUTPUT_HALF_RANGE / halfDensity);\n+    }\n+\n+    public KHyperLogLog mergeWith(KHyperLogLog other)\n+    {\n+        LongIterator iterator = other.minhash.keySet().iterator();\n+        while (iterator.hasNext()) {\n+            long key = iterator.nextLong();\n+            HyperLogLog thisHll = minhash.get(key);\n+            HyperLogLog otherHll = other.minhash.get(key);\n+            if (minhash.containsKey(key)) {\n+                decreaseTotalHllSize(thisHll);\n+                thisHll.mergeWith(otherHll);\n+                increaseTotalHllSize(thisHll);\n+            }\n+            else {\n+                minhash.put(key, otherHll);\n+                increaseTotalHllSize(otherHll);\n+            }\n+        }\n+\n+        removeOverflowEntries();\n+\n+        return this;\n+    }\n+\n+    public double reidentificationPotential(long threshold)\n+    {\n+        int highlyUniqueValues = 0;\n+        for (HyperLogLog hll : minhash.values()) {\n+            if (hll.cardinality() <= threshold) {\n+                highlyUniqueValues++;\n+            }\n+        }\n+        return (double) highlyUniqueValues / minhash.size();\n+    }\n+\n+    public Long2DoubleMap uniquenessDistribution()\n+    {\n+        return uniquenessDistribution(minhash.size());\n+    }\n+\n+    public Long2DoubleMap uniquenessDistribution(long histogramSize)\n+    {\n+        Long2DoubleMap out = new Long2DoubleOpenHashMap();\n+        PrimitiveIterator.OfLong iterator = LongStream.rangeClosed(1, histogramSize).iterator();\n+        while (iterator.hasNext()) {\n+            // Initialize all entries to zero\n+            out.put(iterator.nextLong(), 0D);\n+        }\n+\n+        int size = minhash.size();\n+        for (HyperLogLog hll : minhash.values()) {\n+            long bucket = Math.min(hll.cardinality(), histogramSize);\n+            out.merge(bucket, (double) 1 / size, Double::sum);\n+        }\n+        return out;\n+    }\n+\n+    private void removeOverflowEntries()\n+    {\n+        while (minhash.size() > maxSize) {\n+            HyperLogLog hll = minhash.remove(minhash.lastLongKey());\n+            decreaseTotalHllSize(hll);\n+        }\n+    }\n+\n+    private void decreaseTotalHllSize(HyperLogLog hll)", "originalCommit": "488aa18b8f637ccd46b6253158476826d2c69cde", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg4ODQzMA==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r387888430", "bodyText": "But then we would need one method call for InMemory size and one method call for serialized size", "author": "mcorreaiz", "createdAt": "2020-03-04T19:34:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQ4Nzc2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQ5MDA5NQ==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r387490095", "bodyText": "Let's throw a PrestoException(NOT_SUPPORTED, as IllegalArgumentException will surface as an internal error in Presto.", "author": "tdcmeehan", "createdAt": "2020-03-04T07:33:16Z", "path": "presto-main/src/main/java/com/facebook/presto/type/khyperloglog/KHyperLogLogStateFactory.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.facebook.presto.type.khyperloglog;\n+\n+import com.facebook.presto.array.ObjectBigArray;\n+import com.facebook.presto.spi.function.AccumulatorStateFactory;\n+import com.facebook.presto.spi.function.GroupedAccumulatorState;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+public class KHyperLogLogStateFactory\n+        implements AccumulatorStateFactory<KHyperLogLogState>\n+{\n+    private static final int SIZE_OF_SINGLE = ClassLayout.parseClass(SingleKHyperLogLogState.class).instanceSize();\n+    private static final int SIZE_OF_GROUPED = ClassLayout.parseClass(GroupedKHyperLogLogState.class).instanceSize();\n+\n+    @Override\n+    public KHyperLogLogState createSingleState()\n+    {\n+        return new SingleKHyperLogLogState();\n+    }\n+\n+    @Override\n+    public Class<? extends KHyperLogLogState> getSingleStateClass()\n+    {\n+        return SingleKHyperLogLogState.class;\n+    }\n+\n+    @Override\n+    public KHyperLogLogState createGroupedState()\n+    {\n+        throw new IllegalArgumentException(\"GROUP BY of KHyperLogLog is not supported.\");", "originalCommit": "488aa18b8f637ccd46b6253158476826d2c69cde", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg4OTI1NA==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r387889254", "bodyText": "OK!", "author": "mcorreaiz", "createdAt": "2020-03-04T19:36:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQ5MDA5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQ5MDY0OA==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r387490648", "bodyText": "Formatting is off here", "author": "tdcmeehan", "createdAt": "2020-03-04T07:34:58Z", "path": "presto-main/src/main/java/com/facebook/presto/type/khyperloglog/KHyperLogLog.java", "diffHunk": "@@ -0,0 +1,351 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.facebook.presto.type.khyperloglog;\n+\n+import com.facebook.airlift.stats.cardinality.HyperLogLog;\n+import com.google.common.collect.Sets;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Murmur3Hash128;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import io.airlift.slice.SliceOutput;\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import it.unimi.dsi.fastutil.longs.Long2DoubleMap;\n+import it.unimi.dsi.fastutil.longs.Long2DoubleOpenHashMap;\n+import it.unimi.dsi.fastutil.longs.Long2ObjectRBTreeMap;\n+import it.unimi.dsi.fastutil.longs.Long2ObjectSortedMap;\n+import it.unimi.dsi.fastutil.longs.LongIterator;\n+import it.unimi.dsi.fastutil.longs.LongRBTreeSet;\n+import it.unimi.dsi.fastutil.longs.LongSortedSet;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.PrimitiveIterator;\n+import java.util.stream.LongStream;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static io.airlift.slice.SizeOf.SIZE_OF_BYTE;\n+import static io.airlift.slice.SizeOf.SIZE_OF_INT;\n+import static io.airlift.slice.SizeOf.SIZE_OF_LONG;\n+import static io.airlift.slice.Slices.wrappedIntArray;\n+import static io.airlift.slice.Slices.wrappedLongArray;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * For reference on KHyperLogLog, see \"KHyperLogLog: Estimating Reidentifiability and\n+ * Joinability of Large Data at Scale\" by Chia et al., 2019.\n+ */\n+public class KHyperLogLog\n+{\n+    public static final int DEFAULT_HLL_BUCKETS = 256;\n+    public static final int DEFAULT_MAX_SIZE = 4096;\n+    private static final byte VERSION_BYTE = 1;\n+    private static final long HASH_OUTPUT_HALF_RANGE = Long.MAX_VALUE;\n+    private static final int SIZE_OF_KHYPERLOGLOG = ClassLayout.parseClass(KHyperLogLog.class).instanceSize();\n+    private static final int SIZE_OF_RBTREEMAP = ClassLayout.parseClass(Long2ObjectRBTreeMap.class).instanceSize();\n+\n+    private final Long2ObjectSortedMap<HyperLogLog> minhash;\n+    private final int maxSize;\n+    private final int hllBuckets;\n+\n+    private int hllsTotalEstimatedInMemorySize;\n+    private int hllsTotalEstimatedSerializedSize;\n+\n+    public KHyperLogLog()\n+    {\n+        this(DEFAULT_MAX_SIZE, DEFAULT_HLL_BUCKETS, new Long2ObjectRBTreeMap<>());\n+    }\n+\n+    public KHyperLogLog(int maxSize, int hllBuckets)\n+    {\n+        this(maxSize, hllBuckets, new Long2ObjectRBTreeMap<>());\n+    }\n+\n+    public KHyperLogLog(int maxSize, int hllBuckets, Long2ObjectSortedMap<HyperLogLog> minhash)\n+    {\n+        this.maxSize = maxSize;\n+        this.hllBuckets = hllBuckets;\n+        this.minhash = requireNonNull(minhash, \"minhash is null\");\n+        hllsTotalEstimatedInMemorySize = 0;\n+        hllsTotalEstimatedSerializedSize = 0;\n+\n+        for (HyperLogLog hll : minhash.values()) {\n+            increaseTotalHllSize(hll);\n+        }\n+    }\n+\n+    public static KHyperLogLog newInstance(Slice serialized)\n+    {\n+        requireNonNull(serialized, \"serialized is null\");\n+        SliceInput input = serialized.getInput();\n+        checkArgument(input.readByte() == VERSION_BYTE, \"Unexpected version\");\n+        Long2ObjectRBTreeMap<HyperLogLog> minhash = new Long2ObjectRBTreeMap<>();\n+\n+        int maxSize = input.readInt();\n+        int hllBuckets = input.readInt();\n+        int minhashSize = input.readInt();\n+        int totalHllSize = input.readInt();\n+\n+        int[] hllSizes = new int[minhashSize];\n+        long[] keys = new long[minhashSize];\n+        input.readBytes(wrappedIntArray(hllSizes));\n+        input.readBytes(wrappedLongArray(keys));\n+\n+        Slice allSerializedHlls = input.readSlice(totalHllSize);\n+\n+        int hllLength;\n+        int index = 0;\n+        Slice serializedHll;\n+        for (int i = 0; i < minhashSize; i++) {\n+            hllLength = hllSizes[i];\n+            serializedHll = allSerializedHlls.slice(index, hllLength);\n+            index += hllLength;\n+            minhash.put(keys[i], HyperLogLog.newInstance(serializedHll));\n+        }\n+\n+        return new KHyperLogLog(maxSize, hllBuckets, minhash);\n+    }\n+\n+    public Slice serialize()\n+    {\n+        try (SliceOutput output = new DynamicSliceOutput(estimatedSerializedSize())) {\n+            Slice serializedHll;\n+            List<Slice> hllSlices = new ArrayList<>();\n+            IntList hllSizes = new IntArrayList();\n+            int totalHllSize = 0;\n+\n+            for (HyperLogLog hll : minhash.values()) {\n+                serializedHll = hll.serialize();\n+                hllSlices.add(serializedHll);\n+                totalHllSize += serializedHll.length();\n+                hllSizes.add(serializedHll.length());\n+            }\n+\n+            Slice hashesSlice = wrappedLongArray(minhash.keySet().toLongArray());\n+            Slice hllSizesSlice = wrappedIntArray(hllSizes.toIntArray());\n+\n+            output.appendByte(VERSION_BYTE);\n+            output.appendInt(maxSize);\n+            output.appendInt(hllBuckets);\n+            output.appendInt(minhash.size());\n+            output.appendInt(totalHllSize);\n+            output.appendBytes(hllSizesSlice);\n+            output.appendBytes(hashesSlice);\n+            for (Slice hllSlice : hllSlices) {\n+                output.appendBytes(hllSlice);\n+            }\n+\n+            return output.slice();\n+        }\n+        catch (IOException e) {\n+            throw new UncheckedIOException(e);\n+        }\n+    }\n+\n+    public static long exactIntersectionCardinality(KHyperLogLog a, KHyperLogLog b)\n+    {\n+        checkState(a.isExact(), \"exact intersection cannot operate on approximate sets\");\n+        checkArgument(b.isExact(), \"exact intersection cannot operate on approximate sets\");\n+\n+        return Sets.intersection(a.minhash.keySet(), b.minhash.keySet()).size();\n+    }\n+\n+    public static double jaccardIndex(KHyperLogLog a, KHyperLogLog b)\n+    {\n+        int sizeOfSmallerSet = Math.min(a.minhash.size(), b.minhash.size());\n+        LongSortedSet minUnion = new LongRBTreeSet(a.minhash.keySet());\n+        minUnion.addAll(b.minhash.keySet());\n+\n+        int intersection = 0;\n+        int i = 0;\n+\n+        LongIterator iterator = minUnion.iterator();\n+        while (iterator.hasNext()) {\n+            long key = iterator.nextLong();\n+            if (a.minhash.containsKey(key) && b.minhash.containsKey(key)) {\n+                intersection++;\n+            }\n+            i++;\n+            if (i >= sizeOfSmallerSet) {\n+                break;\n+            }\n+        }\n+        return intersection / (double) sizeOfSmallerSet;\n+    }\n+\n+    public static KHyperLogLog merge(KHyperLogLog khll1, KHyperLogLog khll2)\n+    {\n+        /*\n+        Return the one with smallest K so resolution is not lost. This loss would happen in the case", "originalCommit": "488aa18b8f637ccd46b6253158476826d2c69cde", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk1ODYxNQ==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r387958615", "bodyText": "Got it", "author": "mcorreaiz", "createdAt": "2020-03-04T21:56:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQ5MDY0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQ5MTc3NA==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r387491774", "bodyText": "Can we remove this class entirely?", "author": "tdcmeehan", "createdAt": "2020-03-04T07:38:24Z", "path": "presto-main/src/main/java/com/facebook/presto/type/khyperloglog/KHyperLogLogStateFactory.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.facebook.presto.type.khyperloglog;\n+\n+import com.facebook.presto.array.ObjectBigArray;\n+import com.facebook.presto.spi.function.AccumulatorStateFactory;\n+import com.facebook.presto.spi.function.GroupedAccumulatorState;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+public class KHyperLogLogStateFactory\n+        implements AccumulatorStateFactory<KHyperLogLogState>\n+{\n+    private static final int SIZE_OF_SINGLE = ClassLayout.parseClass(SingleKHyperLogLogState.class).instanceSize();\n+    private static final int SIZE_OF_GROUPED = ClassLayout.parseClass(GroupedKHyperLogLogState.class).instanceSize();\n+\n+    @Override\n+    public KHyperLogLogState createSingleState()\n+    {\n+        return new SingleKHyperLogLogState();\n+    }\n+\n+    @Override\n+    public Class<? extends KHyperLogLogState> getSingleStateClass()\n+    {\n+        return SingleKHyperLogLogState.class;\n+    }\n+\n+    @Override\n+    public KHyperLogLogState createGroupedState()\n+    {\n+        throw new IllegalArgumentException(\"GROUP BY of KHyperLogLog is not supported.\");\n+    }\n+\n+    @Override\n+    public Class<? extends KHyperLogLogState> getGroupedStateClass()\n+    {\n+        return GroupedKHyperLogLogState.class;\n+    }\n+\n+    public static class GroupedKHyperLogLogState", "originalCommit": "488aa18b8f637ccd46b6253158476826d2c69cde", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg5NTgzNw==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r387895837", "bodyText": "Will do", "author": "mcorreaiz", "createdAt": "2020-03-04T19:48:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQ5MTc3NA=="}], "type": "inlineReview"}, {"oid": "5bedbf65b5ba0f6e80c8d8ada8d09e7a67b5b6ad", "url": "https://github.com/prestodb/presto/commit/5bedbf65b5ba0f6e80c8d8ada8d09e7a67b5b6ad", "message": "Merge branch 'master' of github.com:prestodb/presto", "committedDate": "2020-03-04T23:45:11Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODQ0NTEzMQ==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r388445131", "bodyText": "Nit: I would call this KHyperLogLogAggregationFunction", "author": "tdcmeehan", "createdAt": "2020-03-05T17:24:11Z", "path": "presto-main/src/main/java/com/facebook/presto/type/khyperloglog/BuildKHyperLogLogAggregation.java", "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.facebook.presto.type.khyperloglog;\n+\n+import com.facebook.presto.spi.block.BlockBuilder;\n+import com.facebook.presto.spi.function.AggregationFunction;\n+import com.facebook.presto.spi.function.AggregationState;\n+import com.facebook.presto.spi.function.CombineFunction;\n+import com.facebook.presto.spi.function.InputFunction;\n+import com.facebook.presto.spi.function.LiteralParameters;\n+import com.facebook.presto.spi.function.OutputFunction;\n+import com.facebook.presto.spi.function.SqlType;\n+import com.facebook.presto.spi.type.StandardTypes;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.XxHash64;\n+\n+@AggregationFunction(\"khyperloglog_agg\")\n+public final class BuildKHyperLogLogAggregation", "originalCommit": "5bedbf65b5ba0f6e80c8d8ada8d09e7a67b5b6ad", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "caa0320efafc6730c92a21a6aaa44a0fbd882899", "url": "https://github.com/prestodb/presto/commit/caa0320efafc6730c92a21a6aaa44a0fbd882899", "message": "Merge branch 'master' of github.com:prestodb/presto", "committedDate": "2020-03-05T19:32:33Z", "type": "forcePushed"}, {"oid": "0f7e4a8b062cc7c6b8a9c2a42f5302a648eeed4a", "url": "https://github.com/prestodb/presto/commit/0f7e4a8b062cc7c6b8a9c2a42f5302a648eeed4a", "message": "Add allocation info to Task/Stage/QueryStats", "committedDate": "2020-03-05T20:50:04Z", "type": "forcePushed"}, {"oid": "fe31d7f73380a0b140a935c49a8dfb1299d508f4", "url": "https://github.com/prestodb/presto/commit/fe31d7f73380a0b140a935c49a8dfb1299d508f4", "message": "Create first limited working version of KHLL\n\nType is created with its aggregation build method. The only scalar function\nsupported so far is cardinality. Memory layout for mapping from the MinHash\nstructure to the HLL sketches is done naively with RBTreeMap.", "committedDate": "2020-03-05T20:50:02Z", "type": "forcePushed"}, {"oid": "661115198a2e98055273353f0c9dcc5a23931555", "url": "https://github.com/prestodb/presto/commit/661115198a2e98055273353f0c9dcc5a23931555", "message": "Create KHyperLogLog type\n\nInclude aggregate function to instantiate this type and scalar functions to operate over it.\nRefer to https://github.com/prestodb/presto/issues/14035", "committedDate": "2020-03-05T21:56:40Z", "type": "forcePushed"}, {"oid": "d3667f0ef1628dc0e910a8ecd00deaee16bd246f", "url": "https://github.com/prestodb/presto/commit/d3667f0ef1628dc0e910a8ecd00deaee16bd246f", "message": "Create KHyperLogLog type\n\nInclude aggregate function to instantiate this type and scalar functions to operate over it.\nRefer to https://github.com/prestodb/presto/issues/14035", "committedDate": "2020-03-05T22:08:32Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODYyNjM3Mw==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r388626373", "bodyText": "Seems unrelated change but it does not bother me as much.", "author": "shixuan-fan", "createdAt": "2020-03-05T23:32:21Z", "path": "presto-main/src/main/java/com/facebook/presto/type/TypeRegistry.java", "diffHunk": "@@ -103,10 +105,8 @@\n     private final ConcurrentMap<TypeSignature, Type> types = new ConcurrentHashMap<>();\n     private final ConcurrentMap<String, ParametricType> parametricTypes = new ConcurrentHashMap<>();\n     private final FeaturesConfig featuresConfig;\n-\n-    private FunctionManager functionManager;\n-\n     private final LoadingCache<TypeSignature, Type> parametricTypeCache;\n+    private FunctionManager functionManager;", "originalCommit": "d3667f0ef1628dc0e910a8ecd00deaee16bd246f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODYzMzQ4OQ==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r388633489", "bodyText": "Reverted.", "author": "mcorreaiz", "createdAt": "2020-03-05T23:56:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODYyNjM3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODYyNjYzNQ==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r388626635", "bodyText": "nit: unrelated code move?", "author": "shixuan-fan", "createdAt": "2020-03-05T23:33:20Z", "path": "presto-main/src/main/java/com/facebook/presto/type/TypeRegistry.java", "diffHunk": "@@ -362,6 +363,17 @@ private static Type getCommonSuperTypeForChar(CharType firstType, CharType secon\n         return createCharType(Math.max(firstType.getLength(), secondType.getLength()));\n     }\n \n+    private static boolean isCovariantParametrizedType(Type type)", "originalCommit": "d3667f0ef1628dc0e910a8ecd00deaee16bd246f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODYzMzU4NA==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r388633584", "bodyText": "Reverted (it was made by IntelliJ autoformat)", "author": "mcorreaiz", "createdAt": "2020-03-05T23:57:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODYyNjYzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODYyOTIzNw==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r388629237", "bodyText": "Out of curiosity, where does this -1 bias correction kick in within the code?", "author": "shixuan-fan", "createdAt": "2020-03-05T23:42:21Z", "path": "presto-main/src/main/java/com/facebook/presto/type/khyperloglog/KHyperLogLog.java", "diffHunk": "@@ -0,0 +1,349 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.facebook.presto.type.khyperloglog;\n+\n+import com.facebook.airlift.stats.cardinality.HyperLogLog;\n+import com.google.common.collect.Sets;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Murmur3Hash128;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import io.airlift.slice.SliceOutput;\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import it.unimi.dsi.fastutil.longs.Long2DoubleMap;\n+import it.unimi.dsi.fastutil.longs.Long2DoubleOpenHashMap;\n+import it.unimi.dsi.fastutil.longs.Long2ObjectRBTreeMap;\n+import it.unimi.dsi.fastutil.longs.Long2ObjectSortedMap;\n+import it.unimi.dsi.fastutil.longs.LongIterator;\n+import it.unimi.dsi.fastutil.longs.LongRBTreeSet;\n+import it.unimi.dsi.fastutil.longs.LongSortedSet;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.PrimitiveIterator;\n+import java.util.stream.LongStream;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static io.airlift.slice.SizeOf.SIZE_OF_BYTE;\n+import static io.airlift.slice.SizeOf.SIZE_OF_INT;\n+import static io.airlift.slice.SizeOf.SIZE_OF_LONG;\n+import static io.airlift.slice.Slices.wrappedIntArray;\n+import static io.airlift.slice.Slices.wrappedLongArray;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * For reference on KHyperLogLog, see \"KHyperLogLog: Estimating Reidentifiability and\n+ * Joinability of Large Data at Scale\" by Chia et al., 2019.\n+ */\n+public class KHyperLogLog\n+{\n+    public static final int DEFAULT_HLL_BUCKETS = 256;\n+    public static final int DEFAULT_MAX_SIZE = 4096;\n+    private static final byte VERSION_BYTE = 1;\n+    private static final long HASH_OUTPUT_HALF_RANGE = Long.MAX_VALUE;\n+    private static final int SIZE_OF_KHYPERLOGLOG = ClassLayout.parseClass(KHyperLogLog.class).instanceSize();\n+    private static final int SIZE_OF_RBTREEMAP = ClassLayout.parseClass(Long2ObjectRBTreeMap.class).instanceSize();\n+\n+    private final Long2ObjectSortedMap<HyperLogLog> minhash;\n+    private final int maxSize;\n+    private final int hllBuckets;\n+\n+    private int hllsTotalEstimatedInMemorySize;\n+    private int hllsTotalEstimatedSerializedSize;\n+\n+    public KHyperLogLog()\n+    {\n+        this(DEFAULT_MAX_SIZE, DEFAULT_HLL_BUCKETS, new Long2ObjectRBTreeMap<>());\n+    }\n+\n+    public KHyperLogLog(int maxSize, int hllBuckets)\n+    {\n+        this(maxSize, hllBuckets, new Long2ObjectRBTreeMap<>());\n+    }\n+\n+    public KHyperLogLog(int maxSize, int hllBuckets, Long2ObjectSortedMap<HyperLogLog> minhash)\n+    {\n+        this.maxSize = maxSize;\n+        this.hllBuckets = hllBuckets;\n+        this.minhash = requireNonNull(minhash, \"minhash is null\");\n+        hllsTotalEstimatedInMemorySize = 0;\n+        hllsTotalEstimatedSerializedSize = 0;\n+\n+        for (HyperLogLog hll : minhash.values()) {\n+            increaseTotalHllSize(hll);\n+        }\n+    }\n+\n+    public static KHyperLogLog newInstance(Slice serialized)\n+    {\n+        requireNonNull(serialized, \"serialized is null\");\n+        SliceInput input = serialized.getInput();\n+        checkArgument(input.readByte() == VERSION_BYTE, \"Unexpected version\");\n+        Long2ObjectRBTreeMap<HyperLogLog> minhash = new Long2ObjectRBTreeMap<>();\n+\n+        int maxSize = input.readInt();\n+        int hllBuckets = input.readInt();\n+        int minhashSize = input.readInt();\n+        int totalHllSize = input.readInt();\n+\n+        int[] hllSizes = new int[minhashSize];\n+        long[] keys = new long[minhashSize];\n+        input.readBytes(wrappedIntArray(hllSizes));\n+        input.readBytes(wrappedLongArray(keys));\n+\n+        Slice allSerializedHlls = input.readSlice(totalHllSize);\n+\n+        int hllLength;\n+        int index = 0;\n+        Slice serializedHll;\n+        for (int i = 0; i < minhashSize; i++) {\n+            hllLength = hllSizes[i];\n+            serializedHll = allSerializedHlls.slice(index, hllLength);\n+            index += hllLength;\n+            minhash.put(keys[i], HyperLogLog.newInstance(serializedHll));\n+        }\n+\n+        return new KHyperLogLog(maxSize, hllBuckets, minhash);\n+    }\n+\n+    public Slice serialize()\n+    {\n+        try (SliceOutput output = new DynamicSliceOutput(estimatedSerializedSize())) {\n+            Slice serializedHll;\n+            List<Slice> hllSlices = new ArrayList<>();\n+            IntList hllSizes = new IntArrayList();\n+            int totalHllSize = 0;\n+\n+            for (HyperLogLog hll : minhash.values()) {\n+                serializedHll = hll.serialize();\n+                hllSlices.add(serializedHll);\n+                totalHllSize += serializedHll.length();\n+                hllSizes.add(serializedHll.length());\n+            }\n+\n+            Slice hashesSlice = wrappedLongArray(minhash.keySet().toLongArray());\n+            Slice hllSizesSlice = wrappedIntArray(hllSizes.toIntArray());\n+\n+            output.appendByte(VERSION_BYTE);\n+            output.appendInt(maxSize);\n+            output.appendInt(hllBuckets);\n+            output.appendInt(minhash.size());\n+            output.appendInt(totalHllSize);\n+            output.appendBytes(hllSizesSlice);\n+            output.appendBytes(hashesSlice);\n+            for (Slice hllSlice : hllSlices) {\n+                output.appendBytes(hllSlice);\n+            }\n+\n+            return output.slice();\n+        }\n+        catch (IOException e) {\n+            throw new UncheckedIOException(e);\n+        }\n+    }\n+\n+    public static long exactIntersectionCardinality(KHyperLogLog a, KHyperLogLog b)\n+    {\n+        checkState(a.isExact(), \"exact intersection cannot operate on approximate sets\");\n+        checkArgument(b.isExact(), \"exact intersection cannot operate on approximate sets\");\n+\n+        return Sets.intersection(a.minhash.keySet(), b.minhash.keySet()).size();\n+    }\n+\n+    public static double jaccardIndex(KHyperLogLog a, KHyperLogLog b)\n+    {\n+        int sizeOfSmallerSet = Math.min(a.minhash.size(), b.minhash.size());\n+        LongSortedSet minUnion = new LongRBTreeSet(a.minhash.keySet());\n+        minUnion.addAll(b.minhash.keySet());\n+\n+        int intersection = 0;\n+        int i = 0;\n+\n+        LongIterator iterator = minUnion.iterator();\n+        while (iterator.hasNext()) {\n+            long key = iterator.nextLong();\n+            if (a.minhash.containsKey(key) && b.minhash.containsKey(key)) {\n+                intersection++;\n+            }\n+            i++;\n+            if (i >= sizeOfSmallerSet) {\n+                break;\n+            }\n+        }\n+        return intersection / (double) sizeOfSmallerSet;\n+    }\n+\n+    public static KHyperLogLog merge(KHyperLogLog khll1, KHyperLogLog khll2)\n+    {\n+         // Return the one with smallest K so resolution is not lost. This loss would happen in the case\n+         // one merged a smaller KHLL into a bigger one because the former's minhash struct won't\n+         // cover all of the latter's minhash space.\n+        if (khll1.maxSize <= khll2.maxSize) {\n+            return khll1.mergeWith(khll2);\n+        }\n+        return khll2.mergeWith(khll1);\n+    }\n+\n+    public boolean isExact()\n+    {\n+        return minhash.size() < maxSize;\n+    }\n+\n+    public long getMinhashSize()\n+    {\n+        return minhash.size();\n+    }\n+\n+    public int estimatedInMemorySize()\n+    {\n+        return SIZE_OF_KHYPERLOGLOG +\n+                SIZE_OF_RBTREEMAP +\n+                minhash.size() * SIZE_OF_LONG +\n+                hllsTotalEstimatedInMemorySize * SIZE_OF_BYTE;\n+    }\n+\n+    public int estimatedSerializedSize()\n+    {\n+        return SIZE_OF_BYTE +\n+                4 * SIZE_OF_INT +\n+                minhash.size() * (SIZE_OF_LONG + SIZE_OF_INT) +\n+                hllsTotalEstimatedSerializedSize * SIZE_OF_BYTE;\n+    }\n+\n+    public void add(long value, long uii)\n+    {\n+        update(Murmur3Hash128.hash64(value), uii);\n+    }\n+\n+    public void add(Slice value, long uii)\n+    {\n+        update(Murmur3Hash128.hash64(value), uii);\n+    }\n+\n+    private void update(long hash, long uii)\n+    {\n+        if (!(minhash.containsKey(hash) || isExact() || hash < minhash.lastLongKey())) {\n+            return;\n+        }\n+\n+        HyperLogLog hll = minhash.computeIfAbsent(hash, k -> {\n+            HyperLogLog newHll = HyperLogLog.newInstance(hllBuckets);\n+            increaseTotalHllSize(newHll);\n+            return newHll;\n+        });\n+\n+        decreaseTotalHllSize(hll);\n+        hll.add(uii);\n+        increaseTotalHllSize(hll);\n+\n+        removeOverflowEntries();\n+    }\n+\n+    public long cardinality()\n+    {\n+        if (isExact()) {\n+            return minhash.size();\n+        }\n+\n+        // Intuition is: get the stored hashes' density, and extrapolate to the whole Hash output range.\n+        // Since Hash output range (2^64) cannot be stored in long type, I use half of the range\n+        // via Long.MAX_VALUE and also divide the hash values' density by 2. The \"-1\" is bias correction", "originalCommit": "d3667f0ef1628dc0e910a8ecd00deaee16bd246f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODYzMzg4OQ==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r388633889", "bodyText": "Thanks for pointing out! Must've missed it in some revision. I included it back.", "author": "mcorreaiz", "createdAt": "2020-03-05T23:58:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODYyOTIzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIwMjE0OQ==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r389202149", "bodyText": "Is it possible to have a test that could catch this? Sorry I'm not familiar with HLL so if it is not possible then that's fine.", "author": "shixuan-fan", "createdAt": "2020-03-07T00:16:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODYyOTIzNw=="}], "type": "inlineReview"}, {"oid": "18e507419eb8c7d4e32b575963d0b8926461776d", "url": "https://github.com/prestodb/presto/commit/18e507419eb8c7d4e32b575963d0b8926461776d", "message": "Create KHyperLogLog type\n\nInclude aggregate function to instantiate this type and scalar functions to operate over it.\nRefer to https://github.com/prestodb/presto/issues/14035", "committedDate": "2020-03-05T23:59:07Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIwMDUwNQ==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r389200505", "bodyText": "Maybe initialize these two to 0 here instead of in the constructor?", "author": "shixuan-fan", "createdAt": "2020-03-07T00:07:50Z", "path": "presto-main/src/main/java/com/facebook/presto/type/khyperloglog/KHyperLogLog.java", "diffHunk": "@@ -0,0 +1,349 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.facebook.presto.type.khyperloglog;\n+\n+import com.facebook.airlift.stats.cardinality.HyperLogLog;\n+import com.google.common.collect.Sets;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Murmur3Hash128;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import io.airlift.slice.SliceOutput;\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import it.unimi.dsi.fastutil.longs.Long2DoubleMap;\n+import it.unimi.dsi.fastutil.longs.Long2DoubleOpenHashMap;\n+import it.unimi.dsi.fastutil.longs.Long2ObjectRBTreeMap;\n+import it.unimi.dsi.fastutil.longs.Long2ObjectSortedMap;\n+import it.unimi.dsi.fastutil.longs.LongIterator;\n+import it.unimi.dsi.fastutil.longs.LongRBTreeSet;\n+import it.unimi.dsi.fastutil.longs.LongSortedSet;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.PrimitiveIterator;\n+import java.util.stream.LongStream;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static io.airlift.slice.SizeOf.SIZE_OF_BYTE;\n+import static io.airlift.slice.SizeOf.SIZE_OF_INT;\n+import static io.airlift.slice.SizeOf.SIZE_OF_LONG;\n+import static io.airlift.slice.Slices.wrappedIntArray;\n+import static io.airlift.slice.Slices.wrappedLongArray;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * For reference on KHyperLogLog, see \"KHyperLogLog: Estimating Reidentifiability and\n+ * Joinability of Large Data at Scale\" by Chia et al., 2019.\n+ */\n+public class KHyperLogLog\n+{\n+    public static final int DEFAULT_HLL_BUCKETS = 256;\n+    public static final int DEFAULT_MAX_SIZE = 4096;\n+    private static final byte VERSION_BYTE = 1;\n+    private static final long HASH_OUTPUT_HALF_RANGE = Long.MAX_VALUE;\n+    private static final int SIZE_OF_KHYPERLOGLOG = ClassLayout.parseClass(KHyperLogLog.class).instanceSize();\n+    private static final int SIZE_OF_RBTREEMAP = ClassLayout.parseClass(Long2ObjectRBTreeMap.class).instanceSize();\n+\n+    private final Long2ObjectSortedMap<HyperLogLog> minhash;\n+    private final int maxSize;\n+    private final int hllBuckets;\n+\n+    private int hllsTotalEstimatedInMemorySize;", "originalCommit": "18e507419eb8c7d4e32b575963d0b8926461776d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIwNjYyMw==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r389206623", "bodyText": "Ok, looks cleaner", "author": "mcorreaiz", "createdAt": "2020-03-07T00:40:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIwMDUwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIwMDY5Nw==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r389200697", "bodyText": "nit: how about minhash.values().stream().forEach(this:: increaseTotalHllSize)?", "author": "shixuan-fan", "createdAt": "2020-03-07T00:08:38Z", "path": "presto-main/src/main/java/com/facebook/presto/type/khyperloglog/KHyperLogLog.java", "diffHunk": "@@ -0,0 +1,349 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.facebook.presto.type.khyperloglog;\n+\n+import com.facebook.airlift.stats.cardinality.HyperLogLog;\n+import com.google.common.collect.Sets;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Murmur3Hash128;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import io.airlift.slice.SliceOutput;\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import it.unimi.dsi.fastutil.longs.Long2DoubleMap;\n+import it.unimi.dsi.fastutil.longs.Long2DoubleOpenHashMap;\n+import it.unimi.dsi.fastutil.longs.Long2ObjectRBTreeMap;\n+import it.unimi.dsi.fastutil.longs.Long2ObjectSortedMap;\n+import it.unimi.dsi.fastutil.longs.LongIterator;\n+import it.unimi.dsi.fastutil.longs.LongRBTreeSet;\n+import it.unimi.dsi.fastutil.longs.LongSortedSet;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.PrimitiveIterator;\n+import java.util.stream.LongStream;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static io.airlift.slice.SizeOf.SIZE_OF_BYTE;\n+import static io.airlift.slice.SizeOf.SIZE_OF_INT;\n+import static io.airlift.slice.SizeOf.SIZE_OF_LONG;\n+import static io.airlift.slice.Slices.wrappedIntArray;\n+import static io.airlift.slice.Slices.wrappedLongArray;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * For reference on KHyperLogLog, see \"KHyperLogLog: Estimating Reidentifiability and\n+ * Joinability of Large Data at Scale\" by Chia et al., 2019.\n+ */\n+public class KHyperLogLog\n+{\n+    public static final int DEFAULT_HLL_BUCKETS = 256;\n+    public static final int DEFAULT_MAX_SIZE = 4096;\n+    private static final byte VERSION_BYTE = 1;\n+    private static final long HASH_OUTPUT_HALF_RANGE = Long.MAX_VALUE;\n+    private static final int SIZE_OF_KHYPERLOGLOG = ClassLayout.parseClass(KHyperLogLog.class).instanceSize();\n+    private static final int SIZE_OF_RBTREEMAP = ClassLayout.parseClass(Long2ObjectRBTreeMap.class).instanceSize();\n+\n+    private final Long2ObjectSortedMap<HyperLogLog> minhash;\n+    private final int maxSize;\n+    private final int hllBuckets;\n+\n+    private int hllsTotalEstimatedInMemorySize;\n+    private int hllsTotalEstimatedSerializedSize;\n+\n+    public KHyperLogLog()\n+    {\n+        this(DEFAULT_MAX_SIZE, DEFAULT_HLL_BUCKETS, new Long2ObjectRBTreeMap<>());\n+    }\n+\n+    public KHyperLogLog(int maxSize, int hllBuckets)\n+    {\n+        this(maxSize, hllBuckets, new Long2ObjectRBTreeMap<>());\n+    }\n+\n+    public KHyperLogLog(int maxSize, int hllBuckets, Long2ObjectSortedMap<HyperLogLog> minhash)\n+    {\n+        this.maxSize = maxSize;\n+        this.hllBuckets = hllBuckets;\n+        this.minhash = requireNonNull(minhash, \"minhash is null\");\n+        hllsTotalEstimatedInMemorySize = 0;\n+        hllsTotalEstimatedSerializedSize = 0;\n+\n+        for (HyperLogLog hll : minhash.values()) {", "originalCommit": "18e507419eb8c7d4e32b575963d0b8926461776d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIwODY0MA==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r389208640", "bodyText": "Would minhash.values().forEach(this::increaseTotalHllSize) be better?", "author": "mcorreaiz", "createdAt": "2020-03-07T00:54:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIwMDY5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIwOTA5NQ==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r389209095", "bodyText": "Nice catch. Definitely :D", "author": "shixuan-fan", "createdAt": "2020-03-07T00:56:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIwMDY5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIwMTI4Nw==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r389201287", "bodyText": "nit: this could be a local variable in the for loop I think.", "author": "shixuan-fan", "createdAt": "2020-03-07T00:11:33Z", "path": "presto-main/src/main/java/com/facebook/presto/type/khyperloglog/KHyperLogLog.java", "diffHunk": "@@ -0,0 +1,349 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.facebook.presto.type.khyperloglog;\n+\n+import com.facebook.airlift.stats.cardinality.HyperLogLog;\n+import com.google.common.collect.Sets;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Murmur3Hash128;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import io.airlift.slice.SliceOutput;\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import it.unimi.dsi.fastutil.longs.Long2DoubleMap;\n+import it.unimi.dsi.fastutil.longs.Long2DoubleOpenHashMap;\n+import it.unimi.dsi.fastutil.longs.Long2ObjectRBTreeMap;\n+import it.unimi.dsi.fastutil.longs.Long2ObjectSortedMap;\n+import it.unimi.dsi.fastutil.longs.LongIterator;\n+import it.unimi.dsi.fastutil.longs.LongRBTreeSet;\n+import it.unimi.dsi.fastutil.longs.LongSortedSet;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.PrimitiveIterator;\n+import java.util.stream.LongStream;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static io.airlift.slice.SizeOf.SIZE_OF_BYTE;\n+import static io.airlift.slice.SizeOf.SIZE_OF_INT;\n+import static io.airlift.slice.SizeOf.SIZE_OF_LONG;\n+import static io.airlift.slice.Slices.wrappedIntArray;\n+import static io.airlift.slice.Slices.wrappedLongArray;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * For reference on KHyperLogLog, see \"KHyperLogLog: Estimating Reidentifiability and\n+ * Joinability of Large Data at Scale\" by Chia et al., 2019.\n+ */\n+public class KHyperLogLog\n+{\n+    public static final int DEFAULT_HLL_BUCKETS = 256;\n+    public static final int DEFAULT_MAX_SIZE = 4096;\n+    private static final byte VERSION_BYTE = 1;\n+    private static final long HASH_OUTPUT_HALF_RANGE = Long.MAX_VALUE;\n+    private static final int SIZE_OF_KHYPERLOGLOG = ClassLayout.parseClass(KHyperLogLog.class).instanceSize();\n+    private static final int SIZE_OF_RBTREEMAP = ClassLayout.parseClass(Long2ObjectRBTreeMap.class).instanceSize();\n+\n+    private final Long2ObjectSortedMap<HyperLogLog> minhash;\n+    private final int maxSize;\n+    private final int hllBuckets;\n+\n+    private int hllsTotalEstimatedInMemorySize;\n+    private int hllsTotalEstimatedSerializedSize;\n+\n+    public KHyperLogLog()\n+    {\n+        this(DEFAULT_MAX_SIZE, DEFAULT_HLL_BUCKETS, new Long2ObjectRBTreeMap<>());\n+    }\n+\n+    public KHyperLogLog(int maxSize, int hllBuckets)\n+    {\n+        this(maxSize, hllBuckets, new Long2ObjectRBTreeMap<>());\n+    }\n+\n+    public KHyperLogLog(int maxSize, int hllBuckets, Long2ObjectSortedMap<HyperLogLog> minhash)\n+    {\n+        this.maxSize = maxSize;\n+        this.hllBuckets = hllBuckets;\n+        this.minhash = requireNonNull(minhash, \"minhash is null\");\n+        hllsTotalEstimatedInMemorySize = 0;\n+        hllsTotalEstimatedSerializedSize = 0;\n+\n+        for (HyperLogLog hll : minhash.values()) {\n+            increaseTotalHllSize(hll);\n+        }\n+    }\n+\n+    public static KHyperLogLog newInstance(Slice serialized)\n+    {\n+        requireNonNull(serialized, \"serialized is null\");\n+        SliceInput input = serialized.getInput();\n+        checkArgument(input.readByte() == VERSION_BYTE, \"Unexpected version\");\n+        Long2ObjectRBTreeMap<HyperLogLog> minhash = new Long2ObjectRBTreeMap<>();\n+\n+        int maxSize = input.readInt();\n+        int hllBuckets = input.readInt();\n+        int minhashSize = input.readInt();\n+        int totalHllSize = input.readInt();\n+\n+        int[] hllSizes = new int[minhashSize];\n+        long[] keys = new long[minhashSize];\n+        input.readBytes(wrappedIntArray(hllSizes));\n+        input.readBytes(wrappedLongArray(keys));\n+\n+        Slice allSerializedHlls = input.readSlice(totalHllSize);\n+\n+        int hllLength;\n+        int index = 0;\n+        Slice serializedHll;", "originalCommit": "18e507419eb8c7d4e32b575963d0b8926461776d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIwMTM3Mw==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r389201373", "bodyText": "nit: put this into for loop below.", "author": "shixuan-fan", "createdAt": "2020-03-07T00:11:58Z", "path": "presto-main/src/main/java/com/facebook/presto/type/khyperloglog/KHyperLogLog.java", "diffHunk": "@@ -0,0 +1,349 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.facebook.presto.type.khyperloglog;\n+\n+import com.facebook.airlift.stats.cardinality.HyperLogLog;\n+import com.google.common.collect.Sets;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Murmur3Hash128;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import io.airlift.slice.SliceOutput;\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import it.unimi.dsi.fastutil.longs.Long2DoubleMap;\n+import it.unimi.dsi.fastutil.longs.Long2DoubleOpenHashMap;\n+import it.unimi.dsi.fastutil.longs.Long2ObjectRBTreeMap;\n+import it.unimi.dsi.fastutil.longs.Long2ObjectSortedMap;\n+import it.unimi.dsi.fastutil.longs.LongIterator;\n+import it.unimi.dsi.fastutil.longs.LongRBTreeSet;\n+import it.unimi.dsi.fastutil.longs.LongSortedSet;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.PrimitiveIterator;\n+import java.util.stream.LongStream;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static io.airlift.slice.SizeOf.SIZE_OF_BYTE;\n+import static io.airlift.slice.SizeOf.SIZE_OF_INT;\n+import static io.airlift.slice.SizeOf.SIZE_OF_LONG;\n+import static io.airlift.slice.Slices.wrappedIntArray;\n+import static io.airlift.slice.Slices.wrappedLongArray;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * For reference on KHyperLogLog, see \"KHyperLogLog: Estimating Reidentifiability and\n+ * Joinability of Large Data at Scale\" by Chia et al., 2019.\n+ */\n+public class KHyperLogLog\n+{\n+    public static final int DEFAULT_HLL_BUCKETS = 256;\n+    public static final int DEFAULT_MAX_SIZE = 4096;\n+    private static final byte VERSION_BYTE = 1;\n+    private static final long HASH_OUTPUT_HALF_RANGE = Long.MAX_VALUE;\n+    private static final int SIZE_OF_KHYPERLOGLOG = ClassLayout.parseClass(KHyperLogLog.class).instanceSize();\n+    private static final int SIZE_OF_RBTREEMAP = ClassLayout.parseClass(Long2ObjectRBTreeMap.class).instanceSize();\n+\n+    private final Long2ObjectSortedMap<HyperLogLog> minhash;\n+    private final int maxSize;\n+    private final int hllBuckets;\n+\n+    private int hllsTotalEstimatedInMemorySize;\n+    private int hllsTotalEstimatedSerializedSize;\n+\n+    public KHyperLogLog()\n+    {\n+        this(DEFAULT_MAX_SIZE, DEFAULT_HLL_BUCKETS, new Long2ObjectRBTreeMap<>());\n+    }\n+\n+    public KHyperLogLog(int maxSize, int hllBuckets)\n+    {\n+        this(maxSize, hllBuckets, new Long2ObjectRBTreeMap<>());\n+    }\n+\n+    public KHyperLogLog(int maxSize, int hllBuckets, Long2ObjectSortedMap<HyperLogLog> minhash)\n+    {\n+        this.maxSize = maxSize;\n+        this.hllBuckets = hllBuckets;\n+        this.minhash = requireNonNull(minhash, \"minhash is null\");\n+        hllsTotalEstimatedInMemorySize = 0;\n+        hllsTotalEstimatedSerializedSize = 0;\n+\n+        for (HyperLogLog hll : minhash.values()) {\n+            increaseTotalHllSize(hll);\n+        }\n+    }\n+\n+    public static KHyperLogLog newInstance(Slice serialized)\n+    {\n+        requireNonNull(serialized, \"serialized is null\");\n+        SliceInput input = serialized.getInput();\n+        checkArgument(input.readByte() == VERSION_BYTE, \"Unexpected version\");\n+        Long2ObjectRBTreeMap<HyperLogLog> minhash = new Long2ObjectRBTreeMap<>();\n+\n+        int maxSize = input.readInt();\n+        int hllBuckets = input.readInt();\n+        int minhashSize = input.readInt();\n+        int totalHllSize = input.readInt();\n+\n+        int[] hllSizes = new int[minhashSize];\n+        long[] keys = new long[minhashSize];\n+        input.readBytes(wrappedIntArray(hllSizes));\n+        input.readBytes(wrappedLongArray(keys));\n+\n+        Slice allSerializedHlls = input.readSlice(totalHllSize);\n+\n+        int hllLength;\n+        int index = 0;\n+        Slice serializedHll;\n+        for (int i = 0; i < minhashSize; i++) {\n+            hllLength = hllSizes[i];\n+            serializedHll = allSerializedHlls.slice(index, hllLength);\n+            index += hllLength;\n+            minhash.put(keys[i], HyperLogLog.newInstance(serializedHll));\n+        }\n+\n+        return new KHyperLogLog(maxSize, hllBuckets, minhash);\n+    }\n+\n+    public Slice serialize()\n+    {\n+        try (SliceOutput output = new DynamicSliceOutput(estimatedSerializedSize())) {\n+            Slice serializedHll;", "originalCommit": "18e507419eb8c7d4e32b575963d0b8926461776d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIwMjg2OQ==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r389202869", "bodyText": "nit: how about\nint highlyUniqueValues = minhash.values().stream()\n    .map(HyperLogLog::cardinality)\n    .filter(cardinality -> cardinality <= threshold)\n    .count();", "author": "shixuan-fan", "createdAt": "2020-03-07T00:20:04Z", "path": "presto-main/src/main/java/com/facebook/presto/type/khyperloglog/KHyperLogLog.java", "diffHunk": "@@ -0,0 +1,349 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.facebook.presto.type.khyperloglog;\n+\n+import com.facebook.airlift.stats.cardinality.HyperLogLog;\n+import com.google.common.collect.Sets;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Murmur3Hash128;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import io.airlift.slice.SliceOutput;\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import it.unimi.dsi.fastutil.longs.Long2DoubleMap;\n+import it.unimi.dsi.fastutil.longs.Long2DoubleOpenHashMap;\n+import it.unimi.dsi.fastutil.longs.Long2ObjectRBTreeMap;\n+import it.unimi.dsi.fastutil.longs.Long2ObjectSortedMap;\n+import it.unimi.dsi.fastutil.longs.LongIterator;\n+import it.unimi.dsi.fastutil.longs.LongRBTreeSet;\n+import it.unimi.dsi.fastutil.longs.LongSortedSet;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.PrimitiveIterator;\n+import java.util.stream.LongStream;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static io.airlift.slice.SizeOf.SIZE_OF_BYTE;\n+import static io.airlift.slice.SizeOf.SIZE_OF_INT;\n+import static io.airlift.slice.SizeOf.SIZE_OF_LONG;\n+import static io.airlift.slice.Slices.wrappedIntArray;\n+import static io.airlift.slice.Slices.wrappedLongArray;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * For reference on KHyperLogLog, see \"KHyperLogLog: Estimating Reidentifiability and\n+ * Joinability of Large Data at Scale\" by Chia et al., 2019.\n+ */\n+public class KHyperLogLog\n+{\n+    public static final int DEFAULT_HLL_BUCKETS = 256;\n+    public static final int DEFAULT_MAX_SIZE = 4096;\n+    private static final byte VERSION_BYTE = 1;\n+    private static final long HASH_OUTPUT_HALF_RANGE = Long.MAX_VALUE;\n+    private static final int SIZE_OF_KHYPERLOGLOG = ClassLayout.parseClass(KHyperLogLog.class).instanceSize();\n+    private static final int SIZE_OF_RBTREEMAP = ClassLayout.parseClass(Long2ObjectRBTreeMap.class).instanceSize();\n+\n+    private final Long2ObjectSortedMap<HyperLogLog> minhash;\n+    private final int maxSize;\n+    private final int hllBuckets;\n+\n+    private int hllsTotalEstimatedInMemorySize;\n+    private int hllsTotalEstimatedSerializedSize;\n+\n+    public KHyperLogLog()\n+    {\n+        this(DEFAULT_MAX_SIZE, DEFAULT_HLL_BUCKETS, new Long2ObjectRBTreeMap<>());\n+    }\n+\n+    public KHyperLogLog(int maxSize, int hllBuckets)\n+    {\n+        this(maxSize, hllBuckets, new Long2ObjectRBTreeMap<>());\n+    }\n+\n+    public KHyperLogLog(int maxSize, int hllBuckets, Long2ObjectSortedMap<HyperLogLog> minhash)\n+    {\n+        this.maxSize = maxSize;\n+        this.hllBuckets = hllBuckets;\n+        this.minhash = requireNonNull(minhash, \"minhash is null\");\n+        hllsTotalEstimatedInMemorySize = 0;\n+        hllsTotalEstimatedSerializedSize = 0;\n+\n+        for (HyperLogLog hll : minhash.values()) {\n+            increaseTotalHllSize(hll);\n+        }\n+    }\n+\n+    public static KHyperLogLog newInstance(Slice serialized)\n+    {\n+        requireNonNull(serialized, \"serialized is null\");\n+        SliceInput input = serialized.getInput();\n+        checkArgument(input.readByte() == VERSION_BYTE, \"Unexpected version\");\n+        Long2ObjectRBTreeMap<HyperLogLog> minhash = new Long2ObjectRBTreeMap<>();\n+\n+        int maxSize = input.readInt();\n+        int hllBuckets = input.readInt();\n+        int minhashSize = input.readInt();\n+        int totalHllSize = input.readInt();\n+\n+        int[] hllSizes = new int[minhashSize];\n+        long[] keys = new long[minhashSize];\n+        input.readBytes(wrappedIntArray(hllSizes));\n+        input.readBytes(wrappedLongArray(keys));\n+\n+        Slice allSerializedHlls = input.readSlice(totalHllSize);\n+\n+        int hllLength;\n+        int index = 0;\n+        Slice serializedHll;\n+        for (int i = 0; i < minhashSize; i++) {\n+            hllLength = hllSizes[i];\n+            serializedHll = allSerializedHlls.slice(index, hllLength);\n+            index += hllLength;\n+            minhash.put(keys[i], HyperLogLog.newInstance(serializedHll));\n+        }\n+\n+        return new KHyperLogLog(maxSize, hllBuckets, minhash);\n+    }\n+\n+    public Slice serialize()\n+    {\n+        try (SliceOutput output = new DynamicSliceOutput(estimatedSerializedSize())) {\n+            Slice serializedHll;\n+            List<Slice> hllSlices = new ArrayList<>();\n+            IntList hllSizes = new IntArrayList();\n+            int totalHllSize = 0;\n+\n+            for (HyperLogLog hll : minhash.values()) {\n+                serializedHll = hll.serialize();\n+                hllSlices.add(serializedHll);\n+                totalHllSize += serializedHll.length();\n+                hllSizes.add(serializedHll.length());\n+            }\n+\n+            Slice hashesSlice = wrappedLongArray(minhash.keySet().toLongArray());\n+            Slice hllSizesSlice = wrappedIntArray(hllSizes.toIntArray());\n+\n+            output.appendByte(VERSION_BYTE);\n+            output.appendInt(maxSize);\n+            output.appendInt(hllBuckets);\n+            output.appendInt(minhash.size());\n+            output.appendInt(totalHllSize);\n+            output.appendBytes(hllSizesSlice);\n+            output.appendBytes(hashesSlice);\n+            for (Slice hllSlice : hllSlices) {\n+                output.appendBytes(hllSlice);\n+            }\n+\n+            return output.slice();\n+        }\n+        catch (IOException e) {\n+            throw new UncheckedIOException(e);\n+        }\n+    }\n+\n+    public static long exactIntersectionCardinality(KHyperLogLog a, KHyperLogLog b)\n+    {\n+        checkState(a.isExact(), \"exact intersection cannot operate on approximate sets\");\n+        checkArgument(b.isExact(), \"exact intersection cannot operate on approximate sets\");\n+\n+        return Sets.intersection(a.minhash.keySet(), b.minhash.keySet()).size();\n+    }\n+\n+    public static double jaccardIndex(KHyperLogLog a, KHyperLogLog b)\n+    {\n+        int sizeOfSmallerSet = Math.min(a.minhash.size(), b.minhash.size());\n+        LongSortedSet minUnion = new LongRBTreeSet(a.minhash.keySet());\n+        minUnion.addAll(b.minhash.keySet());\n+\n+        int intersection = 0;\n+        int i = 0;\n+\n+        LongIterator iterator = minUnion.iterator();\n+        while (iterator.hasNext()) {\n+            long key = iterator.nextLong();\n+            if (a.minhash.containsKey(key) && b.minhash.containsKey(key)) {\n+                intersection++;\n+            }\n+            i++;\n+            if (i >= sizeOfSmallerSet) {\n+                break;\n+            }\n+        }\n+        return intersection / (double) sizeOfSmallerSet;\n+    }\n+\n+    public static KHyperLogLog merge(KHyperLogLog khll1, KHyperLogLog khll2)\n+    {\n+         // Return the one with smallest K so resolution is not lost. This loss would happen in the case\n+         // one merged a smaller KHLL into a bigger one because the former's minhash struct won't\n+         // cover all of the latter's minhash space.\n+        if (khll1.maxSize <= khll2.maxSize) {\n+            return khll1.mergeWith(khll2);\n+        }\n+        return khll2.mergeWith(khll1);\n+    }\n+\n+    public boolean isExact()\n+    {\n+        return minhash.size() < maxSize;\n+    }\n+\n+    public long getMinhashSize()\n+    {\n+        return minhash.size();\n+    }\n+\n+    public int estimatedInMemorySize()\n+    {\n+        return SIZE_OF_KHYPERLOGLOG +\n+                SIZE_OF_RBTREEMAP +\n+                minhash.size() * SIZE_OF_LONG +\n+                hllsTotalEstimatedInMemorySize * SIZE_OF_BYTE;\n+    }\n+\n+    public int estimatedSerializedSize()\n+    {\n+        return SIZE_OF_BYTE +\n+                4 * SIZE_OF_INT +\n+                minhash.size() * (SIZE_OF_LONG + SIZE_OF_INT) +\n+                hllsTotalEstimatedSerializedSize * SIZE_OF_BYTE;\n+    }\n+\n+    public void add(long value, long uii)\n+    {\n+        update(Murmur3Hash128.hash64(value), uii);\n+    }\n+\n+    public void add(Slice value, long uii)\n+    {\n+        update(Murmur3Hash128.hash64(value), uii);\n+    }\n+\n+    private void update(long hash, long uii)\n+    {\n+        if (!(minhash.containsKey(hash) || isExact() || hash < minhash.lastLongKey())) {\n+            return;\n+        }\n+\n+        HyperLogLog hll = minhash.computeIfAbsent(hash, k -> {\n+            HyperLogLog newHll = HyperLogLog.newInstance(hllBuckets);\n+            increaseTotalHllSize(newHll);\n+            return newHll;\n+        });\n+\n+        decreaseTotalHllSize(hll);\n+        hll.add(uii);\n+        increaseTotalHllSize(hll);\n+\n+        removeOverflowEntries();\n+    }\n+\n+    public long cardinality()\n+    {\n+        if (isExact()) {\n+            return minhash.size();\n+        }\n+\n+        // Intuition is: get the stored hashes' density, and extrapolate to the whole Hash output range.\n+        // Since Hash output range (2^64) cannot be stored in long type, I use half of the range\n+        // via Long.MAX_VALUE and also divide the hash values' density by 2. The \"-1\" is bias correction\n+        // detailed in \"On Synopses for Distinct-Value Estimation Under Multiset Operations\" by Beyer et. al.\n+        long hashesRange = minhash.lastLongKey() - Long.MIN_VALUE;\n+        double halfDensity = Long.divideUnsigned(hashesRange, minhash.size() - 1) / 2D;\n+        return (long) (HASH_OUTPUT_HALF_RANGE / halfDensity);\n+    }\n+\n+    public KHyperLogLog mergeWith(KHyperLogLog other)\n+    {\n+        LongIterator iterator = other.minhash.keySet().iterator();\n+        while (iterator.hasNext()) {\n+            long key = iterator.nextLong();\n+            HyperLogLog thisHll = minhash.get(key);\n+            HyperLogLog otherHll = other.minhash.get(key);\n+            if (minhash.containsKey(key)) {\n+                decreaseTotalHllSize(thisHll);\n+                thisHll.mergeWith(otherHll);\n+                increaseTotalHllSize(thisHll);\n+            }\n+            else {\n+                minhash.put(key, otherHll);\n+                increaseTotalHllSize(otherHll);\n+            }\n+        }\n+\n+        removeOverflowEntries();\n+\n+        return this;\n+    }\n+\n+    public double reidentificationPotential(long threshold)\n+    {\n+        int highlyUniqueValues = 0;\n+        for (HyperLogLog hll : minhash.values()) {", "originalCommit": "18e507419eb8c7d4e32b575963d0b8926461776d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "c345e6ae213022ddea39e7312498ad496bc9d966", "url": "https://github.com/prestodb/presto/commit/c345e6ae213022ddea39e7312498ad496bc9d966", "message": "Create KHyperLogLog type\n\nInclude aggregate function to instantiate this type and scalar functions to operate over it.\nRefer to https://github.com/prestodb/presto/issues/14035", "committedDate": "2020-03-07T01:17:17Z", "type": "forcePushed"}, {"oid": "cb6e367faf849dd9bcc4f79e922670f10184477d", "url": "https://github.com/prestodb/presto/commit/cb6e367faf849dd9bcc4f79e922670f10184477d", "message": "Create KHyperLogLog type\n\nInclude aggregate function to instantiate this type and scalar functions to operate over it.\nRefer to https://github.com/prestodb/presto/issues/14035", "committedDate": "2020-03-07T01:44:49Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTQwOTAwNQ==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r389409005", "bodyText": "I think we normally call static methods create or createXXX. Though this one might be deserialize?", "author": "rongrong", "createdAt": "2020-03-08T21:56:53Z", "path": "presto-main/src/main/java/com/facebook/presto/type/khyperloglog/KHyperLogLog.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.facebook.presto.type.khyperloglog;\n+\n+import com.facebook.airlift.stats.cardinality.HyperLogLog;\n+import com.google.common.collect.Sets;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Murmur3Hash128;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import io.airlift.slice.SliceOutput;\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import it.unimi.dsi.fastutil.longs.Long2DoubleMap;\n+import it.unimi.dsi.fastutil.longs.Long2DoubleOpenHashMap;\n+import it.unimi.dsi.fastutil.longs.Long2ObjectRBTreeMap;\n+import it.unimi.dsi.fastutil.longs.Long2ObjectSortedMap;\n+import it.unimi.dsi.fastutil.longs.LongIterator;\n+import it.unimi.dsi.fastutil.longs.LongRBTreeSet;\n+import it.unimi.dsi.fastutil.longs.LongSortedSet;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.PrimitiveIterator;\n+import java.util.stream.LongStream;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static io.airlift.slice.SizeOf.SIZE_OF_BYTE;\n+import static io.airlift.slice.SizeOf.SIZE_OF_INT;\n+import static io.airlift.slice.SizeOf.SIZE_OF_LONG;\n+import static io.airlift.slice.Slices.wrappedIntArray;\n+import static io.airlift.slice.Slices.wrappedLongArray;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * For reference on KHyperLogLog, see \"KHyperLogLog: Estimating Reidentifiability and\n+ * Joinability of Large Data at Scale\" by Chia et al., 2019.\n+ */\n+public class KHyperLogLog\n+{\n+    public static final int DEFAULT_HLL_BUCKETS = 256;\n+    public static final int DEFAULT_MAX_SIZE = 4096;\n+    public static final long DEFAULT_HISTOGRAM_SIZE = 256;\n+    private static final byte VERSION_BYTE = 1;\n+    private static final long HASH_OUTPUT_HALF_RANGE = Long.MAX_VALUE;\n+    private static final int SIZE_OF_KHYPERLOGLOG = ClassLayout.parseClass(KHyperLogLog.class).instanceSize();\n+    private static final int SIZE_OF_RBTREEMAP = ClassLayout.parseClass(Long2ObjectRBTreeMap.class).instanceSize();\n+\n+    private final Long2ObjectSortedMap<HyperLogLog> minhash;\n+    private final int maxSize;\n+    private final int hllBuckets;\n+\n+    private int hllsTotalEstimatedInMemorySize;\n+    private int hllsTotalEstimatedSerializedSize;\n+\n+    public KHyperLogLog()\n+    {\n+        this(DEFAULT_MAX_SIZE, DEFAULT_HLL_BUCKETS, new Long2ObjectRBTreeMap<>());\n+    }\n+\n+    public KHyperLogLog(int maxSize, int hllBuckets)\n+    {\n+        this(maxSize, hllBuckets, new Long2ObjectRBTreeMap<>());\n+    }\n+\n+    public KHyperLogLog(int maxSize, int hllBuckets, Long2ObjectSortedMap<HyperLogLog> minhash)\n+    {\n+        this.maxSize = maxSize;\n+        this.hllBuckets = hllBuckets;\n+        this.minhash = requireNonNull(minhash, \"minhash is null\");\n+\n+        minhash.values().forEach(this::increaseTotalHllSize);\n+    }\n+\n+    public static KHyperLogLog newInstance(Slice serialized)", "originalCommit": "cb6e367faf849dd9bcc4f79e922670f10184477d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTQxNjc3OQ==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r389416779", "bodyText": "This method follows HyperLogLog's equivalent newInstance(Slice)  method signature. What do you think? Should I leave it as it is or change to deserialize?", "author": "mcorreaiz", "createdAt": "2020-03-08T23:18:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTQwOTAwNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTg1MzkwMw==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r389853903", "bodyText": "I don't have strong opinions on this. newInstance is ok. Thanks!", "author": "rongrong", "createdAt": "2020-03-09T17:42:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTQwOTAwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTQwOTUzMg==", "url": "https://github.com/prestodb/presto/pull/14119#discussion_r389409532", "bodyText": "Can you add comment on what each of these are? Thanks!", "author": "rongrong", "createdAt": "2020-03-08T22:02:19Z", "path": "presto-main/src/main/java/com/facebook/presto/type/khyperloglog/KHyperLogLog.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.facebook.presto.type.khyperloglog;\n+\n+import com.facebook.airlift.stats.cardinality.HyperLogLog;\n+import com.google.common.collect.Sets;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Murmur3Hash128;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import io.airlift.slice.SliceOutput;\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import it.unimi.dsi.fastutil.longs.Long2DoubleMap;\n+import it.unimi.dsi.fastutil.longs.Long2DoubleOpenHashMap;\n+import it.unimi.dsi.fastutil.longs.Long2ObjectRBTreeMap;\n+import it.unimi.dsi.fastutil.longs.Long2ObjectSortedMap;\n+import it.unimi.dsi.fastutil.longs.LongIterator;\n+import it.unimi.dsi.fastutil.longs.LongRBTreeSet;\n+import it.unimi.dsi.fastutil.longs.LongSortedSet;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.PrimitiveIterator;\n+import java.util.stream.LongStream;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static io.airlift.slice.SizeOf.SIZE_OF_BYTE;\n+import static io.airlift.slice.SizeOf.SIZE_OF_INT;\n+import static io.airlift.slice.SizeOf.SIZE_OF_LONG;\n+import static io.airlift.slice.Slices.wrappedIntArray;\n+import static io.airlift.slice.Slices.wrappedLongArray;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * For reference on KHyperLogLog, see \"KHyperLogLog: Estimating Reidentifiability and\n+ * Joinability of Large Data at Scale\" by Chia et al., 2019.\n+ */\n+public class KHyperLogLog\n+{\n+    public static final int DEFAULT_HLL_BUCKETS = 256;\n+    public static final int DEFAULT_MAX_SIZE = 4096;\n+    public static final long DEFAULT_HISTOGRAM_SIZE = 256;\n+    private static final byte VERSION_BYTE = 1;\n+    private static final long HASH_OUTPUT_HALF_RANGE = Long.MAX_VALUE;\n+    private static final int SIZE_OF_KHYPERLOGLOG = ClassLayout.parseClass(KHyperLogLog.class).instanceSize();\n+    private static final int SIZE_OF_RBTREEMAP = ClassLayout.parseClass(Long2ObjectRBTreeMap.class).instanceSize();\n+\n+    private final Long2ObjectSortedMap<HyperLogLog> minhash;\n+    private final int maxSize;\n+    private final int hllBuckets;\n+\n+    private int hllsTotalEstimatedInMemorySize;\n+    private int hllsTotalEstimatedSerializedSize;\n+\n+    public KHyperLogLog()\n+    {\n+        this(DEFAULT_MAX_SIZE, DEFAULT_HLL_BUCKETS, new Long2ObjectRBTreeMap<>());\n+    }\n+\n+    public KHyperLogLog(int maxSize, int hllBuckets)\n+    {\n+        this(maxSize, hllBuckets, new Long2ObjectRBTreeMap<>());\n+    }\n+\n+    public KHyperLogLog(int maxSize, int hllBuckets, Long2ObjectSortedMap<HyperLogLog> minhash)\n+    {\n+        this.maxSize = maxSize;\n+        this.hllBuckets = hllBuckets;\n+        this.minhash = requireNonNull(minhash, \"minhash is null\");\n+\n+        minhash.values().forEach(this::increaseTotalHllSize);\n+    }\n+\n+    public static KHyperLogLog newInstance(Slice serialized)\n+    {\n+        requireNonNull(serialized, \"serialized is null\");\n+        SliceInput input = serialized.getInput();\n+        checkArgument(input.readByte() == VERSION_BYTE, \"Unexpected version\");\n+        Long2ObjectRBTreeMap<HyperLogLog> minhash = new Long2ObjectRBTreeMap<>();\n+\n+        int maxSize = input.readInt();\n+        int hllBuckets = input.readInt();\n+        int minhashSize = input.readInt();\n+        int totalHllSize = input.readInt();\n+\n+        int[] hllSizes = new int[minhashSize];\n+        long[] keys = new long[minhashSize];\n+        input.readBytes(wrappedIntArray(hllSizes));\n+        input.readBytes(wrappedLongArray(keys));\n+\n+        Slice allSerializedHlls = input.readSlice(totalHllSize);\n+\n+        int hllLength;\n+        int index = 0;\n+        for (int i = 0; i < minhashSize; i++) {\n+            Slice serializedHll;\n+            hllLength = hllSizes[i];\n+            serializedHll = allSerializedHlls.slice(index, hllLength);\n+            index += hllLength;\n+            minhash.put(keys[i], HyperLogLog.newInstance(serializedHll));\n+        }\n+\n+        return new KHyperLogLog(maxSize, hllBuckets, minhash);\n+    }\n+\n+    public Slice serialize()\n+    {\n+        try (SliceOutput output = new DynamicSliceOutput(estimatedSerializedSize())) {\n+            List<Slice> hllSlices = new ArrayList<>();\n+            IntList hllSizes = new IntArrayList();\n+            int totalHllSize = 0;\n+\n+            for (HyperLogLog hll : minhash.values()) {\n+                Slice serializedHll = hll.serialize();\n+                hllSlices.add(serializedHll);\n+                totalHllSize += serializedHll.length();\n+                hllSizes.add(serializedHll.length());\n+            }\n+\n+            Slice hashesSlice = wrappedLongArray(minhash.keySet().toLongArray());\n+            Slice hllSizesSlice = wrappedIntArray(hllSizes.toIntArray());\n+\n+            output.appendByte(VERSION_BYTE);\n+            output.appendInt(maxSize);\n+            output.appendInt(hllBuckets);\n+            output.appendInt(minhash.size());\n+            output.appendInt(totalHllSize);\n+            output.appendBytes(hllSizesSlice);\n+            output.appendBytes(hashesSlice);\n+            for (Slice hllSlice : hllSlices) {\n+                output.appendBytes(hllSlice);\n+            }\n+\n+            return output.slice();\n+        }\n+        catch (IOException e) {\n+            throw new UncheckedIOException(e);\n+        }\n+    }\n+\n+    public static long exactIntersectionCardinality(KHyperLogLog a, KHyperLogLog b)\n+    {\n+        checkState(a.isExact(), \"exact intersection cannot operate on approximate sets\");\n+        checkArgument(b.isExact(), \"exact intersection cannot operate on approximate sets\");\n+\n+        return Sets.intersection(a.minhash.keySet(), b.minhash.keySet()).size();\n+    }\n+\n+    public static double jaccardIndex(KHyperLogLog a, KHyperLogLog b)\n+    {\n+        int sizeOfSmallerSet = Math.min(a.minhash.size(), b.minhash.size());\n+        LongSortedSet minUnion = new LongRBTreeSet(a.minhash.keySet());\n+        minUnion.addAll(b.minhash.keySet());\n+\n+        int intersection = 0;\n+        int i = 0;\n+\n+        LongIterator iterator = minUnion.iterator();\n+        while (iterator.hasNext()) {\n+            long key = iterator.nextLong();\n+            if (a.minhash.containsKey(key) && b.minhash.containsKey(key)) {\n+                intersection++;\n+            }\n+            i++;\n+            if (i >= sizeOfSmallerSet) {\n+                break;\n+            }\n+        }\n+        return intersection / (double) sizeOfSmallerSet;\n+    }\n+\n+    public static KHyperLogLog merge(KHyperLogLog khll1, KHyperLogLog khll2)\n+    {\n+         // Return the one with smallest K so resolution is not lost. This loss would happen in the case\n+         // one merged a smaller KHLL into a bigger one because the former's minhash struct won't\n+         // cover all of the latter's minhash space.\n+        if (khll1.maxSize <= khll2.maxSize) {\n+            return khll1.mergeWith(khll2);\n+        }\n+        return khll2.mergeWith(khll1);\n+    }\n+\n+    public boolean isExact()\n+    {\n+        return minhash.size() < maxSize;\n+    }\n+\n+    public long getMinhashSize()\n+    {\n+        return minhash.size();\n+    }\n+\n+    public int estimatedInMemorySize()\n+    {\n+        return SIZE_OF_KHYPERLOGLOG +\n+                SIZE_OF_RBTREEMAP +\n+                minhash.size() * SIZE_OF_LONG +\n+                hllsTotalEstimatedInMemorySize * SIZE_OF_BYTE;\n+    }\n+\n+    public int estimatedSerializedSize()\n+    {\n+        return SIZE_OF_BYTE +", "originalCommit": "cb6e367faf849dd9bcc4f79e922670f10184477d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "c30b86c8b7c565eebf8831dfff8edaa46c6da297", "url": "https://github.com/prestodb/presto/commit/c30b86c8b7c565eebf8831dfff8edaa46c6da297", "message": "Create KHyperLogLog type\n\nInclude aggregate function to instantiate this type and scalar functions to operate over it.\nRefer to https://github.com/prestodb/presto/issues/14035", "committedDate": "2020-03-08T23:34:47Z", "type": "commit"}, {"oid": "c30b86c8b7c565eebf8831dfff8edaa46c6da297", "url": "https://github.com/prestodb/presto/commit/c30b86c8b7c565eebf8831dfff8edaa46c6da297", "message": "Create KHyperLogLog type\n\nInclude aggregate function to instantiate this type and scalar functions to operate over it.\nRefer to https://github.com/prestodb/presto/issues/14035", "committedDate": "2020-03-08T23:34:47Z", "type": "forcePushed"}]}