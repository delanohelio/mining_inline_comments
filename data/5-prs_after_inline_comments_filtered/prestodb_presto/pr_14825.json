{"pr_number": 14825, "pr_title": "Presto spark query info", "pr_createdAt": "2020-07-10T17:17:10Z", "pr_url": "https://github.com/prestodb/presto/pull/14825", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzA2NzIxMQ==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r453067211", "bodyText": "I think it's right to use TaskInfo instead of TaskStats. Just curious why previous TaskStats is chosen?", "author": "wenleix", "createdAt": "2020-07-10T20:40:51Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkModule.java", "diffHunk": "@@ -206,7 +206,7 @@ protected void setup(Binder binder)\n \n         // json codecs\n         jsonCodecBinder(binder).bindJsonCodec(ViewDefinition.class);\n-        jsonCodecBinder(binder).bindJsonCodec(TaskStats.class);\n+        jsonCodecBinder(binder).bindJsonCodec(TaskInfo.class);", "originalCommit": "239e5b3f42fbbab413c86809826e44fe3ebde84e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzc5MjUwMA==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r453792500", "bodyText": "Just curious why previous TaskStats is chosen?\n\nJust some premature coding. I was trying to prototype something, and hadn't finish =)", "author": "arhimondr", "createdAt": "2020-07-13T16:55:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzA2NzIxMQ=="}], "type": "inlineReview"}, {"oid": "572b05208f9c684b6ce5a0ac15b9ca491b41c09d", "url": "https://github.com/prestodb/presto/commit/572b05208f9c684b6ce5a0ac15b9ca491b41c09d", "message": "Allow query info to be stored in a file upon query finish\n\nThis will allow to retrieve query id, stack trace and potentially\nother debug information upon query completition", "committedDate": "2020-07-13T16:56:12Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg4MjA1Ng==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r453882056", "bodyText": "nit: looks like only \"ROW\" and \"PAGE\" can be valid input to this String, what about make it to be an enum?\nI am asking this because I originally thought it's a Presto type (e..g  BIGINT, ARRAY(VARCHAR) )", "author": "wenleix", "createdAt": "2020-07-13T19:30:14Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputBuffer.java", "diffHunk": "@@ -33,8 +35,12 @@\n     @GuardedBy(\"monitor\")\n     private boolean finished;\n \n-    public PrestoSparkOutputBuffer(OutputBufferMemoryManager memoryManager)\n+    private final AtomicLong totalRowsProcessed = new AtomicLong();\n+    private final AtomicLong totalPagesProcessed = new AtomicLong();\n+\n+    public PrestoSparkOutputBuffer(String type, OutputBufferMemoryManager memoryManager)", "originalCommit": "5542710ee5adc1fe0eefc4b1f435b669914e433c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDAyMTE2Nw==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r454021167", "bodyText": "Technically it can accept anything that implements PrestoSparkBufferedResult. What do you think about renaming type to something like description?", "author": "arhimondr", "createdAt": "2020-07-14T00:15:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg4MjA1Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQwNjkwMw==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r454406903", "bodyText": "Actually I removed this fields from the PrestoSparkOutputBuffer class and added private enum OutputBufferType in the PrestoSparkTaskExecutorFactory", "author": "arhimondr", "createdAt": "2020-07-14T14:39:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg4MjA1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg5NTYzNA==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r453895634", "bodyText": "is this for debug?", "author": "wenleix", "createdAt": "2020-07-13T19:56:18Z", "path": "presto-spark-classloader-interface/src/main/java/com/facebook/presto/spark/classloader_interface/SerializedTaskInfo.java", "diffHunk": "@@ -20,15 +20,25 @@\n public class SerializedTaskInfo\n         implements Serializable\n {\n+    private final int fragmentId;\n+    private final int taskId;\n     private final byte[] bytes;\n \n-    public SerializedTaskInfo(byte[] bytes)\n+    public SerializedTaskInfo(int fragmentId, int taskId, byte[] bytes)\n     {\n+        this.fragmentId = fragmentId;\n+        this.taskId = taskId;\n         this.bytes = requireNonNull(bytes, \"bytes is null\");\n     }\n \n     public byte[] getBytes()\n     {\n         return bytes;\n     }\n+\n+    @Override\n+    public String toString()\n+    {\n+        return fragmentId + \".\" + taskId;", "originalCommit": "5542710ee5adc1fe0eefc4b1f435b669914e433c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDAyMDE5NA==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r454020194", "bodyText": "This is to avoid byte[] being displayed on the Spark UI", "author": "arhimondr", "createdAt": "2020-07-14T00:11:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg5NTYzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk2NDE0Nw==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r453964147", "bodyText": "curious: how do we avoid byte[] being displayed on Spark UI?", "author": "wenleix", "createdAt": "2020-07-13T22:03:25Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkTaskExecutorFactory.java", "diffHunk": "@@ -478,14 +496,17 @@ public boolean hasNext()\n                 return output;\n             }\n \n-            //  TODO: Implement task stats collection\n-            //  TaskStats taskStats = taskContext.getTaskStats();\n-            //  byte[] taskStatsSerialized = taskInfoJsonCodec.toJsonBytes(taskStats);\n-            //  taskStatsCollector.add(new SerializedTaskStats(taskStatsSerialized));\n-\n             // task finished\n             TaskState taskState = taskStateMachine.getState();\n             checkState(taskState.isDone(), \"task is expected to be done\");\n+\n+            TaskInfo taskInfo = createTaskInfo(taskContext, taskStateMachine, taskInstanceId, outputBuffer);\n+            SerializedTaskInfo serializedTaskInfo = new SerializedTaskInfo(\n+                    taskInfo.getTaskId().getStageExecutionId().getStageId().getId(),\n+                    taskInfo.getTaskId().getId(),\n+                    compress(taskInfoJsonCodec.toJsonBytes(taskInfo)));\n+            taskInfoCollector.add(serializedTaskInfo);", "originalCommit": "5542710ee5adc1fe0eefc4b1f435b669914e433c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDAyMDI0MA==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r454020240", "bodyText": "Answered in the previous comment", "author": "arhimondr", "createdAt": "2020-07-14T00:12:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk2NDE0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk2NjM0OQ==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r453966349", "bodyText": "Assume it's copied from QueryStateMachine#getQueryStats.", "author": "wenleix", "createdAt": "2020-07-13T22:06:37Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/QueryStats.java", "diffHunk": "@@ -240,6 +246,207 @@ public QueryStats(\n         this.operatorSummaries = ImmutableList.copyOf(requireNonNull(operatorSummaries, \"operatorSummaries is null\"));\n     }\n \n+    public static QueryStats create(", "originalCommit": "27d88f04c6454b8aa63b36d0eec9e86049d6e86f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk3Njk3Mg==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r453976972", "bodyText": "I personally don't prefer to have Optional<Collection<>> as configuration, as the semantic difference between \"not present\" and \"presented but empty\" can be very tricky. Can we enforce eventListenerProperties always have to present? (EVENT_LISTENER_PROPERTY_NAME can be set to a special value such as \"NO_EVENT_LISTENER\")  ?", "author": "wenleix", "createdAt": "2020-07-13T22:22:29Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkInjectorFactory.java", "diffHunk": "@@ -46,29 +46,33 @@\n     private final SparkProcessType sparkProcessType;\n     private final Map<String, String> configProperties;\n     private final Map<String, Map<String, String>> catalogProperties;\n+    private final Optional<Map<String, String>> eventListenerProperties;", "originalCommit": "2cd44517170115bd7d9deb0a0cebfcc87d3d4694", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDAyMTYxNg==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r454021616", "bodyText": "I would rather prefer it to be explicitly. One can read it as event listener is not configured - eventListenerProperties = Optional.empty(). Or event listener is configured - the the Optional contains configuration properties for event listener.", "author": "arhimondr", "createdAt": "2020-07-14T00:16:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk3Njk3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk4MjY1MQ==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r453982651", "bodyText": "nit: one line per parameter.", "author": "wenleix", "createdAt": "2020-07-13T22:31:18Z", "path": "presto-spark-launcher/src/main/java/com/facebook/presto/spark/launcher/PrestoSparkLauncherCommand.java", "diffHunk": "@@ -62,7 +62,7 @@ public void run()\n         String query = readFileUtf8(checkFile(new File(clientOptions.file)));\n \n         try (PrestoSparkRunner runner = new PrestoSparkRunner(distribution)) {\n-            runner.run(clientOptions.catalog, clientOptions.schema, query, ImmutableMap.of(), ImmutableMap.of());\n+            runner.run(clientOptions.catalog, clientOptions.schema, query, ImmutableMap.of(), ImmutableMap.of(), Optional.empty());", "originalCommit": "572b05208f9c684b6ce5a0ac15b9ca491b41c09d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk4MTc5OQ==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r453981799", "bodyText": "Is it possible for rowBatch to be Type PrestoSparkBufferedSerializedPage,  then we can just call it batch.", "author": "viczhang861", "createdAt": "2020-07-13T22:30:11Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputBuffer.java", "diffHunk": "@@ -79,6 +85,25 @@ public T get()\n                 memoryManager.updateMemoryUsage(-rowBatch.getRetainedSizeInBytes());\n             }\n         }\n+        if (rowBatch != null) {", "originalCommit": "5542710ee5adc1fe0eefc4b1f435b669914e433c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDAyMTg0NA==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r454021844", "bodyText": "PrestoSparkBufferedSerializedPage is technically still a batch of rows, just encoded in a columnar fashion", "author": "arhimondr", "createdAt": "2020-07-14T00:17:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk4MTc5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5MTU1NA==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r453991554", "bodyText": "There is a constant in TaskStatus to use STARTING_VERSION", "author": "viczhang861", "createdAt": "2020-07-13T22:50:58Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkTaskExecutorFactory.java", "diffHunk": "@@ -497,6 +518,60 @@ public boolean hasNext()\n             propagateIfPossible(failure, InterruptedException.class);\n             throw new RuntimeException(failure);\n         }\n+\n+        private static TaskInfo createTaskInfo(\n+                TaskContext taskContext,\n+                TaskStateMachine taskStateMachine,\n+                UUID taskInstanceId,\n+                PrestoSparkOutputBuffer<?> outputBuffer)\n+        {\n+            TaskId taskId = taskContext.getTaskId();\n+            TaskState taskState = taskContext.getState();\n+            TaskStats taskStats = taskContext.getTaskStats();\n+\n+            List<ExecutionFailureInfo> failures = ImmutableList.of();\n+            if (taskState == FAILED) {\n+                failures = toFailures(taskStateMachine.getFailureCauses());\n+            }\n+\n+            TaskStatus taskStatus = new TaskStatus(\n+                    taskInstanceId.getLeastSignificantBits(),\n+                    taskInstanceId.getMostSignificantBits(),\n+                    1,", "originalCommit": "5542710ee5adc1fe0eefc4b1f435b669914e433c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDAzMjUxNQ==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r454032515", "bodyText": "nit, this can be inlined", "author": "viczhang861", "createdAt": "2020-07-14T00:51:18Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/QueryStats.java", "diffHunk": "@@ -240,6 +246,207 @@ public QueryStats(\n         this.operatorSummaries = ImmutableList.copyOf(requireNonNull(operatorSummaries, \"operatorSummaries is null\"));\n     }\n \n+    public static QueryStats create(\n+            QueryStateTimer queryStateTimer,\n+            Optional<StageInfo> rootStage,\n+            int peakRunningTasks,\n+            DataSize peakUserMemoryReservation,\n+            DataSize peakTotalMemoryReservation,\n+            DataSize peakTaskUserMemory,\n+            DataSize peakTaskTotalMemory)\n+    {\n+        int totalTasks = 0;\n+        int runningTasks = 0;\n+        int completedTasks = 0;\n+\n+        int totalDrivers = 0;\n+        int queuedDrivers = 0;\n+        int runningDrivers = 0;\n+        int blockedDrivers = 0;\n+        int completedDrivers = 0;\n+\n+        long cumulativeUserMemory = 0;\n+        long userMemoryReservation = 0;\n+        long totalMemoryReservation = 0;\n+\n+        long totalScheduledTime = 0;\n+        long totalCpuTime = 0;\n+        long retriedCpuTime = 0;\n+        long totalBlockedTime = 0;\n+\n+        long totalAllocation = 0;\n+\n+        long rawInputDataSize = 0;\n+        long rawInputPositions = 0;\n+\n+        long processedInputDataSize = 0;\n+        long processedInputPositions = 0;\n+\n+        long outputDataSize = 0;\n+        long outputPositions = 0;\n+\n+        long writtenOutputPositions = 0;\n+        long writtenOutputLogicalDataSize = 0;\n+        long writtenOutputPhysicalDataSize = 0;\n+\n+        long writtenIntermediatePhysicalDataSize = 0;\n+\n+        ImmutableList.Builder<StageGcStatistics> stageGcStatistics = ImmutableList.builder();\n+\n+        boolean fullyBlocked = rootStage.isPresent();\n+        Set<BlockedReason> blockedReasons = new HashSet<>();\n+\n+        ImmutableList.Builder<OperatorStats> operatorStatsSummary = ImmutableList.builder();\n+        boolean completeInfo = true;\n+        for (StageInfo stageInfo : getAllStages(rootStage)) {\n+            StageExecutionStats stageExecutionStats = stageInfo.getLatestAttemptExecutionInfo().getStats();\n+            totalTasks += stageExecutionStats.getTotalTasks();\n+            runningTasks += stageExecutionStats.getRunningTasks();\n+            completedTasks += stageExecutionStats.getCompletedTasks();\n+\n+            totalDrivers += stageExecutionStats.getTotalDrivers();\n+            queuedDrivers += stageExecutionStats.getQueuedDrivers();\n+            runningDrivers += stageExecutionStats.getRunningDrivers();\n+            blockedDrivers += stageExecutionStats.getBlockedDrivers();\n+            completedDrivers += stageExecutionStats.getCompletedDrivers();\n+\n+            cumulativeUserMemory += stageExecutionStats.getCumulativeUserMemory();\n+            userMemoryReservation += stageExecutionStats.getUserMemoryReservation().toBytes();\n+            totalMemoryReservation += stageExecutionStats.getTotalMemoryReservation().toBytes();\n+            totalScheduledTime += stageExecutionStats.getTotalScheduledTime().roundTo(MILLISECONDS);\n+            totalCpuTime += stageExecutionStats.getTotalCpuTime().roundTo(MILLISECONDS);\n+            retriedCpuTime += computeRetriedCpuTime(stageInfo);\n+            totalBlockedTime += stageExecutionStats.getTotalBlockedTime().roundTo(MILLISECONDS);\n+            if (!stageInfo.getLatestAttemptExecutionInfo().getState().isDone()) {\n+                fullyBlocked &= stageExecutionStats.isFullyBlocked();\n+                blockedReasons.addAll(stageExecutionStats.getBlockedReasons());\n+            }\n+\n+            totalAllocation += stageExecutionStats.getTotalAllocation().toBytes();\n+\n+            if (stageInfo.getPlan().isPresent()) {\n+                PlanFragment plan = stageInfo.getPlan().get();\n+                if (!plan.getTableScanSchedulingOrder().isEmpty()) {\n+                    rawInputDataSize += stageExecutionStats.getRawInputDataSize().toBytes();\n+                    rawInputPositions += stageExecutionStats.getRawInputPositions();\n+\n+                    processedInputDataSize += stageExecutionStats.getProcessedInputDataSize().toBytes();\n+                    processedInputPositions += stageExecutionStats.getProcessedInputPositions();\n+                }\n+\n+                if (plan.isOutputTableWriterFragment()) {\n+                    writtenOutputPositions += stageExecutionStats.getOperatorSummaries().stream()\n+                            .filter(stats -> stats.getOperatorType().equals(TableWriterOperator.class.getSimpleName()))\n+                            .mapToLong(OperatorStats::getInputPositions)\n+                            .sum();\n+                    writtenOutputLogicalDataSize += stageExecutionStats.getOperatorSummaries().stream()\n+                            .filter(stats -> stats.getOperatorType().equals(TableWriterOperator.class.getSimpleName()))\n+                            .mapToLong(stats -> stats.getInputDataSize().toBytes())\n+                            .sum();\n+                    writtenOutputPhysicalDataSize += stageExecutionStats.getPhysicalWrittenDataSize().toBytes();\n+                }\n+                else {\n+                    writtenIntermediatePhysicalDataSize += stageExecutionStats.getPhysicalWrittenDataSize().toBytes();\n+                }\n+            }\n+\n+            stageGcStatistics.add(stageExecutionStats.getGcInfo());\n+\n+            completeInfo = completeInfo && stageInfo.isFinalStageInfo();\n+            operatorStatsSummary.addAll(stageExecutionStats.getOperatorSummaries());\n+        }\n+\n+        if (rootStage.isPresent()) {\n+            StageExecutionStats outputStageStats = rootStage.get().getLatestAttemptExecutionInfo().getStats();\n+            outputDataSize += outputStageStats.getOutputDataSize().toBytes();\n+            outputPositions += outputStageStats.getOutputPositions();\n+        }\n+\n+        boolean isScheduled = isScheduled(rootStage);", "originalCommit": "27d88f04c6454b8aa63b36d0eec9e86049d6e86f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDA1NDI1OA==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r454054258", "bodyText": "flatMap", "author": "viczhang861", "createdAt": "2020-07-14T02:06:44Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java", "diffHunk": "@@ -310,6 +369,122 @@ private static TransactionInfo getTransactionInfo(Session session, TransactionMa\n         return transaction.get();\n     }\n \n+    private static QueryInfo createQueryInfo(\n+            Session session,\n+            String query,\n+            QueryState queryState,\n+            Optional<PlanAndMore> planAndMore,\n+            Optional<ExecutionFailureInfo> failureInfo,\n+            QueryStateTimer queryStateTimer,\n+            Optional<StageInfo> rootStage,\n+            WarningCollector warningCollector)\n+    {\n+        checkArgument(failureInfo.isPresent() || queryState != FAILED, \"unexpected query state: %s\", queryState);\n+\n+        int peakRunningTasks = 0;\n+        long peakUserMemoryReservationInBytes = 0;\n+        long peakTotalMemoryReservationInBytes = 0;\n+        long peakTaskUserMemoryInBytes = 0;\n+        long peakTaskTotalMemoryInBytes = 0;\n+\n+        for (StageInfo stageInfo : getAllStages(rootStage)) {\n+            StageExecutionInfo stageExecutionInfo = stageInfo.getLatestAttemptExecutionInfo();\n+            for (TaskInfo taskInfo : stageExecutionInfo.getTasks()) {\n+                // there's no way to know how many tasks were running in parallel in Spark\n+                // for now let's assume that all the tasks were running in parallel\n+                peakRunningTasks++;\n+                long taskPeakUserMemoryInBytes = taskInfo.getStats().getUserMemoryReservation().toBytes();\n+                long taskPeakTotalMemoryInBytes = taskInfo.getStats().getPeakTotalMemoryInBytes();\n+                peakUserMemoryReservationInBytes += taskPeakUserMemoryInBytes;\n+                peakTotalMemoryReservationInBytes += taskPeakTotalMemoryInBytes;\n+                peakTaskUserMemoryInBytes = max(peakTaskUserMemoryInBytes, taskPeakUserMemoryInBytes);\n+                peakTaskTotalMemoryInBytes = max(peakTaskTotalMemoryInBytes, taskPeakTotalMemoryInBytes);\n+            }\n+        }\n+\n+        QueryStats queryStats = QueryStats.create(\n+                queryStateTimer,\n+                rootStage,\n+                peakRunningTasks,\n+                succinctBytes(peakUserMemoryReservationInBytes),\n+                succinctBytes(peakTotalMemoryReservationInBytes),\n+                succinctBytes(peakTaskUserMemoryInBytes),\n+                succinctBytes(peakTaskTotalMemoryInBytes));\n+\n+        return new QueryInfo(\n+                session.getQueryId(),\n+                session.toSessionRepresentation(),\n+                queryState,\n+                new MemoryPoolId(\"spark-memory-pool\"),\n+                queryStats.isScheduled(),\n+                URI.create(\"http://fake.invalid/query/\" + session.getQueryId()),\n+                planAndMore.map(PlanAndMore::getFieldNames).orElse(ImmutableList.of()),\n+                query,\n+                queryStats,\n+                Optional.empty(),\n+                Optional.empty(),\n+                ImmutableMap.of(),\n+                ImmutableSet.of(),\n+                ImmutableMap.of(),\n+                ImmutableMap.of(),\n+                ImmutableSet.of(),\n+                Optional.empty(),\n+                false,\n+                planAndMore.flatMap(PlanAndMore::getUpdateType).orElse(null),\n+                rootStage,\n+                failureInfo.orElse(null),\n+                failureInfo.map(ExecutionFailureInfo::getErrorCode).orElse(null),", "originalCommit": "27d88f04c6454b8aa63b36d0eec9e86049d6e86f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDA2ODI0OQ==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r454068249", "bodyText": "Nevermind, ErrorCode is nullable in ExecutionFailureInfo", "author": "viczhang861", "createdAt": "2020-07-14T02:55:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDA1NDI1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDA1ODM3NQ==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r454058375", "bodyText": "Why not simply get(EVENT_LISTENER_PROPERTY_NAME) ?", "author": "viczhang861", "createdAt": "2020-07-14T02:21:30Z", "path": "presto-main/src/main/java/com/facebook/presto/eventlistener/EventListenerManager.java", "diffHunk": "@@ -59,16 +59,24 @@ public void loadConfiguredEventListener()\n             throws Exception\n     {\n         if (EVENT_LISTENER_CONFIGURATION.exists()) {\n-            Map<String, String> properties = new HashMap<>(loadProperties(EVENT_LISTENER_CONFIGURATION));\n-\n-            String eventListenerName = properties.remove(EVENT_LISTENER_PROPERTY_NAME);\n-            checkArgument(!isNullOrEmpty(eventListenerName),\n-                    \"Access control configuration %s does not contain %s\", EVENT_LISTENER_CONFIGURATION.getAbsoluteFile(), EVENT_LISTENER_PROPERTY_NAME);\n-\n-            setConfiguredEventListener(eventListenerName, properties);\n+            Map<String, String> properties = loadProperties(EVENT_LISTENER_CONFIGURATION);\n+            checkArgument(\n+                    !isNullOrEmpty(properties.get(EVENT_LISTENER_PROPERTY_NAME)),\n+                    \"Access control configuration %s does not contain %s\",\n+                    EVENT_LISTENER_CONFIGURATION.getAbsoluteFile(),\n+                    EVENT_LISTENER_PROPERTY_NAME);\n+            loadConfiguredEventListener(properties);\n         }\n     }\n \n+    public void loadConfiguredEventListener(Map<String, String> properties)\n+    {\n+        properties = new HashMap<>(properties);\n+        String eventListenerName = properties.remove(EVENT_LISTENER_PROPERTY_NAME);", "originalCommit": "2cd44517170115bd7d9deb0a0cebfcc87d3d4694", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM4MjgyNg==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r454382826", "bodyText": "This is per convention. One of the properties defines what event listener provider to use, the other properties is the actual configuration that must be passed to the provider. The property that defines what provider to use must be removed, as the provider itself doesn't understand it.", "author": "arhimondr", "createdAt": "2020-07-14T14:07:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDA1ODM3NQ=="}], "type": "inlineReview"}, {"oid": "3499cc4fb973864178239f0a92a95e8e21feaa45", "url": "https://github.com/prestodb/presto/commit/3499cc4fb973864178239f0a92a95e8e21feaa45", "message": "Apply compression to Presto on Spark splits", "committedDate": "2020-07-14T14:08:19Z", "type": "commit"}, {"oid": "d8d6015c302902f7ff89692c860c85df3b1adf97", "url": "https://github.com/prestodb/presto/commit/d8d6015c302902f7ff89692c860c85df3b1adf97", "message": "Prepare to collect TaskInfo from Presto on Spark tasks", "committedDate": "2020-07-14T14:08:19Z", "type": "commit"}, {"oid": "764bb7728fddd1d57fe46b4801ca6100d49b27ca", "url": "https://github.com/prestodb/presto/commit/764bb7728fddd1d57fe46b4801ca6100d49b27ca", "message": "Collect TaskInfo for Presto on Spark tasks", "committedDate": "2020-07-14T14:45:01Z", "type": "commit"}, {"oid": "44fddb1f7712a67af1083eed9166767f4af57e29", "url": "https://github.com/prestodb/presto/commit/44fddb1f7712a67af1083eed9166767f4af57e29", "message": "Implement QueryMonitor callbacks for Presto on Spark", "committedDate": "2020-07-14T14:45:01Z", "type": "commit"}, {"oid": "a5bf15d92aeabfd8fc76e362f320bb776bf08bc8", "url": "https://github.com/prestodb/presto/commit/a5bf15d92aeabfd8fc76e362f320bb776bf08bc8", "message": "Add ability to register event listener in Presto on Spark", "committedDate": "2020-07-14T14:45:01Z", "type": "commit"}, {"oid": "220dfd7233f2d81bc81d7e3a339355ffb9d72117", "url": "https://github.com/prestodb/presto/commit/220dfd7233f2d81bc81d7e3a339355ffb9d72117", "message": "Allow query info to be stored in a file upon query finish\n\nThis will allow to retrieve query id, stack trace and potentially\nother debug information upon query completition", "committedDate": "2020-07-14T14:45:01Z", "type": "commit"}, {"oid": "220dfd7233f2d81bc81d7e3a339355ffb9d72117", "url": "https://github.com/prestodb/presto/commit/220dfd7233f2d81bc81d7e3a339355ffb9d72117", "message": "Allow query info to be stored in a file upon query finish\n\nThis will allow to retrieve query id, stack trace and potentially\nother debug information upon query completition", "committedDate": "2020-07-14T14:45:01Z", "type": "forcePushed"}]}