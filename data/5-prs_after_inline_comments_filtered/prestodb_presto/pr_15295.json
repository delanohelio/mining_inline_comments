{"pr_number": 15295, "pr_title": "Restore #15130 with null handling fix", "pr_createdAt": "2020-10-09T05:30:29Z", "pr_url": "https://github.com/prestodb/presto/pull/15295", "timeline": [{"oid": "024233be3ba5c6f896547dbdc91df75683d9b0ff", "url": "https://github.com/prestodb/presto/commit/024233be3ba5c6f896547dbdc91df75683d9b0ff", "message": "Revert \"Revert \"Defer the creation of dictionary in SliceDictionarySelectiveReader\"\"\n\nThis reverts commit 8ab725f37277ae91e7218d156ba8158778e86704.", "committedDate": "2020-10-09T05:15:50Z", "type": "commit"}, {"oid": "482d415619503ff8bef3d3a2351700de102e4ad3", "url": "https://github.com/prestodb/presto/commit/482d415619503ff8bef3d3a2351700de102e4ad3", "message": "Revert \"Revert \"Remove stripeDictionaryData buffer in SliceDictionarySelectiveReader\"\"\n\nThis reverts commit 460a4d064bc9ac547e938a98267f651b7e0dd638.", "committedDate": "2020-10-09T05:15:50Z", "type": "commit"}, {"oid": "444357ee6e98b1bcaca8d76d2e1b6c9ec779efa7", "url": "https://github.com/prestodb/presto/commit/444357ee6e98b1bcaca8d76d2e1b6c9ec779efa7", "message": "Introduce large dictionary mode in SliceDictionarySelectiveReader\n\nPreviously we always allocate a dictionary for every rowgroup. When\nthese dictionaries are humongous, the allocations could cause reliability\nand performance issues. This commit materializes the dictionaries if\nthey are too large. Instead of outputting a DictionaryBlock, it will\noutput a plain VariableWidthBlock if the dictionaries size is above\ncertain threshold. The experiment on user reported query shows over 10x\nreduction in allocations and over 2x CPU reduction in scan.", "committedDate": "2020-10-22T01:05:40Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDA3NDQ0Ng==", "url": "https://github.com/prestodb/presto/pull/15295#discussion_r510074446", "bodyText": "Compaction logic is somewhat difficult to get right, hence, it would be better to re-use it by calling compactValues. Also, blockSizeInBytes and nullCount can be computed in separate loops for readability.\n        compactValues(positions, positionCount);\n\n        long blockSizeInBytes = 0;\n        for (int i = 0; i < positionCount; i++) {\n            int id = values[i];\n            blockSizeInBytes += dictionaryOffsetVector[id + 1] - dictionaryOffsetVector[id];\n        }\n\n        int nullCount = 0;  // the nulls count for selected positions\n        for (int i = 0; i < positionCount; i++) {\n            int id = values[i];\n            nullCount += (id == currentDictionarySize - 1 ? 1 : 0);\n        }", "author": "mbasmanova", "createdAt": "2020-10-22T11:07:24Z", "path": "presto-orc/src/main/java/com/facebook/presto/orc/reader/SliceDictionarySelectiveReader.java", "diffHunk": "@@ -384,32 +388,41 @@ public Block getBlock(int[] positions, int positionCount)\n             return new RunLengthEncodedBlock(outputType.createBlockBuilder(null, 1).appendNull().build(), positionCount);\n         }\n \n-        wrapDictionaryIfNecessary();\n+        // compact values(ids) array, and calculate 1) the slice sizeInBytes if materialized, and 2) number of nulls", "originalCommit": "444357ee6e98b1bcaca8d76d2e1b6c9ec779efa7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDQ3NDA3OA==", "url": "https://github.com/prestodb/presto/pull/15295#discussion_r510474078", "bodyText": "@mbasmanova Thanks for the rewrite! How about calculating them in the same loop? This will use less number of lines and still readable:\n        compactValues(positions, positionCount);\n\n        long blockSizeInBytes = 0;\n        int nullCount = 0;\n        for (int i = 0; i < positionCount; i++) {\n            int id = values[i];\n            blockSizeInBytes += dictionaryOffsetVector[id + 1] - dictionaryOffsetVector[id];\n            nullCount += (id == currentDictionarySize - 1 ? 1 : 0);\n        }", "author": "yingsu00", "createdAt": "2020-10-22T21:40:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDA3NDQ0Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDQ3OTg3NQ==", "url": "https://github.com/prestodb/presto/pull/15295#discussion_r510479875", "bodyText": "That works as long as we get to reuse compactValues. Also, null count calculation can be mode a bit more readable:\nif (id == currentDictionarySize - 1) {\n   nullCount++;\n}", "author": "mbasmanova", "createdAt": "2020-10-22T21:53:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDA3NDQ0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDA3NDczNg==", "url": "https://github.com/prestodb/presto/pull/15295#discussion_r510074736", "bodyText": "This doesn't seem right. I think it should be nullCount == positionCount.", "author": "mbasmanova", "createdAt": "2020-10-22T11:07:53Z", "path": "presto-orc/src/main/java/com/facebook/presto/orc/reader/SliceDictionarySelectiveReader.java", "diffHunk": "@@ -384,32 +388,41 @@ public Block getBlock(int[] positions, int positionCount)\n             return new RunLengthEncodedBlock(outputType.createBlockBuilder(null, 1).appendNull().build(), positionCount);\n         }\n \n-        wrapDictionaryIfNecessary();\n+        // compact values(ids) array, and calculate 1) the slice sizeInBytes if materialized, and 2) number of nulls\n+        long blockSizeInBytes = 0;\n+        int nullsCount = 0;  // the nulls count for selected positions\n+        int i = 0;\n+        int j = 0;\n+        while (i < positionCount && j < outputPositionCount) {\n+            if (positions[i] != outputPositions[j]) {\n+                j++;\n+                continue;\n+            }\n \n-        if (positionCount == outputPositionCount) {\n-            DictionaryBlock block = new DictionaryBlock(positionCount, dictionary, values);\n+            int id = this.values[j];\n+            values[i] = id;\n \n-            values = null;\n-            return block;\n+            blockSizeInBytes += dictionaryOffsetVector[id + 1] - dictionaryOffsetVector[id];\n+            nullsCount += (id == currentDictionarySize - 1 ? 1 : 0);\n+\n+            i++;\n+            j++;\n         }\n \n-        int[] valuesCopy = new int[positionCount];\n+        // If all selected positions are null, just return RLE block.\n+        if (nullsCount == outputPositionCount) {", "originalCommit": "444357ee6e98b1bcaca8d76d2e1b6c9ec779efa7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDQ4MjEzNQ==", "url": "https://github.com/prestodb/presto/pull/15295#discussion_r510482135", "bodyText": "Thanks Masha. Yes it should be positionCount.", "author": "yingsu00", "createdAt": "2020-10-22T21:58:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDA3NDczNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDA3NDk5NA==", "url": "https://github.com/prestodb/presto/pull/15295#discussion_r510074994", "bodyText": "naming consistency: nullsCount -> nullCount (to match positionCount and outputPositionCount)", "author": "mbasmanova", "createdAt": "2020-10-22T11:08:26Z", "path": "presto-orc/src/main/java/com/facebook/presto/orc/reader/SliceDictionarySelectiveReader.java", "diffHunk": "@@ -384,32 +388,41 @@ public Block getBlock(int[] positions, int positionCount)\n             return new RunLengthEncodedBlock(outputType.createBlockBuilder(null, 1).appendNull().build(), positionCount);\n         }\n \n-        wrapDictionaryIfNecessary();\n+        // compact values(ids) array, and calculate 1) the slice sizeInBytes if materialized, and 2) number of nulls\n+        long blockSizeInBytes = 0;\n+        int nullsCount = 0;  // the nulls count for selected positions", "originalCommit": "444357ee6e98b1bcaca8d76d2e1b6c9ec779efa7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDA3NTQyNQ==", "url": "https://github.com/prestodb/presto/pull/15295#discussion_r510075425", "bodyText": "nullsCount -> nullCount", "author": "mbasmanova", "createdAt": "2020-10-22T11:09:08Z", "path": "presto-orc/src/main/java/com/facebook/presto/orc/reader/SliceDictionarySelectiveReader.java", "diffHunk": "@@ -691,4 +704,33 @@ private BlockLease newLease(Block block)\n         valuesInUse = true;\n         return ClosingBlockLease.newLease(block, () -> valuesInUse = false);\n     }\n+\n+    private Block getMaterializedBlock(int positionCount, long blockSizeInBytes, int nullsCount)", "originalCommit": "444357ee6e98b1bcaca8d76d2e1b6c9ec779efa7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDA3NjEwNA==", "url": "https://github.com/prestodb/presto/pull/15295#discussion_r510076104", "bodyText": "k -> i", "author": "mbasmanova", "createdAt": "2020-10-22T11:10:26Z", "path": "presto-orc/src/main/java/com/facebook/presto/orc/reader/SliceDictionarySelectiveReader.java", "diffHunk": "@@ -691,4 +704,33 @@ private BlockLease newLease(Block block)\n         valuesInUse = true;\n         return ClosingBlockLease.newLease(block, () -> valuesInUse = false);\n     }\n+\n+    private Block getMaterializedBlock(int positionCount, long blockSizeInBytes, int nullsCount)\n+    {\n+        byte[] sliceData = new byte[toIntExact(blockSizeInBytes)];\n+        int[] offsetVector = new int[positionCount + 1];\n+        int currentOffset = 0;\n+        for (int k = 0; k < positionCount; k++) {", "originalCommit": "444357ee6e98b1bcaca8d76d2e1b6c9ec779efa7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDA3NjE0Ng==", "url": "https://github.com/prestodb/presto/pull/15295#discussion_r510076146", "bodyText": "k -> i", "author": "mbasmanova", "createdAt": "2020-10-22T11:10:31Z", "path": "presto-orc/src/main/java/com/facebook/presto/orc/reader/SliceDictionarySelectiveReader.java", "diffHunk": "@@ -691,4 +704,33 @@ private BlockLease newLease(Block block)\n         valuesInUse = true;\n         return ClosingBlockLease.newLease(block, () -> valuesInUse = false);\n     }\n+\n+    private Block getMaterializedBlock(int positionCount, long blockSizeInBytes, int nullsCount)\n+    {\n+        byte[] sliceData = new byte[toIntExact(blockSizeInBytes)];\n+        int[] offsetVector = new int[positionCount + 1];\n+        int currentOffset = 0;\n+        for (int k = 0; k < positionCount; k++) {\n+            int id = values[k];\n+            int offset = dictionaryOffsetVector[id];\n+            int length = dictionaryOffsetVector[id + 1] - offset;\n+            System.arraycopy(dictionaryData, offset, sliceData, currentOffset, length);\n+\n+            currentOffset += length;\n+            offsetVector[k + 1] = currentOffset;\n+        }\n+\n+        if (nullsCount > 0) {\n+            boolean[] isNullVector = new boolean[positionCount];\n+            for (int k = 0; k < positionCount; k++) {", "originalCommit": "444357ee6e98b1bcaca8d76d2e1b6c9ec779efa7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "d6c3822fbf760f263afbe57e9e9aa458f1a19e1a", "url": "https://github.com/prestodb/presto/commit/d6c3822fbf760f263afbe57e9e9aa458f1a19e1a", "message": "Introduce large dictionary mode in SliceDictionarySelectiveReader\n\nPreviously we always allocate a dictionary for every rowgroup. When\nthese dictionaries are humongous, the allocations could cause reliability\nand performance issues. This commit materializes the dictionaries if\nthey are too large. Instead of outputting a DictionaryBlock, it will\noutput a plain VariableWidthBlock if the dictionaries size is above\ncertain threshold. The experiment on user reported query shows over 10x\nreduction in allocations and over 2x CPU reduction in scan.", "committedDate": "2020-10-22T22:00:30Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDg4ODU5OA==", "url": "https://github.com/prestodb/presto/pull/15295#discussion_r510888598", "bodyText": "k -> i", "author": "mbasmanova", "createdAt": "2020-10-23T13:36:24Z", "path": "presto-orc/src/main/java/com/facebook/presto/orc/reader/SliceDictionarySelectiveReader.java", "diffHunk": "@@ -691,4 +694,33 @@ private BlockLease newLease(Block block)\n         valuesInUse = true;\n         return ClosingBlockLease.newLease(block, () -> valuesInUse = false);\n     }\n+\n+    private Block getMaterializedBlock(int positionCount, long blockSizeInBytes, int nullCount)\n+    {\n+        byte[] sliceData = new byte[toIntExact(blockSizeInBytes)];\n+        int[] offsetVector = new int[positionCount + 1];\n+        int currentOffset = 0;\n+        for (int i = 0; i < positionCount; i++) {\n+            int id = values[i];\n+            int offset = dictionaryOffsetVector[id];\n+            int length = dictionaryOffsetVector[id + 1] - offset;\n+            System.arraycopy(dictionaryData, offset, sliceData, currentOffset, length);\n+\n+            currentOffset += length;\n+            offsetVector[i + 1] = currentOffset;\n+        }\n+\n+        if (nullCount > 0) {\n+            boolean[] isNullVector = new boolean[positionCount];\n+            for (int k = 0; k < positionCount; k++) {", "originalCommit": "d6c3822fbf760f263afbe57e9e9aa458f1a19e1a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "cb8dbd85a5e5e21d2976987986d34902afbdeed6", "url": "https://github.com/prestodb/presto/commit/cb8dbd85a5e5e21d2976987986d34902afbdeed6", "message": "Introduce large dictionary mode in SliceDictionarySelectiveReader\n\nPreviously we always allocate a dictionary for every rowgroup. When\nthese dictionaries are humongous, the allocations could cause reliability\nand performance issues. This commit materializes the dictionaries if\nthey are too large. Instead of outputting a DictionaryBlock, it will\noutput a plain VariableWidthBlock if the dictionaries size is above\ncertain threshold. The experiment on user reported query shows over 10x\nreduction in allocations and over 2x CPU reduction in scan.", "committedDate": "2020-10-30T03:31:20Z", "type": "commit"}, {"oid": "cb8dbd85a5e5e21d2976987986d34902afbdeed6", "url": "https://github.com/prestodb/presto/commit/cb8dbd85a5e5e21d2976987986d34902afbdeed6", "message": "Introduce large dictionary mode in SliceDictionarySelectiveReader\n\nPreviously we always allocate a dictionary for every rowgroup. When\nthese dictionaries are humongous, the allocations could cause reliability\nand performance issues. This commit materializes the dictionaries if\nthey are too large. Instead of outputting a DictionaryBlock, it will\noutput a plain VariableWidthBlock if the dictionaries size is above\ncertain threshold. The experiment on user reported query shows over 10x\nreduction in allocations and over 2x CPU reduction in scan.", "committedDate": "2020-10-30T03:31:20Z", "type": "forcePushed"}]}