{"pr_number": 14834, "pr_title": "Partial Aggregation Pushdown for ORC/Parquet", "pr_createdAt": "2020-07-13T17:01:23Z", "pr_url": "https://github.com/prestodb/presto/pull/14834", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI0NzYwMA==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r458247600", "bodyText": "We don't have to just return TableScanNode. We could still have the AggNode -> TableScanNode to make the optimizer doesn't fail. This assumption holds given the input type for min/max is the same for its output.", "author": "highker", "createdAt": "2020-07-21T16:55:45Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HivePartialAggregationPushdown.java", "diffHunk": "@@ -0,0 +1,258 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive;\n+\n+import com.facebook.presto.common.type.Type;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableMetadata;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.function.FunctionHandle;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.AggregationNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.relation.CallExpression;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+\n+import javax.inject.Inject;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.Supplier;\n+\n+import static com.facebook.presto.common.type.BooleanType.BOOLEAN;\n+import static com.facebook.presto.common.type.TimestampType.TIMESTAMP;\n+import static com.facebook.presto.common.type.TinyintType.TINYINT;\n+import static com.facebook.presto.common.type.VarbinaryType.VARBINARY;\n+import static com.facebook.presto.hive.HiveSessionProperties.isPartialAggregationPushdownEnabled;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.isArrayType;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.isMapType;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.isRowType;\n+import static com.facebook.presto.spi.StandardErrorCode.NOT_FOUND;\n+import static com.facebook.presto.spi.plan.AggregationNode.Step.PARTIAL;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+\n+public class HivePartialAggregationPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private final FunctionMetadataManager functionMetadataManager;\n+    private final StandardFunctionResolution standardFunctionResolution;\n+    private final Supplier<TransactionalMetadata> metadataFactory;\n+\n+    @Inject\n+    public HivePartialAggregationPushdown(\n+            FunctionMetadataManager functionMetadataManager,\n+            StandardFunctionResolution standardFunctionResolution,\n+            Supplier<TransactionalMetadata> metadataFactory)\n+    {\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"function manager is null\");\n+        this.standardFunctionResolution = requireNonNull(standardFunctionResolution, \"standard function resolution is null\");\n+        this.metadataFactory = requireNonNull(metadataFactory, \"metadata factory is null\");\n+    }\n+\n+    private static Optional<HiveTableHandle> getHiveTableHandle(TableScanNode tableScanNode)\n+    {\n+        TableHandle table = tableScanNode.getTable();\n+        if (table != null) {\n+            ConnectorTableHandle connectorHandle = table.getConnectorHandle();\n+            if (connectorHandle instanceof HiveTableHandle) {\n+                return Optional.of((HiveTableHandle) connectorHandle);\n+            }\n+        }\n+        return Optional.empty();\n+    }\n+\n+    private static PlanNode replaceChildren(PlanNode node, List<PlanNode> children)\n+    {\n+        return children.containsAll(node.getSources()) ? node : node.replaceChildren(children);\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan,\n+            ConnectorSession session,\n+            VariableAllocator variableAllocator,\n+            PlanNodeIdAllocator idAllocator)\n+    {\n+        if (!isPartialAggregationPushdownEnabled(session)) {\n+            return maxSubplan;\n+        }\n+        return maxSubplan.accept(new Visitor(variableAllocator, session, idAllocator), null);\n+    }\n+\n+    private class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        private final PlanNodeIdAllocator idAllocator;\n+        private final ConnectorSession session;\n+        private final VariableAllocator variableAllocator;\n+\n+        public Visitor(VariableAllocator variableAllocator, ConnectorSession session, PlanNodeIdAllocator idAllocator)\n+        {\n+            this.session = session;\n+            this.idAllocator = idAllocator;\n+            this.variableAllocator = variableAllocator;\n+        }\n+\n+        private Optional<PlanNode> tryPartialAggregationPushdown(PlanNode plan)\n+        {\n+            if (!(plan instanceof AggregationNode\n+                    && ((AggregationNode) plan).getStep().equals(PARTIAL)\n+                    && ((AggregationNode) plan).getSource() instanceof TableScanNode)) {\n+                return Optional.empty();\n+            }\n+\n+            AggregationNode partialAggregationNode = (AggregationNode) plan;\n+            if (partialAggregationNode.hasNonEmptyGroupingSet()) {\n+                return Optional.empty();\n+            }\n+            TableScanNode oldTableScanNode = (TableScanNode) partialAggregationNode.getSource();\n+            TableHandle oldTableHandle = oldTableScanNode.getTable();\n+            HiveTableHandle hiveTableHandle = getHiveTableHandle(oldTableScanNode).orElseThrow(() -> new PrestoException(NOT_FOUND, \"Hive table handle not found\"));\n+\n+            ConnectorTableMetadata connectorTableMetadata = metadataFactory.get().getTableMetadata(session, oldTableHandle.getConnectorHandle());\n+            Optional<Object> rawFormat = Optional.ofNullable(connectorTableMetadata.getProperties().get(HiveTableProperties.STORAGE_FORMAT_PROPERTY));\n+            if (!rawFormat.isPresent()) {\n+                return Optional.empty();\n+            }\n+            final HiveStorageFormat hiveStorageFormat = HiveStorageFormat.valueOf(rawFormat.get().toString());\n+            if (hiveStorageFormat != HiveStorageFormat.ORC && hiveStorageFormat != HiveStorageFormat.PARQUET) {\n+                return Optional.empty();\n+            }\n+\n+            /**\n+             * Aggregation push downs are supported only on primitive types and supported aggregation functions are:\n+             * count(*), count(columnName), min(columnName), max(columnName)\n+             */\n+            for (AggregationNode.Aggregation aggregation : partialAggregationNode.getAggregations().values()) {\n+                FunctionHandle functionHandle = aggregation.getFunctionHandle();\n+                if (!(standardFunctionResolution.isCountFunction(functionHandle) ||\n+                        standardFunctionResolution.isMaxFunction(functionHandle) ||\n+                        standardFunctionResolution.isMinFunction(functionHandle))) {\n+                    return Optional.empty();\n+                }\n+\n+                if (aggregation.getArguments().isEmpty() && !standardFunctionResolution.isCountFunction(functionHandle)) {\n+                    return Optional.empty();\n+                }\n+\n+                List<RowExpression> arguments = aggregation.getArguments();\n+                if (arguments.size() > 1) {\n+                    return Optional.empty();\n+                }\n+\n+                if (standardFunctionResolution.isMinFunction(functionHandle) || standardFunctionResolution.isMaxFunction(functionHandle)) {\n+                    // Only allow supported datatypes for min/max\n+                    Type type = arguments.get(0).getType();\n+                    if (BOOLEAN.equals(type) ||\n+                            type.getJavaType() == boolean.class ||\n+                            isRowType(type) ||\n+                            isArrayType(type) ||\n+                            isMapType(type)) {\n+                        return Optional.empty();\n+                    }\n+\n+                    if (hiveStorageFormat == HiveStorageFormat.ORC) {\n+                        if (TINYINT.equals(type) ||\n+                                VARBINARY.equals(type) ||\n+                                TIMESTAMP.equals(type)) {\n+                            return Optional.empty();\n+                        }\n+                    }\n+                }\n+            }\n+\n+            HiveTypeTranslator hiveTypeTranslator = new HiveTypeTranslator();\n+            Map<VariableReferenceExpression, ColumnHandle> assignments = new HashMap<>();\n+            for (Map.Entry<VariableReferenceExpression, AggregationNode.Aggregation> aggregationEntry : partialAggregationNode.getAggregations().entrySet()) {\n+                CallExpression callExpression = aggregationEntry.getValue().getCall();\n+                String colName = \"count_star\";\n+                int columnIndex = -20;\n+                HiveType hiveType = HiveType.toHiveType(hiveTypeTranslator, callExpression.getType());\n+                if (!callExpression.getArguments().isEmpty()) {\n+                    RowExpression column = callExpression.getArguments().get(0);\n+                    colName = column.toString();\n+                    HiveColumnHandle oldColumnHandle = (HiveColumnHandle) oldTableScanNode.getAssignments().get(column);\n+                    columnIndex = oldColumnHandle.getHiveColumnIndex();\n+                    hiveType = oldColumnHandle.getHiveType();\n+                }\n+\n+                ColumnHandle newColumnHandle = new HiveColumnHandle(\n+                        colName,\n+                        hiveType,\n+                        callExpression.getType().getTypeSignature(),\n+                        columnIndex,\n+                        HiveColumnHandle.ColumnType.AGGREGATED,\n+                        Optional.of(\"partial aggregation pushed down\"),\n+                        Optional.of(aggregationEntry.getValue()));\n+                assignments.put(aggregationEntry.getKey(), newColumnHandle);\n+            }\n+\n+            HiveTableLayoutHandle oldTableLayoutHandle = (HiveTableLayoutHandle) oldTableHandle.getLayout().get();\n+            HiveTableLayoutHandle newTableLayoutHandle = new HiveTableLayoutHandle(oldTableLayoutHandle.getSchemaTableName(),\n+                    oldTableLayoutHandle.getPartitionColumns(),\n+                    oldTableLayoutHandle.getDataColumns(),\n+                    oldTableLayoutHandle.getTableParameters(),\n+                    oldTableLayoutHandle.getPartitions().get(),\n+                    oldTableLayoutHandle.getDomainPredicate(),\n+                    oldTableLayoutHandle.getRemainingPredicate(),\n+                    oldTableLayoutHandle.getPredicateColumns(),\n+                    oldTableLayoutHandle.getPartitionColumnPredicate(),\n+                    oldTableLayoutHandle.getBucketHandle(),\n+                    oldTableLayoutHandle.getBucketFilter(),\n+                    oldTableLayoutHandle.isPushdownFilterEnabled(),\n+                    oldTableLayoutHandle.getLayoutString(),\n+                    oldTableLayoutHandle.getRequestedColumns(),\n+                    true);\n+\n+            TableHandle newTableHandle = new TableHandle(\n+                    oldTableHandle.getConnectorId(),\n+                    hiveTableHandle,\n+                    oldTableHandle.getTransaction(),\n+                    Optional.of(newTableLayoutHandle));\n+\n+            return Optional.of(new\n+\n+                    TableScanNode(\n+                    idAllocator.getNextId(),\n+                    newTableHandle,\n+                    ImmutableList.copyOf(partialAggregationNode.getOutputVariables()),\n+                    ImmutableMap.copyOf(assignments),\n+                    oldTableScanNode.getCurrentConstraint(),\n+                    oldTableScanNode.getEnforcedConstraint()));", "originalCommit": "1d255a6130fad7625791988bf75f447b44939712", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAxMzY5NA==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r466013694", "bodyText": "As we discussed elsewhere, this would work for min/max - but we would lose the functionality of realizing aggregate pushdown for the two flavors of count (count(*) and count(column name)) that is currently implemented in this PR. Is it worth it to maintain this invariant, given the potential loss of functionality?", "author": "ClarenceThreepwood", "createdAt": "2020-08-05T21:26:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI0NzYwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjE4NDUxOQ==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r466184519", "bodyText": "Let's have it at the moment. BTW, ORC min/max is not tied. They are not necessarily the tight upper or lower bound of the data. With this, potentially, we will have correctness issues. Have you thought about that?", "author": "highker", "createdAt": "2020-08-06T06:54:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI0NzYwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDgwODEwNQ==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r480808105", "bodyText": "Added a new session parameter to control partial aggregation pushdown for variable length types to handle truncation/overflow", "author": "ClarenceThreepwood", "createdAt": "2020-09-01T04:57:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI0NzYwMA=="}], "type": "inlineReview"}, {"oid": "9b53a7d45ee602c6aa82140768d4ecb7b1af1639", "url": "https://github.com/prestodb/presto/commit/9b53a7d45ee602c6aa82140768d4ecb7b1af1639", "message": "Partial Aggregation Pushdown for ORC/Parquet", "committedDate": "2020-08-17T21:41:18Z", "type": "forcePushed"}, {"oid": "2e8acfd14d23a4736169c171d0955cc87b521471", "url": "https://github.com/prestodb/presto/commit/2e8acfd14d23a4736169c171d0955cc87b521471", "message": "Partial Aggregation Pushdown for ORC/Parquet", "committedDate": "2020-08-17T23:03:28Z", "type": "forcePushed"}, {"oid": "ed7e2525eaffc89b2f057bf359277d944a58aa18", "url": "https://github.com/prestodb/presto/commit/ed7e2525eaffc89b2f057bf359277d944a58aa18", "message": "Partial Aggregation Pushdown for ORC/Parquet", "committedDate": "2020-08-18T00:37:38Z", "type": "forcePushed"}, {"oid": "e50fbbcf7e048bb2d42461f92ccb371660bc648e", "url": "https://github.com/prestodb/presto/commit/e50fbbcf7e048bb2d42461f92ccb371660bc648e", "message": "Partial Aggregation Pushdown for ORC/Parquet", "committedDate": "2020-08-26T03:46:59Z", "type": "forcePushed"}, {"oid": "0cabcd99a4e45fde14845e3a019ce608590d7773", "url": "https://github.com/prestodb/presto/commit/0cabcd99a4e45fde14845e3a019ce608590d7773", "message": "Partial Aggregation Pushdown for ORC/Parquet", "committedDate": "2020-08-26T06:53:52Z", "type": "forcePushed"}, {"oid": "ed800f1a7409eda550397f6d76b1141764aae662", "url": "https://github.com/prestodb/presto/commit/ed800f1a7409eda550397f6d76b1141764aae662", "message": "Partial Aggregation Pushdown for ORC/Parquet", "committedDate": "2020-08-26T15:49:15Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU0NDIyMQ==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478544221", "bodyText": "nit: Maybe also edit the comment to include partialAggregationsPushedDown? Though it is obvious but let's keep the comment up-to-date :)", "author": "shixuan-fan", "createdAt": "2020-08-27T16:25:40Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/BackgroundHiveSplitLoader.java", "diffHunk": "@@ -387,7 +390,7 @@ private void invokeNoMoreSplitsIfNecessary()\n         // therefore we must not split files when it is enabled.\n         Properties schema = getHiveSchema(storage.getSerdeParameters(), table.getParameters());\n         // Skip header / footer lines are not splittable except for a special case when skip.header.line.count=1\n-        boolean splittable = !s3SelectPushdownEnabled && getFooterCount(schema) == 0 && getHeaderCount(schema) <= 1;\n+        boolean splittable = !s3SelectPushdownEnabled && !partialAggregationsPushedDown && getFooterCount(schema) == 0 && getHeaderCount(schema) <= 1;", "originalCommit": "ed800f1a7409eda550397f6d76b1141764aae662", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU0NDgzMw==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478544833", "bodyText": "nit: enable", "author": "shixuan-fan", "createdAt": "2020-08-27T16:26:38Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveClientConfig.java", "diffHunk": "@@ -1438,4 +1441,30 @@ public boolean isParquetDereferencePushdownEnabled()\n     {\n         return this.parquetDereferencePushdownEnabled;\n     }\n+\n+    @Config(\"hive.enable_partial_aggregation_pushdown\")\n+    @ConfigDescription(\"enabled partial aggregation pushdown\")", "originalCommit": "ed800f1a7409eda550397f6d76b1141764aae662", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU0NTEwNQ==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478545105", "bodyText": "nit: enable\nDo we really need a separate config?", "author": "shixuan-fan", "createdAt": "2020-08-27T16:27:00Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveClientConfig.java", "diffHunk": "@@ -1438,4 +1441,30 @@ public boolean isParquetDereferencePushdownEnabled()\n     {\n         return this.parquetDereferencePushdownEnabled;\n     }\n+\n+    @Config(\"hive.enable_partial_aggregation_pushdown\")\n+    @ConfigDescription(\"enabled partial aggregation pushdown\")\n+    public HiveClientConfig setPartialAggregationPushdownEnabled(boolean partialAggregationPushdownEnabled)\n+    {\n+        this.isPartialAggregationPushdownEnabled = partialAggregationPushdownEnabled;\n+        return this;\n+    }\n+\n+    public boolean isPartialAggregationPushdownEnabled()\n+    {\n+        return this.isPartialAggregationPushdownEnabled;\n+    }\n+\n+    @Config(\"hive.enable_partial_aggregation_pushdown_for_variable_length_datatypes\")\n+    @ConfigDescription(\"enabled partial aggregation pushdown for variable length datatypes\")", "originalCommit": "ed800f1a7409eda550397f6d76b1141764aae662", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTgxMDU5NA==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r479810594", "bodyText": "I introduced this as the result of a discussion with @highker. Theoretically, the file formats (orc and parquet) specify that if the statistics are truncated in the metadata for large values, then the writers should set a flag to indicate that the values are not the true max/min, and that getmax/getmin should always return null. These truncated max/min would only be accessible via the accessor methods getLowerBound/getUpperBound. However @highker was worried that there may be writers who do not follow this contract and therefore may result in wrong results", "author": "ClarenceThreepwood", "createdAt": "2020-08-30T20:10:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU0NTEwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU0NTU0NQ==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478545545", "bodyText": "nit: static import", "author": "shixuan-fan", "createdAt": "2020-08-27T16:27:44Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveColumnHandle.java", "diffHunk": "@@ -78,16 +82,19 @@ public HiveColumnHandle(\n             @JsonProperty(\"hiveColumnIndex\") int hiveColumnIndex,\n             @JsonProperty(\"columnType\") ColumnType columnType,\n             @JsonProperty(\"comment\") Optional<String> comment,\n-            @JsonProperty(\"requiredSubfields\") List<Subfield> requiredSubfields)\n+            @JsonProperty(\"requiredSubfields\") List<Subfield> requiredSubfields,\n+            @JsonProperty(\"partialAggregation\") Optional<AggregationNode.Aggregation> partialAggregation)", "originalCommit": "ed800f1a7409eda550397f6d76b1141764aae662", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU0NjY4Ng==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478546686", "bodyText": "There is only three non-test callsites and the rest are tests. Maybe we don't need to introduce this new constructor?", "author": "shixuan-fan", "createdAt": "2020-08-27T16:29:32Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveColumnHandle.java", "diffHunk": "@@ -98,7 +105,19 @@ public HiveColumnHandle(\n             ColumnType columnType,\n             Optional<String> comment)\n     {\n-        this(name, hiveType, typeSignature, hiveColumnIndex, columnType, comment, ImmutableList.of());\n+        this(name, hiveType, typeSignature, hiveColumnIndex, columnType, comment, ImmutableList.of(), Optional.empty());\n+    }\n+\n+    public HiveColumnHandle(", "originalCommit": "ed800f1a7409eda550397f6d76b1141764aae662", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTgyNDY5NQ==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r479824695", "bodyText": "To keep the code clean, I retained this constructor and removed the previous one. Let me know if you disagree", "author": "ClarenceThreepwood", "createdAt": "2020-08-30T22:38:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU0NjY4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU0Njk3Ng==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478546976", "bodyText": "nit: unrelated change", "author": "shixuan-fan", "createdAt": "2020-08-27T16:29:55Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveColumnHandle.java", "diffHunk": "@@ -165,7 +190,8 @@ public ColumnHandle withRequiredSubfields(List<Subfield> subfields)\n             // This column is already a pushed down subfield column\n             return this;\n         }\n-        return new HiveColumnHandle(name, hiveType, typeName, hiveColumnIndex, columnType, comment, subfields);\n+", "originalCommit": "ed800f1a7409eda550397f6d76b1141764aae662", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU1MjY3Mg==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478552672", "bodyText": "nit: maybe add a comment like INTERIM?", "author": "shixuan-fan", "createdAt": "2020-08-27T16:39:20Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HivePageSource.java", "diffHunk": "@@ -161,6 +161,8 @@ public Page getNextPage()\n                     case INTERIM:\n                         // interim columns don't show up in output\n                         break;\n+                    case AGGREGATED:", "originalCommit": "ed800f1a7409eda550397f6d76b1141764aae662", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU1NjY5NQ==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478556695", "bodyText": "nit: Can we extract this into a separate method: isAggregationPushdownSupported(...)?", "author": "shixuan-fan", "createdAt": "2020-08-27T16:46:06Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HivePartialAggregationPushdown.java", "diffHunk": "@@ -0,0 +1,264 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive;\n+\n+import com.facebook.presto.common.type.Type;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableMetadata;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.function.FunctionHandle;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.AggregationNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.relation.CallExpression;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+\n+import javax.inject.Inject;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.Supplier;\n+\n+import static com.facebook.presto.common.type.BooleanType.BOOLEAN;\n+import static com.facebook.presto.common.type.TimestampType.TIMESTAMP;\n+import static com.facebook.presto.common.type.TinyintType.TINYINT;\n+import static com.facebook.presto.common.type.VarbinaryType.VARBINARY;\n+import static com.facebook.presto.common.type.VarcharType.VARCHAR;\n+import static com.facebook.presto.hive.HiveSessionProperties.isPartialAggregationPushdownEnabled;\n+import static com.facebook.presto.hive.HiveSessionProperties.isPartialAggregationPushdownForVariableLengthDatatypesEnabled;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.isArrayType;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.isMapType;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.isRowType;\n+import static com.facebook.presto.spi.StandardErrorCode.NOT_FOUND;\n+import static com.facebook.presto.spi.plan.AggregationNode.Step.PARTIAL;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+\n+public class HivePartialAggregationPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private final FunctionMetadataManager functionMetadataManager;\n+    private final StandardFunctionResolution standardFunctionResolution;\n+    private final Supplier<TransactionalMetadata> metadataFactory;\n+\n+    @Inject\n+    public HivePartialAggregationPushdown(\n+            FunctionMetadataManager functionMetadataManager,\n+            StandardFunctionResolution standardFunctionResolution,\n+            Supplier<TransactionalMetadata> metadataFactory)\n+    {\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"function manager is null\");\n+        this.standardFunctionResolution = requireNonNull(standardFunctionResolution, \"standard function resolution is null\");\n+        this.metadataFactory = requireNonNull(metadataFactory, \"metadata factory is null\");\n+    }\n+\n+    private static Optional<HiveTableHandle> getHiveTableHandle(TableScanNode tableScanNode)\n+    {\n+        TableHandle table = tableScanNode.getTable();\n+        if (table != null) {\n+            ConnectorTableHandle connectorHandle = table.getConnectorHandle();\n+            if (connectorHandle instanceof HiveTableHandle) {\n+                return Optional.of((HiveTableHandle) connectorHandle);\n+            }\n+        }\n+        return Optional.empty();\n+    }\n+\n+    private static PlanNode replaceChildren(PlanNode node, List<PlanNode> children)\n+    {\n+        return children.containsAll(node.getSources()) ? node : node.replaceChildren(children);\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan,\n+            ConnectorSession session,\n+            VariableAllocator variableAllocator,\n+            PlanNodeIdAllocator idAllocator)\n+    {\n+        if (!isPartialAggregationPushdownEnabled(session)) {\n+            return maxSubplan;\n+        }\n+        return maxSubplan.accept(new Visitor(variableAllocator, session, idAllocator), null);\n+    }\n+\n+    private class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        private final PlanNodeIdAllocator idAllocator;\n+        private final ConnectorSession session;\n+        private final VariableAllocator variableAllocator;\n+\n+        public Visitor(VariableAllocator variableAllocator, ConnectorSession session, PlanNodeIdAllocator idAllocator)\n+        {\n+            this.session = session;\n+            this.idAllocator = idAllocator;\n+            this.variableAllocator = variableAllocator;\n+        }\n+\n+        private Optional<PlanNode> tryPartialAggregationPushdown(PlanNode plan)\n+        {\n+            if (!(plan instanceof AggregationNode\n+                    && ((AggregationNode) plan).getStep().equals(PARTIAL)\n+                    && ((AggregationNode) plan).getSource() instanceof TableScanNode)) {\n+                return Optional.empty();\n+            }\n+\n+            AggregationNode partialAggregationNode = (AggregationNode) plan;\n+            if (partialAggregationNode.hasNonEmptyGroupingSet()) {\n+                return Optional.empty();\n+            }\n+            TableScanNode oldTableScanNode = (TableScanNode) partialAggregationNode.getSource();\n+            TableHandle oldTableHandle = oldTableScanNode.getTable();\n+            HiveTableHandle hiveTableHandle = getHiveTableHandle(oldTableScanNode).orElseThrow(() -> new PrestoException(NOT_FOUND, \"Hive table handle not found\"));\n+\n+            ConnectorTableMetadata connectorTableMetadata = metadataFactory.get().getTableMetadata(session, oldTableHandle.getConnectorHandle());\n+            Optional<Object> rawFormat = Optional.ofNullable(connectorTableMetadata.getProperties().get(HiveTableProperties.STORAGE_FORMAT_PROPERTY));\n+            if (!rawFormat.isPresent()) {\n+                return Optional.empty();\n+            }\n+            final HiveStorageFormat hiveStorageFormat = HiveStorageFormat.valueOf(rawFormat.get().toString());\n+            if (hiveStorageFormat != HiveStorageFormat.ORC && hiveStorageFormat != HiveStorageFormat.PARQUET) {\n+                return Optional.empty();\n+            }\n+\n+            /**\n+             * Aggregation push downs are supported only on primitive types and supported aggregation functions are:\n+             * count(*), count(columnName), min(columnName), max(columnName)\n+             */\n+            for (AggregationNode.Aggregation aggregation : partialAggregationNode.getAggregations().values()) {", "originalCommit": "ed800f1a7409eda550397f6d76b1141764aae662", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU3MzA3NQ==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478573075", "bodyText": "nit: let's only declare these fields here and assign it in the else clause. It's a little bit confusing as one might interpret this as default.", "author": "shixuan-fan", "createdAt": "2020-08-27T17:14:25Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HivePartialAggregationPushdown.java", "diffHunk": "@@ -0,0 +1,264 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive;\n+\n+import com.facebook.presto.common.type.Type;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableMetadata;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.function.FunctionHandle;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.AggregationNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.relation.CallExpression;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+\n+import javax.inject.Inject;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.Supplier;\n+\n+import static com.facebook.presto.common.type.BooleanType.BOOLEAN;\n+import static com.facebook.presto.common.type.TimestampType.TIMESTAMP;\n+import static com.facebook.presto.common.type.TinyintType.TINYINT;\n+import static com.facebook.presto.common.type.VarbinaryType.VARBINARY;\n+import static com.facebook.presto.common.type.VarcharType.VARCHAR;\n+import static com.facebook.presto.hive.HiveSessionProperties.isPartialAggregationPushdownEnabled;\n+import static com.facebook.presto.hive.HiveSessionProperties.isPartialAggregationPushdownForVariableLengthDatatypesEnabled;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.isArrayType;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.isMapType;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.isRowType;\n+import static com.facebook.presto.spi.StandardErrorCode.NOT_FOUND;\n+import static com.facebook.presto.spi.plan.AggregationNode.Step.PARTIAL;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+\n+public class HivePartialAggregationPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private final FunctionMetadataManager functionMetadataManager;\n+    private final StandardFunctionResolution standardFunctionResolution;\n+    private final Supplier<TransactionalMetadata> metadataFactory;\n+\n+    @Inject\n+    public HivePartialAggregationPushdown(\n+            FunctionMetadataManager functionMetadataManager,\n+            StandardFunctionResolution standardFunctionResolution,\n+            Supplier<TransactionalMetadata> metadataFactory)\n+    {\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"function manager is null\");\n+        this.standardFunctionResolution = requireNonNull(standardFunctionResolution, \"standard function resolution is null\");\n+        this.metadataFactory = requireNonNull(metadataFactory, \"metadata factory is null\");\n+    }\n+\n+    private static Optional<HiveTableHandle> getHiveTableHandle(TableScanNode tableScanNode)\n+    {\n+        TableHandle table = tableScanNode.getTable();\n+        if (table != null) {\n+            ConnectorTableHandle connectorHandle = table.getConnectorHandle();\n+            if (connectorHandle instanceof HiveTableHandle) {\n+                return Optional.of((HiveTableHandle) connectorHandle);\n+            }\n+        }\n+        return Optional.empty();\n+    }\n+\n+    private static PlanNode replaceChildren(PlanNode node, List<PlanNode> children)\n+    {\n+        return children.containsAll(node.getSources()) ? node : node.replaceChildren(children);\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan,\n+            ConnectorSession session,\n+            VariableAllocator variableAllocator,\n+            PlanNodeIdAllocator idAllocator)\n+    {\n+        if (!isPartialAggregationPushdownEnabled(session)) {\n+            return maxSubplan;\n+        }\n+        return maxSubplan.accept(new Visitor(variableAllocator, session, idAllocator), null);\n+    }\n+\n+    private class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        private final PlanNodeIdAllocator idAllocator;\n+        private final ConnectorSession session;\n+        private final VariableAllocator variableAllocator;\n+\n+        public Visitor(VariableAllocator variableAllocator, ConnectorSession session, PlanNodeIdAllocator idAllocator)\n+        {\n+            this.session = session;\n+            this.idAllocator = idAllocator;\n+            this.variableAllocator = variableAllocator;\n+        }\n+\n+        private Optional<PlanNode> tryPartialAggregationPushdown(PlanNode plan)\n+        {\n+            if (!(plan instanceof AggregationNode\n+                    && ((AggregationNode) plan).getStep().equals(PARTIAL)\n+                    && ((AggregationNode) plan).getSource() instanceof TableScanNode)) {\n+                return Optional.empty();\n+            }\n+\n+            AggregationNode partialAggregationNode = (AggregationNode) plan;\n+            if (partialAggregationNode.hasNonEmptyGroupingSet()) {\n+                return Optional.empty();\n+            }\n+            TableScanNode oldTableScanNode = (TableScanNode) partialAggregationNode.getSource();\n+            TableHandle oldTableHandle = oldTableScanNode.getTable();\n+            HiveTableHandle hiveTableHandle = getHiveTableHandle(oldTableScanNode).orElseThrow(() -> new PrestoException(NOT_FOUND, \"Hive table handle not found\"));\n+\n+            ConnectorTableMetadata connectorTableMetadata = metadataFactory.get().getTableMetadata(session, oldTableHandle.getConnectorHandle());\n+            Optional<Object> rawFormat = Optional.ofNullable(connectorTableMetadata.getProperties().get(HiveTableProperties.STORAGE_FORMAT_PROPERTY));\n+            if (!rawFormat.isPresent()) {\n+                return Optional.empty();\n+            }\n+            final HiveStorageFormat hiveStorageFormat = HiveStorageFormat.valueOf(rawFormat.get().toString());\n+            if (hiveStorageFormat != HiveStorageFormat.ORC && hiveStorageFormat != HiveStorageFormat.PARQUET) {\n+                return Optional.empty();\n+            }\n+\n+            /**\n+             * Aggregation push downs are supported only on primitive types and supported aggregation functions are:\n+             * count(*), count(columnName), min(columnName), max(columnName)\n+             */\n+            for (AggregationNode.Aggregation aggregation : partialAggregationNode.getAggregations().values()) {\n+                FunctionHandle functionHandle = aggregation.getFunctionHandle();\n+                if (!(standardFunctionResolution.isCountFunction(functionHandle) ||\n+                        standardFunctionResolution.isMaxFunction(functionHandle) ||\n+                        standardFunctionResolution.isMinFunction(functionHandle))) {\n+                    return Optional.empty();\n+                }\n+\n+                if (aggregation.getArguments().isEmpty() && !standardFunctionResolution.isCountFunction(functionHandle)) {\n+                    return Optional.empty();\n+                }\n+\n+                List<RowExpression> arguments = aggregation.getArguments();\n+                if (arguments.size() > 1) {\n+                    return Optional.empty();\n+                }\n+\n+                if (standardFunctionResolution.isMinFunction(functionHandle) || standardFunctionResolution.isMaxFunction(functionHandle)) {\n+                    // Only allow supported datatypes for min/max\n+                    Type type = arguments.get(0).getType();\n+                    if (BOOLEAN.equals(type) ||\n+                            type.getJavaType() == boolean.class ||\n+                            isRowType(type) ||\n+                            isArrayType(type) ||\n+                            isMapType(type)) {\n+                        return Optional.empty();\n+                    }\n+\n+                    if (hiveStorageFormat == HiveStorageFormat.ORC) {\n+                        if (TINYINT.equals(type) ||\n+                                VARBINARY.equals(type) ||\n+                                TIMESTAMP.equals(type)) {\n+                            return Optional.empty();\n+                        }\n+                    }\n+\n+                    if ((VARBINARY.equals(type) || VARCHAR.equals(type)) &&\n+                            !isPartialAggregationPushdownForVariableLengthDatatypesEnabled(session)) {\n+                        return Optional.empty();\n+                    }\n+                }\n+            }\n+\n+            HiveTypeTranslator hiveTypeTranslator = new HiveTypeTranslator();\n+            Map<VariableReferenceExpression, ColumnHandle> assignments = new HashMap<>();\n+            for (Map.Entry<VariableReferenceExpression, AggregationNode.Aggregation> aggregationEntry : partialAggregationNode.getAggregations().entrySet()) {\n+                CallExpression callExpression = aggregationEntry.getValue().getCall();\n+                String colName = \"count_star\";", "originalCommit": "ed800f1a7409eda550397f6d76b1141764aae662", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU3MzI1Ng==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478573256", "bodyText": "Curious: where does this -20 come from?", "author": "shixuan-fan", "createdAt": "2020-08-27T17:14:45Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HivePartialAggregationPushdown.java", "diffHunk": "@@ -0,0 +1,264 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive;\n+\n+import com.facebook.presto.common.type.Type;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableMetadata;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.function.FunctionHandle;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.AggregationNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.relation.CallExpression;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+\n+import javax.inject.Inject;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.Supplier;\n+\n+import static com.facebook.presto.common.type.BooleanType.BOOLEAN;\n+import static com.facebook.presto.common.type.TimestampType.TIMESTAMP;\n+import static com.facebook.presto.common.type.TinyintType.TINYINT;\n+import static com.facebook.presto.common.type.VarbinaryType.VARBINARY;\n+import static com.facebook.presto.common.type.VarcharType.VARCHAR;\n+import static com.facebook.presto.hive.HiveSessionProperties.isPartialAggregationPushdownEnabled;\n+import static com.facebook.presto.hive.HiveSessionProperties.isPartialAggregationPushdownForVariableLengthDatatypesEnabled;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.isArrayType;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.isMapType;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.isRowType;\n+import static com.facebook.presto.spi.StandardErrorCode.NOT_FOUND;\n+import static com.facebook.presto.spi.plan.AggregationNode.Step.PARTIAL;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+\n+public class HivePartialAggregationPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private final FunctionMetadataManager functionMetadataManager;\n+    private final StandardFunctionResolution standardFunctionResolution;\n+    private final Supplier<TransactionalMetadata> metadataFactory;\n+\n+    @Inject\n+    public HivePartialAggregationPushdown(\n+            FunctionMetadataManager functionMetadataManager,\n+            StandardFunctionResolution standardFunctionResolution,\n+            Supplier<TransactionalMetadata> metadataFactory)\n+    {\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"function manager is null\");\n+        this.standardFunctionResolution = requireNonNull(standardFunctionResolution, \"standard function resolution is null\");\n+        this.metadataFactory = requireNonNull(metadataFactory, \"metadata factory is null\");\n+    }\n+\n+    private static Optional<HiveTableHandle> getHiveTableHandle(TableScanNode tableScanNode)\n+    {\n+        TableHandle table = tableScanNode.getTable();\n+        if (table != null) {\n+            ConnectorTableHandle connectorHandle = table.getConnectorHandle();\n+            if (connectorHandle instanceof HiveTableHandle) {\n+                return Optional.of((HiveTableHandle) connectorHandle);\n+            }\n+        }\n+        return Optional.empty();\n+    }\n+\n+    private static PlanNode replaceChildren(PlanNode node, List<PlanNode> children)\n+    {\n+        return children.containsAll(node.getSources()) ? node : node.replaceChildren(children);\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan,\n+            ConnectorSession session,\n+            VariableAllocator variableAllocator,\n+            PlanNodeIdAllocator idAllocator)\n+    {\n+        if (!isPartialAggregationPushdownEnabled(session)) {\n+            return maxSubplan;\n+        }\n+        return maxSubplan.accept(new Visitor(variableAllocator, session, idAllocator), null);\n+    }\n+\n+    private class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        private final PlanNodeIdAllocator idAllocator;\n+        private final ConnectorSession session;\n+        private final VariableAllocator variableAllocator;\n+\n+        public Visitor(VariableAllocator variableAllocator, ConnectorSession session, PlanNodeIdAllocator idAllocator)\n+        {\n+            this.session = session;\n+            this.idAllocator = idAllocator;\n+            this.variableAllocator = variableAllocator;\n+        }\n+\n+        private Optional<PlanNode> tryPartialAggregationPushdown(PlanNode plan)\n+        {\n+            if (!(plan instanceof AggregationNode\n+                    && ((AggregationNode) plan).getStep().equals(PARTIAL)\n+                    && ((AggregationNode) plan).getSource() instanceof TableScanNode)) {\n+                return Optional.empty();\n+            }\n+\n+            AggregationNode partialAggregationNode = (AggregationNode) plan;\n+            if (partialAggregationNode.hasNonEmptyGroupingSet()) {\n+                return Optional.empty();\n+            }\n+            TableScanNode oldTableScanNode = (TableScanNode) partialAggregationNode.getSource();\n+            TableHandle oldTableHandle = oldTableScanNode.getTable();\n+            HiveTableHandle hiveTableHandle = getHiveTableHandle(oldTableScanNode).orElseThrow(() -> new PrestoException(NOT_FOUND, \"Hive table handle not found\"));\n+\n+            ConnectorTableMetadata connectorTableMetadata = metadataFactory.get().getTableMetadata(session, oldTableHandle.getConnectorHandle());\n+            Optional<Object> rawFormat = Optional.ofNullable(connectorTableMetadata.getProperties().get(HiveTableProperties.STORAGE_FORMAT_PROPERTY));\n+            if (!rawFormat.isPresent()) {\n+                return Optional.empty();\n+            }\n+            final HiveStorageFormat hiveStorageFormat = HiveStorageFormat.valueOf(rawFormat.get().toString());\n+            if (hiveStorageFormat != HiveStorageFormat.ORC && hiveStorageFormat != HiveStorageFormat.PARQUET) {\n+                return Optional.empty();\n+            }\n+\n+            /**\n+             * Aggregation push downs are supported only on primitive types and supported aggregation functions are:\n+             * count(*), count(columnName), min(columnName), max(columnName)\n+             */\n+            for (AggregationNode.Aggregation aggregation : partialAggregationNode.getAggregations().values()) {\n+                FunctionHandle functionHandle = aggregation.getFunctionHandle();\n+                if (!(standardFunctionResolution.isCountFunction(functionHandle) ||\n+                        standardFunctionResolution.isMaxFunction(functionHandle) ||\n+                        standardFunctionResolution.isMinFunction(functionHandle))) {\n+                    return Optional.empty();\n+                }\n+\n+                if (aggregation.getArguments().isEmpty() && !standardFunctionResolution.isCountFunction(functionHandle)) {\n+                    return Optional.empty();\n+                }\n+\n+                List<RowExpression> arguments = aggregation.getArguments();\n+                if (arguments.size() > 1) {\n+                    return Optional.empty();\n+                }\n+\n+                if (standardFunctionResolution.isMinFunction(functionHandle) || standardFunctionResolution.isMaxFunction(functionHandle)) {\n+                    // Only allow supported datatypes for min/max\n+                    Type type = arguments.get(0).getType();\n+                    if (BOOLEAN.equals(type) ||\n+                            type.getJavaType() == boolean.class ||\n+                            isRowType(type) ||\n+                            isArrayType(type) ||\n+                            isMapType(type)) {\n+                        return Optional.empty();\n+                    }\n+\n+                    if (hiveStorageFormat == HiveStorageFormat.ORC) {\n+                        if (TINYINT.equals(type) ||\n+                                VARBINARY.equals(type) ||\n+                                TIMESTAMP.equals(type)) {\n+                            return Optional.empty();\n+                        }\n+                    }\n+\n+                    if ((VARBINARY.equals(type) || VARCHAR.equals(type)) &&\n+                            !isPartialAggregationPushdownForVariableLengthDatatypesEnabled(session)) {\n+                        return Optional.empty();\n+                    }\n+                }\n+            }\n+\n+            HiveTypeTranslator hiveTypeTranslator = new HiveTypeTranslator();\n+            Map<VariableReferenceExpression, ColumnHandle> assignments = new HashMap<>();\n+            for (Map.Entry<VariableReferenceExpression, AggregationNode.Aggregation> aggregationEntry : partialAggregationNode.getAggregations().entrySet()) {\n+                CallExpression callExpression = aggregationEntry.getValue().getCall();\n+                String colName = \"count_star\";\n+                int columnIndex = -20;", "originalCommit": "ed800f1a7409eda550397f6d76b1141764aae662", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTgyMzg2NQ==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r479823865", "bodyText": "Just a placeholder to indicate that it is not really a column index. I'm open to a better suggestion", "author": "ClarenceThreepwood", "createdAt": "2020-08-30T22:29:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU3MzI1Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI3OTQ0OQ==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r480279449", "bodyText": "Ah I see, let's make it a static constant so we could use variable name to make it clearer :)", "author": "shixuan-fan", "createdAt": "2020-08-31T17:31:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU3MzI1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU3NDA3Mw==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478574073", "bodyText": "Will always returning 0 here has side effect?", "author": "shixuan-fan", "createdAt": "2020-08-27T17:16:13Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/orc/AggregatedOrcPageSource.java", "diffHunk": "@@ -0,0 +1,253 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.orc;\n+\n+import com.facebook.presto.common.Page;\n+import com.facebook.presto.common.block.Block;\n+import com.facebook.presto.common.block.BlockBuilder;\n+import com.facebook.presto.common.type.Decimals;\n+import com.facebook.presto.common.type.FixedWidthType;\n+import com.facebook.presto.common.type.Type;\n+import com.facebook.presto.common.type.TypeManager;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveType;\n+import com.facebook.presto.orc.metadata.Footer;\n+import com.facebook.presto.orc.metadata.OrcType;\n+import com.facebook.presto.orc.metadata.statistics.ColumnStatistics;\n+import com.facebook.presto.spi.ConnectorPageSource;\n+import com.facebook.presto.spi.function.FunctionHandle;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.AggregationNode;\n+import io.airlift.slice.Slice;\n+\n+import java.io.IOException;\n+import java.math.BigDecimal;\n+import java.util.List;\n+\n+import static java.lang.Float.floatToRawIntBits;\n+import static java.util.Objects.requireNonNull;\n+\n+public class AggregatedOrcPageSource\n+        implements ConnectorPageSource\n+{\n+    private final List<HiveColumnHandle> columnHandles;\n+    private final Footer footer;\n+    private final TypeManager typeManager;\n+    private final StandardFunctionResolution functionResolution;\n+\n+    private boolean completed;\n+    private long readTimeNanos;\n+    private long completedBytes;\n+\n+    public AggregatedOrcPageSource(List<HiveColumnHandle> columnHandles, Footer footer, TypeManager typeManager, StandardFunctionResolution functionResolution)\n+    {\n+        this.columnHandles = requireNonNull(columnHandles, \"columnHandles is null\");\n+        this.footer = requireNonNull(footer, \"footer is null\");\n+        this.typeManager = requireNonNull(typeManager, \"typeManager is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+    }\n+\n+    @Override\n+    public long getCompletedBytes()\n+    {\n+        return completedBytes;\n+    }\n+\n+    @Override\n+    public long getCompletedPositions()\n+    {\n+        return 0;", "originalCommit": "ed800f1a7409eda550397f6d76b1141764aae662", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTgyNDE0Mg==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r479824142", "bodyText": "According to the comment in ConnectorPageSource - it should be ok to return 0. Though I could be wrong?", "author": "ClarenceThreepwood", "createdAt": "2020-08-30T22:31:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU3NDA3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU4MTQxNQ==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478581415", "bodyText": "Since this always 1 any way, maybe make it a static constant?", "author": "shixuan-fan", "createdAt": "2020-08-27T17:29:09Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/orc/AggregatedOrcPageSource.java", "diffHunk": "@@ -0,0 +1,253 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.orc;\n+\n+import com.facebook.presto.common.Page;\n+import com.facebook.presto.common.block.Block;\n+import com.facebook.presto.common.block.BlockBuilder;\n+import com.facebook.presto.common.type.Decimals;\n+import com.facebook.presto.common.type.FixedWidthType;\n+import com.facebook.presto.common.type.Type;\n+import com.facebook.presto.common.type.TypeManager;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveType;\n+import com.facebook.presto.orc.metadata.Footer;\n+import com.facebook.presto.orc.metadata.OrcType;\n+import com.facebook.presto.orc.metadata.statistics.ColumnStatistics;\n+import com.facebook.presto.spi.ConnectorPageSource;\n+import com.facebook.presto.spi.function.FunctionHandle;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.AggregationNode;\n+import io.airlift.slice.Slice;\n+\n+import java.io.IOException;\n+import java.math.BigDecimal;\n+import java.util.List;\n+\n+import static java.lang.Float.floatToRawIntBits;\n+import static java.util.Objects.requireNonNull;\n+\n+public class AggregatedOrcPageSource\n+        implements ConnectorPageSource\n+{\n+    private final List<HiveColumnHandle> columnHandles;\n+    private final Footer footer;\n+    private final TypeManager typeManager;\n+    private final StandardFunctionResolution functionResolution;\n+\n+    private boolean completed;\n+    private long readTimeNanos;\n+    private long completedBytes;\n+\n+    public AggregatedOrcPageSource(List<HiveColumnHandle> columnHandles, Footer footer, TypeManager typeManager, StandardFunctionResolution functionResolution)\n+    {\n+        this.columnHandles = requireNonNull(columnHandles, \"columnHandles is null\");\n+        this.footer = requireNonNull(footer, \"footer is null\");\n+        this.typeManager = requireNonNull(typeManager, \"typeManager is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+    }\n+\n+    @Override\n+    public long getCompletedBytes()\n+    {\n+        return completedBytes;\n+    }\n+\n+    @Override\n+    public long getCompletedPositions()\n+    {\n+        return 0;\n+    }\n+\n+    @Override\n+    public long getReadTimeNanos()\n+    {\n+        return readTimeNanos;\n+    }\n+\n+    @Override\n+    public boolean isFinished()\n+    {\n+        return completed;\n+    }\n+\n+    @Override\n+    public Page getNextPage()\n+    {\n+        if (completed) {\n+            return null;\n+        }\n+\n+        long start = System.nanoTime();\n+\n+        // Prepare the one required record by looking at the aggregations in pipeline and stats in footer\n+        final int batchSize = 1;", "originalCommit": "ed800f1a7409eda550397f6d76b1141764aae662", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU4NDU2Mg==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478584562", "bodyText": "Is it possible to miss completed bytes counting if we enabled variable length data types and the aggregation is min/max?", "author": "shixuan-fan", "createdAt": "2020-08-27T17:34:17Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/orc/AggregatedOrcPageSource.java", "diffHunk": "@@ -0,0 +1,253 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.orc;\n+\n+import com.facebook.presto.common.Page;\n+import com.facebook.presto.common.block.Block;\n+import com.facebook.presto.common.block.BlockBuilder;\n+import com.facebook.presto.common.type.Decimals;\n+import com.facebook.presto.common.type.FixedWidthType;\n+import com.facebook.presto.common.type.Type;\n+import com.facebook.presto.common.type.TypeManager;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveType;\n+import com.facebook.presto.orc.metadata.Footer;\n+import com.facebook.presto.orc.metadata.OrcType;\n+import com.facebook.presto.orc.metadata.statistics.ColumnStatistics;\n+import com.facebook.presto.spi.ConnectorPageSource;\n+import com.facebook.presto.spi.function.FunctionHandle;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.AggregationNode;\n+import io.airlift.slice.Slice;\n+\n+import java.io.IOException;\n+import java.math.BigDecimal;\n+import java.util.List;\n+\n+import static java.lang.Float.floatToRawIntBits;\n+import static java.util.Objects.requireNonNull;\n+\n+public class AggregatedOrcPageSource\n+        implements ConnectorPageSource\n+{\n+    private final List<HiveColumnHandle> columnHandles;\n+    private final Footer footer;\n+    private final TypeManager typeManager;\n+    private final StandardFunctionResolution functionResolution;\n+\n+    private boolean completed;\n+    private long readTimeNanos;\n+    private long completedBytes;\n+\n+    public AggregatedOrcPageSource(List<HiveColumnHandle> columnHandles, Footer footer, TypeManager typeManager, StandardFunctionResolution functionResolution)\n+    {\n+        this.columnHandles = requireNonNull(columnHandles, \"columnHandles is null\");\n+        this.footer = requireNonNull(footer, \"footer is null\");\n+        this.typeManager = requireNonNull(typeManager, \"typeManager is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+    }\n+\n+    @Override\n+    public long getCompletedBytes()\n+    {\n+        return completedBytes;\n+    }\n+\n+    @Override\n+    public long getCompletedPositions()\n+    {\n+        return 0;\n+    }\n+\n+    @Override\n+    public long getReadTimeNanos()\n+    {\n+        return readTimeNanos;\n+    }\n+\n+    @Override\n+    public boolean isFinished()\n+    {\n+        return completed;\n+    }\n+\n+    @Override\n+    public Page getNextPage()\n+    {\n+        if (completed) {\n+            return null;\n+        }\n+\n+        long start = System.nanoTime();\n+\n+        // Prepare the one required record by looking at the aggregations in pipeline and stats in footer\n+        final int batchSize = 1;\n+\n+        Block[] blocks = new Block[columnHandles.size()];\n+        for (int fieldId = 0; fieldId < blocks.length; fieldId++) {\n+            HiveColumnHandle columnHandle = columnHandles.get(fieldId);\n+            AggregationNode.Aggregation aggregation = columnHandle.getPartialAggregation().get();\n+            int columnIndex = columnHandle.getHiveColumnIndex();\n+            Type type = typeManager.getType(columnHandle.getTypeSignature());\n+            if (type instanceof FixedWidthType) {", "originalCommit": "ed800f1a7409eda550397f6d76b1141764aae662", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTgyNTE1OA==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r479825158", "bodyText": "completed bytes for variable length data types are computed down in line 177", "author": "ClarenceThreepwood", "createdAt": "2020-08-30T22:43:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU4NDU2Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI4ODg3Ng==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r480288876", "bodyText": "In that case, should we move this closer to variable length data? Currently it is a bit fragmented and might be error-prone in the future.", "author": "shixuan-fan", "createdAt": "2020-08-31T17:49:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODU4NDU2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2NzczOA==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478667738", "bodyText": "Do we need a try-catch for close like the existing code?", "author": "shixuan-fan", "createdAt": "2020-08-27T20:10:17Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/orc/OrcSelectivePageSourceFactory.java", "diffHunk": "@@ -333,6 +334,16 @@ public static OrcSelectivePageSource createOrcPageSource(\n             checkArgument(!domainPredicate.isNone(), \"Unexpected NONE domain\");\n \n             List<HiveColumnHandle> physicalColumns = getPhysicalHiveColumnHandles(columns, useOrcColumnNames, reader, path);\n+\n+            if (!physicalColumns.isEmpty() && physicalColumns.get(0).getColumnType() == AGGREGATED) {\n+                try {\n+                    return new AggregatedOrcPageSource(physicalColumns, reader.getFooter(), typeManager, functionResolution);\n+                }\n+                finally {\n+                    orcDataSource.close();", "originalCommit": "ed800f1a7409eda550397f6d76b1141764aae662", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTgyNTc2OA==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r479825768", "bodyText": "Actually this call to AggregatedOrcPageSource() is already covered by the outer try block and will fall into the catch you mention in case of an exception. So I will just remove this altogether", "author": "ClarenceThreepwood", "createdAt": "2020-08-30T22:50:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2NzczOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2ODU3MQ==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478668571", "bodyText": "nit: add try-finally and put DROP TABLE in finally", "author": "shixuan-fan", "createdAt": "2020-08-27T20:11:44Z", "path": "presto-hive/src/test/java/com/facebook/presto/hive/TestHiveIntegrationSmokeTest.java", "diffHunk": "@@ -4774,6 +4774,238 @@ public void testPageFileCompression()\n         }\n     }\n \n+    @Test\n+    public void testPartialAggregatePushdownORC()\n+    {\n+        @Language(\"SQL\") String createTable = \"\" +\n+                \"CREATE TABLE test_orc_table (\" +\n+                \" _boolean BOOLEAN\" +\n+                \", _tinyint TINYINT\" +\n+                \", _smallint SMALLINT\" +\n+                \", _integer INTEGER\" +\n+                \", _bigint BIGINT\" +\n+                \", _real REAL\" +\n+                \", _double DOUBLE\" +\n+                \", _shortdecimal DECIMAL(8,3)\" +\n+                \", _longdecimal DECIMAL(25,2)\" +\n+                \", _string VARCHAR\" +\n+                \", _varchar VARCHAR(10)\" +\n+                \", _singlechar CHAR\" +\n+                \", _char CHAR(10)\" +\n+                \", _varbinary VARBINARY\" +\n+                \", _date DATE\" +\n+                \", _timestamp TIMESTAMP\" +\n+                \")\" +\n+                \"WITH (format = 'orc')\";\n+\n+        Session session = Session.builder(getSession())\n+                .setCatalogSessionProperty(catalog, \"enable_partial_aggregation_pushdown\", \"true\")\n+                .setCatalogSessionProperty(catalog, \"enable_partial_aggregation_pushdown_for_variable_length_datatypes\", \"true\")\n+                .build();\n+        assertUpdate(session, createTable);\n+\n+        TableMetadata tableMetadata = getTableMetadata(catalog, TPCH_SCHEMA, \"test_orc_table\");\n+        assertEquals(tableMetadata.getMetadata().getProperties().get(STORAGE_FORMAT_PROPERTY), HiveStorageFormat.ORC);\n+\n+        assertUpdate(session, \"INSERT INTO test_orc_table VALUES (\" +\n+                \"true\" +\n+                \", cast(1 as tinyint)\" +\n+                \", cast(2 as smallint)\" +\n+                \", 3\" +\n+                \", 4\" +\n+                \", 1.2\" +\n+                \", 2.3\" +\n+                \", 4.5\" +\n+                \", 55555555555555.32\" +\n+                \", 'abc'\" +\n+                \", 'def'\" +\n+                \", 'g'\" +\n+                \", 'hij'\" +\n+                \", cast('klm' as varbinary)\" +\n+                \", cast('2020-05-01' as date)\" +\n+                \", cast('2020-06-04 16:55:40.777' as timestamp)\" +\n+                \")\", 1);\n+\n+        assertUpdate(session, \"INSERT INTO test_orc_table VALUES (\" +\n+                \"false\" +\n+                \", cast(10 as tinyint)\" +\n+                \", cast(20 as smallint)\" +\n+                \", 30\" +\n+                \", 40\" +\n+                \", 10.25\" +\n+                \", 25.334\" +\n+                \", 465.523\" +\n+                \", 88888888555555.91\" +\n+                \", 'foo'\" +\n+                \", 'bar'\" +\n+                \", 'b'\" +\n+                \", 'baz'\" +\n+                \", cast('qux' as varbinary)\" +\n+                \", cast('2020-06-02' as date)\" +\n+                \", cast('2020-05-01 18:34:23.88' as timestamp)\" +\n+                \")\", 1);\n+        String rowCount = \"SELECT 2\";\n+\n+        assertQuery(session, \"SELECT COUNT(*) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_boolean) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_tinyint) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_smallint) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_integer) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_bigint) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_real) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_double) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_shortdecimal) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_longdecimal) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_string) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_varchar) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_singlechar) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_char) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_varbinary) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_date) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_timestamp) FROM test_orc_table\", rowCount);\n+\n+        assertQuery(session, \"SELECT MIN(_boolean), MAX(_boolean) FROM test_orc_table\", \"select false, true\");\n+        assertQuery(session, \"SELECT MIN(_tinyint), MAX(_tinyint) FROM test_orc_table\", \"select 1, 10\");\n+        assertQuery(session, \"SELECT MIN(_smallint), MAX(_smallint) FROM test_orc_table\", \"select 2, 20\");\n+        assertQuery(session, \"SELECT MIN(_integer), MAX(_integer) FROM test_orc_table\", \"select 3, 30\");\n+        assertQuery(session, \"SELECT MIN(_bigint), MAX(_bigint) FROM test_orc_table\", \"select 4, 40\");\n+        assertQuery(session, \"SELECT MIN(_real), MAX(_real) FROM test_orc_table\", \"select 1.2, 10.25\");\n+        assertQuery(session, \"SELECT MIN(_double), MAX(_double) FROM test_orc_table\", \"select 2.3, 25.334\");\n+        assertQuery(session, \"SELECT MIN(_shortdecimal), MAX(_shortdecimal) FROM test_orc_table\", \"select 4.5, 465.523\");\n+        assertQuery(session, \"SELECT MIN(_longdecimal), MAX(_longdecimal) FROM test_orc_table\", \"select 55555555555555.32, 88888888555555.91\");\n+        assertQuery(session, \"SELECT MIN(_string), MAX(_string) FROM test_orc_table\", \"select 'abc', 'foo'\");\n+        assertQuery(session, \"SELECT MIN(_varchar), MAX(_varchar) FROM test_orc_table\", \"select 'bar', 'def'\");\n+        assertQuery(session, \"SELECT MIN(_singlechar), MAX(_singlechar) FROM test_orc_table\", \"select 'b', 'g'\");\n+        assertQuery(session, \"SELECT MIN(_char), MAX(_char) FROM test_orc_table\", \"select 'baz', 'hij'\");\n+        assertQuery(session, \"SELECT MIN(_varbinary), MAX(_varbinary) FROM test_orc_table\", \"select X'6b6c6d', X'717578'\");\n+        assertQuery(session, \"SELECT MIN(_date), MAX(_date) FROM test_orc_table\", \"select cast('2020-05-01' as date), cast('2020-06-02' as date)\");\n+        assertQuery(session, \"SELECT MIN(_timestamp), MAX(_timestamp) FROM test_orc_table\", \"select cast('2020-05-01 18:34:23.88' as timestamp), cast('2020-06-04 16:55:40.777' as timestamp)\");\n+\n+        assertUpdate(session, \"DROP TABLE test_orc_table\");", "originalCommit": "ed800f1a7409eda550397f6d76b1141764aae662", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2OTMwMQ==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478669301", "bodyText": "I'm not sure if I followed...Should we actually remove these tests that are commented out?", "author": "shixuan-fan", "createdAt": "2020-08-27T20:13:09Z", "path": "presto-hive/src/test/java/com/facebook/presto/hive/TestHiveIntegrationSmokeTest.java", "diffHunk": "@@ -4774,6 +4774,238 @@ public void testPageFileCompression()\n         }\n     }\n \n+    @Test\n+    public void testPartialAggregatePushdownORC()\n+    {\n+        @Language(\"SQL\") String createTable = \"\" +\n+                \"CREATE TABLE test_orc_table (\" +\n+                \" _boolean BOOLEAN\" +\n+                \", _tinyint TINYINT\" +\n+                \", _smallint SMALLINT\" +\n+                \", _integer INTEGER\" +\n+                \", _bigint BIGINT\" +\n+                \", _real REAL\" +\n+                \", _double DOUBLE\" +\n+                \", _shortdecimal DECIMAL(8,3)\" +\n+                \", _longdecimal DECIMAL(25,2)\" +\n+                \", _string VARCHAR\" +\n+                \", _varchar VARCHAR(10)\" +\n+                \", _singlechar CHAR\" +\n+                \", _char CHAR(10)\" +\n+                \", _varbinary VARBINARY\" +\n+                \", _date DATE\" +\n+                \", _timestamp TIMESTAMP\" +\n+                \")\" +\n+                \"WITH (format = 'orc')\";\n+\n+        Session session = Session.builder(getSession())\n+                .setCatalogSessionProperty(catalog, \"enable_partial_aggregation_pushdown\", \"true\")\n+                .setCatalogSessionProperty(catalog, \"enable_partial_aggregation_pushdown_for_variable_length_datatypes\", \"true\")\n+                .build();\n+        assertUpdate(session, createTable);\n+\n+        TableMetadata tableMetadata = getTableMetadata(catalog, TPCH_SCHEMA, \"test_orc_table\");\n+        assertEquals(tableMetadata.getMetadata().getProperties().get(STORAGE_FORMAT_PROPERTY), HiveStorageFormat.ORC);\n+\n+        assertUpdate(session, \"INSERT INTO test_orc_table VALUES (\" +\n+                \"true\" +\n+                \", cast(1 as tinyint)\" +\n+                \", cast(2 as smallint)\" +\n+                \", 3\" +\n+                \", 4\" +\n+                \", 1.2\" +\n+                \", 2.3\" +\n+                \", 4.5\" +\n+                \", 55555555555555.32\" +\n+                \", 'abc'\" +\n+                \", 'def'\" +\n+                \", 'g'\" +\n+                \", 'hij'\" +\n+                \", cast('klm' as varbinary)\" +\n+                \", cast('2020-05-01' as date)\" +\n+                \", cast('2020-06-04 16:55:40.777' as timestamp)\" +\n+                \")\", 1);\n+\n+        assertUpdate(session, \"INSERT INTO test_orc_table VALUES (\" +\n+                \"false\" +\n+                \", cast(10 as tinyint)\" +\n+                \", cast(20 as smallint)\" +\n+                \", 30\" +\n+                \", 40\" +\n+                \", 10.25\" +\n+                \", 25.334\" +\n+                \", 465.523\" +\n+                \", 88888888555555.91\" +\n+                \", 'foo'\" +\n+                \", 'bar'\" +\n+                \", 'b'\" +\n+                \", 'baz'\" +\n+                \", cast('qux' as varbinary)\" +\n+                \", cast('2020-06-02' as date)\" +\n+                \", cast('2020-05-01 18:34:23.88' as timestamp)\" +\n+                \")\", 1);\n+        String rowCount = \"SELECT 2\";\n+\n+        assertQuery(session, \"SELECT COUNT(*) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_boolean) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_tinyint) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_smallint) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_integer) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_bigint) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_real) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_double) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_shortdecimal) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_longdecimal) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_string) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_varchar) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_singlechar) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_char) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_varbinary) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_date) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_timestamp) FROM test_orc_table\", rowCount);\n+\n+        assertQuery(session, \"SELECT MIN(_boolean), MAX(_boolean) FROM test_orc_table\", \"select false, true\");\n+        assertQuery(session, \"SELECT MIN(_tinyint), MAX(_tinyint) FROM test_orc_table\", \"select 1, 10\");\n+        assertQuery(session, \"SELECT MIN(_smallint), MAX(_smallint) FROM test_orc_table\", \"select 2, 20\");\n+        assertQuery(session, \"SELECT MIN(_integer), MAX(_integer) FROM test_orc_table\", \"select 3, 30\");\n+        assertQuery(session, \"SELECT MIN(_bigint), MAX(_bigint) FROM test_orc_table\", \"select 4, 40\");\n+        assertQuery(session, \"SELECT MIN(_real), MAX(_real) FROM test_orc_table\", \"select 1.2, 10.25\");\n+        assertQuery(session, \"SELECT MIN(_double), MAX(_double) FROM test_orc_table\", \"select 2.3, 25.334\");\n+        assertQuery(session, \"SELECT MIN(_shortdecimal), MAX(_shortdecimal) FROM test_orc_table\", \"select 4.5, 465.523\");\n+        assertQuery(session, \"SELECT MIN(_longdecimal), MAX(_longdecimal) FROM test_orc_table\", \"select 55555555555555.32, 88888888555555.91\");\n+        assertQuery(session, \"SELECT MIN(_string), MAX(_string) FROM test_orc_table\", \"select 'abc', 'foo'\");\n+        assertQuery(session, \"SELECT MIN(_varchar), MAX(_varchar) FROM test_orc_table\", \"select 'bar', 'def'\");\n+        assertQuery(session, \"SELECT MIN(_singlechar), MAX(_singlechar) FROM test_orc_table\", \"select 'b', 'g'\");\n+        assertQuery(session, \"SELECT MIN(_char), MAX(_char) FROM test_orc_table\", \"select 'baz', 'hij'\");\n+        assertQuery(session, \"SELECT MIN(_varbinary), MAX(_varbinary) FROM test_orc_table\", \"select X'6b6c6d', X'717578'\");\n+        assertQuery(session, \"SELECT MIN(_date), MAX(_date) FROM test_orc_table\", \"select cast('2020-05-01' as date), cast('2020-06-02' as date)\");\n+        assertQuery(session, \"SELECT MIN(_timestamp), MAX(_timestamp) FROM test_orc_table\", \"select cast('2020-05-01 18:34:23.88' as timestamp), cast('2020-06-04 16:55:40.777' as timestamp)\");\n+\n+        assertUpdate(session, \"DROP TABLE test_orc_table\");\n+\n+        assertFalse(getQueryRunner().tableExists(session, \"test_orc_table\"));\n+    }\n+\n+    @Test\n+    public void testPartialAggregatePushdownParquet()\n+    {\n+        @Language(\"SQL\") String createTable = \"\" +\n+                \"CREATE TABLE test_parquet_table (\" +\n+                \" _boolean BOOLEAN\" +\n+                \", _tinyint TINYINT\" +\n+                \", _smallint SMALLINT\" +\n+                \", _integer INTEGER\" +\n+                \", _bigint BIGINT\" +\n+                \", _real REAL\" +\n+                \", _double DOUBLE\" +\n+                \", _shortdecimal DECIMAL(8,3)\" +\n+                \", _longdecimal DECIMAL(25,2)\" +\n+                \", _string VARCHAR\" +\n+                \", _varchar VARCHAR(10)\" +\n+                \", _singlechar CHAR\" +\n+                \", _char CHAR(10)\" +\n+                \", _varbinary VARBINARY\" +\n+                \", _date DATE\" +\n+                \", _timestamp TIMESTAMP\" +\n+                \")\" +\n+                \"WITH (format = 'parquet')\";\n+\n+        Session session = Session.builder(getSession())\n+                .setCatalogSessionProperty(catalog, \"enable_partial_aggregation_pushdown\", \"true\")\n+                .setCatalogSessionProperty(catalog, \"enable_partial_aggregation_pushdown_for_variable_length_datatypes\", \"true\")\n+                .build();\n+        assertUpdate(session, createTable);\n+\n+        TableMetadata tableMetadata = getTableMetadata(catalog, TPCH_SCHEMA, \"test_parquet_table\");\n+        assertEquals(tableMetadata.getMetadata().getProperties().get(STORAGE_FORMAT_PROPERTY), HiveStorageFormat.PARQUET);\n+\n+        assertUpdate(session, \"INSERT INTO test_parquet_table VALUES (\" +\n+                \"true\" +\n+                \", cast(1 as tinyint)\" +\n+                \", cast(2 as smallint)\" +\n+                \", 3\" +\n+                \", 4\" +\n+                \", 1.2\" +\n+                \", 2.3\" +\n+                \", 4.5\" +\n+                \", 55555555555555.32\" +\n+                \", 'abc'\" +\n+                \", 'def'\" +\n+                \", 'g'\" +\n+                \", 'hij'\" +\n+                \", cast('klm' as varbinary)\" +\n+                \", cast('2020-05-01' as date)\" +\n+                \", cast('2020-06-04 16:55:40.777' as timestamp)\" +\n+                \")\", 1);\n+\n+        assertUpdate(session, \"INSERT INTO test_parquet_table VALUES (\" +\n+                \"false\" +\n+                \", cast(10 as tinyint)\" +\n+                \", cast(20 as smallint)\" +\n+                \", 30\" +\n+                \", 40\" +\n+                \", 10.25\" +\n+                \", 25.334\" +\n+                \", 465.523\" +\n+                \", 88888888555555.91\" +\n+                \", 'foo'\" +\n+                \", 'bar'\" +\n+                \", 'b'\" +\n+                \", 'baz'\" +\n+                \", cast('qux' as varbinary)\" +\n+                \", cast('2020-06-02' as date)\" +\n+                \", cast('2020-05-01 18:34:23.88' as timestamp)\" +\n+                \")\", 1);\n+        String rowCount = \"SELECT 2\";\n+\n+        assertQuery(session, \"SELECT COUNT(*) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_boolean) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_tinyint) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_smallint) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_integer) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_bigint) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_real) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_double) FROM test_parquet_table\", rowCount);\n+        // The default Parquet writer does not populate statistics for these datatypes\n+        // though they are populated by hive etl tasks\n+        /*", "originalCommit": "ed800f1a7409eda550397f6d76b1141764aae662", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTgyNDUwMQ==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r479824501", "bodyText": "I'll enabled these. This work was initially developed on an older version of Presto where these statistics were not properly populated. This is fixed on master", "author": "ClarenceThreepwood", "createdAt": "2020-08-30T22:36:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2OTMwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2OTM2Nw==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r478669367", "bodyText": "ditto on try-finally", "author": "shixuan-fan", "createdAt": "2020-08-27T20:13:17Z", "path": "presto-hive/src/test/java/com/facebook/presto/hive/TestHiveIntegrationSmokeTest.java", "diffHunk": "@@ -4774,6 +4774,238 @@ public void testPageFileCompression()\n         }\n     }\n \n+    @Test\n+    public void testPartialAggregatePushdownORC()\n+    {\n+        @Language(\"SQL\") String createTable = \"\" +\n+                \"CREATE TABLE test_orc_table (\" +\n+                \" _boolean BOOLEAN\" +\n+                \", _tinyint TINYINT\" +\n+                \", _smallint SMALLINT\" +\n+                \", _integer INTEGER\" +\n+                \", _bigint BIGINT\" +\n+                \", _real REAL\" +\n+                \", _double DOUBLE\" +\n+                \", _shortdecimal DECIMAL(8,3)\" +\n+                \", _longdecimal DECIMAL(25,2)\" +\n+                \", _string VARCHAR\" +\n+                \", _varchar VARCHAR(10)\" +\n+                \", _singlechar CHAR\" +\n+                \", _char CHAR(10)\" +\n+                \", _varbinary VARBINARY\" +\n+                \", _date DATE\" +\n+                \", _timestamp TIMESTAMP\" +\n+                \")\" +\n+                \"WITH (format = 'orc')\";\n+\n+        Session session = Session.builder(getSession())\n+                .setCatalogSessionProperty(catalog, \"enable_partial_aggregation_pushdown\", \"true\")\n+                .setCatalogSessionProperty(catalog, \"enable_partial_aggregation_pushdown_for_variable_length_datatypes\", \"true\")\n+                .build();\n+        assertUpdate(session, createTable);\n+\n+        TableMetadata tableMetadata = getTableMetadata(catalog, TPCH_SCHEMA, \"test_orc_table\");\n+        assertEquals(tableMetadata.getMetadata().getProperties().get(STORAGE_FORMAT_PROPERTY), HiveStorageFormat.ORC);\n+\n+        assertUpdate(session, \"INSERT INTO test_orc_table VALUES (\" +\n+                \"true\" +\n+                \", cast(1 as tinyint)\" +\n+                \", cast(2 as smallint)\" +\n+                \", 3\" +\n+                \", 4\" +\n+                \", 1.2\" +\n+                \", 2.3\" +\n+                \", 4.5\" +\n+                \", 55555555555555.32\" +\n+                \", 'abc'\" +\n+                \", 'def'\" +\n+                \", 'g'\" +\n+                \", 'hij'\" +\n+                \", cast('klm' as varbinary)\" +\n+                \", cast('2020-05-01' as date)\" +\n+                \", cast('2020-06-04 16:55:40.777' as timestamp)\" +\n+                \")\", 1);\n+\n+        assertUpdate(session, \"INSERT INTO test_orc_table VALUES (\" +\n+                \"false\" +\n+                \", cast(10 as tinyint)\" +\n+                \", cast(20 as smallint)\" +\n+                \", 30\" +\n+                \", 40\" +\n+                \", 10.25\" +\n+                \", 25.334\" +\n+                \", 465.523\" +\n+                \", 88888888555555.91\" +\n+                \", 'foo'\" +\n+                \", 'bar'\" +\n+                \", 'b'\" +\n+                \", 'baz'\" +\n+                \", cast('qux' as varbinary)\" +\n+                \", cast('2020-06-02' as date)\" +\n+                \", cast('2020-05-01 18:34:23.88' as timestamp)\" +\n+                \")\", 1);\n+        String rowCount = \"SELECT 2\";\n+\n+        assertQuery(session, \"SELECT COUNT(*) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_boolean) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_tinyint) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_smallint) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_integer) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_bigint) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_real) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_double) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_shortdecimal) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_longdecimal) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_string) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_varchar) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_singlechar) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_char) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_varbinary) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_date) FROM test_orc_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_timestamp) FROM test_orc_table\", rowCount);\n+\n+        assertQuery(session, \"SELECT MIN(_boolean), MAX(_boolean) FROM test_orc_table\", \"select false, true\");\n+        assertQuery(session, \"SELECT MIN(_tinyint), MAX(_tinyint) FROM test_orc_table\", \"select 1, 10\");\n+        assertQuery(session, \"SELECT MIN(_smallint), MAX(_smallint) FROM test_orc_table\", \"select 2, 20\");\n+        assertQuery(session, \"SELECT MIN(_integer), MAX(_integer) FROM test_orc_table\", \"select 3, 30\");\n+        assertQuery(session, \"SELECT MIN(_bigint), MAX(_bigint) FROM test_orc_table\", \"select 4, 40\");\n+        assertQuery(session, \"SELECT MIN(_real), MAX(_real) FROM test_orc_table\", \"select 1.2, 10.25\");\n+        assertQuery(session, \"SELECT MIN(_double), MAX(_double) FROM test_orc_table\", \"select 2.3, 25.334\");\n+        assertQuery(session, \"SELECT MIN(_shortdecimal), MAX(_shortdecimal) FROM test_orc_table\", \"select 4.5, 465.523\");\n+        assertQuery(session, \"SELECT MIN(_longdecimal), MAX(_longdecimal) FROM test_orc_table\", \"select 55555555555555.32, 88888888555555.91\");\n+        assertQuery(session, \"SELECT MIN(_string), MAX(_string) FROM test_orc_table\", \"select 'abc', 'foo'\");\n+        assertQuery(session, \"SELECT MIN(_varchar), MAX(_varchar) FROM test_orc_table\", \"select 'bar', 'def'\");\n+        assertQuery(session, \"SELECT MIN(_singlechar), MAX(_singlechar) FROM test_orc_table\", \"select 'b', 'g'\");\n+        assertQuery(session, \"SELECT MIN(_char), MAX(_char) FROM test_orc_table\", \"select 'baz', 'hij'\");\n+        assertQuery(session, \"SELECT MIN(_varbinary), MAX(_varbinary) FROM test_orc_table\", \"select X'6b6c6d', X'717578'\");\n+        assertQuery(session, \"SELECT MIN(_date), MAX(_date) FROM test_orc_table\", \"select cast('2020-05-01' as date), cast('2020-06-02' as date)\");\n+        assertQuery(session, \"SELECT MIN(_timestamp), MAX(_timestamp) FROM test_orc_table\", \"select cast('2020-05-01 18:34:23.88' as timestamp), cast('2020-06-04 16:55:40.777' as timestamp)\");\n+\n+        assertUpdate(session, \"DROP TABLE test_orc_table\");\n+\n+        assertFalse(getQueryRunner().tableExists(session, \"test_orc_table\"));\n+    }\n+\n+    @Test\n+    public void testPartialAggregatePushdownParquet()\n+    {\n+        @Language(\"SQL\") String createTable = \"\" +\n+                \"CREATE TABLE test_parquet_table (\" +\n+                \" _boolean BOOLEAN\" +\n+                \", _tinyint TINYINT\" +\n+                \", _smallint SMALLINT\" +\n+                \", _integer INTEGER\" +\n+                \", _bigint BIGINT\" +\n+                \", _real REAL\" +\n+                \", _double DOUBLE\" +\n+                \", _shortdecimal DECIMAL(8,3)\" +\n+                \", _longdecimal DECIMAL(25,2)\" +\n+                \", _string VARCHAR\" +\n+                \", _varchar VARCHAR(10)\" +\n+                \", _singlechar CHAR\" +\n+                \", _char CHAR(10)\" +\n+                \", _varbinary VARBINARY\" +\n+                \", _date DATE\" +\n+                \", _timestamp TIMESTAMP\" +\n+                \")\" +\n+                \"WITH (format = 'parquet')\";\n+\n+        Session session = Session.builder(getSession())\n+                .setCatalogSessionProperty(catalog, \"enable_partial_aggregation_pushdown\", \"true\")\n+                .setCatalogSessionProperty(catalog, \"enable_partial_aggregation_pushdown_for_variable_length_datatypes\", \"true\")\n+                .build();\n+        assertUpdate(session, createTable);\n+\n+        TableMetadata tableMetadata = getTableMetadata(catalog, TPCH_SCHEMA, \"test_parquet_table\");\n+        assertEquals(tableMetadata.getMetadata().getProperties().get(STORAGE_FORMAT_PROPERTY), HiveStorageFormat.PARQUET);\n+\n+        assertUpdate(session, \"INSERT INTO test_parquet_table VALUES (\" +\n+                \"true\" +\n+                \", cast(1 as tinyint)\" +\n+                \", cast(2 as smallint)\" +\n+                \", 3\" +\n+                \", 4\" +\n+                \", 1.2\" +\n+                \", 2.3\" +\n+                \", 4.5\" +\n+                \", 55555555555555.32\" +\n+                \", 'abc'\" +\n+                \", 'def'\" +\n+                \", 'g'\" +\n+                \", 'hij'\" +\n+                \", cast('klm' as varbinary)\" +\n+                \", cast('2020-05-01' as date)\" +\n+                \", cast('2020-06-04 16:55:40.777' as timestamp)\" +\n+                \")\", 1);\n+\n+        assertUpdate(session, \"INSERT INTO test_parquet_table VALUES (\" +\n+                \"false\" +\n+                \", cast(10 as tinyint)\" +\n+                \", cast(20 as smallint)\" +\n+                \", 30\" +\n+                \", 40\" +\n+                \", 10.25\" +\n+                \", 25.334\" +\n+                \", 465.523\" +\n+                \", 88888888555555.91\" +\n+                \", 'foo'\" +\n+                \", 'bar'\" +\n+                \", 'b'\" +\n+                \", 'baz'\" +\n+                \", cast('qux' as varbinary)\" +\n+                \", cast('2020-06-02' as date)\" +\n+                \", cast('2020-05-01 18:34:23.88' as timestamp)\" +\n+                \")\", 1);\n+        String rowCount = \"SELECT 2\";\n+\n+        assertQuery(session, \"SELECT COUNT(*) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_boolean) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_tinyint) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_smallint) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_integer) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_bigint) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_real) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_double) FROM test_parquet_table\", rowCount);\n+        // The default Parquet writer does not populate statistics for these datatypes\n+        // though they are populated by hive etl tasks\n+        /*\n+        assertQuery(session, \"SELECT COUNT(_shortdecimal) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_longdecimal) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_string) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_varchar) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_singlechar) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_char) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_varbinary) FROM test_parquet_table\", rowCount);\n+         */\n+        assertQuery(session, \"SELECT COUNT(_date) FROM test_parquet_table\", rowCount);\n+        assertQuery(session, \"SELECT COUNT(_timestamp) FROM test_parquet_table\", rowCount);\n+\n+        assertQuery(session, \"SELECT MIN(_boolean), MAX(_boolean) FROM test_parquet_table\", \"select false, true\");\n+        assertQuery(session, \"SELECT MIN(_tinyint), MAX(_tinyint) FROM test_parquet_table\", \"select 1, 10\");\n+        assertQuery(session, \"SELECT MIN(_smallint), MAX(_smallint) FROM test_parquet_table\", \"select 2, 20\");\n+        assertQuery(session, \"SELECT MIN(_integer), MAX(_integer) FROM test_parquet_table\", \"select 3, 30\");\n+        assertQuery(session, \"SELECT MIN(_bigint), MAX(_bigint) FROM test_parquet_table\", \"select 4, 40\");\n+        assertQuery(session, \"SELECT MIN(_real), MAX(_real) FROM test_parquet_table\", \"select 1.2, 10.25\");\n+        assertQuery(session, \"SELECT MIN(_double), MAX(_double) FROM test_parquet_table\", \"select 2.3, 25.334\");\n+        // The default Parquet writer does not populate statistics for these datatypes\n+        // though they are populated by hive etl tasks\n+        /*\n+        assertQuery(session, \"SELECT MIN(_shortdecimal), MAX(_shortdecimal) FROM test_parquet_table\", \"select 4.5, 465.523\");\n+        assertQuery(session, \"SELECT MIN(_longdecimal), MAX(_longdecimal) FROM test_parquet_table\", \"select 55555555555555.32, 88888888555555.91\");\n+        assertQuery(session, \"SELECT MIN(_string), MAX(_string) FROM test_parquet_table\", \"select 'abc', 'foo'\");\n+        assertQuery(session, \"SELECT MIN(_varchar), MAX(_varchar) FROM test_parquet_table\", \"select 'bar', 'def'\");\n+        assertQuery(session, \"SELECT MIN(_singlechar), MAX(_singlechar) FROM test_parquet_table\", \"select 'b', 'g'\");\n+        assertQuery(session, \"SELECT MIN(_char), MAX(_char) FROM test_parquet_table\", \"select 'baz', 'hij'\");\n+        assertQuery(session, \"SELECT MIN(_varbinary), MAX(_varbinary) FROM test_orc_table\", \"select X'6b6c6d', X'717578'\");\n+         */\n+        assertQuery(session, \"SELECT MIN(_date), MAX(_date) FROM test_parquet_table\", \"select cast('2020-05-01' as date), cast('2020-06-02' as date)\");\n+        assertQuery(session, \"SELECT MIN(_timestamp), MAX(_timestamp) FROM test_parquet_table\", \"select cast('2020-05-01 18:34:23.88' as timestamp), cast('2020-06-04 16:55:40.777' as timestamp)\");\n+\n+        assertUpdate(session, \"DROP TABLE test_parquet_table\");", "originalCommit": "ed800f1a7409eda550397f6d76b1141764aae662", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "9d1bb5e78118b1c8a5c6b5b63ea5df57d87573f7", "url": "https://github.com/prestodb/presto/commit/9d1bb5e78118b1c8a5c6b5b63ea5df57d87573f7", "message": "Partial Aggregation Pushdown for ORC/Parquet", "committedDate": "2020-08-31T15:47:08Z", "type": "forcePushed"}, {"oid": "c253c32099e0bacb3bdeb90228ba378de1e4f959", "url": "https://github.com/prestodb/presto/commit/c253c32099e0bacb3bdeb90228ba378de1e4f959", "message": "Partial Aggregation Pushdown for ORC/Parquet", "committedDate": "2020-09-01T04:52:39Z", "type": "forcePushed"}, {"oid": "f4f9bfc59e9a1da93a03d494191d433ae49a46b1", "url": "https://github.com/prestodb/presto/commit/f4f9bfc59e9a1da93a03d494191d433ae49a46b1", "message": "Partial Aggregation Pushdown for ORC/Parquet", "committedDate": "2020-09-01T05:15:57Z", "type": "forcePushed"}, {"oid": "ef26c0bf20ab0ab56b148620b5c956e30927e86f", "url": "https://github.com/prestodb/presto/commit/ef26c0bf20ab0ab56b148620b5c956e30927e86f", "message": "Partial Aggregation Pushdown for ORC/Parquet", "committedDate": "2020-09-02T18:39:54Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI2NDM1Mw==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r483264353", "bodyText": "nit: hive.partial_aggregation_pushdown_enabled", "author": "shixuan-fan", "createdAt": "2020-09-03T21:29:27Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveClientConfig.java", "diffHunk": "@@ -1452,4 +1455,30 @@ public boolean isParquetDereferencePushdownEnabled()\n     {\n         return this.parquetDereferencePushdownEnabled;\n     }\n+\n+    @Config(\"hive.enable_partial_aggregation_pushdown\")", "originalCommit": "ef26c0bf20ab0ab56b148620b5c956e30927e86f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI2NDUzNg==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r483264536", "bodyText": "nit: hive.partial_aggregation_pushdown_for_variable_length_datatypes_enabled", "author": "shixuan-fan", "createdAt": "2020-09-03T21:29:51Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveClientConfig.java", "diffHunk": "@@ -1452,4 +1455,30 @@ public boolean isParquetDereferencePushdownEnabled()\n     {\n         return this.parquetDereferencePushdownEnabled;\n     }\n+\n+    @Config(\"hive.enable_partial_aggregation_pushdown\")\n+    @ConfigDescription(\"enable partial aggregation pushdown\")\n+    public HiveClientConfig setPartialAggregationPushdownEnabled(boolean partialAggregationPushdownEnabled)\n+    {\n+        this.isPartialAggregationPushdownEnabled = partialAggregationPushdownEnabled;\n+        return this;\n+    }\n+\n+    public boolean isPartialAggregationPushdownEnabled()\n+    {\n+        return this.isPartialAggregationPushdownEnabled;\n+    }\n+\n+    @Config(\"hive.enable_partial_aggregation_pushdown_for_variable_length_datatypes\")", "originalCommit": "ef26c0bf20ab0ab56b148620b5c956e30927e86f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI2NjczMg==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r483266732", "bodyText": "nit: How about making it final and renaming it DUMMY_AGGREGATED_COLUMN_INDEX", "author": "shixuan-fan", "createdAt": "2020-09-03T21:34:54Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HivePartialAggregationPushdown.java", "diffHunk": "@@ -0,0 +1,278 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive;\n+\n+import com.facebook.presto.common.type.Type;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableMetadata;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.function.FunctionHandle;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.AggregationNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.relation.CallExpression;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+\n+import javax.inject.Inject;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.Supplier;\n+\n+import static com.facebook.presto.common.type.BooleanType.BOOLEAN;\n+import static com.facebook.presto.common.type.TimestampType.TIMESTAMP;\n+import static com.facebook.presto.common.type.TinyintType.TINYINT;\n+import static com.facebook.presto.common.type.VarbinaryType.VARBINARY;\n+import static com.facebook.presto.common.type.VarcharType.VARCHAR;\n+import static com.facebook.presto.hive.HiveSessionProperties.isPartialAggregationPushdownEnabled;\n+import static com.facebook.presto.hive.HiveSessionProperties.isPartialAggregationPushdownForVariableLengthDatatypesEnabled;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.isArrayType;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.isMapType;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.isRowType;\n+import static com.facebook.presto.spi.StandardErrorCode.NOT_FOUND;\n+import static com.facebook.presto.spi.plan.AggregationNode.Step.PARTIAL;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+\n+public class HivePartialAggregationPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private final FunctionMetadataManager functionMetadataManager;\n+    private final StandardFunctionResolution standardFunctionResolution;\n+    private final Supplier<TransactionalMetadata> metadataFactory;\n+\n+    private static int aggregatedColumnIndexDummy = -20;", "originalCommit": "ef26c0bf20ab0ab56b148620b5c956e30927e86f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI3OTE0Mg==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r483279142", "bodyText": "nit: PARTIAL_AGGREGATION_PUSHDOWN_ENABLED", "author": "shixuan-fan", "createdAt": "2020-09-03T22:06:26Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveSessionProperties.java", "diffHunk": "@@ -496,6 +498,16 @@ public HiveSessionProperties(HiveClientConfig hiveClientConfig, OrcFileWriterCon\n                         PARQUET_DEREFERENCE_PUSHDOWN_ENABLED,\n                         \"Is dereference pushdown expression pushdown into Parquet reader enabled?\",\n                         hiveClientConfig.isParquetDereferencePushdownEnabled(),\n+                        false),\n+                booleanProperty(\n+                        ENABLE_PARTIAL_AGGREGATION_PUSHDOWN,", "originalCommit": "ef26c0bf20ab0ab56b148620b5c956e30927e86f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI3OTIxNg==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r483279216", "bodyText": "nit: PARTIAL_AGGREGATION_PUSHDOWN_FOR_VARIABLE_LENGTH_DATATYPES_ENABLED", "author": "shixuan-fan", "createdAt": "2020-09-03T22:06:39Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveSessionProperties.java", "diffHunk": "@@ -496,6 +498,16 @@ public HiveSessionProperties(HiveClientConfig hiveClientConfig, OrcFileWriterCon\n                         PARQUET_DEREFERENCE_PUSHDOWN_ENABLED,\n                         \"Is dereference pushdown expression pushdown into Parquet reader enabled?\",\n                         hiveClientConfig.isParquetDereferencePushdownEnabled(),\n+                        false),\n+                booleanProperty(\n+                        ENABLE_PARTIAL_AGGREGATION_PUSHDOWN,\n+                        \"Is partial aggregation pushdown enabled for Hive file formats\",\n+                        hiveClientConfig.isPartialAggregationPushdownEnabled(),\n+                        false),\n+                booleanProperty(\n+                        ENABLE_PARTIAL_AGGREGATION_PUSHDOWN_FOR_VARIABLE_LENGTH_DATATYPES,", "originalCommit": "ef26c0bf20ab0ab56b148620b5c956e30927e86f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI4MDM5NA==", "url": "https://github.com/prestodb/presto/pull/14834#discussion_r483280394", "bodyText": "nit: Let's extract this and make it a boolean function", "author": "shixuan-fan", "createdAt": "2020-09-03T22:09:46Z", "path": "presto-main/src/main/java/com/facebook/presto/sql/planner/sanity/ValidateAggregationsWithDefaultValues.java", "diffHunk": "@@ -103,6 +104,15 @@ public void validate(PlanNode planNode, Session session, Metadata metadata, SqlP\n             if (!node.getStep().equals(FINAL) || !node.hasEmptyGroupingSet()) {\n                 return Optional.empty();\n             }\n+            // TODO - hack to allow partial aggregation pushdown\n+            if (node.getStep().equals(FINAL)) {", "originalCommit": "ef26c0bf20ab0ab56b148620b5c956e30927e86f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "35878762491941f4bb2f93a35ca916039fac7c45", "url": "https://github.com/prestodb/presto/commit/35878762491941f4bb2f93a35ca916039fac7c45", "message": "Make equals() and hashCode() consistent in TableHandle", "committedDate": "2020-09-04T04:18:22Z", "type": "forcePushed"}, {"oid": "275e21f081c7c6bbd486f326f411ada82fb00a6e", "url": "https://github.com/prestodb/presto/commit/275e21f081c7c6bbd486f326f411ada82fb00a6e", "message": "Partial Aggregation Pushdown for ORC/Parquet", "committedDate": "2020-09-04T05:15:40Z", "type": "forcePushed"}, {"oid": "5c002ea74487a9772949a47a4c11c4e59c1fa1e6", "url": "https://github.com/prestodb/presto/commit/5c002ea74487a9772949a47a4c11c4e59c1fa1e6", "message": "Partial Aggregation Pushdown for ORC/Parquet", "committedDate": "2020-09-04T16:12:52Z", "type": "forcePushed"}, {"oid": "8764c46fb0ff24d8306135ee1c17a033f6978aaa", "url": "https://github.com/prestodb/presto/commit/8764c46fb0ff24d8306135ee1c17a033f6978aaa", "message": "Partial Aggregation Pushdown for ORC/Parquet", "committedDate": "2020-09-04T22:34:06Z", "type": "forcePushed"}, {"oid": "693d63d63914a14eb31cabf288b17e04a8d05221", "url": "https://github.com/prestodb/presto/commit/693d63d63914a14eb31cabf288b17e04a8d05221", "message": "Partial Aggregation Pushdown for ORC/Parquet", "committedDate": "2020-09-05T18:17:04Z", "type": "commit"}, {"oid": "693d63d63914a14eb31cabf288b17e04a8d05221", "url": "https://github.com/prestodb/presto/commit/693d63d63914a14eb31cabf288b17e04a8d05221", "message": "Partial Aggregation Pushdown for ORC/Parquet", "committedDate": "2020-09-05T18:17:04Z", "type": "forcePushed"}]}