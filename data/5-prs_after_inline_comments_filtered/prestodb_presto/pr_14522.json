{"pr_number": 14522, "pr_title": "Integrate Presto on Spark with the TaskExecutor", "pr_createdAt": "2020-05-14T00:05:52Z", "pr_url": "https://github.com/prestodb/presto/pull/14522", "timeline": [{"oid": "300486947eda67b73ecc3c6bee9a50ec9d22dafb", "url": "https://github.com/prestodb/presto/commit/300486947eda67b73ecc3c6bee9a50ec9d22dafb", "message": "Disable force single node output for Presto on Spark", "committedDate": "2020-05-19T00:24:37Z", "type": "forcePushed"}, {"oid": "c157581bd4797cd8267a5535be970234d917e9a2", "url": "https://github.com/prestodb/presto/commit/c157581bd4797cd8267a5535be970234d917e9a2", "message": "Decrease lock contention in PrestoSparkRowBuffer", "committedDate": "2020-05-22T19:49:01Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYxMTIxNA==", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r431611214", "bodyText": "FWIW, before grouped execution is introduced in 4e55aad, they are called partitionedDriverRunnerFactories and unpartitionedDriverRunnerFactories :) . We can also call them tableScanDriverRunnerFactories vs. exchangeDriverRunenrFactories? :)", "author": "wenleix", "createdAt": "2020-05-28T06:35:54Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkTaskExecution.java", "diffHunk": "@@ -0,0 +1,471 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.airlift.concurrent.SetThreadName;\n+import com.facebook.presto.event.SplitMonitor;\n+import com.facebook.presto.execution.Lifespan;\n+import com.facebook.presto.execution.ScheduledSplit;\n+import com.facebook.presto.execution.SplitRunner;\n+import com.facebook.presto.execution.TaskId;\n+import com.facebook.presto.execution.TaskSource;\n+import com.facebook.presto.execution.TaskStateMachine;\n+import com.facebook.presto.execution.executor.TaskExecutor;\n+import com.facebook.presto.execution.executor.TaskHandle;\n+import com.facebook.presto.operator.Driver;\n+import com.facebook.presto.operator.DriverContext;\n+import com.facebook.presto.operator.DriverFactory;\n+import com.facebook.presto.operator.DriverStats;\n+import com.facebook.presto.operator.PipelineContext;\n+import com.facebook.presto.operator.TaskContext;\n+import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.sql.planner.LocalExecutionPlanner.LocalExecutionPlan;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+import com.google.common.util.concurrent.FutureCallback;\n+import com.google.common.util.concurrent.Futures;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import io.airlift.units.Duration;\n+\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.Set;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import static com.facebook.presto.SystemSessionProperties.getInitialSplitsPerNode;\n+import static com.facebook.presto.SystemSessionProperties.getMaxDriversPerTask;\n+import static com.facebook.presto.SystemSessionProperties.getSplitConcurrencyAdjustmentInterval;\n+import static com.facebook.presto.operator.PipelineExecutionStrategy.UNGROUPED_EXECUTION;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.stream.Collectors.collectingAndThen;\n+import static java.util.stream.Collectors.groupingBy;\n+import static java.util.stream.Collectors.mapping;\n+\n+/**\n+ * The PrestoSparkTaskExecution is a simplified version of SqlTaskExecution.\n+ * It doesn't support grouped execution that is not needed on Presto on Spark.\n+ * Unlike the SqlTaskExecution the PrestoSparkTaskExecution does not require\n+ * the output buffer to be drained to mark the task as finished. As long as\n+ * all driver as finished the task execution is marked as finished. That allows to\n+ * have more control over the output Iterator lifecycle in the PrestoSparkTaskExecutor\n+ */\n+public class PrestoSparkTaskExecution\n+{\n+    private final TaskId taskId;\n+    private final TaskStateMachine taskStateMachine;\n+    private final TaskContext taskContext;\n+\n+    private final TaskHandle taskHandle;\n+    private final TaskExecutor taskExecutor;\n+\n+    private final Executor notificationExecutor;\n+\n+    private final SplitMonitor splitMonitor;\n+\n+    private final List<PlanNodeId> schedulingOrder;\n+    private final Map<PlanNodeId, DriverSplitRunnerFactory> driverRunnerFactoriesWithSplitLifeCycle;", "originalCommit": "a26ba8d7d1ff28510647043d2372676f97ce8bdf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTkzNTE5Mg==", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r431935192", "bodyText": "tableScanDriverRunnerFactories sounds good. However exchangeDriverRunenrFactories is not necessarily accurate, as for example aggregation will have task lifecycle runners.", "author": "arhimondr", "createdAt": "2020-05-28T15:40:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYxMTIxNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI2NTIzMg==", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r432265232", "bodyText": "as for example aggregation will have task lifecycle runners.\n\ndon't the drivers with task lifecycle runners read from local exchange ?", "author": "wenleix", "createdAt": "2020-05-29T05:37:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYxMTIxNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzMwMjY0Mw==", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r433302643", "bodyText": "Actually you are right. In order for pipeline to be task wide, the pipeline must either read from a local or from a remove exchange. Let me do the rename.", "author": "arhimondr", "createdAt": "2020-06-01T15:26:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYxMTIxNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzMzMzE3NA==", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r433333174", "bodyText": "After some thinking I realize that exchangeDriverRunenrFactories and tableScanDriverRunnerFactories might sound somehow misleading. The name may imply that the DriverRunners will be running only table scans or only exchanges, when in practice they run some other operators as part of the same pipeline.", "author": "arhimondr", "createdAt": "2020-06-01T16:01:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYxMTIxNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzY0OTc4MA==", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r433649780", "bodyText": "@arhimondr :\n\nThe name may imply that the DriverRunners will be running only table scans or only exchanges, when in practice they run some other operators as part of the same pipeline.\n\nThat's a fair point. I don't think there is good name:\n\n\nThe old \"partitioned\" / \"unpartitioned\" name is cryptic to understand. But it's also quite universal and some engineers (like me) already read them as \"table scan driver\" vs. \"exchange driver\"\n\n\ndriverRunnerFactoriesWithSplitLifeCycle and driverRunnerFactoriesWithTaskLifeCycle is correct, but also not easy to understand.. in fact I did a manual map to \"partitioned driver runner\" vs. \"unpartitioned driver runner\"\n\n\ntableScanDriverRunnerFactories / exchangeDriverRunenrFactories : It's easiest for me to understand, but as you point out, the name is misleading... tableScanSourcedDriverRunnerFactories / exchangeSourcedDriverRunenrFactories is more accurate but also too verbose... \ud83d\ude15\n\n\nSo... let's keep what you named there... \ud83d\ude03", "author": "wenleix", "createdAt": "2020-06-02T06:34:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYxMTIxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYxMzI1Ng==", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r431613256", "bodyText": "I am thinking if it makes sense to write imperative for-loop here? -- My general preference is when Stream API is used in such a complicated way, it's actually more difficult to understand than old good for-loop.\nBut it's just a personal taste.", "author": "wenleix", "createdAt": "2020-05-28T06:41:17Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkTaskExecution.java", "diffHunk": "@@ -0,0 +1,471 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.airlift.concurrent.SetThreadName;\n+import com.facebook.presto.event.SplitMonitor;\n+import com.facebook.presto.execution.Lifespan;\n+import com.facebook.presto.execution.ScheduledSplit;\n+import com.facebook.presto.execution.SplitRunner;\n+import com.facebook.presto.execution.TaskId;\n+import com.facebook.presto.execution.TaskSource;\n+import com.facebook.presto.execution.TaskStateMachine;\n+import com.facebook.presto.execution.executor.TaskExecutor;\n+import com.facebook.presto.execution.executor.TaskHandle;\n+import com.facebook.presto.operator.Driver;\n+import com.facebook.presto.operator.DriverContext;\n+import com.facebook.presto.operator.DriverFactory;\n+import com.facebook.presto.operator.DriverStats;\n+import com.facebook.presto.operator.PipelineContext;\n+import com.facebook.presto.operator.TaskContext;\n+import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.sql.planner.LocalExecutionPlanner.LocalExecutionPlan;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+import com.google.common.util.concurrent.FutureCallback;\n+import com.google.common.util.concurrent.Futures;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import io.airlift.units.Duration;\n+\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.Set;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import static com.facebook.presto.SystemSessionProperties.getInitialSplitsPerNode;\n+import static com.facebook.presto.SystemSessionProperties.getMaxDriversPerTask;\n+import static com.facebook.presto.SystemSessionProperties.getSplitConcurrencyAdjustmentInterval;\n+import static com.facebook.presto.operator.PipelineExecutionStrategy.UNGROUPED_EXECUTION;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.stream.Collectors.collectingAndThen;\n+import static java.util.stream.Collectors.groupingBy;\n+import static java.util.stream.Collectors.mapping;\n+\n+/**\n+ * The PrestoSparkTaskExecution is a simplified version of SqlTaskExecution.\n+ * It doesn't support grouped execution that is not needed on Presto on Spark.\n+ * Unlike the SqlTaskExecution the PrestoSparkTaskExecution does not require\n+ * the output buffer to be drained to mark the task as finished. As long as\n+ * all driver as finished the task execution is marked as finished. That allows to\n+ * have more control over the output Iterator lifecycle in the PrestoSparkTaskExecutor\n+ */\n+public class PrestoSparkTaskExecution\n+{\n+    private final TaskId taskId;\n+    private final TaskStateMachine taskStateMachine;\n+    private final TaskContext taskContext;\n+\n+    private final TaskHandle taskHandle;\n+    private final TaskExecutor taskExecutor;\n+\n+    private final Executor notificationExecutor;\n+\n+    private final SplitMonitor splitMonitor;\n+\n+    private final List<PlanNodeId> schedulingOrder;\n+    private final Map<PlanNodeId, DriverSplitRunnerFactory> driverRunnerFactoriesWithSplitLifeCycle;\n+    private final List<DriverSplitRunnerFactory> driverRunnerFactoriesWithTaskLifeCycle;\n+\n+    private final AtomicInteger remainingDrivers = new AtomicInteger();\n+\n+    public PrestoSparkTaskExecution(\n+            TaskStateMachine taskStateMachine,\n+            TaskContext taskContext,\n+            LocalExecutionPlan localExecutionPlan,\n+            TaskExecutor taskExecutor,\n+            SplitMonitor splitMonitor,\n+            Executor notificationExecutor)\n+    {\n+        this.taskStateMachine = requireNonNull(taskStateMachine, \"taskStateMachine is null\");\n+        this.taskId = taskStateMachine.getTaskId();\n+        this.taskContext = requireNonNull(taskContext, \"taskContext is null\");\n+\n+        this.taskExecutor = requireNonNull(taskExecutor, \"driverExecutor is null\");\n+        this.notificationExecutor = requireNonNull(notificationExecutor, \"notificationExecutor is null\");\n+\n+        this.splitMonitor = requireNonNull(splitMonitor, \"splitMonitor is null\");\n+\n+        // index driver factories\n+        schedulingOrder = localExecutionPlan.getTableScanSourceOrder();\n+        Set<PlanNodeId> tableScanSources = ImmutableSet.copyOf(schedulingOrder);\n+        ImmutableMap.Builder<PlanNodeId, DriverSplitRunnerFactory> driverRunnerFactoriesWithSplitLifeCycle = ImmutableMap.builder();\n+        ImmutableList.Builder<DriverSplitRunnerFactory> driverRunnerFactoriesWithTaskLifeCycle = ImmutableList.builder();\n+        for (DriverFactory driverFactory : localExecutionPlan.getDriverFactories()) {\n+            Optional<PlanNodeId> sourceId = driverFactory.getSourceId();\n+            if (sourceId.isPresent() && tableScanSources.contains(sourceId.get())) {\n+                driverRunnerFactoriesWithSplitLifeCycle.put(sourceId.get(), new DriverSplitRunnerFactory(driverFactory, true));\n+            }\n+            else {\n+                checkArgument(\n+                        driverFactory.getPipelineExecutionStrategy() == UNGROUPED_EXECUTION,\n+                        \"unexpected pipeline execution strategy: %s\",\n+                        driverFactory.getPipelineExecutionStrategy());\n+                driverRunnerFactoriesWithTaskLifeCycle.add(new DriverSplitRunnerFactory(driverFactory, false));\n+            }\n+        }\n+        this.driverRunnerFactoriesWithSplitLifeCycle = driverRunnerFactoriesWithSplitLifeCycle.build();\n+        this.driverRunnerFactoriesWithTaskLifeCycle = driverRunnerFactoriesWithTaskLifeCycle.build();\n+\n+        checkArgument(this.driverRunnerFactoriesWithSplitLifeCycle.keySet().equals(tableScanSources),\n+                \"Fragment is partitioned, but not all partitioned drivers were found\");\n+\n+        taskHandle = createTaskHandle(taskStateMachine, taskContext, localExecutionPlan, taskExecutor);\n+    }\n+\n+    // this is a separate method to ensure that the `this` reference is not leaked during construction\n+    private static TaskHandle createTaskHandle(\n+            TaskStateMachine taskStateMachine,\n+            TaskContext taskContext,\n+            LocalExecutionPlan localExecutionPlan,\n+            TaskExecutor taskExecutor)\n+    {\n+        TaskHandle taskHandle = taskExecutor.addTask(\n+                taskStateMachine.getTaskId(),\n+                () -> 0,\n+                getInitialSplitsPerNode(taskContext.getSession()),\n+                getSplitConcurrencyAdjustmentInterval(taskContext.getSession()),\n+                getMaxDriversPerTask(taskContext.getSession()));\n+        taskStateMachine.addStateChangeListener(state -> {\n+            if (state.isDone()) {\n+                taskExecutor.removeTask(taskHandle);\n+                for (DriverFactory factory : localExecutionPlan.getDriverFactories()) {\n+                    factory.noMoreDrivers();\n+                }\n+            }\n+        });\n+        return taskHandle;\n+    }\n+\n+    public void start(List<TaskSource> sources)\n+    {\n+        requireNonNull(sources, \"sources is null\");\n+\n+        scheduleDriversForTaskLifeCycle();\n+        scheduleDriversForSplitLifeCycle(sources);\n+        checkTaskCompletion();\n+    }\n+\n+    private void scheduleDriversForTaskLifeCycle()\n+    {\n+        List<DriverSplitRunner> runners = new ArrayList<>();\n+        for (DriverSplitRunnerFactory driverRunnerFactory : driverRunnerFactoriesWithTaskLifeCycle) {\n+            for (int i = 0; i < driverRunnerFactory.getDriverInstances().orElse(1); i++) {\n+                runners.add(driverRunnerFactory.createDriverRunner(null));\n+            }\n+        }\n+        enqueueDriverSplitRunner(true, runners);\n+        for (DriverSplitRunnerFactory driverRunnerFactory : driverRunnerFactoriesWithTaskLifeCycle) {\n+            driverRunnerFactory.noMoreDriverRunner();\n+            verify(driverRunnerFactory.isNoMoreDriverRunner());\n+        }\n+    }\n+\n+    private synchronized void scheduleDriversForSplitLifeCycle(List<TaskSource> sources)\n+    {\n+        checkArgument(sources.stream().allMatch(TaskSource::isNoMoreSplits), \"All task sources are expected to be final\");\n+\n+        Map<PlanNodeId, List<ScheduledSplit>> splits = sources.stream()", "originalCommit": "a26ba8d7d1ff28510647043d2372676f97ce8bdf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzMwMzcwMg==", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r433303702", "bodyText": "Yeah, i think it become way to cryptic.", "author": "arhimondr", "createdAt": "2020-06-01T15:28:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYxMzI1Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzMwNjkyOQ==", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r433306929", "bodyText": "The iterative version + ListMultimap is much more readable", "author": "arhimondr", "createdAt": "2020-06-01T15:31:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYxMzI1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYxMzkxNw==", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r431613917", "bodyText": "Are you forking the current SqlTaskExecution (and remove grouped execution related stuff), or you are forking the old SqlTaskExecution (i.e. before commit 4e55aad) . In my opinion the code is much easier to follow with the old SqlTaskExecution", "author": "wenleix", "createdAt": "2020-05-28T06:42:57Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkTaskExecution.java", "diffHunk": "@@ -0,0 +1,471 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.airlift.concurrent.SetThreadName;\n+import com.facebook.presto.event.SplitMonitor;\n+import com.facebook.presto.execution.Lifespan;\n+import com.facebook.presto.execution.ScheduledSplit;\n+import com.facebook.presto.execution.SplitRunner;\n+import com.facebook.presto.execution.TaskId;\n+import com.facebook.presto.execution.TaskSource;\n+import com.facebook.presto.execution.TaskStateMachine;\n+import com.facebook.presto.execution.executor.TaskExecutor;\n+import com.facebook.presto.execution.executor.TaskHandle;\n+import com.facebook.presto.operator.Driver;\n+import com.facebook.presto.operator.DriverContext;\n+import com.facebook.presto.operator.DriverFactory;\n+import com.facebook.presto.operator.DriverStats;\n+import com.facebook.presto.operator.PipelineContext;\n+import com.facebook.presto.operator.TaskContext;\n+import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.sql.planner.LocalExecutionPlanner.LocalExecutionPlan;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+import com.google.common.util.concurrent.FutureCallback;\n+import com.google.common.util.concurrent.Futures;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import io.airlift.units.Duration;\n+\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.Set;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import static com.facebook.presto.SystemSessionProperties.getInitialSplitsPerNode;\n+import static com.facebook.presto.SystemSessionProperties.getMaxDriversPerTask;\n+import static com.facebook.presto.SystemSessionProperties.getSplitConcurrencyAdjustmentInterval;\n+import static com.facebook.presto.operator.PipelineExecutionStrategy.UNGROUPED_EXECUTION;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.stream.Collectors.collectingAndThen;\n+import static java.util.stream.Collectors.groupingBy;\n+import static java.util.stream.Collectors.mapping;\n+\n+/**\n+ * The PrestoSparkTaskExecution is a simplified version of SqlTaskExecution.\n+ * It doesn't support grouped execution that is not needed on Presto on Spark.\n+ * Unlike the SqlTaskExecution the PrestoSparkTaskExecution does not require\n+ * the output buffer to be drained to mark the task as finished. As long as\n+ * all driver as finished the task execution is marked as finished. That allows to\n+ * have more control over the output Iterator lifecycle in the PrestoSparkTaskExecutor\n+ */\n+public class PrestoSparkTaskExecution", "originalCommit": "a26ba8d7d1ff28510647043d2372676f97ce8bdf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTkzNDE1NA==", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r431934154", "bodyText": "I took the current version of SqlTaskExecution as a base, but I was looking at the old version while removing grouped execution code.", "author": "arhimondr", "createdAt": "2020-05-28T15:39:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYxMzkxNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI3MzE5Nw==", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r432273197", "bodyText": "Maybe add some guard to make sure start will only be called once? :)", "author": "wenleix", "createdAt": "2020-05-29T06:05:50Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkTaskExecution.java", "diffHunk": "@@ -0,0 +1,471 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.airlift.concurrent.SetThreadName;\n+import com.facebook.presto.event.SplitMonitor;\n+import com.facebook.presto.execution.Lifespan;\n+import com.facebook.presto.execution.ScheduledSplit;\n+import com.facebook.presto.execution.SplitRunner;\n+import com.facebook.presto.execution.TaskId;\n+import com.facebook.presto.execution.TaskSource;\n+import com.facebook.presto.execution.TaskStateMachine;\n+import com.facebook.presto.execution.executor.TaskExecutor;\n+import com.facebook.presto.execution.executor.TaskHandle;\n+import com.facebook.presto.operator.Driver;\n+import com.facebook.presto.operator.DriverContext;\n+import com.facebook.presto.operator.DriverFactory;\n+import com.facebook.presto.operator.DriverStats;\n+import com.facebook.presto.operator.PipelineContext;\n+import com.facebook.presto.operator.TaskContext;\n+import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.sql.planner.LocalExecutionPlanner.LocalExecutionPlan;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+import com.google.common.util.concurrent.FutureCallback;\n+import com.google.common.util.concurrent.Futures;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import io.airlift.units.Duration;\n+\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.Set;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import static com.facebook.presto.SystemSessionProperties.getInitialSplitsPerNode;\n+import static com.facebook.presto.SystemSessionProperties.getMaxDriversPerTask;\n+import static com.facebook.presto.SystemSessionProperties.getSplitConcurrencyAdjustmentInterval;\n+import static com.facebook.presto.operator.PipelineExecutionStrategy.UNGROUPED_EXECUTION;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.stream.Collectors.collectingAndThen;\n+import static java.util.stream.Collectors.groupingBy;\n+import static java.util.stream.Collectors.mapping;\n+\n+/**\n+ * The PrestoSparkTaskExecution is a simplified version of SqlTaskExecution.\n+ * It doesn't support grouped execution that is not needed on Presto on Spark.\n+ * Unlike the SqlTaskExecution the PrestoSparkTaskExecution does not require\n+ * the output buffer to be drained to mark the task as finished. As long as\n+ * all driver as finished the task execution is marked as finished. That allows to\n+ * have more control over the output Iterator lifecycle in the PrestoSparkTaskExecutor\n+ */\n+public class PrestoSparkTaskExecution\n+{\n+    private final TaskId taskId;\n+    private final TaskStateMachine taskStateMachine;\n+    private final TaskContext taskContext;\n+\n+    private final TaskHandle taskHandle;\n+    private final TaskExecutor taskExecutor;\n+\n+    private final Executor notificationExecutor;\n+\n+    private final SplitMonitor splitMonitor;\n+\n+    private final List<PlanNodeId> schedulingOrder;\n+    private final Map<PlanNodeId, DriverSplitRunnerFactory> driverRunnerFactoriesWithSplitLifeCycle;\n+    private final List<DriverSplitRunnerFactory> driverRunnerFactoriesWithTaskLifeCycle;\n+\n+    private final AtomicInteger remainingDrivers = new AtomicInteger();\n+\n+    public PrestoSparkTaskExecution(\n+            TaskStateMachine taskStateMachine,\n+            TaskContext taskContext,\n+            LocalExecutionPlan localExecutionPlan,\n+            TaskExecutor taskExecutor,\n+            SplitMonitor splitMonitor,\n+            Executor notificationExecutor)\n+    {\n+        this.taskStateMachine = requireNonNull(taskStateMachine, \"taskStateMachine is null\");\n+        this.taskId = taskStateMachine.getTaskId();\n+        this.taskContext = requireNonNull(taskContext, \"taskContext is null\");\n+\n+        this.taskExecutor = requireNonNull(taskExecutor, \"driverExecutor is null\");\n+        this.notificationExecutor = requireNonNull(notificationExecutor, \"notificationExecutor is null\");\n+\n+        this.splitMonitor = requireNonNull(splitMonitor, \"splitMonitor is null\");\n+\n+        // index driver factories\n+        schedulingOrder = localExecutionPlan.getTableScanSourceOrder();\n+        Set<PlanNodeId> tableScanSources = ImmutableSet.copyOf(schedulingOrder);\n+        ImmutableMap.Builder<PlanNodeId, DriverSplitRunnerFactory> driverRunnerFactoriesWithSplitLifeCycle = ImmutableMap.builder();\n+        ImmutableList.Builder<DriverSplitRunnerFactory> driverRunnerFactoriesWithTaskLifeCycle = ImmutableList.builder();\n+        for (DriverFactory driverFactory : localExecutionPlan.getDriverFactories()) {\n+            Optional<PlanNodeId> sourceId = driverFactory.getSourceId();\n+            if (sourceId.isPresent() && tableScanSources.contains(sourceId.get())) {\n+                driverRunnerFactoriesWithSplitLifeCycle.put(sourceId.get(), new DriverSplitRunnerFactory(driverFactory, true));\n+            }\n+            else {\n+                checkArgument(\n+                        driverFactory.getPipelineExecutionStrategy() == UNGROUPED_EXECUTION,\n+                        \"unexpected pipeline execution strategy: %s\",\n+                        driverFactory.getPipelineExecutionStrategy());\n+                driverRunnerFactoriesWithTaskLifeCycle.add(new DriverSplitRunnerFactory(driverFactory, false));\n+            }\n+        }\n+        this.driverRunnerFactoriesWithSplitLifeCycle = driverRunnerFactoriesWithSplitLifeCycle.build();\n+        this.driverRunnerFactoriesWithTaskLifeCycle = driverRunnerFactoriesWithTaskLifeCycle.build();\n+\n+        checkArgument(this.driverRunnerFactoriesWithSplitLifeCycle.keySet().equals(tableScanSources),\n+                \"Fragment is partitioned, but not all partitioned drivers were found\");\n+\n+        taskHandle = createTaskHandle(taskStateMachine, taskContext, localExecutionPlan, taskExecutor);\n+    }\n+\n+    // this is a separate method to ensure that the `this` reference is not leaked during construction\n+    private static TaskHandle createTaskHandle(\n+            TaskStateMachine taskStateMachine,\n+            TaskContext taskContext,\n+            LocalExecutionPlan localExecutionPlan,\n+            TaskExecutor taskExecutor)\n+    {\n+        TaskHandle taskHandle = taskExecutor.addTask(\n+                taskStateMachine.getTaskId(),\n+                () -> 0,\n+                getInitialSplitsPerNode(taskContext.getSession()),\n+                getSplitConcurrencyAdjustmentInterval(taskContext.getSession()),\n+                getMaxDriversPerTask(taskContext.getSession()));\n+        taskStateMachine.addStateChangeListener(state -> {\n+            if (state.isDone()) {\n+                taskExecutor.removeTask(taskHandle);\n+                for (DriverFactory factory : localExecutionPlan.getDriverFactories()) {\n+                    factory.noMoreDrivers();\n+                }\n+            }\n+        });\n+        return taskHandle;\n+    }\n+\n+    public void start(List<TaskSource> sources)", "originalCommit": "a26ba8d7d1ff28510647043d2372676f97ce8bdf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI3Nzk2Ng==", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r432277966", "bodyText": "Does this has to be a ImutableList.Builder? -- or a normal ArrayList would be good?\nAlso maybe consider to use previous list size to initialize new array list capacity -- although shouldn't be a big issue.", "author": "wenleix", "createdAt": "2020-05-29T06:21:50Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputOperator.java", "diffHunk": "@@ -245,15 +258,29 @@ public void addInput(Page page)\n             byte[] rowBytes = output.size() == 0 ? new byte[0] : output.getUnderlyingSlice().byteArray();\n             if (shouldReplicate) {\n                 for (int i = 0; i < partitionFunction.getPartitionCount(); i++) {\n-                    rowBuffer.enqueue(new PrestoSparkRow(i, output.size(), rowBytes));\n+                    appendRow(new PrestoSparkRow(i, output.size(), rowBytes));\n                 }\n                 hasAnyRowBeenReplicated = true;\n             }\n             else {\n                 int partition = getPartition(partitionFunctionArguments, position);\n-                rowBuffer.enqueue(new PrestoSparkRow(partition, output.size(), rowBytes));\n+                appendRow(new PrestoSparkRow(partition, output.size(), rowBytes));\n             }\n         }\n+        updateMemoryContext();\n+    }\n+\n+    private void appendRow(PrestoSparkRow row)\n+    {\n+        long rowSize = row.getRetainedSize();\n+        if (currentBatchSize + rowSize > BATCH_SIZE) {\n+            flush();\n+        }\n+        if (currentBatch == null) {\n+            currentBatch = ImmutableList.builderWithExpectedSize(EXPECTED_ROWS_COUNT_PER_BATCH);", "originalCommit": "c157581bd4797cd8267a5535be970234d917e9a2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzMxMTA0NQ==", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r433311045", "bodyText": "Does this has to be a ImutableList.Builder? -- or a normal ArrayList would be good?\n\nWe usually prefer immutable collections. But in theory it could also be a regular ArrayList.\n\nAlso maybe consider to use previous list size to initialize new array list capacity -- although shouldn't be a big issue.\n\nLet's keep it like this for now to do not complicate the logic. It can be improved in the future if needed.", "author": "arhimondr", "createdAt": "2020-06-01T15:35:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI3Nzk2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI3OTYwOA==", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r432279608", "bodyText": "Is this only get called twice ? (once enqueue and once get)? Note in theory we can always reduce the retain size computation to be once (by wrapping it with something like PrestoSparkRowBatch. But if it's just computed twice I think it's OK to keep it as is.", "author": "wenleix", "createdAt": "2020-05-29T06:26:36Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRowBuffer.java", "diffHunk": "@@ -63,21 +65,34 @@ public void setNoMoreRows()\n         }\n     }\n \n-    public PrestoSparkRow get()\n+    public List<PrestoSparkRow> get()\n             throws InterruptedException\n     {\n-        PrestoSparkRow row = null;\n+        List<PrestoSparkRow> rows = null;\n         synchronized (monitor) {\n             while (buffer.isEmpty() && !finished) {\n                 monitor.wait();\n             }\n             if (!buffer.isEmpty()) {\n-                row = buffer.poll();\n+                rows = buffer.poll();\n             }\n-            if (row != null) {\n-                memoryManager.updateMemoryUsage(-row.getRetainedSize());\n+            if (rows != null) {\n+                memoryManager.updateMemoryUsage(-getRetainedSize(rows));\n             }\n         }\n-        return row;\n+        return rows;\n+    }\n+\n+    /**\n+     * Does not use iterators / streams for efficiency\n+     */\n+    @SuppressWarnings(\"ForLoopReplaceableByForEach\")\n+    private static long getRetainedSize(List<PrestoSparkRow> rows)", "originalCommit": "c157581bd4797cd8267a5535be970234d917e9a2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzMyNDIyMA==", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r433324220", "bodyText": "I think it makes sense. Currently the retained memory is recomputed several times. Added BufferedRows class to reuse the currentBatchSize computed by the PrestoSparkOutputOperator", "author": "arhimondr", "createdAt": "2020-06-01T15:50:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI3OTYwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI4MDc1OA==", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r432280758", "bodyText": "Note the memory doesn't really get cleaned before this batch get fully consumed by PrestoSparkTaskExecutor#getNextRow. So we could under-count 1 batch of rows. Is this acceptable?", "author": "wenleix", "createdAt": "2020-05-29T06:29:56Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRowBuffer.java", "diffHunk": "@@ -63,21 +65,34 @@ public void setNoMoreRows()\n         }\n     }\n \n-    public PrestoSparkRow get()\n+    public List<PrestoSparkRow> get()\n             throws InterruptedException\n     {\n-        PrestoSparkRow row = null;\n+        List<PrestoSparkRow> rows = null;\n         synchronized (monitor) {\n             while (buffer.isEmpty() && !finished) {\n                 monitor.wait();\n             }\n             if (!buffer.isEmpty()) {\n-                row = buffer.poll();\n+                rows = buffer.poll();\n             }\n-            if (row != null) {\n-                memoryManager.updateMemoryUsage(-row.getRetainedSize());\n+            if (rows != null) {\n+                memoryManager.updateMemoryUsage(-getRetainedSize(rows));", "originalCommit": "c157581bd4797cd8267a5535be970234d917e9a2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzMyNzE3Mg==", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r433327172", "bodyText": "Ideally we can make the PrestoSparkTaskExecutor to account for that memory when the rows are handed over to it. But PrestoSparkTaskExecutor is not an operator, so it doesn't have an OperatorContext, thus memory accounting in the PrestoSparkTaskExecutor is a little problematic. Given there's only a single PrestoSparkTaskExecutor exist, and no more than a single batch of rows can go miscounted (~1MB) it feels like it shouldn't be a big problem.", "author": "arhimondr", "createdAt": "2020-06-01T15:53:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI4MDc1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzA1MzI4NA==", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r433053284", "bodyText": "I think the comment in SqlTaskExecution is probably useful?\n    /**\n     * Number of drivers that have been sent to the TaskExecutor that have not finished.\n     */", "author": "wenleix", "createdAt": "2020-06-01T05:53:12Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkTaskExecution.java", "diffHunk": "@@ -0,0 +1,471 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.airlift.concurrent.SetThreadName;\n+import com.facebook.presto.event.SplitMonitor;\n+import com.facebook.presto.execution.Lifespan;\n+import com.facebook.presto.execution.ScheduledSplit;\n+import com.facebook.presto.execution.SplitRunner;\n+import com.facebook.presto.execution.TaskId;\n+import com.facebook.presto.execution.TaskSource;\n+import com.facebook.presto.execution.TaskStateMachine;\n+import com.facebook.presto.execution.executor.TaskExecutor;\n+import com.facebook.presto.execution.executor.TaskHandle;\n+import com.facebook.presto.operator.Driver;\n+import com.facebook.presto.operator.DriverContext;\n+import com.facebook.presto.operator.DriverFactory;\n+import com.facebook.presto.operator.DriverStats;\n+import com.facebook.presto.operator.PipelineContext;\n+import com.facebook.presto.operator.TaskContext;\n+import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.sql.planner.LocalExecutionPlanner.LocalExecutionPlan;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+import com.google.common.util.concurrent.FutureCallback;\n+import com.google.common.util.concurrent.Futures;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import io.airlift.units.Duration;\n+\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.Set;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import static com.facebook.presto.SystemSessionProperties.getInitialSplitsPerNode;\n+import static com.facebook.presto.SystemSessionProperties.getMaxDriversPerTask;\n+import static com.facebook.presto.SystemSessionProperties.getSplitConcurrencyAdjustmentInterval;\n+import static com.facebook.presto.operator.PipelineExecutionStrategy.UNGROUPED_EXECUTION;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.stream.Collectors.collectingAndThen;\n+import static java.util.stream.Collectors.groupingBy;\n+import static java.util.stream.Collectors.mapping;\n+\n+/**\n+ * The PrestoSparkTaskExecution is a simplified version of SqlTaskExecution.\n+ * It doesn't support grouped execution that is not needed on Presto on Spark.\n+ * Unlike the SqlTaskExecution the PrestoSparkTaskExecution does not require\n+ * the output buffer to be drained to mark the task as finished. As long as\n+ * all driver as finished the task execution is marked as finished. That allows to\n+ * have more control over the output Iterator lifecycle in the PrestoSparkTaskExecutor\n+ */\n+public class PrestoSparkTaskExecution\n+{\n+    private final TaskId taskId;\n+    private final TaskStateMachine taskStateMachine;\n+    private final TaskContext taskContext;\n+\n+    private final TaskHandle taskHandle;\n+    private final TaskExecutor taskExecutor;\n+\n+    private final Executor notificationExecutor;\n+\n+    private final SplitMonitor splitMonitor;\n+\n+    private final List<PlanNodeId> schedulingOrder;\n+    private final Map<PlanNodeId, DriverSplitRunnerFactory> driverRunnerFactoriesWithSplitLifeCycle;\n+    private final List<DriverSplitRunnerFactory> driverRunnerFactoriesWithTaskLifeCycle;\n+\n+    private final AtomicInteger remainingDrivers = new AtomicInteger();", "originalCommit": "a26ba8d7d1ff28510647043d2372676f97ce8bdf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzA1NjEyMg==", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r433056122", "bodyText": "Curious: why need to track closed in DriverSplitRunnerFactory?", "author": "wenleix", "createdAt": "2020-06-01T06:04:12Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkTaskExecution.java", "diffHunk": "@@ -0,0 +1,471 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.airlift.concurrent.SetThreadName;\n+import com.facebook.presto.event.SplitMonitor;\n+import com.facebook.presto.execution.Lifespan;\n+import com.facebook.presto.execution.ScheduledSplit;\n+import com.facebook.presto.execution.SplitRunner;\n+import com.facebook.presto.execution.TaskId;\n+import com.facebook.presto.execution.TaskSource;\n+import com.facebook.presto.execution.TaskStateMachine;\n+import com.facebook.presto.execution.executor.TaskExecutor;\n+import com.facebook.presto.execution.executor.TaskHandle;\n+import com.facebook.presto.operator.Driver;\n+import com.facebook.presto.operator.DriverContext;\n+import com.facebook.presto.operator.DriverFactory;\n+import com.facebook.presto.operator.DriverStats;\n+import com.facebook.presto.operator.PipelineContext;\n+import com.facebook.presto.operator.TaskContext;\n+import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.sql.planner.LocalExecutionPlanner.LocalExecutionPlan;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+import com.google.common.util.concurrent.FutureCallback;\n+import com.google.common.util.concurrent.Futures;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import io.airlift.units.Duration;\n+\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.Set;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import static com.facebook.presto.SystemSessionProperties.getInitialSplitsPerNode;\n+import static com.facebook.presto.SystemSessionProperties.getMaxDriversPerTask;\n+import static com.facebook.presto.SystemSessionProperties.getSplitConcurrencyAdjustmentInterval;\n+import static com.facebook.presto.operator.PipelineExecutionStrategy.UNGROUPED_EXECUTION;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.stream.Collectors.collectingAndThen;\n+import static java.util.stream.Collectors.groupingBy;\n+import static java.util.stream.Collectors.mapping;\n+\n+/**\n+ * The PrestoSparkTaskExecution is a simplified version of SqlTaskExecution.\n+ * It doesn't support grouped execution that is not needed on Presto on Spark.\n+ * Unlike the SqlTaskExecution the PrestoSparkTaskExecution does not require\n+ * the output buffer to be drained to mark the task as finished. As long as\n+ * all driver as finished the task execution is marked as finished. That allows to\n+ * have more control over the output Iterator lifecycle in the PrestoSparkTaskExecutor\n+ */\n+public class PrestoSparkTaskExecution\n+{\n+    private final TaskId taskId;\n+    private final TaskStateMachine taskStateMachine;\n+    private final TaskContext taskContext;\n+\n+    private final TaskHandle taskHandle;\n+    private final TaskExecutor taskExecutor;\n+\n+    private final Executor notificationExecutor;\n+\n+    private final SplitMonitor splitMonitor;\n+\n+    private final List<PlanNodeId> schedulingOrder;\n+    private final Map<PlanNodeId, DriverSplitRunnerFactory> driverRunnerFactoriesWithSplitLifeCycle;\n+    private final List<DriverSplitRunnerFactory> driverRunnerFactoriesWithTaskLifeCycle;\n+\n+    private final AtomicInteger remainingDrivers = new AtomicInteger();\n+\n+    public PrestoSparkTaskExecution(\n+            TaskStateMachine taskStateMachine,\n+            TaskContext taskContext,\n+            LocalExecutionPlan localExecutionPlan,\n+            TaskExecutor taskExecutor,\n+            SplitMonitor splitMonitor,\n+            Executor notificationExecutor)\n+    {\n+        this.taskStateMachine = requireNonNull(taskStateMachine, \"taskStateMachine is null\");\n+        this.taskId = taskStateMachine.getTaskId();\n+        this.taskContext = requireNonNull(taskContext, \"taskContext is null\");\n+\n+        this.taskExecutor = requireNonNull(taskExecutor, \"driverExecutor is null\");\n+        this.notificationExecutor = requireNonNull(notificationExecutor, \"notificationExecutor is null\");\n+\n+        this.splitMonitor = requireNonNull(splitMonitor, \"splitMonitor is null\");\n+\n+        // index driver factories\n+        schedulingOrder = localExecutionPlan.getTableScanSourceOrder();\n+        Set<PlanNodeId> tableScanSources = ImmutableSet.copyOf(schedulingOrder);\n+        ImmutableMap.Builder<PlanNodeId, DriverSplitRunnerFactory> driverRunnerFactoriesWithSplitLifeCycle = ImmutableMap.builder();\n+        ImmutableList.Builder<DriverSplitRunnerFactory> driverRunnerFactoriesWithTaskLifeCycle = ImmutableList.builder();\n+        for (DriverFactory driverFactory : localExecutionPlan.getDriverFactories()) {\n+            Optional<PlanNodeId> sourceId = driverFactory.getSourceId();\n+            if (sourceId.isPresent() && tableScanSources.contains(sourceId.get())) {\n+                driverRunnerFactoriesWithSplitLifeCycle.put(sourceId.get(), new DriverSplitRunnerFactory(driverFactory, true));\n+            }\n+            else {\n+                checkArgument(\n+                        driverFactory.getPipelineExecutionStrategy() == UNGROUPED_EXECUTION,\n+                        \"unexpected pipeline execution strategy: %s\",\n+                        driverFactory.getPipelineExecutionStrategy());\n+                driverRunnerFactoriesWithTaskLifeCycle.add(new DriverSplitRunnerFactory(driverFactory, false));\n+            }\n+        }\n+        this.driverRunnerFactoriesWithSplitLifeCycle = driverRunnerFactoriesWithSplitLifeCycle.build();\n+        this.driverRunnerFactoriesWithTaskLifeCycle = driverRunnerFactoriesWithTaskLifeCycle.build();\n+\n+        checkArgument(this.driverRunnerFactoriesWithSplitLifeCycle.keySet().equals(tableScanSources),\n+                \"Fragment is partitioned, but not all partitioned drivers were found\");\n+\n+        taskHandle = createTaskHandle(taskStateMachine, taskContext, localExecutionPlan, taskExecutor);\n+    }\n+\n+    // this is a separate method to ensure that the `this` reference is not leaked during construction\n+    private static TaskHandle createTaskHandle(\n+            TaskStateMachine taskStateMachine,\n+            TaskContext taskContext,\n+            LocalExecutionPlan localExecutionPlan,\n+            TaskExecutor taskExecutor)\n+    {\n+        TaskHandle taskHandle = taskExecutor.addTask(\n+                taskStateMachine.getTaskId(),\n+                () -> 0,\n+                getInitialSplitsPerNode(taskContext.getSession()),\n+                getSplitConcurrencyAdjustmentInterval(taskContext.getSession()),\n+                getMaxDriversPerTask(taskContext.getSession()));\n+        taskStateMachine.addStateChangeListener(state -> {\n+            if (state.isDone()) {\n+                taskExecutor.removeTask(taskHandle);\n+                for (DriverFactory factory : localExecutionPlan.getDriverFactories()) {\n+                    factory.noMoreDrivers();\n+                }\n+            }\n+        });\n+        return taskHandle;\n+    }\n+\n+    public void start(List<TaskSource> sources)\n+    {\n+        requireNonNull(sources, \"sources is null\");\n+\n+        scheduleDriversForTaskLifeCycle();\n+        scheduleDriversForSplitLifeCycle(sources);\n+        checkTaskCompletion();\n+    }\n+\n+    private void scheduleDriversForTaskLifeCycle()\n+    {\n+        List<DriverSplitRunner> runners = new ArrayList<>();\n+        for (DriverSplitRunnerFactory driverRunnerFactory : driverRunnerFactoriesWithTaskLifeCycle) {\n+            for (int i = 0; i < driverRunnerFactory.getDriverInstances().orElse(1); i++) {\n+                runners.add(driverRunnerFactory.createDriverRunner(null));\n+            }\n+        }\n+        enqueueDriverSplitRunner(true, runners);\n+        for (DriverSplitRunnerFactory driverRunnerFactory : driverRunnerFactoriesWithTaskLifeCycle) {\n+            driverRunnerFactory.noMoreDriverRunner();\n+            verify(driverRunnerFactory.isNoMoreDriverRunner());\n+        }\n+    }\n+\n+    private synchronized void scheduleDriversForSplitLifeCycle(List<TaskSource> sources)\n+    {\n+        checkArgument(sources.stream().allMatch(TaskSource::isNoMoreSplits), \"All task sources are expected to be final\");\n+\n+        Map<PlanNodeId, List<ScheduledSplit>> splits = sources.stream()\n+                .collect(groupingBy(\n+                        TaskSource::getPlanNodeId,\n+                        collectingAndThen(\n+                                mapping(TaskSource::getSplits, toImmutableList()),\n+                                s -> s.stream().flatMap(Set::stream).collect(toImmutableList()))));\n+\n+        for (PlanNodeId planNodeId : schedulingOrder) {\n+            DriverSplitRunnerFactory driverSplitRunnerFactory = driverRunnerFactoriesWithSplitLifeCycle.get(planNodeId);\n+            List<ScheduledSplit> planNodeSplits = splits.getOrDefault(planNodeId, ImmutableList.of());\n+            scheduleTableScanSource(driverSplitRunnerFactory, planNodeSplits);\n+        }\n+    }\n+\n+    private synchronized void scheduleTableScanSource(DriverSplitRunnerFactory factory, List<ScheduledSplit> splits)\n+    {\n+        factory.splitsAdded(splits.size());\n+\n+        // Enqueue driver runners with split lifecycle for this plan node and driver life cycle combination.\n+        ImmutableList.Builder<DriverSplitRunner> runners = ImmutableList.builder();\n+        for (ScheduledSplit scheduledSplit : splits) {\n+            // create a new driver for the split\n+            runners.add(factory.createDriverRunner(scheduledSplit));\n+        }\n+        enqueueDriverSplitRunner(false, runners.build());\n+\n+        factory.noMoreDriverRunner();\n+    }\n+\n+    private synchronized void enqueueDriverSplitRunner(boolean forceRunSplit, List<DriverSplitRunner> runners)\n+    {\n+        // schedule driver to be executed\n+        List<ListenableFuture<?>> finishedFutures = taskExecutor.enqueueSplits(taskHandle, forceRunSplit, runners);\n+        checkState(finishedFutures.size() == runners.size(), \"Expected %s futures but got %s\", runners.size(), finishedFutures.size());\n+\n+        // when driver completes, update state and fire events\n+        for (int i = 0; i < finishedFutures.size(); i++) {\n+            ListenableFuture<?> finishedFuture = finishedFutures.get(i);\n+            final DriverSplitRunner splitRunner = runners.get(i);\n+\n+            // record new driver\n+            remainingDrivers.incrementAndGet();\n+\n+            Futures.addCallback(finishedFuture, new FutureCallback<Object>()\n+            {\n+                @Override\n+                public void onSuccess(Object result)\n+                {\n+                    try (SetThreadName ignored = new SetThreadName(\"Task-%s\", taskId)) {\n+                        // record driver is finished\n+                        remainingDrivers.decrementAndGet();\n+\n+                        checkTaskCompletion();\n+\n+                        splitMonitor.splitCompletedEvent(taskId, getDriverStats());\n+                    }\n+                }\n+\n+                @Override\n+                public void onFailure(Throwable cause)\n+                {\n+                    try (SetThreadName ignored = new SetThreadName(\"Task-%s\", taskId)) {\n+                        taskStateMachine.failed(cause);\n+\n+                        // record driver is finished\n+                        remainingDrivers.decrementAndGet();\n+\n+                        // fire failed event with cause\n+                        splitMonitor.splitFailedEvent(taskId, getDriverStats(), cause);\n+                    }\n+                }\n+\n+                private DriverStats getDriverStats()\n+                {\n+                    DriverContext driverContext = splitRunner.getDriverContext();\n+                    DriverStats driverStats;\n+                    if (driverContext != null) {\n+                        driverStats = driverContext.getDriverStats();\n+                    }\n+                    else {\n+                        // split runner did not start successfully\n+                        driverStats = new DriverStats();\n+                    }\n+\n+                    return driverStats;\n+                }\n+            }, notificationExecutor);\n+        }\n+    }\n+\n+    private synchronized void checkTaskCompletion()\n+    {\n+        if (taskStateMachine.getState().isDone()) {\n+            return;\n+        }\n+\n+        // are there more partition splits expected?\n+        for (DriverSplitRunnerFactory driverSplitRunnerFactory : driverRunnerFactoriesWithSplitLifeCycle.values()) {\n+            if (!driverSplitRunnerFactory.isNoMoreDriverRunner()) {\n+                return;\n+            }\n+        }\n+        // do we still have running tasks?\n+        if (remainingDrivers.get() != 0) {\n+            return;\n+        }\n+\n+        // Cool! All done!\n+        taskStateMachine.finished();\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+        return toStringHelper(this)\n+                .add(\"taskId\", taskId)\n+                .add(\"remainingDrivers\", remainingDrivers.get())\n+                .toString();\n+    }\n+\n+    private class DriverSplitRunnerFactory\n+    {\n+        private final DriverFactory driverFactory;\n+        private final PipelineContext pipelineContext;\n+\n+        private final AtomicInteger pendingCreation = new AtomicInteger();\n+        private final AtomicBoolean noMoreDriverRunner = new AtomicBoolean();\n+        private boolean closed;\n+\n+        private DriverSplitRunnerFactory(DriverFactory driverFactory, boolean partitioned)\n+        {\n+            this.driverFactory = requireNonNull(driverFactory, \"driverFactory is null\");\n+            this.pipelineContext = taskContext.addPipelineContext(driverFactory.getPipelineId(), driverFactory.isInputDriver(), driverFactory.isOutputDriver(), partitioned);\n+        }\n+\n+        public DriverSplitRunner createDriverRunner(@Nullable ScheduledSplit partitionedSplit)\n+        {\n+            checkState(!noMoreDriverRunner.get(), \"Cannot create driver for pipeline: %s\", pipelineContext.getPipelineId());\n+            pendingCreation.incrementAndGet();\n+            // create driver context immediately so the driver existence is recorded in the stats\n+            // the number of drivers is used to balance work across nodes\n+            DriverContext driverContext = pipelineContext.addDriverContext(Lifespan.taskWide());\n+            return new DriverSplitRunner(this, driverContext, partitionedSplit);\n+        }\n+\n+        public Driver createDriver(DriverContext driverContext, @Nullable ScheduledSplit partitionedSplit)\n+        {\n+            Driver driver = driverFactory.createDriver(driverContext);\n+\n+            if (partitionedSplit != null) {\n+                // TableScanOperator requires partitioned split to be added before the first call to process\n+                driver.updateSource(new TaskSource(partitionedSplit.getPlanNodeId(), ImmutableSet.of(partitionedSplit), true));\n+            }\n+\n+            verify(pendingCreation.get() > 0, \"pendingCreation is expected to be greater than zero\");\n+            pendingCreation.decrementAndGet();\n+\n+            closeDriverFactoryIfFullyCreated();\n+\n+            return driver;\n+        }\n+\n+        public void noMoreDriverRunner()\n+        {\n+            if (noMoreDriverRunner.get()) {\n+                return;\n+            }\n+            noMoreDriverRunner.set(true);\n+            closeDriverFactoryIfFullyCreated();\n+        }\n+\n+        public boolean isNoMoreDriverRunner()\n+        {\n+            return noMoreDriverRunner.get();\n+        }\n+\n+        public void closeDriverFactoryIfFullyCreated()\n+        {\n+            if (closed) {\n+                return;\n+            }\n+            if (isNoMoreDriverRunner() && pendingCreation.get() == 0) {\n+                driverFactory.noMoreDrivers(Lifespan.taskWide());\n+                driverFactory.noMoreDrivers();\n+                closed = true;", "originalCommit": "a26ba8d7d1ff28510647043d2372676f97ce8bdf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzMzMDk4NQ==", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r433330985", "bodyText": "Probably to avoid calling noMoreDrivers more than once. I moved it from the SqlTaskExecution. I wonder if some  DriferFactory can rely on that. I just realized that having a simple boolean might not be thread safe. Replaced with AtomicBoolean", "author": "arhimondr", "createdAt": "2020-06-01T15:57:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzA1NjEyMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzY1MzE4NA==", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r433653184", "bodyText": "@arhimondr I see. This is added in the grouped execution commit : 4e55aad . closed doesn't exist prior to it:\n\n  \n    \n      presto/presto-main/src/main/java/com/facebook/presto/execution/SqlTaskExecution.java\n    \n    \n        Lines 534 to 539\n      in\n      0309ca4\n    \n    \n    \n    \n\n        \n          \n           private void closeDriverFactoryIfFullyCreated() \n        \n\n        \n          \n           { \n        \n\n        \n          \n               if (isNoMoreSplits() && pendingCreation.get() <= 0) { \n        \n\n        \n          \n                   driverFactory.noMoreDrivers(); \n        \n\n        \n          \n               } \n        \n\n        \n          \n           } \n        \n    \n  \n\n\nSo probably a safe mechanism added for grouped execution, since noMoreDrivers now need to be called both for lifespan and overall...", "author": "wenleix", "createdAt": "2020-06-02T06:43:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzA1NjEyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzA1NjUxOQ==", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r433056519", "bodyText": "nit: Why this method and createDriver has to be public? :)", "author": "wenleix", "createdAt": "2020-06-01T06:05:38Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkTaskExecution.java", "diffHunk": "@@ -0,0 +1,471 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.airlift.concurrent.SetThreadName;\n+import com.facebook.presto.event.SplitMonitor;\n+import com.facebook.presto.execution.Lifespan;\n+import com.facebook.presto.execution.ScheduledSplit;\n+import com.facebook.presto.execution.SplitRunner;\n+import com.facebook.presto.execution.TaskId;\n+import com.facebook.presto.execution.TaskSource;\n+import com.facebook.presto.execution.TaskStateMachine;\n+import com.facebook.presto.execution.executor.TaskExecutor;\n+import com.facebook.presto.execution.executor.TaskHandle;\n+import com.facebook.presto.operator.Driver;\n+import com.facebook.presto.operator.DriverContext;\n+import com.facebook.presto.operator.DriverFactory;\n+import com.facebook.presto.operator.DriverStats;\n+import com.facebook.presto.operator.PipelineContext;\n+import com.facebook.presto.operator.TaskContext;\n+import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.sql.planner.LocalExecutionPlanner.LocalExecutionPlan;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+import com.google.common.util.concurrent.FutureCallback;\n+import com.google.common.util.concurrent.Futures;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import io.airlift.units.Duration;\n+\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.Set;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import static com.facebook.presto.SystemSessionProperties.getInitialSplitsPerNode;\n+import static com.facebook.presto.SystemSessionProperties.getMaxDriversPerTask;\n+import static com.facebook.presto.SystemSessionProperties.getSplitConcurrencyAdjustmentInterval;\n+import static com.facebook.presto.operator.PipelineExecutionStrategy.UNGROUPED_EXECUTION;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.stream.Collectors.collectingAndThen;\n+import static java.util.stream.Collectors.groupingBy;\n+import static java.util.stream.Collectors.mapping;\n+\n+/**\n+ * The PrestoSparkTaskExecution is a simplified version of SqlTaskExecution.\n+ * It doesn't support grouped execution that is not needed on Presto on Spark.\n+ * Unlike the SqlTaskExecution the PrestoSparkTaskExecution does not require\n+ * the output buffer to be drained to mark the task as finished. As long as\n+ * all driver as finished the task execution is marked as finished. That allows to\n+ * have more control over the output Iterator lifecycle in the PrestoSparkTaskExecutor\n+ */\n+public class PrestoSparkTaskExecution\n+{\n+    private final TaskId taskId;\n+    private final TaskStateMachine taskStateMachine;\n+    private final TaskContext taskContext;\n+\n+    private final TaskHandle taskHandle;\n+    private final TaskExecutor taskExecutor;\n+\n+    private final Executor notificationExecutor;\n+\n+    private final SplitMonitor splitMonitor;\n+\n+    private final List<PlanNodeId> schedulingOrder;\n+    private final Map<PlanNodeId, DriverSplitRunnerFactory> driverRunnerFactoriesWithSplitLifeCycle;\n+    private final List<DriverSplitRunnerFactory> driverRunnerFactoriesWithTaskLifeCycle;\n+\n+    private final AtomicInteger remainingDrivers = new AtomicInteger();\n+\n+    public PrestoSparkTaskExecution(\n+            TaskStateMachine taskStateMachine,\n+            TaskContext taskContext,\n+            LocalExecutionPlan localExecutionPlan,\n+            TaskExecutor taskExecutor,\n+            SplitMonitor splitMonitor,\n+            Executor notificationExecutor)\n+    {\n+        this.taskStateMachine = requireNonNull(taskStateMachine, \"taskStateMachine is null\");\n+        this.taskId = taskStateMachine.getTaskId();\n+        this.taskContext = requireNonNull(taskContext, \"taskContext is null\");\n+\n+        this.taskExecutor = requireNonNull(taskExecutor, \"driverExecutor is null\");\n+        this.notificationExecutor = requireNonNull(notificationExecutor, \"notificationExecutor is null\");\n+\n+        this.splitMonitor = requireNonNull(splitMonitor, \"splitMonitor is null\");\n+\n+        // index driver factories\n+        schedulingOrder = localExecutionPlan.getTableScanSourceOrder();\n+        Set<PlanNodeId> tableScanSources = ImmutableSet.copyOf(schedulingOrder);\n+        ImmutableMap.Builder<PlanNodeId, DriverSplitRunnerFactory> driverRunnerFactoriesWithSplitLifeCycle = ImmutableMap.builder();\n+        ImmutableList.Builder<DriverSplitRunnerFactory> driverRunnerFactoriesWithTaskLifeCycle = ImmutableList.builder();\n+        for (DriverFactory driverFactory : localExecutionPlan.getDriverFactories()) {\n+            Optional<PlanNodeId> sourceId = driverFactory.getSourceId();\n+            if (sourceId.isPresent() && tableScanSources.contains(sourceId.get())) {\n+                driverRunnerFactoriesWithSplitLifeCycle.put(sourceId.get(), new DriverSplitRunnerFactory(driverFactory, true));\n+            }\n+            else {\n+                checkArgument(\n+                        driverFactory.getPipelineExecutionStrategy() == UNGROUPED_EXECUTION,\n+                        \"unexpected pipeline execution strategy: %s\",\n+                        driverFactory.getPipelineExecutionStrategy());\n+                driverRunnerFactoriesWithTaskLifeCycle.add(new DriverSplitRunnerFactory(driverFactory, false));\n+            }\n+        }\n+        this.driverRunnerFactoriesWithSplitLifeCycle = driverRunnerFactoriesWithSplitLifeCycle.build();\n+        this.driverRunnerFactoriesWithTaskLifeCycle = driverRunnerFactoriesWithTaskLifeCycle.build();\n+\n+        checkArgument(this.driverRunnerFactoriesWithSplitLifeCycle.keySet().equals(tableScanSources),\n+                \"Fragment is partitioned, but not all partitioned drivers were found\");\n+\n+        taskHandle = createTaskHandle(taskStateMachine, taskContext, localExecutionPlan, taskExecutor);\n+    }\n+\n+    // this is a separate method to ensure that the `this` reference is not leaked during construction\n+    private static TaskHandle createTaskHandle(\n+            TaskStateMachine taskStateMachine,\n+            TaskContext taskContext,\n+            LocalExecutionPlan localExecutionPlan,\n+            TaskExecutor taskExecutor)\n+    {\n+        TaskHandle taskHandle = taskExecutor.addTask(\n+                taskStateMachine.getTaskId(),\n+                () -> 0,\n+                getInitialSplitsPerNode(taskContext.getSession()),\n+                getSplitConcurrencyAdjustmentInterval(taskContext.getSession()),\n+                getMaxDriversPerTask(taskContext.getSession()));\n+        taskStateMachine.addStateChangeListener(state -> {\n+            if (state.isDone()) {\n+                taskExecutor.removeTask(taskHandle);\n+                for (DriverFactory factory : localExecutionPlan.getDriverFactories()) {\n+                    factory.noMoreDrivers();\n+                }\n+            }\n+        });\n+        return taskHandle;\n+    }\n+\n+    public void start(List<TaskSource> sources)\n+    {\n+        requireNonNull(sources, \"sources is null\");\n+\n+        scheduleDriversForTaskLifeCycle();\n+        scheduleDriversForSplitLifeCycle(sources);\n+        checkTaskCompletion();\n+    }\n+\n+    private void scheduleDriversForTaskLifeCycle()\n+    {\n+        List<DriverSplitRunner> runners = new ArrayList<>();\n+        for (DriverSplitRunnerFactory driverRunnerFactory : driverRunnerFactoriesWithTaskLifeCycle) {\n+            for (int i = 0; i < driverRunnerFactory.getDriverInstances().orElse(1); i++) {\n+                runners.add(driverRunnerFactory.createDriverRunner(null));\n+            }\n+        }\n+        enqueueDriverSplitRunner(true, runners);\n+        for (DriverSplitRunnerFactory driverRunnerFactory : driverRunnerFactoriesWithTaskLifeCycle) {\n+            driverRunnerFactory.noMoreDriverRunner();\n+            verify(driverRunnerFactory.isNoMoreDriverRunner());\n+        }\n+    }\n+\n+    private synchronized void scheduleDriversForSplitLifeCycle(List<TaskSource> sources)\n+    {\n+        checkArgument(sources.stream().allMatch(TaskSource::isNoMoreSplits), \"All task sources are expected to be final\");\n+\n+        Map<PlanNodeId, List<ScheduledSplit>> splits = sources.stream()\n+                .collect(groupingBy(\n+                        TaskSource::getPlanNodeId,\n+                        collectingAndThen(\n+                                mapping(TaskSource::getSplits, toImmutableList()),\n+                                s -> s.stream().flatMap(Set::stream).collect(toImmutableList()))));\n+\n+        for (PlanNodeId planNodeId : schedulingOrder) {\n+            DriverSplitRunnerFactory driverSplitRunnerFactory = driverRunnerFactoriesWithSplitLifeCycle.get(planNodeId);\n+            List<ScheduledSplit> planNodeSplits = splits.getOrDefault(planNodeId, ImmutableList.of());\n+            scheduleTableScanSource(driverSplitRunnerFactory, planNodeSplits);\n+        }\n+    }\n+\n+    private synchronized void scheduleTableScanSource(DriverSplitRunnerFactory factory, List<ScheduledSplit> splits)\n+    {\n+        factory.splitsAdded(splits.size());\n+\n+        // Enqueue driver runners with split lifecycle for this plan node and driver life cycle combination.\n+        ImmutableList.Builder<DriverSplitRunner> runners = ImmutableList.builder();\n+        for (ScheduledSplit scheduledSplit : splits) {\n+            // create a new driver for the split\n+            runners.add(factory.createDriverRunner(scheduledSplit));\n+        }\n+        enqueueDriverSplitRunner(false, runners.build());\n+\n+        factory.noMoreDriverRunner();\n+    }\n+\n+    private synchronized void enqueueDriverSplitRunner(boolean forceRunSplit, List<DriverSplitRunner> runners)\n+    {\n+        // schedule driver to be executed\n+        List<ListenableFuture<?>> finishedFutures = taskExecutor.enqueueSplits(taskHandle, forceRunSplit, runners);\n+        checkState(finishedFutures.size() == runners.size(), \"Expected %s futures but got %s\", runners.size(), finishedFutures.size());\n+\n+        // when driver completes, update state and fire events\n+        for (int i = 0; i < finishedFutures.size(); i++) {\n+            ListenableFuture<?> finishedFuture = finishedFutures.get(i);\n+            final DriverSplitRunner splitRunner = runners.get(i);\n+\n+            // record new driver\n+            remainingDrivers.incrementAndGet();\n+\n+            Futures.addCallback(finishedFuture, new FutureCallback<Object>()\n+            {\n+                @Override\n+                public void onSuccess(Object result)\n+                {\n+                    try (SetThreadName ignored = new SetThreadName(\"Task-%s\", taskId)) {\n+                        // record driver is finished\n+                        remainingDrivers.decrementAndGet();\n+\n+                        checkTaskCompletion();\n+\n+                        splitMonitor.splitCompletedEvent(taskId, getDriverStats());\n+                    }\n+                }\n+\n+                @Override\n+                public void onFailure(Throwable cause)\n+                {\n+                    try (SetThreadName ignored = new SetThreadName(\"Task-%s\", taskId)) {\n+                        taskStateMachine.failed(cause);\n+\n+                        // record driver is finished\n+                        remainingDrivers.decrementAndGet();\n+\n+                        // fire failed event with cause\n+                        splitMonitor.splitFailedEvent(taskId, getDriverStats(), cause);\n+                    }\n+                }\n+\n+                private DriverStats getDriverStats()\n+                {\n+                    DriverContext driverContext = splitRunner.getDriverContext();\n+                    DriverStats driverStats;\n+                    if (driverContext != null) {\n+                        driverStats = driverContext.getDriverStats();\n+                    }\n+                    else {\n+                        // split runner did not start successfully\n+                        driverStats = new DriverStats();\n+                    }\n+\n+                    return driverStats;\n+                }\n+            }, notificationExecutor);\n+        }\n+    }\n+\n+    private synchronized void checkTaskCompletion()\n+    {\n+        if (taskStateMachine.getState().isDone()) {\n+            return;\n+        }\n+\n+        // are there more partition splits expected?\n+        for (DriverSplitRunnerFactory driverSplitRunnerFactory : driverRunnerFactoriesWithSplitLifeCycle.values()) {\n+            if (!driverSplitRunnerFactory.isNoMoreDriverRunner()) {\n+                return;\n+            }\n+        }\n+        // do we still have running tasks?\n+        if (remainingDrivers.get() != 0) {\n+            return;\n+        }\n+\n+        // Cool! All done!\n+        taskStateMachine.finished();\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+        return toStringHelper(this)\n+                .add(\"taskId\", taskId)\n+                .add(\"remainingDrivers\", remainingDrivers.get())\n+                .toString();\n+    }\n+\n+    private class DriverSplitRunnerFactory\n+    {\n+        private final DriverFactory driverFactory;\n+        private final PipelineContext pipelineContext;\n+\n+        private final AtomicInteger pendingCreation = new AtomicInteger();\n+        private final AtomicBoolean noMoreDriverRunner = new AtomicBoolean();\n+        private boolean closed;\n+\n+        private DriverSplitRunnerFactory(DriverFactory driverFactory, boolean partitioned)\n+        {\n+            this.driverFactory = requireNonNull(driverFactory, \"driverFactory is null\");\n+            this.pipelineContext = taskContext.addPipelineContext(driverFactory.getPipelineId(), driverFactory.isInputDriver(), driverFactory.isOutputDriver(), partitioned);\n+        }\n+\n+        public DriverSplitRunner createDriverRunner(@Nullable ScheduledSplit partitionedSplit)", "originalCommit": "a26ba8d7d1ff28510647043d2372676f97ce8bdf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzMzMjQwMw==", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r433332403", "bodyText": "That's usually a convention we are trying to maintain in the codebase. The encapsulation of the inner class is enforced by the private modifier on the class level. public modifiers on it's method usually indicate that the method is called from outside the inner class by the outer class. Too bad the Java compiler doesn't enforce it, and allows private inner class methods to be called from the outer class breaking the encapsulation.", "author": "arhimondr", "createdAt": "2020-06-01T16:00:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzA1NjUxOQ=="}], "type": "inlineReview"}, {"oid": "a9ebfee096752c9ebee7d347320ff58870345a20", "url": "https://github.com/prestodb/presto/commit/a9ebfee096752c9ebee7d347320ff58870345a20", "message": "Implement presto like threading model for Presto on Spark", "committedDate": "2020-06-01T16:19:02Z", "type": "commit"}, {"oid": "4b890917767e9c069de83082aa3d2c083a1fe4f0", "url": "https://github.com/prestodb/presto/commit/4b890917767e9c069de83082aa3d2c083a1fe4f0", "message": "Decrease lock contention in PrestoSparkRowBuffer", "committedDate": "2020-06-01T16:19:02Z", "type": "commit"}, {"oid": "4b890917767e9c069de83082aa3d2c083a1fe4f0", "url": "https://github.com/prestodb/presto/commit/4b890917767e9c069de83082aa3d2c083a1fe4f0", "message": "Decrease lock contention in PrestoSparkRowBuffer", "committedDate": "2020-06-01T16:19:02Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzY1NjY3MA==", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r433656670", "bodyText": "nit: Any reason why defer the creation of ImmutableList.Builder to appendRow? Because I would personally eagerly create the new ImmutableList.Builder here.", "author": "wenleix", "createdAt": "2020-06-02T06:51:16Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputOperator.java", "diffHunk": "@@ -285,9 +313,38 @@ public Page getOutput()\n     @Override\n     public void finish()\n     {\n+        flush();\n+        updateMemoryContext();\n         finished = true;\n     }\n \n+    private void flush()\n+    {\n+        if (currentBatchSize > 0) {\n+            verify(currentBatch != null);\n+            // Uses currentBatch internally. Must be called before currentBatch is set to null.\n+            int rowsListRetainedSize = getCurrentBatchRetainedBytes();\n+            List<PrestoSparkRow> rowsList = currentBatch.build();\n+            BufferedRows bufferedRows = new BufferedRows(rowsList, rowsListRetainedSize);\n+            rowBuffer.enqueue(bufferedRows);\n+            currentBatch = null;", "originalCommit": "4b890917767e9c069de83082aa3d2c083a1fe4f0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzk2ODExMw==", "url": "https://github.com/prestodb/presto/pull/14522#discussion_r433968113", "bodyText": "Just in case no more rows will be appended, it saves an allocation. No big difference though.", "author": "arhimondr", "createdAt": "2020-06-02T15:33:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzY1NjY3MA=="}], "type": "inlineReview"}]}