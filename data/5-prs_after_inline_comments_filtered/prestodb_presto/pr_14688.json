{"pr_number": 14688, "pr_title": "Fix estimated serialized size for BlockEncodingBuffers", "pr_createdAt": "2020-06-21T08:36:30Z", "pr_url": "https://github.com/prestodb/presto/pull/14688", "timeline": [{"oid": "1a8424f345a6dcec0108d862d5bd5de93446a811", "url": "https://github.com/prestodb/presto/commit/1a8424f345a6dcec0108d862d5bd5de93446a811", "message": "Break long lines in decodeBlock()", "committedDate": "2020-06-22T02:48:05Z", "type": "forcePushed"}, {"oid": "71ce03c9a501ed7af075ba504cb79b3cfe84477d", "url": "https://github.com/prestodb/presto/commit/71ce03c9a501ed7af075ba504cb79b3cfe84477d", "message": "Allow additional error margin for estimatedMaxCapacity\n\nIn \"Enforce buffer size limits for BlockEncodingBuffer\" we introduced\nestimatedMaxCapacity such that the growth of the buffers beyond that\nvalue become slower. However the estimated max capacity is not always\n100% accurate, and an underestimated value has negative impact on the\nCPU performance. This commit gives the estimatedMaxCapacity some head\nroom by introducing a graceFactorFordMaxCapacity with default value\n1.2f.", "committedDate": "2020-06-30T09:54:00Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYyNDM3Ng==", "url": "https://github.com/prestodb/presto/pull/14688#discussion_r447624376", "bodyText": "What's the motivation to have the default implementation? It seems incorrect to report region-size as region-logical-size.", "author": "mbasmanova", "createdAt": "2020-06-30T11:54:35Z", "path": "presto-common/src/main/java/com/facebook/presto/common/block/Block.java", "diffHunk": "@@ -205,6 +205,15 @@ default long getLogicalSizeInBytes()\n      */\n     long getRegionSizeInBytes(int position, int length);\n \n+    /**\n+     * Returns the size of {@code block.getRegion(position, length)}.\n+     * The method can be expensive. Do not use it outside an implementation of Block.\n+     */\n+    default long getRegionLogicalSizeInBytes(int position, int length)", "originalCommit": "ee04597d09e6711414eb27ea0c534e322d1eaf33", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODA3ODMzNQ==", "url": "https://github.com/prestodb/presto/pull/14688#discussion_r448078335", "bodyText": "@mbasmanova For leaf blocks (ie. non Array/Map/Row/Dict/RLE blocks), the logicalSizeInBytes is the same as sizeInBytes. See the following code:\n/**\n     * Returns the size of the block contents, regardless of internal representation.\n     * The same logical data values should always have the same size, no matter\n     * what block type is used or how they are represented within a specific block.\n     *\n     * This can differ substantially from {@link #getSizeInBytes} for certain block\n     * types. For RLE, it will be {@code N} times larger. For dictionary, it will be\n     * larger based on how many times dictionary entries are reused.\n     */\n    default long getLogicalSizeInBytes()\n    {\n        return getSizeInBytes();\n    }\n\nSimilarly, regional logical size for leaf blocks is the same as the regional size. We have default implementation here so that we don't have to implement the same thing for all leaf blocks.", "author": "yingsu00", "createdAt": "2020-07-01T02:17:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYyNDM3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYyNzM5Ng==", "url": "https://github.com/prestodb/presto/pull/14688#discussion_r447627396", "bodyText": "This loop is duplicated between here and getRegionLogicalSizeInBytes. Consider refactoring to avoid copy-paste.\npublic long getLogicalSizeInBytes() {\n   return getRegionLogicalSizeInBytes(0, getPositionCount());\n}\n\npublic long getRegionLogicalSizeInBytes(int positionOffset, int length) {\n   if (positionOffset == 0 && length == getPositionCount() && logicalSizeInBytes >= 0) {\n      return logicalSizeInBytes;\n   }\n\n   ...loop\n\n\n   if (positionOffset == 0 && length == getPositionCount()) {\n      logicalSizeInBytes = sizeInBytes;\n   }\n   return sizeInBytes;\n}\n}", "author": "mbasmanova", "createdAt": "2020-06-30T12:00:08Z", "path": "presto-common/src/main/java/com/facebook/presto/common/block/DictionaryBlock.java", "diffHunk": "@@ -248,7 +248,7 @@ public long getLogicalSizeInBytes()\n         for (int i = 0; i < getPositionCount(); i++) {\n             int position = getId(i);\n             if (seenSizes[position] < 0) {\n-                seenSizes[position] = dictionary.getRegionSizeInBytes(position, 1);\n+                seenSizes[position] = dictionary.getRegionLogicalSizeInBytes(position, 1);", "originalCommit": "ee04597d09e6711414eb27ea0c534e322d1eaf33", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYyOTAwMA==", "url": "https://github.com/prestodb/presto/pull/14688#discussion_r447629000", "bodyText": "consider replacing comments with variable names, e.g.\n\nBlock arrayOfLong =\nBlock arrayOfRleOfLong =\nBlock arrayOfRleOfArrayOfLong =\n...", "author": "mbasmanova", "createdAt": "2020-06-30T12:02:58Z", "path": "presto-main/src/test/java/com/facebook/presto/block/TestArrayBlock.java", "diffHunk": "@@ -158,6 +164,38 @@ public void testEstimatedDataSizeForStats()\n         }\n     }\n \n+    @Test\n+    public void testLogicalSizeInBytes()\n+    {\n+        int positionCount = 100;\n+        int[] offsets = IntStream.rangeClosed(0, positionCount).toArray();\n+        boolean[] nulls = new boolean[positionCount];\n+\n+        // Array(LongArrayBlock)", "originalCommit": "ee04597d09e6711414eb27ea0c534e322d1eaf33", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODgxNjk0OQ==", "url": "https://github.com/prestodb/presto/pull/14688#discussion_r448816949", "bodyText": "@mbasmanova I renamed the variables. However it's not as straightforward as the comment:\n// Row(Dictionary(LongArrayBlock), Dictionary(Row(LongArrayBlock, LongArrayBlock)))\nBlock rowOfDictionaryOfLongAndDictionaryOfRowOfLongAndLong = ...\n\nSo I kept both the comments and renamed variables.", "author": "yingsu00", "createdAt": "2020-07-02T07:56:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYyOTAwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYzMDAwMg==", "url": "https://github.com/prestodb/presto/pull/14688#discussion_r447630002", "bodyText": "all caps with underscores\nconsider making this configurable", "author": "mbasmanova", "createdAt": "2020-06-30T12:04:50Z", "path": "presto-array/src/main/java/com/facebook/presto/array/Arrays.java", "diffHunk": "@@ -24,6 +24,8 @@\n \n public class Arrays\n {\n+    private static final double graceFactorFordMaxCapacity = 1.2f;", "originalCommit": "71ce03c9a501ed7af075ba504cb79b3cfe84477d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk1MzMwOA==", "url": "https://github.com/prestodb/presto/pull/14688#discussion_r448953308", "bodyText": "@mbasmanova I will send a separate PR to make it configurable.", "author": "yingsu00", "createdAt": "2020-07-02T12:06:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYzMDAwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYzMTMwMg==", "url": "https://github.com/prestodb/presto/pull/14688#discussion_r447631302", "bodyText": "This is a generic method that can be used in many places. However, the commit says that the change applies only to one specific use case. I'd expect the caller to apply this new factor when computing estimatedMaxCapacity.\n\nuse Math.toIntExact instead of (int)", "author": "mbasmanova", "createdAt": "2020-06-30T12:07:03Z", "path": "presto-array/src/main/java/com/facebook/presto/array/Arrays.java", "diffHunk": "@@ -108,7 +110,7 @@ else if (buffer.length < capacity) {\n \n     public static byte[] ensureCapacity(byte[] buffer, int capacity, int estimatedMaxCapacity, ExpansionFactor expansionFactor, ExpansionOption expansionOption, ArrayAllocator allocator)\n     {\n-        int newCapacity = max(capacity, min((int) (capacity * expansionFactor.expansionFactor), estimatedMaxCapacity));\n+        int newCapacity = (int) max(capacity, min((int) (capacity * expansionFactor.expansionFactor), estimatedMaxCapacity * graceFactorFordMaxCapacity));", "originalCommit": "71ce03c9a501ed7af075ba504cb79b3cfe84477d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk1NDUxMQ==", "url": "https://github.com/prestodb/presto/pull/14688#discussion_r448954511", "bodyText": "This is a generic method that can be used in many places. However, the commit says that the change applies only to one specific use case. I'd expect the caller to apply this new factor when computing estimatedMaxCapacity.\n\nMoved the application of this new factor to setupDecodedBlockAndMapPositions() where the estimatedMaxCapacity is calculated.\n\n\nuse Math.toIntExact instead of (int)\n\n\nIt's actually casting double to int. toIntExact(long) only takes long.", "author": "yingsu00", "createdAt": "2020-07-02T12:09:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYzMTMwMg=="}], "type": "inlineReview"}, {"oid": "61f21f7f2c6b1a6dbdc242b1889b75bb91ddb30b", "url": "https://github.com/prestodb/presto/commit/61f21f7f2c6b1a6dbdc242b1889b75bb91ddb30b", "message": "Allow additional error margin for estimatedMaxCapacity\n\nIn \"Enforce buffer size limits for BlockEncodingBuffer\" we introduced\nestimatedMaxCapacity such that the growth of the buffers beyond that\nvalue become slower. However the estimated max capacity is not always\n100% accurate, and a underestimated value has negative impact on the\nCPU performance. This commit gives the estimatedMaxCapacity some head\nroom by introducing a GRACE_FACTOR_FOR_MAX_BUFFER_CAPACITY with\ndefault value 1.2f.", "committedDate": "2020-07-02T12:41:11Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAxNzc3MA==", "url": "https://github.com/prestodb/presto/pull/14688#discussion_r449017770", "bodyText": "nit: perhaps, refactor to extract a helper method to avoid copy-paste", "author": "mbasmanova", "createdAt": "2020-07-02T13:52:18Z", "path": "presto-main/src/main/java/com/facebook/presto/operator/repartition/ArrayBlockEncodingBuffer.java", "diffHunk": "@@ -239,8 +239,8 @@ protected void setupDecodedBlockAndMapPositions(DecodedBlockNode decodedBlockNod\n         double targetBufferSize = partitionBufferCapacity * decodedBlockPageSizeFraction *\n                 (estimatedSerializedSizeInBytes - childrenEstimatedSerializedSizeInBytes) / estimatedSerializedSizeInBytes;\n \n-        setEstimatedNullsBufferMaxCapacity((int) (targetBufferSize * Byte.BYTES / POSITION_SIZE));\n-        estimatedOffsetBufferMaxCapacity = (int) (targetBufferSize * Integer.BYTES / POSITION_SIZE);\n+        setEstimatedNullsBufferMaxCapacity((int) (targetBufferSize * Byte.BYTES / POSITION_SIZE * GRACE_FACTOR_FOR_MAX_BUFFER_CAPACITY));", "originalCommit": "61f21f7f2c6b1a6dbdc242b1889b75bb91ddb30b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTI3NzkxMA==", "url": "https://github.com/prestodb/presto/pull/14688#discussion_r449277910", "bodyText": "@mbasmanova did you mean something like this?\nsetEstimatedNullsBufferMaxCapacity(getEstimatedBufferMaxCapacity(targetBufferSize, Byte.BYTES, POSITION_SIZE));\nestimatedValueBufferMaxCapacity = getEstimatedBufferMaxCapacity(targetBufferSize, Byte.BYTES, POSITION_SIZE);\n\nand in AbstractBlockEncodingBuffer:\nprotected static int getEstimatedBufferMaxCapacity(double targetBufferSize, int unitSize, int positionSize)\n    {\n        return (int) (targetBufferSize * unitSize / positionSize * GRACE_FACTOR_FOR_MAX_BUFFER_CAPACITY);\n    }", "author": "yingsu00", "createdAt": "2020-07-02T21:39:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAxNzc3MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTI3OTQ0OA==", "url": "https://github.com/prestodb/presto/pull/14688#discussion_r449279448", "bodyText": "@yingsu00 Yes, this might reduce copy-paste and make it easier to read and ensure we don't forget GRACE_FACTOR_FOR_MAX_BUFFER_CAPACITY somewhere.", "author": "mbasmanova", "createdAt": "2020-07-02T21:43:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAxNzc3MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTMwMjM2Mg==", "url": "https://github.com/prestodb/presto/pull/14688#discussion_r449302362", "bodyText": "@mbasmanova Hi Masha, I just updated the PR with a new commit e8511df636 Refactor buffer max capacity calculation. Thank you again, and happy long weekend!", "author": "yingsu00", "createdAt": "2020-07-02T23:03:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAxNzc3MA=="}], "type": "inlineReview"}, {"oid": "e8511df6365f108d010d12d50b17e79bca23dadf", "url": "https://github.com/prestodb/presto/commit/e8511df6365f108d010d12d50b17e79bca23dadf", "message": "Refactor buffer max capacity calculation", "committedDate": "2020-07-02T23:02:09Z", "type": "forcePushed"}, {"oid": "2ee722bf73b74777e97855038a0b8f637f5271d8", "url": "https://github.com/prestodb/presto/commit/2ee722bf73b74777e97855038a0b8f637f5271d8", "message": "Fix serialized size estimation in BlockEncodingBuffers", "committedDate": "2020-07-04T09:13:04Z", "type": "commit"}, {"oid": "4df0d74df0e9c7035c6fb99e6aabd0de2b1bbbd0", "url": "https://github.com/prestodb/presto/commit/4df0d74df0e9c7035c6fb99e6aabd0de2b1bbbd0", "message": "Remove childrenEstimatedSerializedSizeInBytes from DecodedBlockNode", "committedDate": "2020-07-04T09:13:04Z", "type": "commit"}, {"oid": "772a2196a151d2001aba83ebce8f57d93c666ea1", "url": "https://github.com/prestodb/presto/commit/772a2196a151d2001aba83ebce8f57d93c666ea1", "message": "Fix getLogicalSizeInBytes() for Blocks\n\ngetLogicalSizeInBytes was supposed to get the deflated sizes of the\nblocks if they are DictionaryBlock or RunLengthEncodedBlock. However\nif the nested blocks are DictionaryBlock or RunLengthEncodedBlock,\nthe size was not correctly calculated. This commit fixed this issue.", "committedDate": "2020-07-04T09:13:04Z", "type": "commit"}, {"oid": "b2b31a74f261cac9178b6cb9aed8b7bfec2e0d19", "url": "https://github.com/prestodb/presto/commit/b2b31a74f261cac9178b6cb9aed8b7bfec2e0d19", "message": "Fix estimatedSerializedSizeInBytes for RLE and Dictionary Blocks\n\nWhen a block passed to OptimizedPartitionedOutputOperator is a RLE or\nDictionary block, we used to estimated the serialized size using\ngetLogicalSize() which returns the size of the block after inflation.\nHowever the child block of the RLE or Dictionary Block was using plain\nsizeInBytes without considering it is going to be expanded. This\ncommit fixes this problem by adding a scale factor to estimate how many\ntimes the child blocks are going to be expanded.", "committedDate": "2020-07-04T09:13:04Z", "type": "commit"}, {"oid": "7adb6a246121dd960d69d41bc3e1c51211263b63", "url": "https://github.com/prestodb/presto/commit/7adb6a246121dd960d69d41bc3e1c51211263b63", "message": "Add tests for max buffer capacity estimation", "committedDate": "2020-07-04T09:13:04Z", "type": "commit"}, {"oid": "36f2c8359f6c9b0dc0f3c7d7dbc76fbbae86d63f", "url": "https://github.com/prestodb/presto/commit/36f2c8359f6c9b0dc0f3c7d7dbc76fbbae86d63f", "message": "Always make space for nullsBuffer and hashTablesBuffer\n\nBlock.getSizeInBytes() and Block.getLogicalSizeInBytes() always adds up\nthe sizes of nulls buffer even if the block cannot contain nulls. When\nestimating the max buffer capacity for BlockEncodingBuffers, we can also\nleave the space for the nullsBuffer and hashTablesBuffer. This will not\nwaste memory because the buffers are not actually allocated until blocks\nwith nulls or hashtables come in. It will make the buffers sizes\nproportional to the blocks' logical sizes, and make the code cleaner.", "committedDate": "2020-07-04T09:13:04Z", "type": "commit"}, {"oid": "e033722c85d9dd91eea1314202c294ebc1b8c7f7", "url": "https://github.com/prestodb/presto/commit/e033722c85d9dd91eea1314202c294ebc1b8c7f7", "message": "Allow additional error margin for estimatedMaxCapacity\n\nIn \"Enforce buffer size limits for BlockEncodingBuffer\" we introduced\nestimatedMaxCapacity such that the growth of the buffers beyond that\nvalue become slower. However the estimated max capacity is not always\n100% accurate, and a underestimated value has negative impact on the\nCPU performance. This commit gives the estimatedMaxCapacity some head\nroom by introducing a GRACE_FACTOR_FOR_MAX_BUFFER_CAPACITY with\ndefault value 1.2f.", "committedDate": "2020-07-04T09:13:04Z", "type": "commit"}, {"oid": "533fd29ed4b6708d51808e2eeb5b6c44922e19a5", "url": "https://github.com/prestodb/presto/commit/533fd29ed4b6708d51808e2eeb5b6c44922e19a5", "message": "Refactor buffer max capacity calculation", "committedDate": "2020-07-04T09:13:04Z", "type": "commit"}, {"oid": "533fd29ed4b6708d51808e2eeb5b6c44922e19a5", "url": "https://github.com/prestodb/presto/commit/533fd29ed4b6708d51808e2eeb5b6c44922e19a5", "message": "Refactor buffer max capacity calculation", "committedDate": "2020-07-04T09:13:04Z", "type": "forcePushed"}]}