{"pr_number": 3994, "pr_title": "DB-9554 check for cancellation requests during long-running compactions.", "pr_createdAt": "2020-08-17T13:10:48Z", "pr_url": "https://github.com/splicemachine/spliceengine/pull/3994", "timeline": [{"oid": "d726b28d2527ad22df93cc172693ec3f88e4ae2f", "url": "https://github.com/splicemachine/spliceengine/commit/d726b28d2527ad22df93cc172693ec3f88e4ae2f", "message": "DB-9554 reactivate compaction-cancellation check.", "committedDate": "2020-08-14T15:45:02Z", "type": "commit"}, {"oid": "449de3e7b902426d2f6c0c94078453047ec74586", "url": "https://github.com/splicemachine/spliceengine/commit/449de3e7b902426d2f6c0c94078453047ec74586", "message": "DB-9554 refactoring", "committedDate": "2020-08-17T09:50:48Z", "type": "commit"}, {"oid": "72e21ccfbad8d51fc232bf72eb37f4425ad82bd7", "url": "https://github.com/splicemachine/spliceengine/commit/72e21ccfbad8d51fc232bf72eb37f4425ad82bd7", "message": "DB-9554 calculate size of input in SICompationState.\n\n- Size of input cells is calculated in SICompactionState and propagated\n  to upper layers.\n- SpliceDefaultCompactor checks if an AbstractSICompactionScanner is\n  used for actual compaction, if so, it queries it for the actual input\n  cells' size for more accurate compaction cancellation check.\n- Add test.", "committedDate": "2020-08-17T13:04:05Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTQ3Njc2Mg==", "url": "https://github.com/splicemachine/spliceengine/pull/3994#discussion_r471476762", "bodyText": "This might always return false when running in Spark, can you verify that?", "author": "dgomezferro", "createdAt": "2020-08-17T13:26:07Z", "path": "hbase_sql/src/main/java/com/splicemachine/compactions/SpliceDefaultCompactor.java", "diffHunk": "@@ -453,19 +458,20 @@ protected boolean performCompaction(Compactor.FileDetails fd, InternalScanner sc\n                 if (closeCheckInterval > 0) {\n                     bytesWritten += len;\n                     if (bytesWritten > closeCheckInterval) {\n-                        bytesWritten = 0;\n-//                        if (!store.areWritesEnabled()) {\n-//                            progress.cancel();\n-//                            return false;\n-//                        }\n+                        bytesWritten = 0; // reset so check whether cancellation is requested in the next\n+                                          // <closeCheckInterval>-bytes mark\n+                        if (!store.areWritesEnabled()) { // this call could be expensive.", "originalCommit": "72e21ccfbad8d51fc232bf72eb37f4425ad82bd7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTQ4NzMxMw==", "url": "https://github.com/splicemachine/spliceengine/pull/3994#discussion_r471487313", "bodyText": "Sure, I am on it.", "author": "hatyo", "createdAt": "2020-08-17T13:42:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTQ3Njc2Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTU3ODk4MA==", "url": "https://github.com/splicemachine/spliceengine/pull/3994#discussion_r471578980", "bodyText": "You're right, when performCompaction is called from Spark executor, the status of regions is always false causing compactions to be cancelled all the time.\nTo solve this, I am adding a isSpark flag that is set when running compactions from Spark, we use this flag to make sure we detect region status only when performCompaction is called from HBase and not Spark.\nThanks for the hint.", "author": "hatyo", "createdAt": "2020-08-17T15:59:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTQ3Njc2Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY0ODAzOA==", "url": "https://github.com/splicemachine/spliceengine/pull/3994#discussion_r471648038", "bodyText": "... I added a branch for Spark jobs, if task is interrupted we perform similar cancellation preventing Spark executors from pointlessly running the compaction job.", "author": "hatyo", "createdAt": "2020-08-17T17:29:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTQ3Njc2Mg=="}], "type": "inlineReview"}, {"oid": "b61f40d3154321bb8e13ac8fbdf4d98048e11612", "url": "https://github.com/splicemachine/spliceengine/commit/b61f40d3154321bb8e13ac8fbdf4d98048e11612", "message": "DB-9554 check compaction cancellation only when running in HBase.", "committedDate": "2020-08-17T16:05:57Z", "type": "commit"}, {"oid": "b61f40d3154321bb8e13ac8fbdf4d98048e11612", "url": "https://github.com/splicemachine/spliceengine/commit/b61f40d3154321bb8e13ac8fbdf4d98048e11612", "message": "DB-9554 check compaction cancellation only when running in HBase.", "committedDate": "2020-08-17T16:05:57Z", "type": "forcePushed"}, {"oid": "83877ab26dc125feedbac542d357f09c85298c4a", "url": "https://github.com/splicemachine/spliceengine/commit/83877ab26dc125feedbac542d357f09c85298c4a", "message": "DB-9554 add compaction cancellation checks to Spark jobs.", "committedDate": "2020-08-17T17:26:24Z", "type": "commit"}, {"oid": "6e4e353d8a9843856490ea7a5a35c5a383d479e5", "url": "https://github.com/splicemachine/spliceengine/commit/6e4e353d8a9843856490ea7a5a35c5a383d479e5", "message": "DB-9554 restructure cancellation logic.", "committedDate": "2020-08-17T18:21:23Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA0NzEzNA==", "url": "https://github.com/splicemachine/spliceengine/pull/3994#discussion_r472047134", "bodyText": "Setting isSpark here is redundant", "author": "arnaud-splice", "createdAt": "2020-08-18T09:33:48Z", "path": "hbase_sql/src/main/java/com/splicemachine/compactions/SpliceDefaultCompactor.java", "diffHunk": "@@ -115,14 +116,16 @@ public SpliceDefaultCompactor(final Configuration conf, final Store store, long\n     @SuppressFBWarnings(value=\"ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD\", justification=\"static attribute hostname is set from here\")\n     public List<Path> compact(CompactionRequestImpl request, ThroughputController throughputController, User user) throws IOException {\n         assert request instanceof SpliceCompactionRequest;\n+        SpliceCompactionRequest spliceRequest = (SpliceCompactionRequest)request;\n         // Used if we cannot compact in Spark\n-        ((SpliceCompactionRequest) request).setPurgeConfig(buildPurgeConfig(request));\n+        spliceRequest.setPurgeConfig(buildPurgeConfig(request));\n \n-        if(!allowSpark || store.getRegionInfo().getTable().isSystemTable())\n+        if(!allowSpark || store.getRegionInfo().getTable().isSystemTable()) {\n+            isSpark = false;", "originalCommit": "6e4e353d8a9843856490ea7a5a35c5a383d479e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjI4NzI5OQ==", "url": "https://github.com/splicemachine/spliceengine/pull/3994#discussion_r472287299", "bodyText": "Right, but I would still leave it there to protect against e.g. accidentally initializing the member variable to true", "author": "hatyo", "createdAt": "2020-08-18T15:31:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA0NzEzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA1MTIwNw==", "url": "https://github.com/splicemachine/spliceengine/pull/3994#discussion_r472051207", "bodyText": "Call to toString is redundant, isn't it?", "author": "arnaud-splice", "createdAt": "2020-08-18T09:40:48Z", "path": "hbase_sql/src/main/java/com/splicemachine/compactions/SpliceDefaultCompactor.java", "diffHunk": "@@ -453,19 +462,19 @@ protected boolean performCompaction(Compactor.FileDetails fd, InternalScanner sc\n                 if (closeCheckInterval > 0) {\n                     bytesWritten += len;\n                     if (bytesWritten > closeCheckInterval) {\n-                        bytesWritten = 0;\n-//                        if (!store.areWritesEnabled()) {\n-//                            progress.cancel();\n-//                            return false;\n-//                        }\n+                        bytesWritten = 0; // reset so check whether cancellation is requested in the next <closeCheckInterval>-bytes mark\n+                        if ((isSpark && TaskContext.get().isInterrupted()) || (!isSpark && !store.areWritesEnabled())) {\n+                            SpliceLogUtils.debug(LOG, \"Compaction cancelled\");\n+                            progress.cancel();\n+                            return false;\n+                        }\n                     }\n                 }\n             }\n-            // Log the progress of long running compactions every minute if\n-            // logging at DEBUG level\n+            // Log the progress of long-running compactions every minute if logging at DEBUG level\n             if (LOG.isDebugEnabled()) {\n                 if ((now - lastMillis) >= 60 * 1000) {\n-                    LOG.debug(\"Compaction progress: \" + progress + String.format(\", rate=%.2f kB/sec\",\n+                    LOG.debug(String.format(\"Compaction progress: %s, rate=%.2f kB/sec\", progress.toString(),", "originalCommit": "6e4e353d8a9843856490ea7a5a35c5a383d479e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjI5MjYwMA==", "url": "https://github.com/splicemachine/spliceengine/pull/3994#discussion_r472292600", "bodyText": "fixed.", "author": "hatyo", "createdAt": "2020-08-18T15:39:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA1MTIwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA1MTk4Ng==", "url": "https://github.com/splicemachine/spliceengine/pull/3994#discussion_r472051986", "bodyText": "I suggest renaming size to numberOfScannedBytes or something like this. The size of a scanner is a bit vague.", "author": "arnaud-splice", "createdAt": "2020-08-18T09:42:11Z", "path": "hbase_storage/src/main/java/com/splicemachine/si/impl/server/AbstractSICompactionScanner.java", "diffHunk": "@@ -107,6 +109,10 @@ public boolean next(List<Cell> list) throws IOException {\n         }\n     }\n \n+    public long getSize() {", "originalCommit": "6e4e353d8a9843856490ea7a5a35c5a383d479e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMyOTcxNQ==", "url": "https://github.com/splicemachine/spliceengine/pull/3994#discussion_r472329715", "bodyText": "done.", "author": "hatyo", "createdAt": "2020-08-18T16:35:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA1MTk4Ng=="}], "type": "inlineReview"}, {"oid": "952d6c2df34cc764be036af98978273dcb1248d5", "url": "https://github.com/splicemachine/spliceengine/commit/952d6c2df34cc764be036af98978273dcb1248d5", "message": "DB-9554 address comments.", "committedDate": "2020-08-18T15:40:12Z", "type": "commit"}, {"oid": "ab52a7c7aa4b854f33159f8174ed474fc9e77d83", "url": "https://github.com/splicemachine/spliceengine/commit/ab52a7c7aa4b854f33159f8174ed474fc9e77d83", "message": "Merge remote-tracking branch 'origin/master' into DB-9554", "committedDate": "2020-08-18T15:40:32Z", "type": "commit"}, {"oid": "8bf2f086e27b9927b4c454f7335e40b1cf549e5d", "url": "https://github.com/splicemachine/spliceengine/commit/8bf2f086e27b9927b4c454f7335e40b1cf549e5d", "message": "Merge remote-tracking branch 'origin/master' into DB-9554", "committedDate": "2020-08-18T16:31:01Z", "type": "commit"}, {"oid": "20018d795c975e2a923ad095832605afbfbbd8da", "url": "https://github.com/splicemachine/spliceengine/commit/20018d795c975e2a923ad095832605afbfbbd8da", "message": "Merge remote-tracking branch 'origin/master' into DB-9554", "committedDate": "2020-08-20T07:22:01Z", "type": "commit"}]}