{"pr_number": 3124, "pr_title": "DB-8883 Referencing clause for statement triggers.", "pr_createdAt": "2020-01-08T08:19:54Z", "pr_url": "https://github.com/splicemachine/spliceengine/pull/3124", "timeline": [{"oid": "06c38571e721c4f637f7c1d6c4775523b1794977", "url": "https://github.com/splicemachine/spliceengine/commit/06c38571e721c4f637f7c1d6c4775523b1794977", "message": "DB-8883 Referencing clause for statement triggers.", "committedDate": "2020-01-08T22:52:48Z", "type": "forcePushed"}, {"oid": "1ec5c205f87e1594cb339e276cdcf8b276623e34", "url": "https://github.com/splicemachine/spliceengine/commit/1ec5c205f87e1594cb339e276cdcf8b276623e34", "message": "DB-8883 Referencing clause for statement triggers.", "committedDate": "2020-01-08T23:27:13Z", "type": "forcePushed"}, {"oid": "f0a2e536e7f84f591d024d196cba88350b705634", "url": "https://github.com/splicemachine/spliceengine/commit/f0a2e536e7f84f591d024d196cba88350b705634", "message": "DB-8883 Use the proper TriggerExecutionContext in spawned threads.", "committedDate": "2020-01-16T19:08:49Z", "type": "forcePushed"}, {"oid": "fcd1f23244d112692bcfcf7180bfa69ea5dcaa38", "url": "https://github.com/splicemachine/spliceengine/commit/fcd1f23244d112692bcfcf7180bfa69ea5dcaa38", "message": "DB-8883 Referencing clause for statement triggers.", "committedDate": "2020-01-16T22:51:57Z", "type": "commit"}, {"oid": "ee100521d3ee0dfc21e6c53b87303b4446a23f88", "url": "https://github.com/splicemachine/spliceengine/commit/ee100521d3ee0dfc21e6c53b87303b4446a23f88", "message": "DB-8883 Fix comment.", "committedDate": "2020-01-16T22:51:57Z", "type": "commit"}, {"oid": "203935dce7626da0f61cb8c02d2f552f31491259", "url": "https://github.com/splicemachine/spliceengine/commit/203935dce7626da0f61cb8c02d2f552f31491259", "message": "DB-8883 Give nested loop join access to the TriggerExecutionContext.", "committedDate": "2020-01-16T22:51:57Z", "type": "commit"}, {"oid": "43ff782ca8baedcfecf11f992c12e79330cfcd86", "url": "https://github.com/splicemachine/spliceengine/commit/43ff782ca8baedcfecf11f992c12e79330cfcd86", "message": "DB-8883 Fix comment.", "committedDate": "2020-01-16T22:51:57Z", "type": "commit"}, {"oid": "8d41edd6902a097e8dfdee90416864f175912675", "url": "https://github.com/splicemachine/spliceengine/commit/8d41edd6902a097e8dfdee90416864f175912675", "message": "DB-8883 Fix ITs.", "committedDate": "2020-01-16T22:51:57Z", "type": "commit"}, {"oid": "2fe2cff5b99547253a70d64f49054101785fa0a6", "url": "https://github.com/splicemachine/spliceengine/commit/2fe2cff5b99547253a70d64f49054101785fa0a6", "message": "DB-8883 Fix trigger bugs involving spawned threads and missing AST visitors.", "committedDate": "2020-01-16T22:51:57Z", "type": "commit"}, {"oid": "3a5b2a2a40b693fd568fabc56032a7d1578041c5", "url": "https://github.com/splicemachine/spliceengine/commit/3a5b2a2a40b693fd568fabc56032a7d1578041c5", "message": "DB-8883 Fix SerDe bugs.", "committedDate": "2020-01-16T22:51:57Z", "type": "commit"}, {"oid": "da88b934b72d277ea243e39bb82fda4276a33fcb", "url": "https://github.com/splicemachine/spliceengine/commit/da88b934b72d277ea243e39bb82fda4276a33fcb", "message": "DB-8883 Fix ITs.", "committedDate": "2020-01-16T22:51:57Z", "type": "commit"}, {"oid": "01f8060e09f9744b04f54cca0f89c8173f61dd71", "url": "https://github.com/splicemachine/spliceengine/commit/01f8060e09f9744b04f54cca0f89c8173f61dd71", "message": "DB-8883 Use the proper TriggerExecutionContext in spawned threads.", "committedDate": "2020-01-16T22:51:57Z", "type": "commit"}, {"oid": "01f8060e09f9744b04f54cca0f89c8173f61dd71", "url": "https://github.com/splicemachine/spliceengine/commit/01f8060e09f9744b04f54cca0f89c8173f61dd71", "message": "DB-8883 Use the proper TriggerExecutionContext in spawned threads.", "committedDate": "2020-01-16T22:51:57Z", "type": "forcePushed"}, {"oid": "2aa80e892d4f0585172e3ce1470b5faf022a2471", "url": "https://github.com/splicemachine/spliceengine/commit/2aa80e892d4f0585172e3ce1470b5faf022a2471", "message": "DB-8106 Concurrent read-only row triggers.", "committedDate": "2020-01-20T17:07:22Z", "type": "commit"}, {"oid": "835adcf71ec50c2b82e1278fd7dbe81f19bb0bf8", "url": "https://github.com/splicemachine/spliceengine/commit/835adcf71ec50c2b82e1278fd7dbe81f19bb0bf8", "message": "DB-8106 Fix statement triggers bug.", "committedDate": "2020-01-20T17:07:40Z", "type": "commit"}, {"oid": "7855ea83a3fba64c15490bebcfc31836c4d28074", "url": "https://github.com/splicemachine/spliceengine/commit/7855ea83a3fba64c15490bebcfc31836c4d28074", "message": "DB-8106 Fix SET statement and concurrency bugs.", "committedDate": "2020-01-21T06:58:26Z", "type": "commit"}, {"oid": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11", "url": "https://github.com/splicemachine/spliceengine/commit/4c9402f38993f2a9e622a0d4ec7562c84f69fa11", "message": "DB-8883 Fix mem leak and bad username in LCC.", "committedDate": "2020-01-22T09:46:38Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA5MzIzMw==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370093233", "bodyText": "Why?\nIt seems that this cannot happen", "author": "arnaud-splice", "createdAt": "2020-01-23T12:37:58Z", "path": "db-engine/src/main/java/com/splicemachine/db/impl/sql/compile/DMLStatementNode.java", "diffHunk": "@@ -392,7 +392,7 @@ void generateParameterValueSet(ActivationClassBuilder acb) throws StandardExcept\n         Vector parameterList = getCompilerContext().getParameterList();\n         int numberOfParameters = (parameterList == null) ? 0 : parameterList.size();\n \n-        if (numberOfParameters <= 0)\n+        if (numberOfParameters < 0)", "originalCommit": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTA3MDcwNQ==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r371070705", "bodyText": "I want generateParameterValueSet to get called even when numberOfParameters is zero.  I can remove the if statement.", "author": "msirek", "createdAt": "2020-01-27T05:46:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA5MzIzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTM4MDYxOA==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r371380618", "bodyText": "the way numberOfParameters is calculated, it seems that we will never enter the if indeed, so let's remove it.", "author": "arnaud-splice", "createdAt": "2020-01-27T17:33:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA5MzIzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA5NDUzNg==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370094536", "bodyText": "Similarly, this would probably always be true.\nEither something is weird here, or we want to remove the if and add an assert numberOfParameters >= 0", "author": "arnaud-splice", "createdAt": "2020-01-23T12:41:04Z", "path": "db-engine/src/main/java/com/splicemachine/db/impl/sql/compile/ParameterNode.java", "diffHunk": "@@ -426,15 +426,15 @@ static public\tvoid generateParameterValueSet(ExpressionClassBuilder\tacb,\n \t\t\t\t\t\t\t\t   Vector\tparameterList)\n \t\tthrows StandardException\n \t{\n-\t\tif (numberOfParameters > 0)\n+\t\tif (numberOfParameters >= 0)", "originalCommit": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTA3MDg5MQ==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r371070891", "bodyText": "Changed the if into an assert.", "author": "msirek", "createdAt": "2020-01-27T05:47:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA5NDUzNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA5NjA3OA==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370096078", "bodyText": "hasReturnParam = numberOfParameters > 0 && ....isReturnOutputParam();", "author": "arnaud-splice", "createdAt": "2020-01-23T12:45:00Z", "path": "db-engine/src/main/java/com/splicemachine/db/impl/sql/compile/ParameterNode.java", "diffHunk": "@@ -426,15 +426,15 @@ static public\tvoid generateParameterValueSet(ExpressionClassBuilder\tacb,\n \t\t\t\t\t\t\t\t   Vector\tparameterList)\n \t\tthrows StandardException\n \t{\n-\t\tif (numberOfParameters > 0)\n+\t\tif (numberOfParameters >= 0)\n \t\t{\n \t\t\tMethodBuilder\tconstructor = acb.getConstructor();\n \n \t\t\t/*\n \t\t\t** Check the first parameter to see if it is a return\n \t\t\t** parameter.\n \t\t\t*/\n-\t\t\tboolean hasReturnParam = ((ParameterNode)parameterList.get(0)).isReturnOutputParam();\n+\t\t\tboolean hasReturnParam = numberOfParameters > 0 ? ((ParameterNode)parameterList.get(0)).isReturnOutputParam() : false;", "originalCommit": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTA3MTE4NQ==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r371071185", "bodyText": "Made the change.", "author": "msirek", "createdAt": "2020-01-27T05:49:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA5NjA3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA5NzE1Nw==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370097157", "bodyText": "Why can triggerStack now be overwritten?", "author": "arnaud-splice", "createdAt": "2020-01-23T12:47:34Z", "path": "db-engine/src/main/java/com/splicemachine/db/impl/sql/conn/GenericLanguageConnectionContext.java", "diffHunk": "@@ -3636,9 +3636,6 @@ public void enterRestoreMode(){\n \n     @Override\n     public void setTriggerStack(TriggerExecutionStack triggerStack){\n-        if(this.triggerStack!=null){", "originalCommit": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTA3NDIxMQ==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r371074211", "bodyText": "I was seeing old LanguageConnectionContexts getting saved in the ConextManager and reused with a previous version of the code.  I will restore this sanity check and re-run tests.", "author": "msirek", "createdAt": "2020-01-27T06:10:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA5NzE1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEwNTY0MA==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370105640", "bodyText": "All those acronyms make the code quite hard to read.\nI think they are fine to use in a small scope such as an inner loop, but should be avoided for class attributes.", "author": "arnaud-splice", "createdAt": "2020-01-23T13:07:08Z", "path": "db-engine/src/main/java/com/splicemachine/db/impl/sql/execute/TriggerEventActivator.java", "diffHunk": "@@ -31,49 +31,69 @@\n \n package com.splicemachine.db.impl.sql.execute;\n \n-import java.util.ArrayList;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Vector;\n-\n import com.splicemachine.db.catalog.UUID;\n import com.splicemachine.db.iapi.error.StandardException;\n+import com.splicemachine.db.iapi.jdbc.ConnectionContext;\n+import com.splicemachine.db.iapi.services.context.ContextService;\n import com.splicemachine.db.iapi.services.io.FormatableBitSet;\n import com.splicemachine.db.iapi.sql.Activation;\n+import com.splicemachine.db.iapi.sql.conn.ConnectionUtil;\n import com.splicemachine.db.iapi.sql.conn.LanguageConnectionContext;\n import com.splicemachine.db.iapi.sql.conn.StatementContext;\n import com.splicemachine.db.iapi.sql.dictionary.TriggerDescriptor;\n import com.splicemachine.db.iapi.sql.execute.CursorResultSet;\n \n+import java.sql.SQLException;\n+import java.util.*;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+import java.util.function.Function;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+import static com.splicemachine.db.impl.sql.execute.TriggerExecutionContext.pushLanguageConnectionContextToCM;\n+\n /**\n  * Responsible for firing a trigger or set of triggers based on an event.\n  */\n public class TriggerEventActivator {\n \n-    private LanguageConnectionContext lcc;\n     private TriggerInfo triggerInfo;\n     private TriggerExecutionContext tec;\n     private Map<TriggerEvent, List<GenericTriggerExecutor>> statementExecutorsMap = new HashMap<>();\n-    private Map<TriggerEvent, List<GenericTriggerExecutor>> rowExecutorsMap = new HashMap<>();\n+    private Map<TriggerEvent, List<TriggerDescriptor>> rowExecutorsMap = new HashMap<>();\n+    private Map<TriggerEvent, List<TriggerDescriptor>> rowConcurrentExecutorsMap = new HashMap<>();\n     private Activation activation;\n+    private ConnectionContext cc;\n     private String statementText;\n     private UUID tableId;\n     private String tableName;\n     private boolean tecPushed;", "originalCommit": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTA3NTIyMA==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r371075220", "bodyText": "I renamed cc, tecPushed and esvPushed to unabreviated names.", "author": "msirek", "createdAt": "2020-01-27T06:16:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEwNTY0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEwNzIwMw==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370107203", "bodyText": "Add comments to explain why we have LCC1 and LCC2", "author": "arnaud-splice", "createdAt": "2020-01-23T13:10:52Z", "path": "db-engine/src/main/java/com/splicemachine/db/impl/sql/execute/TriggerEventActivator.java", "diffHunk": "@@ -31,49 +31,69 @@\n \n package com.splicemachine.db.impl.sql.execute;\n \n-import java.util.ArrayList;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Vector;\n-\n import com.splicemachine.db.catalog.UUID;\n import com.splicemachine.db.iapi.error.StandardException;\n+import com.splicemachine.db.iapi.jdbc.ConnectionContext;\n+import com.splicemachine.db.iapi.services.context.ContextService;\n import com.splicemachine.db.iapi.services.io.FormatableBitSet;\n import com.splicemachine.db.iapi.sql.Activation;\n+import com.splicemachine.db.iapi.sql.conn.ConnectionUtil;\n import com.splicemachine.db.iapi.sql.conn.LanguageConnectionContext;\n import com.splicemachine.db.iapi.sql.conn.StatementContext;\n import com.splicemachine.db.iapi.sql.dictionary.TriggerDescriptor;\n import com.splicemachine.db.iapi.sql.execute.CursorResultSet;\n \n+import java.sql.SQLException;\n+import java.util.*;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+import java.util.function.Function;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+import static com.splicemachine.db.impl.sql.execute.TriggerExecutionContext.pushLanguageConnectionContextToCM;\n+\n /**\n  * Responsible for firing a trigger or set of triggers based on an event.\n  */\n public class TriggerEventActivator {\n \n-    private LanguageConnectionContext lcc;\n     private TriggerInfo triggerInfo;\n     private TriggerExecutionContext tec;\n     private Map<TriggerEvent, List<GenericTriggerExecutor>> statementExecutorsMap = new HashMap<>();\n-    private Map<TriggerEvent, List<GenericTriggerExecutor>> rowExecutorsMap = new HashMap<>();\n+    private Map<TriggerEvent, List<TriggerDescriptor>> rowExecutorsMap = new HashMap<>();\n+    private Map<TriggerEvent, List<TriggerDescriptor>> rowConcurrentExecutorsMap = new HashMap<>();\n     private Activation activation;\n+    private ConnectionContext cc;\n     private String statementText;\n     private UUID tableId;\n     private String tableName;\n     private boolean tecPushed;\n+    private boolean esvPushed;\n+    private LanguageConnectionContext esvLCC1;", "originalCommit": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTA3NjE3Mw==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r371076173", "bodyText": "Added this comment:\n// getLcc() may return a different LanguageConnectionContext at the time\n// we pop the triggerExecutionContext and executionStmtValidator, versus\n// at the time they were pushed.  Saving the original \"LCC\" at the time of\n// the push ensures that we pop from the correct LCC.  We sometimes need to\n// save two versions LCCs because we may push to the LCC in the activation,\n// and also to the LCC stored in the current ContextManager, if they happen\n// to be different.  Trigger execution requires that both the activation and\n// the current ContextManager both have a triggerExecutionContext.", "author": "msirek", "createdAt": "2020-01-27T06:22:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEwNzIwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDExNTQ3MA==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370115470", "bodyText": "Why use a vector here?", "author": "arnaud-splice", "createdAt": "2020-01-23T13:28:34Z", "path": "db-engine/src/main/java/com/splicemachine/db/impl/sql/execute/TriggerExecutionContext.java", "diffHunk": "@@ -83,13 +87,29 @@\n     private int[] changedColIds;\n     private String[] changedColNames;\n     private String statementText;\n+    protected ConnectionContext cc;\n     private UUID targetTableId;\n     private String targetTableName;\n-    private ExecRow triggeringResultSet;\n+    private ExecRow triggeringRow;\n     private TriggerDescriptor triggerd;\n     private ExecRow afterRow;   // used exclusively for InsertResultSets which have autoincrement columns.\n     private TriggerEvent event;\n     private FormatableBitSet heapList;\n+    private ExecRow execRowDefinition;\n+    private String tableVersion;\n+    private long conglomId;\n+\n+    protected CursorResultSet  triggeringResultSet;\n+\n+    /*\n+    ** Used to track all the result sets we have given out to\n+    ** users.  When the trigger context is no longer valid,\n+    ** we close all the result sets that may be in the user\n+    ** space because they can no longer provide meaningful\n+    ** results.\n+    */\n+    @SuppressWarnings(\"UseOfObsoleteCollectionType\")", "originalCommit": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTA3NzA4Mw==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r371077083", "bodyText": "I just pulled this in from the latest Derby code in github.  I didn't focus much attention on it.  Do you think we should change it?", "author": "msirek", "createdAt": "2020-01-27T06:26:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDExNTQ3MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTM4MjM5OQ==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r371382399", "bodyText": "Vector seems to be obsolete, but I don't know much about it. I'd say we leave it like this for now.", "author": "arnaud-splice", "createdAt": "2020-01-27T17:36:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDExNTQ3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDExNzM2NA==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370117364", "bodyText": "pushContext(lcc)", "author": "arnaud-splice", "createdAt": "2020-01-23T13:31:58Z", "path": "db-engine/src/main/java/com/splicemachine/db/impl/sql/execute/TriggerExecutionContext.java", "diffHunk": "@@ -142,8 +165,126 @@ public TriggerExecutionContext(String statementText,\n             }\n         }\n     }\n+    // Push a LanguageConnectionContext into\n+    // the task's ContextManager, if needed.  Return true if the push was done.\n+    public static boolean\n+    pushLanguageConnectionContextToCM(LanguageConnectionContext newLCC, ContextManager cm)\n+                                                               throws StandardException  {\n+        boolean lccPushed = false;\n+        try {\n+            LanguageConnectionContext currentLCC = ConnectionUtil.getCurrentLCC();\n+            if (newLCC != null) {\n+                if (newLCC != currentLCC) {\n+                    cm.pushContext(newLCC);\n+                    lccPushed = true;\n+                }\n+            }\n+        } catch (SQLException e) {\n+            // If the current LCC is not available in the context,\n+            // push it now.\n+            if (newLCC != null) {\n+                lccPushed = true;\n+                cm.pushContext(newLCC);\n+            }\n+        }\n+        return lccPushed;\n+    }\n+\n+    // Push the LanguageConnectionContext from the Activation into\n+    // the task's ContextManager, if needed.  Return true if the push was done.\n+    public static boolean\n+    pushLanguageConnectionContextFromActivation(Activation activation, ContextManager cm)\n+                                                               throws StandardException  {\n+        boolean lccPushed = false;\n+        try {\n+            LanguageConnectionContext currentLCC = ConnectionUtil.getCurrentLCC();\n+            if (activation != null && activation.getLanguageConnectionContext() != null) {\n+                LanguageConnectionContext lcc = activation.getLanguageConnectionContext();\n+                if (lcc != currentLCC) {\n+                    cm.pushContext(activation.getLanguageConnectionContext());", "originalCommit": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTA3NzYwOQ==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r371077609", "bodyText": "Made the change.", "author": "msirek", "createdAt": "2020-01-27T06:27:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDExNzM2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEyNDQzOQ==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370124439", "bodyText": "Indent for clarity", "author": "arnaud-splice", "createdAt": "2020-01-23T13:45:43Z", "path": "pipeline_api/src/main/java/com/splicemachine/pipeline/callbuffer/PipingCallBuffer.java", "diffHunk": "@@ -295,6 +295,7 @@ public void flushBuffer() throws Exception {\n     @Override\n     public void flushBufferAndWait() throws Exception {\n         flushBuffer();\n+        if (serverNameToRegionServerCBMap != null)\n         for (ServerCallBuffer buffer : serverNameToRegionServerCBMap.values()) {", "originalCommit": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTA3Nzk3NQ==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r371077975", "bodyText": "Done.", "author": "msirek", "createdAt": "2020-01-27T06:28:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEyNDQzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzMTgxNg==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370131816", "bodyText": "Why 1000? Probably add a comment or make it a constant", "author": "arnaud-splice", "createdAt": "2020-01-23T13:59:06Z", "path": "splice_machine/src/main/java/com/splicemachine/derby/catalog/TriggerNewTransitionRows.java", "diffHunk": "@@ -0,0 +1,371 @@\n+/*\n+ * This file is part of Splice Machine.\n+ * Splice Machine is free software: you can redistribute it and/or modify it under the terms of the\n+ * GNU Affero General Public License as published by the Free Software Foundation, either\n+ * version 3, or (at your option) any later version.\n+ * Splice Machine is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n+ * See the GNU Affero General Public License for more details.\n+ * You should have received a copy of the GNU Affero General Public License along with Splice Machine.\n+ * If not, see <http://www.gnu.org/licenses/>.\n+ *\n+ * Some parts of this source code are based on Apache Derby, and the following notices apply to\n+ * Apache Derby:\n+ *\n+ * Apache Derby is a subproject of the Apache DB project, and is licensed under\n+ * the Apache License, Version 2.0 (the \"License\"); you may not use these files\n+ * except in compliance with the License. You may obtain a copy of the License at:\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed\n+ * under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR\n+ * CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ *\n+ * Splice Machine, Inc. has modified the Apache Derby code in this file.\n+ *\n+ * All such Splice Machine modifications are Copyright 2012 - 2020 Splice Machine, Inc.,\n+ * and are licensed to you under the GNU Affero General Public License.\n+ */\n+\n+package com.splicemachine.derby.catalog;\n+\n+import com.splicemachine.db.iapi.db.Factory;\n+import com.splicemachine.db.iapi.error.StandardException;\n+import com.splicemachine.db.iapi.jdbc.ConnectionContext;\n+import com.splicemachine.db.iapi.sql.Activation;\n+import com.splicemachine.db.iapi.sql.conn.ConnectionUtil;\n+import com.splicemachine.db.iapi.sql.conn.LanguageConnectionContext;\n+import com.splicemachine.db.iapi.sql.execute.ExecRow;\n+import com.splicemachine.db.iapi.store.access.ScanController;\n+import com.splicemachine.db.iapi.store.access.TransactionController;\n+import com.splicemachine.db.iapi.store.access.conglomerate.TransactionManager;\n+import com.splicemachine.db.iapi.store.raw.Transaction;\n+import com.splicemachine.db.impl.jdbc.EmbedResultSet40;\n+import com.splicemachine.db.impl.sql.execute.TemporaryRowHolderResultSet;\n+import com.splicemachine.db.impl.sql.execute.TriggerExecutionContext;\n+import com.splicemachine.db.vti.VTICosting;\n+import com.splicemachine.db.vti.VTIEnvironment;\n+import com.splicemachine.derby.iapi.sql.execute.SpliceOperation;\n+import com.splicemachine.derby.impl.sql.execute.TriggerRowHolderImpl;\n+import com.splicemachine.derby.impl.sql.execute.operations.DMLWriteOperation;\n+import com.splicemachine.derby.impl.sql.execute.operations.InsertOperation;\n+import com.splicemachine.derby.impl.store.access.BaseSpliceTransaction;\n+import com.splicemachine.derby.stream.control.ControlDataSet;\n+import com.splicemachine.derby.stream.function.TriggerRowsMapFunction;\n+import com.splicemachine.derby.stream.iapi.DataSet;\n+import com.splicemachine.derby.stream.iapi.DataSetProcessor;\n+import com.splicemachine.derby.stream.iapi.OperationContext;\n+import com.splicemachine.derby.utils.Scans;\n+import com.splicemachine.derby.vti.iapi.DatasetProvider;\n+import com.splicemachine.pipeline.Exceptions;\n+import com.splicemachine.si.api.txn.TxnView;\n+import com.splicemachine.storage.DataScan;\n+\n+import java.io.Externalizable;\n+import java.io.IOException;\n+import java.io.ObjectInput;\n+import java.io.ObjectOutput;\n+import java.sql.ResultSet;\n+import java.sql.ResultSetMetaData;\n+import java.sql.SQLException;\n+\n+import static com.splicemachine.derby.impl.sql.execute.operations.ScanOperation.deSiify;\n+\n+/**\n+ * Provides information about the set of NEW rows accessed\n+ * via the REFERENCES clause in a statement trigger.\n+ * \n+ * <p>\n+ * This class implements only JDBC 1.2, not JDBC 2.0.  You cannot\n+ * compile this class with JDK1.2, since it implements only the\n+ * JDBC 1.2 ResultSet interface and not the JDBC 2.0 ResultSet\n+ * interface.  You can only use this class in a JDK 1.2 runtime \n+ * environment if no JDBC 2.0 calls are made against it.\n+ *\n+ */\n+public class TriggerNewTransitionRows\n+                   implements DatasetProvider, VTICosting, AutoCloseable, Externalizable\n+{\n+\n+\tprivate ResultSet resultSet;\n+\tprivate DataSet<ExecRow> sourceSet;\n+\tprivate TriggerExecutionContext tec;\n+\tprivate TemporaryRowHolderResultSet temporaryRowHolderResultSet;\n+\tprotected TriggerRowHolderImpl rowHolder = null;\n+\n+\tpublic TriggerNewTransitionRows()\n+\t{\n+            initializeResultSet();\n+\t}\t/**\n+\t * Construct a VTI on the trigger's new row set.\n+\t * The new row set is the after image of the rows\n+\t * that are changed by the trigger.  For a trigger\n+\t * on a delete, this throws an exception.\n+\t * For a trigger on an update, this is the rows after\n+\t * they are updated.  For an insert, this is the rows\n+\t * that are inserted.\n+\t *\n+\t * @exception SQLException thrown if no trigger active\n+\t */\n+\n+\tpublic TriggerRowHolderImpl getTriggerRowHolder() {\n+\t    if (resultSet == null) {\n+\t        initializeResultSet();\n+\t        if (resultSet == null)\n+                    return null;\n+            }\n+\t    TemporaryRowHolderResultSet tRS = ((TemporaryRowHolderResultSet)(((EmbedResultSet40) resultSet).getUnderlyingResultSet()));\n+            TriggerRowHolderImpl triggerRowsHolder = (tRS == null) ? null : (TriggerRowHolderImpl)tRS.getHolder();\n+            return triggerRowsHolder;\n+        }\n+\n+        @Override\n+        public void readExternal(ObjectInput in) throws IOException, ClassNotFoundException {\n+            // Version number\n+            in.readInt();\n+            boolean hasRowHolder = in.readBoolean();\n+\n+            if (hasRowHolder)\n+                rowHolder = (TriggerRowHolderImpl)in.readObject();\n+\n+            boolean hasTEC = in.readBoolean();\n+            if (hasTEC)\n+                tec = (TriggerExecutionContext)in.readObject();\n+        }\n+\n+        @Override\n+        public void writeExternal(ObjectOutput out) throws IOException {\n+            // Version number\n+            out.writeInt(1);\n+\n+            TriggerRowHolderImpl rowHolder = getTriggerRowHolder();\n+            boolean hasRowHolder = rowHolder != null;\n+            out.writeBoolean(hasRowHolder);\n+            if (hasRowHolder)\n+                out.writeObject(rowHolder);\n+            boolean hasTEC = tec != null;\n+            out.writeBoolean(hasTEC);\n+            if (hasTEC)\n+                out.writeObject(tec);\n+        }\n+\n+        @SuppressWarnings({ \"rawtypes\", \"unchecked\" })\n+\tpublic DataSet<ExecRow> getDataSet(SpliceOperation op, DataSetProcessor dsp, ExecRow execRow) throws StandardException {\n+            TriggerRowHolderImpl triggerRowsHolder;\n+            if (rowHolder != null)\n+                triggerRowsHolder = rowHolder;\n+            else\n+                triggerRowsHolder = getTriggerRowHolder();\n+\n+            DMLWriteOperation writeOperation = null;\n+            Activation activation = null;\n+            String tableVersion;\n+            ExecRow templateRow;\n+            DataSet<ExecRow> triggerRows = null;\n+            long conglomID;\n+\n+            if (triggerRowsHolder == null) {\n+                TriggerExecutionContext tec = null;\n+                try {\n+                    tec = Factory.getTriggerExecutionContext();\n+                }\n+                catch (SQLException e) {\n+\n+                }\n+                if (tec == null || tec.getTableVersion() == null)\n+                    tec = op.getActivation().getLanguageConnectionContext().getTriggerExecutionContext();\n+                tableVersion = tec.getTableVersion();\n+                templateRow = tec.getExecRowDefinition();\n+                conglomID = tec.getConglomId();\n+                activation = op.getActivation();\n+            }\n+            else {\n+\n+                activation = triggerRowsHolder.getActivation();\n+                sourceSet = triggerRowsHolder.getSourceSet();\n+\n+                if (activation.getResultSet() instanceof DMLWriteOperation)\n+                    writeOperation = (DMLWriteOperation) (activation.getResultSet());\n+\n+                conglomID = triggerRowsHolder.getConglomerateId();\n+                tableVersion = triggerRowsHolder.getTableVersion();\n+                templateRow = triggerRowsHolder.getExecRowDefinition();\n+            }\n+\n+            boolean usePersistedDataSet = op.isOlapServer() && sourceSet != null &&\n+                                          !(sourceSet instanceof ControlDataSet) &&\n+                                          writeOperation instanceof InsertOperation;\n+            // Disable the persisted DataSet path for now.\n+            // It doesn't work properly with tables with generated columns.\n+            usePersistedDataSet = false;\n+            if (usePersistedDataSet) {\n+                sourceSet.persist();\n+                triggerRows = sourceSet;\n+            }\n+            else {\n+                DataSet<ExecRow> cachedRowsSet = null;\n+                boolean isSpark = triggerRowsHolder == null || triggerRowsHolder.isSpark();\n+                if (!isSpark)\n+                    cachedRowsSet = new ControlDataSet<>(triggerRowsHolder.getCachedRowsIterator());\n+                if (conglomID != 0) {\n+                    String tableName = Long.toString(conglomID);\n+                    TransactionController transactionExecute = activation.getLanguageConnectionContext().getTransactionExecute();\n+                    Transaction rawStoreXact = ((TransactionManager) transactionExecute).getRawStoreXact();\n+                    TxnView txn = ((BaseSpliceTransaction) rawStoreXact).getActiveStateTxn();\n+\n+                    DataScan s = Scans.setupScan(\n+                    null,    // startKeyValues\n+                    ScanController.NA,   // startSearchOperator\n+                    null,    // stopKeyValues\n+                    null,    // stopPrefixValues\n+                    ScanController.NA,   // stopSearchOperator\n+                    null,       // qualifiers\n+                    null,\n+                    null,   // getAccessedColumns(),\n+                    null,            // txn : non-transactional\n+                    false,  // sameStartStop,\n+                    null,       // conglomerate.getFormat_ids(),\n+                    null,  // keyDecodingMap,\n+                    null,   \n+                    activation.getDataValueFactory(),\n+                    tableVersion,\n+                    false   // rowIdKey\n+                    );\n+\n+                    s.cacheRows(1000).batchCells(-1);", "originalCommit": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTA3OTI0NA==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r371079244", "bodyText": "Added the constant SCAN_CACHE_SIZE.  This value comes from what's used in ScanOperation.", "author": "msirek", "createdAt": "2020-01-27T06:31:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzMTgxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzMzI1MQ==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370133251", "bodyText": "Same, add comment to explain why we use this magic value", "author": "arnaud-splice", "createdAt": "2020-01-23T14:01:36Z", "path": "splice_machine/src/main/java/com/splicemachine/derby/catalog/TriggerNewTransitionRows.java", "diffHunk": "@@ -0,0 +1,371 @@\n+/*\n+ * This file is part of Splice Machine.\n+ * Splice Machine is free software: you can redistribute it and/or modify it under the terms of the\n+ * GNU Affero General Public License as published by the Free Software Foundation, either\n+ * version 3, or (at your option) any later version.\n+ * Splice Machine is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n+ * See the GNU Affero General Public License for more details.\n+ * You should have received a copy of the GNU Affero General Public License along with Splice Machine.\n+ * If not, see <http://www.gnu.org/licenses/>.\n+ *\n+ * Some parts of this source code are based on Apache Derby, and the following notices apply to\n+ * Apache Derby:\n+ *\n+ * Apache Derby is a subproject of the Apache DB project, and is licensed under\n+ * the Apache License, Version 2.0 (the \"License\"); you may not use these files\n+ * except in compliance with the License. You may obtain a copy of the License at:\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed\n+ * under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR\n+ * CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ *\n+ * Splice Machine, Inc. has modified the Apache Derby code in this file.\n+ *\n+ * All such Splice Machine modifications are Copyright 2012 - 2020 Splice Machine, Inc.,\n+ * and are licensed to you under the GNU Affero General Public License.\n+ */\n+\n+package com.splicemachine.derby.catalog;\n+\n+import com.splicemachine.db.iapi.db.Factory;\n+import com.splicemachine.db.iapi.error.StandardException;\n+import com.splicemachine.db.iapi.jdbc.ConnectionContext;\n+import com.splicemachine.db.iapi.sql.Activation;\n+import com.splicemachine.db.iapi.sql.conn.ConnectionUtil;\n+import com.splicemachine.db.iapi.sql.conn.LanguageConnectionContext;\n+import com.splicemachine.db.iapi.sql.execute.ExecRow;\n+import com.splicemachine.db.iapi.store.access.ScanController;\n+import com.splicemachine.db.iapi.store.access.TransactionController;\n+import com.splicemachine.db.iapi.store.access.conglomerate.TransactionManager;\n+import com.splicemachine.db.iapi.store.raw.Transaction;\n+import com.splicemachine.db.impl.jdbc.EmbedResultSet40;\n+import com.splicemachine.db.impl.sql.execute.TemporaryRowHolderResultSet;\n+import com.splicemachine.db.impl.sql.execute.TriggerExecutionContext;\n+import com.splicemachine.db.vti.VTICosting;\n+import com.splicemachine.db.vti.VTIEnvironment;\n+import com.splicemachine.derby.iapi.sql.execute.SpliceOperation;\n+import com.splicemachine.derby.impl.sql.execute.TriggerRowHolderImpl;\n+import com.splicemachine.derby.impl.sql.execute.operations.DMLWriteOperation;\n+import com.splicemachine.derby.impl.sql.execute.operations.InsertOperation;\n+import com.splicemachine.derby.impl.store.access.BaseSpliceTransaction;\n+import com.splicemachine.derby.stream.control.ControlDataSet;\n+import com.splicemachine.derby.stream.function.TriggerRowsMapFunction;\n+import com.splicemachine.derby.stream.iapi.DataSet;\n+import com.splicemachine.derby.stream.iapi.DataSetProcessor;\n+import com.splicemachine.derby.stream.iapi.OperationContext;\n+import com.splicemachine.derby.utils.Scans;\n+import com.splicemachine.derby.vti.iapi.DatasetProvider;\n+import com.splicemachine.pipeline.Exceptions;\n+import com.splicemachine.si.api.txn.TxnView;\n+import com.splicemachine.storage.DataScan;\n+\n+import java.io.Externalizable;\n+import java.io.IOException;\n+import java.io.ObjectInput;\n+import java.io.ObjectOutput;\n+import java.sql.ResultSet;\n+import java.sql.ResultSetMetaData;\n+import java.sql.SQLException;\n+\n+import static com.splicemachine.derby.impl.sql.execute.operations.ScanOperation.deSiify;\n+\n+/**\n+ * Provides information about the set of NEW rows accessed\n+ * via the REFERENCES clause in a statement trigger.\n+ * \n+ * <p>\n+ * This class implements only JDBC 1.2, not JDBC 2.0.  You cannot\n+ * compile this class with JDK1.2, since it implements only the\n+ * JDBC 1.2 ResultSet interface and not the JDBC 2.0 ResultSet\n+ * interface.  You can only use this class in a JDK 1.2 runtime \n+ * environment if no JDBC 2.0 calls are made against it.\n+ *\n+ */\n+public class TriggerNewTransitionRows\n+                   implements DatasetProvider, VTICosting, AutoCloseable, Externalizable\n+{\n+\n+\tprivate ResultSet resultSet;\n+\tprivate DataSet<ExecRow> sourceSet;\n+\tprivate TriggerExecutionContext tec;\n+\tprivate TemporaryRowHolderResultSet temporaryRowHolderResultSet;\n+\tprotected TriggerRowHolderImpl rowHolder = null;\n+\n+\tpublic TriggerNewTransitionRows()\n+\t{\n+            initializeResultSet();\n+\t}\t/**\n+\t * Construct a VTI on the trigger's new row set.\n+\t * The new row set is the after image of the rows\n+\t * that are changed by the trigger.  For a trigger\n+\t * on a delete, this throws an exception.\n+\t * For a trigger on an update, this is the rows after\n+\t * they are updated.  For an insert, this is the rows\n+\t * that are inserted.\n+\t *\n+\t * @exception SQLException thrown if no trigger active\n+\t */\n+\n+\tpublic TriggerRowHolderImpl getTriggerRowHolder() {\n+\t    if (resultSet == null) {\n+\t        initializeResultSet();\n+\t        if (resultSet == null)\n+                    return null;\n+            }\n+\t    TemporaryRowHolderResultSet tRS = ((TemporaryRowHolderResultSet)(((EmbedResultSet40) resultSet).getUnderlyingResultSet()));\n+            TriggerRowHolderImpl triggerRowsHolder = (tRS == null) ? null : (TriggerRowHolderImpl)tRS.getHolder();\n+            return triggerRowsHolder;\n+        }\n+\n+        @Override\n+        public void readExternal(ObjectInput in) throws IOException, ClassNotFoundException {\n+            // Version number\n+            in.readInt();\n+            boolean hasRowHolder = in.readBoolean();\n+\n+            if (hasRowHolder)\n+                rowHolder = (TriggerRowHolderImpl)in.readObject();\n+\n+            boolean hasTEC = in.readBoolean();\n+            if (hasTEC)\n+                tec = (TriggerExecutionContext)in.readObject();\n+        }\n+\n+        @Override\n+        public void writeExternal(ObjectOutput out) throws IOException {\n+            // Version number\n+            out.writeInt(1);\n+\n+            TriggerRowHolderImpl rowHolder = getTriggerRowHolder();\n+            boolean hasRowHolder = rowHolder != null;\n+            out.writeBoolean(hasRowHolder);\n+            if (hasRowHolder)\n+                out.writeObject(rowHolder);\n+            boolean hasTEC = tec != null;\n+            out.writeBoolean(hasTEC);\n+            if (hasTEC)\n+                out.writeObject(tec);\n+        }\n+\n+        @SuppressWarnings({ \"rawtypes\", \"unchecked\" })\n+\tpublic DataSet<ExecRow> getDataSet(SpliceOperation op, DataSetProcessor dsp, ExecRow execRow) throws StandardException {\n+            TriggerRowHolderImpl triggerRowsHolder;\n+            if (rowHolder != null)\n+                triggerRowsHolder = rowHolder;\n+            else\n+                triggerRowsHolder = getTriggerRowHolder();\n+\n+            DMLWriteOperation writeOperation = null;\n+            Activation activation = null;\n+            String tableVersion;\n+            ExecRow templateRow;\n+            DataSet<ExecRow> triggerRows = null;\n+            long conglomID;\n+\n+            if (triggerRowsHolder == null) {\n+                TriggerExecutionContext tec = null;\n+                try {\n+                    tec = Factory.getTriggerExecutionContext();\n+                }\n+                catch (SQLException e) {\n+\n+                }\n+                if (tec == null || tec.getTableVersion() == null)\n+                    tec = op.getActivation().getLanguageConnectionContext().getTriggerExecutionContext();\n+                tableVersion = tec.getTableVersion();\n+                templateRow = tec.getExecRowDefinition();\n+                conglomID = tec.getConglomId();\n+                activation = op.getActivation();\n+            }\n+            else {\n+\n+                activation = triggerRowsHolder.getActivation();\n+                sourceSet = triggerRowsHolder.getSourceSet();\n+\n+                if (activation.getResultSet() instanceof DMLWriteOperation)\n+                    writeOperation = (DMLWriteOperation) (activation.getResultSet());\n+\n+                conglomID = triggerRowsHolder.getConglomerateId();\n+                tableVersion = triggerRowsHolder.getTableVersion();\n+                templateRow = triggerRowsHolder.getExecRowDefinition();\n+            }\n+\n+            boolean usePersistedDataSet = op.isOlapServer() && sourceSet != null &&\n+                                          !(sourceSet instanceof ControlDataSet) &&\n+                                          writeOperation instanceof InsertOperation;\n+            // Disable the persisted DataSet path for now.\n+            // It doesn't work properly with tables with generated columns.\n+            usePersistedDataSet = false;\n+            if (usePersistedDataSet) {\n+                sourceSet.persist();\n+                triggerRows = sourceSet;\n+            }\n+            else {\n+                DataSet<ExecRow> cachedRowsSet = null;\n+                boolean isSpark = triggerRowsHolder == null || triggerRowsHolder.isSpark();\n+                if (!isSpark)\n+                    cachedRowsSet = new ControlDataSet<>(triggerRowsHolder.getCachedRowsIterator());\n+                if (conglomID != 0) {\n+                    String tableName = Long.toString(conglomID);\n+                    TransactionController transactionExecute = activation.getLanguageConnectionContext().getTransactionExecute();\n+                    Transaction rawStoreXact = ((TransactionManager) transactionExecute).getRawStoreXact();\n+                    TxnView txn = ((BaseSpliceTransaction) rawStoreXact).getActiveStateTxn();\n+\n+                    DataScan s = Scans.setupScan(\n+                    null,    // startKeyValues\n+                    ScanController.NA,   // startSearchOperator\n+                    null,    // stopKeyValues\n+                    null,    // stopPrefixValues\n+                    ScanController.NA,   // stopSearchOperator\n+                    null,       // qualifiers\n+                    null,\n+                    null,   // getAccessedColumns(),\n+                    null,            // txn : non-transactional\n+                    false,  // sameStartStop,\n+                    null,       // conglomerate.getFormat_ids(),\n+                    null,  // keyDecodingMap,\n+                    null,   \n+                    activation.getDataValueFactory(),\n+                    tableVersion,\n+                    false   // rowIdKey\n+                    );\n+\n+                    s.cacheRows(1000).batchCells(-1);\n+                    deSiify(s);\n+\n+                    int numColumns = templateRow.nColumns();\n+                    int[] rowDecodingMap = new int[numColumns];\n+                    for (int i = 0; i < numColumns; i++)\n+                        rowDecodingMap[i] = i;\n+\n+                    DataSet<ExecRow> sourceSet = dsp.<SpliceOperation, ExecRow>newScanSet(op, tableName)\n+                    .activation(activation)\n+                    .transaction(txn)\n+                    .scan(s)\n+                    .template(templateRow)\n+                    .tableVersion(tableVersion)\n+                    .reuseRowLocation(!isSpark)  // Needed for tables with generated columns.\n+                    .ignoreRecentTransactions(false)\n+                    .rowDecodingMap(rowDecodingMap)\n+                    .buildDataSet(op);\n+\n+                    if (cachedRowsSet == null)\n+                        triggerRows = sourceSet;\n+                    else\n+                        triggerRows = sourceSet.union(cachedRowsSet, op.getOperationContext());\n+                }\n+                else\n+                    triggerRows = cachedRowsSet;\n+            }\n+            boolean isOld = (this instanceof TriggerOldTransitionRows);\n+            triggerRows = triggerRows.map(new TriggerRowsMapFunction<>(op.getOperationContext(), isOld));\n+            if (writeOperation != null)\n+                writeOperation.registerCloseable(this);\n+\t    return triggerRows;\n+        }\n+\n+        public OperationContext getOperationContext() {\n+\t    return null;\n+        }\n+\n+        public void finishDeserialization(Activation activation) throws StandardException {\n+\t    if (tec != null) {\n+\t        LanguageConnectionContext lcc = null;\n+\t        try {\n+\t            lcc = activation.getLanguageConnectionContext();\n+\n+\t            if (tec.statementTriggerWithReferencingClause() &&\n+                        !tec.hasTriggeringResultSet() &&\n+                        ConnectionUtil.getCurrentLCC() != lcc &&\n+                        lcc.getTriggerExecutionContext() != null) {\n+\n+\t                TriggerExecutionContext currentTEC =\n+                            ConnectionUtil.getCurrentLCC().getTriggerExecutionContext();\n+                        if (currentTEC != null)\n+                            ConnectionUtil.getCurrentLCC().popTriggerExecutionContext(currentTEC);\n+                        tec = lcc.getTriggerExecutionContext();\n+                        ConnectionUtil.getCurrentLCC().pushTriggerExecutionContext(tec);\n+                    }\n+                    if (ConnectionUtil.getCurrentLCC().getTriggerExecutionContext() == null)\n+                        ConnectionUtil.getCurrentLCC().pushTriggerExecutionContext(tec);\n+                }\n+\t        catch (SQLException e) {\n+\n+                }\n+                if (rowHolder != null) {\n+\n+                    ConnectionContext cc =\n+                    (ConnectionContext) lcc.getContextManager().\n+                    getContext(ConnectionContext.CONTEXT_ID);\n+                    if (lcc.getTriggerExecutionContext() == null)\n+                        lcc.pushTriggerExecutionContext(tec);\n+\n+                    tec.setConnectionContext(cc);\n+                    rowHolder.setActivation(activation);\n+                    tec.setTriggeringResultSet(rowHolder.getResultSet());\n+                    try {\n+                        if (resultSet != null)\n+                            resultSet.close();\n+                        resultSet = tec.getNewRowSet();\n+                    } catch (SQLException e) {\n+                        throw Exceptions.parseException(e);\n+                    }\n+                }\n+            }\n+        }\n+\n+\tprotected ResultSet initializeResultSet() {\n+\t\ttry {\n+                    if (resultSet != null)\n+                            resultSet.close();\n+\n+                    tec = Factory.getTriggerExecutionContext();\n+                    if (tec != null)\n+                        resultSet = tec.getNewRowSet();\n+                }\n+\t\tcatch (SQLException e) {\n+\t\t    // This may happen on initial deserialization.\n+                    // Don't crash.  We will fill in the tec later\n+                    // in a subsequent deserialization.\n+                }\n+\n+\t\treturn resultSet;\n+\t}\n+    \n+    public ResultSetMetaData getMetaData() throws SQLException\n+    {\n+        if (resultSet != null)\n+            return resultSet.getMetaData();\n+        return null;\n+    }\n+\n+    public void close() throws SQLException {\n+       if (resultSet != null) {\n+           resultSet.close();\n+           resultSet = null;\n+       }\n+       if (sourceSet != null) {\n+           sourceSet.unpersistIt();\n+           sourceSet = null;\n+       }\n+   }\n+\n+    @Override\n+    public double getEstimatedRowCount(VTIEnvironment vtiEnvironment) throws SQLException {\n+        return 1000;", "originalCommit": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTA4MDExMQ==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r371080111", "bodyText": "Added constants and labelled this as a TODO item.  I'll open a Jira for better cost and cardinality estimation.", "author": "msirek", "createdAt": "2020-01-27T06:36:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzMzI1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTA4Nzk5OQ==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r371087999", "bodyText": "Opened DB-9103", "author": "msirek", "createdAt": "2020-01-27T07:15:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzMzI1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzMzMxOA==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370133318", "bodyText": "same", "author": "arnaud-splice", "createdAt": "2020-01-23T14:01:44Z", "path": "splice_machine/src/main/java/com/splicemachine/derby/catalog/TriggerNewTransitionRows.java", "diffHunk": "@@ -0,0 +1,371 @@\n+/*\n+ * This file is part of Splice Machine.\n+ * Splice Machine is free software: you can redistribute it and/or modify it under the terms of the\n+ * GNU Affero General Public License as published by the Free Software Foundation, either\n+ * version 3, or (at your option) any later version.\n+ * Splice Machine is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n+ * See the GNU Affero General Public License for more details.\n+ * You should have received a copy of the GNU Affero General Public License along with Splice Machine.\n+ * If not, see <http://www.gnu.org/licenses/>.\n+ *\n+ * Some parts of this source code are based on Apache Derby, and the following notices apply to\n+ * Apache Derby:\n+ *\n+ * Apache Derby is a subproject of the Apache DB project, and is licensed under\n+ * the Apache License, Version 2.0 (the \"License\"); you may not use these files\n+ * except in compliance with the License. You may obtain a copy of the License at:\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed\n+ * under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR\n+ * CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ *\n+ * Splice Machine, Inc. has modified the Apache Derby code in this file.\n+ *\n+ * All such Splice Machine modifications are Copyright 2012 - 2020 Splice Machine, Inc.,\n+ * and are licensed to you under the GNU Affero General Public License.\n+ */\n+\n+package com.splicemachine.derby.catalog;\n+\n+import com.splicemachine.db.iapi.db.Factory;\n+import com.splicemachine.db.iapi.error.StandardException;\n+import com.splicemachine.db.iapi.jdbc.ConnectionContext;\n+import com.splicemachine.db.iapi.sql.Activation;\n+import com.splicemachine.db.iapi.sql.conn.ConnectionUtil;\n+import com.splicemachine.db.iapi.sql.conn.LanguageConnectionContext;\n+import com.splicemachine.db.iapi.sql.execute.ExecRow;\n+import com.splicemachine.db.iapi.store.access.ScanController;\n+import com.splicemachine.db.iapi.store.access.TransactionController;\n+import com.splicemachine.db.iapi.store.access.conglomerate.TransactionManager;\n+import com.splicemachine.db.iapi.store.raw.Transaction;\n+import com.splicemachine.db.impl.jdbc.EmbedResultSet40;\n+import com.splicemachine.db.impl.sql.execute.TemporaryRowHolderResultSet;\n+import com.splicemachine.db.impl.sql.execute.TriggerExecutionContext;\n+import com.splicemachine.db.vti.VTICosting;\n+import com.splicemachine.db.vti.VTIEnvironment;\n+import com.splicemachine.derby.iapi.sql.execute.SpliceOperation;\n+import com.splicemachine.derby.impl.sql.execute.TriggerRowHolderImpl;\n+import com.splicemachine.derby.impl.sql.execute.operations.DMLWriteOperation;\n+import com.splicemachine.derby.impl.sql.execute.operations.InsertOperation;\n+import com.splicemachine.derby.impl.store.access.BaseSpliceTransaction;\n+import com.splicemachine.derby.stream.control.ControlDataSet;\n+import com.splicemachine.derby.stream.function.TriggerRowsMapFunction;\n+import com.splicemachine.derby.stream.iapi.DataSet;\n+import com.splicemachine.derby.stream.iapi.DataSetProcessor;\n+import com.splicemachine.derby.stream.iapi.OperationContext;\n+import com.splicemachine.derby.utils.Scans;\n+import com.splicemachine.derby.vti.iapi.DatasetProvider;\n+import com.splicemachine.pipeline.Exceptions;\n+import com.splicemachine.si.api.txn.TxnView;\n+import com.splicemachine.storage.DataScan;\n+\n+import java.io.Externalizable;\n+import java.io.IOException;\n+import java.io.ObjectInput;\n+import java.io.ObjectOutput;\n+import java.sql.ResultSet;\n+import java.sql.ResultSetMetaData;\n+import java.sql.SQLException;\n+\n+import static com.splicemachine.derby.impl.sql.execute.operations.ScanOperation.deSiify;\n+\n+/**\n+ * Provides information about the set of NEW rows accessed\n+ * via the REFERENCES clause in a statement trigger.\n+ * \n+ * <p>\n+ * This class implements only JDBC 1.2, not JDBC 2.0.  You cannot\n+ * compile this class with JDK1.2, since it implements only the\n+ * JDBC 1.2 ResultSet interface and not the JDBC 2.0 ResultSet\n+ * interface.  You can only use this class in a JDK 1.2 runtime \n+ * environment if no JDBC 2.0 calls are made against it.\n+ *\n+ */\n+public class TriggerNewTransitionRows\n+                   implements DatasetProvider, VTICosting, AutoCloseable, Externalizable\n+{\n+\n+\tprivate ResultSet resultSet;\n+\tprivate DataSet<ExecRow> sourceSet;\n+\tprivate TriggerExecutionContext tec;\n+\tprivate TemporaryRowHolderResultSet temporaryRowHolderResultSet;\n+\tprotected TriggerRowHolderImpl rowHolder = null;\n+\n+\tpublic TriggerNewTransitionRows()\n+\t{\n+            initializeResultSet();\n+\t}\t/**\n+\t * Construct a VTI on the trigger's new row set.\n+\t * The new row set is the after image of the rows\n+\t * that are changed by the trigger.  For a trigger\n+\t * on a delete, this throws an exception.\n+\t * For a trigger on an update, this is the rows after\n+\t * they are updated.  For an insert, this is the rows\n+\t * that are inserted.\n+\t *\n+\t * @exception SQLException thrown if no trigger active\n+\t */\n+\n+\tpublic TriggerRowHolderImpl getTriggerRowHolder() {\n+\t    if (resultSet == null) {\n+\t        initializeResultSet();\n+\t        if (resultSet == null)\n+                    return null;\n+            }\n+\t    TemporaryRowHolderResultSet tRS = ((TemporaryRowHolderResultSet)(((EmbedResultSet40) resultSet).getUnderlyingResultSet()));\n+            TriggerRowHolderImpl triggerRowsHolder = (tRS == null) ? null : (TriggerRowHolderImpl)tRS.getHolder();\n+            return triggerRowsHolder;\n+        }\n+\n+        @Override\n+        public void readExternal(ObjectInput in) throws IOException, ClassNotFoundException {\n+            // Version number\n+            in.readInt();\n+            boolean hasRowHolder = in.readBoolean();\n+\n+            if (hasRowHolder)\n+                rowHolder = (TriggerRowHolderImpl)in.readObject();\n+\n+            boolean hasTEC = in.readBoolean();\n+            if (hasTEC)\n+                tec = (TriggerExecutionContext)in.readObject();\n+        }\n+\n+        @Override\n+        public void writeExternal(ObjectOutput out) throws IOException {\n+            // Version number\n+            out.writeInt(1);\n+\n+            TriggerRowHolderImpl rowHolder = getTriggerRowHolder();\n+            boolean hasRowHolder = rowHolder != null;\n+            out.writeBoolean(hasRowHolder);\n+            if (hasRowHolder)\n+                out.writeObject(rowHolder);\n+            boolean hasTEC = tec != null;\n+            out.writeBoolean(hasTEC);\n+            if (hasTEC)\n+                out.writeObject(tec);\n+        }\n+\n+        @SuppressWarnings({ \"rawtypes\", \"unchecked\" })\n+\tpublic DataSet<ExecRow> getDataSet(SpliceOperation op, DataSetProcessor dsp, ExecRow execRow) throws StandardException {\n+            TriggerRowHolderImpl triggerRowsHolder;\n+            if (rowHolder != null)\n+                triggerRowsHolder = rowHolder;\n+            else\n+                triggerRowsHolder = getTriggerRowHolder();\n+\n+            DMLWriteOperation writeOperation = null;\n+            Activation activation = null;\n+            String tableVersion;\n+            ExecRow templateRow;\n+            DataSet<ExecRow> triggerRows = null;\n+            long conglomID;\n+\n+            if (triggerRowsHolder == null) {\n+                TriggerExecutionContext tec = null;\n+                try {\n+                    tec = Factory.getTriggerExecutionContext();\n+                }\n+                catch (SQLException e) {\n+\n+                }\n+                if (tec == null || tec.getTableVersion() == null)\n+                    tec = op.getActivation().getLanguageConnectionContext().getTriggerExecutionContext();\n+                tableVersion = tec.getTableVersion();\n+                templateRow = tec.getExecRowDefinition();\n+                conglomID = tec.getConglomId();\n+                activation = op.getActivation();\n+            }\n+            else {\n+\n+                activation = triggerRowsHolder.getActivation();\n+                sourceSet = triggerRowsHolder.getSourceSet();\n+\n+                if (activation.getResultSet() instanceof DMLWriteOperation)\n+                    writeOperation = (DMLWriteOperation) (activation.getResultSet());\n+\n+                conglomID = triggerRowsHolder.getConglomerateId();\n+                tableVersion = triggerRowsHolder.getTableVersion();\n+                templateRow = triggerRowsHolder.getExecRowDefinition();\n+            }\n+\n+            boolean usePersistedDataSet = op.isOlapServer() && sourceSet != null &&\n+                                          !(sourceSet instanceof ControlDataSet) &&\n+                                          writeOperation instanceof InsertOperation;\n+            // Disable the persisted DataSet path for now.\n+            // It doesn't work properly with tables with generated columns.\n+            usePersistedDataSet = false;\n+            if (usePersistedDataSet) {\n+                sourceSet.persist();\n+                triggerRows = sourceSet;\n+            }\n+            else {\n+                DataSet<ExecRow> cachedRowsSet = null;\n+                boolean isSpark = triggerRowsHolder == null || triggerRowsHolder.isSpark();\n+                if (!isSpark)\n+                    cachedRowsSet = new ControlDataSet<>(triggerRowsHolder.getCachedRowsIterator());\n+                if (conglomID != 0) {\n+                    String tableName = Long.toString(conglomID);\n+                    TransactionController transactionExecute = activation.getLanguageConnectionContext().getTransactionExecute();\n+                    Transaction rawStoreXact = ((TransactionManager) transactionExecute).getRawStoreXact();\n+                    TxnView txn = ((BaseSpliceTransaction) rawStoreXact).getActiveStateTxn();\n+\n+                    DataScan s = Scans.setupScan(\n+                    null,    // startKeyValues\n+                    ScanController.NA,   // startSearchOperator\n+                    null,    // stopKeyValues\n+                    null,    // stopPrefixValues\n+                    ScanController.NA,   // stopSearchOperator\n+                    null,       // qualifiers\n+                    null,\n+                    null,   // getAccessedColumns(),\n+                    null,            // txn : non-transactional\n+                    false,  // sameStartStop,\n+                    null,       // conglomerate.getFormat_ids(),\n+                    null,  // keyDecodingMap,\n+                    null,   \n+                    activation.getDataValueFactory(),\n+                    tableVersion,\n+                    false   // rowIdKey\n+                    );\n+\n+                    s.cacheRows(1000).batchCells(-1);\n+                    deSiify(s);\n+\n+                    int numColumns = templateRow.nColumns();\n+                    int[] rowDecodingMap = new int[numColumns];\n+                    for (int i = 0; i < numColumns; i++)\n+                        rowDecodingMap[i] = i;\n+\n+                    DataSet<ExecRow> sourceSet = dsp.<SpliceOperation, ExecRow>newScanSet(op, tableName)\n+                    .activation(activation)\n+                    .transaction(txn)\n+                    .scan(s)\n+                    .template(templateRow)\n+                    .tableVersion(tableVersion)\n+                    .reuseRowLocation(!isSpark)  // Needed for tables with generated columns.\n+                    .ignoreRecentTransactions(false)\n+                    .rowDecodingMap(rowDecodingMap)\n+                    .buildDataSet(op);\n+\n+                    if (cachedRowsSet == null)\n+                        triggerRows = sourceSet;\n+                    else\n+                        triggerRows = sourceSet.union(cachedRowsSet, op.getOperationContext());\n+                }\n+                else\n+                    triggerRows = cachedRowsSet;\n+            }\n+            boolean isOld = (this instanceof TriggerOldTransitionRows);\n+            triggerRows = triggerRows.map(new TriggerRowsMapFunction<>(op.getOperationContext(), isOld));\n+            if (writeOperation != null)\n+                writeOperation.registerCloseable(this);\n+\t    return triggerRows;\n+        }\n+\n+        public OperationContext getOperationContext() {\n+\t    return null;\n+        }\n+\n+        public void finishDeserialization(Activation activation) throws StandardException {\n+\t    if (tec != null) {\n+\t        LanguageConnectionContext lcc = null;\n+\t        try {\n+\t            lcc = activation.getLanguageConnectionContext();\n+\n+\t            if (tec.statementTriggerWithReferencingClause() &&\n+                        !tec.hasTriggeringResultSet() &&\n+                        ConnectionUtil.getCurrentLCC() != lcc &&\n+                        lcc.getTriggerExecutionContext() != null) {\n+\n+\t                TriggerExecutionContext currentTEC =\n+                            ConnectionUtil.getCurrentLCC().getTriggerExecutionContext();\n+                        if (currentTEC != null)\n+                            ConnectionUtil.getCurrentLCC().popTriggerExecutionContext(currentTEC);\n+                        tec = lcc.getTriggerExecutionContext();\n+                        ConnectionUtil.getCurrentLCC().pushTriggerExecutionContext(tec);\n+                    }\n+                    if (ConnectionUtil.getCurrentLCC().getTriggerExecutionContext() == null)\n+                        ConnectionUtil.getCurrentLCC().pushTriggerExecutionContext(tec);\n+                }\n+\t        catch (SQLException e) {\n+\n+                }\n+                if (rowHolder != null) {\n+\n+                    ConnectionContext cc =\n+                    (ConnectionContext) lcc.getContextManager().\n+                    getContext(ConnectionContext.CONTEXT_ID);\n+                    if (lcc.getTriggerExecutionContext() == null)\n+                        lcc.pushTriggerExecutionContext(tec);\n+\n+                    tec.setConnectionContext(cc);\n+                    rowHolder.setActivation(activation);\n+                    tec.setTriggeringResultSet(rowHolder.getResultSet());\n+                    try {\n+                        if (resultSet != null)\n+                            resultSet.close();\n+                        resultSet = tec.getNewRowSet();\n+                    } catch (SQLException e) {\n+                        throw Exceptions.parseException(e);\n+                    }\n+                }\n+            }\n+        }\n+\n+\tprotected ResultSet initializeResultSet() {\n+\t\ttry {\n+                    if (resultSet != null)\n+                            resultSet.close();\n+\n+                    tec = Factory.getTriggerExecutionContext();\n+                    if (tec != null)\n+                        resultSet = tec.getNewRowSet();\n+                }\n+\t\tcatch (SQLException e) {\n+\t\t    // This may happen on initial deserialization.\n+                    // Don't crash.  We will fill in the tec later\n+                    // in a subsequent deserialization.\n+                }\n+\n+\t\treturn resultSet;\n+\t}\n+    \n+    public ResultSetMetaData getMetaData() throws SQLException\n+    {\n+        if (resultSet != null)\n+            return resultSet.getMetaData();\n+        return null;\n+    }\n+\n+    public void close() throws SQLException {\n+       if (resultSet != null) {\n+           resultSet.close();\n+           resultSet = null;\n+       }\n+       if (sourceSet != null) {\n+           sourceSet.unpersistIt();\n+           sourceSet = null;\n+       }\n+   }\n+\n+    @Override\n+    public double getEstimatedRowCount(VTIEnvironment vtiEnvironment) throws SQLException {\n+        return 1000;\n+    }\n+\n+    @Override\n+    public double getEstimatedCostPerInstantiation(VTIEnvironment vtiEnvironment) throws SQLException {\n+        return 1000;", "originalCommit": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTA4MDEzMA==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r371080130", "bodyText": "See above comment.", "author": "msirek", "createdAt": "2020-01-27T06:36:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzMzMxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzNDg3Mw==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370134873", "bodyText": "Why do we cap initialArraySize to 2000?", "author": "arnaud-splice", "createdAt": "2020-01-23T14:04:34Z", "path": "splice_machine/src/main/java/com/splicemachine/derby/impl/sql/execute/TriggerRowHolderImpl.java", "diffHunk": "@@ -0,0 +1,517 @@\n+/*\n+ * Copyright (c) 2012 - 2019 Splice Machine, Inc.\n+ *\n+ * This file is part of Splice Machine.\n+ * Splice Machine is free software: you can redistribute it and/or modify it under the terms of the\n+ * GNU Affero General Public License as published by the Free Software Foundation, either\n+ * version 3, or (at your option) any later version.\n+ * Splice Machine is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n+ * See the GNU Affero General Public License for more details.\n+ * You should have received a copy of the GNU Affero General Public License along with Splice Machine.\n+ * If not, see <http://www.gnu.org/licenses/>.\n+ */\n+\n+package com.splicemachine.derby.impl.sql.execute;\n+\n+\n+import com.splicemachine.access.api.PartitionAdmin;\n+import com.splicemachine.access.api.PartitionFactory;\n+import com.splicemachine.db.iapi.services.sanity.SanityManager;\n+import com.splicemachine.db.iapi.error.StandardException;\n+import com.splicemachine.db.iapi.sql.conn.ResubmitDistributedException;\n+import com.splicemachine.db.iapi.sql.execute.CursorResultSet;\n+import com.splicemachine.db.iapi.sql.execute.ExecRow;\n+import com.splicemachine.db.iapi.sql.execute.TemporaryRowHolder;\n+import com.splicemachine.db.iapi.sql.Activation;\n+import com.splicemachine.db.iapi.sql.ResultDescription;\n+import com.splicemachine.db.iapi.store.access.ConglomerateController;\n+import com.splicemachine.db.iapi.store.access.TransactionController;\n+import com.splicemachine.db.iapi.types.DataValueDescriptor;\n+import com.splicemachine.db.impl.sql.execute.IndexValueRow;\n+import com.splicemachine.db.impl.sql.execute.TemporaryRowHolderResultSet;\n+import com.splicemachine.db.impl.sql.execute.TriggerExecutionContext;\n+import com.splicemachine.db.impl.sql.execute.ValueRow;\n+\n+import java.io.*;\n+import java.util.Iterator;\n+import java.util.Properties;\n+import java.util.concurrent.Callable;\n+\n+import com.splicemachine.derby.impl.sql.execute.operations.DMLWriteOperation;\n+import com.splicemachine.derby.impl.sql.execute.operations.TriggerHandler;\n+import com.splicemachine.derby.stream.iapi.DataSet;\n+import com.splicemachine.kvpair.KVPair;\n+import com.splicemachine.pipeline.Exceptions;\n+import com.splicemachine.pipeline.PipelineDriver;\n+import com.splicemachine.pipeline.callbuffer.RecordingCallBuffer;\n+import com.splicemachine.pipeline.client.WriteCoordinator;\n+import com.splicemachine.pipeline.config.UnsafeWriteConfiguration;\n+import com.splicemachine.pipeline.config.WriteConfiguration;\n+import com.splicemachine.si.api.txn.TxnView;\n+import com.splicemachine.si.impl.driver.SIDriver;\n+import com.splicemachine.storage.Partition;\n+import org.apache.log4j.Logger;\n+\n+import static java.lang.String.format;\n+\n+\n+/**\n+* This is a class that is used to temporarily\n+* (non-persistently) hold rows of the DML result\n+* set for statement triggers.  It will store them in an\n+* array, plus a temporary conglomerate, if there is overflow.\n+* But upon overflow of the array, if running true Splice with HBase, the\n+* statement is aborted and rerouted to run on Spark.\n+* <p>\n+* It is used for deferred DML processing.\n+* This class is a modified version of TemporaryRowHolderImpl.\n+*\n+*/\n+public class TriggerRowHolderImpl implements TemporaryRowHolder, Externalizable\n+{\n+     private static final Logger LOG = Logger.getLogger(TriggerRowHolderImpl.class);\n+\n+    protected static final int STATE_UNINIT = 0;\n+    public static final int STATE_INSERT = 1;\n+    public static final int STATE_DRAIN = 2;\n+\n+\n+    protected ExecRow[]         rowArray;\n+    private int                 numRowsIn = 0;\n+    private int                 lastArraySlot = -1;\n+    public int                  state = STATE_UNINIT;\n+\n+    private long                CID;\n+    private boolean             conglomCreated;\n+    private boolean             pipelineBufferCreated;\n+    private ConglomerateController\tcc;\n+    private Properties\t\t\t\tproperties;\n+\n+    private\tResultDescription\t\tresultDescription;\n+    /** Activation object with local state information. */\n+    public Activation\t\t\t\t\t\tactivation;\n+\n+    int \t\t\toverflowToConglomThreshold;\n+    int \t\t\tswitchToSparkThreshold;\n+    boolean                     isSpark;  // Is the query executing on spark?\n+    private ExecRow execRowDefinition;\n+    private String  tableVersion;\n+\n+    protected WriteCoordinator writeCoordinator;\n+    protected RecordingCallBuffer<KVPair> triggerTempTableWriteBuffer;\n+    protected Callable<Void> triggerTempTableflushCallback;\n+    protected Partition triggerTempPartition;\n+    private TxnView txn;\n+    private byte[] token;\n+    private TriggerExecutionContext tec;\n+\n+    public TriggerRowHolderImpl() {\n+\n+    }\n+\n+    /**\n+     * Create a temporary row holder with the defined overflow to conglom\n+     *\n+     * @param activation the activation\n+     * @param properties the properties of the original table.  Used\n+     *\t\tto help the store use optimal page size, etc.\n+     * @param resultDescription the result description.  Relevant for the getResultDescription\n+     * \t\tcall on the result set returned by getResultSet.  May be null\n+     * @param overflowToConglomThreshold on an attempt to insert\n+     * \t\tthis number of rows, the rows will be put\n+     *\t\tinto a temporary conglomerate.\n+     */\n+    public TriggerRowHolderImpl\n+    (\n+            Activation              activation,\n+            Properties              properties,\n+            ResultDescription       resultDescription,\n+            int                     overflowToConglomThreshold,\n+            int                     switchToSparkThreshold,\n+            ExecRow                 execRowDefinition,\n+            String                  tableVersion,\n+            boolean                 isSpark,\n+            TxnView                 txn,\n+            byte[]                  token,\n+            long                    ConglomID,\n+            TriggerExecutionContext tec\n+    )\n+    {\n+        if (SanityManager.DEBUG)\n+        {\n+                if (overflowToConglomThreshold < 0)\n+                {\n+                        SanityManager.THROWASSERT(\"It is assumed that \"+\n+                                \"the overflow threshold is >= 0.  \"+\n+                                \"If you you need to change this you have to recode some of \"+\n+                                \"this class.\");\n+                }\n+        }\n+\n+        this.activation = activation;\n+        this.properties = properties;\n+        this.resultDescription = resultDescription;\n+        this.txn = txn;\n+        this.token = token;\n+        this.tec = tec;\n+        this.isSpark = isSpark;\n+\n+        int initialArraySize = overflowToConglomThreshold < 1 ? 1 : overflowToConglomThreshold;\n+        if (initialArraySize > 2000)", "originalCommit": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTA4MDYwOA==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r371080608", "bodyText": "To save space.  If we had hundreds of triggers firing simultaneously, each allocated with 1000000 entries initially, even if they are not needed, it would waste a lot of space, which may cause memory pressure.", "author": "msirek", "createdAt": "2020-01-27T06:38:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzNDg3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0NDI4MA==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370144280", "bodyText": "Remove DB-8883 comment", "author": "arnaud-splice", "createdAt": "2020-01-23T14:21:04Z", "path": "splice_machine/src/test/java/com/splicemachine/triggers/Trigger_When_Clause_IT.java", "diffHunk": "@@ -547,44 +548,64 @@ public void testDependencies() throws Exception {\n             // table fails, even if the column is not referenced in the WHEN clause\n             // or in the triggered SQL text.\n             // Need DB-8883 for the following commented tests:", "originalCommit": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTA4MDcxOA==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r371080718", "bodyText": "Done.", "author": "msirek", "createdAt": "2020-01-27T06:39:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0NDI4MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0ODQ1Nw==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370148457", "bodyText": "this.tableVersion = tableVersion is probably missing", "author": "arnaud-splice", "createdAt": "2020-01-23T14:27:55Z", "path": "splice_machine/src/main/java/com/splicemachine/derby/stream/output/direct/DirectPipelineWriter.java", "diffHunk": "@@ -46,10 +46,11 @@\n     private TxnView txn;\n     private final OperationContext opCtx;\n     private final boolean skipIndex;\n+    protected String tableVersion;\n \n     private RecordingCallBuffer<KVPair> writeBuffer;\n \n-    public DirectPipelineWriter(long destConglomerate, TxnView txn, byte[] token, OperationContext opCtx, boolean skipIndex){\n+    public DirectPipelineWriter(long destConglomerate, TxnView txn, byte[] token, OperationContext opCtx, boolean skipIndex, String tableVersion){\n         this.destConglomerate=destConglomerate;", "originalCommit": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTA4MTAyMQ==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r371081021", "bodyText": "Added.  This is just there for consistency with other pipelinewriters, but is not actually used.", "author": "msirek", "createdAt": "2020-01-27T06:41:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0ODQ1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE1MjgzNQ==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370152835", "bodyText": "Should that 1 million limit also be applied in the other place we use that setting?\nIf so, you can set the limit directly in SQLConfiguration.java\ncf SPARK_COMPACTION_RESOLUTION_SHARE in OlapConfigurations.java for an example", "author": "arnaud-splice", "createdAt": "2020-01-23T14:35:18Z", "path": "splice_machine/src/main/java/com/splicemachine/derby/impl/sql/execute/operations/TriggerHandler.java", "diffHunk": "@@ -62,36 +75,174 @@\n     private final boolean hasBeforeStatement;\n     private final boolean hasAfterRow;\n     private final boolean hasAfterStatement;\n+    private final boolean hasStatementTriggerWithReferencingClause;\n     private FormatableBitSet heapList;\n+    private ExecRow templateRow;\n+    private String tableVersion;\n+\n+    private DMLWriteInfo writeInfo;\n+    private Activation activation;\n+    private TriggerRowHolderImpl triggerRowHolder;\n+    private boolean isSpark;\n+    private TxnView txn;\n+    private byte[] token;\n+\n+    private Function<Function<LanguageConnectionContext,Void>, Callable> withContext;\n \n     public TriggerHandler(TriggerInfo triggerInfo,\n                           DMLWriteInfo writeInfo,\n                           Activation activation,\n                           TriggerEvent beforeEvent,\n                           TriggerEvent afterEvent,\n-                          FormatableBitSet heapList) throws StandardException {\n+                          FormatableBitSet heapList,\n+                          ExecRow templateRow,\n+                          String tableVersion) throws StandardException {\n         WriteCursorConstantOperation constantAction = (WriteCursorConstantOperation) writeInfo.getConstantAction();\n         initConnectionContext(activation.getLanguageConnectionContext());\n \n         this.beforeEvent = beforeEvent;\n         this.afterEvent = afterEvent;\n+        this.activation = activation;\n         this.resultDescription = activation.getResultDescription();\n         this.pendingAfterRows = Lists.newArrayListWithCapacity(AFTER_ROW_BUFFER_SIZE);\n \n         this.hasBeforeRow = triggerInfo.hasBeforeRowTrigger();\n         this.hasAfterRow = triggerInfo.hasAfterRowTrigger();\n         this.hasBeforeStatement = triggerInfo.hasBeforeStatementTrigger();\n         this.hasAfterStatement = triggerInfo.hasAfterStatementTrigger();\n+        this.hasStatementTriggerWithReferencingClause = triggerInfo.hasStatementTriggerWithReferencingClause();\n         this.heapList = heapList;\n+        this.templateRow = templateRow;\n+        this.tableVersion = tableVersion;\n+        this.activation = activation;\n+        this.writeInfo = writeInfo;\n         initTriggerActivator(activation, constantAction);\n     }\n \n+    public Callable<Void> getTriggerTempTableflushCallback () {\n+        if (triggerRowHolder != null)\n+             return triggerRowHolder.getTriggerTempTableflushCallback();\n+        return null;\n+    }\n+\n+    public void setTxn(TxnView txn) {\n+        this.txn = txn;\n+        if (triggerRowHolder != null)\n+            triggerRowHolder.setTxn(txn);\n+    }\n+\n+    public boolean hasStatementTrigger() {\n+        return hasBeforeStatement || hasAfterStatement;\n+    }\n+\n+    public boolean hasStatementTriggerWithReferencingClause() {\n+        return this.hasStatementTriggerWithReferencingClause;\n+    }\n+\n+    public void addRowToNewTableRowHolder(ExecRow row, KVPair encode) throws StandardException {\n+        if (triggerRowHolder != null)\n+            triggerRowHolder.insert(row, encode);\n+    }\n+\n+    public void setIsSpark(boolean isSpark) {\n+        this.isSpark = isSpark;\n+    }\n+\n+    public boolean isSpark() {\n+        return this.isSpark;\n+    }\n+\n+    public long getTriggerConglomID() {\n+        if (triggerRowHolder != null) {\n+            return triggerRowHolder.getConglomerateId();\n+        }\n+        return 0;\n+    }\n+\n+    public void initTriggerRowHolders(boolean isSpark, TxnView txn, byte[] token, long ConglomID) throws StandardException {\n+        this.isSpark = isSpark;\n+        this.txn = txn;\n+        this.token = token;\n+        Properties properties = new Properties();\n+        if (hasStatementTriggerWithReferencingClause) {\n+            // Use the smaller of ControlExecutionRowLimit or 1000000 to determine when to switch to spark execution.\n+            // Hard cap at 1 million despite the setting of controlExecutionRowLimit since we don't want to exhaust", "originalCommit": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTA4MTQyNw==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r371081427", "bodyText": "No, I would like users to be able to freely adjust that setting for normal SQL queries.  For triggers we have a hard upper limit of 1000000 rows for the in-memory buffer, which I don't want to grow any larger.  Instead we just switch to running on spark.", "author": "msirek", "createdAt": "2020-01-27T06:43:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE1MjgzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE1NTE2OA==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370155168", "bodyText": "withContext = f -> (Callable) () -> { ActivationHolder ah = new ActivationHolder(activation, null); try { ...", "author": "arnaud-splice", "createdAt": "2020-01-23T14:39:13Z", "path": "splice_machine/src/main/java/com/splicemachine/derby/impl/sql/execute/operations/TriggerHandler.java", "diffHunk": "@@ -62,36 +75,174 @@\n     private final boolean hasBeforeStatement;\n     private final boolean hasAfterRow;\n     private final boolean hasAfterStatement;\n+    private final boolean hasStatementTriggerWithReferencingClause;\n     private FormatableBitSet heapList;\n+    private ExecRow templateRow;\n+    private String tableVersion;\n+\n+    private DMLWriteInfo writeInfo;\n+    private Activation activation;\n+    private TriggerRowHolderImpl triggerRowHolder;\n+    private boolean isSpark;\n+    private TxnView txn;\n+    private byte[] token;\n+\n+    private Function<Function<LanguageConnectionContext,Void>, Callable> withContext;\n \n     public TriggerHandler(TriggerInfo triggerInfo,\n                           DMLWriteInfo writeInfo,\n                           Activation activation,\n                           TriggerEvent beforeEvent,\n                           TriggerEvent afterEvent,\n-                          FormatableBitSet heapList) throws StandardException {\n+                          FormatableBitSet heapList,\n+                          ExecRow templateRow,\n+                          String tableVersion) throws StandardException {\n         WriteCursorConstantOperation constantAction = (WriteCursorConstantOperation) writeInfo.getConstantAction();\n         initConnectionContext(activation.getLanguageConnectionContext());\n \n         this.beforeEvent = beforeEvent;\n         this.afterEvent = afterEvent;\n+        this.activation = activation;\n         this.resultDescription = activation.getResultDescription();\n         this.pendingAfterRows = Lists.newArrayListWithCapacity(AFTER_ROW_BUFFER_SIZE);\n \n         this.hasBeforeRow = triggerInfo.hasBeforeRowTrigger();\n         this.hasAfterRow = triggerInfo.hasAfterRowTrigger();\n         this.hasBeforeStatement = triggerInfo.hasBeforeStatementTrigger();\n         this.hasAfterStatement = triggerInfo.hasAfterStatementTrigger();\n+        this.hasStatementTriggerWithReferencingClause = triggerInfo.hasStatementTriggerWithReferencingClause();\n         this.heapList = heapList;\n+        this.templateRow = templateRow;\n+        this.tableVersion = tableVersion;\n+        this.activation = activation;\n+        this.writeInfo = writeInfo;\n         initTriggerActivator(activation, constantAction);\n     }\n \n+    public Callable<Void> getTriggerTempTableflushCallback () {\n+        if (triggerRowHolder != null)\n+             return triggerRowHolder.getTriggerTempTableflushCallback();\n+        return null;\n+    }\n+\n+    public void setTxn(TxnView txn) {\n+        this.txn = txn;\n+        if (triggerRowHolder != null)\n+            triggerRowHolder.setTxn(txn);\n+    }\n+\n+    public boolean hasStatementTrigger() {\n+        return hasBeforeStatement || hasAfterStatement;\n+    }\n+\n+    public boolean hasStatementTriggerWithReferencingClause() {\n+        return this.hasStatementTriggerWithReferencingClause;\n+    }\n+\n+    public void addRowToNewTableRowHolder(ExecRow row, KVPair encode) throws StandardException {\n+        if (triggerRowHolder != null)\n+            triggerRowHolder.insert(row, encode);\n+    }\n+\n+    public void setIsSpark(boolean isSpark) {\n+        this.isSpark = isSpark;\n+    }\n+\n+    public boolean isSpark() {\n+        return this.isSpark;\n+    }\n+\n+    public long getTriggerConglomID() {\n+        if (triggerRowHolder != null) {\n+            return triggerRowHolder.getConglomerateId();\n+        }\n+        return 0;\n+    }\n+\n+    public void initTriggerRowHolders(boolean isSpark, TxnView txn, byte[] token, long ConglomID) throws StandardException {\n+        this.isSpark = isSpark;\n+        this.txn = txn;\n+        this.token = token;\n+        Properties properties = new Properties();\n+        if (hasStatementTriggerWithReferencingClause) {\n+            // Use the smaller of ControlExecutionRowLimit or 1000000 to determine when to switch to spark execution.\n+            // Hard cap at 1 million despite the setting of controlExecutionRowLimit since we don't want to exhaust\n+            // memory if the sysadmin cranked this setting really high.\n+            int switchToSparkThreshold = EngineDriver.driver().getConfiguration().getControlExecutionRowLimit() <= Integer.MAX_VALUE ?\n+            (int) EngineDriver.driver().getConfiguration().getControlExecutionRowLimit() : Integer.MAX_VALUE;\n+\n+            if (switchToSparkThreshold < 0)\n+                switchToSparkThreshold = 0;\n+            else if (switchToSparkThreshold > 1000000)\n+                switchToSparkThreshold = 1000000;\n+\n+\n+            long doubleDetermineSparkRowThreshold = 2 * getLcc().getOptimizerFactory().getDetermineSparkRowThreshold();\n+            int inMemoryLimit = switchToSparkThreshold;\n+\n+            // Pick the larger of switchToSparkThreshold or 2*determineSparkRowThreshold as the\n+            // threshold for creating a conglomerate.  By design this will cause the trigger rows\n+            // to always be held in memory when executing on control, for performance.\n+            // But the interface also supports values of switchToSparkThreshold which are larger than\n+            // overflowToConglomThreshold, in which case we could create a temporary conglomerate while\n+            // executing in control.\n+            int overflowToConglomThreshold =\n+                 doubleDetermineSparkRowThreshold > inMemoryLimit ? (int)doubleDetermineSparkRowThreshold :\n+                 doubleDetermineSparkRowThreshold < 0 ? 0 :\n+                 inMemoryLimit;\n+\n+            // Spark doesn't support use of an in-memory TriggerRowHolderImpl, so we\n+            // set overflowToConglomThreshold to zero and always use a conglomerate.\n+            if (isSpark) {\n+                switchToSparkThreshold = 0;\n+                overflowToConglomThreshold = 0;\n+            }\n+\n+            triggerRowHolder =\n+                new TriggerRowHolderImpl(activation, properties, writeInfo.getResultDescription(),\n+                                         overflowToConglomThreshold, switchToSparkThreshold,\n+                                         templateRow, tableVersion, isSpark, txn, token, ConglomID,\n+                                          this.getTriggerExecutionContext());\n+        }\n+\n+    }\n+\n+    public TriggerExecutionContext getTriggerExecutionContext() { return this.triggerActivator.getTriggerExecutionContext(); }\n+\n     private void initTriggerActivator(Activation activation, WriteCursorConstantOperation constantAction) throws StandardException {\n         try {\n+            withContext = new Function<Function<LanguageConnectionContext,Void>, Callable>() {", "originalCommit": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTA4MjE4Mw==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r371082183", "bodyText": "Is that shorthand or something?  Is there anything wrong with the code in its current form?  I'm just porting from Daniel's branch.", "author": "msirek", "createdAt": "2020-01-27T06:47:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE1NTE2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE1NzE0Ng==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370157146", "bodyText": "Same here, use lambda", "author": "arnaud-splice", "createdAt": "2020-01-23T14:42:36Z", "path": "splice_machine/src/main/java/com/splicemachine/derby/impl/sql/execute/operations/TriggerHandler.java", "diffHunk": "@@ -147,37 +316,89 @@ public void firePendingAfterTriggers(Callable<Void> flushCallback) throws Except\n          * Which is what we want. Check constraints before firing after triggers. */\n         try {\n             flushCallback.call();\n+            if (getTriggerTempTableflushCallback() != null)\n+                getTriggerTempTableflushCallback().call();\n         } catch (Exception e) {\n             pendingAfterRows.clear();\n             throw e;\n         }\n \n-        for (ExecRow flushedRow : pendingAfterRows) {\n-            fireAfterRowTriggers(flushedRow);\n+        if (!hasAfterRow)\n+            return;\n+\n+        List<Future<Void>> futures = new ArrayList<>();\n+\n+        // The LCC can't be shared amongst threads, so\n+        // only use one level of concurrency for now.\n+        if (true || pendingAfterRows.size() <= 1) {\n+            for (ExecRow flushedRow : pendingAfterRows)\n+                futures.addAll(fireAfterRowConcurrentTriggers(flushedRow));\n+            for (ExecRow flushedRow : pendingAfterRows)\n+                fireAfterRowTriggers(flushedRow);\n+        } else {\n+            Object lock = new Object();\n+            // work concurrently\n+            List<Future<Void>> rowFutures = new ArrayList<>();\n+            for (ExecRow flushedRow : pendingAfterRows) {\n+                rowFutures.add(SIDriver.driver().getExecutorService().submit(withContext.apply(new Function<LanguageConnectionContext,Void>() {", "originalCommit": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTA4MjMyNA==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r371082324", "bodyText": "Reason?", "author": "msirek", "createdAt": "2020-01-27T06:48:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE1NzE0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE2MDE5Nw==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r370160197", "bodyText": "Why are resets still there?", "author": "arnaud-splice", "createdAt": "2020-01-23T14:47:19Z", "path": "splice_machine/src/test/java/com/splicemachine/triggers/Trigger_Referencing_Clause_IT.java", "diffHunk": "@@ -0,0 +1,1294 @@\n+/*\n+ * This file is part of Splice Machine.\n+ * Splice Machine is free software: you can redistribute it and/or modify it under the terms of the\n+ * GNU Affero General Public License as published by the Free Software Foundation, either\n+ * version 3, or (at your option) any later version.\n+ * Splice Machine is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n+ * See the GNU Affero General Public License for more details.\n+ * You should have received a copy of the GNU Affero General Public License along with Splice Machine.\n+ * If not, see <http://www.gnu.org/licenses/>.\n+ *\n+ * Some parts of this source code are based on Apache Derby, and the following notices apply to\n+ * Apache Derby:\n+ *\n+ * Apache Derby is a subproject of the Apache DB project, and is licensed under\n+ * the Apache License, Version 2.0 (the \"License\"); you may not use these files\n+ * except in compliance with the License. You may obtain a copy of the License at:\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed\n+ * under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR\n+ * CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ *\n+ * Splice Machine, Inc. has modified the Apache Derby code in this file.\n+ *\n+ * All such Splice Machine modifications are Copyright 2012 - 2019 Splice Machine, Inc.,\n+ * and are licensed to you under the GNU Affero General Public License.\n+ */\n+\n+package com.splicemachine.triggers;\n+\n+import com.splicemachine.derby.test.framework.*;\n+import com.splicemachine.test.SerialTest;\n+import org.junit.*;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+import org.spark_project.guava.collect.Lists;\n+\n+import java.sql.*;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Properties;\n+\n+import static com.splicemachine.db.shared.common.reference.MessageId.SPLICE_GENERIC_EXCEPTION;\n+import static com.splicemachine.db.shared.common.reference.SQLState.LANG_TRIGGER_BAD_REF_MISMATCH;\n+\n+/**\n+ * Test REFERENCING clause in triggers.\n+ */\n+@Category(value = {SerialTest.class})\n+@RunWith(Parameterized.class)\n+public class Trigger_Referencing_Clause_IT extends SpliceUnitTest {\n+\n+\n+    private static final String SCHEMA = Trigger_Referencing_Clause_IT.class.getSimpleName();\n+    public static final String CLASS_NAME = Trigger_Referencing_Clause_IT.class.getSimpleName().toUpperCase();\n+    protected static final String USER1 = \"U1\";\n+    protected static final String PASSWORD1 = \"U1\";\n+    protected static final String USER2 = \"U2\";\n+    protected static final String PASSWORD2 = \"U2\";\n+\n+    @ClassRule\n+    public static SpliceSchemaWatcher spliceSchemaWatcher = new SpliceSchemaWatcher(SCHEMA);\n+\n+    @ClassRule\n+    public static SpliceWatcher classWatcher = new SpliceWatcher(SCHEMA);\n+\n+    @ClassRule\n+    public static SpliceUserWatcher spliceUserWatcher1 = new SpliceUserWatcher(USER1, PASSWORD1);\n+\n+    @ClassRule\n+    public static SpliceUserWatcher spliceUserWatcher2 = new SpliceUserWatcher(USER2, PASSWORD2);\n+\n+    private TestConnection conn;\n+    private TestConnection c1;\n+    private TestConnection c2;\n+\n+    private static final String SYNTAX_ERROR = \"42X01\";\n+    private static final String NON_SCALAR_QUERY = \"21000\";\n+    private static final String TRIGGER_RECURSION = \"54038\";\n+\n+\n+    @Parameterized.Parameters\n+    public static Collection<Object[]> data() {\n+        Collection<Object[]> params = Lists.newArrayListWithCapacity(2);\n+        params.add(new Object[]{\"jdbc:splice://localhost:1527/splicedb;user=splice;password=admin\"});\n+        params.add(new Object[]{\"jdbc:splice://localhost:1527/splicedb;user=splice;password=admin;useSpark=true\"});\n+        return params;\n+    }\n+\n+    private String connectionString;\n+\n+    public Trigger_Referencing_Clause_IT(String connectionString ) {\n+        this.connectionString = connectionString;\n+    }\n+\n+    protected void createInt_Proc() throws Exception {\n+        Connection c = conn;\n+        try(Statement s = c.createStatement()) {\n+            s.execute(\"create function f(x varchar(50)) returns boolean \"\n+            + \"language java parameter style java external name \"\n+            + \"'org.splicetest.sqlj.SqlJTestProcs.tableIsEmpty' reads sql data\");\n+\n+            s.executeUpdate(\"create procedure int_proc(i int) language java \"\n+            + \"parameter style java external name \"\n+            + \"'org.splicetest.sqlj.SqlJTestProcs.intProcedure' reads sql data\");\n+            // If running tests in IntelliJ, use one of the commented-out versions of STORED_PROCS_JAR_FILE.\n+            String STORED_PROCS_JAR_FILE = System.getProperty(\"user.dir\") + \"/target/sql-it/sql-it.jar\";\n+            //String STORED_PROCS_JAR_FILE = System.getProperty(\"user.dir\") + \"/../platform_it/target/sql-it/sql-it.jar\";\n+            //String STORED_PROCS_JAR_FILE = System.getProperty(\"user.dir\") + \"/../mem_sql/target/sql-it/sql-it.jar\";\n+            String JAR_FILE_SQL_NAME = CLASS_NAME + \".\" + \"SQLJ_IT_PROCS_JAR\";\n+            s.execute(String.format(\"CALL SQLJ.INSTALL_JAR('%s', '%s', 0)\", STORED_PROCS_JAR_FILE, JAR_FILE_SQL_NAME));\n+            s.execute(String.format(\"CALL SYSCS_UTIL.SYSCS_SET_GLOBAL_DATABASE_PROPERTY('derby.database.classpath', '%s')\", JAR_FILE_SQL_NAME));\n+            c.commit();\n+        }\n+    }\n+\n+    /* Each test starts with same table state */\n+    @Before\n+    public void initTable() throws Exception {\n+        spliceSchemaWatcher.cleanSchemaObjects();\n+        conn = new TestConnection(DriverManager.getConnection(connectionString, new Properties()));\n+        // grant schema privileges\n+        conn.execute(format(\"grant ALL PRIVILEGES on schema %s to %s\", SCHEMA, USER1));\n+        conn.execute(format(\"grant access on schema %s to %s\", SCHEMA, USER2));\n+\n+        // grant execution privileges\n+        conn.execute(format(\"grant execute on procedure syscs_util.syscs_get_schema_info to %s\", USER1));\n+        conn.execute(format(\"grant execute on procedure syscs_util.syscs_get_schema_info to %s\", USER2));\n+        conn.execute(format(\"grant execute on procedure SYSCS_UTIL.INVALIDATE_GLOBAL_DICTIONARY_CACHE to %s\", USER1));\n+        conn.execute(format(\"grant execute on procedure SYSCS_UTIL.INVALIDATE_GLOBAL_DICTIONARY_CACHE to %s\", USER2));\n+        conn.execute(format(\"grant execute on procedure SYSCS_UTIL.INVALIDATE_DICTIONARY_CACHE to %s\", USER1));\n+        conn.execute(format(\"grant execute on procedure SYSCS_UTIL.INVALIDATE_DICTIONARY_CACHE to %s\", USER2));\n+\n+        conn.setAutoCommit(false);\n+        conn.setSchema(SCHEMA.toUpperCase());\n+\n+        c1 = classWatcher.createConnection(\"U1\", \"U1\");\n+        c2 = classWatcher.createConnection(\"U2\", \"U2\");\n+        c1.setAutoCommit(false);\n+        c1.setSchema(SCHEMA.toUpperCase());\n+        c2.setAutoCommit(false);\n+        c2.setSchema(SCHEMA.toUpperCase());\n+    }\n+\n+    @After\n+    public void rollback() throws Exception{\n+        conn.rollback();\n+        //conn.reset();", "originalCommit": "4c9402f38993f2a9e622a0d4ec7562c84f69fa11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTA4MjQ3Ng==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r371082476", "bodyText": "Removed the commented code.", "author": "msirek", "createdAt": "2020-01-27T06:49:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE2MDE5Nw=="}], "type": "inlineReview"}, {"oid": "3ca022525e200e504d68b9d377a85e15bbfc8189", "url": "https://github.com/splicemachine/spliceengine/commit/3ca022525e200e504d68b9d377a85e15bbfc8189", "message": "DB-8883 Address review comments.", "committedDate": "2020-01-27T06:52:00Z", "type": "commit"}, {"oid": "492bcc740ab765f2eccdabd08314221183af4ed8", "url": "https://github.com/splicemachine/spliceengine/commit/492bcc740ab765f2eccdabd08314221183af4ed8", "message": "DB-8106 Fix synchronization issue.", "committedDate": "2020-01-27T16:18:50Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjkyMjkxNA==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r372922914", "bodyText": "What's this for?", "author": "dgomezferro", "createdAt": "2020-01-30T12:34:56Z", "path": "db-engine/src/main/java/com/splicemachine/db/impl/sql/catalog/DataDictionaryImpl.java", "diffHunk": "@@ -4013,11 +4017,20 @@ public String getTriggerActionString(\n             // Add the replacement code that accesses a value in the\n             // transition variable.\n             final int replacementOffset = newText.length();\n+            boolean isSetTarget = false;\n+            if (actionStmt instanceof SetNode) {\n+                String regex    =   \"(^set[\\\\s]+$)|([\\\\s]+set[\\\\s]+$)|(,[\\\\s]*$)\";", "originalCommit": "492bcc740ab765f2eccdabd08314221183af4ed8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzExMzI3OQ==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r373113279", "bodyText": "This is for the SET statement to change the column values in the trigger NEW row.  Firing those in different orders may change the final result, so they can't be run concurrently.", "author": "msirek", "createdAt": "2020-01-30T18:19:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjkyMjkxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzAzMzU0OQ==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r373033549", "bodyText": "Having all these LCCs around doesn't seem like a good thing. Does trigger execution require both for some specific reason or is it that it just didn't work without both? Context handling is very messy in general and I feel we are making it even worse, but I don't have specific advice on how to make it better. We'd need someone to spend a significant amount of time going through it and trying to come up with a simpler design.", "author": "dgomezferro", "createdAt": "2020-01-30T15:54:14Z", "path": "db-engine/src/main/java/com/splicemachine/db/impl/sql/execute/TriggerEventActivator.java", "diffHunk": "@@ -31,49 +31,78 @@\n \n package com.splicemachine.db.impl.sql.execute;\n \n-import java.util.ArrayList;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Vector;\n-\n import com.splicemachine.db.catalog.UUID;\n import com.splicemachine.db.iapi.error.StandardException;\n+import com.splicemachine.db.iapi.jdbc.ConnectionContext;\n+import com.splicemachine.db.iapi.services.context.ContextService;\n import com.splicemachine.db.iapi.services.io.FormatableBitSet;\n import com.splicemachine.db.iapi.sql.Activation;\n+import com.splicemachine.db.iapi.sql.conn.ConnectionUtil;\n import com.splicemachine.db.iapi.sql.conn.LanguageConnectionContext;\n import com.splicemachine.db.iapi.sql.conn.StatementContext;\n import com.splicemachine.db.iapi.sql.dictionary.TriggerDescriptor;\n import com.splicemachine.db.iapi.sql.execute.CursorResultSet;\n \n+import java.sql.SQLException;\n+import java.util.*;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+import java.util.function.Function;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+import static com.splicemachine.db.impl.sql.execute.TriggerExecutionContext.pushLanguageConnectionContextToCM;\n+\n /**\n  * Responsible for firing a trigger or set of triggers based on an event.\n  */\n public class TriggerEventActivator {\n \n-    private LanguageConnectionContext lcc;\n     private TriggerInfo triggerInfo;\n     private TriggerExecutionContext tec;\n     private Map<TriggerEvent, List<GenericTriggerExecutor>> statementExecutorsMap = new HashMap<>();\n-    private Map<TriggerEvent, List<GenericTriggerExecutor>> rowExecutorsMap = new HashMap<>();\n+    private Map<TriggerEvent, List<TriggerDescriptor>> rowExecutorsMap = new HashMap<>();\n+    private Map<TriggerEvent, List<TriggerDescriptor>> rowConcurrentExecutorsMap = new HashMap<>();\n     private Activation activation;\n+    private ConnectionContext connectionContext;\n     private String statementText;\n     private UUID tableId;\n     private String tableName;\n-    private boolean tecPushed;\n+    private boolean triggerExecutionContextPushed;\n+    private boolean executionStmtValidatorPushed;\n+\n+    // getLcc() may return a different LanguageConnectionContext at the time\n+    // we pop the triggerExecutionContext and executionStmtValidator, versus\n+    // at the time they were pushed.  Saving the original \"LCC\" at the time of\n+    // the push ensures that we pop from the correct LCC.  We sometimes need to\n+    // save two versions LCCs because we may push to the LCC in the activation,\n+    // and also to the LCC stored in the current ContextManager, if they happen\n+    // to be different.  Trigger execution requires that both the activation and\n+    // the current ContextManager both have a triggerExecutionContext.\n+    private LanguageConnectionContext esvLCC1;\n+    private LanguageConnectionContext esvLCC2;\n+    private LanguageConnectionContext tecLCC1;", "originalCommit": "492bcc740ab765f2eccdabd08314221183af4ed8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzEyNDU5Ng==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r373124596", "bodyText": "Yes it is messy.  The ContextManager doesn't seem well designed for threading.  The ExecutionStmtValidator is required to detect if we're doing DDL on a trigger table.  The TriggerExecutionContext is required to be in both the LCC of the Activation and of the active ContextManager for proper trigger execution.  A lot of the time the Activation and the ContextManager share the same LCC, which is what we want.  But sometimes the ContextManager's LCC is pushed in someplace unexpected and we end up with a mismatch.  I think the whole ContextManager logic should probably be revisited and maybe rewritten.  I had tried some things to add more synchronization or use different data structures, e.g. ConcurrentHashMap in place of HashMap, but that either caused the database to run too slowly or caused hangs or other failures.", "author": "msirek", "createdAt": "2020-01-30T18:42:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzAzMzU0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzA1Mzg0Mw==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r373053843", "bodyText": "This branch is always going to be picked", "author": "dgomezferro", "createdAt": "2020-01-30T16:27:10Z", "path": "splice_machine/src/main/java/com/splicemachine/derby/impl/sql/execute/operations/TriggerHandler.java", "diffHunk": "@@ -147,37 +316,89 @@ public void firePendingAfterTriggers(Callable<Void> flushCallback) throws Except\n          * Which is what we want. Check constraints before firing after triggers. */\n         try {\n             flushCallback.call();\n+            if (getTriggerTempTableflushCallback() != null)\n+                getTriggerTempTableflushCallback().call();\n         } catch (Exception e) {\n             pendingAfterRows.clear();\n             throw e;\n         }\n \n-        for (ExecRow flushedRow : pendingAfterRows) {\n-            fireAfterRowTriggers(flushedRow);\n+        if (!hasAfterRow)\n+            return;\n+\n+        List<Future<Void>> futures = new ArrayList<>();\n+\n+        // The LCC can't be shared amongst threads, so\n+        // only use one level of concurrency for now.\n+        if (true || pendingAfterRows.size() <= 1) {", "originalCommit": "492bcc740ab765f2eccdabd08314221183af4ed8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzExNTUwMg==", "url": "https://github.com/splicemachine/spliceengine/pull/3124#discussion_r373115502", "bodyText": "That's correct.  The else branch results in sharing of an LCC between threads which is not allowed.  I kept the code in as a reminder of a potential improvement, in case we find a way to enable the else branch in the future.  We could remove the else branch if we want to keep the code clean.", "author": "msirek", "createdAt": "2020-01-30T18:24:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzA1Mzg0Mw=="}], "type": "inlineReview"}, {"oid": "3b50638ef4c912029fc894d04d39a0774aa6deac", "url": "https://github.com/splicemachine/spliceengine/commit/3b50638ef4c912029fc894d04d39a0774aa6deac", "message": "Merge branch 'master' into DB-8883_final", "committedDate": "2020-01-30T18:46:19Z", "type": "commit"}]}