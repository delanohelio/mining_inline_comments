{"pr_number": 3892, "pr_title": "DB-9425 Reduce scale of a result decimal type when necessary", "pr_createdAt": "2020-07-27T10:35:31Z", "pr_url": "https://github.com/splicemachine/spliceengine/pull/3892", "timeline": [{"oid": "1a706716594ea8156c8f62f2be4d53eea3b33c36", "url": "https://github.com/splicemachine/spliceengine/commit/1a706716594ea8156c8f62f2be4d53eea3b33c36", "message": "DB-9425 Reduce scale of a result decimal type when necessary", "committedDate": "2020-07-27T11:08:01Z", "type": "commit"}, {"oid": "1a706716594ea8156c8f62f2be4d53eea3b33c36", "url": "https://github.com/splicemachine/spliceengine/commit/1a706716594ea8156c8f62f2be4d53eea3b33c36", "message": "DB-9425 Reduce scale of a result decimal type when necessary", "committedDate": "2020-07-27T11:08:01Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTUwMzg4OQ==", "url": "https://github.com/splicemachine/spliceengine/pull/3892#discussion_r461503889", "bodyText": "i can't see immediately if this covers all the cases above. what i do see is that you don't use + or -, so that code is not tested.\ncan we have, additional to this, something for sum, for times, for divide separated?", "author": "martinrupp", "createdAt": "2020-07-28T11:16:06Z", "path": "splice_machine/src/test/java/com/splicemachine/db/impl/sql/compile/DecimalIT.java", "diffHunk": "@@ -677,4 +684,17 @@ public void testPreparedStatementRetainsFractionalDigits() throws Exception {\n                 \"14.51000 |\";\n         testQuery(sqlText, expected, methodWatcher);\n     }\n+\n+    // DB-9425\n+    @Test\n+    public void testReduceFractionalDigitsForIntegralPart() throws Exception {\n+        String sqlText = String.format(\"select cast(COALESCE(((quantity/units) * ( price / units)* cast(factor AS decimal(10,2)) ),0 ) AS NUMERIC(31,10))\\n\" +\n+                \"from DB_9425_TBL --splice-properties useSpark=%s\", useSpark);\n+\n+        String expected = \"1              |\\n\" +\n+                \"-----------------------------\\n\" +\n+                \"3112011525395705.4789182174 |\";\n+\n+        testQuery(sqlText, expected, methodWatcher);\n+    }", "originalCommit": "1a706716594ea8156c8f62f2be4d53eea3b33c36", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0OTcwMg==", "url": "https://github.com/splicemachine/spliceengine/pull/3892#discussion_r461949702", "bodyText": "When trying to build tests for individual arithmetic operators, I actually found something interesting in our way of deducing division result precision and scale. I document it in the code.\nBut because of this special thing, I have to follow SQL Server's rules of reducing scale and cannot make it more strict. As a result, we lose scale digits more often and small error accumulates. A lot more tests fail now and I'm trying to get the results from SQL Server for those queries.", "author": "ascend1", "createdAt": "2020-07-28T23:26:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTUwMzg4OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjI1MjQxMQ==", "url": "https://github.com/splicemachine/spliceengine/pull/3892#discussion_r462252411", "bodyText": "I end up with implementing SQL Server's scale reduction rules and fixing our result type precision/scale of division. In this way, TPC-H results are correct and only a few tests need to be adapted. Seems to be the best approach so far.\nAnd separate tests on sum, times, and divide are added.", "author": "ascend1", "createdAt": "2020-07-29T12:14:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTUwMzg4OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTg4NDAzMg==", "url": "https://github.com/splicemachine/spliceengine/pull/3892#discussion_r461884032", "bodyText": "I think PLUS_OP should be added here similar to MINUS_OP.", "author": "yxia92", "createdAt": "2020-07-28T21:15:18Z", "path": "db-engine/src/main/java/com/splicemachine/db/impl/sql/compile/NumericTypeCompiler.java", "diffHunk": "@@ -364,6 +364,53 @@ else if (typeId.isBigIntTypeId() &&\n \t\t\t}\n \t\t\telse if (typeId.isDecimalTypeId())\n \t\t\t{\n+\t\t\t\t/* DB-9425\n+\t\t\t\t * Make sure we still have enough digits for the integral part.\n+\t\t\t\t * Reduce scale when necessary, or leave it when not possible.\n+\t\t\t\t */\n+\t\t\t\t{\n+\t\t\t\t\tint lprec = leftType.getPrecision();\n+\t\t\t\t\tint lscale = leftType.getScale();\n+\t\t\t\t\tint rprec = rightType.getPrecision();\n+\t\t\t\t\tint rscale = rightType.getScale();\n+\t\t\t\t\tint integralNumDigits;\n+\n+\t\t\t\t\tswitch (operator) {\n+\t\t\t\t\t\tcase TypeCompiler.SUM_OP:\n+\t\t\t\t\t\tcase TypeCompiler.MINUS_OP:", "originalCommit": "1a706716594ea8156c8f62f2be4d53eea3b33c36", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjE2NTE5NQ==", "url": "https://github.com/splicemachine/spliceengine/pull/3892#discussion_r462165195", "bodyText": "Yes, it was a mistake. It should be PLUS_OP, not SUM_OP.", "author": "ascend1", "createdAt": "2020-07-29T09:28:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTg4NDAzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTg4NTU4Nw==", "url": "https://github.com/splicemachine/spliceengine/pull/3892#discussion_r461885587", "bodyText": "should it be rscale instead of rprec?", "author": "yxia92", "createdAt": "2020-07-28T21:18:30Z", "path": "db-engine/src/main/java/com/splicemachine/db/impl/sql/compile/NumericTypeCompiler.java", "diffHunk": "@@ -364,6 +364,53 @@ else if (typeId.isBigIntTypeId() &&\n \t\t\t}\n \t\t\telse if (typeId.isDecimalTypeId())\n \t\t\t{\n+\t\t\t\t/* DB-9425\n+\t\t\t\t * Make sure we still have enough digits for the integral part.\n+\t\t\t\t * Reduce scale when necessary, or leave it when not possible.\n+\t\t\t\t */\n+\t\t\t\t{\n+\t\t\t\t\tint lprec = leftType.getPrecision();\n+\t\t\t\t\tint lscale = leftType.getScale();\n+\t\t\t\t\tint rprec = rightType.getPrecision();\n+\t\t\t\t\tint rscale = rightType.getScale();\n+\t\t\t\t\tint integralNumDigits;\n+\n+\t\t\t\t\tswitch (operator) {\n+\t\t\t\t\t\tcase TypeCompiler.SUM_OP:\n+\t\t\t\t\t\tcase TypeCompiler.MINUS_OP:\n+\t\t\t\t\t\t\tboolean addOne = (lprec != maxPrecision && rprec != maxPrecision);\n+\t\t\t\t\t\t\tintegralNumDigits = Math.max(lprec - lscale, rprec - rscale) + (addOne ? 1 : 0);\n+\t\t\t\t\t\t\tif (integralNumDigits <= precision && integralNumDigits + scale > precision) {\n+\t\t\t\t\t\t\t\tscale = precision - integralNumDigits;\n+\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t\tbreak;\n+\t\t\t\t\t\tcase TypeCompiler.TIMES_OP: {\n+\t\t\t\t\t\t\tint fullScale = lscale + rscale;\n+\t\t\t\t\t\t\tint fullPrec = lprec + rprec + 1;\n+\t\t\t\t\t\t\tintegralNumDigits = fullPrec - fullScale;\n+\t\t\t\t\t\t\tif (integralNumDigits <= precision &&\n+\t\t\t\t\t\t\t\tintegralNumDigits + scale > precision && scale > MIN_DECIMAL_DIVIDE_SCALE &&\n+\t\t\t\t\t\t\t    precision - integralNumDigits >= MIN_DECIMAL_DIVIDE_SCALE) {\n+\t\t\t\t\t\t\t\tscale = precision - integralNumDigits;\n+\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t\tbreak;\n+\t\t\t\t\t\t}\n+\t\t\t\t\t\tcase TypeCompiler.DIVIDE_OP: {\n+\t\t\t\t\t\t\tif (rightTypeId.isDecimalTypeId()) {\n+\t\t\t\t\t\t\t\tintegralNumDigits = lprec - lscale + rprec;", "originalCommit": "1a706716594ea8156c8f62f2be4d53eea3b33c36", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTg5NTE3NQ==", "url": "https://github.com/splicemachine/spliceengine/pull/3892#discussion_r461895175", "bodyText": "It seems that for the division precision and scale computation, the logic in getScale() and getPrecision() are not consistent.\nIn getPrecision():\n\t\t\tval = Math.min(maxPrecision,\n\t\t\t\t\t\t   this.getScale(operator, leftType, rightType) + lprec - lscale + rprec);\n\nIn getScale():\n\t\t\t\tval = Math.max(maxPrecision - lprec + lscale - rscale,\n\t\t\t\t\t\tMIN_DECIMAL_DIVIDE_SCALE);\n\nI think the formula in getPrecision should be changed to\n\t\t\tval = Math.min(maxPrecision,\n\t\t\t\t\t\t   this.getScale(operator, leftType, rightType) + lprec - lscale + rscale);\n\nto be consistent with getScale().", "author": "yxia92", "createdAt": "2020-07-28T21:38:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTg4NTU4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjE3Mzg5MQ==", "url": "https://github.com/splicemachine/spliceengine/pull/3892#discussion_r462173891", "bodyText": "This is the mystery part and I think it was done like this on purpose. The idea seems to be always use maxPrecision for division and leave all free digits to scale. Let's take a closer look:\nThe way we get scale for division, is to calculate the number of digits needed for the integral part (lprec - lscale + rscale), and subtract it from maxPrecision. When getting precision, we add to scale a term lprec - lscale + rprec that is always GE than the integral part, so it will be always maxPrecision in the end. This change was done in implementing Decimal 38. The logic of getting scale for division was not like this, and we can see that from the old comment.\nChanging the logic back to the old comment or the SQL server way causes quite many tests to fail, including TPCH ITs. I'm examining the failing tests one by one.", "author": "ascend1", "createdAt": "2020-07-29T09:43:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTg4NTU4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjI1NjQxOA==", "url": "https://github.com/splicemachine/spliceengine/pull/3892#discussion_r462256418", "bodyText": "I finally get the root cause of test failures: SQL Server's MIN_DECIMAL_DIVIDE_SCALE = 6, but we set it to 4, and I was using 4 in multiplication case, too. That causes TPC-H queries return wrong results.\nI fixed this part and also revert the logic of getPrecision() for division according to the old comment. Now only a few tests need to be adapted.", "author": "ascend1", "createdAt": "2020-07-29T12:21:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTg4NTU4Nw=="}], "type": "inlineReview"}, {"oid": "b44a57eafea12b7e2da1682e25ebd6214e451054", "url": "https://github.com/splicemachine/spliceengine/commit/b44a57eafea12b7e2da1682e25ebd6214e451054", "message": "DB-9425 Fix division result type precision/scale", "committedDate": "2020-07-29T11:57:49Z", "type": "commit"}, {"oid": "207e319c0b9aa6d90177ef0a67aae8f0f659d096", "url": "https://github.com/splicemachine/spliceengine/commit/207e319c0b9aa6d90177ef0a67aae8f0f659d096", "message": "DB-9425 Make comments correct", "committedDate": "2020-07-29T12:10:10Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjUxMjcxOA==", "url": "https://github.com/splicemachine/spliceengine/pull/3892#discussion_r462512718", "bodyText": "Now that you introduced MIN_DECIMAL_MULTIPLICATION_SCALE, would there be an impact on the below code which looks at MIN_DECIMAL_DIVIDE_SCALE only. Could you double check the effect of your change on it:\n\t\t\t\t// Use high precision for decimals, so we don't overflow.\n\t\t\t\t// But don't use max precision to leave room for 4 digits to\n\t\t\t\t// the right of the decimal place for operations like AVG.\n\t\t\t\t// For the old client, use the old size of 31 for consistent behavior.\n\t\t\t\tint scaleAllowance = Math.max(0, MIN_DECIMAL_DIVIDE_SCALE - Math.max(scale, 0));\n\t\t\t\tint maxImplicitCastPrecision = precision > OLD_MAX_DECIMAL_PRECISION_SCALE ||\n\t\t\t\t                               supportsDecimal38()  ?\n\t\t\t\t      MAX_DECIMAL_PRECISION_WITH_RESERVE_FOR_SCALE + scaleAllowance :\n\t\t\t\t      OLD_MAX_DECIMAL_PRECISION_SCALE;\n\t\t\t\tif (precision < maxImplicitCastPrecision)\n\t\t\t\t    precision = maxImplicitCastPrecision;\n\nHowever, I have some reservation about this code to use the highest precision possible for an operation on decimals(See DB-9639).", "author": "yxia92", "createdAt": "2020-07-29T18:47:24Z", "path": "db-engine/src/main/java/com/splicemachine/db/impl/sql/compile/NumericTypeCompiler.java", "diffHunk": "@@ -364,6 +364,57 @@ else if (typeId.isBigIntTypeId() &&\n \t\t\t}\n \t\t\telse if (typeId.isDecimalTypeId())\n \t\t\t{\n+\t\t\t\t/* DB-9425\n+\t\t\t\t * Make sure we still have enough digits for the integral part.\n+\t\t\t\t * Reduce scale when necessary, or leave it when not possible.\n+\t\t\t\t * Rules follow SQL Server 2019:\n+\t\t\t\t * https://docs.microsoft.com/en-us/sql/t-sql/data-types/precision-scale-and-length-transact-sql?view=sql-server-ver15\n+\t\t\t\t */\n+\t\t\t\t{\n+\t\t\t\t\tint lprec = leftType.getPrecision();\n+\t\t\t\t\tint lscale = leftType.getScale();\n+\t\t\t\t\tint rprec = rightType.getPrecision();\n+\t\t\t\t\tint rscale = rightType.getScale();\n+\t\t\t\t\tint integralNumDigits;\n+\n+\t\t\t\t\tswitch (operator) {\n+\t\t\t\t\t\tcase TypeCompiler.PLUS_OP:\n+\t\t\t\t\t\tcase TypeCompiler.MINUS_OP:\n+\t\t\t\t\t\t\tboolean addOne = (lprec != maxPrecision && rprec != maxPrecision);\n+\t\t\t\t\t\t\tintegralNumDigits = Math.max(lprec - lscale, rprec - rscale) + (addOne ? 1 : 0);\n+\t\t\t\t\t\t\tif (integralNumDigits <= precision && integralNumDigits + scale > precision) {\n+\t\t\t\t\t\t\t\tscale = precision - integralNumDigits;\n+\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t\tbreak;\n+\t\t\t\t\t\tcase TypeCompiler.TIMES_OP: {\n+\t\t\t\t\t\t\tintegralNumDigits = lprec + rprec + 1 - lscale - rscale;\n+\t\t\t\t\t\t\t/* In SQL Server, MIN_DECIMAL_DIVIDE_SCALE = 6. In splice, it's 4.\n+\t\t\t\t\t\t\t * We have to use 6 in multiplication case, otherwise TPC-H results would be\n+\t\t\t\t\t\t\t * off too much because we round intermediate results too early.\n+\t\t\t\t\t\t\t */\n+\t\t\t\t\t\t\tif (integralNumDigits < maxPrecision - MIN_DECIMAL_MULTIPLICATION_SCALE) {\n+\t\t\t\t\t\t\t\tscale = Math.min(scale, maxPrecision - integralNumDigits);\n+\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t\telse if (scale > MIN_DECIMAL_MULTIPLICATION_SCALE) {", "originalCommit": "207e319c0b9aa6d90177ef0a67aae8f0f659d096", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkxMTcwMA==", "url": "https://github.com/splicemachine/spliceengine/pull/3892#discussion_r462911700", "bodyText": "Right, this part basically promotes the precision to at least 34. If the determined scale is smaller than 4, then there would be some digits allowance for the integral part, thus total precision is further increased.\nMIN_DECIMAL_MULTIPLICATION_SCALE should have no impact here. If the initial scale <= 6, say 3, then there will be no scale reduction in case of an multiplication. This part sees that there is 4-3=1 digit allowance for the integral part, and promote the type to (35,3), just as before this change.\nIf the initial scale was bigger than 6, we may reduce it but it would never be smaller than 6. Or we don't reduce it at all. In both cases, there would be no scale allowance. So if the initial precision was smaller than 34, final type would be (34,scale), otherwise it's (precision,scale).\nKey idea is, when we reach this part, we know that we either have enough digits for integral part (scale reduced) or we cannot prevent overflow (scale untouched). In both cases, increasing precision do not affect correctness.\nBUT!!!!!\nThis logic seems very strange to me. In my opinion, we should not blindly increase precision but to deduce it properly. If (20,8) is enough, then we should not increase it to (34,8).", "author": "ascend1", "createdAt": "2020-07-30T10:46:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjUxMjcxOA=="}], "type": "inlineReview"}]}