{"pr_number": 13604, "pr_title": "[FLINK-19585][tests] Waiting for job to run before savepointing in UnalignedCheckpointCompatibilityITCase.", "pr_createdAt": "2020-10-13T05:38:50Z", "pr_url": "https://github.com/apache/flink/pull/13604", "timeline": [{"oid": "a7dfc27d1536928c114b7e065865fb5e156a7f65", "url": "https://github.com/apache/flink/commit/a7dfc27d1536928c114b7e065865fb5e156a7f65", "message": "[FLINK-19585][minicluster] Use SavepointRestoreSettings of StreamGraph while creating JobGraph.", "committedDate": "2020-10-13T22:02:11Z", "type": "forcePushed"}, {"oid": "f8b8123bdb849188383542ba20927f2118a34c70", "url": "https://github.com/apache/flink/commit/f8b8123bdb849188383542ba20927f2118a34c70", "message": "[FLINK-19585][minicluster] Use SavepointRestoreSettings of StreamGraph while creating JobGraph.", "committedDate": "2020-10-14T06:39:43Z", "type": "forcePushed"}, {"oid": "755d9eb83e7fa1f497fe083850ce369d8d1d5940", "url": "https://github.com/apache/flink/commit/755d9eb83e7fa1f497fe083850ce369d8d1d5940", "message": "[FLINK-19585][tests] Waiting for all tasks to run before savepointing in UnalignedCheckpointCompatibilityITCase.", "committedDate": "2020-10-14T06:51:47Z", "type": "forcePushed"}, {"oid": "f573014ea1efca40fbd14f2880fd7ce922559dc9", "url": "https://github.com/apache/flink/commit/f573014ea1efca40fbd14f2880fd7ce922559dc9", "message": "[FLINK-19585][minicluster] Use SavepointRestoreSettings of StreamGraph while creating JobGraph.\n\nThere is currently no way to start from savepoints while using MiniCluster. The cluster config cannot be used (and would be a mismatch) because it's overridden by MiniClusterPipelineExecutorServiceLoader#createConfiguration.\nHowever, the jobgraph that is being generated in MiniClusterPipelineExecutorServiceLoader#MiniClusterExecutor only uses this configuration to translate the Pipeline/StreamGraph. In production code, savepoint restore settings are usually applied last and taken from the StreamGraph.", "committedDate": "2020-10-14T06:56:04Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc1NjU0Mw==", "url": "https://github.com/apache/flink/pull/13604#discussion_r504756543", "bodyText": "It's generally an anti-pattern in tests to \"just sleep for a while\". Can't you use the backpressure monitoring to wait until there is backpressure? (or would that take longer?)", "author": "rmetzger", "createdAt": "2020-10-14T15:08:56Z", "path": "flink-tests/src/test/java/org/apache/flink/test/checkpointing/UnalignedCheckpointCompatibilityITCase.java", "diffHunk": "@@ -107,28 +119,55 @@ public void test() throws Exception {\n \t}\n \n \tprivate Tuple2<String, Map<String, Object>> runAndTakeSavepoint() throws Exception {\n-\t\tJobClient jobClient = submitJobInitially(env(startAligned, 0, emptyMap()));\n-\t\tThread.sleep(FIRST_RUN_EL_COUNT * FIRST_RUN_BACKPRESSURE_MS); // wait for all tasks to run and some backpressure from sink\n-\t\tFuture<Map<String, Object>> accFuture = jobClient.getAccumulators();\n-\t\tFuture<String> savepointFuture = jobClient.stopWithSavepoint(false, tempFolder().toURI().toString());\n-\t\treturn new Tuple2<>(savepointFuture.get(), accFuture.get());\n+\t\treturn withCluster(new Configuration(), miniCluster -> {\n+\t\t\tJobClient jobClient = submitJobInitially(env(startAligned, 0));\n+\t\t\twaitForAllTaskRunning(miniCluster, jobClient.getJobID(), Deadline.fromNow(Duration.of(30, ChronoUnit.SECONDS)));\n+\t\t\tThread.sleep(FIRST_RUN_BACKPRESSURE_MS); // wait for some backpressure from sink", "originalCommit": "755d9eb83e7fa1f497fe083850ce369d8d1d5940", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDkxMzA3NA==", "url": "https://github.com/apache/flink/pull/13604#discussion_r504913074", "bodyText": "The original test used sleeping for waiting until all jobs are running (hence this bug). However, whether backpressure build up or not is quite irrelevant for the semantics of the test. It's just testing that some outputs are present. I could probably wait on the output metric.\nHowever, it feels like LOTS of such building blocks are missing and should probably be at a more general place. (I tried to do that with waitForAllTaskRunning but it's easily overlooked. Ideally it should be in MiniCluster).", "author": "AHeise", "createdAt": "2020-10-14T19:15:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc1NjU0Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDkxNTI5OQ==", "url": "https://github.com/apache/flink/pull/13604#discussion_r504915299", "bodyText": "Maybe such utilities should also be made available to the user, for writing their own tests.\nThere are a lot of very useful utilities everywhere in our tests, but it's difficult to discover them. Ideally we have them categorized and standardized somewhere.", "author": "rmetzger", "createdAt": "2020-10-14T19:19:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc1NjU0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc2MjQ4NA==", "url": "https://github.com/apache/flink/pull/13604#discussion_r504762484", "bodyText": "Why are you not reusing the cluster for the different tests / jobs?", "author": "rmetzger", "createdAt": "2020-10-14T15:16:37Z", "path": "flink-tests/src/test/java/org/apache/flink/test/checkpointing/UnalignedCheckpointCompatibilityITCase.java", "diffHunk": "@@ -107,28 +119,55 @@ public void test() throws Exception {\n \t}\n \n \tprivate Tuple2<String, Map<String, Object>> runAndTakeSavepoint() throws Exception {\n-\t\tJobClient jobClient = submitJobInitially(env(startAligned, 0, emptyMap()));\n-\t\tThread.sleep(FIRST_RUN_EL_COUNT * FIRST_RUN_BACKPRESSURE_MS); // wait for all tasks to run and some backpressure from sink\n-\t\tFuture<Map<String, Object>> accFuture = jobClient.getAccumulators();\n-\t\tFuture<String> savepointFuture = jobClient.stopWithSavepoint(false, tempFolder().toURI().toString());\n-\t\treturn new Tuple2<>(savepointFuture.get(), accFuture.get());\n+\t\treturn withCluster(new Configuration(), miniCluster -> {\n+\t\t\tJobClient jobClient = submitJobInitially(env(startAligned, 0));\n+\t\t\twaitForAllTaskRunning(miniCluster, jobClient.getJobID(), Deadline.fromNow(Duration.of(30, ChronoUnit.SECONDS)));\n+\t\t\tThread.sleep(FIRST_RUN_BACKPRESSURE_MS); // wait for some backpressure from sink\n+\n+\t\t\tFuture<Map<String, Object>> accFuture = jobClient.getAccumulators();\n+\t\t\tFuture<String> savepointFuture = jobClient.stopWithSavepoint(false, tempFolder().toURI().toString());\n+\t\t\treturn new Tuple2<>(savepointFuture.get(), accFuture.get());\n+\t\t});\n \t}\n \n \tprivate Tuple2<String, Map<String, Object>> runAndTakeExternalCheckpoint() throws Exception {\n \t\tFile folder = tempFolder();\n-\t\tJobClient jobClient = submitJobInitially(externalCheckpointEnv(startAligned, folder, 100));\n-\t\tFile metadata = waitForChild(waitForChild(waitForChild(folder))); // structure: root/attempt/checkpoint/_metadata\n-\t\tcancelJob(jobClient);\n-\t\treturn new Tuple2<>(metadata.getParentFile().toString(), emptyMap());\n+\t\tfinal Configuration conf = new Configuration();\n+\t\tconf.set(CHECKPOINTS_DIRECTORY, folder.toURI().toString());\n+\t\t// prevent deletion of checkpoint files while it's being checked and used\n+\t\tconf.set(MAX_RETAINED_CHECKPOINTS, Integer.MAX_VALUE);\n+\t\treturn withCluster(conf,\n+\t\t\tminiCluster -> {\n+\t\t\t\tJobClient jobClient = submitJobInitially(externalCheckpointEnv(startAligned, 100));\n+\t\t\t\tFile metadata = waitForChild(waitForChild(waitForChild(folder))); // structure: root/attempt/checkpoint/_metadata\n+\t\t\t\tcancelJob(jobClient);\n+\t\t\t\treturn new Tuple2<>(metadata.getParentFile().toString(), emptyMap());\n+\t\t\t});\n \t}\n \n \tprivate static JobClient submitJobInitially(StreamExecutionEnvironment env) throws Exception {\n \t\treturn env.executeAsync(dag(FIRST_RUN_EL_COUNT, true, FIRST_RUN_BACKPRESSURE_MS, env));\n \t}\n \n \tprivate Map<String, Object> runFromSavepoint(String path, boolean isAligned, int totalCount) throws Exception {\n-\t\tStreamExecutionEnvironment env = env(isAligned, 50, Collections.singletonMap(SAVEPOINT_PATH, path));\n-\t\treturn env.execute(dag(totalCount, false, 0, env)).getJobExecutionResult().getAllAccumulatorResults();\n+\t\treturn withCluster(new Configuration(), miniCluster -> {\n+\t\t\tStreamExecutionEnvironment env = env(isAligned, 50);\n+\t\t\tfinal StreamGraph streamGraph = dag(totalCount, false, 0, env);\n+\t\t\tstreamGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(path));\n+\t\t\treturn env.execute(streamGraph).getJobExecutionResult().getAllAccumulatorResults();\n+\t\t});\n+\t}\n+\n+\tprivate <T> T withCluster(Configuration configuration,", "originalCommit": "755d9eb83e7fa1f497fe083850ce369d8d1d5940", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDkxMTU2NQ==", "url": "https://github.com/apache/flink/pull/13604#discussion_r504911565", "bodyText": "Good point. Originally, I needed to inject the configuration to restore from savepoints, but that didn't work. So I can probably leave a cluster per test. A global cluster would probably also work, I just need to make the TempFolder a class rule.", "author": "AHeise", "createdAt": "2020-10-14T19:12:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc2MjQ4NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDkxMTY2Ng==", "url": "https://github.com/apache/flink/pull/13604#discussion_r504911666", "bodyText": "Good point. Originally, I needed to inject the configuration to restore from savepoints, but that didn't work. So I can probably leave a cluster per test. A global cluster would probably also work, I just need to make the TempFolder a class rule.", "author": "AHeise", "createdAt": "2020-10-14T19:13:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc2MjQ4NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc3NzA2OA==", "url": "https://github.com/apache/flink/pull/13604#discussion_r504777068", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \tpublic static void waitForAllTaskRunning(MiniClusterResource miniCluster, JobID jobID, Deadline deadline) throws Exception {\n          \n          \n            \n            \t\ttry (final RestClusterClient<?> clusterClient = new RestClusterClient<Object>(\n          \n          \n            \n            \t\t\t\tminiCluster.getClientConfiguration(),\n          \n          \n            \n            \t\t\t\tStandaloneClusterId.getInstance())) {\n          \n          \n            \n            \t\t\tJobMessageParameters params = new JobMessageParameters();\n          \n          \n            \n            \t\t\tparams.jobPathParameter.resolve(jobID);\n          \n          \n            \n            \t\t\torg.apache.flink.runtime.testutils.CommonTestUtils.waitUntilCondition(() -> {\n          \n          \n            \n            \t\t\t\tfinal JobDetailsInfo jobDetailsInfo = clusterClient.sendRequest(\n          \n          \n            \n            \t\t\t\t\tJobDetailsHeaders.getInstance(),\n          \n          \n            \n            \t\t\t\t\tparams,\n          \n          \n            \n            \t\t\t\t\tEmptyRequestBody.getInstance()).get();\n          \n          \n            \n            \t\t\t\treturn jobDetailsInfo.getJobStatus() == JobStatus.RUNNING &&\n          \n          \n            \n            \t\t\t\t\tjobDetailsInfo.getJobVerticesPerState().get(ExecutionState.RUNNING) ==\n          \n          \n            \n            \t\t\t\t\t\tjobDetailsInfo.getJobVertexInfos().size();\n          \n          \n            \n            \t\t\t}, deadline, 500);\n          \n          \n            \n            \t\t}\n          \n          \n            \n            \t}\n          \n          \n            \n            \tpublic static void waitForAllTaskRunning(MiniCluster miniCluster, JobID jobID, Deadline deadline) throws Exception {\n          \n          \n            \n            \t\torg.apache.flink.runtime.testutils.CommonTestUtils.waitUntilCondition(() -> {\n          \n          \n            \n            \t\t\tAccessExecutionGraph ec = miniCluster.getExecutionGraph(jobID).get();\n          \n          \n            \n            \t\t\treturn ec.getState() == JobStatus.RUNNING && ec.getAllVertices()\n          \n          \n            \n            \t\t\t\t.values()\n          \n          \n            \n            \t\t\t\t.stream()\n          \n          \n            \n            \t\t\t\t.allMatch(jobVertex ->\n          \n          \n            \n            \t\t\t\t\tArrays.stream(jobVertex.getTaskVertices()).allMatch(task -> task.getExecutionState() == ExecutionState.RUNNING)\n          \n          \n            \n            \t\t\t\t);\n          \n          \n            \n            \t\t}, deadline);\n          \n          \n            \n            \t}", "author": "rmetzger", "createdAt": "2020-10-14T15:35:36Z", "path": "flink-test-utils-parent/flink-test-utils/src/main/java/org/apache/flink/test/util/TestBaseUtils.java", "diffHunk": "@@ -102,6 +116,24 @@ private static void verifyJvmOptions() {\n \t\t\t\t+ \"m\", heap > MINIMUM_HEAP_SIZE_MB - 50);\n \t}\n \n+\tpublic static void waitForAllTaskRunning(MiniClusterResource miniCluster, JobID jobID, Deadline deadline) throws Exception {\n+\t\ttry (final RestClusterClient<?> clusterClient = new RestClusterClient<Object>(\n+\t\t\t\tminiCluster.getClientConfiguration(),\n+\t\t\t\tStandaloneClusterId.getInstance())) {\n+\t\t\tJobMessageParameters params = new JobMessageParameters();\n+\t\t\tparams.jobPathParameter.resolve(jobID);\n+\t\t\torg.apache.flink.runtime.testutils.CommonTestUtils.waitUntilCondition(() -> {\n+\t\t\t\tfinal JobDetailsInfo jobDetailsInfo = clusterClient.sendRequest(\n+\t\t\t\t\tJobDetailsHeaders.getInstance(),\n+\t\t\t\t\tparams,\n+\t\t\t\t\tEmptyRequestBody.getInstance()).get();\n+\t\t\t\treturn jobDetailsInfo.getJobStatus() == JobStatus.RUNNING &&\n+\t\t\t\t\tjobDetailsInfo.getJobVerticesPerState().get(ExecutionState.RUNNING) ==\n+\t\t\t\t\t\tjobDetailsInfo.getJobVertexInfos().size();\n+\t\t\t}, deadline, 500);\n+\t\t}\n+\t}\n+", "originalCommit": "755d9eb83e7fa1f497fe083850ce369d8d1d5940", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc3NzM1OA==", "url": "https://github.com/apache/flink/pull/13604#discussion_r504777358", "bodyText": "Not sure about the code formatting, and I haven't tested it much. But I guess you get the idea.", "author": "rmetzger", "createdAt": "2020-10-14T15:36:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc3NzA2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDkxNDEwNg==", "url": "https://github.com/apache/flink/pull/13604#discussion_r504914106", "bodyText": "Hm Till actually proposed to use rest client, but I can't really see why your version wouldn't work.", "author": "AHeise", "createdAt": "2020-10-14T19:17:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc3NzA2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDkzMTUxOQ==", "url": "https://github.com/apache/flink/pull/13604#discussion_r504931519", "bodyText": "With your version, I can actually move it into flink-runtime CommonTestUtils.", "author": "AHeise", "createdAt": "2020-10-14T19:48:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc3NzA2OA=="}], "type": "inlineReview"}, {"oid": "2ae2677fac9f1e1fadcef3f236191950c23f82a1", "url": "https://github.com/apache/flink/commit/2ae2677fac9f1e1fadcef3f236191950c23f82a1", "message": "[FLINK-19585][tests] Waiting for all tasks to run before savepointing in UnalignedCheckpointCompatibilityITCase.", "committedDate": "2020-10-14T19:45:48Z", "type": "forcePushed"}, {"oid": "493263a69146fe8c801c25febbb5e972634f9379", "url": "https://github.com/apache/flink/commit/493263a69146fe8c801c25febbb5e972634f9379", "message": "[FLINK-19585][tests] Waiting for all tasks to run before savepointing in UnalignedCheckpointCompatibilityITCase.", "committedDate": "2020-10-14T19:47:58Z", "type": "forcePushed"}, {"oid": "2c46ee38b46372ba7e5fbe33d186b29b39a2a0e1", "url": "https://github.com/apache/flink/commit/2c46ee38b46372ba7e5fbe33d186b29b39a2a0e1", "message": "[FLINK-19585][tests] Waiting for all tasks to run before savepointing in UnalignedCheckpointCompatibilityITCase.", "committedDate": "2020-10-15T09:03:15Z", "type": "commit"}, {"oid": "2c46ee38b46372ba7e5fbe33d186b29b39a2a0e1", "url": "https://github.com/apache/flink/commit/2c46ee38b46372ba7e5fbe33d186b29b39a2a0e1", "message": "[FLINK-19585][tests] Waiting for all tasks to run before savepointing in UnalignedCheckpointCompatibilityITCase.", "committedDate": "2020-10-15T09:03:15Z", "type": "forcePushed"}]}