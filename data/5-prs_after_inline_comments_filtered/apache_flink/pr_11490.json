{"pr_number": 11490, "pr_title": "[FLINK-15579][table-planner-blink] UpsertStreamTableSink should work on batch mode", "pr_createdAt": "2020-03-23T11:06:49Z", "pr_url": "https://github.com/apache/flink/pull/11490", "timeline": [{"oid": "d1a5a4372582555948fb210c33efe3699822089e", "url": "https://github.com/apache/flink/commit/d1a5a4372582555948fb210c33efe3699822089e", "message": "[FLINK-15579][table-planner-blink] Fix UpsertStreamTableSink support and add tests", "committedDate": "2020-03-23T11:13:52Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjQ5MjUyNw==", "url": "https://github.com/apache/flink/pull/11490#discussion_r396492527", "bodyText": "We should avoid creating too many testing TableSource. You can use VALUES instead.\nINSERT INTO USER_RESULT\n  SELECT user_name, score\n  FROM (VALUES (1, 'Bob'), (22, 'Tom'), (42, 'Kim'), (42, 'Kim'), (42, 'Kim'), (1, 'Bob'))\n    AS UserCountTable(score, user_name)", "author": "wuchong", "createdAt": "2020-03-23T14:29:16Z", "path": "flink-connectors/flink-jdbc/src/test/java/org/apache/flink/api/java/io/jdbc/JDBCUpsertTableSinkITCase.java", "diffHunk": "@@ -210,4 +228,76 @@ public void testAppend() throws Exception {\n \t\t\t\tRow.of(20, 6, Timestamp.valueOf(\"1970-01-01 00:00:00.02\"))\n \t\t}, DB_URL, OUTPUT_TABLE2, new String[]{\"id\", \"num\", \"ts\"});\n \t}\n+\n+\t@Test\n+\tpublic void testBatchUpsert() throws Exception {\n+\t\tStreamExecutionEnvironment bsEnv = StreamExecutionEnvironment.getExecutionEnvironment();\n+\t\tEnvironmentSettings bsSettings = EnvironmentSettings.newInstance().useBlinkPlanner().inStreamingMode().build();\n+\t\tStreamTableEnvironment bsTableEnv = StreamTableEnvironment.create(bsEnv, bsSettings);\n+\t\tRowTypeInfo rt = (RowTypeInfo) Types.ROW_NAMED(new String[]{\"NAME\", \"SCORE\"}, Types.STRING, Types.LONG);\n+\t\tTable source = bsTableEnv.fromTableSource(new CollectionTableSource(generateRecords(2), rt));\n+\t\tbsTableEnv.registerTable(\"sourceTable\", source);\n+\t\tbsTableEnv.sqlUpdate(\n+\t\t\t\"CREATE TABLE USER_RESULT(\" +\n+\t\t\t\t\"NAME VARCHAR,\" +\n+\t\t\t\t\"SCORE BIGINT\" +\n+\t\t\t\t\") WITH ( \" +\n+\t\t\t\t\"'connector.type' = 'jdbc',\" +\n+\t\t\t\t\"'connector.url'='\" + DB_URL + \"',\" +\n+\t\t\t\t\"'connector.table' = '\" + OUTPUT_TABLE3 + \"'\" +\n+\t\t\t\t\")\");\n+\n+\t\tbsTableEnv.sqlUpdate(\"insert into USER_RESULT SELECT s.NAME, s.SCORE \" +\n+\t\t\t\"FROM sourceTable as s \");\n+\t\tbsTableEnv.execute(\"test\");\n+\n+\t\tcheck(new Row[] {\n+\t\t\tRow.of(\"a0\", 0L),\n+\t\t\tRow.of(\"a1\", 1L)\n+\t\t}, DB_URL, OUTPUT_TABLE3, new String[]{\"NAME\", \"SCORE\"});\n+\t}\n+\n+\tprivate List<Row> generateRecords(int numRecords) {\n+\t\tint arity = 2;\n+\t\tList<Row> res = new ArrayList<>(numRecords);\n+\t\tfor (long i = 0; i < numRecords; i++) {\n+\t\t\tRow row = new Row(arity);\n+\t\t\trow.setField(0, \"a\" + i);\n+\t\t\trow.setField(1, i);\n+\t\t\tres.add(row);\n+\t\t}\n+\t\treturn res;\n+\t}\n+\n+\tprivate static class CollectionTableSource extends InputFormatTableSource<Row> {", "originalCommit": "d1a5a4372582555948fb210c33efe3699822089e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "38222efd1cde395cc2110d4c799c9227e7f1e12b", "url": "https://github.com/apache/flink/commit/38222efd1cde395cc2110d4c799c9227e7f1e12b", "message": "[FLINK-15579][table-planner-blink] UpsertStreamTableSink should work on batch mode", "committedDate": "2020-03-25T02:26:09Z", "type": "commit"}, {"oid": "3d3ddb474eace1680157c2ccb826b8e6d8c593d0", "url": "https://github.com/apache/flink/commit/3d3ddb474eace1680157c2ccb826b8e6d8c593d0", "message": "[FLINK-15579][table-planner-blink] Fix UpsertStreamTableSink support and add tests", "committedDate": "2020-03-25T02:26:10Z", "type": "commit"}, {"oid": "3d3ddb474eace1680157c2ccb826b8e6d8c593d0", "url": "https://github.com/apache/flink/commit/3d3ddb474eace1680157c2ccb826b8e6d8c593d0", "message": "[FLINK-15579][table-planner-blink] Fix UpsertStreamTableSink support and add tests", "committedDate": "2020-03-25T02:26:10Z", "type": "forcePushed"}]}