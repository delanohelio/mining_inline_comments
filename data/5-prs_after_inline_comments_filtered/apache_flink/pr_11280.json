{"pr_number": 11280, "pr_title": "[FLINK-16377][table] Support inline user defined functions in expression dsl", "pr_createdAt": "2020-03-02T11:59:35Z", "pr_url": "https://github.com/apache/flink/pull/11280", "timeline": [{"oid": "f5de98e8347bd4652b3ba5f91cd09281d621a72a", "url": "https://github.com/apache/flink/commit/f5de98e8347bd4652b3ba5f91cd09281d621a72a", "message": "[FLINK-16377][table-api] Enable new type inference for functions called from Table API", "committedDate": "2020-03-02T12:03:44Z", "type": "forcePushed"}, {"oid": "69161e40e90e997a26f113cb6da10f7815ebbe0f", "url": "https://github.com/apache/flink/commit/69161e40e90e997a26f113cb6da10f7815ebbe0f", "message": "[FLINK-16377][table-api] Enable new type inference for functions called from Table API", "committedDate": "2020-03-02T15:36:37Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzIzNjAxMg==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397236012", "bodyText": "very nit: new line between the two sentences", "author": "twalthr", "createdAt": "2020-03-24T15:19:55Z", "path": "flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/api/Expressions.java", "diffHunk": "@@ -515,6 +516,14 @@ public static ApiExpression call(String path, Object... params) {\n \t\t\tArrays.stream(params).map(ApiExpressionUtils::objectToExpression).toArray(Expression[]::new)));\n \t}\n \n+\t/**\n+\t * A call to an unregistered, inline function. For functions that have been registered before and", "originalCommit": "69161e40e90e997a26f113cb6da10f7815ebbe0f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzIzODczOQ==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397238739", "bodyText": "Something is wrong with this JavaDoc. Can you verify all parenthesis?", "author": "twalthr", "createdAt": "2020-03-24T15:23:28Z", "path": "flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/expressions/ApiExpressionUtils.java", "diffHunk": "@@ -198,4 +204,48 @@ public static boolean isFunction(Expression expression, BuiltInFunctionDefinitio\n \t\t}\n \t\treturn false;\n \t}\n+\n+\t/**\n+\t * Extracts a {@link FunctionIdentifier} for the given {@link CallExpression}. If the call is an inline funcion\n+\t * ({@link CallExpression#getFunctionIdentifier()} returns empty)", "originalCommit": "69161e40e90e997a26f113cb6da10f7815ebbe0f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI0MjM3Mg==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397242372", "bodyText": "This case should not be supported. Either we are dealing with built-ins or user-defined functions.", "author": "twalthr", "createdAt": "2020-03-24T15:27:57Z", "path": "flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/expressions/ApiExpressionUtils.java", "diffHunk": "@@ -198,4 +204,48 @@ public static boolean isFunction(Expression expression, BuiltInFunctionDefinitio\n \t\t}\n \t\treturn false;\n \t}\n+\n+\t/**\n+\t * Extracts a {@link FunctionIdentifier} for the given {@link CallExpression}. If the call is an inline funcion\n+\t * ({@link CallExpression#getFunctionIdentifier()} returns empty)\n+\t * <ul>\n+\t *     <li>it uses {@link BuiltInFunctionDefinition#getName()} ()} for built in functions</li>\n+\t *     <li>it uses {@link UserDefinedFunction#functionIdentifier()} for user defined functions</li>\n+\t *     <li>it uses {@link FunctionDefinition#toString()} ()} for any other functions</li>", "originalCommit": "69161e40e90e997a26f113cb6da10f7815ebbe0f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI0OTA0Ng==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397249046", "bodyText": "should we merge this logic into BuiltInFunctionDefinition?", "author": "twalthr", "createdAt": "2020-03-24T15:36:22Z", "path": "flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/expressions/ApiExpressionUtils.java", "diffHunk": "@@ -198,4 +204,48 @@ public static boolean isFunction(Expression expression, BuiltInFunctionDefinitio\n \t\t}\n \t\treturn false;\n \t}\n+\n+\t/**\n+\t * Extracts a {@link FunctionIdentifier} for the given {@link CallExpression}. If the call is an inline funcion\n+\t * ({@link CallExpression#getFunctionIdentifier()} returns empty)\n+\t * <ul>\n+\t *     <li>it uses {@link BuiltInFunctionDefinition#getName()} ()} for built in functions</li>\n+\t *     <li>it uses {@link UserDefinedFunction#functionIdentifier()} for user defined functions</li>\n+\t *     <li>it uses {@link FunctionDefinition#toString()} ()} for any other functions</li>\n+\t * </ul>\n+\t */\n+\tpublic static FunctionIdentifier getFunctionIdentifier(CallExpression callExpression) {\n+\t\tif (callExpression.getFunctionIdentifier().isPresent()) {\n+\t\t\treturn callExpression.getFunctionIdentifier().get();\n+\t\t} else {\n+\t\t\treturn getInlineFunctionIdentifier(callExpression);\n+\t\t}\n+\t}\n+\n+\tprivate static FunctionIdentifier getInlineFunctionIdentifier(CallExpression callExpression) {\n+\t\tFunctionDefinition functionDefinition = callExpression.getFunctionDefinition();\n+\t\tif (functionDefinition instanceof BuiltInFunctionDefinition) {\n+\t\t\treturn FunctionIdentifier.of(((BuiltInFunctionDefinition) functionDefinition).getName());", "originalCommit": "69161e40e90e997a26f113cb6da10f7815ebbe0f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzY3NjIzMA==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397676230", "bodyText": "Not sure, theoretically BuiltInFunctionDefinition can also be registered in an arbitrary path. Then having a FunctionIdentifier in the function definition would be wrong. FunctionDefinition is not aware of the path it comes from. It can even be registered at multiple locations.\nAs far as I understand the difference between built-in and user defined functions is where the implementation comes from. For user defined functions the implementation comes from the definition whereas for bult-in it is looked up in the planner.", "author": "dawidwys", "createdAt": "2020-03-25T08:24:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI0OTA0Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzg4NDI3Mg==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397884272", "bodyText": "After an offline discussion, we concluded that all functions must come from the catalog manager and thus have an identifier except for inline functions.", "author": "twalthr", "createdAt": "2020-03-25T14:11:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI0OTA0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI1MDMyNg==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397250326", "bodyText": "can we call it \"arguments\" everywhere consistently? also in the call(..., params)", "author": "twalthr", "createdAt": "2020-03-24T15:38:04Z", "path": "flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/operations/CalculatedQueryOperation.java", "diffHunk": "@@ -33,34 +34,34 @@\n  * Describes a relational operation that was created from applying a {@link TableFunction}.\n  */\n @Internal\n-public class CalculatedQueryOperation<T> implements QueryOperation {\n+public class CalculatedQueryOperation implements QueryOperation {\n \n-\tprivate final TableFunction<T> tableFunction;\n+\tprivate final FunctionDefinition functionDefinition;\n+\tprivate final FunctionIdentifier functionIdentifier;\n \tprivate final List<ResolvedExpression> parameters;\n-\tprivate final TypeInformation<T> resultType;\n \tprivate final TableSchema tableSchema;\n \n \tpublic CalculatedQueryOperation(\n-\t\t\tTableFunction<T> tableFunction,\n+\t\t\tFunctionDefinition functionDefinition,\n+\t\t\tFunctionIdentifier functionIdentifier,\n \t\t\tList<ResolvedExpression> parameters,\n-\t\t\tTypeInformation<T> resultType,\n \t\t\tTableSchema tableSchema) {\n-\t\tthis.tableFunction = tableFunction;\n+\t\tthis.functionDefinition = functionDefinition;\n+\t\tthis.functionIdentifier = functionIdentifier;\n \t\tthis.parameters = parameters;\n-\t\tthis.resultType = resultType;\n \t\tthis.tableSchema = tableSchema;\n \t}\n \n-\tpublic TableFunction<T> getTableFunction() {\n-\t\treturn tableFunction;\n+\tpublic FunctionDefinition getFunctionDefinition() {\n+\t\treturn functionDefinition;\n \t}\n \n-\tpublic List<ResolvedExpression> getParameters() {\n-\t\treturn parameters;\n+\tpublic FunctionIdentifier getFunctionIdentifier() {\n+\t\treturn functionIdentifier;\n \t}\n \n-\tpublic TypeInformation<T> getResultType() {\n-\t\treturn resultType;\n+\tpublic List<ResolvedExpression> getParameters() {", "originalCommit": "69161e40e90e997a26f113cb6da10f7815ebbe0f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI1MDY4MQ==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397250681", "bodyText": "nit: unnecessary", "author": "twalthr", "createdAt": "2020-03-24T15:38:32Z", "path": "flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/operations/CalculatedQueryOperation.java", "diffHunk": "@@ -86,4 +87,5 @@ public String asSummaryString() {\n \tpublic <U> U accept(QueryOperationVisitor<U> visitor) {\n \t\treturn visitor.visit(this);\n \t}\n+", "originalCommit": "69161e40e90e997a26f113cb6da10f7815ebbe0f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI1MTYzMA==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397251630", "bodyText": "please add a follow-up issue in FLINK-13191", "author": "twalthr", "createdAt": "2020-03-24T15:39:43Z", "path": "flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/operations/utils/OperationTreeBuilder.java", "diffHunk": "@@ -471,9 +471,14 @@ public QueryOperation flatMap(Expression tableFunction, QueryOperation child) {\n \t\t\tthrow new ValidationException(\"Only a table function can be used in the flatMap operator.\");\n \t\t}\n \n-\t\tTypeInformation<?> resultType = ((TableFunctionDefinition) ((UnresolvedCallExpression) resolvedTableFunction)\n-\t\t\t.getFunctionDefinition())\n-\t\t\t.getResultType();\n+\t\tFunctionDefinition functionDefinition = ((UnresolvedCallExpression) resolvedTableFunction)\n+\t\t\t.getFunctionDefinition();\n+\t\tif (!(functionDefinition instanceof TableFunctionDefinition)) {", "originalCommit": "69161e40e90e997a26f113cb6da10f7815ebbe0f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzY3OTk5Nw==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397679997", "bodyText": "Created https://issues.apache.org/jira/browse/FLINK-16769", "author": "dawidwys", "createdAt": "2020-03-25T08:31:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI1MTYzMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI1MzI5Ng==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397253296", "bodyText": "just to make sure: we are failing now in the code gen, right?", "author": "twalthr", "createdAt": "2020-03-24T15:41:49Z", "path": "flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/operations/utils/factories/CalculatedTableFactory.java", "diffHunk": "@@ -59,82 +59,101 @@ public QueryOperation create(ResolvedExpression callExpr, String[] leftTableFiel\n \t\treturn callExpr.accept(calculatedTableCreator);\n \t}\n \n-\tprivate class FunctionTableCallVisitor extends ResolvedExpressionDefaultVisitor<CalculatedQueryOperation<?>> {\n-\n-\t\tprivate String[] leftTableFieldNames;\n+\tprivate static class FunctionTableCallVisitor extends ResolvedExpressionDefaultVisitor<CalculatedQueryOperation> {\n+\t\tprivate List<String> leftTableFieldNames;\n+\t\tprivate static final String ATOMIC_FIELD_NAME = \"f0\";\n \n \t\tpublic FunctionTableCallVisitor(String[] leftTableFieldNames) {\n-\t\t\tthis.leftTableFieldNames = leftTableFieldNames;\n+\t\t\tthis.leftTableFieldNames = Arrays.asList(leftTableFieldNames);\n \t\t}\n \n \t\t@Override\n-\t\tpublic CalculatedQueryOperation<?> visit(CallExpression call) {\n+\t\tpublic CalculatedQueryOperation visit(CallExpression call) {\n \t\t\tFunctionDefinition definition = call.getFunctionDefinition();\n \t\t\tif (definition.equals(AS)) {\n \t\t\t\treturn unwrapFromAlias(call);\n-\t\t\t} else if (definition instanceof TableFunctionDefinition) {\n-\t\t\t\treturn createFunctionCall(\n-\t\t\t\t\t(TableFunctionDefinition) definition,\n-\t\t\t\t\tCollections.emptyList(),\n-\t\t\t\t\tcall.getResolvedChildren());\n-\t\t\t} else {\n-\t\t\t\treturn defaultMethod(call);\n \t\t\t}\n+\n+\t\t\treturn createFunctionCall(call, Collections.emptyList(), call.getResolvedChildren());\n \t\t}\n \n-\t\tprivate CalculatedQueryOperation<?> unwrapFromAlias(CallExpression call) {\n+\t\tprivate CalculatedQueryOperation unwrapFromAlias(CallExpression call) {\n \t\t\tList<Expression> children = call.getChildren();\n \t\t\tList<String> aliases = children.subList(1, children.size())\n \t\t\t\t.stream()\n \t\t\t\t.map(alias -> ExpressionUtils.extractValue(alias, String.class)\n \t\t\t\t\t.orElseThrow(() -> new ValidationException(\"Unexpected alias: \" + alias)))\n \t\t\t\t.collect(toList());\n \n-\t\t\tif (!isFunctionOfKind(children.get(0), TABLE)) {\n+\t\t\tif (!(children.get(0) instanceof CallExpression)) {", "originalCommit": "69161e40e90e997a26f113cb6da10f7815ebbe0f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzc3MDYxMA==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397770610", "bodyText": "correct", "author": "dawidwys", "createdAt": "2020-03-25T11:04:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI1MzI5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI1NTk4MA==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397255980", "bodyText": "nit: use asSummaryString", "author": "twalthr", "createdAt": "2020-03-24T15:45:14Z", "path": "flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/operations/utils/factories/CalculatedTableFactory.java", "diffHunk": "@@ -59,82 +59,101 @@ public QueryOperation create(ResolvedExpression callExpr, String[] leftTableFiel\n \t\treturn callExpr.accept(calculatedTableCreator);\n \t}\n \n-\tprivate class FunctionTableCallVisitor extends ResolvedExpressionDefaultVisitor<CalculatedQueryOperation<?>> {\n-\n-\t\tprivate String[] leftTableFieldNames;\n+\tprivate static class FunctionTableCallVisitor extends ResolvedExpressionDefaultVisitor<CalculatedQueryOperation> {\n+\t\tprivate List<String> leftTableFieldNames;\n+\t\tprivate static final String ATOMIC_FIELD_NAME = \"f0\";\n \n \t\tpublic FunctionTableCallVisitor(String[] leftTableFieldNames) {\n-\t\t\tthis.leftTableFieldNames = leftTableFieldNames;\n+\t\t\tthis.leftTableFieldNames = Arrays.asList(leftTableFieldNames);\n \t\t}\n \n \t\t@Override\n-\t\tpublic CalculatedQueryOperation<?> visit(CallExpression call) {\n+\t\tpublic CalculatedQueryOperation visit(CallExpression call) {\n \t\t\tFunctionDefinition definition = call.getFunctionDefinition();\n \t\t\tif (definition.equals(AS)) {\n \t\t\t\treturn unwrapFromAlias(call);\n-\t\t\t} else if (definition instanceof TableFunctionDefinition) {\n-\t\t\t\treturn createFunctionCall(\n-\t\t\t\t\t(TableFunctionDefinition) definition,\n-\t\t\t\t\tCollections.emptyList(),\n-\t\t\t\t\tcall.getResolvedChildren());\n-\t\t\t} else {\n-\t\t\t\treturn defaultMethod(call);\n \t\t\t}\n+\n+\t\t\treturn createFunctionCall(call, Collections.emptyList(), call.getResolvedChildren());\n \t\t}\n \n-\t\tprivate CalculatedQueryOperation<?> unwrapFromAlias(CallExpression call) {\n+\t\tprivate CalculatedQueryOperation unwrapFromAlias(CallExpression call) {\n \t\t\tList<Expression> children = call.getChildren();\n \t\t\tList<String> aliases = children.subList(1, children.size())\n \t\t\t\t.stream()\n \t\t\t\t.map(alias -> ExpressionUtils.extractValue(alias, String.class)\n \t\t\t\t\t.orElseThrow(() -> new ValidationException(\"Unexpected alias: \" + alias)))\n \t\t\t\t.collect(toList());\n \n-\t\t\tif (!isFunctionOfKind(children.get(0), TABLE)) {\n+\t\t\tif (!(children.get(0) instanceof CallExpression)) {\n \t\t\t\tthrow fail();\n \t\t\t}\n \n \t\t\tCallExpression tableCall = (CallExpression) children.get(0);\n-\t\t\tTableFunctionDefinition tableFunctionDefinition =\n-\t\t\t\t(TableFunctionDefinition) tableCall.getFunctionDefinition();\n-\t\t\treturn createFunctionCall(tableFunctionDefinition, aliases, tableCall.getResolvedChildren());\n+\t\t\treturn createFunctionCall(tableCall, aliases, tableCall.getResolvedChildren());\n \t\t}\n \n-\t\tprivate CalculatedQueryOperation<?> createFunctionCall(\n-\t\t\t\tTableFunctionDefinition tableFunctionDefinition,\n+\t\tprivate CalculatedQueryOperation createFunctionCall(\n+\t\t\t\tCallExpression callExpression,\n \t\t\t\tList<String> aliases,\n \t\t\t\tList<ResolvedExpression> parameters) {\n-\t\t\tTypeInformation<?> resultType = tableFunctionDefinition.getResultType();\n \n-\t\t\tint callArity = resultType.getTotalFields();\n-\t\t\tint aliasesSize = aliases.size();\n+\t\t\tFunctionDefinition functionDefinition = callExpression.getFunctionDefinition();\n+\t\t\tFunctionIdentifier functionIdentifier = ApiExpressionUtils.getFunctionIdentifier(callExpression);\n+\t\t\tfinal TableSchema tableSchema = adjustNames(\n+\t\t\t\textractSchema(callExpression.getOutputDataType()),\n+\t\t\t\taliases,\n+\t\t\t\tfunctionIdentifier);\n+\n+\t\t\treturn new CalculatedQueryOperation(\n+\t\t\t\tfunctionDefinition,\n+\t\t\t\tfunctionIdentifier,\n+\t\t\t\tparameters,\n+\t\t\t\ttableSchema);\n+\t\t}\n \n-\t\t\tString[] fieldNames;\n+\t\tprivate TableSchema extractSchema(DataType resultType) {\n+\t\t\tif (LogicalTypeChecks.isCompositeType(resultType.getLogicalType())) {\n+\t\t\t\treturn DataTypeUtils.expandCompositeTypeToSchema(resultType);\n+\t\t\t}\n+\n+\t\t\tint i = 0;\n+\t\t\tString fieldName = ATOMIC_FIELD_NAME;\n+\t\t\twhile (leftTableFieldNames.contains(fieldName)) {\n+\t\t\t\tfieldName = ATOMIC_FIELD_NAME + \"_\" + i++;\n+\t\t\t}\n+\t\t\treturn TableSchema.builder()\n+\t\t\t\t.field(fieldName, resultType)\n+\t\t\t\t.build();\n+\t\t}\n+\n+\t\tprivate TableSchema adjustNames(\n+\t\t\t\tTableSchema tableSchema,\n+\t\t\t\tList<String> aliases,\n+\t\t\t\tFunctionIdentifier identifier) {\n+\t\t\tint aliasesSize = aliases.size();\n \t\t\tif (aliasesSize == 0) {\n-\t\t\t\tfieldNames = FieldInfoUtils.getFieldNames(resultType, Arrays.asList(leftTableFieldNames));\n-\t\t\t} else if (aliasesSize != callArity) {\n+\t\t\t\treturn tableSchema;\n+\t\t\t}\n+\n+\t\t\tint callArity = tableSchema.getFieldCount();\n+\t\t\tif (callArity != aliasesSize) {\n \t\t\t\tthrow new ValidationException(String.format(\n \t\t\t\t\t\"List of column aliases must have same degree as table; \" +\n \t\t\t\t\t\t\"the returned table of function '%s' has \" +\n \t\t\t\t\t\t\"%d columns, whereas alias list has %d columns\",\n-\t\t\t\t\ttableFunctionDefinition.toString(),\n+\t\t\t\t\tidentifier.toString(),", "originalCommit": "69161e40e90e997a26f113cb6da10f7815ebbe0f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI1OTE0Mg==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397259142", "bodyText": "nit: name it resultDataType", "author": "twalthr", "createdAt": "2020-03-24T15:49:01Z", "path": "flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/operations/utils/factories/CalculatedTableFactory.java", "diffHunk": "@@ -59,82 +59,101 @@ public QueryOperation create(ResolvedExpression callExpr, String[] leftTableFiel\n \t\treturn callExpr.accept(calculatedTableCreator);\n \t}\n \n-\tprivate class FunctionTableCallVisitor extends ResolvedExpressionDefaultVisitor<CalculatedQueryOperation<?>> {\n-\n-\t\tprivate String[] leftTableFieldNames;\n+\tprivate static class FunctionTableCallVisitor extends ResolvedExpressionDefaultVisitor<CalculatedQueryOperation> {\n+\t\tprivate List<String> leftTableFieldNames;\n+\t\tprivate static final String ATOMIC_FIELD_NAME = \"f0\";\n \n \t\tpublic FunctionTableCallVisitor(String[] leftTableFieldNames) {\n-\t\t\tthis.leftTableFieldNames = leftTableFieldNames;\n+\t\t\tthis.leftTableFieldNames = Arrays.asList(leftTableFieldNames);\n \t\t}\n \n \t\t@Override\n-\t\tpublic CalculatedQueryOperation<?> visit(CallExpression call) {\n+\t\tpublic CalculatedQueryOperation visit(CallExpression call) {\n \t\t\tFunctionDefinition definition = call.getFunctionDefinition();\n \t\t\tif (definition.equals(AS)) {\n \t\t\t\treturn unwrapFromAlias(call);\n-\t\t\t} else if (definition instanceof TableFunctionDefinition) {\n-\t\t\t\treturn createFunctionCall(\n-\t\t\t\t\t(TableFunctionDefinition) definition,\n-\t\t\t\t\tCollections.emptyList(),\n-\t\t\t\t\tcall.getResolvedChildren());\n-\t\t\t} else {\n-\t\t\t\treturn defaultMethod(call);\n \t\t\t}\n+\n+\t\t\treturn createFunctionCall(call, Collections.emptyList(), call.getResolvedChildren());\n \t\t}\n \n-\t\tprivate CalculatedQueryOperation<?> unwrapFromAlias(CallExpression call) {\n+\t\tprivate CalculatedQueryOperation unwrapFromAlias(CallExpression call) {\n \t\t\tList<Expression> children = call.getChildren();\n \t\t\tList<String> aliases = children.subList(1, children.size())\n \t\t\t\t.stream()\n \t\t\t\t.map(alias -> ExpressionUtils.extractValue(alias, String.class)\n \t\t\t\t\t.orElseThrow(() -> new ValidationException(\"Unexpected alias: \" + alias)))\n \t\t\t\t.collect(toList());\n \n-\t\t\tif (!isFunctionOfKind(children.get(0), TABLE)) {\n+\t\t\tif (!(children.get(0) instanceof CallExpression)) {\n \t\t\t\tthrow fail();\n \t\t\t}\n \n \t\t\tCallExpression tableCall = (CallExpression) children.get(0);\n-\t\t\tTableFunctionDefinition tableFunctionDefinition =\n-\t\t\t\t(TableFunctionDefinition) tableCall.getFunctionDefinition();\n-\t\t\treturn createFunctionCall(tableFunctionDefinition, aliases, tableCall.getResolvedChildren());\n+\t\t\treturn createFunctionCall(tableCall, aliases, tableCall.getResolvedChildren());\n \t\t}\n \n-\t\tprivate CalculatedQueryOperation<?> createFunctionCall(\n-\t\t\t\tTableFunctionDefinition tableFunctionDefinition,\n+\t\tprivate CalculatedQueryOperation createFunctionCall(\n+\t\t\t\tCallExpression callExpression,\n \t\t\t\tList<String> aliases,\n \t\t\t\tList<ResolvedExpression> parameters) {\n-\t\t\tTypeInformation<?> resultType = tableFunctionDefinition.getResultType();\n \n-\t\t\tint callArity = resultType.getTotalFields();\n-\t\t\tint aliasesSize = aliases.size();\n+\t\t\tFunctionDefinition functionDefinition = callExpression.getFunctionDefinition();\n+\t\t\tFunctionIdentifier functionIdentifier = ApiExpressionUtils.getFunctionIdentifier(callExpression);\n+\t\t\tfinal TableSchema tableSchema = adjustNames(\n+\t\t\t\textractSchema(callExpression.getOutputDataType()),\n+\t\t\t\taliases,\n+\t\t\t\tfunctionIdentifier);\n+\n+\t\t\treturn new CalculatedQueryOperation(\n+\t\t\t\tfunctionDefinition,\n+\t\t\t\tfunctionIdentifier,\n+\t\t\t\tparameters,\n+\t\t\t\ttableSchema);\n+\t\t}\n \n-\t\t\tString[] fieldNames;\n+\t\tprivate TableSchema extractSchema(DataType resultType) {", "originalCommit": "69161e40e90e997a26f113cb6da10f7815ebbe0f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI2NjUyNA==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397266524", "bodyText": "nit: a new line for every new Call? like below?", "author": "twalthr", "createdAt": "2020-03-24T15:58:03Z", "path": "flink-table/flink-table-api-java/src/test/java/org/apache/flink/table/expressions/resolver/ExpressionResolverTest.java", "diffHunk": "@@ -157,20 +161,79 @@\n \t\t\t\t\tDataTypes.BOOLEAN()\n \t\t\t\t)),\n \n-\t\t\tTestSpec.test(\"Lookup system function call\")\n+\t\t\tTestSpec.test(\"Lookup legacy scalar function call\")\n \t\t\t\t.inputSchemas(\n \t\t\t\t\tTableSchema.builder()\n \t\t\t\t\t\t.field(\"f0\", DataTypes.INT())\n \t\t\t\t\t\t.build()\n \t\t\t\t)\n-\t\t\t\t.lookupFunction(\"func\", new ScalarFunctionDefinition(\"func\", new ScalarFunc()))\n+\t\t\t\t.lookupFunction(\"func\", new ScalarFunctionDefinition(\"func\", new LegacyScalarFunc()))\n \t\t\t\t.select(call(\"func\", 1, $(\"f0\")))\n \t\t\t\t.equalTo(new CallExpression(\n \t\t\t\t\tFunctionIdentifier.of(\"func\"),\n-\t\t\t\t\tnew ScalarFunctionDefinition(\"func\", new ScalarFunc()),\n+\t\t\t\t\tnew ScalarFunctionDefinition(\"func\", new LegacyScalarFunc()),\n \t\t\t\t\tArrays.asList(valueLiteral(1), new FieldReferenceExpression(\"f0\", DataTypes.INT(), 0, 0)),\n \t\t\t\t\tDataTypes.INT().bridgedTo(Integer.class)\n-\t\t\t\t)));\n+\t\t\t\t)),\n+\n+\t\t\tTestSpec.test(\"Lookup system function call\")\n+\t\t\t\t.inputSchemas(\n+\t\t\t\t\tTableSchema.builder()\n+\t\t\t\t\t\t.field(\"f0\", DataTypes.INT())\n+\t\t\t\t\t\t.build()\n+\t\t\t\t)\n+\t\t\t\t.lookupFunction(\"func\", new ScalarFunc())\n+\t\t\t\t.select(call(\"func\", 1, $(\"f0\")))\n+\t\t\t\t.equalTo(new CallExpression(\n+\t\t\t\t\tFunctionIdentifier.of(\"func\"),\n+\t\t\t\t\tnew ScalarFunc(),\n+\t\t\t\t\tArrays.asList(valueLiteral(1), new FieldReferenceExpression(\"f0\", DataTypes.INT(), 0, 0)),\n+\t\t\t\t\tDataTypes.INT().notNull().bridgedTo(int.class)\n+\t\t\t\t)),\n+\n+\t\t\tTestSpec.test(\"Lookup catalog function call\")\n+\t\t\t\t.inputSchemas(\n+\t\t\t\t\tTableSchema.builder()\n+\t\t\t\t\t\t.field(\"f0\", DataTypes.INT())\n+\t\t\t\t\t\t.build()\n+\t\t\t\t)\n+\t\t\t\t.lookupFunction(ObjectIdentifier.of(\"cat\", \"db\", \"func\"), new ScalarFunc())\n+\t\t\t\t.select(call(\"cat.db.func\", 1, $(\"f0\")))\n+\t\t\t\t.equalTo(new CallExpression(", "originalCommit": "69161e40e90e997a26f113cb6da10f7815ebbe0f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI2NzczOQ==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397267739", "bodyText": "nit: fix formatting", "author": "twalthr", "createdAt": "2020-03-24T15:59:36Z", "path": "flink-table/flink-table-api-java/src/test/java/org/apache/flink/table/expressions/resolver/ExpressionResolverTest.java", "diffHunk": "@@ -186,13 +249,37 @@ public void testResolvingExpressions() {\n \t}\n \n \t/**\n-\t * Test scalar function that uses legacy type inference logic.\n+\t * Test scalar function.\n \t */\n+\t@FunctionHint(\n+\t\tinput = @DataTypeHint(inputGroup = InputGroup.ANY),\n+\t\tisVarArgs = true,\n+\t\toutput = @DataTypeHint(value = \"INTEGER NOT NULL\",\n+\t\tbridgedTo = int.class))", "originalCommit": "69161e40e90e997a26f113cb6da10f7815ebbe0f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI3MTMxNQ==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397271315", "bodyText": "Use org.apache.flink.table.planner.utils.ShortcutUtils for readability.", "author": "twalthr", "createdAt": "2020-03-24T16:04:04Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/expressions/converter/ExpressionConverter.java", "diffHunk": "@@ -71,18 +72,26 @@\n public class ExpressionConverter implements ExpressionVisitor<RexNode> {\n \n \tprivate static final List<CallExpressionConvertRule> FUNCTION_CONVERT_CHAIN = Arrays.asList(\n-\t\tnew ScalarFunctionConvertRule(),\n+\t\tnew LegacyScalarFunctionConvertRule(),\n+\t\tnew UserDefinedFunctionConvertRule(),\n \t\tnew OverConvertRule(),\n \t\tnew DirectConvertRule(),\n \t\tnew CustomizedConvertRule()\n \t);\n \n \tprivate final RelBuilder relBuilder;\n \tprivate final FlinkTypeFactory typeFactory;\n+\tprivate final DataTypeFactory dataTypeFactory;\n \n \tpublic ExpressionConverter(RelBuilder relBuilder) {\n \t\tthis.relBuilder = relBuilder;\n \t\tthis.typeFactory = (FlinkTypeFactory) relBuilder.getRexBuilder().getTypeFactory();\n+\t\tthis.dataTypeFactory = relBuilder.getCluster()", "originalCommit": "69161e40e90e997a26f113cb6da10f7815ebbe0f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI3MzExMg==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397273112", "bodyText": "Is it necessary to limit this code to UserDefinedFunctions?", "author": "twalthr", "createdAt": "2020-03-24T16:06:28Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/expressions/converter/UserDefinedFunctionConvertRule.java", "diffHunk": "@@ -0,0 +1,63 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.expressions.converter;\n+\n+import org.apache.flink.table.expressions.ApiExpressionUtils;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.functions.UserDefinedFunction;\n+import org.apache.flink.table.planner.functions.bridging.BridgingSqlFunction;\n+\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.sql.SqlKind;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * A call expression converter rule that converts calls to user defined functions.\n+ */\n+public class UserDefinedFunctionConvertRule implements CallExpressionConvertRule {\n+\t@Override\n+\tpublic Optional<RexNode> convert(\n+\t\t\tCallExpression call,\n+\t\t\tConvertContext context) {\n+\t\tif (!(call.getFunctionDefinition() instanceof UserDefinedFunction)) {", "originalCommit": "69161e40e90e997a26f113cb6da10f7815ebbe0f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI3NjkzNA==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397276934", "bodyText": "Or can this be a FunctionDefinitionConvertRule?", "author": "twalthr", "createdAt": "2020-03-24T16:11:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI3MzExMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzcyNDgzMg==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397724832", "bodyText": "For now I think it is safer to limit it to UserDefinedFunction, until we have proper inference strategies for all built in functions.\nRight now BuiltinFunctionDefinitions are mapped to Calcite's alternatives. Removing this limitation would result in all built-in functions ending in BridgingSqlFunction.", "author": "dawidwys", "createdAt": "2020-03-25T09:47:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI3MzExMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzcyOTE2Mw==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397729163", "bodyText": "Hmm...\nAfter thinking of the second comment below, I think we can already let more functions go through this code:\n\t@Override\n\tpublic Optional<RexNode> convert(\n\t\t\tCallExpression call,\n\t\t\tConvertContext context) {\n\t\tTypeInference typeInference;\n\t\ttry {\n\t\t\ttypeInference = call.getFunctionDefinition().getTypeInference(context.getDataTypeFactory());\n\t\t} catch (Throwable t) {\n\t\t\tthrow new ValidationException(\n\t\t\t\tString.format(\n\t\t\t\t\t\"An error occurred in the type inference logic of function '%s'.\",\n\t\t\t\t\tcall.asSummaryString()),\n\t\t\t\tt);\n\t\t}\n\t\tif (typeInference.getOutputTypeStrategy() == TypeStrategies.MISSING) {\n\t\t\treturn Optional.empty();\n\t\t}\n\n\t\tswitch (call.getFunctionDefinition().getKind()) {\n\t\t\tcase SCALAR:\n\t\t\tcase TABLE:\n\t\t\t\tList<RexNode> args = call.getChildren().stream().map(context::toRexNode).collect(Collectors.toList());\n\t\t\t\treturn Optional.of(context.getRelBuilder().call(\n\t\t\t\t\tBridgingSqlFunction.of(\n\t\t\t\t\t\tcontext.getDataTypeFactory(),\n\t\t\t\t\t\tcontext.getTypeFactory(),\n\t\t\t\t\t\tSqlKind.OTHER_FUNCTION,\n\t\t\t\t\t\tApiExpressionUtils.getFunctionIdentifier(call),\n\t\t\t\t\t\tcall.getFunctionDefinition(),\n\t\t\t\t\t\ttypeInference),\n\t\t\t\t\targs)\n\t\t\t\t);\n\t\t\tdefault:\n\t\t\t\treturn Optional.empty();\n\t\t}\n\t}", "author": "dawidwys", "createdAt": "2020-03-25T09:54:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI3MzExMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI3NDA4MQ==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397274081", "bodyText": "This can throw errors. We should wrap the exception again like in FunctionCatalogOperatorTable.", "author": "twalthr", "createdAt": "2020-03-24T16:07:46Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/expressions/converter/UserDefinedFunctionConvertRule.java", "diffHunk": "@@ -0,0 +1,63 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.expressions.converter;\n+\n+import org.apache.flink.table.expressions.ApiExpressionUtils;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.functions.UserDefinedFunction;\n+import org.apache.flink.table.planner.functions.bridging.BridgingSqlFunction;\n+\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.sql.SqlKind;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * A call expression converter rule that converts calls to user defined functions.\n+ */\n+public class UserDefinedFunctionConvertRule implements CallExpressionConvertRule {\n+\t@Override\n+\tpublic Optional<RexNode> convert(\n+\t\t\tCallExpression call,\n+\t\t\tConvertContext context) {\n+\t\tif (!(call.getFunctionDefinition() instanceof UserDefinedFunction)) {\n+\t\t\treturn Optional.empty();\n+\t\t}\n+\n+\t\tswitch (call.getFunctionDefinition().getKind()) {\n+\t\t\tcase SCALAR:\n+\t\t\tcase TABLE:\n+\t\t\t\tList<RexNode> args = call.getChildren().stream().map(context::toRexNode).collect(Collectors.toList());\n+\t\t\t\treturn Optional.of(context.getRelBuilder().call(\n+\t\t\t\t\tBridgingSqlFunction.of(\n+\t\t\t\t\t\tcontext.getDataTypeFactory(),\n+\t\t\t\t\t\tcontext.getTypeFactory(),\n+\t\t\t\t\t\tSqlKind.OTHER_FUNCTION,\n+\t\t\t\t\t\tApiExpressionUtils.getFunctionIdentifier(call),\n+\t\t\t\t\t\tcall.getFunctionDefinition(),\n+\t\t\t\t\t\tcall.getFunctionDefinition().getTypeInference(context.getDataTypeFactory())),", "originalCommit": "69161e40e90e997a26f113cb6da10f7815ebbe0f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI3NjI1MQ==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397276251", "bodyText": "It seems wrong to me that we are using ApiUtils in the planner. This should be done earlier when constructing the call.", "author": "twalthr", "createdAt": "2020-03-24T16:10:24Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/expressions/converter/UserDefinedFunctionConvertRule.java", "diffHunk": "@@ -0,0 +1,63 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.expressions.converter;\n+\n+import org.apache.flink.table.expressions.ApiExpressionUtils;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.functions.UserDefinedFunction;\n+import org.apache.flink.table.planner.functions.bridging.BridgingSqlFunction;\n+\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.sql.SqlKind;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * A call expression converter rule that converts calls to user defined functions.\n+ */\n+public class UserDefinedFunctionConvertRule implements CallExpressionConvertRule {\n+\t@Override\n+\tpublic Optional<RexNode> convert(\n+\t\t\tCallExpression call,\n+\t\t\tConvertContext context) {\n+\t\tif (!(call.getFunctionDefinition() instanceof UserDefinedFunction)) {\n+\t\t\treturn Optional.empty();\n+\t\t}\n+\n+\t\tswitch (call.getFunctionDefinition().getKind()) {\n+\t\t\tcase SCALAR:\n+\t\t\tcase TABLE:\n+\t\t\t\tList<RexNode> args = call.getChildren().stream().map(context::toRexNode).collect(Collectors.toList());\n+\t\t\t\treturn Optional.of(context.getRelBuilder().call(\n+\t\t\t\t\tBridgingSqlFunction.of(\n+\t\t\t\t\t\tcontext.getDataTypeFactory(),\n+\t\t\t\t\t\tcontext.getTypeFactory(),\n+\t\t\t\t\t\tSqlKind.OTHER_FUNCTION,\n+\t\t\t\t\t\tApiExpressionUtils.getFunctionIdentifier(call),", "originalCommit": "69161e40e90e997a26f113cb6da10f7815ebbe0f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzcxOTkwMQ==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397719901", "bodyText": "No it cannot be done when constructing the call. The call is properly constructed.\nIf the call is an inline call we do not have any function identifier and imo it is correct. It clearly identifies all the categories of calls:\nWhen function identifier is\n\nnull -> inline function\nthree part identifier -> catalog function\nsimple name/one part -> system function\n\nImo the problem might be in the way BridgingSqlFunction handles identifiers/names. It requires a non null identifier to bridge it to calcite.\nAnother option I see is we can change the way BridgingSqlFunction handles it. We can make the SqlIdentifier optional. And then move the logic from ApiExpressionUtils#getInlineFunctionIdentifier into the BridgingSqlFunction.\nWhat I have in mind is something along this:\nfinal class BridgingUtils {\n\tstatic String createName(FunctionIdentifier identifier) {\n\t\tif (identifier.getSimpleName().isPresent()) {\n\t\t\treturn identifier.getSimpleName().get();\n\t\t}\n\t\treturn identifier.getIdentifier()\n\t\t\t.map(ObjectIdentifier::getObjectName)\n\t\t\t.orElseThrow(IllegalStateException::new);\n\t}\n\n\tstatic SqlIdentifier createSqlIdentifier(FunctionIdentifier identifier) {\n\t\treturn identifier.getIdentifier()\n\t\t\t.map(i -> new SqlIdentifier(i.toList(), SqlParserPos.ZERO))\n\t\t\t.orElseGet(() -> new SqlIdentifier(identifier.getSimpleName().get(), SqlParserPos.ZERO)); // null indicates a built-in system function\n\t}\n}\n\nclass BridgingSqlFunction extends SqlFunction  {\n\tprivate BridgingSqlFunction(\n\t\t\tDataTypeFactory dataTypeFactory,\n\t\t\tFlinkTypeFactory typeFactory,\n\t\t\tSqlKind kind,\n\t\t\tFunctionIdentifier identifier,\n\t\t\tFunctionDefinition definition,\n\t\t\tTypeInference typeInference) {\n\t\tsuper(\n\t\t\tidentifier != null ? createName(identifier) : createInlineFunctionName(definition),\n\t\t\tidentifier != null ? createSqlIdentifier(identifier) : null,\n\t\t\tkind,\n\t\t\tcreateSqlReturnTypeInference(dataTypeFactory, definition, typeInference),\n\t\t\tcreateSqlOperandTypeInference(dataTypeFactory, definition, typeInference),\n\t\t\tcreateSqlOperandTypeChecker(dataTypeFactory, definition, typeInference),\n\t\t\tcreateParamTypes(typeFactory, typeInference),\n\t\t\tcreateSqlFunctionCategory(identifier));\n\n\t\tthis.dataTypeFactory = dataTypeFactory;\n\t\tthis.typeFactory = typeFactory;\n\t\tthis.identifier = identifier;\n\t\tthis.definition = definition;\n\t\tthis.typeInference = typeInference;\n\t}\n\n        \tprivate static String createInlineFunctionName(FunctionDefinition functionDefinition) {\n\t\tif (functionDefinition instanceof BuiltInFunctionDefinition) {\n\t\t\treturn ((BuiltInFunctionDefinition) functionDefinition).getName();\n\t\t} else {\n\t\t\tfinal Optional<UserDefinedFunction> userDefinedFunction = extractUserDefinedFunction(functionDefinition);\n\n\t\t\treturn userDefinedFunction.map(UserDefinedFunction::functionIdentifier)\n\t\t\t\t.orElseThrow(() -> new TableException(\"Unknown function type. Function: \" + functionDefinition));\n\t\t}\n\t}\n\n\tprivate static Optional<UserDefinedFunction> extractUserDefinedFunction(FunctionDefinition functionDefinition) {\n\t\tif (functionDefinition instanceof UserDefinedFunction) {\n\t\t\treturn Optional.of((UserDefinedFunction) functionDefinition);\n\t\t} else if (functionDefinition instanceof ScalarFunctionDefinition) {\n\t\t\treturn Optional.ofNullable(((ScalarFunctionDefinition) functionDefinition).getScalarFunction());\n\t\t} else if (functionDefinition instanceof AggregateFunctionDefinition) {\n\t\t\treturn Optional.ofNullable(((AggregateFunctionDefinition) functionDefinition).getAggregateFunction());\n\t\t} else if (functionDefinition instanceof TableFunctionDefinition) {\n\t\t\treturn Optional.ofNullable(((TableFunctionDefinition) functionDefinition).getTableFunction());\n\t\t} else if (functionDefinition instanceof TableAggregateFunctionDefinition) {\n\t\t\treturn Optional.ofNullable(((TableAggregateFunctionDefinition) functionDefinition).getTableAggregateFunction());\n\t\t}\n\t\treturn Optional.empty();\n\t}\n}\n\nThis has the downside that, at least from Calcite's javadocs perspective, our inline functions would be Calcite's built-in functions. Nevertheless from our perspective I think this would be the cleanest approach. We can also do a mixed approach, more similar in the effect to the current state:\nsuper(\n\tidentifier != null ? createName(identifier) : createName(createInlineFunctionName(definition)),\n\tidentifier != null ? createSqlIdentifier(identifier) : new SqlIdentifier(createInlineFunctionName(definition), SqlParserPos.ZERO),\n        ...\n)", "author": "dawidwys", "createdAt": "2020-03-25T09:40:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI3NjI1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI3ODg3Ng==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397278876", "bodyText": "Same comment as in UserDefinedFunctionConverterRule. I think we should get the inference earlier in the API. Otherwise a wrong implemented UDF fails quite late.", "author": "twalthr", "createdAt": "2020-03-24T16:13:45Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/QueryOperationConverter.java", "diffHunk": "@@ -270,36 +273,69 @@ public RelNode visit(SortQueryOperation sort) {\n \t\t}\n \n \t\t@Override\n-\t\tpublic <U> RelNode visit(CalculatedQueryOperation<U> calculatedTable) {\n-\t\t\tDataType resultType = fromLegacyInfoToDataType(calculatedTable.getResultType());\n-\t\t\tTableFunction<?> tableFunction = calculatedTable.getTableFunction();\n-\t\t\tString[] fieldNames = calculatedTable.getTableSchema().getFieldNames();\n-\n-\t\t\tTypedFlinkTableFunction function = new TypedFlinkTableFunction(\n-\t\t\t\t\ttableFunction, fieldNames, resultType);\n-\n+\t\tpublic RelNode visit(CalculatedQueryOperation calculatedTable) {\n+\t\t\tFunctionDefinition functionDefinition = calculatedTable.getFunctionDefinition();\n+\t\t\tList<RexNode> parameters = convertToRexNodes(calculatedTable.getParameters());\n \t\t\tFlinkTypeFactory typeFactory = relBuilder.getTypeFactory();\n+\t\t\tif (functionDefinition instanceof TableFunctionDefinition) {\n+\t\t\t\treturn convertLegacyTableFunction(\n+\t\t\t\t\tcalculatedTable,\n+\t\t\t\t\t(TableFunctionDefinition) functionDefinition,\n+\t\t\t\t\tparameters,\n+\t\t\t\t\ttypeFactory);\n+\t\t\t}\n \n-\t\t\tTableSqlFunction sqlFunction = new TableSqlFunction(\n-\t\t\t\t\tFunctionIdentifier.of(tableFunction.functionIdentifier()),\n-\t\t\t\t\ttableFunction.toString(),\n-\t\t\t\t\ttableFunction,\n-\t\t\t\t\tresultType,\n+\t\t\tDataTypeFactory dataTypeFactory = relBuilder.getCluster()\n+\t\t\t\t.getPlanner()\n+\t\t\t\t.getContext()\n+\t\t\t\t.unwrap(FlinkContext.class)\n+\t\t\t\t.getCatalogManager()\n+\t\t\t\t.getDataTypeFactory();\n+\t\t\treturn relBuilder.functionScan(\n+\t\t\t\tBridgingSqlFunction.of(\n+\t\t\t\t\tdataTypeFactory,\n \t\t\t\t\ttypeFactory,\n-\t\t\t\t\tfunction,\n-\t\t\t\t\tscala.Option.empty());\n+\t\t\t\t\tSqlKind.OTHER_FUNCTION,\n+\t\t\t\t\tcalculatedTable.getFunctionIdentifier(),\n+\t\t\t\t\tcalculatedTable.getFunctionDefinition(),\n+\t\t\t\t\tcalculatedTable.getFunctionDefinition().getTypeInference(dataTypeFactory)),", "originalCommit": "69161e40e90e997a26f113cb6da10f7815ebbe0f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzczMjEwNw==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397732107", "bodyText": "As far as I understand if we end up here it was already called once in the ResolveCallByArgumentsRule, so it succeeded at least once.", "author": "dawidwys", "createdAt": "2020-03-25T09:59:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI3ODg3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI5MDY2OQ==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397290669", "bodyText": "remove comment", "author": "twalthr", "createdAt": "2020-03-24T16:28:36Z", "path": "flink-table/flink-table-planner/src/test/java/org/apache/flink/table/runtime/stream/sql/FunctionITCase.java", "diffHunk": "@@ -444,6 +450,31 @@ private void testUserDefinedCatalogFunction(TableEnvironment tableEnv, String cr\n \t\ttableEnv.sqlUpdate(\"drop table t2\");\n \t}\n \n+\t@Test\n+\tpublic void testDataTypeBasedTypeInferenceNotSupported() throws Exception {\n+\t\tthrown.expect(ValidationException.class);\n+\t\tthrown.expectMessage(\"The new type inference for functions is only supported in the Blink planner.\");\n+\n+\t\tStreamExecutionEnvironment streamExecEnvironment = StreamExecutionEnvironment.getExecutionEnvironment();\n+\t\tStreamTableEnvironment tableEnvironment = StreamTableEnvironment.create(streamExecEnvironment);\n+\n+\t\ttableEnvironment.createTemporarySystemFunction(\"func\", SimpleScalarFunction.class);\n+\t\tTable table = tableEnvironment\n+\t\t\t.sqlQuery(\"SELECT func(1)\");\n+\t\ttableEnvironment.toAppendStream(table, Row.class).print();\n+\n+\t\tstreamExecEnvironment.execute();\n+\t}\n+\n+\t/**", "originalCommit": "69161e40e90e997a26f113cb6da10f7815ebbe0f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzczODQwNQ==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397738405", "bodyText": "We must have a comment to satisfy the checkstyle. We have the same in the Blink's version of this test.", "author": "dawidwys", "createdAt": "2020-03-25T10:09:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI5MDY2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzg4ODE5Mg==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397888192", "bodyText": "True, but there we really tested different kind of functions. The comment has nothing to do with the new type inference. But I don't have a strong opinion there.", "author": "twalthr", "createdAt": "2020-03-25T14:16:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI5MDY2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzkwMzc1MQ==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397903751", "bodyText": "Will simplify it.", "author": "dawidwys", "createdAt": "2020-03-25T14:35:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI5MDY2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI5MTgwNA==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397291804", "bodyText": "remove comment", "author": "twalthr", "createdAt": "2020-03-24T16:30:05Z", "path": "flink-table/flink-table-planner/src/test/java/org/apache/flink/table/runtime/stream/table/FunctionITCase.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.stream.table;\n+\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+import org.apache.flink.table.annotation.DataTypeHint;\n+import org.apache.flink.table.annotation.FunctionHint;\n+import org.apache.flink.table.api.Table;\n+import org.apache.flink.table.api.ValidationException;\n+import org.apache.flink.table.api.java.StreamTableEnvironment;\n+import org.apache.flink.table.functions.ScalarFunction;\n+import org.apache.flink.table.functions.TableFunction;\n+import org.apache.flink.test.util.AbstractTestBase;\n+import org.apache.flink.types.Row;\n+\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.ExpectedException;\n+\n+import static org.apache.flink.table.api.Expressions.$;\n+import static org.apache.flink.table.api.Expressions.call;\n+\n+/**\n+ * Tests for user defined functions in the Table API.\n+ */\n+public class FunctionITCase extends AbstractTestBase {\n+\n+\t@Rule\n+\tpublic ExpectedException thrown = ExpectedException.none();\n+\n+\t@Test\n+\tpublic void testDataTypeBasedTypeInferenceNotSupported() throws Exception {\n+\t\tthrown.expect(ValidationException.class);\n+\t\tthrown.expectMessage(\"The new type inference for functions is only supported in the Blink planner.\");\n+\n+\t\tStreamExecutionEnvironment streamExecEnvironment = StreamExecutionEnvironment.getExecutionEnvironment();\n+\t\tStreamTableEnvironment tableEnvironment = StreamTableEnvironment.create(streamExecEnvironment);\n+\n+\t\tTable table = tableEnvironment\n+\t\t\t.sqlQuery(\"SELECT * FROM (VALUES (1)) AS TableName(f0)\")\n+\t\t\t.select(call(new SimpleScalarFunction(), $(\"f0\")));\n+\t\ttableEnvironment.toAppendStream(table, Row.class).print();\n+\n+\t\tstreamExecEnvironment.execute();\n+\t}\n+\n+\t@Test\n+\tpublic void testDataTypeBasedTypeInferenceNotSupportedInLateralJoin() throws Exception {\n+\t\tthrown.expect(ValidationException.class);\n+\t\tthrown.expectMessage(\"The new type inference for functions is only supported in the Blink planner.\");\n+\n+\t\tStreamExecutionEnvironment streamExecEnvironment = StreamExecutionEnvironment.getExecutionEnvironment();\n+\t\tStreamTableEnvironment tableEnvironment = StreamTableEnvironment.create(streamExecEnvironment);\n+\n+\t\tTable table = tableEnvironment\n+\t\t\t.sqlQuery(\"SELECT * FROM (VALUES ('A,B,C')) AS TableName(f0)\")\n+\t\t\t.joinLateral(call(new SimpleTableFunction(), $(\"f0\")).as(\"a\", \"b\"))\n+\t\t\t.select($(\"a\"), $(\"b\"));\n+\t\ttableEnvironment.toAppendStream(table, Row.class).print();\n+\n+\t\tstreamExecEnvironment.execute();\n+\t}\n+\n+\t/**", "originalCommit": "69161e40e90e997a26f113cb6da10f7815ebbe0f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzc0MDM5Mg==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397740392", "bodyText": "ditto", "author": "dawidwys", "createdAt": "2020-03-25T10:13:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI5MTgwNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI5NDAzNg==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397294036", "bodyText": "remove comment and simplify code?", "author": "twalthr", "createdAt": "2020-03-24T16:33:02Z", "path": "flink-table/flink-table-planner/src/test/java/org/apache/flink/table/runtime/stream/table/FunctionITCase.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.stream.table;\n+\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+import org.apache.flink.table.annotation.DataTypeHint;\n+import org.apache.flink.table.annotation.FunctionHint;\n+import org.apache.flink.table.api.Table;\n+import org.apache.flink.table.api.ValidationException;\n+import org.apache.flink.table.api.java.StreamTableEnvironment;\n+import org.apache.flink.table.functions.ScalarFunction;\n+import org.apache.flink.table.functions.TableFunction;\n+import org.apache.flink.test.util.AbstractTestBase;\n+import org.apache.flink.types.Row;\n+\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.ExpectedException;\n+\n+import static org.apache.flink.table.api.Expressions.$;\n+import static org.apache.flink.table.api.Expressions.call;\n+\n+/**\n+ * Tests for user defined functions in the Table API.\n+ */\n+public class FunctionITCase extends AbstractTestBase {\n+\n+\t@Rule\n+\tpublic ExpectedException thrown = ExpectedException.none();\n+\n+\t@Test\n+\tpublic void testDataTypeBasedTypeInferenceNotSupported() throws Exception {\n+\t\tthrown.expect(ValidationException.class);\n+\t\tthrown.expectMessage(\"The new type inference for functions is only supported in the Blink planner.\");\n+\n+\t\tStreamExecutionEnvironment streamExecEnvironment = StreamExecutionEnvironment.getExecutionEnvironment();\n+\t\tStreamTableEnvironment tableEnvironment = StreamTableEnvironment.create(streamExecEnvironment);\n+\n+\t\tTable table = tableEnvironment\n+\t\t\t.sqlQuery(\"SELECT * FROM (VALUES (1)) AS TableName(f0)\")\n+\t\t\t.select(call(new SimpleScalarFunction(), $(\"f0\")));\n+\t\ttableEnvironment.toAppendStream(table, Row.class).print();\n+\n+\t\tstreamExecEnvironment.execute();\n+\t}\n+\n+\t@Test\n+\tpublic void testDataTypeBasedTypeInferenceNotSupportedInLateralJoin() throws Exception {\n+\t\tthrown.expect(ValidationException.class);\n+\t\tthrown.expectMessage(\"The new type inference for functions is only supported in the Blink planner.\");\n+\n+\t\tStreamExecutionEnvironment streamExecEnvironment = StreamExecutionEnvironment.getExecutionEnvironment();\n+\t\tStreamTableEnvironment tableEnvironment = StreamTableEnvironment.create(streamExecEnvironment);\n+\n+\t\tTable table = tableEnvironment\n+\t\t\t.sqlQuery(\"SELECT * FROM (VALUES ('A,B,C')) AS TableName(f0)\")\n+\t\t\t.joinLateral(call(new SimpleTableFunction(), $(\"f0\")).as(\"a\", \"b\"))\n+\t\t\t.select($(\"a\"), $(\"b\"));\n+\t\ttableEnvironment.toAppendStream(table, Row.class).print();\n+\n+\t\tstreamExecEnvironment.execute();\n+\t}\n+\n+\t/**\n+\t * Scalar function that uses new type inference stack.\n+\t */\n+\tpublic static class SimpleScalarFunction extends ScalarFunction {\n+\t\tpublic long eval(Integer i) {\n+\t\t\treturn i;\n+\t\t}\n+\t}\n+\n+\t/**", "originalCommit": "69161e40e90e997a26f113cb6da10f7815ebbe0f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzc0MDMyNg==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397740326", "bodyText": "What's wrong with the current code. I think it makes sense to have a sensible function that can be reused in other tests.", "author": "dawidwys", "createdAt": "2020-03-25T10:13:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI5NDAzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzg4ODk3NQ==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397888975", "bodyText": "I think the function has too much code for just testing an exception. It is dead code.", "author": "twalthr", "createdAt": "2020-03-25T14:17:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI5NDAzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzg5MDA0MA==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397890040", "bodyText": "Ok, will simplify it.", "author": "dawidwys", "createdAt": "2020-03-25T14:19:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzI5NDAzNg=="}], "type": "inlineReview"}, {"oid": "ea837d9968d89fd583a3aa5841b16908be1294b6", "url": "https://github.com/apache/flink/commit/ea837d9968d89fd583a3aa5841b16908be1294b6", "message": "first comments applied", "committedDate": "2020-03-25T11:00:06Z", "type": "forcePushed"}, {"oid": "e4011cdc261980e822a90d1d6c1649243a924e40", "url": "https://github.com/apache/flink/commit/e4011cdc261980e822a90d1d6c1649243a924e40", "message": "comments applied", "committedDate": "2020-03-25T14:01:58Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzg5OTE3MA==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397899170", "bodyText": "can we integrate the case distinction in the methods createName(), createSqlIdentifier(), createSqlFunctionCategory() directly? First of all, I'm not big fan of inline if/else and more importantly, we need the same logic for BridgingSqlAggFunction which is why the BridgingUtils class exists.", "author": "twalthr", "createdAt": "2020-03-25T14:30:24Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/functions/bridging/BridgingSqlFunction.java", "diffHunk": "@@ -110,9 +114,11 @@ public static BridgingSqlFunction of(\n \t\t\tdataTypeFactory,\n \t\t\ttypeFactory,\n \t\t\tkind,\n-\t\t\tidentifier,\n+\t\t\tidentifier != null ? createName(identifier) : createInlineFunctionName(definition),", "originalCommit": "e4011cdc261980e822a90d1d6c1649243a924e40", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzkwNjMzMA==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397906330", "bodyText": "sure", "author": "dawidwys", "createdAt": "2020-03-25T14:39:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzg5OTE3MA=="}], "type": "inlineReview"}, {"oid": "e0df6ea361347a181a72a3f5d553860fdaaf6bc0", "url": "https://github.com/apache/flink/commit/e0df6ea361347a181a72a3f5d553860fdaaf6bc0", "message": "Unified function identifier handling for both BridgingSqlFunction and BridgingSqlAggFunction", "committedDate": "2020-03-25T14:49:19Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzkxOTQzMw==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397919433", "bodyText": "nit: add @Nullable to all arguments in this util", "author": "twalthr", "createdAt": "2020-03-25T14:55:19Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/functions/bridging/BridgingUtils.java", "diffHunk": "@@ -52,8 +52,15 @@\n  * Utilities for bridging {@link FunctionDefinition} with Calcite's representation of functions.\n  */\n final class BridgingUtils {\n+\tstatic String createName(FunctionIdentifier identifier, FunctionDefinition definition) {", "originalCommit": "e0df6ea361347a181a72a3f5d553860fdaaf6bc0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzkyMDk1OA==", "url": "https://github.com/apache/flink/pull/11280#discussion_r397920958", "bodyText": "nit: return Optional", "author": "twalthr", "createdAt": "2020-03-25T14:57:10Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/functions/bridging/BridgingSqlFunction.java", "diffHunk": "@@ -129,6 +125,10 @@ public FlinkTypeFactory getTypeFactory() {\n \t\treturn typeFactory;\n \t}\n \n+\tpublic FunctionIdentifier getIdentifier() {", "originalCommit": "e0df6ea361347a181a72a3f5d553860fdaaf6bc0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "265ed1e4ff1400247a3720fe42ef352778bf2533", "url": "https://github.com/apache/flink/commit/265ed1e4ff1400247a3720fe42ef352778bf2533", "message": "[FLINK-16377][table] Support calls to inline functions in the\nexpressions DSL.", "committedDate": "2020-03-25T15:35:46Z", "type": "commit"}, {"oid": "265ed1e4ff1400247a3720fe42ef352778bf2533", "url": "https://github.com/apache/flink/commit/265ed1e4ff1400247a3720fe42ef352778bf2533", "message": "[FLINK-16377][table] Support calls to inline functions in the\nexpressions DSL.", "committedDate": "2020-03-25T15:35:46Z", "type": "forcePushed"}]}