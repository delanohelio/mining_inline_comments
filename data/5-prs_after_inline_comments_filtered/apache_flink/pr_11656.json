{"pr_number": 11656, "pr_title": "[FLINK-16983][python] Support RowType in vectorized Python UDF", "pr_createdAt": "2020-04-07T10:54:51Z", "pr_url": "https://github.com/apache/flink/pull/11656", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjA1MTU3Ng==", "url": "https://github.com/apache/flink/pull/11656#discussion_r406051576", "bodyText": "new Row(n)?", "author": "hequn8128", "createdAt": "2020-04-09T08:46:46Z", "path": "flink-python/src/test/java/org/apache/flink/table/runtime/arrow/RowArrowReaderWriterTest.java", "diffHunk": "@@ -118,18 +127,20 @@ public static void init() {\n \t\t\tSqlDateTimeUtils.internalToTime(3600000), SqlDateTimeUtils.internalToTime(3600000), SqlDateTimeUtils.internalToTime(3600000), SqlDateTimeUtils.internalToTime(3600000),\n \t\t\tnew Timestamp(3600000), new Timestamp(3600000), new Timestamp(3600000), new Timestamp(3600000),\n \t\t\tnew Timestamp(3600000), new Timestamp(3600000), new Timestamp(3600000), new Timestamp(3600000),\n-\t\t\tnew String[] {null, null, null});\n+\t\t\tnew String[] {null, null, null},\n+\t\t\tRow.of(1, \"hello\", new String[] {null, null, null}, new Timestamp(3600000), Row.of(1, \"hello\")));\n \t\tRow row2 = Row.of(null, (short) 2, 3, 4L, false, 1.0f, 1.0, \"\u4e2d\u6587\", \"\u4e2d\u6587\".getBytes(), new BigDecimal(1), SqlDateTimeUtils.internalToDate(100),\n \t\t\tSqlDateTimeUtils.internalToTime(3600000), SqlDateTimeUtils.internalToTime(3600000), SqlDateTimeUtils.internalToTime(3600000), SqlDateTimeUtils.internalToTime(3600000),\n \t\t\tnew Timestamp(3600000), new Timestamp(3600000), new Timestamp(3600000), new Timestamp(3600000),\n \t\t\tnew Timestamp(3600000), new Timestamp(3600000), new Timestamp(3600000), new Timestamp(3600000),\n-\t\t\tnew String[] {\"hello\", \"\u4e2d\u6587\", null});\n+\t\t\tnew String[] {\"hello\", \"\u4e2d\u6587\", null},\n+\t\t\tRow.of(1, \"hello\", new String[] {\"hello\", \"\u4e2d\u6587\", null}, new Timestamp(3600000), Row.of(1, \"hello\")));\n \t\tRow row3 = Row.of((byte) 1, null, 3, 4L, true, 1.0f, 1.0, \"hello\", \"hello\".getBytes(), new BigDecimal(1), SqlDateTimeUtils.internalToDate(100),\n \t\t\tSqlDateTimeUtils.internalToTime(3600000), SqlDateTimeUtils.internalToTime(3600000), SqlDateTimeUtils.internalToTime(3600000), SqlDateTimeUtils.internalToTime(3600000),\n \t\t\tnew Timestamp(3600000), new Timestamp(3600000), new Timestamp(3600000), new Timestamp(3600000),\n \t\t\tnew Timestamp(3600000), new Timestamp(3600000), new Timestamp(3600000), new Timestamp(3600000),\n-\t\t\tnull);\n-\t\tRow row4 = Row.of(null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null);\n+\t\t\tnull, null);\n+\t\tRow row4 = Row.of(null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null);", "originalCommit": "4597eea52db61944a6fd122f55392eb4a165ea32", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjA1NjM5Nw==", "url": "https://github.com/apache/flink/pull/11656#discussion_r406056397", "bodyText": "StreamRecordUtils.baserow(new Object[n]) ?", "author": "hequn8128", "createdAt": "2020-04-09T08:55:07Z", "path": "flink-python/src/test/java/org/apache/flink/table/runtime/arrow/BaseRowArrowReaderWriterTest.java", "diffHunk": "@@ -152,21 +164,25 @@ public static void init() {\n \t\tBaseRow row1 = StreamRecordUtils.baserow((byte) 1, (short) 2, 3, 4L, true, 1.0f, 1.0, \"hello\", \"hello\".getBytes(), Decimal.fromLong(1, 10, 3), 100, 3600000, 3600000, 3600000, 3600000,\n \t\t\tSqlTimestamp.fromEpochMillis(3600000), SqlTimestamp.fromEpochMillis(3600000), SqlTimestamp.fromEpochMillis(3600000, 100000), SqlTimestamp.fromEpochMillis(3600000, 100000),\n \t\t\tSqlTimestamp.fromEpochMillis(3600000), SqlTimestamp.fromEpochMillis(3600000), SqlTimestamp.fromEpochMillis(3600000, 100000), SqlTimestamp.fromEpochMillis(3600000, 100000),\n-\t\t\tnew GenericArray(new BinaryString[] {BinaryString.fromString(\"hello\"), BinaryString.fromString(\"\u4e2d\u6587\"), null}, 3));\n+\t\t\tnew GenericArray(new BinaryString[] {BinaryString.fromString(\"hello\"), BinaryString.fromString(\"\u4e2d\u6587\"), null}, 3),\n+\t\t\tGenericRow.of(1, BinaryString.fromString(\"hello\"), new GenericArray(new BinaryString[] {BinaryString.fromString(\"hello\")}, 1), SqlTimestamp.fromEpochMillis(3600000), GenericRow.of(1, BinaryString.fromString(\"hello\"))));\n \t\tBinaryRow row2 = StreamRecordUtils.binaryrow((byte) 1, (short) 2, 3, 4L, false, 1.0f, 1.0, \"\u4e2d\u6587\", \"\u4e2d\u6587\".getBytes(), Decimal.fromLong(1, 10, 3), 100, 3600000, 3600000, 3600000, 3600000,\n \t\t\tTuple2.of(SqlTimestamp.fromEpochMillis(3600000), 0), Tuple2.of(SqlTimestamp.fromEpochMillis(3600000), 2), Tuple2.of(SqlTimestamp.fromEpochMillis(3600000, 100000), 4), Tuple2.of(SqlTimestamp.fromEpochMillis(3600000, 100000), 8),\n \t\t\tTuple2.of(SqlTimestamp.fromEpochMillis(3600000), 0), Tuple2.of(SqlTimestamp.fromEpochMillis(3600000), 2), Tuple2.of(SqlTimestamp.fromEpochMillis(3600000, 100000), 4), Tuple2.of(SqlTimestamp.fromEpochMillis(3600000, 100000), 8),\n-\t\t\tTuple2.of(new GenericArray(new String[] {null, null, null}, 3), new BaseArraySerializer(new VarCharType(), null)));\n+\t\t\tTuple2.of(new GenericArray(new String[] {null, null, null}, 3), new BaseArraySerializer(new VarCharType(), null)),\n+\t\t\tTuple2.of(GenericRow.of(1, null, new GenericArray(new BinaryString[] {BinaryString.fromString(\"hello\")}, 1), null, GenericRow.of(1, BinaryString.fromString(\"hello\"))), new BaseRowSerializer(new ExecutionConfig(), rowFieldType)));\n \t\tBaseRow row3 = StreamRecordUtils.baserow(null, (short) 2, 3, 4L, false, 1.0f, 1.0, \"\u4e2d\u6587\", \"\u4e2d\u6587\".getBytes(), Decimal.fromLong(1, 10, 3), 100, 3600000, 3600000, 3600000, 3600000,\n \t\t\tSqlTimestamp.fromEpochMillis(3600000), SqlTimestamp.fromEpochMillis(3600000), SqlTimestamp.fromEpochMillis(3600000, 100000), SqlTimestamp.fromEpochMillis(3600000, 100000),\n \t\t\tSqlTimestamp.fromEpochMillis(3600000), SqlTimestamp.fromEpochMillis(3600000), SqlTimestamp.fromEpochMillis(3600000, 100000), SqlTimestamp.fromEpochMillis(3600000, 100000),\n-\t\t\tnew GenericArray(new String[] {null, null, null}, 3));\n+\t\t\tnew GenericArray(new String[] {null, null, null}, 3),\n+\t\t\tGenericRow.of(1, null, new GenericArray(new BinaryString[] {BinaryString.fromString(\"hello\")}, 1), null, null));\n \t\tBinaryRow row4 = StreamRecordUtils.binaryrow((byte) 1, null, 3, 4L, true, 1.0f, 1.0, \"hello\", \"hello\".getBytes(), Decimal.fromLong(1, 10, 3), 100, 3600000, 3600000, 3600000, 3600000,\n \t\t\tTuple2.of(SqlTimestamp.fromEpochMillis(3600000), 0), Tuple2.of(SqlTimestamp.fromEpochMillis(3600000), 2), Tuple2.of(SqlTimestamp.fromEpochMillis(3600000, 100000), 4), Tuple2.of(SqlTimestamp.fromEpochMillis(3600000, 100000), 8),\n \t\t\tTuple2.of(SqlTimestamp.fromEpochMillis(3600000), 0), Tuple2.of(SqlTimestamp.fromEpochMillis(3600000), 2), Tuple2.of(SqlTimestamp.fromEpochMillis(3600000, 100000), 4), Tuple2.of(SqlTimestamp.fromEpochMillis(3600000, 100000), 8),\n-\t\t\tTuple2.of(new GenericArray(new BinaryString[] {BinaryString.fromString(\"hello\"), BinaryString.fromString(\"\u4e2d\u6587\"), null}, 3), new BaseArraySerializer(new VarCharType(), null)));\n-\t\tBaseRow row5 = StreamRecordUtils.baserow(null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null);\n-\t\tBinaryRow row6 = StreamRecordUtils.binaryrow(null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null);\n+\t\t\tTuple2.of(new GenericArray(new BinaryString[] {BinaryString.fromString(\"hello\"), BinaryString.fromString(\"\u4e2d\u6587\"), null}, 3), new BaseArraySerializer(new VarCharType(), null)),\n+\t\t\tTuple2.of(GenericRow.of(1, null, new GenericArray(new BinaryString[] {BinaryString.fromString(\"hello\")}, 1), null, null), new BaseRowSerializer(new ExecutionConfig(), rowFieldType)));\n+\t\tBaseRow row5 = StreamRecordUtils.baserow(null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null);", "originalCommit": "4597eea52db61944a6fd122f55392eb4a165ea32", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "eeb34a5dcd83ce70e0863b003f4eced6a2e2a353", "url": "https://github.com/apache/flink/commit/eeb34a5dcd83ce70e0863b003f4eced6a2e2a353", "message": "[FLINK-16983][table-runtime-blink] Introduce row column vector in blink", "committedDate": "2020-04-10T06:48:49Z", "type": "commit"}, {"oid": "ed4b87dfa57d1b0dca1623ddd40e29de6037839b", "url": "https://github.com/apache/flink/commit/ed4b87dfa57d1b0dca1623ddd40e29de6037839b", "message": "[FLINK-16983][python] Support RowType in vectorized Python UDF", "committedDate": "2020-04-10T06:49:05Z", "type": "commit"}, {"oid": "ed4b87dfa57d1b0dca1623ddd40e29de6037839b", "url": "https://github.com/apache/flink/commit/ed4b87dfa57d1b0dca1623ddd40e29de6037839b", "message": "[FLINK-16983][python] Support RowType in vectorized Python UDF", "committedDate": "2020-04-10T06:49:05Z", "type": "forcePushed"}]}