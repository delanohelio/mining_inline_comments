{"pr_number": 11195, "pr_title": "[FLINK-16222][runtime] Use plugins mechanism for initializing MetricReporters", "pr_createdAt": "2020-02-23T12:17:34Z", "pr_url": "https://github.com/apache/flink/pull/11195", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2NTQzMg==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386465432", "bodyText": "we don't allow star imports", "author": "zentol", "createdAt": "2020-03-02T15:34:23Z", "path": "flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/FlinkDistribution.java", "diffHunk": "@@ -38,11 +38,7 @@\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n-import java.io.BufferedReader;\n-import java.io.FileInputStream;\n-import java.io.FileNotFoundException;\n-import java.io.IOException;\n-import java.io.InputStreamReader;\n+import java.io.*;", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjYyODM4Nw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386628387", "bodyText": "fixed", "author": "afedulov", "createdAt": "2020-03-02T20:21:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2NTQzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2NzkwMQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386467901", "bodyText": "why is this passing null and not following the same approach as JobManagerHAProcessFailureRecoveryITCase?", "author": "zentol", "createdAt": "2020-03-02T15:38:29Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/taskexecutor/TaskManagerRunnerTest.java", "diffHunk": "@@ -92,7 +92,7 @@ private static Configuration createConfiguration() {\n \t}\n \n \tprivate static TaskManagerRunner createTaskManagerRunner(final Configuration configuration) throws Exception {\n-\t\tTaskManagerRunner taskManagerRunner = new TaskManagerRunner(configuration, ResourceID.generate());\n+\t\tTaskManagerRunner taskManagerRunner = new TaskManagerRunner(configuration, ResourceID.generate(), null);", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjYyMDc2NA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386620764", "bodyText": "adjusted", "author": "afedulov", "createdAt": "2020-03-02T20:05:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2NzkwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2ODY5MQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386468691", "bodyText": "In the PRs current state pluginManager should be annotated with Nullable", "author": "zentol", "createdAt": "2020-03-02T15:39:35Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskManagerRunner.java", "diffHunk": "@@ -119,7 +120,7 @@\n \n \tprivate boolean shutdown;\n \n-\tpublic TaskManagerRunner(Configuration configuration, ResourceID resourceId) throws Exception {\n+\tpublic TaskManagerRunner(Configuration configuration, ResourceID resourceId, PluginManager pluginManager) throws Exception {", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY0NDUwMQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386644501", "bodyText": "I am  not sure what should be the expected contract here. ReporterSetup will currently only work with the null pluginManager if no reporters are configured (namedReporters.isEmpty()). We could maybe add a checkNonNull in  the ReporterSetup after that first return due to empty namedReporters.\n(TaskManagerRunnerTest is now fixed to initialize the PluginManager properly)", "author": "afedulov", "createdAt": "2020-03-02T20:55:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2ODY5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODMxMjQ5OQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r388312499", "bodyText": "FileSystem can also take a null for plugin manager. We should probably extract an interface and have a no-op implementation instead. That's out of scope for this PR though.", "author": "AHeise", "createdAt": "2020-03-05T14:04:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2ODY5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2OTAwMw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386469003", "bodyText": "revert", "author": "zentol", "createdAt": "2020-03-02T15:40:04Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -273,3 +319,4 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\treturn Optional.of((MetricReporter) reporterClass.newInstance());\n \t}\n }\n+", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY2MjM3Nw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386662377", "bodyText": "done", "author": "afedulov", "createdAt": "2020-03-02T21:31:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2OTAwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2OTY5Ng==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386469696", "bodyText": "remove TODOs", "author": "zentol", "createdAt": "2020-03-02T15:41:07Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -178,36 +164,96 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\t\t\tmetricReporterOptional.ifPresent(reporter -> {\n \t\t\t\t\tMetricConfig metricConfig = new MetricConfig();\n \t\t\t\t\treporterConfig.addAllToProperties(metricConfig);\n-\n-\t\t\t\t\treporterArguments.add(createReporterSetup(reporterName, metricConfig, reporter));\n+\t\t\t\t\treporterSetups.add(createReporterSetup(reporterName, metricConfig, reporter));\n \t\t\t\t});\n-\t\t\t}\n-\t\t\tcatch (Throwable t) {\n+\t\t\t} catch (Throwable t) {\n \t\t\t\tLOG.error(\"Could not instantiate metrics reporter {}. Metrics might not be exposed/reported.\", reporterName, t);\n \t\t\t}\n \t\t}\n-\t\treturn reporterArguments;\n+\t\treturn reporterSetups;\n \t}\n \n-\tprivate static Map<String, MetricReporterFactory> loadReporterFactories() {\n-\t\tfinal ServiceLoader<MetricReporterFactory> serviceLoader = ServiceLoader.load(MetricReporterFactory.class);\n+\tprivate static List<Tuple2<String, Configuration>> loadReporterConfigurations(Configuration configuration, Set<String> namedReporters) {\n+\t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = new ArrayList<>(namedReporters.size());\n+\n+\t\tfor (String namedReporter: namedReporters) {\n+\t\t\tDelegatingConfiguration delegatingConfiguration = new DelegatingConfiguration(\n+\t\t\t\tconfiguration,\n+\t\t\t\tConfigConstants.METRICS_REPORTER_PREFIX + namedReporter + '.');\n \n+\t\t\treporterConfigurations.add(Tuple2.of(namedReporter, delegatingConfiguration));\n+\t\t}\n+\t\treturn reporterConfigurations;\n+\t}\n+\n+\tprivate static Set<String> findEnabledReportersInConfiguration(Configuration configuration, String includedReportersString) {\n+\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)\n+\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n+\t\t\t.collect(Collectors.toSet());\n+\n+\t\t// use a TreeSet to make the reporter order deterministic, which is useful for testing\n+\t\tSet<String> namedOrderedReporters = new TreeSet<>(String::compareTo);\n+\n+\t\t// scan entire configuration for keys starting with METRICS_REPORTER_PREFIX and determine the set of enabled reporters\n+\t\tfor (String key : configuration.keySet()) {\n+\t\t\tif (key.startsWith(ConfigConstants.METRICS_REPORTER_PREFIX)) {\n+\t\t\t\tMatcher matcher = reporterClassPattern.matcher(key);\n+\t\t\t\tif (matcher.matches()) {\n+\t\t\t\t\tString reporterName = matcher.group(1);\n+\t\t\t\t\tif (includedReporters.isEmpty() || includedReporters.contains(reporterName)) {\n+\t\t\t\t\t\tif (namedOrderedReporters.contains(reporterName)) {\n+\t\t\t\t\t\t\tLOG.warn(\"Duplicate class configuration detected for reporter {}.\", reporterName);\n+\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\tnamedOrderedReporters.add(reporterName);\n+\t\t\t\t\t\t}\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tLOG.info(\"Excluding reporter {}, not configured in reporter list ({}).\", reporterName, includedReportersString);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\treturn namedOrderedReporters;\n+\t}\n+\n+\tprivate static Map<String, MetricReporterFactory> loadAvailableReporterFactories(PluginManager pluginManager) {\n \t\tfinal Map<String, MetricReporterFactory> reporterFactories = new HashMap<>(2);\n-\t\tfinal Iterator<MetricReporterFactory> factoryIterator = serviceLoader.iterator();\n+\t\tfinal Iterator<MetricReporterFactory> factoryIterator = getAllReporterFactories(pluginManager);\n+\t\tLOG.debug(\"All available factories (from both SPIs and Plugins):\");\n+\t\tgetAllReporterFactories(pluginManager).forEachRemaining(i -> LOG.debug(i.toString()));\n \t\t// do not use streams or for-each loops here because they do not allow catching individual ServiceConfigurationErrors\n \t\t// such an error might be caused if the META-INF/services contains an entry to a non-existing factory class\n \t\twhile (factoryIterator.hasNext()) {\n \t\t\ttry {\n \t\t\t\tMetricReporterFactory factory = factoryIterator.next();\n-\t\t\t\treporterFactories.put(factory.getClass().getName(), factory);\n+\t\t\t\tString factoryClassName = factory.getClass().getName();\n+\t\t\t\tMetricReporterFactory existingFactory = reporterFactories.get(factoryClassName);\n+\t\t\t\tif (existingFactory == null){\n+\t\t\t\t\treporterFactories.put(factoryClassName, factory);\n+\t\t\t\t\tLOG.warn(new File(factory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+\t\t\t\t\t\t.toURI()).getCanonicalPath());\n+\t\t\t\t} else {\n+\t\t\t\t\t//TODO: use path information below, when Plugin Classloader stops always prioritizing factories from /lib\n+//\t\t\t\t\tString jarPath1 = new File(existingFactory.getClass().getProtectionDomain().getCodeSource().getLocation()", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjYzMDkyOQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386630929", "bodyText": "ping @pnowojski @AHeise  (depends if we want to proceed with the classloading modifications)", "author": "afedulov", "createdAt": "2020-03-02T20:26:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2OTY5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0ODM0OA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r388348348", "bodyText": "Takes a while until we get proper SPI, so I'd add the commented code to increase usability.", "author": "AHeise", "createdAt": "2020-03-05T15:00:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2OTY5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzU3MDg0Nw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393570847", "bodyText": "@AHeise the jar path for existing metrics reporters will currently point to the same file due to parent-first loading of org.apache.flink packages (even if one of the jars is in /plugin directory). It might be misleading, so I wanted to keep the note for improvement for later, for when the loading is done differently.", "author": "afedulov", "createdAt": "2020-03-17T10:13:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2OTY5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE0NzI2NQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r394147265", "bodyText": "So this would then only work for two plugins. I don't see a way around that without proper SPI.\nI'd probably remove the commented code completely; it shouldn't be hard to bring back and would avoid some confusion.", "author": "AHeise", "createdAt": "2020-03-18T07:25:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2OTY5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDI0NjUyOA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r394246528", "bodyText": "We usually don't allow commented code, and I agree with arvid that it would be easy to bring back.", "author": "zentol", "createdAt": "2020-03-18T10:31:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2OTY5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM2ODA3Mw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395368073", "bodyText": "Removed.", "author": "afedulov", "createdAt": "2020-03-19T23:06:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2OTY5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2OTc0MA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386469740", "bodyText": "revert", "author": "zentol", "createdAt": "2020-03-02T15:41:11Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -178,36 +164,96 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\t\t\tmetricReporterOptional.ifPresent(reporter -> {\n \t\t\t\t\tMetricConfig metricConfig = new MetricConfig();\n \t\t\t\t\treporterConfig.addAllToProperties(metricConfig);\n-\n-\t\t\t\t\treporterArguments.add(createReporterSetup(reporterName, metricConfig, reporter));\n+\t\t\t\t\treporterSetups.add(createReporterSetup(reporterName, metricConfig, reporter));\n \t\t\t\t});\n-\t\t\t}\n-\t\t\tcatch (Throwable t) {\n+\t\t\t} catch (Throwable t) {\n \t\t\t\tLOG.error(\"Could not instantiate metrics reporter {}. Metrics might not be exposed/reported.\", reporterName, t);\n \t\t\t}\n \t\t}\n-\t\treturn reporterArguments;\n+\t\treturn reporterSetups;\n \t}\n \n-\tprivate static Map<String, MetricReporterFactory> loadReporterFactories() {\n-\t\tfinal ServiceLoader<MetricReporterFactory> serviceLoader = ServiceLoader.load(MetricReporterFactory.class);\n+\tprivate static List<Tuple2<String, Configuration>> loadReporterConfigurations(Configuration configuration, Set<String> namedReporters) {\n+\t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = new ArrayList<>(namedReporters.size());\n+\n+\t\tfor (String namedReporter: namedReporters) {\n+\t\t\tDelegatingConfiguration delegatingConfiguration = new DelegatingConfiguration(\n+\t\t\t\tconfiguration,\n+\t\t\t\tConfigConstants.METRICS_REPORTER_PREFIX + namedReporter + '.');\n \n+\t\t\treporterConfigurations.add(Tuple2.of(namedReporter, delegatingConfiguration));\n+\t\t}\n+\t\treturn reporterConfigurations;\n+\t}\n+\n+\tprivate static Set<String> findEnabledReportersInConfiguration(Configuration configuration, String includedReportersString) {\n+\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)\n+\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n+\t\t\t.collect(Collectors.toSet());\n+\n+\t\t// use a TreeSet to make the reporter order deterministic, which is useful for testing\n+\t\tSet<String> namedOrderedReporters = new TreeSet<>(String::compareTo);\n+\n+\t\t// scan entire configuration for keys starting with METRICS_REPORTER_PREFIX and determine the set of enabled reporters\n+\t\tfor (String key : configuration.keySet()) {\n+\t\t\tif (key.startsWith(ConfigConstants.METRICS_REPORTER_PREFIX)) {\n+\t\t\t\tMatcher matcher = reporterClassPattern.matcher(key);\n+\t\t\t\tif (matcher.matches()) {\n+\t\t\t\t\tString reporterName = matcher.group(1);\n+\t\t\t\t\tif (includedReporters.isEmpty() || includedReporters.contains(reporterName)) {\n+\t\t\t\t\t\tif (namedOrderedReporters.contains(reporterName)) {\n+\t\t\t\t\t\t\tLOG.warn(\"Duplicate class configuration detected for reporter {}.\", reporterName);\n+\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\tnamedOrderedReporters.add(reporterName);\n+\t\t\t\t\t\t}\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tLOG.info(\"Excluding reporter {}, not configured in reporter list ({}).\", reporterName, includedReportersString);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\treturn namedOrderedReporters;\n+\t}\n+\n+\tprivate static Map<String, MetricReporterFactory> loadAvailableReporterFactories(PluginManager pluginManager) {\n \t\tfinal Map<String, MetricReporterFactory> reporterFactories = new HashMap<>(2);\n-\t\tfinal Iterator<MetricReporterFactory> factoryIterator = serviceLoader.iterator();\n+\t\tfinal Iterator<MetricReporterFactory> factoryIterator = getAllReporterFactories(pluginManager);\n+\t\tLOG.debug(\"All available factories (from both SPIs and Plugins):\");\n+\t\tgetAllReporterFactories(pluginManager).forEachRemaining(i -> LOG.debug(i.toString()));\n \t\t// do not use streams or for-each loops here because they do not allow catching individual ServiceConfigurationErrors\n \t\t// such an error might be caused if the META-INF/services contains an entry to a non-existing factory class\n \t\twhile (factoryIterator.hasNext()) {\n \t\t\ttry {\n \t\t\t\tMetricReporterFactory factory = factoryIterator.next();\n-\t\t\t\treporterFactories.put(factory.getClass().getName(), factory);\n+\t\t\t\tString factoryClassName = factory.getClass().getName();\n+\t\t\t\tMetricReporterFactory existingFactory = reporterFactories.get(factoryClassName);\n+\t\t\t\tif (existingFactory == null){\n+\t\t\t\t\treporterFactories.put(factoryClassName, factory);\n+\t\t\t\t\tLOG.warn(new File(factory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+\t\t\t\t\t\t.toURI()).getCanonicalPath());\n+\t\t\t\t} else {\n+\t\t\t\t\t//TODO: use path information below, when Plugin Classloader stops always prioritizing factories from /lib\n+//\t\t\t\t\tString jarPath1 = new File(existingFactory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+//\t\t\t\t\t\t.toURI()).getCanonicalPath();\n+//\t\t\t\t\tString jarPath2 = new File(factory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+//\t\t\t\t\t\t.toURI()).getCanonicalPath();\n+//\t\t\t\t\tLOG.warn(\"Multiple implementations of the same reporter were found: \\n {} and \\n{}\", jarPath1, jarPath2);\n+\t\t\t\t\tLOG.warn(\"Multiple implementations of the same reporter were found in 'lib' and 'plugins' directories for {}. It is recommended to remove redundant reporter JARs to resolve used versions' ambiguity.\", factoryClassName);\n+\t\t\t\t}\n \t\t\t} catch (Exception | ServiceConfigurationError e) {\n \t\t\t\tLOG.warn(\"Error while loading reporter factory.\", e);\n \t\t\t}\n \t\t}\n-", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY0OTA3OQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386649079", "bodyText": "Is this a preferred style in Flink or just according to a principle of touching as few lines as possible?", "author": "afedulov", "createdAt": "2020-03-02T21:04:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2OTc0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3MTg5MQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386471891", "bodyText": "Is it guaranteed that they are in opt and lib? What if 2 plugins specified the same factory class?", "author": "zentol", "createdAt": "2020-03-02T15:44:25Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -178,36 +164,96 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\t\t\tmetricReporterOptional.ifPresent(reporter -> {\n \t\t\t\t\tMetricConfig metricConfig = new MetricConfig();\n \t\t\t\t\treporterConfig.addAllToProperties(metricConfig);\n-\n-\t\t\t\t\treporterArguments.add(createReporterSetup(reporterName, metricConfig, reporter));\n+\t\t\t\t\treporterSetups.add(createReporterSetup(reporterName, metricConfig, reporter));\n \t\t\t\t});\n-\t\t\t}\n-\t\t\tcatch (Throwable t) {\n+\t\t\t} catch (Throwable t) {\n \t\t\t\tLOG.error(\"Could not instantiate metrics reporter {}. Metrics might not be exposed/reported.\", reporterName, t);\n \t\t\t}\n \t\t}\n-\t\treturn reporterArguments;\n+\t\treturn reporterSetups;\n \t}\n \n-\tprivate static Map<String, MetricReporterFactory> loadReporterFactories() {\n-\t\tfinal ServiceLoader<MetricReporterFactory> serviceLoader = ServiceLoader.load(MetricReporterFactory.class);\n+\tprivate static List<Tuple2<String, Configuration>> loadReporterConfigurations(Configuration configuration, Set<String> namedReporters) {\n+\t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = new ArrayList<>(namedReporters.size());\n+\n+\t\tfor (String namedReporter: namedReporters) {\n+\t\t\tDelegatingConfiguration delegatingConfiguration = new DelegatingConfiguration(\n+\t\t\t\tconfiguration,\n+\t\t\t\tConfigConstants.METRICS_REPORTER_PREFIX + namedReporter + '.');\n \n+\t\t\treporterConfigurations.add(Tuple2.of(namedReporter, delegatingConfiguration));\n+\t\t}\n+\t\treturn reporterConfigurations;\n+\t}\n+\n+\tprivate static Set<String> findEnabledReportersInConfiguration(Configuration configuration, String includedReportersString) {\n+\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)\n+\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n+\t\t\t.collect(Collectors.toSet());\n+\n+\t\t// use a TreeSet to make the reporter order deterministic, which is useful for testing\n+\t\tSet<String> namedOrderedReporters = new TreeSet<>(String::compareTo);\n+\n+\t\t// scan entire configuration for keys starting with METRICS_REPORTER_PREFIX and determine the set of enabled reporters\n+\t\tfor (String key : configuration.keySet()) {\n+\t\t\tif (key.startsWith(ConfigConstants.METRICS_REPORTER_PREFIX)) {\n+\t\t\t\tMatcher matcher = reporterClassPattern.matcher(key);\n+\t\t\t\tif (matcher.matches()) {\n+\t\t\t\t\tString reporterName = matcher.group(1);\n+\t\t\t\t\tif (includedReporters.isEmpty() || includedReporters.contains(reporterName)) {\n+\t\t\t\t\t\tif (namedOrderedReporters.contains(reporterName)) {\n+\t\t\t\t\t\t\tLOG.warn(\"Duplicate class configuration detected for reporter {}.\", reporterName);\n+\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\tnamedOrderedReporters.add(reporterName);\n+\t\t\t\t\t\t}\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tLOG.info(\"Excluding reporter {}, not configured in reporter list ({}).\", reporterName, includedReportersString);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\treturn namedOrderedReporters;\n+\t}\n+\n+\tprivate static Map<String, MetricReporterFactory> loadAvailableReporterFactories(PluginManager pluginManager) {\n \t\tfinal Map<String, MetricReporterFactory> reporterFactories = new HashMap<>(2);\n-\t\tfinal Iterator<MetricReporterFactory> factoryIterator = serviceLoader.iterator();\n+\t\tfinal Iterator<MetricReporterFactory> factoryIterator = getAllReporterFactories(pluginManager);\n+\t\tLOG.debug(\"All available factories (from both SPIs and Plugins):\");\n+\t\tgetAllReporterFactories(pluginManager).forEachRemaining(i -> LOG.debug(i.toString()));\n \t\t// do not use streams or for-each loops here because they do not allow catching individual ServiceConfigurationErrors\n \t\t// such an error might be caused if the META-INF/services contains an entry to a non-existing factory class\n \t\twhile (factoryIterator.hasNext()) {\n \t\t\ttry {\n \t\t\t\tMetricReporterFactory factory = factoryIterator.next();\n-\t\t\t\treporterFactories.put(factory.getClass().getName(), factory);\n+\t\t\t\tString factoryClassName = factory.getClass().getName();\n+\t\t\t\tMetricReporterFactory existingFactory = reporterFactories.get(factoryClassName);\n+\t\t\t\tif (existingFactory == null){\n+\t\t\t\t\treporterFactories.put(factoryClassName, factory);\n+\t\t\t\t\tLOG.warn(new File(factory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+\t\t\t\t\t\t.toURI()).getCanonicalPath());\n+\t\t\t\t} else {\n+\t\t\t\t\t//TODO: use path information below, when Plugin Classloader stops always prioritizing factories from /lib\n+//\t\t\t\t\tString jarPath1 = new File(existingFactory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+//\t\t\t\t\t\t.toURI()).getCanonicalPath();\n+//\t\t\t\t\tString jarPath2 = new File(factory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+//\t\t\t\t\t\t.toURI()).getCanonicalPath();\n+//\t\t\t\t\tLOG.warn(\"Multiple implementations of the same reporter were found: \\n {} and \\n{}\", jarPath1, jarPath2);\n+\t\t\t\t\tLOG.warn(\"Multiple implementations of the same reporter were found in 'lib' and 'plugins' directories for {}. It is recommended to remove redundant reporter JARs to resolve used versions' ambiguity.\", factoryClassName);", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY0NjY5Mg==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386646692", "bodyText": "But this would technically be \"multiple implementations of the same reporter\"? The message does not tell explicitly that one of them is in lib and another in plugins - just that while searching those two directories, multiple implementations were found.", "author": "afedulov", "createdAt": "2020-03-02T20:59:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3MTg5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0NzgxMg==", "url": "https://github.com/apache/flink/pull/11195#discussion_r388347812", "bodyText": "Should be 'or'", "author": "AHeise", "createdAt": "2020-03-05T14:59:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3MTg5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzU4MDQ1Mw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393580453", "bodyText": "Strictly speaking it then should be 'and/or', because 'or' could mean that there are two jars, both of which are either in 'lib' or in 'plugins'. I think and was more fitting, but I am also ok with and/or", "author": "afedulov", "createdAt": "2020-03-17T10:30:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3MTg5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3MjQ5MQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386472491", "bodyText": "Given that we are iterating over all factories anyway we should be able to move this into the while loop.", "author": "zentol", "createdAt": "2020-03-02T15:45:14Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -178,36 +164,96 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\t\t\tmetricReporterOptional.ifPresent(reporter -> {\n \t\t\t\t\tMetricConfig metricConfig = new MetricConfig();\n \t\t\t\t\treporterConfig.addAllToProperties(metricConfig);\n-\n-\t\t\t\t\treporterArguments.add(createReporterSetup(reporterName, metricConfig, reporter));\n+\t\t\t\t\treporterSetups.add(createReporterSetup(reporterName, metricConfig, reporter));\n \t\t\t\t});\n-\t\t\t}\n-\t\t\tcatch (Throwable t) {\n+\t\t\t} catch (Throwable t) {\n \t\t\t\tLOG.error(\"Could not instantiate metrics reporter {}. Metrics might not be exposed/reported.\", reporterName, t);\n \t\t\t}\n \t\t}\n-\t\treturn reporterArguments;\n+\t\treturn reporterSetups;\n \t}\n \n-\tprivate static Map<String, MetricReporterFactory> loadReporterFactories() {\n-\t\tfinal ServiceLoader<MetricReporterFactory> serviceLoader = ServiceLoader.load(MetricReporterFactory.class);\n+\tprivate static List<Tuple2<String, Configuration>> loadReporterConfigurations(Configuration configuration, Set<String> namedReporters) {\n+\t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = new ArrayList<>(namedReporters.size());\n+\n+\t\tfor (String namedReporter: namedReporters) {\n+\t\t\tDelegatingConfiguration delegatingConfiguration = new DelegatingConfiguration(\n+\t\t\t\tconfiguration,\n+\t\t\t\tConfigConstants.METRICS_REPORTER_PREFIX + namedReporter + '.');\n \n+\t\t\treporterConfigurations.add(Tuple2.of(namedReporter, delegatingConfiguration));\n+\t\t}\n+\t\treturn reporterConfigurations;\n+\t}\n+\n+\tprivate static Set<String> findEnabledReportersInConfiguration(Configuration configuration, String includedReportersString) {\n+\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)\n+\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n+\t\t\t.collect(Collectors.toSet());\n+\n+\t\t// use a TreeSet to make the reporter order deterministic, which is useful for testing\n+\t\tSet<String> namedOrderedReporters = new TreeSet<>(String::compareTo);\n+\n+\t\t// scan entire configuration for keys starting with METRICS_REPORTER_PREFIX and determine the set of enabled reporters\n+\t\tfor (String key : configuration.keySet()) {\n+\t\t\tif (key.startsWith(ConfigConstants.METRICS_REPORTER_PREFIX)) {\n+\t\t\t\tMatcher matcher = reporterClassPattern.matcher(key);\n+\t\t\t\tif (matcher.matches()) {\n+\t\t\t\t\tString reporterName = matcher.group(1);\n+\t\t\t\t\tif (includedReporters.isEmpty() || includedReporters.contains(reporterName)) {\n+\t\t\t\t\t\tif (namedOrderedReporters.contains(reporterName)) {\n+\t\t\t\t\t\t\tLOG.warn(\"Duplicate class configuration detected for reporter {}.\", reporterName);\n+\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\tnamedOrderedReporters.add(reporterName);\n+\t\t\t\t\t\t}\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tLOG.info(\"Excluding reporter {}, not configured in reporter list ({}).\", reporterName, includedReportersString);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\treturn namedOrderedReporters;\n+\t}\n+\n+\tprivate static Map<String, MetricReporterFactory> loadAvailableReporterFactories(PluginManager pluginManager) {\n \t\tfinal Map<String, MetricReporterFactory> reporterFactories = new HashMap<>(2);\n-\t\tfinal Iterator<MetricReporterFactory> factoryIterator = serviceLoader.iterator();\n+\t\tfinal Iterator<MetricReporterFactory> factoryIterator = getAllReporterFactories(pluginManager);\n+\t\tLOG.debug(\"All available factories (from both SPIs and Plugins):\");\n+\t\tgetAllReporterFactories(pluginManager).forEachRemaining(i -> LOG.debug(i.toString()));", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY2Mjk2Ng==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386662966", "bodyText": "done", "author": "afedulov", "createdAt": "2020-03-02T21:32:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3MjQ5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3MjcwMg==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386472702", "bodyText": "Should likely be removed or replaced with a meaningful INFO message that a factory was found.", "author": "zentol", "createdAt": "2020-03-02T15:45:33Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -178,36 +164,96 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\t\t\tmetricReporterOptional.ifPresent(reporter -> {\n \t\t\t\t\tMetricConfig metricConfig = new MetricConfig();\n \t\t\t\t\treporterConfig.addAllToProperties(metricConfig);\n-\n-\t\t\t\t\treporterArguments.add(createReporterSetup(reporterName, metricConfig, reporter));\n+\t\t\t\t\treporterSetups.add(createReporterSetup(reporterName, metricConfig, reporter));\n \t\t\t\t});\n-\t\t\t}\n-\t\t\tcatch (Throwable t) {\n+\t\t\t} catch (Throwable t) {\n \t\t\t\tLOG.error(\"Could not instantiate metrics reporter {}. Metrics might not be exposed/reported.\", reporterName, t);\n \t\t\t}\n \t\t}\n-\t\treturn reporterArguments;\n+\t\treturn reporterSetups;\n \t}\n \n-\tprivate static Map<String, MetricReporterFactory> loadReporterFactories() {\n-\t\tfinal ServiceLoader<MetricReporterFactory> serviceLoader = ServiceLoader.load(MetricReporterFactory.class);\n+\tprivate static List<Tuple2<String, Configuration>> loadReporterConfigurations(Configuration configuration, Set<String> namedReporters) {\n+\t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = new ArrayList<>(namedReporters.size());\n+\n+\t\tfor (String namedReporter: namedReporters) {\n+\t\t\tDelegatingConfiguration delegatingConfiguration = new DelegatingConfiguration(\n+\t\t\t\tconfiguration,\n+\t\t\t\tConfigConstants.METRICS_REPORTER_PREFIX + namedReporter + '.');\n \n+\t\t\treporterConfigurations.add(Tuple2.of(namedReporter, delegatingConfiguration));\n+\t\t}\n+\t\treturn reporterConfigurations;\n+\t}\n+\n+\tprivate static Set<String> findEnabledReportersInConfiguration(Configuration configuration, String includedReportersString) {\n+\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)\n+\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n+\t\t\t.collect(Collectors.toSet());\n+\n+\t\t// use a TreeSet to make the reporter order deterministic, which is useful for testing\n+\t\tSet<String> namedOrderedReporters = new TreeSet<>(String::compareTo);\n+\n+\t\t// scan entire configuration for keys starting with METRICS_REPORTER_PREFIX and determine the set of enabled reporters\n+\t\tfor (String key : configuration.keySet()) {\n+\t\t\tif (key.startsWith(ConfigConstants.METRICS_REPORTER_PREFIX)) {\n+\t\t\t\tMatcher matcher = reporterClassPattern.matcher(key);\n+\t\t\t\tif (matcher.matches()) {\n+\t\t\t\t\tString reporterName = matcher.group(1);\n+\t\t\t\t\tif (includedReporters.isEmpty() || includedReporters.contains(reporterName)) {\n+\t\t\t\t\t\tif (namedOrderedReporters.contains(reporterName)) {\n+\t\t\t\t\t\t\tLOG.warn(\"Duplicate class configuration detected for reporter {}.\", reporterName);\n+\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\tnamedOrderedReporters.add(reporterName);\n+\t\t\t\t\t\t}\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tLOG.info(\"Excluding reporter {}, not configured in reporter list ({}).\", reporterName, includedReportersString);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\treturn namedOrderedReporters;\n+\t}\n+\n+\tprivate static Map<String, MetricReporterFactory> loadAvailableReporterFactories(PluginManager pluginManager) {\n \t\tfinal Map<String, MetricReporterFactory> reporterFactories = new HashMap<>(2);\n-\t\tfinal Iterator<MetricReporterFactory> factoryIterator = serviceLoader.iterator();\n+\t\tfinal Iterator<MetricReporterFactory> factoryIterator = getAllReporterFactories(pluginManager);\n+\t\tLOG.debug(\"All available factories (from both SPIs and Plugins):\");\n+\t\tgetAllReporterFactories(pluginManager).forEachRemaining(i -> LOG.debug(i.toString()));\n \t\t// do not use streams or for-each loops here because they do not allow catching individual ServiceConfigurationErrors\n \t\t// such an error might be caused if the META-INF/services contains an entry to a non-existing factory class\n \t\twhile (factoryIterator.hasNext()) {\n \t\t\ttry {\n \t\t\t\tMetricReporterFactory factory = factoryIterator.next();\n-\t\t\t\treporterFactories.put(factory.getClass().getName(), factory);\n+\t\t\t\tString factoryClassName = factory.getClass().getName();\n+\t\t\t\tMetricReporterFactory existingFactory = reporterFactories.get(factoryClassName);\n+\t\t\t\tif (existingFactory == null){\n+\t\t\t\t\treporterFactories.put(factoryClassName, factory);\n+\t\t\t\t\tLOG.warn(new File(factory.getClass().getProtectionDomain().getCodeSource().getLocation()", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY2Mzc0NA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386663744", "bodyText": "done", "author": "afedulov", "createdAt": "2020-03-02T21:34:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3MjcwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3NDE4OA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386474188", "bodyText": "why is this necessary?", "author": "zentol", "createdAt": "2020-03-02T15:47:39Z", "path": "flink-metrics/flink-metrics-prometheus/src/main/java/org/apache/flink/metrics/prometheus/PrometheusReporter.java", "diffHunk": "@@ -35,7 +35,7 @@\n  * {@link MetricReporter} that exports {@link Metric Metrics} via Prometheus.\n  */\n @PublicEvolving\n-public class PrometheusReporter extends AbstractPrometheusReporter {\n+public class PrometheusReporter extends AbstractPrometheusReporter implements MetricReporter {", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY3NTUzMA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386675530", "bodyText": "missed that AbstractPrometheusReporter already implements it. Fixed.", "author": "afedulov", "createdAt": "2020-03-02T21:57:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3NDE4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3NDU5MQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386474591", "bodyText": "Add @InstantiateViaFactory annotation so that all instantiations go through the factory.", "author": "zentol", "createdAt": "2020-03-02T15:48:10Z", "path": "flink-metrics/flink-metrics-prometheus/src/main/java/org/apache/flink/metrics/prometheus/PrometheusReporter.java", "diffHunk": "@@ -35,7 +35,7 @@\n  * {@link MetricReporter} that exports {@link Metric Metrics} via Prometheus.\n  */\n @PublicEvolving", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3NDcyMg==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386474722", "bodyText": "revert", "author": "zentol", "createdAt": "2020-03-02T15:48:21Z", "path": "flink-end-to-end-tests/flink-metrics-reporter-prometheus-test/src/test/java/org/apache/flink/metrics/prometheus/tests/PrometheusReporterEndToEndITCase.java", "diffHunk": "@@ -185,6 +214,7 @@ public void testReporter() throws Exception {\n \n \t\t\tcheckMetricAvailability(client, \"flink_jobmanager_numRegisteredTaskManagers\");\n \t\t\tcheckMetricAvailability(client, \"flink_taskmanager_Status_Network_TotalMemorySegments\");\n+", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY4MjgwMA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386682800", "bodyText": "done", "author": "afedulov", "createdAt": "2020-03-02T22:13:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3NDcyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3NjI5MQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386476291", "bodyText": "ping @pnowojski / @AHeise", "author": "zentol", "createdAt": "2020-03-02T15:50:33Z", "path": "flink-core/src/main/java/org/apache/flink/core/plugin/PluginLoader.java", "diffHunk": "@@ -69,7 +68,7 @@ public static PluginLoader create(PluginDescriptor pluginDescriptor, ClassLoader\n \t * @param <P> Type of the requested plugin service.\n \t * @return An iterator of all implementations of the given service interface that could be loaded from the plugin.\n \t */\n-\tpublic <P extends Plugin> Iterator<P> load(Class<P> service) {\n+\tpublic <P> Iterator<P> load(Class<P> service) {", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0MDAyOA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r388340028", "bodyText": "That was actually my proposal, since there is no benefit from implementing Plugin and its #configure method does not work well with existing metric factories.", "author": "AHeise", "createdAt": "2020-03-05T14:47:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3NjI5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI1Njc3MQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393256771", "bodyText": "Marking as resolved.", "author": "afedulov", "createdAt": "2020-03-16T19:15:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3NjI5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3NzY3MA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386477670", "bodyText": "we should actually remove this line (or exclude the metricConfig) as we may be leaking sensitive information.", "author": "zentol", "createdAt": "2020-03-02T15:52:29Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -120,55 +124,37 @@ public static ReporterSetup forReporter(String reporterName, MetricConfig metric\n \t}\n \n \tprivate static ReporterSetup createReporterSetup(String reporterName, MetricConfig metricConfig, MetricReporter reporter) {\n-\t\tLOG.info(\"Configuring {} with {}.\", reporterName, metricConfig);\n+\t\tLOG.debug(\"Configuring {} with {}.\", reporterName, metricConfig);", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjYwNDA3OA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386604078", "bodyText": "Good point. I am not 100% sure about it - do we have a Flink-wide way to handle such cases? I guess the cleanest approach would be to have a special set of keys that are considered sensitive, which have to be obfuscated prior to logging. Seeing which other config values are used during the initialization could be generally pretty useful for debugging.", "author": "afedulov", "createdAt": "2020-03-02T19:32:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3NzY3MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzgzOTc1NA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393839754", "bodyText": "Ping @AHeise @zentol - could we agree on something here?\nI am always \"pro extensive logging\", but this could be professional deformation. Being able to \"on-demand\" see what is going on is very valuable for production systems. We could declare somewhere for Flink in general that if you choose to run with debug log level, some potentially sensitive information could leak into logs. My arguments are:\n\nIf someone has uncontrolled access to the log files on your machine in production, content of this file is probably not the biggest of your problems.\nRunning with debug level is not a \"normal\" scenario - this is intended for hands on investigation of issues. Log level for potentially compromisable external systems could be explicitly set to trace in such cases.\nWe have been \"leaking\" this data in the current versions with info (!) level without much concern", "author": "afedulov", "createdAt": "2020-03-17T17:14:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3NzY3MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzkwMzUwNQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393903505", "bodyText": "do we have a Flink-wide way to handle such cases\n\nThe GlobalConfiguration contains a set of keys that are considered sensitive, which we use for the WebUI and various INFO logging.\n\nWe have been \"leaking\" this data in the current versions with info (!) level without much concern\n\nFew reporters actually use credentials (afaik only datadog does), so the sample size is fairly low.\n\nIf someone has uncontrolled access to the log files on your machine in production, content of this file is probably not the biggest of your problems.\n\nDoesn't need access to the machine; access to the UI is sufficient, which was grave enough that we introduced the whole secret-key concept in the first place.\n\nRunning with debug level is not a \"normal\" scenario - this is intended for hands on investigation of issues. Log level for potentially compromisable external systems could be explicitly set to trace in such cases.\n\nThere's precedence with FLINK-10363 that credentials should not be logged even on debug.\nFLINK-16478 also which proposes a REST API for modifying the log level potentially voiding any argument for it being opt-in insecurity.\nI would approach this cautiously and never log anything sensitive.", "author": "zentol", "createdAt": "2020-03-17T18:58:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3NzY3MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzk1MDY4Mw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393950683", "bodyText": "Removed.", "author": "afedulov", "createdAt": "2020-03-17T20:30:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3NzY3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3Nzc0NQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386477745", "bodyText": "same as above", "author": "zentol", "createdAt": "2020-03-02T15:52:36Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -120,55 +124,37 @@ public static ReporterSetup forReporter(String reporterName, MetricConfig metric\n \t}\n \n \tprivate static ReporterSetup createReporterSetup(String reporterName, MetricConfig metricConfig, MetricReporter reporter) {\n-\t\tLOG.info(\"Configuring {} with {}.\", reporterName, metricConfig);\n+\t\tLOG.debug(\"Configuring {} with {}.\", reporterName, metricConfig);\n \t\treporter.open(metricConfig);\n \n \t\treturn new ReporterSetup(reporterName, metricConfig, reporter);\n \t}\n \n-\tpublic static List<ReporterSetup> fromConfiguration(final Configuration configuration) {\n+\tpublic static List<ReporterSetup> fromConfiguration(final Configuration configuration, final PluginManager pluginManager) {\n+\t\tLOG.debug(\"Initializing Reporters from Configuration: {}\", configuration);", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzk1MDgxMA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393950810", "bodyText": "Removed.", "author": "afedulov", "createdAt": "2020-03-17T20:30:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3Nzc0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3Nzk3Mw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386477973", "bodyText": "revert", "author": "zentol", "createdAt": "2020-03-02T15:52:55Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -178,36 +164,96 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\t\t\tmetricReporterOptional.ifPresent(reporter -> {\n \t\t\t\t\tMetricConfig metricConfig = new MetricConfig();\n \t\t\t\t\treporterConfig.addAllToProperties(metricConfig);\n-\n-\t\t\t\t\treporterArguments.add(createReporterSetup(reporterName, metricConfig, reporter));\n+\t\t\t\t\treporterSetups.add(createReporterSetup(reporterName, metricConfig, reporter));\n \t\t\t\t});\n-\t\t\t}\n-\t\t\tcatch (Throwable t) {\n+\t\t\t} catch (Throwable t) {", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjYxMzk4MQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386613981", "bodyText": "Is this an accepted style in Flink? I mostly see \"classic\" variant with } catch ... , including the same class in loadReporterFactories() method.", "author": "afedulov", "createdAt": "2020-03-02T19:52:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3Nzk3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0NDI1Mw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r388344253", "bodyText": "In general, the best option is to leave old code as is to not blow up the PR. You could make a separate hotfix to address code style fixes though.", "author": "AHeise", "createdAt": "2020-03-05T14:54:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3Nzk3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzgzMjUwMA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393832500", "bodyText": "This whole code block was already \"touched\" anyhow, because of refactoring, so I think it should be OK to do such things, unless you have a strong opinion.", "author": "afedulov", "createdAt": "2020-03-17T17:02:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3Nzk3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDI0MTMyMg==", "url": "https://github.com/apache/flink/pull/11195#discussion_r394241322", "bodyText": "our code style unfortunately does not cover the placement of such braces; hence we reject any changes such as this to existing code.", "author": "zentol", "createdAt": "2020-03-18T10:22:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3Nzk3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5ODMyNA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395298324", "bodyText": "@zentol Ok, I find it a bit strange, but I am not setting the rules here.", "author": "afedulov", "createdAt": "2020-03-19T20:23:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3Nzk3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTMyMzAzMg==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395323032", "bodyText": "Done.", "author": "afedulov", "createdAt": "2020-03-19T21:13:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3Nzk3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3ODY1Mg==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386478652", "bodyText": "reviews are a lot easier if we either a) refrain from non-critical refactorings b) move such refactorings into a separate commit.", "author": "zentol", "createdAt": "2020-03-02T15:53:50Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -120,55 +124,37 @@ public static ReporterSetup forReporter(String reporterName, MetricConfig metric\n \t}\n \n \tprivate static ReporterSetup createReporterSetup(String reporterName, MetricConfig metricConfig, MetricReporter reporter) {\n-\t\tLOG.info(\"Configuring {} with {}.\", reporterName, metricConfig);\n+\t\tLOG.debug(\"Configuring {} with {}.\", reporterName, metricConfig);\n \t\treporter.open(metricConfig);\n \n \t\treturn new ReporterSetup(reporterName, metricConfig, reporter);\n \t}\n \n-\tpublic static List<ReporterSetup> fromConfiguration(final Configuration configuration) {\n+\tpublic static List<ReporterSetup> fromConfiguration(final Configuration configuration, final PluginManager pluginManager) {\n+\t\tLOG.debug(\"Initializing Reporters from Configuration: {}\", configuration);\n \t\tString includedReportersString = configuration.getString(MetricOptions.REPORTERS_LIST, \"\");\n-\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0NDcyNA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r388344724", "bodyText": "\ud83d\udc4d to split up refactoring from actual commit. But in general also \ud83d\udc4d to refactorings.", "author": "AHeise", "createdAt": "2020-03-05T14:54:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3ODY1Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzg0MDk1Mg==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393840952", "bodyText": "Done.", "author": "afedulov", "createdAt": "2020-03-17T17:16:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3ODY1Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5OTM5Ng==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395299396", "bodyText": "As this did not come up in the second round I consider the new split of commits as appropriate. Resolving.", "author": "afedulov", "createdAt": "2020-03-19T20:25:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3ODY1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3OTUwMA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386479500", "bodyText": "same as above about leaking sensitive information", "author": "zentol", "createdAt": "2020-03-02T15:55:01Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -120,55 +124,37 @@ public static ReporterSetup forReporter(String reporterName, MetricConfig metric\n \t}\n \n \tprivate static ReporterSetup createReporterSetup(String reporterName, MetricConfig metricConfig, MetricReporter reporter) {\n-\t\tLOG.info(\"Configuring {} with {}.\", reporterName, metricConfig);\n+\t\tLOG.debug(\"Configuring {} with {}.\", reporterName, metricConfig);\n \t\treporter.open(metricConfig);\n \n \t\treturn new ReporterSetup(reporterName, metricConfig, reporter);\n \t}\n \n-\tpublic static List<ReporterSetup> fromConfiguration(final Configuration configuration) {\n+\tpublic static List<ReporterSetup> fromConfiguration(final Configuration configuration, final PluginManager pluginManager) {\n+\t\tLOG.debug(\"Initializing Reporters from Configuration: {}\", configuration);\n \t\tString includedReportersString = configuration.getString(MetricOptions.REPORTERS_LIST, \"\");\n-\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)\n-\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n-\t\t\t.collect(Collectors.toSet());\n \n-\t\t// use a TreeSet to make the reporter order deterministic, which is useful for testing\n-\t\tSet<String> namedReporters = new TreeSet<>(String::compareTo);\n-\t\t// scan entire configuration for \"metric.reporter\" keys and parse individual reporter configurations\n-\t\tfor (String key : configuration.keySet()) {\n-\t\t\tif (key.startsWith(ConfigConstants.METRICS_REPORTER_PREFIX)) {\n-\t\t\t\tMatcher matcher = reporterClassPattern.matcher(key);\n-\t\t\t\tif (matcher.matches()) {\n-\t\t\t\t\tString reporterName = matcher.group(1);\n-\t\t\t\t\tif (includedReporters.isEmpty() || includedReporters.contains(reporterName)) {\n-\t\t\t\t\t\tif (namedReporters.contains(reporterName)) {\n-\t\t\t\t\t\t\tLOG.warn(\"Duplicate class configuration detected for reporter {}.\", reporterName);\n-\t\t\t\t\t\t} else {\n-\t\t\t\t\t\t\tnamedReporters.add(reporterName);\n-\t\t\t\t\t\t}\n-\t\t\t\t\t} else {\n-\t\t\t\t\t\tLOG.info(\"Excluding reporter {}, not configured in reporter list ({}).\", reporterName, includedReportersString);\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n+\t\tSet<String> namedReporters = findEnabledReportersInConfiguration(configuration,\n+\t\t\tincludedReportersString);\n \n \t\tif (namedReporters.isEmpty()) {\n \t\t\treturn Collections.emptyList();\n \t\t}\n \n-\t\tList<Tuple2<String, Configuration>> reporterConfigurations = new ArrayList<>(namedReporters.size());\n+\t\tfinal Map<String, MetricReporterFactory> reporterFactories = loadAvailableReporterFactories(pluginManager);\n+\t\tLOG.debug(\"Loaded Reporter Factories: {}\", reporterFactories);\n+\t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = loadReporterConfigurations(configuration, namedReporters);\n+\t\tLOG.debug(\"Loaded Reporter Configurations: {}\", reporterConfigurations);", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzk1MDU3OQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393950579", "bodyText": "Addressed.", "author": "afedulov", "createdAt": "2020-03-17T20:30:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3OTUwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3OTUzNw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386479537", "bodyText": "same as above about leaking sensitive information", "author": "zentol", "createdAt": "2020-03-02T15:55:04Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -120,55 +124,37 @@ public static ReporterSetup forReporter(String reporterName, MetricConfig metric\n \t}\n \n \tprivate static ReporterSetup createReporterSetup(String reporterName, MetricConfig metricConfig, MetricReporter reporter) {\n-\t\tLOG.info(\"Configuring {} with {}.\", reporterName, metricConfig);\n+\t\tLOG.debug(\"Configuring {} with {}.\", reporterName, metricConfig);\n \t\treporter.open(metricConfig);\n \n \t\treturn new ReporterSetup(reporterName, metricConfig, reporter);\n \t}\n \n-\tpublic static List<ReporterSetup> fromConfiguration(final Configuration configuration) {\n+\tpublic static List<ReporterSetup> fromConfiguration(final Configuration configuration, final PluginManager pluginManager) {\n+\t\tLOG.debug(\"Initializing Reporters from Configuration: {}\", configuration);\n \t\tString includedReportersString = configuration.getString(MetricOptions.REPORTERS_LIST, \"\");\n-\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)\n-\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n-\t\t\t.collect(Collectors.toSet());\n \n-\t\t// use a TreeSet to make the reporter order deterministic, which is useful for testing\n-\t\tSet<String> namedReporters = new TreeSet<>(String::compareTo);\n-\t\t// scan entire configuration for \"metric.reporter\" keys and parse individual reporter configurations\n-\t\tfor (String key : configuration.keySet()) {\n-\t\t\tif (key.startsWith(ConfigConstants.METRICS_REPORTER_PREFIX)) {\n-\t\t\t\tMatcher matcher = reporterClassPattern.matcher(key);\n-\t\t\t\tif (matcher.matches()) {\n-\t\t\t\t\tString reporterName = matcher.group(1);\n-\t\t\t\t\tif (includedReporters.isEmpty() || includedReporters.contains(reporterName)) {\n-\t\t\t\t\t\tif (namedReporters.contains(reporterName)) {\n-\t\t\t\t\t\t\tLOG.warn(\"Duplicate class configuration detected for reporter {}.\", reporterName);\n-\t\t\t\t\t\t} else {\n-\t\t\t\t\t\t\tnamedReporters.add(reporterName);\n-\t\t\t\t\t\t}\n-\t\t\t\t\t} else {\n-\t\t\t\t\t\tLOG.info(\"Excluding reporter {}, not configured in reporter list ({}).\", reporterName, includedReportersString);\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n+\t\tSet<String> namedReporters = findEnabledReportersInConfiguration(configuration,\n+\t\t\tincludedReportersString);\n \n \t\tif (namedReporters.isEmpty()) {\n \t\t\treturn Collections.emptyList();\n \t\t}\n \n-\t\tList<Tuple2<String, Configuration>> reporterConfigurations = new ArrayList<>(namedReporters.size());\n+\t\tfinal Map<String, MetricReporterFactory> reporterFactories = loadAvailableReporterFactories(pluginManager);\n+\t\tLOG.debug(\"Loaded Reporter Factories: {}\", reporterFactories);\n+\t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = loadReporterConfigurations(configuration, namedReporters);\n+\t\tLOG.debug(\"Loaded Reporter Configurations: {}\", reporterConfigurations);\n \n-\t\tfor (String namedReporter: namedReporters) {\n-\t\t\tDelegatingConfiguration delegatingConfiguration = new DelegatingConfiguration(\n-\t\t\t\tconfiguration,\n-\t\t\t\tConfigConstants.METRICS_REPORTER_PREFIX + namedReporter + '.');\n+\t\tList<ReporterSetup> reporterSetups = setupReporters(reporterFactories, reporterConfigurations);\n+\t\tLOG.debug(\"All initialized Reporters:\");\n+\t\treporterSetups.forEach(i -> LOG.debug(\"{} - {}\", i.getName(), i.getConfiguration()));", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzk1MDUwOA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393950508", "bodyText": "Addressed.", "author": "afedulov", "createdAt": "2020-03-17T20:29:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3OTUzNw=="}], "type": "inlineReview"}, {"oid": "738a6fd162d5ba99432438d224f3b4890961af56", "url": "https://github.com/apache/flink/commit/738a6fd162d5ba99432438d224f3b4890961af56", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters", "committedDate": "2020-03-02T20:03:21Z", "type": "forcePushed"}, {"oid": "1613baf0244adc63bf029415e97227a6770591c9", "url": "https://github.com/apache/flink/commit/1613baf0244adc63bf029415e97227a6770591c9", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters", "committedDate": "2020-03-02T20:18:06Z", "type": "forcePushed"}, {"oid": "21c0efa3b9bae9e5bb23338c23483f41f0d1e738", "url": "https://github.com/apache/flink/commit/21c0efa3b9bae9e5bb23338c23483f41f0d1e738", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters", "committedDate": "2020-03-02T21:23:39Z", "type": "forcePushed"}, {"oid": "77f24b292a04fde34f4c645151484cf86a13832c", "url": "https://github.com/apache/flink/commit/77f24b292a04fde34f4c645151484cf86a13832c", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters", "committedDate": "2020-03-02T21:57:12Z", "type": "forcePushed"}, {"oid": "666e058b3924dd6593106ccffa84ebdfb68ea1fa", "url": "https://github.com/apache/flink/commit/666e058b3924dd6593106ccffa84ebdfb68ea1fa", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters", "committedDate": "2020-03-02T22:08:35Z", "type": "forcePushed"}, {"oid": "5dfb306ba6ff07f700b1afc21847641321705d4d", "url": "https://github.com/apache/flink/commit/5dfb306ba6ff07f700b1afc21847641321705d4d", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters", "committedDate": "2020-03-02T22:12:52Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODMxMDA1OA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r388310058", "bodyText": "Just tagging TODO.", "author": "AHeise", "createdAt": "2020-03-05T14:00:05Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/entrypoint/ClusterEntrypoint.java", "diffHunk": "@@ -160,13 +161,14 @@ public void startCluster() throws ClusterEntrypointException {\n \t\tLOG.info(\"Starting {}.\", getClass().getSimpleName());\n \n \t\ttry {\n-\n-\t\t\tconfigureFileSystems(configuration);\n+\t\t\t//TODO: push down filesystem initialization into runCluster - initializeServices (?)", "originalCommit": "bc188f48bff0c164ad2e36ef0eda3a5557e5adba", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzU2MzI1OA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393563258", "bodyText": "@AHeise I wanted to ask if what is written in TODO is a good idea in your opinion. I am not sure about the implications of initializing FileSystems within runSecured. I do not quite like that initialization of services (initializeServices) and  file systems happen in different places.", "author": "afedulov", "createdAt": "2020-03-17T09:59:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODMxMDA1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE0NDA0Mg==", "url": "https://github.com/apache/flink/pull/11195#discussion_r394144042", "bodyText": "That's something that @zentol knows much better. It sounds plausible to me.", "author": "AHeise", "createdAt": "2020-03-18T07:17:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODMxMDA1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIzNjMyMA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r394236320", "bodyText": "I've got no clue. Maybe @tillrohrmann remembers why this was added outside runSecured in bbac4a6#diff-5334e24ac6a0d7e69599ceca71fd2e99.", "author": "zentol", "createdAt": "2020-03-18T10:14:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODMxMDA1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM2NjM1Mw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395366353", "bodyText": "If it is something non-trivial and hard to make a call about, I would propose to skip this refactoring for now.", "author": "afedulov", "createdAt": "2020-03-19T23:01:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODMxMDA1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODMxMDQwNg==", "url": "https://github.com/apache/flink/pull/11195#discussion_r388310406", "bodyText": "Just tagging TODO.", "author": "AHeise", "createdAt": "2020-03-05T14:00:38Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/entrypoint/ClusterEntrypoint.java", "diffHunk": "@@ -202,9 +204,11 @@ private SecurityContext installSecurityContext(Configuration configuration) thro\n \t\treturn SecurityUtils.getInstalledContext();\n \t}\n \n-\tprivate void runCluster(Configuration configuration) throws Exception {\n+\tprivate void runCluster(Configuration configuration, PluginManager pluginManager) throws Exception {\n \t\tsynchronized (lock) {\n-\t\t\tinitializeServices(configuration);\n+\n+\t\t\t//TODO: Ask why FileSystem is not initialized here too.", "originalCommit": "bc188f48bff0c164ad2e36ef0eda3a5557e5adba", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzg0Mzc0Ng==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393843746", "bodyText": "See above.", "author": "afedulov", "createdAt": "2020-03-17T17:20:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODMxMDQwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODMxMzEwMg==", "url": "https://github.com/apache/flink/pull/11195#discussion_r388313102", "bodyText": "Commit message should explain what's actually happening.", "author": "AHeise", "createdAt": "2020-03-05T14:05:20Z", "path": "flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/FlinkDistribution.java", "diffHunk": "@@ -77,6 +77,7 @@\n \tprivate Path conf;", "originalCommit": "c2c2b9d6b545c77ed473156d7bbf54c5aecd632b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzU3ODMyMA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393578320", "bodyText": "Addressed.", "author": "afedulov", "createdAt": "2020-03-17T10:27:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODMxMzEwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0NjI0Nw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r388346247", "bodyText": "Collectors.toCollection(TreeSet::new) to get rid of the next few lines.", "author": "AHeise", "createdAt": "2020-03-05T14:56:56Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -179,28 +164,82 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\t\t\tmetricReporterOptional.ifPresent(reporter -> {\n \t\t\t\t\tMetricConfig metricConfig = new MetricConfig();\n \t\t\t\t\treporterConfig.addAllToProperties(metricConfig);\n-\n-\t\t\t\t\treporterArguments.add(createReporterSetup(reporterName, metricConfig, reporter));\n+\t\t\t\t\treporterSetups.add(createReporterSetup(reporterName, metricConfig, reporter));\n \t\t\t\t});\n-\t\t\t}\n-\t\t\tcatch (Throwable t) {\n+\t\t\t} catch (Throwable t) {\n \t\t\t\tLOG.error(\"Could not instantiate metrics reporter {}. Metrics might not be exposed/reported.\", reporterName, t);\n \t\t\t}\n \t\t}\n-\t\treturn reporterArguments;\n+\t\treturn reporterSetups;\n \t}\n \n-\tprivate static Map<String, MetricReporterFactory> loadReporterFactories() {\n-\t\tfinal ServiceLoader<MetricReporterFactory> serviceLoader = ServiceLoader.load(MetricReporterFactory.class);\n+\tprivate static List<Tuple2<String, Configuration>> loadReporterConfigurations(Configuration configuration, Set<String> namedReporters) {\n+\t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = new ArrayList<>(namedReporters.size());\n \n+\t\tfor (String namedReporter: namedReporters) {\n+\t\t\tDelegatingConfiguration delegatingConfiguration = new DelegatingConfiguration(\n+\t\t\t\tconfiguration,\n+\t\t\t\tConfigConstants.METRICS_REPORTER_PREFIX + namedReporter + '.');\n+\n+\t\t\treporterConfigurations.add(Tuple2.of(namedReporter, delegatingConfiguration));\n+\t\t}\n+\t\treturn reporterConfigurations;\n+\t}\n+\n+\tprivate static Set<String> findEnabledReportersInConfiguration(Configuration configuration, String includedReportersString) {\n+\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)\n+\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n+\t\t\t.collect(Collectors.toSet());", "originalCommit": "5dfb306ba6ff07f700b1afc21847641321705d4d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzg0ODM4Ng==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393848386", "bodyText": "Thanks, changed as proposed.", "author": "afedulov", "createdAt": "2020-03-17T17:27:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0NjI0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM0ODA1NQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395348055", "bodyText": "@AHeise I have applied this refactoring but then understood that I probably really did not get what you actually propose. Could you please clarify?", "author": "afedulov", "createdAt": "2020-03-19T22:11:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0NjI0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njk2ODI1Nw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r396968257", "bodyText": "Set<String> namedOrderedReporters = reporterListPattern.splitAsStream(includedReportersString)\n\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n\t\t\t.collect(Collectors.toCollection(TreeSet::new));", "author": "AHeise", "createdAt": "2020-03-24T08:15:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0NjI0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzAzMDI2OA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r397030268", "bodyText": "You've mentioned \"to get rid of the next few lines\", but this Tree data structure is further used as a container that is filled using some conditional logic and returned from the method, it is not just about having the input entries sorted. Do you propose to rewrite it?", "author": "afedulov", "createdAt": "2020-03-24T09:59:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0NjI0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzAzNjYyMA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r397036620", "bodyText": "Ah you are right. Ignore my comment.", "author": "AHeise", "createdAt": "2020-03-24T10:09:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0NjI0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0Njg1MA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r388346850", "bodyText": "warn if it doesn't match?", "author": "AHeise", "createdAt": "2020-03-05T14:57:51Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -179,28 +164,82 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\t\t\tmetricReporterOptional.ifPresent(reporter -> {\n \t\t\t\t\tMetricConfig metricConfig = new MetricConfig();\n \t\t\t\t\treporterConfig.addAllToProperties(metricConfig);\n-\n-\t\t\t\t\treporterArguments.add(createReporterSetup(reporterName, metricConfig, reporter));\n+\t\t\t\t\treporterSetups.add(createReporterSetup(reporterName, metricConfig, reporter));\n \t\t\t\t});\n-\t\t\t}\n-\t\t\tcatch (Throwable t) {\n+\t\t\t} catch (Throwable t) {\n \t\t\t\tLOG.error(\"Could not instantiate metrics reporter {}. Metrics might not be exposed/reported.\", reporterName, t);\n \t\t\t}\n \t\t}\n-\t\treturn reporterArguments;\n+\t\treturn reporterSetups;\n \t}\n \n-\tprivate static Map<String, MetricReporterFactory> loadReporterFactories() {\n-\t\tfinal ServiceLoader<MetricReporterFactory> serviceLoader = ServiceLoader.load(MetricReporterFactory.class);\n+\tprivate static List<Tuple2<String, Configuration>> loadReporterConfigurations(Configuration configuration, Set<String> namedReporters) {\n+\t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = new ArrayList<>(namedReporters.size());\n \n+\t\tfor (String namedReporter: namedReporters) {\n+\t\t\tDelegatingConfiguration delegatingConfiguration = new DelegatingConfiguration(\n+\t\t\t\tconfiguration,\n+\t\t\t\tConfigConstants.METRICS_REPORTER_PREFIX + namedReporter + '.');\n+\n+\t\t\treporterConfigurations.add(Tuple2.of(namedReporter, delegatingConfiguration));\n+\t\t}\n+\t\treturn reporterConfigurations;\n+\t}\n+\n+\tprivate static Set<String> findEnabledReportersInConfiguration(Configuration configuration, String includedReportersString) {\n+\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)\n+\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n+\t\t\t.collect(Collectors.toSet());\n+\n+\t\t// use a TreeSet to make the reporter order deterministic, which is useful for testing\n+\t\tSet<String> namedOrderedReporters = new TreeSet<>(String::compareTo);\n+\n+\t\t// scan entire configuration for keys starting with METRICS_REPORTER_PREFIX and determine the set of enabled reporters\n+\t\tfor (String key : configuration.keySet()) {\n+\t\t\tif (key.startsWith(ConfigConstants.METRICS_REPORTER_PREFIX)) {\n+\t\t\t\tMatcher matcher = reporterClassPattern.matcher(key);\n+\t\t\t\tif (matcher.matches()) {", "originalCommit": "5dfb306ba6ff07f700b1afc21847641321705d4d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzg0Mjg3Ng==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393842876", "bodyText": "Seems like a silent skip . This is old code, maybe @zentol could comment.", "author": "afedulov", "createdAt": "2020-03-17T17:19:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0Njg1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzkwNDczMg==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393904732", "bodyText": "This would flood the logs with warnings for every single configured parameter, as they all have the metrics.reporter. prefix but don't end with class.", "author": "zentol", "createdAt": "2020-03-17T19:01:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0Njg1MA=="}], "type": "inlineReview"}, {"oid": "3aded2be8a0019e7b025d811d204e92d36dd24e7", "url": "https://github.com/apache/flink/commit/3aded2be8a0019e7b025d811d204e92d36dd24e7", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters", "committedDate": "2020-03-17T10:25:49Z", "type": "forcePushed"}, {"oid": "57db59bd20c14d5a0872f6d35b2b3220624ec96b", "url": "https://github.com/apache/flink/commit/57db59bd20c14d5a0872f6d35b2b3220624ec96b", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters", "committedDate": "2020-03-17T13:51:44Z", "type": "forcePushed"}, {"oid": "5b0f219689e81fe11c3511c13c7f4943a997a4ef", "url": "https://github.com/apache/flink/commit/5b0f219689e81fe11c3511c13c7f4943a997a4ef", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters", "committedDate": "2020-03-17T16:58:33Z", "type": "forcePushed"}, {"oid": "a244cee274bab74683c25f90bfd515698bc04c95", "url": "https://github.com/apache/flink/commit/a244cee274bab74683c25f90bfd515698bc04c95", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging", "committedDate": "2020-03-17T20:29:22Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE0NzY3Ng==", "url": "https://github.com/apache/flink/pull/11195#discussion_r394147676", "bodyText": "/ means or. and/or is and or or, which can be simplified to or. (or is not xor in English)", "author": "AHeise", "createdAt": "2020-03-18T07:26:11Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -210,17 +213,31 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\treturn namedOrderedReporters;\n \t}\n \n-\tprivate static Map<String, MetricReporterFactory> loadReporterFactories() {\n-\t\tfinal ServiceLoader<MetricReporterFactory> serviceLoader = ServiceLoader.load(MetricReporterFactory.class);\n-\n+\tprivate static Map<String, MetricReporterFactory> loadAvailableReporterFactories(PluginManager pluginManager) {\n \t\tfinal Map<String, MetricReporterFactory> reporterFactories = new HashMap<>(2);\n-\t\tfinal Iterator<MetricReporterFactory> factoryIterator = serviceLoader.iterator();\n+\t\tfinal Iterator<MetricReporterFactory> factoryIterator = getAllReporterFactories(pluginManager);\n+\t\tLOG.info(\"Prepare reporter factories (from both SPIs and Plugins):\");\n \t\t// do not use streams or for-each loops here because they do not allow catching individual ServiceConfigurationErrors\n \t\t// such an error might be caused if the META-INF/services contains an entry to a non-existing factory class\n \t\twhile (factoryIterator.hasNext()) {\n \t\t\ttry {\n \t\t\t\tMetricReporterFactory factory = factoryIterator.next();\n-\t\t\t\treporterFactories.put(factory.getClass().getName(), factory);\n+\t\t\t\tString factoryClassName = factory.getClass().getName();\n+\t\t\t\tMetricReporterFactory existingFactory = reporterFactories.get(factoryClassName);\n+\t\t\t\tif (existingFactory == null){\n+\t\t\t\t\treporterFactories.put(factoryClassName, factory);\n+\t\t\t\t\tLOG.info(\"Found reporter factory {} at {} \",\n+\t\t\t\t\t\tfactoryClassName,\n+\t\t\t\t\t\tnew File(factory.getClass().getProtectionDomain().getCodeSource().getLocation().toURI()).getCanonicalPath());\n+\t\t\t\t} else {\n+\t\t\t\t\t//TODO: use path information below, when Plugin Classloader stops always prioritizing factories from /lib\n+//\t\t\t\t\tString jarPath1 = new File(existingFactory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+//\t\t\t\t\t\t.toURI()).getCanonicalPath();\n+//\t\t\t\t\tString jarPath2 = new File(factory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+//\t\t\t\t\t\t.toURI()).getCanonicalPath();\n+//\t\t\t\t\tLOG.warn(\"Multiple implementations of the same reporter were found: \\n {} and \\n{}\", jarPath1, jarPath2);\n+\t\t\t\t\tLOG.warn(\"Multiple implementations of the same reporter were found in 'lib' and/or 'plugins' directories for {}. It is recommended to remove redundant reporter JARs to resolve used versions' ambiguity.\", factoryClassName);", "originalCommit": "63001ed57dcdebbf5f0642285f6e82565caf7b4e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDI0NTc0NQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r394245745", "bodyText": "It's frequently used in our code and documentation; I don't think we gain anything by watching out for things like this.\nPersonally I find it less ambiguous than just or.", "author": "zentol", "createdAt": "2020-03-18T10:30:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE0NzY3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDMyMTg4MA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r394321880", "bodyText": "I wouldn't care if it's just in a comment or internal exception. But if it's user facing, I'd strongly recommend to proof-read everything and fix it.", "author": "AHeise", "createdAt": "2020-03-18T12:51:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE0NzY3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTMyNjAzNw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395326037", "bodyText": "https://en.wikipedia.org/wiki/And/or\nIt is used as an inclusive \"or\" (as in logic and mathematics), while an \"or\" in spoken language might be inclusive or exclusive.\nSeems to me like something that reduces ambiguity, as @zentol said.", "author": "afedulov", "createdAt": "2020-03-19T21:20:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE0NzY3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTMzMDEyMg==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395330122", "bodyText": "No hard feelings. You can safely ignore that comment. Just wanted to point it out and closing with a cite of your link\n\nIt has been strongly criticized as both ugly in style, and ambiguous in legal documents .\n\nSame in academic writing.", "author": "AHeise", "createdAt": "2020-03-19T21:28:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE0NzY3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM2NTExNA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395365114", "bodyText": "I thing the problem is that we have too many variants to describe with a single coordinating conjunction like \"or\" (plus \"or\" can unfortunately be both inclusive and exclusive). Cases:\n(xx) _ ()\n() _ (xx)\n(x) _ (x)\n(xx) _ (xx)\nAlternatives like \"a or b or both\" also do not work, because in this particular case they can be easily be interpreted as if the \"(x) _ (x)\" case is not an issue (because of \"Multiple\" in the beginning). Seems to me like the best case to indicate this ambiguity is is to use \"and/or\" so that people will be aware of multiple ways this can happen.", "author": "afedulov", "createdAt": "2020-03-19T22:57:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE0NzY3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYxODgyOA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395618828", "bodyText": "I think we should stop discussing this here; this is relevant for the entirety of the documentation, and we could get much more experienced people involved if we target that instead.", "author": "zentol", "createdAt": "2020-03-20T12:59:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE0NzY3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTY2MTI1OA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395661258", "bodyText": "I leave it as \"and/or\" here, and then we comb through the docs and sources to address it separately.", "author": "afedulov", "createdAt": "2020-03-20T14:10:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE0NzY3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE4MDE0Mg==", "url": "https://github.com/apache/flink/pull/11195#discussion_r394180142", "bodyText": "This will require a rebase; we added a more generic version for copying jars so we don't have to keep adding new ones. You will have to add a JarLocation for the plugins directory, and modify FlinkDistribution#moveJar to handle this location appropriately.", "author": "zentol", "createdAt": "2020-03-18T08:38:16Z", "path": "flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/FlinkDistribution.java", "diffHunk": "@@ -260,16 +262,26 @@ public void submitSQLJob(SQLJobSubmission job) throws IOException {\n \t}\n \n \tpublic void copyOptJarsToLib(String jarNamePrefix) throws FileNotFoundException, IOException {\n-\t\tfinal Optional<Path> reporterJarOptional;\n-\t\ttry (Stream<Path> logFiles = Files.walk(opt)) {\n-\t\t\treporterJarOptional = logFiles\n+\t\tcopyOptJars(jarNamePrefix, lib);\n+\t}\n+\n+\tpublic void copyOptJarsToPlugins(String jarNamePrefix) throws FileNotFoundException, IOException {", "originalCommit": "a244cee274bab74683c25f90bfd515698bc04c95", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM3NTQyMw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395375423", "bodyText": "But this is not really \"copying jars\", right? It will actually move the file from opt to lib or plugins. The problem is that one of the cases I would like to test required the jar to be actually copied to both.", "author": "afedulov", "createdAt": "2020-03-19T23:30:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE4MDE0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM3NjMzNA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395376334", "bodyText": "I assume you mean to modify FlinkDistribution#mapJarLocationToPath ?", "author": "afedulov", "createdAt": "2020-03-19T23:34:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE4MDE0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYxNzg3Mw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395617873", "bodyText": "hmmm that's a bit frustrating; now we have to open up the API to allow things that people shouldn't be doing; though admittedly we should be able to test everything a user might do.\nA dumb intermediate workaround would be to have 2 variants; one for copying/moving each.\nYou will also have to modify #moveJar to pass in the file(name at least) to #mapJarLocationPath so that you can introduce the directory for the individual plugin.", "author": "zentol", "createdAt": "2020-03-20T12:57:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE4MDE0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE4MTI4OA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r394181288", "bodyText": "this will also need adjustments after a rebase, as this test now works against the FlinkResource interface, where jar copies and configuration settings are done as part of the FlinkResource setup.", "author": "zentol", "createdAt": "2020-03-18T08:40:35Z", "path": "flink-end-to-end-tests/flink-metrics-reporter-prometheus-test/src/test/java/org/apache/flink/metrics/prometheus/tests/PrometheusReporterEndToEndITCase.java", "diffHunk": "@@ -120,24 +122,51 @@ public static void checkOS() {\n \tpublic final DownloadCache downloadCache = DownloadCache.get();\n \n \t@Test\n-\tpublic void testReporter() throws Exception {\n-\t\tdist.copyOptJarsToLib(\"flink-metrics-prometheus\");\n+\tpublic void reporterWorksWhenFoundInLibsViaReflection() throws Exception {\n+\t\tdist.copyOptJarsToLib(PROMETHEUS_JAR_PREFIX);", "originalCommit": "a244cee274bab74683c25f90bfd515698bc04c95", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjgwOTg5NA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r396809894", "bodyText": "@zentol It seems that this updated approach that got merged into master does not support the kinds of tests that we would need to do for the supported scenarios (see reporterWorksWhenFoundInLibsViaReflection, reporterWorksWhenFoundInPluginsViaReflection, reporterWorksWhenFoundBothInPluginsAndLibsViaFactories in this PR). How should we proceed? I can either bend the FlinkResource implementation back to the state where it supports modifications of the underlying resources after creation and keep the initialization in @Rule (a hack), or reinitialize FlinkResource in every test. What do you think?", "author": "afedulov", "createdAt": "2020-03-23T23:05:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE4MTI4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzY3NjIxOA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r397676218", "bodyText": "I'd opt for creating a separate FlinkResource in every test.", "author": "zentol", "createdAt": "2020-03-25T08:24:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE4MTI4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE4MzE1MA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r394183150", "bodyText": "Ideally we move the logic from PrometheusReporter#open into this method and change the constructor accordingly.", "author": "zentol", "createdAt": "2020-03-18T08:43:55Z", "path": "flink-metrics/flink-metrics-prometheus/src/main/java/org/apache/flink/metrics/prometheus/PrometheusReporterFactory.java", "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.metrics.prometheus;\n+\n+import org.apache.flink.core.plugin.Plugin;\n+import org.apache.flink.metrics.reporter.MetricReporterFactory;\n+\n+import java.util.Properties;\n+\n+/**\n+ * {@link MetricReporterFactory} for {@link PrometheusReporter}.\n+ */\n+public class PrometheusReporterFactory implements MetricReporterFactory, Plugin {\n+\n+\t@Override\n+\tpublic PrometheusReporter createMetricReporter(Properties properties) {\n+\t\treturn new PrometheusReporter();", "originalCommit": "a244cee274bab74683c25f90bfd515698bc04c95", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTMzNTMzMw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395335333", "bodyText": "It seems that this will pull a rather large refactoring with it, because of the call to super.open(config) in the open methods and because of having to reconcile different configuration containers - Properties vs MetricsConfig. I would prefer to address it in a separate refactoring PR, if possible.", "author": "afedulov", "createdAt": "2020-03-19T21:40:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE4MzE1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYxOTM4Mg==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395619382", "bodyText": "hmm that is true, I suppose the dual nature of the Prometheus reporters make things a bit funky. Let's leave it like this for now.", "author": "zentol", "createdAt": "2020-03-20T13:00:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE4MzE1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE4MzMwMA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r394183300", "bodyText": "We need a second factory for the PrometheusPushGatewayReporter", "author": "zentol", "createdAt": "2020-03-18T08:44:10Z", "path": "flink-metrics/flink-metrics-prometheus/src/main/java/org/apache/flink/metrics/prometheus/PrometheusReporterFactory.java", "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.metrics.prometheus;\n+\n+import org.apache.flink.core.plugin.Plugin;\n+import org.apache.flink.metrics.reporter.MetricReporterFactory;\n+\n+import java.util.Properties;\n+\n+/**\n+ * {@link MetricReporterFactory} for {@link PrometheusReporter}.\n+ */\n+public class PrometheusReporterFactory implements MetricReporterFactory, Plugin {", "originalCommit": "a244cee274bab74683c25f90bfd515698bc04c95", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTMzNzI0MQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395337241", "bodyText": "Added.", "author": "afedulov", "createdAt": "2020-03-19T21:44:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE4MzMwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIzODA1MA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r394238050", "bodyText": "unused?", "author": "zentol", "createdAt": "2020-03-18T10:17:12Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/metrics/ReporterSetupTest.java", "diffHunk": "@@ -21,6 +21,7 @@\n import org.apache.flink.configuration.ConfigConstants;\n import org.apache.flink.configuration.Configuration;\n import org.apache.flink.configuration.MetricOptions;\n+import org.apache.flink.core.plugin.PluginManager;", "originalCommit": "a244cee274bab74683c25f90bfd515698bc04c95", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIzOTExNA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r394239114", "bodyText": "this belongs into a separate commit since it is fixing a bug in the test that can occur independently from this PR.", "author": "zentol", "createdAt": "2020-03-18T10:18:59Z", "path": "flink-end-to-end-tests/flink-metrics-reporter-prometheus-test/src/test/java/org/apache/flink/metrics/prometheus/tests/PrometheusReporterEndToEndITCase.java", "diffHunk": "@@ -120,24 +122,51 @@ public static void checkOS() {\n \tpublic final DownloadCache downloadCache = DownloadCache.get();\n \n \t@Test\n-\tpublic void testReporter() throws Exception {\n-\t\tdist.copyOptJarsToLib(\"flink-metrics-prometheus\");\n+\tpublic void reporterWorksWhenFoundInLibsViaReflection() throws Exception {\n+\t\tdist.copyOptJarsToLib(PROMETHEUS_JAR_PREFIX);\n+\t\ttestReporter(false);\n+\t}\n+\n+\t@Test\n+\tpublic void reporterWorksWhenFoundInPluginsViaReflection() throws Exception {\n+\t\tdist.copyOptJarsToPlugins(PROMETHEUS_JAR_PREFIX);\n+\t\ttestReporter(false);\n+\t}\n+\n+\t@Test\n+\tpublic void reporterWorksWhenFoundInPluginsViaFactories() throws Exception {\n+\t\tdist.copyOptJarsToPlugins(PROMETHEUS_JAR_PREFIX);\n+\t\ttestReporter(true);\n+\t}\n \n+\t@Test\n+\tpublic void reporterWorksWhenFoundBothInPluginsAndLibsViaFactories() throws Exception {\n+\t\tdist.copyOptJarsToPlugins(PROMETHEUS_JAR_PREFIX);\n+\t\tdist.copyOptJarsToLib(PROMETHEUS_JAR_PREFIX);\n+\t\ttestReporter(true);\n+\t}\n+\n+\tprivate void testReporter(boolean useFactory) throws Exception {\n \t\tfinal Configuration config = new Configuration();\n-\t\tconfig.setString(ConfigConstants.METRICS_REPORTER_PREFIX + \"prom.\" + ConfigConstants.METRICS_REPORTER_CLASS_SUFFIX, PrometheusReporter.class.getCanonicalName());\n+\n+\t\tif (useFactory) {\n+\t\t\tconfig.setString(ConfigConstants.METRICS_REPORTER_PREFIX + \"prom.\" + ConfigConstants.METRICS_REPORTER_FACTORY_CLASS_SUFFIX, PrometheusReporterFactory.class.getName());\n+\t\t} else {\n+\t\t\tconfig.setString(ConfigConstants.METRICS_REPORTER_PREFIX + \"prom.\" + ConfigConstants.METRICS_REPORTER_CLASS_SUFFIX, PrometheusReporter.class.getCanonicalName());\n+\t\t}\n+\n \t\tconfig.setString(ConfigConstants.METRICS_REPORTER_PREFIX + \"prom.port\", \"9000-9100\");\n \n \t\tdist.appendConfiguration(config);\n \n \t\tfinal Path tmpPrometheusDir = tmp.newFolder().toPath().resolve(\"prometheus\");\n-\t\tfinal Path prometheusArchive = tmpPrometheusDir.resolve(PROMETHEUS_FILE_NAME + \".tar.gz\");\n \t\tfinal Path prometheusBinDir = tmpPrometheusDir.resolve(PROMETHEUS_FILE_NAME);\n \t\tfinal Path prometheusConfig = prometheusBinDir.resolve(\"prometheus.yml\");\n \t\tfinal Path prometheusBinary = prometheusBinDir.resolve(\"prometheus\");\n \t\tFiles.createDirectory(tmpPrometheusDir);\n \n-\t\tdownloadCache.getOrDownload(\n-\t\t\t\"https://github.com/prometheus/prometheus/releases/download/v\" + PROMETHEUS_VERSION + '/' + prometheusArchive.getFileName(),\n+\t\tfinal Path prometheusArchive = downloadCache.getOrDownload(", "originalCommit": "37984c5d08a46b06bee75779aed813a5e1f04863", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM2MDQyNw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395360427", "bodyText": "Split as requested.", "author": "afedulov", "createdAt": "2020-03-19T22:44:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIzOTExNA=="}], "type": "inlineReview"}, {"oid": "7ce9ad87a780aab19b9c97680d7af5f648c13f3b", "url": "https://github.com/apache/flink/commit/7ce9ad87a780aab19b9c97680d7af5f648c13f3b", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging", "committedDate": "2020-03-19T21:12:49Z", "type": "forcePushed"}, {"oid": "245fcd1ee6e8a5515ccb44621e86361fd9f3cd78", "url": "https://github.com/apache/flink/commit/245fcd1ee6e8a5515ccb44621e86361fd9f3cd78", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging", "committedDate": "2020-03-19T21:42:39Z", "type": "forcePushed"}, {"oid": "7f6ad172474e37bbf346a7762868c9114510c4c9", "url": "https://github.com/apache/flink/commit/7f6ad172474e37bbf346a7762868c9114510c4c9", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging", "committedDate": "2020-03-19T21:47:24Z", "type": "forcePushed"}, {"oid": "2590a69417bdd2b6bf2f4765b276a051040a97cf", "url": "https://github.com/apache/flink/commit/2590a69417bdd2b6bf2f4765b276a051040a97cf", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging", "committedDate": "2020-03-19T22:15:42Z", "type": "forcePushed"}, {"oid": "d07ec693eb90e33071e710be0b774fc995f05867", "url": "https://github.com/apache/flink/commit/d07ec693eb90e33071e710be0b774fc995f05867", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging", "committedDate": "2020-03-19T22:43:07Z", "type": "forcePushed"}, {"oid": "a1b15671c97e8809c0301fb4c225fdc1a7f78545", "url": "https://github.com/apache/flink/commit/a1b15671c97e8809c0301fb4c225fdc1a7f78545", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging", "committedDate": "2020-03-19T23:05:05Z", "type": "forcePushed"}, {"oid": "eccc41d96524bd8ff6bfa6bfa36f366689255893", "url": "https://github.com/apache/flink/commit/eccc41d96524bd8ff6bfa6bfa36f366689255893", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging", "committedDate": "2020-03-26T17:29:07Z", "type": "forcePushed"}, {"oid": "19b07382fedcab4e7c4866eb260a12cde4780538", "url": "https://github.com/apache/flink/commit/19b07382fedcab4e7c4866eb260a12cde4780538", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging", "committedDate": "2020-03-26T21:38:06Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTA4NDkyOA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r399084928", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\t\treturn new FlinkResourceSetup(config,  Collections.unmodifiableCollection(jarOperations));\n          \n          \n            \n            \t\t\treturn new FlinkResourceSetup(config, Collections.unmodifiableCollection(jarOperations));", "author": "zentol", "createdAt": "2020-03-27T07:48:14Z", "path": "flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/flink/FlinkResourceSetup.java", "diffHunk": "@@ -69,13 +69,13 @@ public FlinkResourceSetupBuilder addConfiguration(Configuration config) {\n \t\t\treturn this;\n \t\t}\n \n-\t\tpublic FlinkResourceSetupBuilder moveJar(String jarNamePrefix, JarLocation source, JarLocation target) {\n-\t\t\tthis.jarMoveOperations.add(new JarMove(jarNamePrefix, source, target));\n+\t\tpublic FlinkResourceSetupBuilder addJarOperation(JarOperation jarOperation) {\n+\t\t\tthis.jarOperations.add(jarOperation);\n \t\t\treturn this;\n \t\t}\n \n \t\tpublic FlinkResourceSetup build() {\n-\t\t\treturn new FlinkResourceSetup(config, Collections.unmodifiableCollection(jarMoveOperations));\n+\t\t\treturn new FlinkResourceSetup(config,  Collections.unmodifiableCollection(jarOperations));", "originalCommit": "19b07382fedcab4e7c4866eb260a12cde4780538", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "590a281040da44deee5137b037bbabcaedd0b487", "url": "https://github.com/apache/flink/commit/590a281040da44deee5137b037bbabcaedd0b487", "message": "[FLINK-16222][core] Relax Plugin bounded type parameter constraint", "committedDate": "2020-03-27T15:24:35Z", "type": "commit"}, {"oid": "ad42c142ec109c5fb4cf1bcccb61183c3e8b4a68", "url": "https://github.com/apache/flink/commit/ad42c142ec109c5fb4cf1bcccb61183c3e8b4a68", "message": "[FLINK-16222][runtime] Introduce PluginManager to ReporterSetup", "committedDate": "2020-03-27T18:11:23Z", "type": "commit"}, {"oid": "3630f07793d9eba899a746df43549b971ea6b2b7", "url": "https://github.com/apache/flink/commit/3630f07793d9eba899a746df43549b971ea6b2b7", "message": "[FLINK-16222][metrics][prometheus] Add plugin e2e test", "committedDate": "2020-03-27T18:11:49Z", "type": "forcePushed"}, {"oid": "672c515dda8d5d659c009099b98dd6a5835bbd40", "url": "https://github.com/apache/flink/commit/672c515dda8d5d659c009099b98dd6a5835bbd40", "message": "[FLINK-16222][metrics] Support loading reporters as plugins", "committedDate": "2020-03-27T18:19:01Z", "type": "commit"}, {"oid": "6a088a5f122ccce53e5baa97603eb8b0a9599247", "url": "https://github.com/apache/flink/commit/6a088a5f122ccce53e5baa97603eb8b0a9599247", "message": "[FLINK-16222][metrics][prometheus] Add plugin e2e test", "committedDate": "2020-03-27T18:19:01Z", "type": "commit"}, {"oid": "6a088a5f122ccce53e5baa97603eb8b0a9599247", "url": "https://github.com/apache/flink/commit/6a088a5f122ccce53e5baa97603eb8b0a9599247", "message": "[FLINK-16222][metrics][prometheus] Add plugin e2e test", "committedDate": "2020-03-27T18:19:01Z", "type": "forcePushed"}]}