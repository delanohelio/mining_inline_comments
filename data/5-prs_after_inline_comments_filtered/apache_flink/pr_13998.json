{"pr_number": 13998, "pr_title": "[FLINK-20062][hive] ContinuousHiveSplitEnumerator should be lock-free", "pr_createdAt": "2020-11-09T12:40:27Z", "pr_url": "https://github.com/apache/flink/pull/13998", "timeline": [{"oid": "530e65e61ae94f952ffb682f0573071724da27d6", "url": "https://github.com/apache/flink/commit/530e65e61ae94f952ffb682f0573071724da27d6", "message": "Throw exception in new splits handler", "committedDate": "2020-11-16T04:13:03Z", "type": "forcePushed"}, {"oid": "f2604cf33407322990661ccd10cde560b6c801a3", "url": "https://github.com/apache/flink/commit/f2604cf33407322990661ccd10cde560b6c801a3", "message": "[FLINK-20062][hive] ContinuousHiveSplitEnumerator should be lock-free", "committedDate": "2020-11-18T02:36:17Z", "type": "commit"}, {"oid": "6beffeeaa6311b7d58dca3eea2d876ce03bbd816", "url": "https://github.com/apache/flink/commit/6beffeeaa6311b7d58dca3eea2d876ce03bbd816", "message": "Throw exception in new splits handler", "committedDate": "2020-11-18T02:36:17Z", "type": "commit"}, {"oid": "6beffeeaa6311b7d58dca3eea2d876ce03bbd816", "url": "https://github.com/apache/flink/commit/6beffeeaa6311b7d58dca3eea2d876ce03bbd816", "message": "Throw exception in new splits handler", "committedDate": "2020-11-18T02:36:17Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk4MDgzMw==", "url": "https://github.com/apache/flink/pull/13998#discussion_r525980833", "bodyText": "Just PartitionMonitor?", "author": "JingsongLi", "createdAt": "2020-11-18T10:35:00Z", "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/ContinuousHiveSplitEnumerator.java", "diffHunk": "@@ -158,12 +142,64 @@ public void close() throws IOException {\n \t\t}\n \t}\n \n-\tprivate Void monitorAndGetSplits() throws Exception {\n-\t\tstateLock.writeLock().lock();\n-\t\ttry {\n+\tprivate void handleNewSplits(NewSplitsAndState<T> newSplitsAndState, Throwable error) {\n+\t\tif (error != null) {\n+\t\t\t// we need to failover because the worker thread is stateful\n+\t\t\tthrow new FlinkHiveException(\"Failed to enumerate files\", error);\n+\t\t}\n+\t\tthis.currentReadOffset = newSplitsAndState.offset;\n+\t\tthis.seenPartitionsSinceOffset = newSplitsAndState.seenPartitions;\n+\t\tsplitAssigner.addSplits(new ArrayList<>(newSplitsAndState.newSplits));\n+\t\tassignSplits();\n+\t}\n+\n+\tprivate void assignSplits() {\n+\t\tfinal Iterator<Map.Entry<Integer, String>> awaitingReader = readersAwaitingSplit.entrySet().iterator();\n+\t\twhile (awaitingReader.hasNext()) {\n+\t\t\tfinal Map.Entry<Integer, String> nextAwaiting = awaitingReader.next();\n+\t\t\tfinal String hostname = nextAwaiting.getValue();\n+\t\t\tfinal int awaitingSubtask = nextAwaiting.getKey();\n+\t\t\tfinal Optional<FileSourceSplit> nextSplit = splitAssigner.getNext(hostname);\n+\t\t\tif (nextSplit.isPresent()) {\n+\t\t\t\tenumeratorContext.assignSplit((HiveSourceSplit) nextSplit.get(), awaitingSubtask);\n+\t\t\t\tawaitingReader.remove();\n+\t\t\t} else {\n+\t\t\t\tbreak;\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate static class NewPartitionMonitor<T extends Comparable<T>> implements Callable<NewSplitsAndState<T>> {", "originalCommit": "6beffeeaa6311b7d58dca3eea2d876ce03bbd816", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk4MDg5NA==", "url": "https://github.com/apache/flink/pull/13998#discussion_r525980894", "bodyText": "private", "author": "JingsongLi", "createdAt": "2020-11-18T10:35:06Z", "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/ContinuousHiveSplitEnumerator.java", "diffHunk": "@@ -158,12 +142,64 @@ public void close() throws IOException {\n \t\t}\n \t}\n \n-\tprivate Void monitorAndGetSplits() throws Exception {\n-\t\tstateLock.writeLock().lock();\n-\t\ttry {\n+\tprivate void handleNewSplits(NewSplitsAndState<T> newSplitsAndState, Throwable error) {\n+\t\tif (error != null) {\n+\t\t\t// we need to failover because the worker thread is stateful\n+\t\t\tthrow new FlinkHiveException(\"Failed to enumerate files\", error);\n+\t\t}\n+\t\tthis.currentReadOffset = newSplitsAndState.offset;\n+\t\tthis.seenPartitionsSinceOffset = newSplitsAndState.seenPartitions;\n+\t\tsplitAssigner.addSplits(new ArrayList<>(newSplitsAndState.newSplits));\n+\t\tassignSplits();\n+\t}\n+\n+\tprivate void assignSplits() {\n+\t\tfinal Iterator<Map.Entry<Integer, String>> awaitingReader = readersAwaitingSplit.entrySet().iterator();\n+\t\twhile (awaitingReader.hasNext()) {\n+\t\t\tfinal Map.Entry<Integer, String> nextAwaiting = awaitingReader.next();\n+\t\t\tfinal String hostname = nextAwaiting.getValue();\n+\t\t\tfinal int awaitingSubtask = nextAwaiting.getKey();\n+\t\t\tfinal Optional<FileSourceSplit> nextSplit = splitAssigner.getNext(hostname);\n+\t\t\tif (nextSplit.isPresent()) {\n+\t\t\t\tenumeratorContext.assignSplit((HiveSourceSplit) nextSplit.get(), awaitingSubtask);\n+\t\t\t\tawaitingReader.remove();\n+\t\t\t} else {\n+\t\t\t\tbreak;\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate static class NewPartitionMonitor<T extends Comparable<T>> implements Callable<NewSplitsAndState<T>> {\n+\n+\t\t// keep these locally so that we don't need to share state with main thread\n+\t\tprivate T currentReadOffset;\n+\t\tprivate final Set<List<String>> seenPartitionsSinceOffset;\n+\n+\t\tprivate final ObjectPath tablePath;\n+\t\tprivate final JobConf jobConf;\n+\t\tprivate final ContinuousPartitionFetcher<Partition, T> fetcher;\n+\t\tprivate final HiveTableSource.HiveContinuousPartitionFetcherContext<T> fetcherContext;\n+\n+\t\tNewPartitionMonitor(", "originalCommit": "6beffeeaa6311b7d58dca3eea2d876ce03bbd816", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk4MTUxNA==", "url": "https://github.com/apache/flink/pull/13998#discussion_r525981514", "bodyText": "There is a thread safe problem? Two thread share a same seenPartitionsSinceOffset\nWe need return a immutable seenPartitionsSinceOffset", "author": "JingsongLi", "createdAt": "2020-11-18T10:36:07Z", "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/ContinuousHiveSplitEnumerator.java", "diffHunk": "@@ -158,12 +142,64 @@ public void close() throws IOException {\n \t\t}\n \t}\n \n-\tprivate Void monitorAndGetSplits() throws Exception {\n-\t\tstateLock.writeLock().lock();\n-\t\ttry {\n+\tprivate void handleNewSplits(NewSplitsAndState<T> newSplitsAndState, Throwable error) {\n+\t\tif (error != null) {\n+\t\t\t// we need to failover because the worker thread is stateful\n+\t\t\tthrow new FlinkHiveException(\"Failed to enumerate files\", error);\n+\t\t}\n+\t\tthis.currentReadOffset = newSplitsAndState.offset;\n+\t\tthis.seenPartitionsSinceOffset = newSplitsAndState.seenPartitions;\n+\t\tsplitAssigner.addSplits(new ArrayList<>(newSplitsAndState.newSplits));\n+\t\tassignSplits();\n+\t}\n+\n+\tprivate void assignSplits() {\n+\t\tfinal Iterator<Map.Entry<Integer, String>> awaitingReader = readersAwaitingSplit.entrySet().iterator();\n+\t\twhile (awaitingReader.hasNext()) {\n+\t\t\tfinal Map.Entry<Integer, String> nextAwaiting = awaitingReader.next();\n+\t\t\tfinal String hostname = nextAwaiting.getValue();\n+\t\t\tfinal int awaitingSubtask = nextAwaiting.getKey();\n+\t\t\tfinal Optional<FileSourceSplit> nextSplit = splitAssigner.getNext(hostname);\n+\t\t\tif (nextSplit.isPresent()) {\n+\t\t\t\tenumeratorContext.assignSplit((HiveSourceSplit) nextSplit.get(), awaitingSubtask);\n+\t\t\t\tawaitingReader.remove();\n+\t\t\t} else {\n+\t\t\t\tbreak;\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate static class NewPartitionMonitor<T extends Comparable<T>> implements Callable<NewSplitsAndState<T>> {\n+\n+\t\t// keep these locally so that we don't need to share state with main thread\n+\t\tprivate T currentReadOffset;\n+\t\tprivate final Set<List<String>> seenPartitionsSinceOffset;\n+\n+\t\tprivate final ObjectPath tablePath;\n+\t\tprivate final JobConf jobConf;\n+\t\tprivate final ContinuousPartitionFetcher<Partition, T> fetcher;\n+\t\tprivate final HiveTableSource.HiveContinuousPartitionFetcherContext<T> fetcherContext;\n+\n+\t\tNewPartitionMonitor(\n+\t\t\t\tT currentReadOffset,\n+\t\t\t\tCollection<List<String>> seenPartitionsSinceOffset,\n+\t\t\t\tObjectPath tablePath,\n+\t\t\t\tJobConf jobConf,\n+\t\t\t\tContinuousPartitionFetcher<Partition, T> fetcher,\n+\t\t\t\tHiveTableSource.HiveContinuousPartitionFetcherContext<T> fetcherContext) {\n+\t\t\tthis.currentReadOffset = currentReadOffset;\n+\t\t\tthis.seenPartitionsSinceOffset = new HashSet<>(seenPartitionsSinceOffset);\n+\t\t\tthis.tablePath = tablePath;\n+\t\t\tthis.jobConf = jobConf;\n+\t\t\tthis.fetcher = fetcher;\n+\t\t\tthis.fetcherContext = fetcherContext;\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic NewSplitsAndState<T> call() throws Exception {\n \t\t\tList<Tuple2<Partition, T>> partitions = fetcher.fetchPartitions(fetcherContext, currentReadOffset);\n \t\t\tif (partitions.isEmpty()) {\n-\t\t\t\treturn null;\n+\t\t\t\treturn new NewSplitsAndState<>(Collections.emptyList(), currentReadOffset, seenPartitionsSinceOffset);", "originalCommit": "6beffeeaa6311b7d58dca3eea2d876ce03bbd816", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjA1ODgyNg==", "url": "https://github.com/apache/flink/pull/13998#discussion_r526058826", "bodyText": "The seenPartitionsSinceOffset here is local to this class and is a copy of the set parameter in constructor. So it's not shared with main thread", "author": "lirui-apache", "createdAt": "2020-11-18T12:45:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk4MTUxNA=="}], "type": "inlineReview"}, {"oid": "98fb6be3e33813d21dff02dfc527bef97c06c1b9", "url": "https://github.com/apache/flink/commit/98fb6be3e33813d21dff02dfc527bef97c06c1b9", "message": "address comments", "committedDate": "2020-11-18T13:54:09Z", "type": "commit"}]}