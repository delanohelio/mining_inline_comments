{"pr_number": 13434, "pr_title": "[FLINK-19292][hive] HiveCatalog should support specifying Hadoop conf dir with configuration", "pr_createdAt": "2020-09-21T03:59:14Z", "pr_url": "https://github.com/apache/flink/pull/13434", "timeline": [{"oid": "03e7a1d140dacb7667db4601272c599dff775370", "url": "https://github.com/apache/flink/commit/03e7a1d140dacb7667db4601272c599dff775370", "message": "[FLINK-19292][hive] HiveCatalog should support specifying Hadoop conf dir with configuration", "committedDate": "2020-09-21T12:36:31Z", "type": "forcePushed"}, {"oid": "dacd4ae1b261fa2dca65aa02b69142c34da121be", "url": "https://github.com/apache/flink/commit/dacd4ae1b261fa2dca65aa02b69142c34da121be", "message": "[FLINK-19292][hive] HiveCatalog should support specifying Hadoop conf dir with configuration", "committedDate": "2020-09-22T05:45:30Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjcxNjk0OA==", "url": "https://github.com/apache/flink/pull/13434#discussion_r492716948", "bodyText": "Let's not modify HadoopUtils. Instead, if hadoopConfDir is not null, set ConfigConstants.PATH_HADOOP_CONFIG in the Configuration instance.", "author": "lirui-apache", "createdAt": "2020-09-22T13:06:04Z", "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/HiveCatalog.java", "diffHunk": "@@ -199,7 +207,7 @@ private static HiveConf createHiveConf(@Nullable String hiveConfDir) {\n \t\tConfiguration hadoopConf = HadoopUtils.getHadoopConfiguration(new org.apache.flink.configuration.Configuration());\n \n \t\t// Add mapred-site.xml. We need to read configurations like compression codec.\n-\t\tfor (String possibleHadoopConfPath : HadoopUtils.possibleHadoopConfPaths(new org.apache.flink.configuration.Configuration())) {\n+\t\tfor (String possibleHadoopConfPath : HadoopUtils.possibleHadoopConfPaths(new org.apache.flink.configuration.Configuration(), hadoopConfDir)) {", "originalCommit": "dacd4ae1b261fa2dca65aa02b69142c34da121be", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjcxOTU1Mg==", "url": "https://github.com/apache/flink/pull/13434#discussion_r492719552", "bodyText": "Create a new test case for this", "author": "lirui-apache", "createdAt": "2020-09-22T13:09:57Z", "path": "flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/catalog/hive/factories/HiveCatalogFactoryTest.java", "diffHunk": "@@ -57,10 +59,10 @@\n \tpublic ExpectedException expectedException = ExpectedException.none();\n \n \t@Test\n-\tpublic void test() {\n+\tpublic void test() throws IOException {", "originalCommit": "dacd4ae1b261fa2dca65aa02b69142c34da121be", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTkzMTYzMA==", "url": "https://github.com/apache/flink/pull/13434#discussion_r495931630", "bodyText": "test is too generic, please give a meaningful name for this test", "author": "godfreyhe", "createdAt": "2020-09-28T13:18:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjcxOTU1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjcyMDMyOQ==", "url": "https://github.com/apache/flink/pull/13434#discussion_r492720329", "bodyText": "Besides, we need to add a test case for the hadoop conf dir configuration.", "author": "lirui-apache", "createdAt": "2020-09-22T13:11:04Z", "path": "flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/catalog/hive/factories/HiveCatalogFactoryTest.java", "diffHunk": "@@ -57,10 +59,10 @@\n \tpublic ExpectedException expectedException = ExpectedException.none();\n \n \t@Test\n-\tpublic void test() {\n+\tpublic void test() throws IOException {", "originalCommit": "dacd4ae1b261fa2dca65aa02b69142c34da121be", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "b79b3d92803dc7478830ac866e68936d1d372f58", "url": "https://github.com/apache/flink/commit/b79b3d92803dc7478830ac866e68936d1d372f58", "message": "[FLINK-19292][hive] HiveCatalog should support specifying Hadoop conf dir with configuration", "committedDate": "2020-09-23T07:21:46Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTUxOTc5Mw==", "url": "https://github.com/apache/flink/pull/13434#discussion_r495519793", "bodyText": "Why do we need hdfs-default.xml?", "author": "lirui-apache", "createdAt": "2020-09-27T02:52:25Z", "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/util/HiveTableUtil.java", "diffHunk": "@@ -421,6 +424,31 @@ public static void checkAcidTable(CatalogTable catalogTable, ObjectPath tablePat\n \t\t}\n \t}\n \n+\t/**\n+\t * Returns a new Hadoop Configuration object using the path to the hadoop conf configured.\n+\t *\n+\t * @param hadoopConfDir Hadoop conf directory path.\n+\t * @return A Hadoop configuration instance.\n+\t */\n+\tpublic static Configuration getHadoopConfiguration(String hadoopConfDir) {\n+\t\tConfiguration hadoopConfiguration = new Configuration();\n+\t\tif (new File(hadoopConfDir).exists()) {\n+\t\t\tif (new File(hadoopConfDir + \"/core-site.xml\").exists()) {\n+\t\t\t\thadoopConfiguration.addResource(new Path(hadoopConfDir + \"/core-site.xml\"));\n+\t\t\t}\n+\t\t\tif (new File(hadoopConfDir + \"/hdfs-default.xml\").exists()) {", "originalCommit": "f4033f16e326039a0f33958d096ba0c30ef26a6f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTUxOTg2OQ==", "url": "https://github.com/apache/flink/pull/13434#discussion_r495519869", "bodyText": "We also need yarn-site.xml, which is needed to generate Parquet splits in a kerberized environment.", "author": "lirui-apache", "createdAt": "2020-09-27T02:53:33Z", "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/util/HiveTableUtil.java", "diffHunk": "@@ -421,6 +424,31 @@ public static void checkAcidTable(CatalogTable catalogTable, ObjectPath tablePat\n \t\t}\n \t}\n \n+\t/**\n+\t * Returns a new Hadoop Configuration object using the path to the hadoop conf configured.\n+\t *\n+\t * @param hadoopConfDir Hadoop conf directory path.\n+\t * @return A Hadoop configuration instance.\n+\t */\n+\tpublic static Configuration getHadoopConfiguration(String hadoopConfDir) {\n+\t\tConfiguration hadoopConfiguration = new Configuration();\n+\t\tif (new File(hadoopConfDir).exists()) {\n+\t\t\tif (new File(hadoopConfDir + \"/core-site.xml\").exists()) {\n+\t\t\t\thadoopConfiguration.addResource(new Path(hadoopConfDir + \"/core-site.xml\"));\n+\t\t\t}\n+\t\t\tif (new File(hadoopConfDir + \"/hdfs-default.xml\").exists()) {\n+\t\t\t\thadoopConfiguration.addResource(new Path(hadoopConfDir + \"/hdfs-default.xml\"));\n+\t\t\t}\n+\t\t\tif (new File(hadoopConfDir + \"/hdfs-site.xml\").exists()) {\n+\t\t\t\thadoopConfiguration.addResource(new Path(hadoopConfDir + \"/hdfs-site.xml\"));\n+\t\t\t}\n+\t\t\tif (new File(hadoopConfDir + \"/mapred-site.xml\").exists()) {", "originalCommit": "f4033f16e326039a0f33958d096ba0c30ef26a6f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTUyMDIxNw==", "url": "https://github.com/apache/flink/pull/13434#discussion_r495520217", "bodyText": "Let's not rely on HadoopUtils.getHadoopConfiguration to get the configuration. We can just call HadoopUtils.possibleHadoopConfPaths to get the paths and load the files by ourselves. And the loading logic should be consistent with HiveTableUtil.getHadoopConfiguration.", "author": "lirui-apache", "createdAt": "2020-09-27T02:58:03Z", "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/HiveCatalog.java", "diffHunk": "@@ -196,15 +204,21 @@ private static HiveConf createHiveConf(@Nullable String hiveConfDir) {\n \t\t}\n \n \t\t// create HiveConf from hadoop configuration\n-\t\tConfiguration hadoopConf = HadoopUtils.getHadoopConfiguration(new org.apache.flink.configuration.Configuration());\n+\t\tConfiguration hadoopConf;\n \n-\t\t// Add mapred-site.xml. We need to read configurations like compression codec.\n-\t\tfor (String possibleHadoopConfPath : HadoopUtils.possibleHadoopConfPaths(new org.apache.flink.configuration.Configuration())) {\n-\t\t\tFile mapredSite = new File(new File(possibleHadoopConfPath), \"mapred-site.xml\");\n-\t\t\tif (mapredSite.exists()) {\n-\t\t\t\thadoopConf.addResource(new Path(mapredSite.getAbsolutePath()));\n-\t\t\t\tbreak;\n+\t\tif (isNullOrWhitespaceOnly(hadoopConfDir)) {\n+\t\t\thadoopConf = HadoopUtils.getHadoopConfiguration(new org.apache.flink.configuration.Configuration());", "originalCommit": "f4033f16e326039a0f33958d096ba0c30ef26a6f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTUzNDU5MA==", "url": "https://github.com/apache/flink/pull/13434#discussion_r495534590", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\t\tif (new File(hadoopConfDir + \"/core-site.xml\").exists()) {\n          \n          \n            \n            \t\t\tif (new File(hadoopConfDir, \"core-site.xml\").exists()) {", "author": "lirui-apache", "createdAt": "2020-09-27T06:15:53Z", "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/util/HiveTableUtil.java", "diffHunk": "@@ -431,22 +431,23 @@ public static void checkAcidTable(CatalogTable catalogTable, ObjectPath tablePat\n \t * @return A Hadoop configuration instance.\n \t */\n \tpublic static Configuration getHadoopConfiguration(String hadoopConfDir) {\n-\t\tConfiguration hadoopConfiguration = new Configuration();\n \t\tif (new File(hadoopConfDir).exists()) {\n+\t\t\tConfiguration hadoopConfiguration = new Configuration();\n \t\t\tif (new File(hadoopConfDir + \"/core-site.xml\").exists()) {", "originalCommit": "2c08acf8c251407d39f2628b970d5b7eb437af99", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTUzNDg4NQ==", "url": "https://github.com/apache/flink/pull/13434#discussion_r495534885", "bodyText": "This comment should be migrated to HiveTableUtil::getHadoopConfiguration", "author": "lirui-apache", "createdAt": "2020-09-27T06:20:10Z", "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/HiveCatalog.java", "diffHunk": "@@ -195,18 +202,19 @@ private static HiveConf createHiveConf(@Nullable String hiveConfDir) {\n \t\t\t\tString.format(\"Failed to get hive-site.xml from %s\", hiveConfDir), e);\n \t\t}\n \n-\t\t// create HiveConf from hadoop configuration\n-\t\tConfiguration hadoopConf = HadoopUtils.getHadoopConfiguration(new org.apache.flink.configuration.Configuration());\n-\n-\t\t// Add mapred-site.xml. We need to read configurations like compression codec.", "originalCommit": "2c08acf8c251407d39f2628b970d5b7eb437af99", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "07fb09f8651e79ab795f1d888d794b018a213a4f", "url": "https://github.com/apache/flink/commit/07fb09f8651e79ab795f1d888d794b018a213a4f", "message": "[FLINK-19292][hive] HiveCatalog should support specifying Hadoop conf dir with configuration", "committedDate": "2020-09-27T07:27:19Z", "type": "forcePushed"}, {"oid": "b5ac11907cbbe41f2b13e2b738458a3315d61663", "url": "https://github.com/apache/flink/commit/b5ac11907cbbe41f2b13e2b738458a3315d61663", "message": "[FLINK-19292][hive] HiveCatalog should support specifying Hadoop conf dir with configuration", "committedDate": "2020-09-27T07:30:41Z", "type": "forcePushed"}, {"oid": "7a2be06f74b2abc1d40f345fe995634e0f246413", "url": "https://github.com/apache/flink/commit/7a2be06f74b2abc1d40f345fe995634e0f246413", "message": "[FLINK-19292][hive] HiveCatalog should support specifying Hadoop conf dir with configuration", "committedDate": "2020-09-29T02:04:43Z", "type": "forcePushed"}, {"oid": "d7638e715ec7af65f8a45e276204ce86bce4369c", "url": "https://github.com/apache/flink/commit/d7638e715ec7af65f8a45e276204ce86bce4369c", "message": "[FLINK-19292][hive] HiveCatalog should support specifying Hadoop conf dir with configuration", "committedDate": "2020-09-29T03:30:37Z", "type": "forcePushed"}, {"oid": "cda95f3a0ee6988a3852d5e731ad360484bad53a", "url": "https://github.com/apache/flink/commit/cda95f3a0ee6988a3852d5e731ad360484bad53a", "message": "[FLINK-19292][hive] HiveCatalog should support specifying Hadoop conf dir with configuration", "committedDate": "2020-09-29T03:49:13Z", "type": "commit"}, {"oid": "cda95f3a0ee6988a3852d5e731ad360484bad53a", "url": "https://github.com/apache/flink/commit/cda95f3a0ee6988a3852d5e731ad360484bad53a", "message": "[FLINK-19292][hive] HiveCatalog should support specifying Hadoop conf dir with configuration", "committedDate": "2020-09-29T03:49:13Z", "type": "forcePushed"}]}