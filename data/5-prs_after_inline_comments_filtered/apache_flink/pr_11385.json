{"pr_number": 11385, "pr_title": "[FLINK-11395][formats] Support for Avro StreamingFileSink", "pr_createdAt": "2020-03-12T00:53:41Z", "pr_url": "https://github.com/apache/flink/pull/11385", "timeline": [{"oid": "9e1bbeafa1a4d0f673ebba7f87ef9032253a29f0", "url": "https://github.com/apache/flink/commit/9e1bbeafa1a4d0f673ebba7f87ef9032253a29f0", "message": "[FLINK-11395][formats] Support for Avro StreamingFileSink", "committedDate": "2020-03-12T01:16:37Z", "type": "forcePushed"}, {"oid": "f5daa5c0432bbc64add6d302841f26e9d919ce98", "url": "https://github.com/apache/flink/commit/f5daa5c0432bbc64add6d302841f26e9d919ce98", "message": "[FLINK-11395][formats] Support for Avro StreamingFileSink", "committedDate": "2020-03-13T05:40:35Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzY3MDYxNA==", "url": "https://github.com/apache/flink/pull/11385#discussion_r423670614", "bodyText": "To configure what? This interface looks weird to me.", "author": "JingsongLi", "createdAt": "2020-05-12T11:48:32Z", "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroWriters.java", "diffHunk": "@@ -0,0 +1,197 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.formats.avro;\n+\n+import org.apache.avro.Schema;\n+import org.apache.avro.file.DataFileWriter;\n+import org.apache.avro.generic.GenericDatumWriter;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.avro.io.DatumWriter;\n+import org.apache.avro.reflect.ReflectData;\n+import org.apache.avro.reflect.ReflectDatumWriter;\n+import org.apache.avro.specific.SpecificData;\n+import org.apache.avro.specific.SpecificDatumWriter;\n+import org.apache.avro.specific.SpecificRecord;\n+import org.apache.avro.specific.SpecificRecordBase;\n+\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.io.Serializable;\n+\n+/**\n+ * Convenience builder to create {@link AvroWriterFactory} instances for the different Avro types.\n+ */\n+public class AvroWriters {\n+\n+\t/**\n+\t * A configurator to set the properties of the writer.\n+\t */\n+\tpublic interface WriterConfigurator<T> extends Serializable {", "originalCommit": "f5daa5c0432bbc64add6d302841f26e9d919ce98", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDE2MjAzNQ==", "url": "https://github.com/apache/flink/pull/11385#discussion_r424162035", "bodyText": "It should be used to configure DataFileWriter, I have changed the name to DataFileWriterConfigurator.", "author": "gaoyunhaii", "createdAt": "2020-05-13T04:11:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzY3MDYxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzY3MTY5MA==", "url": "https://github.com/apache/flink/pull/11385#discussion_r423671690", "bodyText": "Pass a Function<Schema, DatumWriter>?", "author": "JingsongLi", "createdAt": "2020-05-12T11:50:42Z", "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroWriters.java", "diffHunk": "@@ -0,0 +1,197 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.formats.avro;\n+\n+import org.apache.avro.Schema;\n+import org.apache.avro.file.DataFileWriter;\n+import org.apache.avro.generic.GenericDatumWriter;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.avro.io.DatumWriter;\n+import org.apache.avro.reflect.ReflectData;\n+import org.apache.avro.reflect.ReflectDatumWriter;\n+import org.apache.avro.specific.SpecificData;\n+import org.apache.avro.specific.SpecificDatumWriter;\n+import org.apache.avro.specific.SpecificRecord;\n+import org.apache.avro.specific.SpecificRecordBase;\n+\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.io.Serializable;\n+\n+/**\n+ * Convenience builder to create {@link AvroWriterFactory} instances for the different Avro types.\n+ */\n+public class AvroWriters {\n+\n+\t/**\n+\t * A configurator to set the properties of the writer.\n+\t */\n+\tpublic interface WriterConfigurator<T> extends Serializable {\n+\n+\t\t/**\n+\t\t * Modifies the properties of the writer.\n+\t\t *\n+\t\t * @param dataFileWriter The writer to modify.\n+\t\t */\n+\t\tvoid configureWriter(DataFileWriter<T> dataFileWriter);\n+\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} for an Avro specific type. The Avro writers\n+\t * will use the schema of that specific type to build and write the records.\n+\t *\n+\t * @param type The class of the type to write.\n+\t */\n+\tpublic static <T extends SpecificRecordBase> AvroWriterFactory<T> forSpecificRecord(Class<T> type) {\n+\t\treturn forSpecificRecord(type, writer -> {});\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} for an Avro specific type and given <tt>configurator</tt>.\n+\t * The Avro writers will use the schema of that specific type to build and write the records.\n+\t *\n+\t * @param type The class of the type to write.\n+\t * @param configurator The configurator to modify the writer properties.\n+\t */\n+\tpublic static <T extends SpecificRecordBase> AvroWriterFactory<T> forSpecificRecord(\n+\t\tClass<T> type,\n+\t\tWriterConfigurator<T> configurator) {\n+\n+\t\tString schemaString = SpecificData.get().getSchema(type).toString();\n+\t\tAvroBuilder<T> builder = (out) -> createAvroDataFileWriter(\n+\t\t\tschemaString,\n+\t\t\tAvroRecordType.SPECIFIC,\n+\t\t\tconfigurator,\n+\t\t\tout);\n+\t\treturn new AvroWriterFactory<>(builder);\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} that accepts and writes Avro generic types.\n+\t * The Avro writers will use the given schema to build and write the records.\n+\t *\n+\t * @param schema The schema of the generic type.\n+\t */\n+\tpublic static AvroWriterFactory<GenericRecord> forGenericRecord(Schema schema) {\n+\t\treturn forGenericRecord(schema, writer -> {});\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} that accepts and writes Avro generic types\n+\t * and given <tt>configurator</tt>. The Avro writers will use the given schema to\n+\t * build and write the records.\n+\t *\n+\t * @param schema The schema of the generic type.\n+\t * @param configurator The configurator to modify the writer properties.\n+\t */\n+\tpublic static AvroWriterFactory<GenericRecord> forGenericRecord(\n+\t\tSchema schema,\n+\t\tWriterConfigurator<GenericRecord> configurator) {\n+\n+\t\tString schemaString = schema.toString();\n+\t\tAvroBuilder<GenericRecord> builder = (out) -> createAvroDataFileWriter(\n+\t\t\tschemaString,\n+\t\t\tAvroRecordType.GENERIC,\n+\t\t\tconfigurator,\n+\t\t\tout);\n+\t\treturn new AvroWriterFactory<>(builder);\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} for the given type. The Avro writers will\n+\t * use reflection to create the schema for the type and use that schema to write\n+\t * the records.\n+\t *\n+\t * @param type The class of the type to write.\n+\t */\n+\tpublic static <T> AvroWriterFactory<T> forReflectRecord(Class<T> type) {\n+\t\treturn forReflectRecord(type, writer -> {});\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} for the given type and given <tt>configurator</tt>.\n+\t * The Avro writers will use reflection to create the schema for the type and use that schema\n+\t * to write the records.\n+\t *\n+\t * @param type The class of the type to write.\n+\t * @param configurator The configurator to modify the writer properties.\n+\t */\n+\tpublic static <T> AvroWriterFactory<T> forReflectRecord(\n+\t\tClass<T> type,\n+\t\tWriterConfigurator<T> configurator) {\n+\n+\t\tString schemaString = ReflectData.get().getSchema(type).toString();\n+\t\tAvroBuilder<T> builder = (out) -> createAvroDataFileWriter(\n+\t\t\tschemaString,\n+\t\t\tAvroRecordType.REFLECT,\n+\t\t\tconfigurator,\n+\t\t\tout);\n+\t\treturn new AvroWriterFactory<>(builder);\n+\t}\n+\n+\tprivate static <T> DataFileWriter<T> createAvroDataFileWriter(\n+\t\tString schemaString,\n+\t\tAvroRecordType recordType,", "originalCommit": "f5daa5c0432bbc64add6d302841f26e9d919ce98", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzY3MjI1Mw==", "url": "https://github.com/apache/flink/pull/11385#discussion_r423672253", "bodyText": "Just Schema?", "author": "JingsongLi", "createdAt": "2020-05-12T11:51:45Z", "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroWriters.java", "diffHunk": "@@ -0,0 +1,197 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.formats.avro;\n+\n+import org.apache.avro.Schema;\n+import org.apache.avro.file.DataFileWriter;\n+import org.apache.avro.generic.GenericDatumWriter;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.avro.io.DatumWriter;\n+import org.apache.avro.reflect.ReflectData;\n+import org.apache.avro.reflect.ReflectDatumWriter;\n+import org.apache.avro.specific.SpecificData;\n+import org.apache.avro.specific.SpecificDatumWriter;\n+import org.apache.avro.specific.SpecificRecord;\n+import org.apache.avro.specific.SpecificRecordBase;\n+\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.io.Serializable;\n+\n+/**\n+ * Convenience builder to create {@link AvroWriterFactory} instances for the different Avro types.\n+ */\n+public class AvroWriters {\n+\n+\t/**\n+\t * A configurator to set the properties of the writer.\n+\t */\n+\tpublic interface WriterConfigurator<T> extends Serializable {\n+\n+\t\t/**\n+\t\t * Modifies the properties of the writer.\n+\t\t *\n+\t\t * @param dataFileWriter The writer to modify.\n+\t\t */\n+\t\tvoid configureWriter(DataFileWriter<T> dataFileWriter);\n+\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} for an Avro specific type. The Avro writers\n+\t * will use the schema of that specific type to build and write the records.\n+\t *\n+\t * @param type The class of the type to write.\n+\t */\n+\tpublic static <T extends SpecificRecordBase> AvroWriterFactory<T> forSpecificRecord(Class<T> type) {\n+\t\treturn forSpecificRecord(type, writer -> {});\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} for an Avro specific type and given <tt>configurator</tt>.\n+\t * The Avro writers will use the schema of that specific type to build and write the records.\n+\t *\n+\t * @param type The class of the type to write.\n+\t * @param configurator The configurator to modify the writer properties.\n+\t */\n+\tpublic static <T extends SpecificRecordBase> AvroWriterFactory<T> forSpecificRecord(\n+\t\tClass<T> type,\n+\t\tWriterConfigurator<T> configurator) {\n+\n+\t\tString schemaString = SpecificData.get().getSchema(type).toString();\n+\t\tAvroBuilder<T> builder = (out) -> createAvroDataFileWriter(\n+\t\t\tschemaString,\n+\t\t\tAvroRecordType.SPECIFIC,\n+\t\t\tconfigurator,\n+\t\t\tout);\n+\t\treturn new AvroWriterFactory<>(builder);\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} that accepts and writes Avro generic types.\n+\t * The Avro writers will use the given schema to build and write the records.\n+\t *\n+\t * @param schema The schema of the generic type.\n+\t */\n+\tpublic static AvroWriterFactory<GenericRecord> forGenericRecord(Schema schema) {\n+\t\treturn forGenericRecord(schema, writer -> {});\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} that accepts and writes Avro generic types\n+\t * and given <tt>configurator</tt>. The Avro writers will use the given schema to\n+\t * build and write the records.\n+\t *\n+\t * @param schema The schema of the generic type.\n+\t * @param configurator The configurator to modify the writer properties.\n+\t */\n+\tpublic static AvroWriterFactory<GenericRecord> forGenericRecord(\n+\t\tSchema schema,\n+\t\tWriterConfigurator<GenericRecord> configurator) {\n+\n+\t\tString schemaString = schema.toString();\n+\t\tAvroBuilder<GenericRecord> builder = (out) -> createAvroDataFileWriter(\n+\t\t\tschemaString,\n+\t\t\tAvroRecordType.GENERIC,\n+\t\t\tconfigurator,\n+\t\t\tout);\n+\t\treturn new AvroWriterFactory<>(builder);\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} for the given type. The Avro writers will\n+\t * use reflection to create the schema for the type and use that schema to write\n+\t * the records.\n+\t *\n+\t * @param type The class of the type to write.\n+\t */\n+\tpublic static <T> AvroWriterFactory<T> forReflectRecord(Class<T> type) {\n+\t\treturn forReflectRecord(type, writer -> {});\n+\t}\n+\n+\t/**\n+\t * Creates an {@link AvroWriterFactory} for the given type and given <tt>configurator</tt>.\n+\t * The Avro writers will use reflection to create the schema for the type and use that schema\n+\t * to write the records.\n+\t *\n+\t * @param type The class of the type to write.\n+\t * @param configurator The configurator to modify the writer properties.\n+\t */\n+\tpublic static <T> AvroWriterFactory<T> forReflectRecord(\n+\t\tClass<T> type,\n+\t\tWriterConfigurator<T> configurator) {\n+\n+\t\tString schemaString = ReflectData.get().getSchema(type).toString();\n+\t\tAvroBuilder<T> builder = (out) -> createAvroDataFileWriter(\n+\t\t\tschemaString,\n+\t\t\tAvroRecordType.REFLECT,\n+\t\t\tconfigurator,\n+\t\t\tout);\n+\t\treturn new AvroWriterFactory<>(builder);\n+\t}\n+\n+\tprivate static <T> DataFileWriter<T> createAvroDataFileWriter(\n+\t\tString schemaString,", "originalCommit": "f5daa5c0432bbc64add6d302841f26e9d919ce98", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDE2MzAyMg==", "url": "https://github.com/apache/flink/pull/11385#discussion_r424163022", "bodyText": "We cannot directly pass schema because schema is not serializable, and since shcemaString (or schema) is reference by the anonymous function builder, it must be serializable.", "author": "gaoyunhaii", "createdAt": "2020-05-13T04:15:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzY3MjI1Mw=="}], "type": "inlineReview"}, {"oid": "f7b6b1a8fa6eb65d34a8020a154e0d94c86cc4e6", "url": "https://github.com/apache/flink/commit/f7b6b1a8fa6eb65d34a8020a154e0d94c86cc4e6", "message": "Address comments", "committedDate": "2020-05-13T04:16:08Z", "type": "forcePushed"}, {"oid": "88eb4f91c72b735fe947ea5beb4ab430138a6077", "url": "https://github.com/apache/flink/commit/88eb4f91c72b735fe947ea5beb4ab430138a6077", "message": "Remove data file writer configuror", "committedDate": "2020-05-15T03:18:38Z", "type": "forcePushed"}, {"oid": "bd4df28b75f51afcf7d1bac5ee1a1e686f064c4a", "url": "https://github.com/apache/flink/commit/bd4df28b75f51afcf7d1bac5ee1a1e686f064c4a", "message": "[FLINK-11395][formats] Support for Avro StreamingFileSink", "committedDate": "2020-05-15T06:57:22Z", "type": "commit"}, {"oid": "cab7822e2f7a63daa2a5eab32426790519764e6d", "url": "https://github.com/apache/flink/commit/cab7822e2f7a63daa2a5eab32426790519764e6d", "message": "Address comments", "committedDate": "2020-05-15T06:57:22Z", "type": "commit"}, {"oid": "06c125ce79d2719ac9d217aa90a2ce9881fec3da", "url": "https://github.com/apache/flink/commit/06c125ce79d2719ac9d217aa90a2ce9881fec3da", "message": "Remove data file writer configuror", "committedDate": "2020-05-15T06:57:22Z", "type": "commit"}, {"oid": "06c125ce79d2719ac9d217aa90a2ce9881fec3da", "url": "https://github.com/apache/flink/commit/06c125ce79d2719ac9d217aa90a2ce9881fec3da", "message": "Remove data file writer configuror", "committedDate": "2020-05-15T06:57:22Z", "type": "forcePushed"}]}