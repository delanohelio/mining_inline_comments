{"pr_number": 13800, "pr_title": "[FLINK-19650][connectors jdbc]Support the limit push down for the Jdb\u2026", "pr_createdAt": "2020-10-27T03:40:39Z", "pr_url": "https://github.com/apache/flink/pull/13800", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjQ1ODcyNQ==", "url": "https://github.com/apache/flink/pull/13800#discussion_r512458725", "bodyText": "We don't need to adapt fetch size, it is a best effort read size.", "author": "wuchong", "createdAt": "2020-10-27T07:12:55Z", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/table/JdbcDynamicTableSource.java", "diffHunk": "@@ -92,8 +99,14 @@ public ScanRuntimeProvider getScanRuntimeProvider(ScanContext runtimeProviderCon\n \t\t\t.setPassword(options.getPassword().orElse(null))\n \t\t\t.setAutoCommit(readOptions.getAutoCommit());\n \n-\t\tif (readOptions.getFetchSize() != 0) {\n-\t\t\tbuilder.setFetchSize(readOptions.getFetchSize());\n+\t\tif (readOptions.getFetchSize() != 0 || this.limit >= 0) {\n+\t\t\tint fetchsize = readOptions.getFetchSize();\n+\t\t\tif (fetchsize == 0) {\n+\t\t\t\tfetchsize = limit;\n+\t\t\t} else if (limit != -1) {\n+\t\t\t\tfetchsize = Integer.min(fetchsize, limit);\n+\t\t\t}\n+\t\t\tbuilder.setFetchSize(fetchsize);", "originalCommit": "d03e417c4b828ffb3e3b8061d0a9b5dd9a38b018", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjQ1OTgyMg==", "url": "https://github.com/apache/flink/pull/13800#discussion_r512459822", "bodyText": "This doesn't break the test?", "author": "wuchong", "createdAt": "2020-10-27T07:15:28Z", "path": "flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/table/JdbcDynamicTableSourceITCase.java", "diffHunk": "@@ -154,7 +155,7 @@ public void testProject() throws Exception {\n \t\t\t\t\")\"\n \t\t);\n \n-\t\tIterator<Row> collected = tEnv.executeSql(\"SELECT id,timestamp6_col,decimal_col FROM \" + INPUT_TABLE).collect();\n+\t\tIterator<Row> collected = tEnv.executeSql(\"SELECT id,timestamp6_col,decimal_col FROM \" + INPUT_TABLE + \" LIMIT 1\").collect();", "originalCommit": "d03e417c4b828ffb3e3b8061d0a9b5dd9a38b018", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjQ2MDIxNA==", "url": "https://github.com/apache/flink/pull/13800#discussion_r512460214", "bodyText": "Please select all the fields.", "author": "wuchong", "createdAt": "2020-10-27T07:16:22Z", "path": "flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/table/JdbcDynamicTableSourceITCase.java", "diffHunk": "@@ -166,4 +167,38 @@ public void testProject() throws Exception {\n \t\t\t\t.sorted().collect(Collectors.toList());\n \t\tassertEquals(expected, result);\n \t}\n+\n+\t@Test\n+\tpublic void testLimit() throws Exception {\n+\t\tStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+\t\tEnvironmentSettings envSettings = EnvironmentSettings.newInstance()\n+\t\t\t\t.useBlinkPlanner()\n+\t\t\t\t.inStreamingMode()\n+\t\t\t\t.build();\n+\t\tStreamTableEnvironment tEnv = StreamTableEnvironment.create(env, envSettings);\n+\n+\t\ttEnv.executeSql(\n+\t\t\t\t\"CREATE TABLE \" + INPUT_TABLE + \"(\" +\n+\t\t\t\t\t\t\"id BIGINT,\" +\n+\t\t\t\t\t\t\"timestamp6_col TIMESTAMP(6),\" +\n+\t\t\t\t\t\t\"timestamp9_col TIMESTAMP(9),\" +\n+\t\t\t\t\t\t\"time_col TIME,\" +\n+\t\t\t\t\t\t\"real_col FLOAT,\" +\n+\t\t\t\t\t\t\"double_col DOUBLE,\" +\n+\t\t\t\t\t\t\"decimal_col DECIMAL(10, 4)\" +\n+\t\t\t\t\t\t\") WITH (\" +\n+\t\t\t\t\t\t\"  'connector'='jdbc',\" +\n+\t\t\t\t\t\t\"  'url'='\" + DB_URL + \"',\" +\n+\t\t\t\t\t\t\"  'table-name'='\" + INPUT_TABLE + \"'\" +\n+\t\t\t\t\t\t\")\"\n+\t\t);\n+\n+\t\tIterator<Row> collected = tEnv.executeSql(\"SELECT id FROM \" + INPUT_TABLE + \" LIMIT 1\").collect();", "originalCommit": "d03e417c4b828ffb3e3b8061d0a9b5dd9a38b018", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjQ2MDg3Ng==", "url": "https://github.com/apache/flink/pull/13800#discussion_r512460876", "bodyText": "We don't need to cast to int.", "author": "wuchong", "createdAt": "2020-10-27T07:18:09Z", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/table/JdbcDynamicTableSource.java", "diffHunk": "@@ -156,11 +169,25 @@ public boolean equals(Object o) {\n \t\t\tObjects.equals(readOptions, that.readOptions) &&\n \t\t\tObjects.equals(lookupOptions, that.lookupOptions) &&\n \t\t\tObjects.equals(physicalSchema, that.physicalSchema) &&\n-\t\t\tObjects.equals(dialectName, that.dialectName);\n+\t\t\tObjects.equals(dialectName, that.dialectName) &&\n+\t\t\tObjects.equals(limit, that.limit);\n \t}\n \n \t@Override\n \tpublic int hashCode() {\n \t\treturn Objects.hash(options, readOptions, lookupOptions, physicalSchema, dialectName);\n \t}\n+\n+\t/**\n+\t * {@link java.sql.Statement#setFetchSize(int)} only accepts int value.\n+\t */\n+\t@Override\n+\tpublic void applyLimit(long limit) {\n+\t\tif (limit > Integer.MAX_VALUE) {\n+\t\t\tthrow new TableException(\n+\t\t\t\t\tString.format(\"The maximum limit value is %d for jdbc connector. Get %d.\",\n+\t\t\t\t\t\t\tInteger.MAX_VALUE, limit));\n+\t\t}\n+\t\tthis.limit = Math.toIntExact(limit);", "originalCommit": "d03e417c4b828ffb3e3b8061d0a9b5dd9a38b018", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "6e7748ddea8ff84587d15a1c8050b14b51cf1fcb", "url": "https://github.com/apache/flink/commit/6e7748ddea8ff84587d15a1c8050b14b51cf1fcb", "message": "[FLINK-19650][connectors jdbc]Support the limit push down for the Jdbc connector\n\n1. add getLimit method in dialects\n2. expand getSelectFromStatement parameters to include limit\n3. use dialect to get query with query in jdbc source", "committedDate": "2020-11-30T04:19:35Z", "type": "forcePushed"}, {"oid": "e7a4ae2ed2de185200b562bb882af275a49e972e", "url": "https://github.com/apache/flink/commit/e7a4ae2ed2de185200b562bb882af275a49e972e", "message": "[FLINK-19650][connectors jdbc]Support the limit push down for the Jdbc connector\n\n1. add getLimit method in dialects\n2. expand getSelectFromStatement parameters to include limit\n3. use dialect to get query with query in jdbc source", "committedDate": "2020-11-30T04:30:33Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzEwMzM1MA==", "url": "https://github.com/apache/flink/pull/13800#discussion_r547103350", "bodyText": "how about move limit >= 0 ? \" \" + getLimit(limit) : \"\" to  getLimit(long limit) internal?", "author": "leonardBang", "createdAt": "2020-12-22T07:01:42Z", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/dialect/JdbcDialect.java", "diffHunk": "@@ -148,14 +150,15 @@ default String getDeleteStatement(String tableName, String[] conditionFields) {\n \t/**\n \t * Get select fields statement by condition fields. Default use SELECT.\n \t */\n-\tdefault String getSelectFromStatement(String tableName, String[] selectFields, String[] conditionFields) {\n+\tdefault String getSelectFromStatement(String tableName, String[] selectFields, String[] conditionFields, long limit) {\n \t\tString selectExpressions = Arrays.stream(selectFields)\n \t\t\t\t.map(this::quoteIdentifier)\n \t\t\t\t.collect(Collectors.joining(\", \"));\n \t\tString fieldExpressions = Arrays.stream(conditionFields)\n \t\t\t\t.map(f -> format(\"%s = :%s\", quoteIdentifier(f), f))\n \t\t\t\t.collect(Collectors.joining(\" AND \"));\n \t\treturn \"SELECT \" + selectExpressions + \" FROM \" +\n-\t\t\t\tquoteIdentifier(tableName) + (conditionFields.length > 0 ? \" WHERE \" + fieldExpressions : \"\");\n+\t\t\t\tquoteIdentifier(tableName) + (conditionFields.length > 0 ? \" WHERE \" + fieldExpressions : \"\") +\n+\t\t\t\t(limit >= 0 ? \" \" + getLimit(limit) : \"\");", "originalCommit": "e7a4ae2ed2de185200b562bb882af275a49e972e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzEwMzg0OA==", "url": "https://github.com/apache/flink/pull/13800#discussion_r547103848", "bodyText": "please also add missed limit", "author": "leonardBang", "createdAt": "2020-12-22T07:03:10Z", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/table/JdbcDynamicTableSource.java", "diffHunk": "@@ -156,11 +163,17 @@ public boolean equals(Object o) {\n \t\t\tObjects.equals(readOptions, that.readOptions) &&\n \t\t\tObjects.equals(lookupOptions, that.lookupOptions) &&\n \t\t\tObjects.equals(physicalSchema, that.physicalSchema) &&\n-\t\t\tObjects.equals(dialectName, that.dialectName);\n+\t\t\tObjects.equals(dialectName, that.dialectName) &&\n+\t\t\tObjects.equals(limit, that.limit);\n \t}\n \n \t@Override\n \tpublic int hashCode() {\n \t\treturn Objects.hash(options, readOptions, lookupOptions, physicalSchema, dialectName);", "originalCommit": "e7a4ae2ed2de185200b562bb882af275a49e972e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "62897544138e2bececa6a3f53c63289150864495", "url": "https://github.com/apache/flink/commit/62897544138e2bececa6a3f53c63289150864495", "message": "[FLINK-19650][jdbc] support limit push down for jdbc connector", "committedDate": "2020-12-22T13:15:31Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzYxNjU4Nw==", "url": "https://github.com/apache/flink/pull/13800#discussion_r547616587", "bodyText": "how about rename to getLimitStatement to make the function definition more clear?", "author": "leonardBang", "createdAt": "2020-12-23T03:15:15Z", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/dialect/MySQLDialect.java", "diffHunk": "@@ -55,6 +55,15 @@ public JdbcRowConverter getRowConverter(RowType rowType) {\n \t\treturn new MySQLRowConverter(rowType);\n \t}\n \n+\t@Override\n+\tpublic String getLimit(long limit) {", "originalCommit": "71a5140cb517517feb3a0dea17c4e274f3ed7fcb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODM2MzgzMQ==", "url": "https://github.com/apache/flink/pull/13800#discussion_r548363831", "bodyText": "Could you remove the the begging space? The space should be handled by framework. It's easy to forget to add the space for new dialects.\nPlease use upper case for the SQL keywords.", "author": "wuchong", "createdAt": "2020-12-24T03:16:52Z", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/dialect/DerbyDialect.java", "diffHunk": "@@ -66,6 +66,15 @@ public String dialectName() {\n \t\treturn \"Derby\";\n \t}\n \n+\t@Override\n+\tpublic String getLimitStatement(long limit) {\n+\t\tif (limit >= 0) {\n+\t\t\treturn String.format(\" fetch first %d rows only\", limit);", "originalCommit": "f408d4cb2758fe350988e815b93b1c48d15497aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODM2NDE4OQ==", "url": "https://github.com/apache/flink/pull/13800#discussion_r548364189", "bodyText": "The else branch should also handled by framework. The limit parameter should always be a valid limit.", "author": "wuchong", "createdAt": "2020-12-24T03:18:34Z", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/dialect/DerbyDialect.java", "diffHunk": "@@ -66,6 +66,15 @@ public String dialectName() {\n \t\treturn \"Derby\";\n \t}\n \n+\t@Override\n+\tpublic String getLimitStatement(long limit) {\n+\t\tif (limit >= 0) {\n+\t\t\treturn String.format(\" fetch first %d rows only\", limit);\n+\t\t} else {\n+\t\t\treturn \"\";", "originalCommit": "f408d4cb2758fe350988e815b93b1c48d15497aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODM2NDE5Mg==", "url": "https://github.com/apache/flink/pull/13800#discussion_r548364192", "bodyText": "The else branch should also handled by framework. The limit parameter should always be a valid limit.", "author": "wuchong", "createdAt": "2020-12-24T03:18:35Z", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/dialect/DerbyDialect.java", "diffHunk": "@@ -66,6 +66,15 @@ public String dialectName() {\n \t\treturn \"Derby\";\n \t}\n \n+\t@Override\n+\tpublic String getLimitStatement(long limit) {\n+\t\tif (limit >= 0) {\n+\t\t\treturn String.format(\" fetch first %d rows only\", limit);\n+\t\t} else {\n+\t\t\treturn \"\";", "originalCommit": "f408d4cb2758fe350988e815b93b1c48d15497aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODM2NTI2Mw==", "url": "https://github.com/apache/flink/pull/13800#discussion_r548365263", "bodyText": "Why separate the initialization into another line?", "author": "wuchong", "createdAt": "2020-12-24T03:24:18Z", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/table/JdbcDynamicTableSource.java", "diffHunk": "@@ -96,8 +102,9 @@ public ScanRuntimeProvider getScanRuntimeProvider(ScanContext runtimeProviderCon\n \t\t\tbuilder.setFetchSize(readOptions.getFetchSize());\n \t\t}\n \t\tfinal JdbcDialect dialect = options.getDialect();\n-\t\tString query = dialect.getSelectFromStatement(\n-\t\t\toptions.getTableName(), physicalSchema.getFieldNames(), new String[0]);\n+\t\tString query;\n+\t\tquery = dialect.getSelectFromStatement(", "originalCommit": "f408d4cb2758fe350988e815b93b1c48d15497aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODM2NTcxNQ==", "url": "https://github.com/apache/flink/pull/13800#discussion_r548365715", "bodyText": "Could you add a test that the source is configured with partition columns and submit a select query with limit clause. I'm wondering currently they can't work together well.", "author": "wuchong", "createdAt": "2020-12-24T03:26:15Z", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/table/JdbcDynamicTableSource.java", "diffHunk": "@@ -96,8 +102,9 @@ public ScanRuntimeProvider getScanRuntimeProvider(ScanContext runtimeProviderCon\n \t\t\tbuilder.setFetchSize(readOptions.getFetchSize());\n \t\t}\n \t\tfinal JdbcDialect dialect = options.getDialect();\n-\t\tString query = dialect.getSelectFromStatement(\n-\t\t\toptions.getTableName(), physicalSchema.getFieldNames(), new String[0]);\n+\t\tString query;\n+\t\tquery = dialect.getSelectFromStatement(\n+\t\t\t\toptions.getTableName(), physicalSchema.getFieldNames(), new String[0], limit);\n \t\tif (readOptions.getPartitionColumnName().isPresent()) {", "originalCommit": "f408d4cb2758fe350988e815b93b1c48d15497aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODM3NDc0NA==", "url": "https://github.com/apache/flink/pull/13800#discussion_r548374744", "bodyText": "Personally, I don't like the current design of the new interface.\n\nit couples the limit to the select statement which makes it impossible to inject additional where clause.\ndialects need to implement/take care 2 interfaces about limit.\nmany invokers have to pass an invalid limit.\n\nIn my opinion, a better solution would be separate them, by having a new interface for limit:\nString getLimitClause(long limit);\nAnd concat the limit caluse with the select statement where needs the limit clause.", "author": "wuchong", "createdAt": "2020-12-24T04:15:25Z", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/dialect/JdbcDialect.java", "diffHunk": "@@ -148,14 +150,15 @@ default String getDeleteStatement(String tableName, String[] conditionFields) {\n \t/**\n \t * Get select fields statement by condition fields. Default use SELECT.\n \t */\n-\tdefault String getSelectFromStatement(String tableName, String[] selectFields, String[] conditionFields) {\n+\tdefault String getSelectFromStatement(String tableName, String[] selectFields, String[] conditionFields, long limit) {\n \t\tString selectExpressions = Arrays.stream(selectFields)\n \t\t\t\t.map(this::quoteIdentifier)\n \t\t\t\t.collect(Collectors.joining(\", \"));\n \t\tString fieldExpressions = Arrays.stream(conditionFields)\n \t\t\t\t.map(f -> format(\"%s = :%s\", quoteIdentifier(f), f))\n \t\t\t\t.collect(Collectors.joining(\" AND \"));\n \t\treturn \"SELECT \" + selectExpressions + \" FROM \" +\n-\t\t\t\tquoteIdentifier(tableName) + (conditionFields.length > 0 ? \" WHERE \" + fieldExpressions : \"\");\n+\t\t\t\tquoteIdentifier(tableName) + (conditionFields.length > 0 ? \" WHERE \" + fieldExpressions : \"\") +\n+\t\t\t\tgetLimitStatement(limit);", "originalCommit": "f408d4cb2758fe350988e815b93b1c48d15497aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODM3NDkxNg==", "url": "https://github.com/apache/flink/pull/13800#discussion_r548374916", "bodyText": "Please add javadoc on the method, including the description for limit parameter, e.g. the value range.", "author": "wuchong", "createdAt": "2020-12-24T04:16:14Z", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/dialect/JdbcDialect.java", "diffHunk": "@@ -57,6 +57,8 @@\n \t */\n \tJdbcRowConverter getRowConverter(RowType rowType);\n \n+\tString getLimitStatement(long limit);", "originalCommit": "f408d4cb2758fe350988e815b93b1c48d15497aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "ba4c6121faa50f3aa26b8c05bf7ea36b85d82642", "url": "https://github.com/apache/flink/commit/ba4c6121faa50f3aa26b8c05bf7ea36b85d82642", "message": "[FLINK-19650][planner] add PushLimitIntoTableSourceScanRule into StreamRuleSet", "committedDate": "2020-12-25T12:14:32Z", "type": "commit"}, {"oid": "c5ee9b57baaef312efba7080bb279dd85cda21ed", "url": "https://github.com/apache/flink/commit/c5ee9b57baaef312efba7080bb279dd85cda21ed", "message": "[FLINK-19650][jdbc] support limit push down for jdbc connector", "committedDate": "2020-12-25T12:14:32Z", "type": "commit"}, {"oid": "6e9c706b2e0ee94e0242ecfc491969df563aaf14", "url": "https://github.com/apache/flink/commit/6e9c706b2e0ee94e0242ecfc491969df563aaf14", "message": "fix plan test", "committedDate": "2020-12-25T12:14:32Z", "type": "commit"}, {"oid": "fe59ee44fb269934215d4569f65bd0eff2de17a5", "url": "https://github.com/apache/flink/commit/fe59ee44fb269934215d4569f65bd0eff2de17a5", "message": "address comments", "committedDate": "2020-12-25T12:14:33Z", "type": "commit"}, {"oid": "bfbae787e414d2cd1c9dec08f5bbfb3a9b91e6ce", "url": "https://github.com/apache/flink/commit/bfbae787e414d2cd1c9dec08f5bbfb3a9b91e6ce", "message": "address comments", "committedDate": "2020-12-25T12:14:33Z", "type": "commit"}, {"oid": "bfbae787e414d2cd1c9dec08f5bbfb3a9b91e6ce", "url": "https://github.com/apache/flink/commit/bfbae787e414d2cd1c9dec08f5bbfb3a9b91e6ce", "message": "address comments", "committedDate": "2020-12-25T12:14:33Z", "type": "forcePushed"}]}