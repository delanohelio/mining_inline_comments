{"pr_number": 13017, "pr_title": "[FLINK-18258][hive] Implement SHOW PARTITIONS for Hive dialect", "pr_createdAt": "2020-07-29T09:40:32Z", "pr_url": "https://github.com/apache/flink/pull/13017", "timeline": [{"oid": "16cd7dffbff67fd8aa060e9dcfde4af700db0839", "url": "https://github.com/apache/flink/commit/16cd7dffbff67fd8aa060e9dcfde4af700db0839", "message": "[FLINK-18258][hive] Implement SHOW PARTITIONS for Hive dialect", "committedDate": "2020-07-29T09:29:43Z", "type": "commit"}, {"oid": "2f2a2d5d7ef165e0c7ce068535bc79e90aae9cca", "url": "https://github.com/apache/flink/commit/2f2a2d5d7ef165e0c7ce068535bc79e90aae9cca", "message": "[FLINK-18258][hive] Implement SHOW PARTITIONS for Hive dialect", "committedDate": "2020-08-06T03:24:03Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjExNzc3Ng==", "url": "https://github.com/apache/flink/pull/13017#discussion_r466117776", "bodyText": "I think it'll be clearer to move these to a separate test case.", "author": "lirui-apache", "createdAt": "2020-08-06T03:04:18Z", "path": "flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveDialectITCase.java", "diffHunk": "@@ -450,6 +450,18 @@ public void testAddDropPartitions() throws Exception {\n \t\tObjectPath tablePath = new ObjectPath(\"default\", \"tbl\");\n \t\tassertEquals(2, hiveCatalog.listPartitions(tablePath).size());\n \n+\t\tList<Row> partitions = Lists.newArrayList(tableEnv.executeSql(\"show partitions tbl\").collect());", "originalCommit": "16cd7dffbff67fd8aa060e9dcfde4af700db0839", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjE4Njk2OA==", "url": "https://github.com/apache/flink/pull/13017#discussion_r466186968", "bodyText": "@lirui-apache OK, I would like to separate this case to another test case.", "author": "SteNicholas", "createdAt": "2020-08-06T07:00:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjExNzc3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEyMjc0OA==", "url": "https://github.com/apache/flink/pull/13017#discussion_r466122748", "bodyText": "If partitionSpec is not null, I think it must not be empty. We can add a check to verify that.", "author": "lirui-apache", "createdAt": "2020-08-06T03:24:44Z", "path": "flink-table/flink-sql-parser/src/main/java/org/apache/flink/sql/parser/dql/SqlShowPartitions.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.sql.parser.dql;\n+\n+import org.apache.flink.sql.parser.SqlPartitionUtils;\n+\n+import org.apache.calcite.sql.SqlCall;\n+import org.apache.calcite.sql.SqlIdentifier;\n+import org.apache.calcite.sql.SqlKind;\n+import org.apache.calcite.sql.SqlNode;\n+import org.apache.calcite.sql.SqlNodeList;\n+import org.apache.calcite.sql.SqlOperator;\n+import org.apache.calcite.sql.SqlSpecialOperator;\n+import org.apache.calcite.sql.SqlWriter;\n+import org.apache.calcite.sql.parser.SqlParserPos;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.ArrayList;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * SHOW PARTITIONS sql call.\n+ */\n+public class SqlShowPartitions extends SqlCall {\n+\n+\tpublic static final SqlSpecialOperator OPERATOR = new SqlSpecialOperator(\"SHOW PARTITIONS\", SqlKind.OTHER);\n+\n+\tprotected final SqlIdentifier tableIdentifier;\n+\tprotected final SqlNodeList partitionSpec;\n+\n+\tpublic SqlShowPartitions(SqlParserPos pos, SqlIdentifier tableName, @Nullable SqlNodeList partitionSpec) {\n+\t\tsuper(pos);\n+\t\tthis.tableIdentifier = requireNonNull(tableName, \"tableName should not be null\");\n+\t\tthis.partitionSpec = partitionSpec;\n+\t}\n+\n+\t@Override\n+\tpublic SqlOperator getOperator() {\n+\t\treturn OPERATOR;\n+\t}\n+\n+\t@Override\n+\tpublic List<SqlNode> getOperandList() {\n+\t\tList<SqlNode> operands = new ArrayList<>();\n+\t\toperands.add(tableIdentifier);\n+\t\toperands.add(partitionSpec);\n+\t\treturn operands;\n+\t}\n+\n+\t@Override\n+\tpublic void unparse(SqlWriter writer, int leftPrec, int rightPrec) {\n+\t\twriter.keyword(\"SHOW PARTITIONS\");\n+\t\ttableIdentifier.unparse(writer, leftPrec, rightPrec);\n+\t\tSqlNodeList partitionSpec = getPartitionSpec();\n+\t\tif (partitionSpec != null && partitionSpec.size() > 0) {", "originalCommit": "16cd7dffbff67fd8aa060e9dcfde4af700db0839", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEyMzc5Nw==", "url": "https://github.com/apache/flink/pull/13017#discussion_r466123797", "bodyText": "Don't we need the table identifier and partition spec here?", "author": "lirui-apache", "createdAt": "2020-08-06T03:28:39Z", "path": "flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliClient.java", "diffHunk": "@@ -549,6 +552,22 @@ private void callShowModules() {\n \t\tterminal.flush();\n \t}\n \n+\tprivate void callShowPartitions() {\n+\t\tfinal List<String> partitions;\n+\t\ttry {\n+\t\t\tpartitions = getShowResult(\"PARTITIONS\");", "originalCommit": "2f2a2d5d7ef165e0c7ce068535bc79e90aae9cca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjIyNTQwMA==", "url": "https://github.com/apache/flink/pull/13017#discussion_r466225400", "bodyText": "@lirui-apache Yes, this need the table identifier and partition spec. I missed it.", "author": "SteNicholas", "createdAt": "2020-08-06T08:12:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEyMzc5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEyNzA2Mw==", "url": "https://github.com/apache/flink/pull/13017#discussion_r466127063", "bodyText": "Why not just call getDDLOpExecuteErrorMsg?", "author": "lirui-apache", "createdAt": "2020-08-06T03:41:25Z", "path": "flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/api/internal/TableEnvironmentImpl.java", "diffHunk": "@@ -1021,6 +1022,28 @@ private TableResult executeOperation(Operation operation) {\n \t\t\treturn buildShowResult(\"function name\", listFunctions());\n \t\t} else if (operation instanceof ShowViewsOperation) {\n \t\t\treturn buildShowResult(\"view name\", listViews());\n+\t\t} else if (operation instanceof ShowPartitionsOperation) {\n+\t\t\tString exMsg = getDQLOpExecuteErrorMsg(operation.asSummaryString());", "originalCommit": "2f2a2d5d7ef165e0c7ce068535bc79e90aae9cca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjE4NzUwNg==", "url": "https://github.com/apache/flink/pull/13017#discussion_r466187506", "bodyText": "@lirui-apache I thought that SHOW PARTITIONS is DQL. I will modify getDQLOpExecuteErrorMsg to getDDLOpExecuteErrorMsg.", "author": "SteNicholas", "createdAt": "2020-08-06T07:01:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEyNzA2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEzMDE3Mw==", "url": "https://github.com/apache/flink/pull/13017#discussion_r466130173", "bodyText": "We already have a TestItem::validSql method that takes SQL dialect as a parameter. Can you reuse that?", "author": "lirui-apache", "createdAt": "2020-08-06T03:53:53Z", "path": "flink-table/flink-sql-client/src/test/java/org/apache/flink/table/client/cli/SqlCommandParserTest.java", "diffHunk": "@@ -389,6 +409,15 @@ public static TestItem validSql(\n \t\t\treturn testItem;\n \t\t}\n \n+\t\tpublic static TestItem validSql(", "originalCommit": "2f2a2d5d7ef165e0c7ce068535bc79e90aae9cca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjIwMTA4Ng==", "url": "https://github.com/apache/flink/pull/13017#discussion_r466201086", "bodyText": "@lirui-apache Sorry for previously not finding the TestItem::validSql method that takes SQL dialect as a parameter. I would like to call this method.", "author": "SteNicholas", "createdAt": "2020-08-06T07:29:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEzMDE3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEzMDk0Mg==", "url": "https://github.com/apache/flink/pull/13017#discussion_r466130942", "bodyText": "I don't think this makes sense, unless TestItem::invalidSql also supports HIVE dialect.", "author": "lirui-apache", "createdAt": "2020-08-06T03:56:50Z", "path": "flink-table/flink-sql-client/src/test/java/org/apache/flink/table/client/cli/SqlCommandParserTest.java", "diffHunk": "@@ -299,6 +299,21 @@ public void testCommands() throws Exception {\n \t\t}\n \t}\n \n+\t@Test\n+\tpublic void testHiveCommands() throws Exception {\n+\t\tSqlParserHelper helper = new SqlParserHelper(SqlDialect.HIVE);\n+\t\tparser = helper.getSqlParser();\n+\t\tList<TestItem> testItems = Arrays.asList(\n+\t\t\t// show partitions\n+\t\t\tTestItem.invalidSql(\"SHOW PARTITIONS \", SqlExecutionException.class, \"Encountered \\\"<EOF>\\\"\"),", "originalCommit": "2f2a2d5d7ef165e0c7ce068535bc79e90aae9cca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjE5NzUyOA==", "url": "https://github.com/apache/flink/pull/13017#discussion_r466197528", "bodyText": "@lirui-apache I would like to remove this case. Previously I use this test case to verfiy SHOW PARTITIONS without table name.", "author": "SteNicholas", "createdAt": "2020-08-06T07:22:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEzMDk0Mg=="}], "type": "inlineReview"}, {"oid": "898931cb7d94e490f094504c8d8f544d123ad0e5", "url": "https://github.com/apache/flink/commit/898931cb7d94e490f094504c8d8f544d123ad0e5", "message": "[FLINK-18258][hive] Implement SHOW PARTITIONS for Hive dialect", "committedDate": "2020-08-06T08:11:14Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM0NjY2OA==", "url": "https://github.com/apache/flink/pull/13017#discussion_r466346668", "bodyText": "Also add a test case where the partition spec only contains country", "author": "lirui-apache", "createdAt": "2020-08-06T11:29:10Z", "path": "flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveDialectITCase.java", "diffHunk": "@@ -465,6 +465,49 @@ public void testAddDropPartitions() throws Exception {\n \t\tassertEquals(1, hiveCatalog.listPartitions(tablePath).size());\n \t}\n \n+\t@Test\n+\tpublic void testShowPartitions() throws Exception {\n+\t\ttableEnv.executeSql(\"create table tbl (x int,y binary) partitioned by (dt date,country string)\");\n+\t\ttableEnv.executeSql(\"alter table tbl add partition (dt='2020-04-30',country='china') partition (dt='2020-04-30',country='us')\");\n+\n+\t\tObjectPath tablePath = new ObjectPath(\"default\", \"tbl\");\n+\t\tassertEquals(2, hiveCatalog.listPartitions(tablePath).size());\n+\n+\t\tList<Row> partitions = Lists.newArrayList(tableEnv.executeSql(\"show partitions tbl\").collect());\n+\t\tassertEquals(2, partitions.size());\n+\t\tassertTrue(partitions.toString().contains(\"dt=2020-04-30/country=china\"));\n+\t\tassertTrue(partitions.toString().contains(\"dt=2020-04-30/country=us\"));\n+\t\tpartitions = Lists.newArrayList(tableEnv.executeSql(\"show partitions tbl partition (dt='2020-04-30')\").collect());", "originalCommit": "898931cb7d94e490f094504c8d8f544d123ad0e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjkxOTY4MQ==", "url": "https://github.com/apache/flink/pull/13017#discussion_r466919681", "bodyText": "@lirui-apache Yeah, I would like to add this case to verify.", "author": "SteNicholas", "createdAt": "2020-08-07T09:09:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM0NjY2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM1MTI0MA==", "url": "https://github.com/apache/flink/pull/13017#discussion_r466351240", "bodyText": "Does a DATE column accept values like '2020-04-30 01:02:03'?", "author": "lirui-apache", "createdAt": "2020-08-06T11:38:41Z", "path": "flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveDialectITCase.java", "diffHunk": "@@ -465,6 +465,49 @@ public void testAddDropPartitions() throws Exception {\n \t\tassertEquals(1, hiveCatalog.listPartitions(tablePath).size());\n \t}\n \n+\t@Test\n+\tpublic void testShowPartitions() throws Exception {\n+\t\ttableEnv.executeSql(\"create table tbl (x int,y binary) partitioned by (dt date,country string)\");\n+\t\ttableEnv.executeSql(\"alter table tbl add partition (dt='2020-04-30',country='china') partition (dt='2020-04-30',country='us')\");\n+\n+\t\tObjectPath tablePath = new ObjectPath(\"default\", \"tbl\");\n+\t\tassertEquals(2, hiveCatalog.listPartitions(tablePath).size());\n+\n+\t\tList<Row> partitions = Lists.newArrayList(tableEnv.executeSql(\"show partitions tbl\").collect());\n+\t\tassertEquals(2, partitions.size());\n+\t\tassertTrue(partitions.toString().contains(\"dt=2020-04-30/country=china\"));\n+\t\tassertTrue(partitions.toString().contains(\"dt=2020-04-30/country=us\"));\n+\t\tpartitions = Lists.newArrayList(tableEnv.executeSql(\"show partitions tbl partition (dt='2020-04-30')\").collect());\n+\t\tassertEquals(2, partitions.size());\n+\t\tassertTrue(partitions.toString().contains(\"dt=2020-04-30/country=china\"));\n+\t\tassertTrue(partitions.toString().contains(\"dt=2020-04-30/country=us\"));\n+\t\tpartitions = Lists.newArrayList(tableEnv.executeSql(\"show partitions tbl partition (dt='2020-04-30',country='china')\").collect());\n+\t\tassertEquals(1, partitions.size());\n+\t\tassertTrue(partitions.toString().contains(\"dt=2020-04-30/country=china\"));\n+\n+\t\ttableEnv.executeSql(\"alter table tbl drop partition (dt='2020-04-30',country='china'),partition (dt='2020-04-30',country='us')\");\n+\t\tassertEquals(0, hiveCatalog.listPartitions(tablePath).size());\n+\n+\t\ttableEnv.executeSql(\"alter table tbl add partition (dt='2020-04-30 01:02:03',country='china') partition (dt='2020-04-30 04:05:06',country='us')\");", "originalCommit": "898931cb7d94e490f094504c8d8f544d123ad0e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzM3MjgzMw==", "url": "https://github.com/apache/flink/pull/13017#discussion_r467372833", "bodyText": "@lirui-apache I will modify the column to Timestamp type.", "author": "SteNicholas", "createdAt": "2020-08-08T07:10:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM1MTI0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM1MjE0Ng==", "url": "https://github.com/apache/flink/pull/13017#discussion_r466352146", "bodyText": "I don't think this is necessary. We're not testing add/drop partitions here.", "author": "lirui-apache", "createdAt": "2020-08-06T11:40:31Z", "path": "flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveDialectITCase.java", "diffHunk": "@@ -465,6 +465,49 @@ public void testAddDropPartitions() throws Exception {\n \t\tassertEquals(1, hiveCatalog.listPartitions(tablePath).size());\n \t}\n \n+\t@Test\n+\tpublic void testShowPartitions() throws Exception {\n+\t\ttableEnv.executeSql(\"create table tbl (x int,y binary) partitioned by (dt date,country string)\");\n+\t\ttableEnv.executeSql(\"alter table tbl add partition (dt='2020-04-30',country='china') partition (dt='2020-04-30',country='us')\");\n+\n+\t\tObjectPath tablePath = new ObjectPath(\"default\", \"tbl\");\n+\t\tassertEquals(2, hiveCatalog.listPartitions(tablePath).size());\n+\n+\t\tList<Row> partitions = Lists.newArrayList(tableEnv.executeSql(\"show partitions tbl\").collect());\n+\t\tassertEquals(2, partitions.size());\n+\t\tassertTrue(partitions.toString().contains(\"dt=2020-04-30/country=china\"));\n+\t\tassertTrue(partitions.toString().contains(\"dt=2020-04-30/country=us\"));\n+\t\tpartitions = Lists.newArrayList(tableEnv.executeSql(\"show partitions tbl partition (dt='2020-04-30')\").collect());\n+\t\tassertEquals(2, partitions.size());\n+\t\tassertTrue(partitions.toString().contains(\"dt=2020-04-30/country=china\"));\n+\t\tassertTrue(partitions.toString().contains(\"dt=2020-04-30/country=us\"));\n+\t\tpartitions = Lists.newArrayList(tableEnv.executeSql(\"show partitions tbl partition (dt='2020-04-30',country='china')\").collect());\n+\t\tassertEquals(1, partitions.size());\n+\t\tassertTrue(partitions.toString().contains(\"dt=2020-04-30/country=china\"));\n+\n+\t\ttableEnv.executeSql(\"alter table tbl drop partition (dt='2020-04-30',country='china'),partition (dt='2020-04-30',country='us')\");\n+\t\tassertEquals(0, hiveCatalog.listPartitions(tablePath).size());\n+\n+\t\ttableEnv.executeSql(\"alter table tbl add partition (dt='2020-04-30 01:02:03',country='china') partition (dt='2020-04-30 04:05:06',country='us')\");\n+\n+\t\tpartitions = Lists.newArrayList(tableEnv.executeSql(\"show partitions tbl\").collect());\n+\t\tassertEquals(2, partitions.size());\n+\t\tassertTrue(partitions.toString().contains(\"dt=2020-04-30 01:02:03/country=china\"));\n+\t\tassertTrue(partitions.toString().contains(\"dt=2020-04-30 04:05:06/country=us\"));\n+\t\tpartitions = Lists.newArrayList(tableEnv.executeSql(\"show partitions tbl partition (dt='2020-04-30 01:02:03')\").collect());\n+\t\tassertEquals(1, partitions.size());\n+\t\tassertTrue(partitions.toString().contains(\"dt=2020-04-30 01:02:03/country=china\"));\n+\t\tpartitions = Lists.newArrayList(tableEnv.executeSql(\"show partitions tbl partition (dt='2020-04-30 04:05:06')\").collect());\n+\t\tassertEquals(1, partitions.size());\n+\t\tassertTrue(partitions.toString().contains(\"dt=2020-04-30 04:05:06/country=us\"));\n+\t\tpartitions = Lists.newArrayList(tableEnv.executeSql(\"show partitions tbl partition (dt='2020-04-30 01:02:03',country='china')\").collect());\n+\t\tassertEquals(1, partitions.size());\n+\t\tassertTrue(partitions.toString().contains(\"dt=2020-04-30 01:02:03/country=china\"));\n+\n+\t\ttableEnv.executeSql(\"alter table tbl drop partition (dt='2020-04-30 01:02:03',country='china'),partition (dt='2020-04-30 04:05:06',country='us')\");\n+\t\tassertEquals(1, hiveCatalog.listPartitions(tablePath).size());", "originalCommit": "898931cb7d94e490f094504c8d8f544d123ad0e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjkyMDgxNg==", "url": "https://github.com/apache/flink/pull/13017#discussion_r466920816", "bodyText": "@lirui-apache Okay, I will remove this unnecessary case.", "author": "SteNicholas", "createdAt": "2020-08-07T09:11:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM1MjE0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM1NzM0Ng==", "url": "https://github.com/apache/flink/pull/13017#discussion_r466357346", "bodyText": "I think cmdCall.operands[0] contains the whole SQL statement, no?", "author": "lirui-apache", "createdAt": "2020-08-06T11:51:47Z", "path": "flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliClient.java", "diffHunk": "@@ -532,6 +535,14 @@ private void callShowFunctions() {\n \t\t\t\t.collect(Collectors.toList());\n \t}\n \n+\tprivate List<String> getShowResult(String objectToShow, SqlCommandCall cmdCall) {\n+\t\tTableResult tableResult = executor.executeSql(sessionId, \"SHOW \" + objectToShow + \" \" + cmdCall.operands[0]);", "originalCommit": "898931cb7d94e490f094504c8d8f544d123ad0e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODM3NDc0OQ==", "url": "https://github.com/apache/flink/pull/13017#discussion_r468374749", "bodyText": "Yeah, I check the parseBySqlParser method, and confirm the cmdCall.operands[0] contains the whole SQL statement.", "author": "SteNicholas", "createdAt": "2020-08-11T07:17:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM1NzM0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM2MDAyOA==", "url": "https://github.com/apache/flink/pull/13017#discussion_r466360028", "bodyText": "Do we still need these?", "author": "lirui-apache", "createdAt": "2020-08-06T11:57:12Z", "path": "flink-table/flink-sql-client/src/test/java/org/apache/flink/table/client/cli/SqlCommandParserTest.java", "diffHunk": "@@ -299,6 +300,20 @@ public void testCommands() throws Exception {\n \t\t}\n \t}\n \n+\t@Test\n+\tpublic void testHiveCommands() throws Exception {\n+\t\tSqlParserHelper helper = new SqlParserHelper(SqlDialect.HIVE);\n+\t\tparser = helper.getSqlParser();", "originalCommit": "898931cb7d94e490f094504c8d8f544d123ad0e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjkzMjgxMw==", "url": "https://github.com/apache/flink/pull/13017#discussion_r466932813", "bodyText": "@lirui-apache It's indeed unnecessary.", "author": "SteNicholas", "createdAt": "2020-08-07T09:35:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM2MDAyOA=="}], "type": "inlineReview"}, {"oid": "79c5ec9370376b93a352d9bf7c67f904aee0c6ed", "url": "https://github.com/apache/flink/commit/79c5ec9370376b93a352d9bf7c67f904aee0c6ed", "message": "[FLINK-18258][hive] Implement SHOW PARTITIONS for Hive dialect", "committedDate": "2020-08-11T07:15:46Z", "type": "commit"}, {"oid": "31623f278ff1fab58be814e077669f032711a82b", "url": "https://github.com/apache/flink/commit/31623f278ff1fab58be814e077669f032711a82b", "message": "[FLINK-18258][hive] Implement SHOW PARTITIONS for Hive dialect", "committedDate": "2020-08-11T13:10:06Z", "type": "commit"}, {"oid": "60db23d3f621b7817e97750d7bddb86ea1c35b4c", "url": "https://github.com/apache/flink/commit/60db23d3f621b7817e97750d7bddb86ea1c35b4c", "message": "[FLINK-18258][hive] Implement SHOW PARTITIONS for Hive dialect", "committedDate": "2020-08-12T07:44:54Z", "type": "commit"}]}