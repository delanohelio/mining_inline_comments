{"pr_number": 13373, "pr_title": "[FLINK-18802] Upgrade avro to 1.10 ", "pr_createdAt": "2020-09-11T12:52:27Z", "pr_url": "https://github.com/apache/flink/pull/13373", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAyNzMwOQ==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487027309", "bodyText": "Had to drop the logical types, because the BatchTableEnvironment fails if we have a java.time.Instant in the input DataSet. We extract BasicTypeInfo.INSTANT_TYPE_INFO for it, which is translated to TIMESTAMP_WITH_LOCAL_TIME_ZONE which fails in legacy planner.\nAfter the upgrade to avro 1.10 one of the fields of the User class is of type java.time.Instant, previously it was joda's DateTime.", "author": "dawidwys", "createdAt": "2020-09-11T12:58:31Z", "path": "flink-formats/flink-avro/src/test/java/org/apache/flink/table/runtime/batch/AvroTypesITCase.java", "diffHunk": "@@ -58,7 +55,7 @@\n @RunWith(Parameterized.class)\n public class AvroTypesITCase extends TableProgramsClusterTestBase {\n \n-\tprivate static final User USER_1 = User.newBuilder()\n+\tprivate static final SimpleUser USER_1 = SimpleUser.newBuilder()", "originalCommit": "df666257b536825e8cb4e3497349079e9a35c51e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzA1NDE5OQ==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487054199", "bodyText": "Thanks for the explanation.", "author": "twalthr", "createdAt": "2020-09-11T13:43:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAyNzMwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzA1NTUzNA==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487055534", "bodyText": "But it would still be nice to test all types for Avro but maybe to the new Blink planner. Could we add least have a separate commit for this class? Then we can revert the changes because after FLIP-136 this test should definitely work again, no? Or does it work already today?", "author": "twalthr", "createdAt": "2020-09-11T13:45:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAyNzMwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAyOTE2MQ==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487029161", "bodyText": "wouldn't it be easier (and also more performant) to simply make the field accessible in the constructor of the comparator? Going through all methods for every field access is not very beautiful.", "author": "twalthr", "createdAt": "2020-09-11T13:01:55Z", "path": "flink-core/src/main/java/org/apache/flink/api/java/typeutils/runtime/PojoComparator.java", "diffHunk": "@@ -176,14 +181,25 @@ public void getFlatComparator(List<TypeComparator> flatComparators) {\n \t */\n \tpublic final Object accessField(Field field, Object object) {\n \t\ttry {\n-\t\t\tobject = field.get(object);\n+\t\t\tif (field.isAccessible()) {", "originalCommit": "ed7fa522fc930a22eee7e51e87dc778ad6ad3b71", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAzNTg3Mg==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487035872", "bodyText": "It would. I changed it.", "author": "dawidwys", "createdAt": "2020-09-11T13:13:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAyOTE2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAzMjE4MA==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487032180", "bodyText": "we can simply access the member field instead of passing it through the methods, no?", "author": "twalthr", "createdAt": "2020-09-11T13:07:28Z", "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroRowDeserializationSchema.java", "diffHunk": "@@ -218,7 +231,7 @@ private Object convertAvroType(Schema schema, TypeInformation<?> info, Object ob\n \t\tswitch (schema.getType()) {\n \t\t\tcase RECORD:\n \t\t\t\tif (object instanceof IndexedRecord) {\n-\t\t\t\t\treturn convertAvroRecordToRow(schema, (RowTypeInfo) info, (IndexedRecord) object);\n+\t\t\t\t\treturn convertAvroRecordToRow(schema, (RowTypeInfo) info, (IndexedRecord) object, jodaConverter);", "originalCommit": "20cabf7afcac656efb5b959fa8c1a33b76c44fb1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAzODI4Mw==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487038283", "bodyText": "Right in this class we can. I was too fast to follow the same scheme as in the AvroRowDataDeserializationSchema were we have runtime converters instead of member methods.", "author": "dawidwys", "createdAt": "2020-09-11T13:17:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAzMjE4MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAzMzgzMQ==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487033831", "bodyText": "We can simply access JodaConverter where needed as a singleton? I would not pollute this methods.", "author": "twalthr", "createdAt": "2020-09-11T13:10:10Z", "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroToRowDataConverters.java", "diffHunk": "@@ -101,7 +106,7 @@ private static AvroToRowDataConverter createNullableConverter(LogicalType type)\n \t/**\n \t * Creates a runtime converter which assuming input object is not null.\n \t */\n-\tprivate static AvroToRowDataConverter createConverter(LogicalType type) {\n+\tprivate static AvroToRowDataConverter createConverter(LogicalType type, @Nullable JodaConverter jodaConverter) {", "originalCommit": "20cabf7afcac656efb5b959fa8c1a33b76c44fb1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "0f6f3bd9e8607ed77350723e5710e1705af3f710", "url": "https://github.com/apache/flink/commit/0f6f3bd9e8607ed77350723e5710e1705af3f710", "message": "[FLINK-18802] Create an uber jar for avro for sql-client", "committedDate": "2020-09-11T13:13:13Z", "type": "forcePushed"}, {"oid": "8396f34387c87703171a06563b15e0f0b2a53699", "url": "https://github.com/apache/flink/commit/8396f34387c87703171a06563b15e0f0b2a53699", "message": "[FLINK-18802] Create an uber jar for avro for sql-client", "committedDate": "2020-09-11T13:18:05Z", "type": "forcePushed"}, {"oid": "2cb9ec4b5e8daf8f4333acb2a8c09a8f2b1cfdb8", "url": "https://github.com/apache/flink/commit/2cb9ec4b5e8daf8f4333acb2a8c09a8f2b1cfdb8", "message": "[FLINK-18802] Create an uber jar for avro for sql-client", "committedDate": "2020-09-11T13:32:13Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzA0NjY5MQ==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487046691", "bodyText": "maybe to much optimization but should we just do the long arithmetic ourselves here and below? We are creating a lot of objects for the hot path.", "author": "twalthr", "createdAt": "2020-09-11T13:31:41Z", "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroRowDeserializationSchema.java", "diffHunk": "@@ -340,10 +357,22 @@ private Time convertToTime(Object object, @Nullable JodaConverter jodaConverter)\n \t\treturn new Time(millis - LOCAL_TZ.getOffset(millis));\n \t}\n \n-\tprivate Timestamp convertToTimestamp(Object object) {\n+\tprivate Timestamp convertToTimestamp(Object object, @Nullable JodaConverter jodaConverter, boolean isMicros) {\n \t\tfinal long millis;\n \t\tif (object instanceof Long) {\n-\t\t\tmillis = (Long) object;\n+\t\t\tif (isMicros) {\n+\t\t\t\tlong micros = (Long) object;\n+\t\t\t\tInstant instant = Instant.ofEpochSecond(0)", "originalCommit": "9038509a993f32233b4406cd6f6ca713258622c5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzA1MDkxMQ==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487050911", "bodyText": "Shouldn't this be a SQL type like the others? Is this method actually used?", "author": "twalthr", "createdAt": "2020-09-11T13:38:56Z", "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "diffHunk": "@@ -272,11 +276,14 @@ private static DataType convertToDataType(Schema schema) {\n \t\t\t\treturn DataTypes.TIMESTAMP(3)\n \t\t\t\t\t\t.bridgedTo(java.sql.Timestamp.class)\n \t\t\t\t\t\t.notNull();\n-\t\t\t}\n-\t\t\tif (schema.getLogicalType() == LogicalTypes.timestampMicros()) {\n+\t\t\t} else if (schema.getLogicalType() == LogicalTypes.timestampMicros()) {\n \t\t\t\treturn DataTypes.TIMESTAMP(6)\n \t\t\t\t\t\t.bridgedTo(java.sql.Timestamp.class)\n \t\t\t\t\t\t.notNull();\n+\t\t\t} else if (schema.getLogicalType() == LogicalTypes.timeMicros()) {\n+\t\t\t\treturn DataTypes.TIME(6)\n+\t\t\t\t\t.bridgedTo(LocalTime.class)", "originalCommit": "9038509a993f32233b4406cd6f6ca713258622c5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzIwODcxNg==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487208716", "bodyText": "Actually, those should be the default conversion classes from java.time. I changed that. It is not used, at least for now. We might need that later e.g. in schema-registry where we will need to convert schema retrieved from schema-registry to a SQL schema.\nIt was added as a  complementary method to org.apache.flink.formats.avro.typeutils.AvroSchemaConverter#convertToSchema(org.apache.flink.table.types.logical.LogicalType)", "author": "dawidwys", "createdAt": "2020-09-11T18:10:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzA1MDkxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzA1MjU4MQ==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487052581", "bodyText": "same question as above why is this not sql.Time?", "author": "twalthr", "createdAt": "2020-09-11T13:41:31Z", "path": "flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverterTest.java", "diffHunk": "@@ -193,7 +193,7 @@ private void validateUserSchema(DataType actual) {\n \t\t\t\tDataTypes.FIELD(\"type_bytes\", DataTypes.ARRAY(DataTypes.TINYINT().bridgedTo(Byte.class)).notNull()),\n \t\t\t\tDataTypes.FIELD(\"type_date\", DataTypes.DATE().bridgedTo(java.sql.Date.class).notNull()),\n \t\t\t\tDataTypes.FIELD(\"type_time_millis\", DataTypes.TIME().bridgedTo(java.sql.Time.class).notNull()),\n-\t\t\t\tDataTypes.FIELD(\"type_time_micros\", DataTypes.INT().notNull()),\n+\t\t\t\tDataTypes.FIELD(\"type_time_micros\", DataTypes.TIME(6).notNull()),", "originalCommit": "9038509a993f32233b4406cd6f6ca713258622c5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "0999b2c052be034e7de38f03a13840292a4b497f", "url": "https://github.com/apache/flink/commit/0999b2c052be034e7de38f03a13840292a4b497f", "message": "[FLINK-18802] Create an uber jar for avro for sql-client", "committedDate": "2020-09-11T18:06:58Z", "type": "forcePushed"}, {"oid": "bab621c4f92387eef5bf0101a5b687e45c479f80", "url": "https://github.com/apache/flink/commit/bab621c4f92387eef5bf0101a5b687e45c479f80", "message": "[FLINK-18802] Create an uber jar for avro for sql-client", "committedDate": "2020-09-11T19:56:10Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzY5NDQwOA==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487694408", "bodyText": "Actually, this should be DataTypes.BYTES() which would also match to Avro's BYTES type.", "author": "twalthr", "createdAt": "2020-09-14T07:08:11Z", "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "diffHunk": "@@ -255,28 +257,24 @@ private static DataType convertToDataType(Schema schema) {\n \t\t\t\t\t\tdecimalType.getScale())\n \t\t\t\t\t\t.notNull();\n \t\t\t}\n-\t\t\treturn DataTypes.ARRAY(DataTypes.TINYINT().bridgedTo(Byte.class))\n-\t\t\t\t\t.notNull();\n+\t\t\treturn DataTypes.ARRAY(DataTypes.TINYINT()).notNull();", "originalCommit": "cac5bf3b0420f10b9480c8e1e8e0b00884612ee7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzcyMzI3OA==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487723278", "bodyText": "or is Avro using Byte[] instead of byte[]", "author": "twalthr", "createdAt": "2020-09-14T08:01:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzY5NDQwOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzczODc2OQ==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487738769", "bodyText": "Avro uses ByteBuffer, therefore we do a conversion there. I will change it to DataTypes.BYTES().", "author": "dawidwys", "createdAt": "2020-09-14T08:28:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzY5NDQwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzY5Njc0Nw==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487696747", "bodyText": "nit: private?", "author": "twalthr", "createdAt": "2020-09-14T07:13:06Z", "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroRowDeserializationSchema.java", "diffHunk": "@@ -75,12 +75,11 @@\n  */\n @PublicEvolving\n public class AvroRowDeserializationSchema extends AbstractDeserializationSchema<Row> {\n-\n \t/**\n \t * Used for time conversions into SQL types.\n \t */\n \tprivate static final TimeZone LOCAL_TZ = TimeZone.getDefault();\n-\n+\tpublic static final long MICROS_PER_SECOND = 1_000_000L;", "originalCommit": "a639495f2bc3cef6fedf52492e546ebeb6306be5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzcwMzIxMQ==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487703211", "bodyText": "can we add a TODO here, because actually the record should pass the Table API unmodified, but this will come with FLUP-136", "author": "twalthr", "createdAt": "2020-09-14T07:25:49Z", "path": "flink-formats/flink-avro/src/test/java/org/apache/flink/table/runtime/batch/AvroTypesITCase.java", "diffHunk": "@@ -147,24 +150,26 @@ public AvroTypesITCase(\n \n \t@Test\n \tpublic void testAvroToRow() throws Exception {\n-\t\tExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n+\t\tStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n \t\tenv.getConfig().registerTypeWithKryoSerializer(LocalDate.class, AvroKryoSerializerUtils.JodaLocalDateSerializer.class);\n \t\tenv.getConfig().registerTypeWithKryoSerializer(LocalTime.class, AvroKryoSerializerUtils.JodaLocalTimeSerializer.class);\n-\t\tBatchTableEnvironment tEnv = BatchTableEnvironment.create(env, config());\n+\t\tStreamTableEnvironment tEnv = StreamTableEnvironment.create(env, EnvironmentSettings.newInstance().useBlinkPlanner().build());\n \n-\t\tTable t = tEnv.fromDataSet(testData(env));\n+\t\tTable t = tEnv.fromDataStream(testData(env));\n \t\tTable result = t.select($(\"*\"));\n \n-\t\tList<Row> results = tEnv.toDataSet(result, Row.class).collect();\n+\t\tIterable<Row> users = () -> DataStreamUtils.collect(tEnv.toAppendStream(result, Row.class));\n+\t\tList<Row> results = StreamSupport\n+\t\t\t.stream(users.spliterator(), false)\n+\t\t\t.collect(Collectors.toList());\n \t\tString expected =\n \t\t\t\"black,null,Whatever,[true],[hello],true,java.nio.HeapByteBuffer[pos=0 lim=10 cap=10],\" +\n \t\t\t\"2014-03-01,java.nio.HeapByteBuffer[pos=0 lim=2 cap=2],[7, -48],0.0,GREEN,\" +\n \t\t\t\"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],42,{},null,null,null,123456,\" +\n \t\t\t\"12:12:12.000,123456,2014-03-01T12:12:12.321Z,null\\n\" +\n \t\t\t\"blue,null,Charlie,[],[],false,java.nio.HeapByteBuffer[pos=0 lim=10 cap=10],2014-03-01,\" +\n \t\t\t\"java.nio.HeapByteBuffer[pos=0 lim=2 cap=2],[7, -48],1.337,RED,null,1337,{},\" +\n-\t\t\t\"{\\\"num\\\": 42, \\\"street\\\": \\\"Bakerstreet\\\", \\\"city\\\": \\\"Berlin\\\", \\\"state\\\": \" +\n-\t\t\t\"\\\"Berlin\\\", \\\"zip\\\": \\\"12049\\\"},null,null,123456,12:12:12.000,123456,\" +\n+\t\t\t\"Berlin,42,Berlin,Bakerstreet,12049,null,null,123456,12:12:12.000,123456,\" +", "originalCommit": "a0122e0683100ca2e8e1190b940cdd3a7166a19d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzcwMzcwOQ==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487703709", "bodyText": "These should not be necessary in our tests, right?", "author": "twalthr", "createdAt": "2020-09-14T07:26:48Z", "path": "flink-formats/flink-avro/src/test/java/org/apache/flink/table/runtime/batch/AvroTypesITCase.java", "diffHunk": "@@ -147,24 +150,26 @@ public AvroTypesITCase(\n \n \t@Test\n \tpublic void testAvroToRow() throws Exception {\n-\t\tExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n+\t\tStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n \t\tenv.getConfig().registerTypeWithKryoSerializer(LocalDate.class, AvroKryoSerializerUtils.JodaLocalDateSerializer.class);", "originalCommit": "a0122e0683100ca2e8e1190b940cdd3a7166a19d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzc0ODkyNg==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487748926", "bodyText": "We do need those in a0122e0 as we still use the joda time in this commit. We can remove them, (and we do in the next commit).\nThe default Kryo serialization does not work well.", "author": "dawidwys", "createdAt": "2020-09-14T08:45:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzcwMzcwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzc2NjkyMA==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487766920", "bodyText": "BTW, after the comment, I removed the JodaLocalDateSerializer and JodaLocalTimeSerializer classes in 453d02c as they are no longer used.", "author": "dawidwys", "createdAt": "2020-09-14T09:14:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzcwMzcwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzcwNDU2OQ==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487704569", "bodyText": "nit: We recently added a CollectionUtils.iterableToList maybe this is easier to read than the StreamSupport class.", "author": "twalthr", "createdAt": "2020-09-14T07:28:32Z", "path": "flink-formats/flink-avro/src/test/java/org/apache/flink/table/runtime/batch/AvroTypesITCase.java", "diffHunk": "@@ -147,24 +150,26 @@ public AvroTypesITCase(\n \n \t@Test\n \tpublic void testAvroToRow() throws Exception {\n-\t\tExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n+\t\tStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n \t\tenv.getConfig().registerTypeWithKryoSerializer(LocalDate.class, AvroKryoSerializerUtils.JodaLocalDateSerializer.class);\n \t\tenv.getConfig().registerTypeWithKryoSerializer(LocalTime.class, AvroKryoSerializerUtils.JodaLocalTimeSerializer.class);\n-\t\tBatchTableEnvironment tEnv = BatchTableEnvironment.create(env, config());\n+\t\tStreamTableEnvironment tEnv = StreamTableEnvironment.create(env, EnvironmentSettings.newInstance().useBlinkPlanner().build());\n \n-\t\tTable t = tEnv.fromDataSet(testData(env));\n+\t\tTable t = tEnv.fromDataStream(testData(env));\n \t\tTable result = t.select($(\"*\"));\n \n-\t\tList<Row> results = tEnv.toDataSet(result, Row.class).collect();\n+\t\tIterable<Row> users = () -> DataStreamUtils.collect(tEnv.toAppendStream(result, Row.class));\n+\t\tList<Row> results = StreamSupport", "originalCommit": "a0122e0683100ca2e8e1190b940cdd3a7166a19d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "44161ed79481cd2f7b76527124fbd6186eac5aaf", "url": "https://github.com/apache/flink/commit/44161ed79481cd2f7b76527124fbd6186eac5aaf", "message": "[hotfix] Fix Pojo comparator field access\n\nThe PojoComparator assumes it can access a field of a pojo directly. It assumes the field is either public or setAccessible was called before. This is the case though only if  the record went through serialization. This is not the case e.g. in CollectionExecution mode.\n\nStarting from this commit we make all fields accessible in\nPojoComparator constructor.", "committedDate": "2020-09-14T08:28:44Z", "type": "commit"}, {"oid": "a99c86b50af1d061dcb329d44c88d7419f8ddfb2", "url": "https://github.com/apache/flink/commit/a99c86b50af1d061dcb329d44c88d7419f8ddfb2", "message": "[hotfix] Extract joda conversions to a separate class", "committedDate": "2020-09-14T08:28:44Z", "type": "commit"}, {"oid": "bb7e8094f0675c882471f7ca31732f954275e470", "url": "https://github.com/apache/flink/commit/bb7e8094f0675c882471f7ca31732f954275e470", "message": "[hotfix] Fix schema to DataType/Type conversion", "committedDate": "2020-09-14T08:39:43Z", "type": "commit"}, {"oid": "76e7b1f3424c7348e99ba27d6f533ac01cb0af4d", "url": "https://github.com/apache/flink/commit/76e7b1f3424c7348e99ba27d6f533ac01cb0af4d", "message": "[hotfix] Fix time-micros and timestamp-micros handling", "committedDate": "2020-09-14T08:40:47Z", "type": "commit"}, {"oid": "8442f93c6b63aa92c72b890e012151dd8c58d81b", "url": "https://github.com/apache/flink/commit/8442f93c6b63aa92c72b890e012151dd8c58d81b", "message": "[hotfix] Migrate AvroTypesITCase to blink planner", "committedDate": "2020-09-14T09:06:04Z", "type": "commit"}, {"oid": "58d8186564b4f1e810985d59fb8764b1cabb21ff", "url": "https://github.com/apache/flink/commit/58d8186564b4f1e810985d59fb8764b1cabb21ff", "message": "[FLINK-18802] Create an uber jar for avro for sql-client", "committedDate": "2020-09-14T09:12:05Z", "type": "forcePushed"}, {"oid": "1979b49a8f98b6edfb860d3e514076407ae2a0d1", "url": "https://github.com/apache/flink/commit/1979b49a8f98b6edfb860d3e514076407ae2a0d1", "message": "[FLINK-18192] Upgrade avro to 1.10\n\nThis commit upgrades the default version of avro that flink-avro will use. It should be possible to downgrade the avro version in a user job as the binary format is compatible and we do not expose any dependencies on avro in the API.\n\nAdditionally this commit fixes handling of logical types: time-micros and timestamp-micros as well as interpretation of timestamp-millis in the AvroRowDataDeserializationSchema.", "committedDate": "2020-09-14T09:15:08Z", "type": "commit"}, {"oid": "166a17e676304c9215f3b5b517cca71fdb2e927f", "url": "https://github.com/apache/flink/commit/166a17e676304c9215f3b5b517cca71fdb2e927f", "message": "[FLINK-18802] Create an uber jar for avro for sql-client", "committedDate": "2020-09-14T09:15:15Z", "type": "commit"}, {"oid": "166a17e676304c9215f3b5b517cca71fdb2e927f", "url": "https://github.com/apache/flink/commit/166a17e676304c9215f3b5b517cca71fdb2e927f", "message": "[FLINK-18802] Create an uber jar for avro for sql-client", "committedDate": "2020-09-14T09:15:15Z", "type": "forcePushed"}]}