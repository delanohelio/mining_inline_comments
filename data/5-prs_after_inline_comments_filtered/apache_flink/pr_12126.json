{"pr_number": 12126, "pr_title": "[FLINK-17664][table] Introduce print, blackhole connector in table", "pr_createdAt": "2020-05-13T12:49:48Z", "pr_url": "https://github.com/apache/flink/pull/12126", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUwODQwMQ==", "url": "https://github.com/apache/flink/pull/12126#discussion_r424508401", "bodyText": "Put it under org.apache.flink.table.factories ? I think org.apache.flink.table.sinks is a legacy package, all the interfaces/classes under this package will be removed in the future.", "author": "wuchong", "createdAt": "2020-05-13T15:01:20Z", "path": "flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/sinks/BlackHoleTableSinkFactory.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.sinks;", "originalCommit": "9a9ae4d5447c18f4cd593e7f0ea115698026db4f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUwODU3Ng==", "url": "https://github.com/apache/flink/pull/12126#discussion_r424508576", "bodyText": "I'm not sure what should the annotation be. But I think either @Internal or @PublicEvolving. The reason for @PublicEvolving is the connector options are public API and we should keep backward-compatible.", "author": "wuchong", "createdAt": "2020-05-13T15:01:35Z", "path": "flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/sinks/BlackHoleTableSinkFactory.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.sinks;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.configuration.ConfigOption;\n+import org.apache.flink.streaming.api.functions.sink.SinkFunction;\n+import org.apache.flink.table.connector.ChangelogMode;\n+import org.apache.flink.table.connector.sink.DynamicTableSink;\n+import org.apache.flink.table.connector.sink.SinkFunctionProvider;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.factories.DynamicTableSinkFactory;\n+import org.apache.flink.types.RowKind;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+/**\n+ * Black hole table sink factory.\n+ */\n+@Experimental", "originalCommit": "9a9ae4d5447c18f4cd593e7f0ea115698026db4f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDg4NDUxOQ==", "url": "https://github.com/apache/flink/pull/12126#discussion_r424884519", "bodyText": "@PublicEvolving", "author": "JingsongLi", "createdAt": "2020-05-14T05:48:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUwODU3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUxMDE1OA==", "url": "https://github.com/apache/flink/pull/12126#discussion_r424510158", "bodyText": "Could you add more description about this connector? The behavior and how to use it.", "author": "wuchong", "createdAt": "2020-05-13T15:03:37Z", "path": "flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/sinks/BlackHoleTableSinkFactory.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.sinks;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.configuration.ConfigOption;\n+import org.apache.flink.streaming.api.functions.sink.SinkFunction;\n+import org.apache.flink.table.connector.ChangelogMode;\n+import org.apache.flink.table.connector.sink.DynamicTableSink;\n+import org.apache.flink.table.connector.sink.SinkFunctionProvider;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.factories.DynamicTableSinkFactory;\n+import org.apache.flink.types.RowKind;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+/**\n+ * Black hole table sink factory.", "originalCommit": "9a9ae4d5447c18f4cd593e7f0ea115698026db4f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUxMzkzNA==", "url": "https://github.com/apache/flink/pull/12126#discussion_r424513934", "bodyText": "Could you extract this SinkFunction as a static class?", "author": "wuchong", "createdAt": "2020-05-13T15:08:32Z", "path": "flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/sinks/PrintTableSinkFactory.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.sinks;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.configuration.ConfigOption;\n+import org.apache.flink.streaming.api.functions.sink.SinkFunction;\n+import org.apache.flink.table.connector.ChangelogMode;\n+import org.apache.flink.table.connector.sink.DynamicTableSink;\n+import org.apache.flink.table.connector.sink.SinkFunctionProvider;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.factories.DynamicTableSinkFactory;\n+import org.apache.flink.table.types.DataType;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+/**\n+ * Print table sink factory.\n+ */\n+@Experimental\n+public class PrintTableSinkFactory implements DynamicTableSinkFactory {\n+\n+\tpublic static final String IDENTIFIER = \"print\";\n+\n+\t@Override\n+\tpublic String factoryIdentifier() {\n+\t\treturn IDENTIFIER;\n+\t}\n+\n+\t@Override\n+\tpublic Set<ConfigOption<?>> requiredOptions() {\n+\t\treturn new HashSet<>();\n+\t}\n+\n+\t@Override\n+\tpublic Set<ConfigOption<?>> optionalOptions() {\n+\t\treturn new HashSet<>();\n+\t}\n+\n+\t@Override\n+\tpublic DynamicTableSink createDynamicTableSink(Context context) {\n+\t\treturn new PrintSink(context.getCatalogTable().getSchema().toRowDataType());\n+\t}\n+\n+\tstatic class PrintSink implements DynamicTableSink {\n+\n+\t\tprivate final DataType type;\n+\n+\t\tprivate PrintSink(DataType type) {\n+\t\t\tthis.type = type;\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic ChangelogMode getChangelogMode(ChangelogMode requestedMode) {\n+\t\t\treturn requestedMode;\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic SinkRuntimeProvider getSinkRuntimeProvider(DynamicTableSink.Context context) {\n+\t\t\tDataStructureConverter converter = context.createDataStructureConverter(type);\n+\t\t\treturn SinkFunctionProvider.of(new SinkFunction<RowData>() {", "originalCommit": "9a9ae4d5447c18f4cd593e7f0ea115698026db4f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDg0Mjg5MQ==", "url": "https://github.com/apache/flink/pull/12126#discussion_r424842891", "bodyText": "I'd like to use PrintSinkFunction.", "author": "JingsongLi", "createdAt": "2020-05-14T02:56:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUxMzkzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDg0NTM2OA==", "url": "https://github.com/apache/flink/pull/12126#discussion_r424845368", "bodyText": "PrintSinkFunction is not suitable for our case, because it will just simply print to toString.", "author": "wuchong", "createdAt": "2020-05-14T03:07:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUxMzkzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDg0NzQyMA==", "url": "https://github.com/apache/flink/pull/12126#discussion_r424847420", "bodyText": "Yeah, I want to extend or invoke it in our sink function.", "author": "JingsongLi", "createdAt": "2020-05-14T03:16:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUxMzkzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUxNDc3Mg==", "url": "https://github.com/apache/flink/pull/12126#discussion_r424514772", "bodyText": "Use toPhysicalRowDataType to ignore the computed columns.", "author": "wuchong", "createdAt": "2020-05-13T15:09:40Z", "path": "flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/sinks/PrintTableSinkFactory.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.sinks;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.configuration.ConfigOption;\n+import org.apache.flink.streaming.api.functions.sink.SinkFunction;\n+import org.apache.flink.table.connector.ChangelogMode;\n+import org.apache.flink.table.connector.sink.DynamicTableSink;\n+import org.apache.flink.table.connector.sink.SinkFunctionProvider;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.factories.DynamicTableSinkFactory;\n+import org.apache.flink.table.types.DataType;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+/**\n+ * Print table sink factory.\n+ */\n+@Experimental\n+public class PrintTableSinkFactory implements DynamicTableSinkFactory {\n+\n+\tpublic static final String IDENTIFIER = \"print\";\n+\n+\t@Override\n+\tpublic String factoryIdentifier() {\n+\t\treturn IDENTIFIER;\n+\t}\n+\n+\t@Override\n+\tpublic Set<ConfigOption<?>> requiredOptions() {\n+\t\treturn new HashSet<>();\n+\t}\n+\n+\t@Override\n+\tpublic Set<ConfigOption<?>> optionalOptions() {\n+\t\treturn new HashSet<>();\n+\t}\n+\n+\t@Override\n+\tpublic DynamicTableSink createDynamicTableSink(Context context) {\n+\t\treturn new PrintSink(context.getCatalogTable().getSchema().toRowDataType());", "originalCommit": "9a9ae4d5447c18f4cd593e7f0ea115698026db4f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUxNTMwNA==", "url": "https://github.com/apache/flink/pull/12126#discussion_r424515304", "bodyText": "I think we can ignore the change flags when this print sink works in insert-only mode. The falg is verbose and meaning less for batch processing.", "author": "wuchong", "createdAt": "2020-05-13T15:10:20Z", "path": "flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/sinks/PrintTableSinkFactory.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.sinks;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.configuration.ConfigOption;\n+import org.apache.flink.streaming.api.functions.sink.SinkFunction;\n+import org.apache.flink.table.connector.ChangelogMode;\n+import org.apache.flink.table.connector.sink.DynamicTableSink;\n+import org.apache.flink.table.connector.sink.SinkFunctionProvider;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.factories.DynamicTableSinkFactory;\n+import org.apache.flink.table.types.DataType;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+/**\n+ * Print table sink factory.\n+ */\n+@Experimental\n+public class PrintTableSinkFactory implements DynamicTableSinkFactory {\n+\n+\tpublic static final String IDENTIFIER = \"print\";\n+\n+\t@Override\n+\tpublic String factoryIdentifier() {\n+\t\treturn IDENTIFIER;\n+\t}\n+\n+\t@Override\n+\tpublic Set<ConfigOption<?>> requiredOptions() {\n+\t\treturn new HashSet<>();\n+\t}\n+\n+\t@Override\n+\tpublic Set<ConfigOption<?>> optionalOptions() {\n+\t\treturn new HashSet<>();\n+\t}\n+\n+\t@Override\n+\tpublic DynamicTableSink createDynamicTableSink(Context context) {\n+\t\treturn new PrintSink(context.getCatalogTable().getSchema().toRowDataType());\n+\t}\n+\n+\tstatic class PrintSink implements DynamicTableSink {\n+\n+\t\tprivate final DataType type;\n+\n+\t\tprivate PrintSink(DataType type) {\n+\t\t\tthis.type = type;\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic ChangelogMode getChangelogMode(ChangelogMode requestedMode) {\n+\t\t\treturn requestedMode;\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic SinkRuntimeProvider getSinkRuntimeProvider(DynamicTableSink.Context context) {\n+\t\t\tDataStructureConverter converter = context.createDataStructureConverter(type);\n+\t\t\treturn SinkFunctionProvider.of(new SinkFunction<RowData>() {\n+\t\t\t\t@Override\n+\t\t\t\tpublic void invoke(RowData value, Context context) {\n+\t\t\t\t\tObject row = converter.toExternal(value);\n+\t\t\t\t\tSystem.out.println(\n+\t\t\t\t\t\t\tvalue.getRowKind().shortString() + \"(\" + row + \")\");", "originalCommit": "9a9ae4d5447c18f4cd593e7f0ea115698026db4f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDg4NTUxNg==", "url": "https://github.com/apache/flink/pull/12126#discussion_r424885516", "bodyText": "I think we should keep one string format. Just like nested fields, we can keep change flags.", "author": "JingsongLi", "createdAt": "2020-05-14T05:51:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUxNTMwNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUxNjU3MQ==", "url": "https://github.com/apache/flink/pull/12126#discussion_r424516571", "bodyText": "This class name is too generic.. It sounds like a test for TableSinkFactory. Could you split this class into BlackHoleTableSinkITCase and PrintTableSinkITCase?\nCould you use DDL to test the connectors to have more coverage? I think it's fine to move the ITCase into blink planner.", "author": "wuchong", "createdAt": "2020-05-13T15:12:05Z", "path": "flink-table/flink-table-api-java-bridge/src/test/java/org/apache/flink/table/sinks/TableSinkFactoryTest.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.sinks;\n+\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.streaming.api.functions.sink.SinkFunction;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.catalog.CatalogTableImpl;\n+import org.apache.flink.table.catalog.ObjectIdentifier;\n+import org.apache.flink.table.connector.sink.DynamicTableSink;\n+import org.apache.flink.table.connector.sink.SinkFunctionProvider;\n+import org.apache.flink.table.data.GenericRowData;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.data.StringData;\n+import org.apache.flink.table.factories.FactoryUtil;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.types.Row;\n+\n+import org.junit.Test;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Tests for {@link BlackHoleTableSinkFactory} and {@link PrintTableSinkFactory}.\n+ */\n+public class TableSinkFactoryTest {", "originalCommit": "9a9ae4d5447c18f4cd593e7f0ea115698026db4f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDg1NDEzNQ==", "url": "https://github.com/apache/flink/pull/12126#discussion_r424854135", "bodyText": "A new table factory deserves a it case.", "author": "JingsongLi", "createdAt": "2020-05-14T03:44:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUxNjU3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUxODk2Ng==", "url": "https://github.com/apache/flink/pull/12126#discussion_r424518966", "bodyText": "A way to verify print sink is delegating System.out to an OutputStream, then we can verify the outputs in the OutputStream. You can take PrintSinkFunctionTest as an example.", "author": "wuchong", "createdAt": "2020-05-13T15:15:09Z", "path": "flink-table/flink-table-api-java-bridge/src/test/java/org/apache/flink/table/sinks/TableSinkFactoryTest.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.sinks;\n+\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.streaming.api.functions.sink.SinkFunction;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.catalog.CatalogTableImpl;\n+import org.apache.flink.table.catalog.ObjectIdentifier;\n+import org.apache.flink.table.connector.sink.DynamicTableSink;\n+import org.apache.flink.table.connector.sink.SinkFunctionProvider;\n+import org.apache.flink.table.data.GenericRowData;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.data.StringData;\n+import org.apache.flink.table.factories.FactoryUtil;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.types.Row;\n+\n+import org.junit.Test;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Tests for {@link BlackHoleTableSinkFactory} and {@link PrintTableSinkFactory}.\n+ */\n+public class TableSinkFactoryTest {\n+\n+\tprivate static final TableSchema TEST_SCHEMA = TableSchema.builder()\n+\t\t.field(\"f0\", DataTypes.STRING())\n+\t\t.field(\"f1\", DataTypes.BIGINT())\n+\t\t.field(\"f2\", DataTypes.BIGINT())\n+\t\t.build();\n+\n+\t@Test\n+\tpublic void testPrint() throws Exception {\n+\t\tMap<String, String> properties = new HashMap<>();\n+\t\tproperties.put(\"connector\", \"print\");\n+\n+\t\tDynamicTableSink sink = FactoryUtil.createTableSink(\n+\t\t\t\tnull,\n+\t\t\t\tObjectIdentifier.of(\"\", \"\", \"\"),\n+\t\t\t\tnew CatalogTableImpl(TEST_SCHEMA, properties, \"\"),\n+\t\t\t\tnew Configuration(),\n+\t\t\t\tThread.currentThread().getContextClassLoader());\n+\n+\t\tassertTrue(sink instanceof PrintTableSinkFactory.PrintSink);\n+\t\tDynamicTableSink.Context context = new DynamicTableSink.Context() {\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isBounded() {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic DynamicTableSink.DataStructureConverter createDataStructureConverter(\n+\t\t\t\t\tDataType consumedDataType) {\n+\t\t\t\treturn new DynamicTableSink.DataStructureConverter() {\n+\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic void open(Context context) {\n+\t\t\t\t\t}\n+\n+\t\t\t\t\t@Nullable\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic Object toExternal(@Nullable Object o) {\n+\t\t\t\t\t\tRowData row = (RowData) o;\n+\t\t\t\t\t\treturn o == null ? null : Row.of(row.getInt(0), row.getString(1).toString());", "originalCommit": "9a9ae4d5447c18f4cd593e7f0ea115698026db4f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyMDQwOA==", "url": "https://github.com/apache/flink/pull/12126#discussion_r424520408", "bodyText": "Use DiscardingSink.", "author": "wuchong", "createdAt": "2020-05-13T15:17:04Z", "path": "flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/sinks/BlackHoleTableSinkFactory.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.sinks;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.configuration.ConfigOption;\n+import org.apache.flink.streaming.api.functions.sink.SinkFunction;\n+import org.apache.flink.table.connector.ChangelogMode;\n+import org.apache.flink.table.connector.sink.DynamicTableSink;\n+import org.apache.flink.table.connector.sink.SinkFunctionProvider;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.factories.DynamicTableSinkFactory;\n+import org.apache.flink.types.RowKind;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+/**\n+ * Black hole table sink factory.\n+ */\n+@Experimental\n+public class BlackHoleTableSinkFactory implements DynamicTableSinkFactory {\n+\n+\tpublic static final String IDENTIFIER = \"blackhole\";\n+\n+\t@Override\n+\tpublic String factoryIdentifier() {\n+\t\treturn IDENTIFIER;\n+\t}\n+\n+\t@Override\n+\tpublic Set<ConfigOption<?>> requiredOptions() {\n+\t\treturn new HashSet<>();\n+\t}\n+\n+\t@Override\n+\tpublic Set<ConfigOption<?>> optionalOptions() {\n+\t\treturn new HashSet<>();\n+\t}\n+\n+\t@Override\n+\tpublic DynamicTableSink createDynamicTableSink(Context context) {\n+\t\treturn new BlackHoleSink();\n+\t}\n+\n+\tstatic class BlackHoleSink implements DynamicTableSink {\n+\n+\t\t@Override\n+\t\tpublic ChangelogMode getChangelogMode(ChangelogMode requestedMode) {\n+\t\t\tChangelogMode.Builder builder = ChangelogMode.newBuilder();\n+\t\t\tfor (RowKind kind : requestedMode.getContainedKinds()) {\n+\t\t\t\tif (kind != RowKind.UPDATE_BEFORE) {\n+\t\t\t\t\tbuilder.addContainedKind(kind);\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\treturn builder.build();\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic SinkRuntimeProvider getSinkRuntimeProvider(DynamicTableSink.Context context) {\n+\t\t\treturn SinkFunctionProvider.of(new SinkFunction<RowData>() {", "originalCommit": "9a9ae4d5447c18f4cd593e7f0ea115698026db4f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyMjU4Ng==", "url": "https://github.com/apache/flink/pull/12126#discussion_r424522586", "bodyText": "Could you add all the data types? Especially for print sink. We should make sure all the types are displayed as expected.", "author": "wuchong", "createdAt": "2020-05-13T15:19:57Z", "path": "flink-table/flink-table-api-java-bridge/src/test/java/org/apache/flink/table/sinks/TableSinkFactoryTest.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.sinks;\n+\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.streaming.api.functions.sink.SinkFunction;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.catalog.CatalogTableImpl;\n+import org.apache.flink.table.catalog.ObjectIdentifier;\n+import org.apache.flink.table.connector.sink.DynamicTableSink;\n+import org.apache.flink.table.connector.sink.SinkFunctionProvider;\n+import org.apache.flink.table.data.GenericRowData;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.data.StringData;\n+import org.apache.flink.table.factories.FactoryUtil;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.types.Row;\n+\n+import org.junit.Test;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Tests for {@link BlackHoleTableSinkFactory} and {@link PrintTableSinkFactory}.\n+ */\n+public class TableSinkFactoryTest {\n+\n+\tprivate static final TableSchema TEST_SCHEMA = TableSchema.builder()\n+\t\t.field(\"f0\", DataTypes.STRING())\n+\t\t.field(\"f1\", DataTypes.BIGINT())\n+\t\t.field(\"f2\", DataTypes.BIGINT())\n+\t\t.build();", "originalCommit": "9a9ae4d5447c18f4cd593e7f0ea115698026db4f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDg1NDYwNA==", "url": "https://github.com/apache/flink/pull/12126#discussion_r424854604", "bodyText": "It is hard to construct converter, I will add to it case.", "author": "JingsongLi", "createdAt": "2020-05-14T03:47:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyMjU4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDkwNTUzOA==", "url": "https://github.com/apache/flink/pull/12126#discussion_r424905538", "bodyText": "Do we need this?", "author": "wuchong", "createdAt": "2020-05-14T06:46:13Z", "path": "flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/factories/PrintTableSinkFactory.java", "diffHunk": "@@ -0,0 +1,171 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.factories;\n+\n+import org.apache.flink.annotation.PublicEvolving;\n+import org.apache.flink.api.common.functions.util.PrintSinkOutputWriter;\n+import org.apache.flink.configuration.ConfigOption;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.ReadableConfig;\n+import org.apache.flink.streaming.api.functions.sink.PrintSinkFunction;\n+import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;\n+import org.apache.flink.streaming.api.operators.StreamingRuntimeContext;\n+import org.apache.flink.table.connector.ChangelogMode;\n+import org.apache.flink.table.connector.sink.DynamicTableSink;\n+import org.apache.flink.table.connector.sink.DynamicTableSink.DataStructureConverter;\n+import org.apache.flink.table.connector.sink.SinkFunctionProvider;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.types.DataType;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+import static org.apache.flink.configuration.ConfigOptions.key;\n+\n+/**\n+ * Print table sink factory writing every row to the standard output or standard error stream.\n+ * It is designed for:\n+ * - easy test for streaming job.\n+ * - very useful in production debugging.\n+ *\n+ * <p>\n+ * Four possible format options:\n+ *\t{@code PRINT_IDENTIFIER}:taskId> output  <- {@code PRINT_IDENTIFIER} provided, parallelism > 1\n+ *\t{@code PRINT_IDENTIFIER}> output         <- {@code PRINT_IDENTIFIER} provided, parallelism == 1\n+ *  taskId> output         \t\t\t\t   <- no {@code PRINT_IDENTIFIER} provided, parallelism > 1\n+ *  output                 \t\t\t\t   <- no {@code PRINT_IDENTIFIER} provided, parallelism == 1\n+ * </p>\n+ *\n+ * <p>output string format is \"$RowKind(f0,f1,f2...)\", example is: \"+I(1,1)\".\n+ */\n+@PublicEvolving\n+public class PrintTableSinkFactory implements DynamicTableSinkFactory {\n+\n+\tpublic static final String IDENTIFIER = \"print\";\n+\n+\tpublic static final ConfigOption<String> PRINT_IDENTIFIER = key(\"print-identifier\")\n+\t\t\t.stringType()\n+\t\t\t.noDefaultValue()\n+\t\t\t.withDescription(\"Message that identify print and is prefixed to the output of the value.\");\n+\n+\tpublic static final ConfigOption<Boolean> STANDARD_ERROR = key(\"standard-error\")\n+\t\t\t.booleanType()\n+\t\t\t.defaultValue(false)\n+\t\t\t.withDescription(\"True, if the format should print to standard error instead of standard out.\");\n+\n+\t@Override\n+\tpublic String factoryIdentifier() {\n+\t\treturn IDENTIFIER;\n+\t}\n+\n+\t@Override\n+\tpublic Set<ConfigOption<?>> requiredOptions() {\n+\t\treturn new HashSet<>();\n+\t}\n+\n+\t@Override\n+\tpublic Set<ConfigOption<?>> optionalOptions() {\n+\t\tSet<ConfigOption<?>> options = new HashSet<>();\n+\t\toptions.add(PRINT_IDENTIFIER);\n+\t\toptions.add(STANDARD_ERROR);\n+\t\treturn options;\n+\t}\n+\n+\t@Override\n+\tpublic DynamicTableSink createDynamicTableSink(Context context) {\n+\t\tFactoryUtil.TableFactoryHelper helper = FactoryUtil.createTableFactoryHelper(this, context);\n+\t\thelper.validate();\n+\t\tReadableConfig options = helper.getOptions();\n+\t\treturn new PrintSink(\n+\t\t\t\tcontext.getCatalogTable().getSchema().toPhysicalRowDataType(),\n+\t\t\t\toptions.get(PRINT_IDENTIFIER),\n+\t\t\t\toptions.get(STANDARD_ERROR));\n+\t}\n+\n+\tprivate static class PrintSink implements DynamicTableSink {\n+\n+\t\tprivate final DataType type;\n+\t\tprivate final String printIdentifier;\n+\t\tprivate final boolean stdErr;\n+\n+\t\tprivate PrintSink(DataType type, String printIdentifier, boolean stdErr) {\n+\t\t\tthis.type = type;\n+\t\t\tthis.printIdentifier = printIdentifier;\n+\t\t\tthis.stdErr = stdErr;\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic ChangelogMode getChangelogMode(ChangelogMode requestedMode) {\n+\t\t\treturn requestedMode;\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic SinkRuntimeProvider getSinkRuntimeProvider(DynamicTableSink.Context context) {\n+\t\t\tDataStructureConverter converter = context.createDataStructureConverter(type);\n+\t\t\treturn SinkFunctionProvider.of(new RowDataPrintFunction(converter, printIdentifier, stdErr));\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic DynamicTableSink copy() {\n+\t\t\treturn new PrintSink(type, printIdentifier, stdErr);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic String asSummaryString() {\n+\t\t\treturn \"Print to \" + (stdErr ? \"System.err\" : \"System.out\");\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Implementation of the SinkFunction converting {@link RowData} to string and\n+\t * passing to {@link PrintSinkFunction}.\n+\t */\n+\tprivate static class RowDataPrintFunction extends RichSinkFunction<RowData> {\n+\n+\t\tprivate static final long serialVersionUID = 1L;\n+\n+\t\tprivate final DataStructureConverter converter;\n+\t\tprivate final PrintSinkOutputWriter<String> writer;\n+\n+\t\tprivate RowDataPrintFunction(\n+\t\t\t\tDataStructureConverter converter, String printIdentifier, boolean stdErr) {\n+\t\t\tthis.converter = converter;\n+\t\t\tthis.writer = new PrintSinkOutputWriter<>(printIdentifier, stdErr);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void open(Configuration parameters) throws Exception {\n+\t\t\tsuper.open(parameters);\n+\t\t\tStreamingRuntimeContext context = (StreamingRuntimeContext) getRuntimeContext();\n+\t\t\twriter.open(context.getIndexOfThisSubtask(), context.getNumberOfParallelSubtasks());\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic void invoke(RowData value, Context context) {\n+\t\t\tString rowKind = value.getRowKind().shortString();\n+\t\t\tObject data = converter.toExternal(value);\n+\t\t\twriter.write(rowKind + \"(\" + data + \")\");\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic String toString() {\n+\t\t\treturn writer.toString();\n+\t\t}", "originalCommit": "9c81e3b4619274d580ade40a3d37f57abedc0192", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDkxNDA3NA==", "url": "https://github.com/apache/flink/pull/12126#discussion_r424914074", "bodyText": "Delete it.", "author": "JingsongLi", "createdAt": "2020-05-14T07:05:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDkwNTUzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDkwNzY3NQ==", "url": "https://github.com/apache/flink/pull/12126#discussion_r424907675", "bodyText": "Can be simplified to tEnv().fromValues(row(1, 1.1), row(2, 2.2)), use the org.apache.flink.table.api.Expressions.row.", "author": "wuchong", "createdAt": "2020-05-14T06:51:06Z", "path": "flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/runtime/stream/table/BlackHoleITCase.java", "diffHunk": "@@ -0,0 +1,42 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.runtime.stream.table;\n+\n+import org.apache.flink.table.factories.BlackHoleTableSinkFactory;\n+import org.apache.flink.table.planner.runtime.utils.StreamingTestBase;\n+import org.apache.flink.types.Row;\n+\n+import org.junit.Test;\n+\n+import java.util.Arrays;\n+\n+/**\n+ * End to end tests for {@link BlackHoleTableSinkFactory}.\n+ */\n+public class BlackHoleITCase extends StreamingTestBase {\n+\n+\t@Test\n+\tpublic void testTypes() {\n+\t\ttEnv().executeSql(\n+\t\t\t\t\"create table blackhole_t (f0 int, f1 double) with ('connector' = 'blackhole')\");\n+\t\texecInsertTableAndWaitResult(\n+\t\t\t\ttEnv().fromValues(Arrays.asList(Row.of(1, 1.1), Row.of(2, 2.2))),", "originalCommit": "9c81e3b4619274d580ade40a3d37f57abedc0192", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDkwODk3MQ==", "url": "https://github.com/apache/flink/pull/12126#discussion_r424908971", "bodyText": "Could you format the DDL a bit? Put every column at a single line.", "author": "wuchong", "createdAt": "2020-05-14T06:54:00Z", "path": "flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/runtime/stream/table/PrintITCase.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.runtime.stream.table;\n+\n+import org.apache.flink.table.factories.PrintTableSinkFactory;\n+import org.apache.flink.table.planner.runtime.utils.StreamingTestBase;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.types.Row;\n+\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.PrintStream;\n+import java.math.BigDecimal;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * End to end tests for {@link PrintTableSinkFactory}.\n+ */\n+public class PrintITCase extends StreamingTestBase {\n+\n+\tprivate final PrintStream originalSystemOut = System.out;\n+\tprivate final PrintStream originalSystemErr = System.err;\n+\n+\tprivate final ByteArrayOutputStream arrayOutputStream = new ByteArrayOutputStream();\n+\tprivate final ByteArrayOutputStream arrayErrorStream = new ByteArrayOutputStream();\n+\n+\t@Before\n+\tpublic void setUp() {\n+\t\tSystem.setOut(new PrintStream(arrayOutputStream));\n+\t\tSystem.setErr(new PrintStream(arrayErrorStream));\n+\t}\n+\n+\t@After\n+\tpublic void tearDown() {\n+\t\tif (System.out != originalSystemOut) {\n+\t\t\tSystem.out.close();\n+\t\t}\n+\t\tif (System.err != originalSystemErr) {\n+\t\t\tSystem.err.close();\n+\t\t}\n+\t\tSystem.setOut(originalSystemOut);\n+\t\tSystem.setErr(originalSystemErr);\n+\t}\n+\n+\t@Test\n+\tpublic void testTypes() {\n+\t\ttest(false);\n+\t}\n+\n+\t@Test\n+\tpublic void testStandardError() {\n+\t\ttest(true);\n+\t}\n+\n+\tprivate void test(boolean standardError) {\n+\t\ttEnv().executeSql(String.format(\"create table print_t (\" +", "originalCommit": "9c81e3b4619274d580ade40a3d37f57abedc0192", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDkwOTU0Mg==", "url": "https://github.com/apache/flink/pull/12126#discussion_r424909542", "bodyText": "PrintConnectorITCase? Make it more explicitly it's not a print IT case for Table#executeInsert()#print().", "author": "wuchong", "createdAt": "2020-05-14T06:55:19Z", "path": "flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/runtime/stream/table/PrintITCase.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.runtime.stream.table;\n+\n+import org.apache.flink.table.factories.PrintTableSinkFactory;\n+import org.apache.flink.table.planner.runtime.utils.StreamingTestBase;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.types.Row;\n+\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.PrintStream;\n+import java.math.BigDecimal;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * End to end tests for {@link PrintTableSinkFactory}.\n+ */\n+public class PrintITCase extends StreamingTestBase {", "originalCommit": "9c81e3b4619274d580ade40a3d37f57abedc0192", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDkwOTgxMw==", "url": "https://github.com/apache/flink/pull/12126#discussion_r424909813", "bodyText": "BlackHoleConnectorITCase?", "author": "wuchong", "createdAt": "2020-05-14T06:55:52Z", "path": "flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/runtime/stream/table/BlackHoleITCase.java", "diffHunk": "@@ -0,0 +1,42 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.runtime.stream.table;\n+\n+import org.apache.flink.table.factories.BlackHoleTableSinkFactory;\n+import org.apache.flink.table.planner.runtime.utils.StreamingTestBase;\n+import org.apache.flink.types.Row;\n+\n+import org.junit.Test;\n+\n+import java.util.Arrays;\n+\n+/**\n+ * End to end tests for {@link BlackHoleTableSinkFactory}.\n+ */\n+public class BlackHoleITCase extends StreamingTestBase {", "originalCommit": "9c81e3b4619274d580ade40a3d37f57abedc0192", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "aaf5a890b85f9fb1e1511ca3c53549afef71bd40", "url": "https://github.com/apache/flink/commit/aaf5a890b85f9fb1e1511ca3c53549afef71bd40", "message": "[FLINK-17664][table] Introduce print, blackhole connector in table", "committedDate": "2020-05-15T05:58:53Z", "type": "commit"}, {"oid": "aaf5a890b85f9fb1e1511ca3c53549afef71bd40", "url": "https://github.com/apache/flink/commit/aaf5a890b85f9fb1e1511ca3c53549afef71bd40", "message": "[FLINK-17664][table] Introduce print, blackhole connector in table", "committedDate": "2020-05-15T05:58:53Z", "type": "forcePushed"}]}