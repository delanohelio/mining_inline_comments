{"pr_number": 12452, "pr_title": "[FLINK-18056][fs-connector] Hadoop path-based file writer adds UUID to in-progress file to avoid conflicts", "pr_createdAt": "2020-06-03T02:41:00Z", "pr_url": "https://github.com/apache/flink/pull/12452", "timeline": [{"oid": "fef42fb8497d9822a12ab18114ecb0ea4f36509f", "url": "https://github.com/apache/flink/commit/fef42fb8497d9822a12ab18114ecb0ea4f36509f", "message": "Fix checkstyle", "committedDate": "2020-06-04T16:25:33Z", "type": "forcePushed"}, {"oid": "3f7e6da089bea0dd3a2f2fc2bfafb88a13aa482c", "url": "https://github.com/apache/flink/commit/3f7e6da089bea0dd3a2f2fc2bfafb88a13aa482c", "message": "[FLINK-18056][fs-connector] Hadoop path-based file writer adds UUID to in-progress file to avoid conflicts", "committedDate": "2020-06-05T08:02:22Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTc4MjM5OA==", "url": "https://github.com/apache/flink/pull/12452#discussion_r435782398", "bodyText": "just 12 + pathBytes.length + inProgressBytes.length", "author": "JingsongLi", "createdAt": "2020-06-05T08:53:14Z", "path": "flink-formats/flink-hadoop-bulk/src/main/java/org/apache/flink/formats/hadoop/bulk/HadoopPathBasedPartFileWriter.java", "diffHunk": "@@ -142,14 +150,21 @@ public int getVersion() {\n \t\t\t\tthrow new UnsupportedOperationException(\"Only HadoopPathBasedPendingFileRecoverable is supported.\");\n \t\t\t}\n \n-\t\t\tPath path = ((HadoopPathBasedPendingFileRecoverable) pendingFileRecoverable).getPath();\n+\t\t\tHadoopPathBasedPendingFileRecoverable hadoopRecoverable =\n+\t\t\t\t(HadoopPathBasedPendingFileRecoverable) pendingFileRecoverable;\n+\t\t\tPath path = hadoopRecoverable.getPath();\n+\t\t\tPath inProgressPath = hadoopRecoverable.getInProgressPath();\n+\n \t\t\tbyte[] pathBytes = path.toUri().toString().getBytes(CHARSET);\n+\t\t\tbyte[] inProgressBytes = inProgressPath.toUri().toString().getBytes(CHARSET);\n \n-\t\t\tbyte[] targetBytes = new byte[8 + pathBytes.length];\n+\t\t\tbyte[] targetBytes = new byte[8 + pathBytes.length + 4 + inProgressBytes.length];", "originalCommit": "3f7e6da089bea0dd3a2f2fc2bfafb88a13aa482c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTc4MzE2Mg==", "url": "https://github.com/apache/flink/pull/12452#discussion_r435783162", "bodyText": "I think you can add some comments to explain in HadoopPathBasedPartFileWriter, what we store in state.", "author": "JingsongLi", "createdAt": "2020-06-05T08:54:39Z", "path": "flink-formats/flink-hadoop-bulk/src/main/java/org/apache/flink/formats/hadoop/bulk/HadoopPathBasedPartFileWriter.java", "diffHunk": "@@ -142,14 +150,21 @@ public int getVersion() {\n \t\t\t\tthrow new UnsupportedOperationException(\"Only HadoopPathBasedPendingFileRecoverable is supported.\");\n \t\t\t}\n ", "originalCommit": "3f7e6da089bea0dd3a2f2fc2bfafb88a13aa482c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTc4MzkxMA==", "url": "https://github.com/apache/flink/pull/12452#discussion_r435783910", "bodyText": "Can be consistent with HadoopFsRecoverable, Path targetFile, Path tempFile", "author": "JingsongLi", "createdAt": "2020-06-05T08:56:00Z", "path": "flink-formats/flink-hadoop-bulk/src/main/java/org/apache/flink/formats/hadoop/bulk/HadoopPathBasedPartFileWriter.java", "diffHunk": "@@ -103,21 +103,29 @@ public void commitAfterRecovery() throws IOException {\n \n \t\tpublic PendingFileRecoverable getRecoverable() {\n \t\t\treturn new HadoopPathBasedPendingFileRecoverable(\n-\t\t\t\tfileCommitter.getTargetFilePath());\n+\t\t\t\tfileCommitter.getTargetFilePath(),\n+\t\t\t\tfileCommitter.getInProgressFilePath());\n \t\t}\n \t}\n \n \t@VisibleForTesting\n \tstatic class HadoopPathBasedPendingFileRecoverable implements PendingFileRecoverable {\n \t\tprivate final Path path;\n \n-\t\tpublic HadoopPathBasedPendingFileRecoverable(Path path) {\n+\t\tprivate final Path inProgressPath;\n+\n+\t\tpublic HadoopPathBasedPendingFileRecoverable(Path path, Path inProgressPath) {", "originalCommit": "3f7e6da089bea0dd3a2f2fc2bfafb88a13aa482c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTc4NTc2Mw==", "url": "https://github.com/apache/flink/pull/12452#discussion_r435785763", "bodyText": "\".inprogress\" -> \".inprogress.\"", "author": "JingsongLi", "createdAt": "2020-06-05T08:59:13Z", "path": "flink-formats/flink-hadoop-bulk/src/main/java/org/apache/flink/formats/hadoop/bulk/committer/HadoopRenameFileCommitter.java", "diffHunk": "@@ -96,12 +107,19 @@ private void rename(boolean assertFileExists) throws IOException {\n \t\t}\n \t}\n \n-\tprivate Path generateInProgressFilePath() {\n+\tprivate Path generateInProgressFilePath() throws IOException {\n \t\tcheckArgument(targetFilePath.isAbsolute(), \"Target file must be absolute\");\n \n+\t\tFileSystem fileSystem = FileSystem.get(targetFilePath.toUri(), configuration);\n+\n \t\tPath parent = targetFilePath.getParent();\n \t\tString name = targetFilePath.getName();\n \n-\t\treturn new Path(parent, \".\" + name + \".inprogress\");\n+\t\twhile (true) {\n+\t\t\tPath candidate = new Path(parent, \".\" + name + \".inprogress\" + UUID.randomUUID().toString());", "originalCommit": "3f7e6da089bea0dd3a2f2fc2bfafb88a13aa482c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "248476005c601939c42dab33d7f689809090ff35", "url": "https://github.com/apache/flink/commit/248476005c601939c42dab33d7f689809090ff35", "message": "Remove the S3 tests", "committedDate": "2020-06-08T11:39:21Z", "type": "forcePushed"}, {"oid": "de8e31736af54c3a8e00a38994b949051aa1b98c", "url": "https://github.com/apache/flink/commit/de8e31736af54c3a8e00a38994b949051aa1b98c", "message": "[FLINK-18056][fs-connector] Hadoop path-based file writer adds UUID to in-progress file to avoid conflicts", "committedDate": "2020-06-09T03:03:12Z", "type": "commit"}, {"oid": "de8e31736af54c3a8e00a38994b949051aa1b98c", "url": "https://github.com/apache/flink/commit/de8e31736af54c3a8e00a38994b949051aa1b98c", "message": "[FLINK-18056][fs-connector] Hadoop path-based file writer adds UUID to in-progress file to avoid conflicts", "committedDate": "2020-06-09T03:03:12Z", "type": "forcePushed"}]}