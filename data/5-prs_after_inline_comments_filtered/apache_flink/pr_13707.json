{"pr_number": 13707, "pr_title": "[FLINK-19737][table] Introduce TableOperatorWrapperGenerator to translate transformation DAG in a multiple-input node to TableOperatorWrapper DAG", "pr_createdAt": "2020-10-20T14:52:18Z", "pr_url": "https://github.com/apache/flink/pull/13707", "timeline": [{"oid": "a4eab96b447c76d5290b74306aaec06b8d5b5c36", "url": "https://github.com/apache/flink/commit/a4eab96b447c76d5290b74306aaec06b8d5b5c36", "message": "[FLINK-19737][table] Introduce TableOperatorWrapperGenerator to translate transformation DAG in a multiple-input node to TableOperatorWrapper DAG", "committedDate": "2020-10-20T15:05:46Z", "type": "forcePushed"}, {"oid": "21c8f136608b0ce47d5bdf3a4b6e27654f90b872", "url": "https://github.com/apache/flink/commit/21c8f136608b0ce47d5bdf3a4b6e27654f90b872", "message": "[FLINK-19737][table] Introduce TableOperatorWrapperGenerator to translate transformation DAG in a multiple-input node to TableOperatorWrapper DAG", "committedDate": "2020-10-20T15:09:21Z", "type": "commit"}, {"oid": "21c8f136608b0ce47d5bdf3a4b6e27654f90b872", "url": "https://github.com/apache/flink/commit/21c8f136608b0ce47d5bdf3a4b6e27654f90b872", "message": "[FLINK-19737][table] Introduce TableOperatorWrapperGenerator to translate transformation DAG in a multiple-input node to TableOperatorWrapper DAG", "committedDate": "2020-10-20T15:09:21Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODk1NjE1OQ==", "url": "https://github.com/apache/flink/pull/13707#discussion_r508956159", "bodyText": "extra space", "author": "tsreaper", "createdAt": "2020-10-21T02:47:44Z", "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/multipleinput/TableOperatorWrapperGenerator.java", "diffHunk": "@@ -0,0 +1,342 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.operators.multipleinput;\n+\n+import org.apache.flink.api.common.operators.ResourceSpec;\n+import org.apache.flink.api.dag.Transformation;\n+import org.apache.flink.core.memory.ManagedMemoryUseCase;\n+import org.apache.flink.streaming.api.operators.MultipleInputStreamOperator;\n+import org.apache.flink.streaming.api.operators.SimpleOperatorFactory;\n+import org.apache.flink.streaming.api.transformations.OneInputTransformation;\n+import org.apache.flink.streaming.api.transformations.TwoInputTransformation;\n+import org.apache.flink.streaming.api.transformations.UnionTransformation;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.runtime.operators.multipleinput.input.InputSpec;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.IdentityHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * A generator that generates a {@link TableOperatorWrapper} graph from a graph of {@link Transformation}.\n+ */\n+public class TableOperatorWrapperGenerator {\n+\n+\t/**\n+\t * Original input transformations for {@link MultipleInputStreamOperator}.\n+\t */\n+\tprivate final List<Transformation<?>> inputTransforms;\n+\n+\t/**\n+\t * The tail (root) transformation of the transformation-graph in {@link MultipleInputStreamOperator}.\n+\t */\n+\tprivate final Transformation<?> tailTransform;\n+\n+\t/**\n+\t * The read order corresponding to each transformation in {@link #inputTransforms}.\n+\t */\n+\tprivate final int[] readOrders;\n+\n+\t/**\n+\t * Reordered input transformations which order corresponds to the order of {@link #inputSpecs}.\n+\t */\n+\tprivate final List<Transformation<?>> orderedInputTransforms;\n+\n+\t/**\n+\t * The input specs which order corresponds to the order of {@link #orderedInputTransforms}.\n+\t */\n+\tprivate final List<InputSpec> inputSpecs;\n+\n+\t/**\n+\t * The head (leaf) operator wrappers of the operator-graph in {@link MultipleInputStreamOperator}.\n+\t */\n+\tprivate final List<TableOperatorWrapper<?>> headWrappers;\n+\n+\t/**\n+\t * The tail (root) operator wrapper of the operator-graph in {@link MultipleInputStreamOperator}.\n+\t */\n+\tprivate TableOperatorWrapper<?> tailWrapper;\n+\n+\t/**\n+\t * Map the visited transformation to its generated TableOperatorWrapper.\n+\t */\n+\tprivate final Map<Transformation<?>, TableOperatorWrapper<?>> visitedTransforms;\n+\t/**\n+\t * The identifier for each sub operator in {@link MultipleInputStreamOperator}.\n+\t */\n+\tprivate int identifierOfSubOp = 0;\n+\n+\tprivate int parallelism;\n+\tprivate int maxParallelism;\n+\tprivate ResourceSpec minResources;\n+\tprivate ResourceSpec preferredResources;\n+\t/**\n+\t * managed memory weight for batch operator.\n+\t */\n+\tprivate int managedMemoryWeight;\n+\n+\tpublic TableOperatorWrapperGenerator(\n+\t\t\tList<Transformation<?>> inputTransforms,\n+\t\t\tTransformation<?> tailTransform) {\n+\t\tthis(inputTransforms, tailTransform, new int[inputTransforms.size()]);\n+\t}\n+\n+\tpublic TableOperatorWrapperGenerator(\n+\t\t\tList<Transformation<?>> inputTransforms,\n+\t\t\tTransformation<?> tailTransform,\n+\t\t\tint[] readOrders) {\n+\t\tthis.inputTransforms = inputTransforms;\n+\t\tthis.tailTransform = tailTransform;\n+\t\tthis.readOrders = readOrders;\n+\t\tthis.inputSpecs = new ArrayList<>();\n+\t\tthis.headWrappers = new ArrayList<>();\n+\t\tthis.orderedInputTransforms = new ArrayList<>();\n+\t\tthis.visitedTransforms = new IdentityHashMap<>();\n+\n+\t\tthis.parallelism = -1;\n+\t\tthis.maxParallelism = -1;\n+\t}\n+\n+\tpublic void generate() {\n+\t\ttailWrapper = visit(tailTransform);\n+\t\tcheckState(orderedInputTransforms.size() == inputTransforms.size());\n+\t\tcheckState(orderedInputTransforms.size() == inputSpecs.size());\n+\t\tcalculateManagedMemoryFraction();\n+\t}\n+\n+\tpublic List<Transformation<?>> getOrderedInputTransforms() {\n+\t\treturn orderedInputTransforms;\n+\t}\n+\n+\tpublic List<InputSpec> getInputSpecs() {\n+\t\treturn inputSpecs;\n+\t}\n+\n+\tpublic List<TableOperatorWrapper<?>> getHeadWrappers() {\n+\t\treturn headWrappers;\n+\t}\n+\n+\tpublic TableOperatorWrapper<?> getTailWrapper() {\n+\t\treturn tailWrapper;\n+\t}\n+\n+\tpublic int getParallelism() {\n+\t\treturn parallelism;\n+\t}\n+\n+\tpublic int getMaxParallelism() {\n+\t\treturn maxParallelism;\n+\t}\n+\n+\tpublic ResourceSpec getMinResources() {\n+\t\treturn minResources;\n+\t}\n+\n+\tpublic ResourceSpec getPreferredResources() {\n+\t\treturn preferredResources;\n+\t}\n+\n+\tpublic int getManagedMemoryWeight() {\n+\t\treturn managedMemoryWeight;\n+\t}\n+\n+\tprivate TableOperatorWrapper<?> visit(Transformation<?> transform) {\n+\t\t// ignore UnionTransformation because it's not a really operator\n+\t\tif (!(transform instanceof UnionTransformation)) {\n+\t\t\tcalcParallelismAndResource(transform);\n+\t\t}\n+\n+\t\tfinal TableOperatorWrapper<?> wrapper;\n+\t\tif (visitedTransforms.containsKey(transform)) {\n+\t\t\twrapper = visitedTransforms.get(transform);\n+\t\t} else {\n+\t\t\twrapper = visitTransformation(transform);\n+\t\t\tvisitedTransforms.put(transform, wrapper);\n+\t\t}\n+\t\treturn wrapper;\n+\t}\n+\n+\tprivate void calcParallelismAndResource(Transformation<?> transform) {\n+\t\tint currentParallelism = transform.getParallelism();\n+\t\tif (parallelism < 0) {\n+\t\t\tparallelism = currentParallelism;\n+\t\t} else {\n+\t\t\tcheckState(\n+\t\t\t\t\tcurrentParallelism < 0 || parallelism == currentParallelism,\n+\t\t\t\t\t\"Parallelism of a transformation in MultipleInputNode is different from others. This is a bug.\");\n+\t\t}\n+\n+\t\tint currentMaxParallelism = transform.getMaxParallelism();\n+\t\tif (maxParallelism < 0) {\n+\t\t\tmaxParallelism = currentMaxParallelism;\n+\t\t} else {\n+\t\t\tcheckState(\n+\t\t\t\t\tcurrentMaxParallelism < 0 || maxParallelism == currentMaxParallelism,\n+\t\t\t\t\t\"Max parallelism of a transformation in MultipleInputNode is different from others. This is a bug.\");\n+\t\t}\n+\n+\t\tif (minResources == null) {\n+\t\t\tminResources = transform.getMinResources();\n+\t\t\tpreferredResources = transform.getPreferredResources();\n+\t\t\tmanagedMemoryWeight = transform.getManagedMemoryOperatorScopeUseCaseWeights()\n+\t\t\t\t\t.getOrDefault(ManagedMemoryUseCase.BATCH_OP, 0);\n+\t\t} else {\n+\t\t\tminResources = minResources.merge(transform.getMinResources());\n+\t\t\tpreferredResources = preferredResources.merge(transform.getPreferredResources());\n+\t\t\tmanagedMemoryWeight += transform.getManagedMemoryOperatorScopeUseCaseWeights()\n+\t\t\t\t\t.getOrDefault(ManagedMemoryUseCase.BATCH_OP, 0);\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+\tprivate TableOperatorWrapper<?> visitTransformation(Transformation<?> transform) {\n+\t\tif (transform instanceof OneInputTransformation) {\n+\t\t\treturn visitOneInputTransformation((OneInputTransformation) transform);\n+\t\t} else if (transform instanceof TwoInputTransformation) {\n+\t\t\treturn visitTwoInputTransformation((TwoInputTransformation) transform);\n+\t\t} else  if (transform instanceof UnionTransformation) {\n+\t\t\treturn visitUnionTransformation((UnionTransformation) transform);\n+\t\t} else  {\n+\t\t\tthrow new RuntimeException(\"Unsupported Transformation: \" + transform);\n+\t\t}\n+\t}\n+\n+\tprivate TableOperatorWrapper<?> visitOneInputTransformation(\n+\t\t\tOneInputTransformation<RowData, RowData> transform) {\n+\t\tTransformation<?> input = transform.getInputs().get(0);\n+\n+\t\tTableOperatorWrapper<?> wrapper = new TableOperatorWrapper<>(\n+\t\t\t\ttransform.getOperatorFactory(),\n+\t\t\t\tgenSubOperatorName(transform),\n+\t\t\t\tCollections.singletonList(transform.getInputType()),\n+\t\t\t\ttransform.getOutputType()\n+\t\t);\n+\n+\t\tint inputIdx = inputTransforms.indexOf(input);\n+\t\tif (inputIdx >= 0) {\n+\t\t\torderedInputTransforms.add(input);\n+\t\t\tinputSpecs.add(createInputSpec(readOrders[inputIdx], wrapper, 1));\n+\t\t\theadWrappers.add(wrapper);\n+\t\t} else {\n+\t\t\tTableOperatorWrapper<?> inputWrapper = visit(input);\n+\t\t\twrapper.addInput(inputWrapper, 1);\n+\t\t}\n+\t\treturn wrapper;\n+\t}\n+\n+\tprivate TableOperatorWrapper<?> visitTwoInputTransformation(\n+\t\t\tTwoInputTransformation<RowData, RowData, RowData> transform) {\n+\t\tTransformation<?> input1 = transform.getInput1();\n+\t\tTransformation<?> input2 = transform.getInput2();\n+\t\tint inputIdx1 = inputTransforms.indexOf(input1);\n+\t\tint inputIdx2 = inputTransforms.indexOf(input2);\n+\n+\t\tTableOperatorWrapper<?> wrapper = new TableOperatorWrapper<>(\n+\t\t\t\ttransform.getOperatorFactory(),\n+\t\t\t\tgenSubOperatorName(transform),\n+\t\t\t\tArrays.asList(transform.getInputType1(), transform.getInputType2()),\n+\t\t\t\ttransform.getOutputType());\n+\n+\t\tif (inputIdx1 >= 0 && inputIdx2 >= 0) {\n+\t\t\torderedInputTransforms.add(input1);\n+\t\t\tinputSpecs.add(createInputSpec(readOrders[inputIdx1], wrapper, 1));\n+\t\t\torderedInputTransforms.add(input2);\n+\t\t\tinputSpecs.add(createInputSpec(readOrders[inputIdx2], wrapper, 2));\n+\t\t\theadWrappers.add(wrapper);\n+\t\t} else if (inputIdx1 >= 0) {\n+\t\t\tTableOperatorWrapper<?> inputWrapper = visit(input2);\n+\t\t\twrapper.addInput(inputWrapper, 2);\n+\t\t\torderedInputTransforms.add(input1);\n+\t\t\tinputSpecs.add(createInputSpec(readOrders[inputIdx1], wrapper, 1));\n+\t\t\theadWrappers.add(wrapper);\n+\t\t} else if (inputIdx2 >= 0) {\n+\t\t\tTableOperatorWrapper<?> inputWrapper = visit(input1);\n+\t\t\twrapper.addInput(inputWrapper, 1);\n+\t\t\torderedInputTransforms.add(input2);\n+\t\t\tinputSpecs.add(createInputSpec(readOrders[inputIdx2], wrapper, 2));\n+\t\t\theadWrappers.add(wrapper);\n+\t\t} else {\n+\t\t\tTableOperatorWrapper<?> inputWrapper1 = visit(input1);\n+\t\t\twrapper.addInput(inputWrapper1, 1);\n+\t\t\tTableOperatorWrapper<?> inputWrapper2 = visit(input2);\n+\t\t\twrapper.addInput(inputWrapper2, 2);\n+\t\t}\n+\n+\t\treturn wrapper;\n+\t}\n+\n+\tprivate TableOperatorWrapper<?> visitUnionTransformation(\n+\t\t\tUnionTransformation<RowData> transform) {\n+\t\t// use MapFunction to combine the input data\n+\t\tTableOperatorWrapper<?> wrapper = new TableOperatorWrapper<>(\n+\t\t\t\tSimpleOperatorFactory.of(new UnionStreamOperator()),\n+\t\t\t\tgenSubOperatorName(transform),\n+\t\t\t\ttransform.getInputs().stream().map(Transformation::getOutputType).collect(Collectors.toList()),\n+\t\t\t\ttransform.getOutputType());\n+\n+\t\tint numberOfHeadInput = 0;\n+\t\tfor (Transformation<?> input : transform.getInputs()) {\n+\t\t\tint inputIdx = inputTransforms.indexOf(input);\n+\t\t\tif (inputIdx >= 0) {\n+\t\t\t\tnumberOfHeadInput ++;", "originalCommit": "21c8f136608b0ce47d5bdf3a4b6e27654f90b872", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODk5MDE4OA==", "url": "https://github.com/apache/flink/pull/13707#discussion_r508990188", "bodyText": "propagateEndOperatorInput?", "author": "tsreaper", "createdAt": "2020-10-21T04:59:09Z", "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/multipleinput/TableOperatorWrapper.java", "diffHunk": "@@ -0,0 +1,273 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.operators.multipleinput;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.streaming.api.operators.BoundedMultiInput;\n+import org.apache.flink.streaming.api.operators.BoundedOneInput;\n+import org.apache.flink.streaming.api.operators.StreamOperator;\n+import org.apache.flink.streaming.api.operators.StreamOperatorFactory;\n+import org.apache.flink.streaming.api.operators.StreamOperatorParameters;\n+import org.apache.flink.streaming.runtime.tasks.ProcessingTimeServiceAware;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.util.Preconditions;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.flink.util.Preconditions.checkArgument;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+\n+/**\n+ * This class handles the close, endInput and other related logic of a {@link StreamOperator}.\n+ * It also automatically propagates the end-input operation to the next wrapper that\n+ * the {@link #outputEdges} points to, so we only need to call the head wrapper's\n+ * {@link #endOperatorInput(int)} method.\n+ */\n+public class TableOperatorWrapper<OP extends StreamOperator<RowData>> implements Serializable {\n+\tprivate static final long serialVersionUID = 1L;\n+\n+\t/**\n+\t * The factory to create the wrapped operator.\n+\t */\n+\tprivate final StreamOperatorFactory<RowData> factory;\n+\n+\t/**\n+\t * the operator name for debugging.\n+\t */\n+\tprivate final String operatorName;\n+\n+\t/**\n+\t * The type info of this wrapped operator's all inputs.\n+\t *\n+\t * <p>NOTE:The inputs of an operator may not all be in the multiple-input operator, e.g.\n+\t * The multiple-input operator contains A and J, and A is one of the input of J,\n+\t * and another input of J is not in the multiple-input operator.\n+\t * <pre>\n+\t * -------\n+\t *        \\\n+\t *         J --\n+\t *        /\n+\t * -- A --\n+\t * </pre>\n+\t * For this example, `allInputTypes` contains two input types.\n+\t */\n+\tprivate final List<TypeInformation<?>> allInputTypes;\n+\n+\t/**\n+\t * The type info of this wrapped operator's output.\n+\t */\n+\tprivate final TypeInformation<?> outputType;\n+\n+\t/**\n+\t * Managed memory fraction in the multiple-input operator.\n+\t */\n+\tprivate double managedMemoryFraction = -1;\n+\n+\t/**\n+\t * The input edges of this operator wrapper, the edges' target is current instance.\n+\t */\n+\tprivate final List<Edge> inputEdges;\n+\n+\t/**\n+\t * The output edges of this operator wrapper, the edges' source is current instance.\n+\t */\n+\tprivate final List<Edge> outputEdges;\n+\n+\t/**\n+\t * The wrapped operator, which will be generated by {@link #factory}.\n+\t */\n+\tprivate transient OP wrapped;\n+\n+\tprivate boolean closed;\n+\tprivate int endedInputCount;\n+\n+\tpublic TableOperatorWrapper(\n+\t\t\tStreamOperatorFactory<RowData> factory,\n+\t\t\tString operatorName,\n+\t\t\tList<TypeInformation<?>> allInputTypes,\n+\t\t\tTypeInformation<?> outputType) {\n+\t\tthis.factory = checkNotNull(factory);\n+\t\tthis.operatorName = checkNotNull(operatorName);\n+\t\tthis.outputType = checkNotNull(outputType);\n+\t\tthis.allInputTypes = checkNotNull(allInputTypes);\n+\n+\t\tthis.inputEdges = new ArrayList<>();\n+\t\tthis.outputEdges = new ArrayList<>();\n+\n+\t\tthis.endedInputCount = 0;\n+\t}\n+\n+\tpublic void createOperator(StreamOperatorParameters<RowData> parameters) {\n+\t\tcheckArgument(wrapped == null, \"This operator has been initialized\");\n+\t\tif (factory instanceof ProcessingTimeServiceAware) {\n+\t\t\t((ProcessingTimeServiceAware) factory)\n+\t\t\t\t\t.setProcessingTimeService(parameters.getProcessingTimeService());\n+\t\t}\n+\t\twrapped = factory.createStreamOperator(parameters);\n+\t}\n+\n+\tpublic void endOperatorInput(int inputId) throws Exception {\n+\t\tendedInputCount++;\n+\t\tif (wrapped instanceof BoundedOneInput) {\n+\t\t\t((BoundedOneInput) wrapped).endInput();\n+\t\t\tendOperatorInputForOutput();\n+\t\t} else if (wrapped instanceof BoundedMultiInput) {\n+\t\t\t((BoundedMultiInput) wrapped).endInput(inputId);\n+\t\t\tif (endedInputCount >= allInputTypes.size()) {\n+\t\t\t\tendOperatorInputForOutput();\n+\t\t\t}\n+\t\t} else {\n+\t\t\t// some batch operators do not extend from BoundedOneInput, such as BatchCalc\n+\t\t\tendOperatorInputForOutput();\n+\t\t}\n+\t}\n+\n+\tprivate void endOperatorInputForOutput() throws Exception {", "originalCommit": "21c8f136608b0ce47d5bdf3a4b6e27654f90b872", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODk5MjA2Mw==", "url": "https://github.com/apache/flink/pull/13707#discussion_r508992063", "bodyText": "really -> real", "author": "tsreaper", "createdAt": "2020-10-21T05:06:12Z", "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/multipleinput/TableOperatorWrapperGenerator.java", "diffHunk": "@@ -0,0 +1,342 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.operators.multipleinput;\n+\n+import org.apache.flink.api.common.operators.ResourceSpec;\n+import org.apache.flink.api.dag.Transformation;\n+import org.apache.flink.core.memory.ManagedMemoryUseCase;\n+import org.apache.flink.streaming.api.operators.MultipleInputStreamOperator;\n+import org.apache.flink.streaming.api.operators.SimpleOperatorFactory;\n+import org.apache.flink.streaming.api.transformations.OneInputTransformation;\n+import org.apache.flink.streaming.api.transformations.TwoInputTransformation;\n+import org.apache.flink.streaming.api.transformations.UnionTransformation;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.runtime.operators.multipleinput.input.InputSpec;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.IdentityHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * A generator that generates a {@link TableOperatorWrapper} graph from a graph of {@link Transformation}.\n+ */\n+public class TableOperatorWrapperGenerator {\n+\n+\t/**\n+\t * Original input transformations for {@link MultipleInputStreamOperator}.\n+\t */\n+\tprivate final List<Transformation<?>> inputTransforms;\n+\n+\t/**\n+\t * The tail (root) transformation of the transformation-graph in {@link MultipleInputStreamOperator}.\n+\t */\n+\tprivate final Transformation<?> tailTransform;\n+\n+\t/**\n+\t * The read order corresponding to each transformation in {@link #inputTransforms}.\n+\t */\n+\tprivate final int[] readOrders;\n+\n+\t/**\n+\t * Reordered input transformations which order corresponds to the order of {@link #inputSpecs}.\n+\t */\n+\tprivate final List<Transformation<?>> orderedInputTransforms;\n+\n+\t/**\n+\t * The input specs which order corresponds to the order of {@link #orderedInputTransforms}.\n+\t */\n+\tprivate final List<InputSpec> inputSpecs;\n+\n+\t/**\n+\t * The head (leaf) operator wrappers of the operator-graph in {@link MultipleInputStreamOperator}.\n+\t */\n+\tprivate final List<TableOperatorWrapper<?>> headWrappers;\n+\n+\t/**\n+\t * The tail (root) operator wrapper of the operator-graph in {@link MultipleInputStreamOperator}.\n+\t */\n+\tprivate TableOperatorWrapper<?> tailWrapper;\n+\n+\t/**\n+\t * Map the visited transformation to its generated TableOperatorWrapper.\n+\t */\n+\tprivate final Map<Transformation<?>, TableOperatorWrapper<?>> visitedTransforms;\n+\t/**\n+\t * The identifier for each sub operator in {@link MultipleInputStreamOperator}.\n+\t */\n+\tprivate int identifierOfSubOp = 0;\n+\n+\tprivate int parallelism;\n+\tprivate int maxParallelism;\n+\tprivate ResourceSpec minResources;\n+\tprivate ResourceSpec preferredResources;\n+\t/**\n+\t * managed memory weight for batch operator.\n+\t */\n+\tprivate int managedMemoryWeight;\n+\n+\tpublic TableOperatorWrapperGenerator(\n+\t\t\tList<Transformation<?>> inputTransforms,\n+\t\t\tTransformation<?> tailTransform) {\n+\t\tthis(inputTransforms, tailTransform, new int[inputTransforms.size()]);\n+\t}\n+\n+\tpublic TableOperatorWrapperGenerator(\n+\t\t\tList<Transformation<?>> inputTransforms,\n+\t\t\tTransformation<?> tailTransform,\n+\t\t\tint[] readOrders) {\n+\t\tthis.inputTransforms = inputTransforms;\n+\t\tthis.tailTransform = tailTransform;\n+\t\tthis.readOrders = readOrders;\n+\t\tthis.inputSpecs = new ArrayList<>();\n+\t\tthis.headWrappers = new ArrayList<>();\n+\t\tthis.orderedInputTransforms = new ArrayList<>();\n+\t\tthis.visitedTransforms = new IdentityHashMap<>();\n+\n+\t\tthis.parallelism = -1;\n+\t\tthis.maxParallelism = -1;\n+\t}\n+\n+\tpublic void generate() {\n+\t\ttailWrapper = visit(tailTransform);\n+\t\tcheckState(orderedInputTransforms.size() == inputTransforms.size());\n+\t\tcheckState(orderedInputTransforms.size() == inputSpecs.size());\n+\t\tcalculateManagedMemoryFraction();\n+\t}\n+\n+\tpublic List<Transformation<?>> getOrderedInputTransforms() {\n+\t\treturn orderedInputTransforms;\n+\t}\n+\n+\tpublic List<InputSpec> getInputSpecs() {\n+\t\treturn inputSpecs;\n+\t}\n+\n+\tpublic List<TableOperatorWrapper<?>> getHeadWrappers() {\n+\t\treturn headWrappers;\n+\t}\n+\n+\tpublic TableOperatorWrapper<?> getTailWrapper() {\n+\t\treturn tailWrapper;\n+\t}\n+\n+\tpublic int getParallelism() {\n+\t\treturn parallelism;\n+\t}\n+\n+\tpublic int getMaxParallelism() {\n+\t\treturn maxParallelism;\n+\t}\n+\n+\tpublic ResourceSpec getMinResources() {\n+\t\treturn minResources;\n+\t}\n+\n+\tpublic ResourceSpec getPreferredResources() {\n+\t\treturn preferredResources;\n+\t}\n+\n+\tpublic int getManagedMemoryWeight() {\n+\t\treturn managedMemoryWeight;\n+\t}\n+\n+\tprivate TableOperatorWrapper<?> visit(Transformation<?> transform) {\n+\t\t// ignore UnionTransformation because it's not a really operator", "originalCommit": "21c8f136608b0ce47d5bdf3a4b6e27654f90b872", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODk5MjE2OA==", "url": "https://github.com/apache/flink/pull/13707#discussion_r508992168", "bodyText": "connects -> connecting", "author": "tsreaper", "createdAt": "2020-10-21T05:06:39Z", "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/multipleinput/TableOperatorWrapper.java", "diffHunk": "@@ -0,0 +1,273 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.operators.multipleinput;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.streaming.api.operators.BoundedMultiInput;\n+import org.apache.flink.streaming.api.operators.BoundedOneInput;\n+import org.apache.flink.streaming.api.operators.StreamOperator;\n+import org.apache.flink.streaming.api.operators.StreamOperatorFactory;\n+import org.apache.flink.streaming.api.operators.StreamOperatorParameters;\n+import org.apache.flink.streaming.runtime.tasks.ProcessingTimeServiceAware;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.util.Preconditions;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.flink.util.Preconditions.checkArgument;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+\n+/**\n+ * This class handles the close, endInput and other related logic of a {@link StreamOperator}.\n+ * It also automatically propagates the end-input operation to the next wrapper that\n+ * the {@link #outputEdges} points to, so we only need to call the head wrapper's\n+ * {@link #endOperatorInput(int)} method.\n+ */\n+public class TableOperatorWrapper<OP extends StreamOperator<RowData>> implements Serializable {\n+\tprivate static final long serialVersionUID = 1L;\n+\n+\t/**\n+\t * The factory to create the wrapped operator.\n+\t */\n+\tprivate final StreamOperatorFactory<RowData> factory;\n+\n+\t/**\n+\t * the operator name for debugging.\n+\t */\n+\tprivate final String operatorName;\n+\n+\t/**\n+\t * The type info of this wrapped operator's all inputs.\n+\t *\n+\t * <p>NOTE:The inputs of an operator may not all be in the multiple-input operator, e.g.\n+\t * The multiple-input operator contains A and J, and A is one of the input of J,\n+\t * and another input of J is not in the multiple-input operator.\n+\t * <pre>\n+\t * -------\n+\t *        \\\n+\t *         J --\n+\t *        /\n+\t * -- A --\n+\t * </pre>\n+\t * For this example, `allInputTypes` contains two input types.\n+\t */\n+\tprivate final List<TypeInformation<?>> allInputTypes;\n+\n+\t/**\n+\t * The type info of this wrapped operator's output.\n+\t */\n+\tprivate final TypeInformation<?> outputType;\n+\n+\t/**\n+\t * Managed memory fraction in the multiple-input operator.\n+\t */\n+\tprivate double managedMemoryFraction = -1;\n+\n+\t/**\n+\t * The input edges of this operator wrapper, the edges' target is current instance.\n+\t */\n+\tprivate final List<Edge> inputEdges;\n+\n+\t/**\n+\t * The output edges of this operator wrapper, the edges' source is current instance.\n+\t */\n+\tprivate final List<Edge> outputEdges;\n+\n+\t/**\n+\t * The wrapped operator, which will be generated by {@link #factory}.\n+\t */\n+\tprivate transient OP wrapped;\n+\n+\tprivate boolean closed;\n+\tprivate int endedInputCount;\n+\n+\tpublic TableOperatorWrapper(\n+\t\t\tStreamOperatorFactory<RowData> factory,\n+\t\t\tString operatorName,\n+\t\t\tList<TypeInformation<?>> allInputTypes,\n+\t\t\tTypeInformation<?> outputType) {\n+\t\tthis.factory = checkNotNull(factory);\n+\t\tthis.operatorName = checkNotNull(operatorName);\n+\t\tthis.outputType = checkNotNull(outputType);\n+\t\tthis.allInputTypes = checkNotNull(allInputTypes);\n+\n+\t\tthis.inputEdges = new ArrayList<>();\n+\t\tthis.outputEdges = new ArrayList<>();\n+\n+\t\tthis.endedInputCount = 0;\n+\t}\n+\n+\tpublic void createOperator(StreamOperatorParameters<RowData> parameters) {\n+\t\tcheckArgument(wrapped == null, \"This operator has been initialized\");\n+\t\tif (factory instanceof ProcessingTimeServiceAware) {\n+\t\t\t((ProcessingTimeServiceAware) factory)\n+\t\t\t\t\t.setProcessingTimeService(parameters.getProcessingTimeService());\n+\t\t}\n+\t\twrapped = factory.createStreamOperator(parameters);\n+\t}\n+\n+\tpublic void endOperatorInput(int inputId) throws Exception {\n+\t\tendedInputCount++;\n+\t\tif (wrapped instanceof BoundedOneInput) {\n+\t\t\t((BoundedOneInput) wrapped).endInput();\n+\t\t\tendOperatorInputForOutput();\n+\t\t} else if (wrapped instanceof BoundedMultiInput) {\n+\t\t\t((BoundedMultiInput) wrapped).endInput(inputId);\n+\t\t\tif (endedInputCount >= allInputTypes.size()) {\n+\t\t\t\tendOperatorInputForOutput();\n+\t\t\t}\n+\t\t} else {\n+\t\t\t// some batch operators do not extend from BoundedOneInput, such as BatchCalc\n+\t\t\tendOperatorInputForOutput();\n+\t\t}\n+\t}\n+\n+\tprivate void endOperatorInputForOutput() throws Exception {\n+\t\tfor (Edge edge : outputEdges) {\n+\t\t\tedge.target.endOperatorInput(edge.inputId);\n+\t\t}\n+\t}\n+\n+\tpublic OP getStreamOperator() {\n+\t\treturn checkNotNull(wrapped);\n+\t}\n+\n+\tpublic List<TypeInformation<?>> getAllInputTypes() {\n+\t\treturn allInputTypes;\n+\t}\n+\n+\tpublic TypeInformation<?> getOutputType() {\n+\t\treturn outputType;\n+\t}\n+\n+\tpublic void addInput(\n+\t\t\tTableOperatorWrapper<?> input,\n+\t\t\tint inputId) {\n+\t\tPreconditions.checkArgument(inputId > 0 && inputId <= getAllInputTypes().size());\n+\t\tEdge edge = new Edge(input, this, inputId);\n+\t\tthis.inputEdges.add(edge);\n+\t\tinput.outputEdges.add(edge);\n+\t}\n+\n+\tpublic void setManagedMemoryFraction(double managedMemoryFraction) {\n+\t\tthis.managedMemoryFraction = managedMemoryFraction;\n+\t}\n+\n+\tpublic double getManagedMemoryFraction() {\n+\t\treturn managedMemoryFraction;\n+\t}\n+\n+\tpublic List<Edge> getInputEdges() {\n+\t\treturn inputEdges;\n+\t}\n+\n+\tpublic List<TableOperatorWrapper<?>> getInputWrappers() {\n+\t\treturn inputEdges.stream().map(Edge::getSource).collect(Collectors.toList());\n+\t}\n+\n+\tpublic List<Edge> getOutputEdges() {\n+\t\treturn outputEdges;\n+\t}\n+\n+\tpublic List<TableOperatorWrapper<?>> getOutputWrappers() {\n+\t\treturn outputEdges.stream().map(Edge::getTarget).collect(Collectors.toList());\n+\t}\n+\n+\t/**\n+\t * Checks if the wrapped operator has been closed.\n+\t *\n+\t * <p>Note that this method must be called in the task thread.\n+\t */\n+\tpublic boolean isClosed() {\n+\t\treturn closed;\n+\t}\n+\n+\tpublic void close() throws Exception {\n+\t\tif (isClosed()) {\n+\t\t\treturn;\n+\t\t}\n+\t\tclosed = true;\n+\t\twrapped.close();\n+\t}\n+\n+\tpublic String getOperatorName() {\n+\t\treturn operatorName;\n+\t}\n+\n+\t@VisibleForTesting\n+\tpublic int getEndedInputCount() {\n+\t\treturn endedInputCount;\n+\t}\n+\n+\t@Override\n+\tpublic String toString() {\n+\t\treturn operatorName;\n+\t}\n+\n+\t/**\n+\t * The edge connects two {@link TableOperatorWrapper}s.", "originalCommit": "21c8f136608b0ce47d5bdf3a4b6e27654f90b872", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODk5MjU0Mg==", "url": "https://github.com/apache/flink/pull/13707#discussion_r508992542", "bodyText": "wrapper = visitedTransforms.computeIfAbsent(transform, t -> visitTransformation(t))", "author": "tsreaper", "createdAt": "2020-10-21T05:08:08Z", "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/multipleinput/TableOperatorWrapperGenerator.java", "diffHunk": "@@ -0,0 +1,342 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.operators.multipleinput;\n+\n+import org.apache.flink.api.common.operators.ResourceSpec;\n+import org.apache.flink.api.dag.Transformation;\n+import org.apache.flink.core.memory.ManagedMemoryUseCase;\n+import org.apache.flink.streaming.api.operators.MultipleInputStreamOperator;\n+import org.apache.flink.streaming.api.operators.SimpleOperatorFactory;\n+import org.apache.flink.streaming.api.transformations.OneInputTransformation;\n+import org.apache.flink.streaming.api.transformations.TwoInputTransformation;\n+import org.apache.flink.streaming.api.transformations.UnionTransformation;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.runtime.operators.multipleinput.input.InputSpec;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.IdentityHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * A generator that generates a {@link TableOperatorWrapper} graph from a graph of {@link Transformation}.\n+ */\n+public class TableOperatorWrapperGenerator {\n+\n+\t/**\n+\t * Original input transformations for {@link MultipleInputStreamOperator}.\n+\t */\n+\tprivate final List<Transformation<?>> inputTransforms;\n+\n+\t/**\n+\t * The tail (root) transformation of the transformation-graph in {@link MultipleInputStreamOperator}.\n+\t */\n+\tprivate final Transformation<?> tailTransform;\n+\n+\t/**\n+\t * The read order corresponding to each transformation in {@link #inputTransforms}.\n+\t */\n+\tprivate final int[] readOrders;\n+\n+\t/**\n+\t * Reordered input transformations which order corresponds to the order of {@link #inputSpecs}.\n+\t */\n+\tprivate final List<Transformation<?>> orderedInputTransforms;\n+\n+\t/**\n+\t * The input specs which order corresponds to the order of {@link #orderedInputTransforms}.\n+\t */\n+\tprivate final List<InputSpec> inputSpecs;\n+\n+\t/**\n+\t * The head (leaf) operator wrappers of the operator-graph in {@link MultipleInputStreamOperator}.\n+\t */\n+\tprivate final List<TableOperatorWrapper<?>> headWrappers;\n+\n+\t/**\n+\t * The tail (root) operator wrapper of the operator-graph in {@link MultipleInputStreamOperator}.\n+\t */\n+\tprivate TableOperatorWrapper<?> tailWrapper;\n+\n+\t/**\n+\t * Map the visited transformation to its generated TableOperatorWrapper.\n+\t */\n+\tprivate final Map<Transformation<?>, TableOperatorWrapper<?>> visitedTransforms;\n+\t/**\n+\t * The identifier for each sub operator in {@link MultipleInputStreamOperator}.\n+\t */\n+\tprivate int identifierOfSubOp = 0;\n+\n+\tprivate int parallelism;\n+\tprivate int maxParallelism;\n+\tprivate ResourceSpec minResources;\n+\tprivate ResourceSpec preferredResources;\n+\t/**\n+\t * managed memory weight for batch operator.\n+\t */\n+\tprivate int managedMemoryWeight;\n+\n+\tpublic TableOperatorWrapperGenerator(\n+\t\t\tList<Transformation<?>> inputTransforms,\n+\t\t\tTransformation<?> tailTransform) {\n+\t\tthis(inputTransforms, tailTransform, new int[inputTransforms.size()]);\n+\t}\n+\n+\tpublic TableOperatorWrapperGenerator(\n+\t\t\tList<Transformation<?>> inputTransforms,\n+\t\t\tTransformation<?> tailTransform,\n+\t\t\tint[] readOrders) {\n+\t\tthis.inputTransforms = inputTransforms;\n+\t\tthis.tailTransform = tailTransform;\n+\t\tthis.readOrders = readOrders;\n+\t\tthis.inputSpecs = new ArrayList<>();\n+\t\tthis.headWrappers = new ArrayList<>();\n+\t\tthis.orderedInputTransforms = new ArrayList<>();\n+\t\tthis.visitedTransforms = new IdentityHashMap<>();\n+\n+\t\tthis.parallelism = -1;\n+\t\tthis.maxParallelism = -1;\n+\t}\n+\n+\tpublic void generate() {\n+\t\ttailWrapper = visit(tailTransform);\n+\t\tcheckState(orderedInputTransforms.size() == inputTransforms.size());\n+\t\tcheckState(orderedInputTransforms.size() == inputSpecs.size());\n+\t\tcalculateManagedMemoryFraction();\n+\t}\n+\n+\tpublic List<Transformation<?>> getOrderedInputTransforms() {\n+\t\treturn orderedInputTransforms;\n+\t}\n+\n+\tpublic List<InputSpec> getInputSpecs() {\n+\t\treturn inputSpecs;\n+\t}\n+\n+\tpublic List<TableOperatorWrapper<?>> getHeadWrappers() {\n+\t\treturn headWrappers;\n+\t}\n+\n+\tpublic TableOperatorWrapper<?> getTailWrapper() {\n+\t\treturn tailWrapper;\n+\t}\n+\n+\tpublic int getParallelism() {\n+\t\treturn parallelism;\n+\t}\n+\n+\tpublic int getMaxParallelism() {\n+\t\treturn maxParallelism;\n+\t}\n+\n+\tpublic ResourceSpec getMinResources() {\n+\t\treturn minResources;\n+\t}\n+\n+\tpublic ResourceSpec getPreferredResources() {\n+\t\treturn preferredResources;\n+\t}\n+\n+\tpublic int getManagedMemoryWeight() {\n+\t\treturn managedMemoryWeight;\n+\t}\n+\n+\tprivate TableOperatorWrapper<?> visit(Transformation<?> transform) {\n+\t\t// ignore UnionTransformation because it's not a really operator\n+\t\tif (!(transform instanceof UnionTransformation)) {\n+\t\t\tcalcParallelismAndResource(transform);\n+\t\t}\n+\n+\t\tfinal TableOperatorWrapper<?> wrapper;\n+\t\tif (visitedTransforms.containsKey(transform)) {\n+\t\t\twrapper = visitedTransforms.get(transform);\n+\t\t} else {\n+\t\t\twrapper = visitTransformation(transform);\n+\t\t\tvisitedTransforms.put(transform, wrapper);\n+\t\t}", "originalCommit": "21c8f136608b0ce47d5bdf3a4b6e27654f90b872", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTAwMDYxMw==", "url": "https://github.com/apache/flink/pull/13707#discussion_r509000613", "bodyText": "Consider the following case:\nsource1 (100 parallelism) -> calc -\\\n                                     -> union -> join -> ...\nsource2 (50 parallelism)  -> calc -/\n\nIf both source1 and 2 are chainable, both calc will be merged into the multiple input node. However their parallelism are different. Multiple input creation algorithm handles ExecNode which has no information about parallelism, so this problem cannot be avoid by that algorithm.\nWhat I would suggest is to set the parallelism to the maximum parallelism of the members.", "author": "tsreaper", "createdAt": "2020-10-21T05:35:36Z", "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/multipleinput/TableOperatorWrapperGenerator.java", "diffHunk": "@@ -0,0 +1,342 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.operators.multipleinput;\n+\n+import org.apache.flink.api.common.operators.ResourceSpec;\n+import org.apache.flink.api.dag.Transformation;\n+import org.apache.flink.core.memory.ManagedMemoryUseCase;\n+import org.apache.flink.streaming.api.operators.MultipleInputStreamOperator;\n+import org.apache.flink.streaming.api.operators.SimpleOperatorFactory;\n+import org.apache.flink.streaming.api.transformations.OneInputTransformation;\n+import org.apache.flink.streaming.api.transformations.TwoInputTransformation;\n+import org.apache.flink.streaming.api.transformations.UnionTransformation;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.runtime.operators.multipleinput.input.InputSpec;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.IdentityHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * A generator that generates a {@link TableOperatorWrapper} graph from a graph of {@link Transformation}.\n+ */\n+public class TableOperatorWrapperGenerator {\n+\n+\t/**\n+\t * Original input transformations for {@link MultipleInputStreamOperator}.\n+\t */\n+\tprivate final List<Transformation<?>> inputTransforms;\n+\n+\t/**\n+\t * The tail (root) transformation of the transformation-graph in {@link MultipleInputStreamOperator}.\n+\t */\n+\tprivate final Transformation<?> tailTransform;\n+\n+\t/**\n+\t * The read order corresponding to each transformation in {@link #inputTransforms}.\n+\t */\n+\tprivate final int[] readOrders;\n+\n+\t/**\n+\t * Reordered input transformations which order corresponds to the order of {@link #inputSpecs}.\n+\t */\n+\tprivate final List<Transformation<?>> orderedInputTransforms;\n+\n+\t/**\n+\t * The input specs which order corresponds to the order of {@link #orderedInputTransforms}.\n+\t */\n+\tprivate final List<InputSpec> inputSpecs;\n+\n+\t/**\n+\t * The head (leaf) operator wrappers of the operator-graph in {@link MultipleInputStreamOperator}.\n+\t */\n+\tprivate final List<TableOperatorWrapper<?>> headWrappers;\n+\n+\t/**\n+\t * The tail (root) operator wrapper of the operator-graph in {@link MultipleInputStreamOperator}.\n+\t */\n+\tprivate TableOperatorWrapper<?> tailWrapper;\n+\n+\t/**\n+\t * Map the visited transformation to its generated TableOperatorWrapper.\n+\t */\n+\tprivate final Map<Transformation<?>, TableOperatorWrapper<?>> visitedTransforms;\n+\t/**\n+\t * The identifier for each sub operator in {@link MultipleInputStreamOperator}.\n+\t */\n+\tprivate int identifierOfSubOp = 0;\n+\n+\tprivate int parallelism;\n+\tprivate int maxParallelism;\n+\tprivate ResourceSpec minResources;\n+\tprivate ResourceSpec preferredResources;\n+\t/**\n+\t * managed memory weight for batch operator.\n+\t */\n+\tprivate int managedMemoryWeight;\n+\n+\tpublic TableOperatorWrapperGenerator(\n+\t\t\tList<Transformation<?>> inputTransforms,\n+\t\t\tTransformation<?> tailTransform) {\n+\t\tthis(inputTransforms, tailTransform, new int[inputTransforms.size()]);\n+\t}\n+\n+\tpublic TableOperatorWrapperGenerator(\n+\t\t\tList<Transformation<?>> inputTransforms,\n+\t\t\tTransformation<?> tailTransform,\n+\t\t\tint[] readOrders) {\n+\t\tthis.inputTransforms = inputTransforms;\n+\t\tthis.tailTransform = tailTransform;\n+\t\tthis.readOrders = readOrders;\n+\t\tthis.inputSpecs = new ArrayList<>();\n+\t\tthis.headWrappers = new ArrayList<>();\n+\t\tthis.orderedInputTransforms = new ArrayList<>();\n+\t\tthis.visitedTransforms = new IdentityHashMap<>();\n+\n+\t\tthis.parallelism = -1;\n+\t\tthis.maxParallelism = -1;\n+\t}\n+\n+\tpublic void generate() {\n+\t\ttailWrapper = visit(tailTransform);\n+\t\tcheckState(orderedInputTransforms.size() == inputTransforms.size());\n+\t\tcheckState(orderedInputTransforms.size() == inputSpecs.size());\n+\t\tcalculateManagedMemoryFraction();\n+\t}\n+\n+\tpublic List<Transformation<?>> getOrderedInputTransforms() {\n+\t\treturn orderedInputTransforms;\n+\t}\n+\n+\tpublic List<InputSpec> getInputSpecs() {\n+\t\treturn inputSpecs;\n+\t}\n+\n+\tpublic List<TableOperatorWrapper<?>> getHeadWrappers() {\n+\t\treturn headWrappers;\n+\t}\n+\n+\tpublic TableOperatorWrapper<?> getTailWrapper() {\n+\t\treturn tailWrapper;\n+\t}\n+\n+\tpublic int getParallelism() {\n+\t\treturn parallelism;\n+\t}\n+\n+\tpublic int getMaxParallelism() {\n+\t\treturn maxParallelism;\n+\t}\n+\n+\tpublic ResourceSpec getMinResources() {\n+\t\treturn minResources;\n+\t}\n+\n+\tpublic ResourceSpec getPreferredResources() {\n+\t\treturn preferredResources;\n+\t}\n+\n+\tpublic int getManagedMemoryWeight() {\n+\t\treturn managedMemoryWeight;\n+\t}\n+\n+\tprivate TableOperatorWrapper<?> visit(Transformation<?> transform) {\n+\t\t// ignore UnionTransformation because it's not a really operator\n+\t\tif (!(transform instanceof UnionTransformation)) {\n+\t\t\tcalcParallelismAndResource(transform);\n+\t\t}\n+\n+\t\tfinal TableOperatorWrapper<?> wrapper;\n+\t\tif (visitedTransforms.containsKey(transform)) {\n+\t\t\twrapper = visitedTransforms.get(transform);\n+\t\t} else {\n+\t\t\twrapper = visitTransformation(transform);\n+\t\t\tvisitedTransforms.put(transform, wrapper);\n+\t\t}\n+\t\treturn wrapper;\n+\t}\n+\n+\tprivate void calcParallelismAndResource(Transformation<?> transform) {\n+\t\tint currentParallelism = transform.getParallelism();\n+\t\tif (parallelism < 0) {\n+\t\t\tparallelism = currentParallelism;\n+\t\t} else {\n+\t\t\tcheckState(\n+\t\t\t\t\tcurrentParallelism < 0 || parallelism == currentParallelism,\n+\t\t\t\t\t\"Parallelism of a transformation in MultipleInputNode is different from others. This is a bug.\");", "originalCommit": "21c8f136608b0ce47d5bdf3a4b6e27654f90b872", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTE0MjIzOA==", "url": "https://github.com/apache/flink/pull/13707#discussion_r509142238", "bodyText": "good catch, set the parallelism to the maximum parallelism of the members looks good to me. but we should add more strict validation for the plan when constructing multiple input node.", "author": "godfreyhe", "createdAt": "2020-10-21T09:47:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTAwMDYxMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTAwMjExNQ==", "url": "https://github.com/apache/flink/pull/13707#discussion_r509002115", "bodyText": "extract into a function", "author": "tsreaper", "createdAt": "2020-10-21T05:40:24Z", "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/multipleinput/TableOperatorWrapperGenerator.java", "diffHunk": "@@ -0,0 +1,342 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.operators.multipleinput;\n+\n+import org.apache.flink.api.common.operators.ResourceSpec;\n+import org.apache.flink.api.dag.Transformation;\n+import org.apache.flink.core.memory.ManagedMemoryUseCase;\n+import org.apache.flink.streaming.api.operators.MultipleInputStreamOperator;\n+import org.apache.flink.streaming.api.operators.SimpleOperatorFactory;\n+import org.apache.flink.streaming.api.transformations.OneInputTransformation;\n+import org.apache.flink.streaming.api.transformations.TwoInputTransformation;\n+import org.apache.flink.streaming.api.transformations.UnionTransformation;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.runtime.operators.multipleinput.input.InputSpec;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.IdentityHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * A generator that generates a {@link TableOperatorWrapper} graph from a graph of {@link Transformation}.\n+ */\n+public class TableOperatorWrapperGenerator {\n+\n+\t/**\n+\t * Original input transformations for {@link MultipleInputStreamOperator}.\n+\t */\n+\tprivate final List<Transformation<?>> inputTransforms;\n+\n+\t/**\n+\t * The tail (root) transformation of the transformation-graph in {@link MultipleInputStreamOperator}.\n+\t */\n+\tprivate final Transformation<?> tailTransform;\n+\n+\t/**\n+\t * The read order corresponding to each transformation in {@link #inputTransforms}.\n+\t */\n+\tprivate final int[] readOrders;\n+\n+\t/**\n+\t * Reordered input transformations which order corresponds to the order of {@link #inputSpecs}.\n+\t */\n+\tprivate final List<Transformation<?>> orderedInputTransforms;\n+\n+\t/**\n+\t * The input specs which order corresponds to the order of {@link #orderedInputTransforms}.\n+\t */\n+\tprivate final List<InputSpec> inputSpecs;\n+\n+\t/**\n+\t * The head (leaf) operator wrappers of the operator-graph in {@link MultipleInputStreamOperator}.\n+\t */\n+\tprivate final List<TableOperatorWrapper<?>> headWrappers;\n+\n+\t/**\n+\t * The tail (root) operator wrapper of the operator-graph in {@link MultipleInputStreamOperator}.\n+\t */\n+\tprivate TableOperatorWrapper<?> tailWrapper;\n+\n+\t/**\n+\t * Map the visited transformation to its generated TableOperatorWrapper.\n+\t */\n+\tprivate final Map<Transformation<?>, TableOperatorWrapper<?>> visitedTransforms;\n+\t/**\n+\t * The identifier for each sub operator in {@link MultipleInputStreamOperator}.\n+\t */\n+\tprivate int identifierOfSubOp = 0;\n+\n+\tprivate int parallelism;\n+\tprivate int maxParallelism;\n+\tprivate ResourceSpec minResources;\n+\tprivate ResourceSpec preferredResources;\n+\t/**\n+\t * managed memory weight for batch operator.\n+\t */\n+\tprivate int managedMemoryWeight;\n+\n+\tpublic TableOperatorWrapperGenerator(\n+\t\t\tList<Transformation<?>> inputTransforms,\n+\t\t\tTransformation<?> tailTransform) {\n+\t\tthis(inputTransforms, tailTransform, new int[inputTransforms.size()]);\n+\t}\n+\n+\tpublic TableOperatorWrapperGenerator(\n+\t\t\tList<Transformation<?>> inputTransforms,\n+\t\t\tTransformation<?> tailTransform,\n+\t\t\tint[] readOrders) {\n+\t\tthis.inputTransforms = inputTransforms;\n+\t\tthis.tailTransform = tailTransform;\n+\t\tthis.readOrders = readOrders;\n+\t\tthis.inputSpecs = new ArrayList<>();\n+\t\tthis.headWrappers = new ArrayList<>();\n+\t\tthis.orderedInputTransforms = new ArrayList<>();\n+\t\tthis.visitedTransforms = new IdentityHashMap<>();\n+\n+\t\tthis.parallelism = -1;\n+\t\tthis.maxParallelism = -1;\n+\t}\n+\n+\tpublic void generate() {\n+\t\ttailWrapper = visit(tailTransform);\n+\t\tcheckState(orderedInputTransforms.size() == inputTransforms.size());\n+\t\tcheckState(orderedInputTransforms.size() == inputSpecs.size());\n+\t\tcalculateManagedMemoryFraction();\n+\t}\n+\n+\tpublic List<Transformation<?>> getOrderedInputTransforms() {\n+\t\treturn orderedInputTransforms;\n+\t}\n+\n+\tpublic List<InputSpec> getInputSpecs() {\n+\t\treturn inputSpecs;\n+\t}\n+\n+\tpublic List<TableOperatorWrapper<?>> getHeadWrappers() {\n+\t\treturn headWrappers;\n+\t}\n+\n+\tpublic TableOperatorWrapper<?> getTailWrapper() {\n+\t\treturn tailWrapper;\n+\t}\n+\n+\tpublic int getParallelism() {\n+\t\treturn parallelism;\n+\t}\n+\n+\tpublic int getMaxParallelism() {\n+\t\treturn maxParallelism;\n+\t}\n+\n+\tpublic ResourceSpec getMinResources() {\n+\t\treturn minResources;\n+\t}\n+\n+\tpublic ResourceSpec getPreferredResources() {\n+\t\treturn preferredResources;\n+\t}\n+\n+\tpublic int getManagedMemoryWeight() {\n+\t\treturn managedMemoryWeight;\n+\t}\n+\n+\tprivate TableOperatorWrapper<?> visit(Transformation<?> transform) {\n+\t\t// ignore UnionTransformation because it's not a really operator\n+\t\tif (!(transform instanceof UnionTransformation)) {\n+\t\t\tcalcParallelismAndResource(transform);\n+\t\t}\n+\n+\t\tfinal TableOperatorWrapper<?> wrapper;\n+\t\tif (visitedTransforms.containsKey(transform)) {\n+\t\t\twrapper = visitedTransforms.get(transform);\n+\t\t} else {\n+\t\t\twrapper = visitTransformation(transform);\n+\t\t\tvisitedTransforms.put(transform, wrapper);\n+\t\t}\n+\t\treturn wrapper;\n+\t}\n+\n+\tprivate void calcParallelismAndResource(Transformation<?> transform) {\n+\t\tint currentParallelism = transform.getParallelism();\n+\t\tif (parallelism < 0) {\n+\t\t\tparallelism = currentParallelism;\n+\t\t} else {\n+\t\t\tcheckState(\n+\t\t\t\t\tcurrentParallelism < 0 || parallelism == currentParallelism,\n+\t\t\t\t\t\"Parallelism of a transformation in MultipleInputNode is different from others. This is a bug.\");\n+\t\t}\n+\n+\t\tint currentMaxParallelism = transform.getMaxParallelism();\n+\t\tif (maxParallelism < 0) {\n+\t\t\tmaxParallelism = currentMaxParallelism;\n+\t\t} else {\n+\t\t\tcheckState(\n+\t\t\t\t\tcurrentMaxParallelism < 0 || maxParallelism == currentMaxParallelism,\n+\t\t\t\t\t\"Max parallelism of a transformation in MultipleInputNode is different from others. This is a bug.\");\n+\t\t}\n+\n+\t\tif (minResources == null) {\n+\t\t\tminResources = transform.getMinResources();\n+\t\t\tpreferredResources = transform.getPreferredResources();\n+\t\t\tmanagedMemoryWeight = transform.getManagedMemoryOperatorScopeUseCaseWeights()\n+\t\t\t\t\t.getOrDefault(ManagedMemoryUseCase.BATCH_OP, 0);\n+\t\t} else {\n+\t\t\tminResources = minResources.merge(transform.getMinResources());\n+\t\t\tpreferredResources = preferredResources.merge(transform.getPreferredResources());\n+\t\t\tmanagedMemoryWeight += transform.getManagedMemoryOperatorScopeUseCaseWeights()\n+\t\t\t\t\t.getOrDefault(ManagedMemoryUseCase.BATCH_OP, 0);\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+\tprivate TableOperatorWrapper<?> visitTransformation(Transformation<?> transform) {\n+\t\tif (transform instanceof OneInputTransformation) {\n+\t\t\treturn visitOneInputTransformation((OneInputTransformation) transform);\n+\t\t} else if (transform instanceof TwoInputTransformation) {\n+\t\t\treturn visitTwoInputTransformation((TwoInputTransformation) transform);\n+\t\t} else  if (transform instanceof UnionTransformation) {\n+\t\t\treturn visitUnionTransformation((UnionTransformation) transform);\n+\t\t} else  {\n+\t\t\tthrow new RuntimeException(\"Unsupported Transformation: \" + transform);\n+\t\t}\n+\t}\n+\n+\tprivate TableOperatorWrapper<?> visitOneInputTransformation(\n+\t\t\tOneInputTransformation<RowData, RowData> transform) {\n+\t\tTransformation<?> input = transform.getInputs().get(0);\n+\n+\t\tTableOperatorWrapper<?> wrapper = new TableOperatorWrapper<>(\n+\t\t\t\ttransform.getOperatorFactory(),\n+\t\t\t\tgenSubOperatorName(transform),\n+\t\t\t\tCollections.singletonList(transform.getInputType()),\n+\t\t\t\ttransform.getOutputType()\n+\t\t);\n+\n+\t\tint inputIdx = inputTransforms.indexOf(input);\n+\t\tif (inputIdx >= 0) {\n+\t\t\torderedInputTransforms.add(input);\n+\t\t\tinputSpecs.add(createInputSpec(readOrders[inputIdx], wrapper, 1));\n+\t\t\theadWrappers.add(wrapper);\n+\t\t} else {\n+\t\t\tTableOperatorWrapper<?> inputWrapper = visit(input);\n+\t\t\twrapper.addInput(inputWrapper, 1);\n+\t\t}\n+\t\treturn wrapper;\n+\t}\n+\n+\tprivate TableOperatorWrapper<?> visitTwoInputTransformation(\n+\t\t\tTwoInputTransformation<RowData, RowData, RowData> transform) {\n+\t\tTransformation<?> input1 = transform.getInput1();\n+\t\tTransformation<?> input2 = transform.getInput2();\n+\t\tint inputIdx1 = inputTransforms.indexOf(input1);\n+\t\tint inputIdx2 = inputTransforms.indexOf(input2);\n+\n+\t\tTableOperatorWrapper<?> wrapper = new TableOperatorWrapper<>(\n+\t\t\t\ttransform.getOperatorFactory(),\n+\t\t\t\tgenSubOperatorName(transform),\n+\t\t\t\tArrays.asList(transform.getInputType1(), transform.getInputType2()),\n+\t\t\t\ttransform.getOutputType());\n+\n+\t\tif (inputIdx1 >= 0 && inputIdx2 >= 0) {\n+\t\t\torderedInputTransforms.add(input1);\n+\t\t\tinputSpecs.add(createInputSpec(readOrders[inputIdx1], wrapper, 1));\n+\t\t\torderedInputTransforms.add(input2);\n+\t\t\tinputSpecs.add(createInputSpec(readOrders[inputIdx2], wrapper, 2));\n+\t\t\theadWrappers.add(wrapper);", "originalCommit": "21c8f136608b0ce47d5bdf3a4b6e27654f90b872", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTAwMjc5MA==", "url": "https://github.com/apache/flink/pull/13707#discussion_r509002790", "bodyText": "Why not merge this into InputSpec to be a transient member?", "author": "tsreaper", "createdAt": "2020-10-21T05:42:32Z", "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/operators/multipleinput/TableOperatorWrapperGenerator.java", "diffHunk": "@@ -0,0 +1,342 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.operators.multipleinput;\n+\n+import org.apache.flink.api.common.operators.ResourceSpec;\n+import org.apache.flink.api.dag.Transformation;\n+import org.apache.flink.core.memory.ManagedMemoryUseCase;\n+import org.apache.flink.streaming.api.operators.MultipleInputStreamOperator;\n+import org.apache.flink.streaming.api.operators.SimpleOperatorFactory;\n+import org.apache.flink.streaming.api.transformations.OneInputTransformation;\n+import org.apache.flink.streaming.api.transformations.TwoInputTransformation;\n+import org.apache.flink.streaming.api.transformations.UnionTransformation;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.runtime.operators.multipleinput.input.InputSpec;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.IdentityHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * A generator that generates a {@link TableOperatorWrapper} graph from a graph of {@link Transformation}.\n+ */\n+public class TableOperatorWrapperGenerator {\n+\n+\t/**\n+\t * Original input transformations for {@link MultipleInputStreamOperator}.\n+\t */\n+\tprivate final List<Transformation<?>> inputTransforms;\n+\n+\t/**\n+\t * The tail (root) transformation of the transformation-graph in {@link MultipleInputStreamOperator}.\n+\t */\n+\tprivate final Transformation<?> tailTransform;\n+\n+\t/**\n+\t * The read order corresponding to each transformation in {@link #inputTransforms}.\n+\t */\n+\tprivate final int[] readOrders;\n+\n+\t/**\n+\t * Reordered input transformations which order corresponds to the order of {@link #inputSpecs}.\n+\t */\n+\tprivate final List<Transformation<?>> orderedInputTransforms;", "originalCommit": "21c8f136608b0ce47d5bdf3a4b6e27654f90b872", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTEwMzk4Ng==", "url": "https://github.com/apache/flink/pull/13707#discussion_r509103986", "bodyText": "we should keep InputSpec clean. we can return List<Pair<Transformation<?>, InputSpec>> instead", "author": "godfreyhe", "createdAt": "2020-10-21T08:51:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTAwMjc5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTAwMzQ0NA==", "url": "https://github.com/apache/flink/pull/13707#discussion_r509003444", "bodyText": "TestOneInputStreamOperator -> TestingOneInputStreamOperator", "author": "tsreaper", "createdAt": "2020-10-21T05:44:34Z", "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/multipleinput/TestOneInputStreamOperator.java", "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.operators.multipleinput;\n+\n+import org.apache.flink.streaming.api.operators.AbstractStreamOperator;\n+import org.apache.flink.streaming.api.operators.BoundedOneInput;\n+import org.apache.flink.streaming.api.operators.OneInputStreamOperator;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.table.data.RowData;\n+\n+/**\n+ * A {@link OneInputStreamOperator} for testing.\n+ */\n+public class TestOneInputStreamOperator extends AbstractStreamOperator<RowData>", "originalCommit": "21c8f136608b0ce47d5bdf3a4b6e27654f90b872", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTAwMzQ4NA==", "url": "https://github.com/apache/flink/pull/13707#discussion_r509003484", "bodyText": "ditto", "author": "tsreaper", "createdAt": "2020-10-21T05:44:43Z", "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/runtime/operators/multipleinput/TestTwoInputStreamOperator.java", "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.operators.multipleinput;\n+\n+import org.apache.flink.streaming.api.operators.AbstractStreamOperator;\n+import org.apache.flink.streaming.api.operators.BoundedMultiInput;\n+import org.apache.flink.streaming.api.operators.TwoInputStreamOperator;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.table.data.RowData;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * A {@link TwoInputStreamOperator} for testing.\n+ */\n+public class TestTwoInputStreamOperator extends AbstractStreamOperator<RowData>", "originalCommit": "21c8f136608b0ce47d5bdf3a4b6e27654f90b872", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "022b84ab6402143d4660e2f2348ea85e08d6649d", "url": "https://github.com/apache/flink/commit/022b84ab6402143d4660e2f2348ea85e08d6649d", "message": "address comments", "committedDate": "2020-10-21T10:39:03Z", "type": "commit"}]}