{"pr_number": 13767, "pr_title": "[FLINK-19787][table-runtime] Migrate Filesystem connector to new table source sink interface", "pr_createdAt": "2020-10-23T10:06:58Z", "pr_url": "https://github.com/apache/flink/pull/13767", "timeline": [{"oid": "7e5bf1cc81043553e2f6df80a6b6412634c80609", "url": "https://github.com/apache/flink/commit/7e5bf1cc81043553e2f6df80a6b6412634c80609", "message": "[FLINK-19787][table-runtime] Migrate Filesystem connector to new table source sink interface", "committedDate": "2020-10-23T10:21:37Z", "type": "forcePushed"}, {"oid": "c532d886b68b7dd265c9056945a3cfc94e8352b7", "url": "https://github.com/apache/flink/commit/c532d886b68b7dd265c9056945a3cfc94e8352b7", "message": "[FLINK-19787][table-runtime] Migrate Filesystem connector to new table source sink interface", "committedDate": "2020-10-24T01:53:17Z", "type": "forcePushed"}, {"oid": "163f5bf1d5d95564d16e44573d0eb3932808a64e", "url": "https://github.com/apache/flink/commit/163f5bf1d5d95564d16e44573d0eb3932808a64e", "message": "[FLINK-19787][table-runtime] Migrate Filesystem connector to new table source sink interface", "committedDate": "2020-10-26T02:37:26Z", "type": "commit"}, {"oid": "0b644cc4e0ffb153ecdd67e8d4ba214341dc1a06", "url": "https://github.com/apache/flink/commit/0b644cc4e0ffb153ecdd67e8d4ba214341dc1a06", "message": "Fix cases", "committedDate": "2020-10-26T03:03:09Z", "type": "commit"}, {"oid": "0b644cc4e0ffb153ecdd67e8d4ba214341dc1a06", "url": "https://github.com/apache/flink/commit/0b644cc4e0ffb153ecdd67e8d4ba214341dc1a06", "message": "Fix cases", "committedDate": "2020-10-26T03:03:09Z", "type": "forcePushed"}, {"oid": "2979dcd1fa92a3a5653914203311aba30f62ad09", "url": "https://github.com/apache/flink/commit/2979dcd1fa92a3a5653914203311aba30f62ad09", "message": "Fix cases", "committedDate": "2020-10-26T05:37:59Z", "type": "commit"}, {"oid": "afd866cd911131de15dfe3a2d3ec80b93ea78da7", "url": "https://github.com/apache/flink/commit/afd866cd911131de15dfe3a2d3ec80b93ea78da7", "message": "Fix streaming source", "committedDate": "2020-10-26T08:03:32Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjAxMjIyNw==", "url": "https://github.com/apache/flink/pull/13767#discussion_r512012227", "bodyText": "update the note", "author": "leonardBang", "createdAt": "2020-10-26T14:40:36Z", "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/filesystem/FileSystemTableFactoryTest.java", "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.filesystem;\n+\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.api.ValidationException;\n+import org.apache.flink.table.catalog.CatalogTableImpl;\n+import org.apache.flink.table.catalog.ObjectIdentifier;\n+import org.apache.flink.table.connector.sink.DynamicTableSink;\n+import org.apache.flink.table.connector.source.DynamicTableSource;\n+import org.apache.flink.table.descriptors.DescriptorProperties;\n+import org.apache.flink.table.factories.DataGenTableSourceFactory;\n+import org.apache.flink.table.factories.FactoryUtil;\n+\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * Tests for {@link DataGenTableSourceFactory}.", "originalCommit": "afd866cd911131de15dfe3a2d3ec80b93ea78da7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjAxNTQxMQ==", "url": "https://github.com/apache/flink/pull/13767#discussion_r512015411", "bodyText": "That's better we can given a more readable identifier like ObjectIdentifier.of(\"mycatalog\", \"mydb\", \"mytable\")", "author": "leonardBang", "createdAt": "2020-10-26T14:44:39Z", "path": "flink-table/flink-table-runtime-blink/src/test/java/org/apache/flink/table/filesystem/FileSystemTableFactoryTest.java", "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.filesystem;\n+\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.api.ValidationException;\n+import org.apache.flink.table.catalog.CatalogTableImpl;\n+import org.apache.flink.table.catalog.ObjectIdentifier;\n+import org.apache.flink.table.connector.sink.DynamicTableSink;\n+import org.apache.flink.table.connector.source.DynamicTableSource;\n+import org.apache.flink.table.descriptors.DescriptorProperties;\n+import org.apache.flink.table.factories.DataGenTableSourceFactory;\n+import org.apache.flink.table.factories.FactoryUtil;\n+\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * Tests for {@link DataGenTableSourceFactory}.\n+ */\n+public class FileSystemTableFactoryTest {\n+\n+\tprivate static final TableSchema TEST_SCHEMA = TableSchema.builder()\n+\t\t\t.field(\"f0\", DataTypes.STRING())\n+\t\t\t.field(\"f1\", DataTypes.BIGINT())\n+\t\t\t.field(\"f2\", DataTypes.BIGINT())\n+\t\t\t.build();\n+\n+\t@Test\n+\tpublic void testSourceSink() throws Exception {\n+\t\tDescriptorProperties descriptor = new DescriptorProperties();\n+\t\tdescriptor.putString(FactoryUtil.CONNECTOR.key(), \"filesystem\");\n+\t\tdescriptor.putString(\"path\", \"/tmp\");\n+\t\tdescriptor.putString(\"format\", \"csv\");\n+\n+\t\tDynamicTableSource source = createSource(descriptor);\n+\t\tAssert.assertTrue(source instanceof FileSystemTableSource);\n+\n+\t\tDynamicTableSink sink = createSink(descriptor);\n+\t\tAssert.assertTrue(sink instanceof FileSystemTableSink);\n+\t}\n+\n+\t@Test\n+\tpublic void testLackOptionSource() {\n+\t\tDescriptorProperties descriptor = new DescriptorProperties();\n+\t\tdescriptor.putString(FactoryUtil.CONNECTOR.key(), \"filesystem\");\n+\t\tdescriptor.putString(\"path\", \"/tmp\");\n+\n+\t\ttry {\n+\t\t\tcreateSource(descriptor);\n+\t\t} catch (ValidationException e) {\n+\t\t\tThrowable cause = e.getCause();\n+\t\t\tAssert.assertTrue(cause.toString(), cause instanceof ValidationException);\n+\t\t\tAssert.assertTrue(cause.getMessage(), cause.getMessage().contains(\n+\t\t\t\t\t\"Missing required options are:\\n\\nformat\"));\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tAssert.fail(\"Should fail by ValidationException.\");\n+\t}\n+\n+\t@Test\n+\tpublic void testLackOptionSink() {\n+\t\tDescriptorProperties descriptor = new DescriptorProperties();\n+\t\tdescriptor.putString(FactoryUtil.CONNECTOR.key(), \"filesystem\");\n+\t\tdescriptor.putString(\"path\", \"/tmp\");\n+\n+\t\ttry {\n+\t\t\tcreateSink(descriptor);\n+\t\t} catch (ValidationException e) {\n+\t\t\tThrowable cause = e.getCause();\n+\t\t\tAssert.assertTrue(cause.toString(), cause instanceof ValidationException);\n+\t\t\tAssert.assertTrue(cause.getMessage(), cause.getMessage().contains(\n+\t\t\t\t\t\"Missing required options are:\\n\\nformat\"));\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tAssert.fail(\"Should fail by ValidationException.\");\n+\t}\n+\n+\t@Test\n+\tpublic void testUnsupportedOptionSource() {\n+\t\tDescriptorProperties descriptor = new DescriptorProperties();\n+\t\tdescriptor.putString(FactoryUtil.CONNECTOR.key(), \"filesystem\");\n+\t\tdescriptor.putString(\"path\", \"/tmp\");\n+\t\tdescriptor.putString(\"format\", \"csv\");\n+\t\tdescriptor.putString(\"my_option\", \"my\");\n+\n+\t\ttry {\n+\t\t\tcreateSource(descriptor);\n+\t\t} catch (ValidationException e) {\n+\t\t\tThrowable cause = e.getCause();\n+\t\t\tAssert.assertTrue(cause.toString(), cause instanceof ValidationException);\n+\t\t\tAssert.assertTrue(cause.getMessage(), cause.getMessage().contains(\n+\t\t\t\t\t\"Unsupported options:\\n\\nmy_option\"));\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tAssert.fail(\"Should fail by ValidationException.\");\n+\t}\n+\n+\t@Test\n+\tpublic void testUnsupportedOptionSink() {\n+\t\tDescriptorProperties descriptor = new DescriptorProperties();\n+\t\tdescriptor.putString(FactoryUtil.CONNECTOR.key(), \"filesystem\");\n+\t\tdescriptor.putString(\"path\", \"/tmp\");\n+\t\tdescriptor.putString(\"format\", \"csv\");\n+\t\tdescriptor.putString(\"my_option\", \"my\");\n+\n+\t\ttry {\n+\t\t\tcreateSink(descriptor);\n+\t\t} catch (ValidationException e) {\n+\t\t\tThrowable cause = e.getCause();\n+\t\t\tAssert.assertTrue(cause.toString(), cause instanceof ValidationException);\n+\t\t\tAssert.assertTrue(cause.getMessage(), cause.getMessage().contains(\n+\t\t\t\t\t\"Unsupported options:\\n\\nmy_option\"));\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tAssert.fail(\"Should fail by ValidationException.\");\n+\t}\n+\n+\tprivate static DynamicTableSource createSource(DescriptorProperties properties) {\n+\t\treturn FactoryUtil.createTableSource(\n+\t\t\t\tnull,\n+\t\t\t\tObjectIdentifier.of(\"\", \"\", \"\"),", "originalCommit": "afd866cd911131de15dfe3a2d3ec80b93ea78da7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjAyNDM2NA==", "url": "https://github.com/apache/flink/pull/13767#discussion_r512024364", "bodyText": "Considering the format options is never validated, I suggest at least add one test in FileSystemTableFactoryTest", "author": "leonardBang", "createdAt": "2020-10-26T14:55:43Z", "path": "flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/AvroFilesystemStreamITCase.java", "diffHunk": "@@ -32,7 +32,7 @@\n \tpublic String[] additionalProperties() {\n \t\tList<String> ret = new ArrayList<>();\n \t\tret.add(\"'format'='avro'\");\n-\t\tret.add(\"'format.avro.codec'='snappy'\");", "originalCommit": "afd866cd911131de15dfe3a2d3ec80b93ea78da7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjAzMDI4NA==", "url": "https://github.com/apache/flink/pull/13767#discussion_r512030284", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\t// Except format options, some format like parquet and orc can not list all support options.\n          \n          \n            \n            \t\t// Except format options, some formats like parquet and orc can not list all supported options.", "author": "leonardBang", "createdAt": "2020-10-26T15:02:54Z", "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/filesystem/FileSystemTableFactory.java", "diffHunk": "@@ -48,71 +36,59 @@\n  * table or a catalog table.\n  * 2.Support insert into (append) and insert overwrite.\n  * 3.Support static and dynamic partition inserting.\n- *\n- * <p>Migrate to new source/sink interface after FLIP-95 is ready.\n  */\n public class FileSystemTableFactory implements\n-\t\tTableSourceFactory<RowData>,\n-\t\tTableSinkFactory<RowData> {\n+\t\tDynamicTableSourceFactory,\n+\t\tDynamicTableSinkFactory {\n \n \tpublic static final String IDENTIFIER = \"filesystem\";\n \n \t@Override\n-\tpublic Map<String, String> requiredContext() {\n-\t\tMap<String, String> context = new HashMap<>();\n-\t\tcontext.put(CONNECTOR, IDENTIFIER);\n-\t\treturn context;\n+\tpublic String factoryIdentifier() {\n+\t\treturn IDENTIFIER;\n \t}\n \n \t@Override\n-\tpublic List<String> supportedProperties() {\n-\t\t// contains format properties.\n-\t\treturn Collections.singletonList(\"*\");\n+\tpublic DynamicTableSink createDynamicTableSink(Context context) {\n+\t\tvalidate(FactoryUtil.createTableFactoryHelper(this, context));\n+\t\treturn new FileSystemTableSink(context);\n \t}\n \n \t@Override\n-\tpublic TableSource<RowData> createTableSource(TableSourceFactory.Context context) {\n-\t\tConfiguration conf = new Configuration();\n-\t\tcontext.getTable().getOptions().forEach(conf::setString);\n-\n-\t\treturn new FileSystemTableSource(\n-\t\t\t\tTableSchemaUtils.getPhysicalSchema(context.getTable().getSchema()),\n-\t\t\t\tgetPath(conf),\n-\t\t\t\tcontext.getTable().getPartitionKeys(),\n-\t\t\t\tconf.get(PARTITION_DEFAULT_NAME),\n-\t\t\t\tcontext.getTable().getProperties());\n+\tpublic DynamicTableSource createDynamicTableSource(Context context) {\n+\t\tvalidate(FactoryUtil.createTableFactoryHelper(this, context));\n+\t\treturn new FileSystemTableSource(context);\n \t}\n \n-\t@Override\n-\tpublic TableSink<RowData> createTableSink(TableSinkFactory.Context context) {\n-\t\tConfiguration conf = new Configuration();\n-\t\tcontext.getTable().getOptions().forEach(conf::setString);\n-\n-\t\treturn new FileSystemTableSink(\n-\t\t\t\tcontext.getObjectIdentifier(),\n-\t\t\t\tcontext.isBounded(),\n-\t\t\t\tTableSchemaUtils.getPhysicalSchema(context.getTable().getSchema()),\n-\t\t\t\tgetPath(conf),\n-\t\t\t\tcontext.getTable().getPartitionKeys(),\n-\t\t\t\tconf.get(PARTITION_DEFAULT_NAME),\n-\t\t\t\tcontext.getTable().getOptions());\n+\tprivate void validate(FactoryUtil.TableFactoryHelper helper) {\n+\t\t// Except format options, some format like parquet and orc can not list all support options.", "originalCommit": "afd866cd911131de15dfe3a2d3ec80b93ea78da7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjA0MzEwNQ==", "url": "https://github.com/apache/flink/pull/13767#discussion_r512043105", "bodyText": "Filesystem", "author": "leonardBang", "createdAt": "2020-10-26T15:19:15Z", "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/filesystem/FileSystemTableSource.java", "diffHunk": "@@ -226,87 +195,63 @@ public long getPushedDownLimit() {\n \t\t\t\t\t\tspec.forEach((k, v) -> ret.put(k, defaultPartName.equals(v) ? null : v));\n \t\t\t\t\t\treturn ret;\n \t\t\t\t\t})\n-\t\t\t\t\t.collect(Collectors.toList());\n+\t\t\t\t\t.collect(Collectors.toList()));\n \t\t} catch (Exception e) {\n \t\t\tthrow new TableException(\"Fetch partitions fail.\", e);\n \t\t}\n \t}\n \n \t@Override\n-\tpublic FileSystemTableSource applyPartitionPruning(\n-\t\t\tList<Map<String, String>> remainingPartitions) {\n-\t\treturn new FileSystemTableSource(\n-\t\t\t\tschema,\n-\t\t\t\tpath,\n-\t\t\t\tpartitionKeys,\n-\t\t\t\tdefaultPartName,\n-\t\t\t\tproperties,\n-\t\t\t\tremainingPartitions,\n-\t\t\t\tselectFields,\n-\t\t\t\tlimit,\n-\t\t\t\tfilters);\n+\tpublic void applyPartitions(List<Map<String, String>> remainingPartitions) {\n+\t\tthis.remainingPartitions = remainingPartitions;\n \t}\n \n \t@Override\n-\tpublic FileSystemTableSource projectFields(int[] fields) {\n-\t\treturn new FileSystemTableSource(\n-\t\t\t\tschema,\n-\t\t\t\tpath,\n-\t\t\t\tpartitionKeys,\n-\t\t\t\tdefaultPartName,\n-\t\t\t\tproperties,\n-\t\t\t\treadPartitions,\n-\t\t\t\tfields,\n-\t\t\t\tlimit,\n-\t\t\t\tfilters);\n+\tpublic boolean supportsNestedProjection() {\n+\t\treturn false;\n \t}\n \n \t@Override\n-\tpublic FileSystemTableSource applyLimit(long limit) {\n-\t\treturn new FileSystemTableSource(\n-\t\t\t\tschema,\n-\t\t\t\tpath,\n-\t\t\t\tpartitionKeys,\n-\t\t\t\tdefaultPartName,\n-\t\t\t\tproperties,\n-\t\t\t\treadPartitions,\n-\t\t\t\tselectFields,\n-\t\t\t\tlimit,\n-\t\t\t\tfilters);\n+\tpublic void applyProjection(int[][] projectedFields) {\n+\t\tthis.projectedFields = projectedFields;\n \t}\n \n \t@Override\n-\tpublic boolean isLimitPushedDown() {\n-\t\treturn limit != null;\n+\tpublic FileSystemTableSource copy() {\n+\t\treturn new FileSystemTableSource(context, projectedFields, remainingPartitions, filters, limit);\n \t}\n \n \t@Override\n-\tpublic FileSystemTableSource applyPredicate(List<Expression> predicates) {\n-\t\treturn new FileSystemTableSource(\n-\t\t\t\tschema,\n-\t\t\t\tpath,\n-\t\t\t\tpartitionKeys,\n-\t\t\t\tdefaultPartName,\n-\t\t\t\tproperties,\n-\t\t\t\treadPartitions,\n-\t\t\t\tselectFields,\n-\t\t\t\tlimit,\n-\t\t\t\tnew ArrayList<>(predicates));\n+\tpublic String asSummaryString() {\n+\t\treturn \"filesystem\";", "originalCommit": "afd866cd911131de15dfe3a2d3ec80b93ea78da7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjA0MzM4OQ==", "url": "https://github.com/apache/flink/pull/13767#discussion_r512043389", "bodyText": "FileSystem", "author": "leonardBang", "createdAt": "2020-10-26T15:19:34Z", "path": "flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/filesystem/FileSystemTableSink.java", "diffHunk": "@@ -351,19 +315,34 @@ public void setStaticPartition(Map<String, String> partitions) {\n \t}\n \n \t@Override\n-\tpublic TableSchema getTableSchema() {\n-\t\treturn schema;\n+\tpublic boolean requiresPartitionGrouping(boolean supportsGrouping) {\n+\t\tthis.dynamicGrouping = supportsGrouping;\n+\t\treturn dynamicGrouping;\n \t}\n \n \t@Override\n-\tpublic DataType getConsumedDataType() {\n-\t\treturn schema.toRowDataType().bridgedTo(RowData.class);\n+\tpublic ChangelogMode getChangelogMode(ChangelogMode requestedMode) {\n+\t\treturn ChangelogMode.insertOnly();\n \t}\n \n \t@Override\n-\tpublic boolean configurePartitionGrouping(boolean supportsGrouping) {\n-\t\tthis.dynamicGrouping = supportsGrouping;\n-\t\treturn dynamicGrouping;\n+\tpublic DynamicTableSink copy() {\n+\t\treturn new FileSystemTableSink(context, overwrite, dynamicGrouping, staticPartitions);\n+\t}\n+\n+\t@Override\n+\tpublic String asSummaryString() {\n+\t\treturn \"filesystem\";", "originalCommit": "afd866cd911131de15dfe3a2d3ec80b93ea78da7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "bf0d914e9559cdfb49695af72933911fa83bbb26", "url": "https://github.com/apache/flink/commit/bf0d914e9559cdfb49695af72933911fa83bbb26", "message": "Address comments", "committedDate": "2020-10-27T02:22:02Z", "type": "commit"}]}