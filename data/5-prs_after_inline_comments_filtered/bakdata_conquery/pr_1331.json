{"pr_number": 1331, "pr_title": "Feature/fix processing of not contained entities", "pr_createdAt": "2020-08-31T14:19:06Z", "pr_url": "https://github.com/bakdata/conquery/pull/1331", "timeline": [{"oid": "0c59af4e4cc7778c19ffd0daaaa81c396fb0af88", "url": "https://github.com/bakdata/conquery/commit/0c59af4e4cc7778c19ffd0daaaa81c396fb0af88", "message": "fix dataset deletion test", "committedDate": "2020-08-31T14:10:48Z", "type": "commit"}, {"oid": "1c9fc72a67febfbfec8f633f05a7d9d92de026fe", "url": "https://github.com/bakdata/conquery/commit/1c9fc72a67febfbfec8f633f05a7d9d92de026fe", "message": "adds helper method for column count of a entity result", "committedDate": "2020-08-31T14:12:07Z", "type": "commit"}, {"oid": "a157c0a2967340f92ed12ac6bcd0289489a29801", "url": "https://github.com/bakdata/conquery/commit/a157c0a2967340f92ed12ac6bcd0289489a29801", "message": "check datecontexts for formquery for consistency and precalculate the number of constants", "committedDate": "2020-08-31T14:14:43Z", "type": "commit"}, {"oid": "1f00bf2daef4c7ac967a81cf4ef64d0e5b3f664a", "url": "https://github.com/bakdata/conquery/commit/1f00bf2daef4c7ac967a81cf4ef64d0e5b3f664a", "message": "also support NotContained in relativeformqueryplan subquery", "committedDate": "2020-08-31T14:17:58Z", "type": "commit"}, {"oid": "79393422abd2fef4ecab26aed206d15cec8b6774", "url": "https://github.com/bakdata/conquery/commit/79393422abd2fef4ecab26aed206d15cec8b6774", "message": "adapted test to provoke casting error", "committedDate": "2020-09-01T08:53:42Z", "type": "commit"}, {"oid": "1547c2449c46373306a3b95cad1e940ab0db0096", "url": "https://github.com/bakdata/conquery/commit/1547c2449c46373306a3b95cad1e940ab0db0096", "message": "Merge branch 'feature/test-failing-on-not-contained-entities' into feature/fix-processing-of-not-contained-entities", "committedDate": "2020-09-01T08:54:02Z", "type": "commit"}, {"oid": "2a556db45fc7486853ab6741ceb72d0b5cbc9771", "url": "https://github.com/bakdata/conquery/commit/2a556db45fc7486853ab6741ceb72d0b5cbc9771", "message": "correct subresult check", "committedDate": "2020-09-01T09:11:39Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjAxNTE2OQ==", "url": "https://github.com/bakdata/conquery/pull/1331#discussion_r482015169", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\t// Check if the result if of an processible type (multiline or not contained)\n          \n          \n            \n            \t\t// Check if the result is processible (type is multiline or not contained)", "author": "awildturtok", "createdAt": "2020-09-02T12:02:34Z", "path": "backend/src/main/java/com/bakdata/conquery/models/forms/managed/RelativeFormQueryPlan.java", "diffHunk": "@@ -63,63 +62,118 @@ public EntityResult execute(QueryExecutionContext ctx, Entity entity) {\n \t\tList<DateContext> contexts = DateContext\n \t\t\t.generateRelativeContexts(sample, indexPlacement, timeCountBefore, timeCountAfter, timeUnit, resolutions);\n \n-\t\tSubResult featureResult = executeSubQuery(ctx, FeatureGroup.FEATURE, entity, contexts);\n-\t\tSubResult outcomeResult = executeSubQuery(ctx, FeatureGroup.OUTCOME, entity, contexts);\n+\t\tFormQueryPlan featureSubquery = executeSubQuery(ctx, FeatureGroup.FEATURE, entity, contexts);\n+\t\tFormQueryPlan outcomeSubquery = executeSubQuery(ctx, FeatureGroup.OUTCOME, entity, contexts);\n+\n+\t\tEntityResult featureResult = featureSubquery.execute(ctx, entity);\n+\t\tEntityResult outcomeResult = outcomeSubquery.execute(ctx, entity);\n+\n+\t\t// on fail return failed result\n+\t\tif (featureResult.isFailed()) {\n+\t\t\treturn featureResult;\n+\t\t}\n+\t\tif (outcomeResult.isFailed()) {\n+\t\t\treturn outcomeResult;\n+\t\t}\n+\n+\t\t// Check if the result if of an processible type (multiline or not contained)", "originalCommit": "2a556db45fc7486853ab6741ceb72d0b5cbc9771", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjAxNTU4Mg==", "url": "https://github.com/bakdata/conquery/pull/1331#discussion_r482015582", "bodyText": "kannst du das in zwei checks aufsplitten?", "author": "awildturtok", "createdAt": "2020-09-02T12:03:24Z", "path": "backend/src/main/java/com/bakdata/conquery/models/forms/managed/RelativeFormQueryPlan.java", "diffHunk": "@@ -63,63 +62,118 @@ public EntityResult execute(QueryExecutionContext ctx, Entity entity) {\n \t\tList<DateContext> contexts = DateContext\n \t\t\t.generateRelativeContexts(sample, indexPlacement, timeCountBefore, timeCountAfter, timeUnit, resolutions);\n \n-\t\tSubResult featureResult = executeSubQuery(ctx, FeatureGroup.FEATURE, entity, contexts);\n-\t\tSubResult outcomeResult = executeSubQuery(ctx, FeatureGroup.OUTCOME, entity, contexts);\n+\t\tFormQueryPlan featureSubquery = executeSubQuery(ctx, FeatureGroup.FEATURE, entity, contexts);\n+\t\tFormQueryPlan outcomeSubquery = executeSubQuery(ctx, FeatureGroup.OUTCOME, entity, contexts);\n+\n+\t\tEntityResult featureResult = featureSubquery.execute(ctx, entity);\n+\t\tEntityResult outcomeResult = outcomeSubquery.execute(ctx, entity);\n+\n+\t\t// on fail return failed result\n+\t\tif (featureResult.isFailed()) {\n+\t\t\treturn featureResult;\n+\t\t}\n+\t\tif (outcomeResult.isFailed()) {\n+\t\t\treturn outcomeResult;\n+\t\t}\n+\n+\t\t// Check if the result if of an processible type (multiline or not contained)\n+\t\tcheckIfResultProcessible(featureResult);\n+\t\tcheckIfResultProcessible(outcomeResult);\n+\n+\t\tif (!featureResult.isContained() && !outcomeResult.isContained()) {\n+\t\t\t// if both, feature and outcome are not contained fast quit.\n+\t\t\treturn EntityResult.notContained();\n+\t\t}\n+\n+\t\t// determine result length and check against aggregators in query\n+\t\tint featureLength = determineResultWithAndCheck(featureSubquery, featureResult);\n+\t\tint outcomeLength = determineResultWithAndCheck(outcomeSubquery, outcomeResult);\n \n-\t\tList<Object[]> values = new ArrayList<>();\n-\t\t// We look at the first result line to determine the length of the subresult\n-\t\tint featureLength = featureResult.getValues().get(0).length;\n-\t\tint outcomeLength = outcomeResult.getValues().get(0).length;\n-\t\t\n \t\t/*\n-\t\t *  Whole result is the concatenation of the subresults. The final output format combines resolution info, index and eventdate of both sub queries.\n-\t\t *  The feature/outcome sub queries are of in form of: [RESOLUTION], [INDEX], [EVENTDATE], [FEATURE/OUTCOME_DR], [FEATURE/OUTCOME_SELECTS]... \n-\t\t *  The wanted format is: [RESOLUTION], [INDEX], [EVENTDATE], [FEATURE_DR], [OUTCOME_DR], [FEATURE_SELECTS]... , [OUTCOME_SELECTS]\n+\t\t * Whole result is the concatenation of the subresults. The final output format\n+\t\t * combines resolution info, index and eventdate of both sub queries. The\n+\t\t * feature/outcome sub queries are of in form of: [RESOLUTION], [INDEX],\n+\t\t * [EVENTDATE], [FEATURE/OUTCOME_DR], [FEATURE/OUTCOME_SELECTS]... The wanted\n+\t\t * format is: [RESOLUTION], [INDEX], [EVENTDATE], [FEATURE_DR], [OUTCOME_DR],\n+\t\t * [FEATURE_SELECTS]... , [OUTCOME_SELECTS]\n \t\t */\n-\t\tint size = featureLength + outcomeLength - 3/*= [RESOLUTION], [INDEX], [EVENTDATE]*/;\n+\t\tint size = featureLength + outcomeLength - 3/* ^= [RESOLUTION], [INDEX], [EVENTDATE] */;\n \n \t\tint resultStartIndex = 0;\n-\t\tif(hasCompleteDateContexts(contexts)) {\n-\t\t\t// merge a line for the complete daterange, when two dateContext were generated that don't target the same feature group,\n+\t\tList<Object[]> values = new ArrayList<>();\n+\t\tif (hasCompleteDateContexts(contexts)) {\n+\t\t\t// merge a line for the complete daterange, when two dateContext were generated\n+\t\t\t// that don't target the same feature group,\n \t\t\t// which would be a mistake by the generation\n-\t\t\t// Since the DateContexts are primarily ordered by their coarseness and COMPLETE is the coarsed resolution it must be at the first\n+\t\t\t// Since the DateContexts are primarily ordered by their coarseness and COMPLETE\n+\t\t\t// is the coarsed resolution it must be at the first\n \t\t\t// to indexes of the list.\n \t\t\tObject[] mergedFull = new Object[size];\n-\t\t\tsetFeatureValues(mergedFull, featureResult.getValues().get(resultStartIndex));\n-\t\t\tsetOutcomeValues(mergedFull, outcomeResult.getValues().get(resultStartIndex), featureLength);\n+\t\t\tif (featureResult.isContained()) {\n+\t\t\t\tsetFeatureValues(mergedFull, ((MultilineContainedEntityResult) featureResult).getValues().get(resultStartIndex));\n+\t\t\t}\n+\t\t\tif (outcomeResult.isContained()) {\n+\t\t\t\tsetOutcomeValues(\n+\t\t\t\t\tmergedFull,\n+\t\t\t\t\t((MultilineContainedEntityResult) outcomeResult).getValues().get(resultStartIndex),\n+\t\t\t\t\tfeatureLength);\n+\t\t\t}\n \t\t\tvalues.add(mergedFull);\n \t\t\tresultStartIndex++;\n \t\t}\n \n \t\t// append all other lines directly\n-\t\tfor (int i = resultStartIndex; i < featureResult.getValues().size(); i++) {\n-\t\t\tObject[] result = new Object[size];\n-\t\t\tsetFeatureValues(result, featureResult.getValues().get(i));\n-\t\t\tvalues.add(result);\n+\t\tif (featureResult.isContained()) {\n+\t\t\tMultilineContainedEntityResult multiresult = ((MultilineContainedEntityResult) featureResult);\n+\t\t\tfor (int i = resultStartIndex; i < multiresult.getValues().size(); i++) {\n+\t\t\t\tObject[] result = new Object[size];\n+\t\t\t\tsetFeatureValues(result, multiresult.getValues().get(i));\n+\t\t\t\tvalues.add(result);\n+\t\t\t}\n \t\t}\n-\t\tfor (int i = resultStartIndex; i < outcomeResult.getValues().size(); i++) {\n-\t\t\tObject[] result = new Object[size];\n-\t\t\tsetOutcomeValues(result, outcomeResult.getValues().get(i), featureLength);\n-\t\t\tvalues.add(result);\n+\t\tif (outcomeResult.isContained()) {\n+\t\t\tMultilineContainedEntityResult multiresult = ((MultilineContainedEntityResult) outcomeResult);\n+\t\t\tfor (int i = resultStartIndex; i < multiresult.getValues().size(); i++) {\n+\t\t\t\tObject[] result = new Object[size];\n+\t\t\t\tsetOutcomeValues(result, multiresult.getValues().get(i), featureLength);\n+\t\t\t\tvalues.add(result);\n+\t\t\t}\n \t\t}\n \t\treturn EntityResult.multilineOf(entity.getId(), values);\n \t}\n \n+\tprivate int determineResultWithAndCheck(FormQueryPlan subquery, EntityResult subResult) {\n+\t\tint featureLength = subquery.columnCount();\n+\t\tint featureResultColumnCount;\n+\t\tif (subResult.isContained() && (featureResultColumnCount = subResult.asContained().columnCount()) != featureLength) {", "originalCommit": "2a556db45fc7486853ab6741ceb72d0b5cbc9771", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjAxNjAyMg==", "url": "https://github.com/bakdata/conquery/pull/1331#discussion_r482016022", "bodyText": "wenn das ne fehlermeldung wirft, w\u00fcrde ich das assertProcessible oder so nennen", "author": "awildturtok", "createdAt": "2020-09-02T12:04:19Z", "path": "backend/src/main/java/com/bakdata/conquery/models/forms/managed/RelativeFormQueryPlan.java", "diffHunk": "@@ -63,63 +62,118 @@ public EntityResult execute(QueryExecutionContext ctx, Entity entity) {\n \t\tList<DateContext> contexts = DateContext\n \t\t\t.generateRelativeContexts(sample, indexPlacement, timeCountBefore, timeCountAfter, timeUnit, resolutions);\n \n-\t\tSubResult featureResult = executeSubQuery(ctx, FeatureGroup.FEATURE, entity, contexts);\n-\t\tSubResult outcomeResult = executeSubQuery(ctx, FeatureGroup.OUTCOME, entity, contexts);\n+\t\tFormQueryPlan featureSubquery = executeSubQuery(ctx, FeatureGroup.FEATURE, entity, contexts);\n+\t\tFormQueryPlan outcomeSubquery = executeSubQuery(ctx, FeatureGroup.OUTCOME, entity, contexts);\n+\n+\t\tEntityResult featureResult = featureSubquery.execute(ctx, entity);\n+\t\tEntityResult outcomeResult = outcomeSubquery.execute(ctx, entity);\n+\n+\t\t// on fail return failed result\n+\t\tif (featureResult.isFailed()) {\n+\t\t\treturn featureResult;\n+\t\t}\n+\t\tif (outcomeResult.isFailed()) {\n+\t\t\treturn outcomeResult;\n+\t\t}\n+\n+\t\t// Check if the result if of an processible type (multiline or not contained)\n+\t\tcheckIfResultProcessible(featureResult);", "originalCommit": "2a556db45fc7486853ab6741ceb72d0b5cbc9771", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjAxNjc1Mw==", "url": "https://github.com/bakdata/conquery/pull/1331#discussion_r482016753", "bodyText": "die methode macht zu viel auf einmal, kannst du das nicht splitten?", "author": "awildturtok", "createdAt": "2020-09-02T12:05:43Z", "path": "backend/src/main/java/com/bakdata/conquery/models/forms/managed/RelativeFormQueryPlan.java", "diffHunk": "@@ -63,63 +62,118 @@ public EntityResult execute(QueryExecutionContext ctx, Entity entity) {\n \t\tList<DateContext> contexts = DateContext\n \t\t\t.generateRelativeContexts(sample, indexPlacement, timeCountBefore, timeCountAfter, timeUnit, resolutions);\n \n-\t\tSubResult featureResult = executeSubQuery(ctx, FeatureGroup.FEATURE, entity, contexts);\n-\t\tSubResult outcomeResult = executeSubQuery(ctx, FeatureGroup.OUTCOME, entity, contexts);\n+\t\tFormQueryPlan featureSubquery = executeSubQuery(ctx, FeatureGroup.FEATURE, entity, contexts);\n+\t\tFormQueryPlan outcomeSubquery = executeSubQuery(ctx, FeatureGroup.OUTCOME, entity, contexts);\n+\n+\t\tEntityResult featureResult = featureSubquery.execute(ctx, entity);\n+\t\tEntityResult outcomeResult = outcomeSubquery.execute(ctx, entity);\n+\n+\t\t// on fail return failed result\n+\t\tif (featureResult.isFailed()) {\n+\t\t\treturn featureResult;\n+\t\t}\n+\t\tif (outcomeResult.isFailed()) {\n+\t\t\treturn outcomeResult;\n+\t\t}\n+\n+\t\t// Check if the result if of an processible type (multiline or not contained)\n+\t\tcheckIfResultProcessible(featureResult);\n+\t\tcheckIfResultProcessible(outcomeResult);\n+\n+\t\tif (!featureResult.isContained() && !outcomeResult.isContained()) {\n+\t\t\t// if both, feature and outcome are not contained fast quit.\n+\t\t\treturn EntityResult.notContained();\n+\t\t}\n+\n+\t\t// determine result length and check against aggregators in query\n+\t\tint featureLength = determineResultWithAndCheck(featureSubquery, featureResult);\n+\t\tint outcomeLength = determineResultWithAndCheck(outcomeSubquery, outcomeResult);\n \n-\t\tList<Object[]> values = new ArrayList<>();\n-\t\t// We look at the first result line to determine the length of the subresult\n-\t\tint featureLength = featureResult.getValues().get(0).length;\n-\t\tint outcomeLength = outcomeResult.getValues().get(0).length;\n-\t\t\n \t\t/*\n-\t\t *  Whole result is the concatenation of the subresults. The final output format combines resolution info, index and eventdate of both sub queries.\n-\t\t *  The feature/outcome sub queries are of in form of: [RESOLUTION], [INDEX], [EVENTDATE], [FEATURE/OUTCOME_DR], [FEATURE/OUTCOME_SELECTS]... \n-\t\t *  The wanted format is: [RESOLUTION], [INDEX], [EVENTDATE], [FEATURE_DR], [OUTCOME_DR], [FEATURE_SELECTS]... , [OUTCOME_SELECTS]\n+\t\t * Whole result is the concatenation of the subresults. The final output format\n+\t\t * combines resolution info, index and eventdate of both sub queries. The\n+\t\t * feature/outcome sub queries are of in form of: [RESOLUTION], [INDEX],\n+\t\t * [EVENTDATE], [FEATURE/OUTCOME_DR], [FEATURE/OUTCOME_SELECTS]... The wanted\n+\t\t * format is: [RESOLUTION], [INDEX], [EVENTDATE], [FEATURE_DR], [OUTCOME_DR],\n+\t\t * [FEATURE_SELECTS]... , [OUTCOME_SELECTS]\n \t\t */\n-\t\tint size = featureLength + outcomeLength - 3/*= [RESOLUTION], [INDEX], [EVENTDATE]*/;\n+\t\tint size = featureLength + outcomeLength - 3/* ^= [RESOLUTION], [INDEX], [EVENTDATE] */;\n \n \t\tint resultStartIndex = 0;\n-\t\tif(hasCompleteDateContexts(contexts)) {\n-\t\t\t// merge a line for the complete daterange, when two dateContext were generated that don't target the same feature group,\n+\t\tList<Object[]> values = new ArrayList<>();\n+\t\tif (hasCompleteDateContexts(contexts)) {\n+\t\t\t// merge a line for the complete daterange, when two dateContext were generated\n+\t\t\t// that don't target the same feature group,\n \t\t\t// which would be a mistake by the generation\n-\t\t\t// Since the DateContexts are primarily ordered by their coarseness and COMPLETE is the coarsed resolution it must be at the first\n+\t\t\t// Since the DateContexts are primarily ordered by their coarseness and COMPLETE\n+\t\t\t// is the coarsed resolution it must be at the first\n \t\t\t// to indexes of the list.\n \t\t\tObject[] mergedFull = new Object[size];\n-\t\t\tsetFeatureValues(mergedFull, featureResult.getValues().get(resultStartIndex));\n-\t\t\tsetOutcomeValues(mergedFull, outcomeResult.getValues().get(resultStartIndex), featureLength);\n+\t\t\tif (featureResult.isContained()) {\n+\t\t\t\tsetFeatureValues(mergedFull, ((MultilineContainedEntityResult) featureResult).getValues().get(resultStartIndex));\n+\t\t\t}\n+\t\t\tif (outcomeResult.isContained()) {\n+\t\t\t\tsetOutcomeValues(\n+\t\t\t\t\tmergedFull,\n+\t\t\t\t\t((MultilineContainedEntityResult) outcomeResult).getValues().get(resultStartIndex),\n+\t\t\t\t\tfeatureLength);\n+\t\t\t}\n \t\t\tvalues.add(mergedFull);\n \t\t\tresultStartIndex++;\n \t\t}\n \n \t\t// append all other lines directly\n-\t\tfor (int i = resultStartIndex; i < featureResult.getValues().size(); i++) {\n-\t\t\tObject[] result = new Object[size];\n-\t\t\tsetFeatureValues(result, featureResult.getValues().get(i));\n-\t\t\tvalues.add(result);\n+\t\tif (featureResult.isContained()) {\n+\t\t\tMultilineContainedEntityResult multiresult = ((MultilineContainedEntityResult) featureResult);\n+\t\t\tfor (int i = resultStartIndex; i < multiresult.getValues().size(); i++) {\n+\t\t\t\tObject[] result = new Object[size];\n+\t\t\t\tsetFeatureValues(result, multiresult.getValues().get(i));\n+\t\t\t\tvalues.add(result);\n+\t\t\t}\n \t\t}\n-\t\tfor (int i = resultStartIndex; i < outcomeResult.getValues().size(); i++) {\n-\t\t\tObject[] result = new Object[size];\n-\t\t\tsetOutcomeValues(result, outcomeResult.getValues().get(i), featureLength);\n-\t\t\tvalues.add(result);\n+\t\tif (outcomeResult.isContained()) {\n+\t\t\tMultilineContainedEntityResult multiresult = ((MultilineContainedEntityResult) outcomeResult);\n+\t\t\tfor (int i = resultStartIndex; i < multiresult.getValues().size(); i++) {\n+\t\t\t\tObject[] result = new Object[size];\n+\t\t\t\tsetOutcomeValues(result, multiresult.getValues().get(i), featureLength);\n+\t\t\t\tvalues.add(result);\n+\t\t\t}\n \t\t}\n \t\treturn EntityResult.multilineOf(entity.getId(), values);\n \t}\n \n+\tprivate int determineResultWithAndCheck(FormQueryPlan subquery, EntityResult subResult) {", "originalCommit": "2a556db45fc7486853ab6741ceb72d0b5cbc9771", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjAzOTc3NQ==", "url": "https://github.com/bakdata/conquery/pull/1331#discussion_r482039775", "bodyText": "Ich habe sie jetzt mehr dokumentiert. Ich w\u00fcrde es nicht trennen, da es sehr nah bei ein ander ist.", "author": "thoniTUB", "createdAt": "2020-09-02T12:45:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjAxNjc1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjAxNzYzOA==", "url": "https://github.com/bakdata/conquery/pull/1331#discussion_r482017638", "bodyText": "danke!", "author": "awildturtok", "createdAt": "2020-09-02T12:07:24Z", "path": "backend/src/main/java/com/bakdata/conquery/models/forms/managed/RelativeFormQueryPlan.java", "diffHunk": "@@ -160,16 +214,6 @@ public RelativeFormQueryPlan clone(CloneContext ctx) {\n \n \t@Override\n \tpublic boolean isOfInterest(Entity entity) {\n-\t\treturn query.isOfInterest(entity);\n+\t\treturn query.isOfInterest(entity) || featurePlan.isOfInterest(entity) || outcomePlan.isOfInterest(entity);", "originalCommit": "2a556db45fc7486853ab6741ceb72d0b5cbc9771", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "afd22368728008e5e54a67077c8f45c8b1e74f4c", "url": "https://github.com/bakdata/conquery/commit/afd22368728008e5e54a67077c8f45c8b1e74f4c", "message": "Update backend/src/main/java/com/bakdata/conquery/models/forms/managed/RelativeFormQueryPlan.java\n\nCo-authored-by: awildturtok <1553491+awildturtok@users.noreply.github.com>", "committedDate": "2020-09-02T12:34:41Z", "type": "commit"}, {"oid": "19eb30e0eb0ef4edd101dbdcbe71a001ea116f96", "url": "https://github.com/bakdata/conquery/commit/19eb30e0eb0ef4edd101dbdcbe71a001ea116f96", "message": "review cleanup of resultWidth calculation", "committedDate": "2020-09-02T12:46:28Z", "type": "commit"}, {"oid": "d07d10ede20d05f57f4eae50875f949006eb6253", "url": "https://github.com/bakdata/conquery/commit/d07d10ede20d05f57f4eae50875f949006eb6253", "message": "method renaming", "committedDate": "2020-09-02T12:48:21Z", "type": "commit"}]}