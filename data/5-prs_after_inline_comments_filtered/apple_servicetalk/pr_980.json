{"pr_number": 980, "pr_title": "HTTP Client Pipelining fullduplex", "pr_createdAt": "2020-03-23T19:39:08Z", "pr_url": "https://github.com/apple/servicetalk/pull/980", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjgzNDk1MQ==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r396834951", "bodyText": "we could consider moving this to concurrent.internal in the future, but for now I just left them internal here.", "author": "Scottmitch", "createdAt": "2020-03-24T00:18:44Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+\n+import io.netty.channel.Channel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Arrays;\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(NettyPipelinedConnection.class);\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            writeQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"writeQueueTail\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            readQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"readQueueTail\");\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node writeQueueTail;\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node readQueueTail;\n+\n+    private final NettyConnection<Resp, Req> connection;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} producing the request(s) to write.\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        return Publisher.defer(() -> {\n+            // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+\n+            // Setup read side publisher and nodes\n+            DelayedSubscribePublisher<Resp> delayedResponsePublisher = new DelayedSubscribePublisher<>(\n+                    toSource(connection.read()));\n+            Node readNode = new Node(delayedResponsePublisher::processSubscribers);\n+            Publisher<Resp> composedResponsePublisher =\n+                    delayedResponsePublisher.liftSync(new ReadPopNextOperator(readNode));\n+\n+            // Setup write side publisher and nodes\n+            DelayedSubscribeCompletable delayedRequestCompletable = new DelayedSubscribeCompletable(toSource(\n+                            connection.write(requestPublisher, flushStrategySupplier, writeDemandEstimatorSupplier)));\n+            Node writeNode = new Node(() -> {\n+                try {\n+                    queueOffer(readQueueTailUpdater, readNode);\n+                } finally {\n+                    delayedRequestCompletable.processSubscribers();\n+                }\n+            });\n+\n+            queueOffer(writeQueueTailUpdater, writeNode);\n+\n+            return delayedRequestCompletable.liftSync(new WritePopNextOperator(writeNode))\n+                    // If there is an error on the read/write side we propagate the errors between the two via merge.\n+                    .merge(composedResponsePublisher);\n+        });\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void queueOffer(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node node) {\n+        for (;;) {\n+            Node tail = tailUpdater.get(this);\n+            if (tail == null) {\n+                if (tailUpdater.compareAndSet(this, null, node)) {\n+                    // node has been inserted and is the only node, we initiate processing.\n+                    safeProcessSubscribers(node.delayedSource);\n+                    break;\n+                }\n+                // Another thread won the race to offer a node, loop around and try again.\n+            } else if (tail.append(node)) {\n+                // Make the newly appended node visible as the tail. This is a best effort CAS and may fail because:\n+                // 1. Another thread is also inserting, has a stale tail, followed its existing tail links, and updated\n+                // the tail reference via queueOfferPatchTail.\n+                // 2. The consumer thread has seen the link from the old tail to the new node, processed node,\n+                // popped node from the list (updated node's next to point to EMPTY_NODE), another producer thread\n+                // appends a new node, sees the tail is popped, and updates the tail reference via CAS.\n+                tailUpdater.compareAndSet(this, tail, node);\n+                break;\n+            } else if (tail.isPopped()) {\n+                // A previously appended node was processed, and popped before updating the tail after append. In that\n+                // case the tail maybe pointing to an invalid node and we clear it out.\n+                if (tailUpdater.compareAndSet(this, tail, node)) {\n+                    safeProcessSubscribers(node.delayedSource);\n+                    break;\n+                }\n+                // Best effort to clear the tail, and failure is OK because:\n+                // 1. Another thread is in offer and already patched up the tail pointer and we will read the new tail\n+                // on the next loop iteration.\n+            } else if (queueOfferPatchTail(tailUpdater, node, tail)) {\n+                break;\n+            }\n+        }\n+    }\n+\n+    private boolean queueOfferPatchTail(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node node,\n+            final Node tail) {\n+        Node currentTail = tailUpdater.get(this);\n+        if (currentTail == tail) {\n+            // tail is stale so attempt to iterate through the linked list and update tail.\n+            currentTail = tail.iterateToTail();\n+            if (currentTail.isPopped()) {\n+                if (tailUpdater.compareAndSet(this, tail, node)) {\n+                    safeProcessSubscribers(node.delayedSource);\n+                    return true;\n+                }\n+            } else {\n+                tailUpdater.compareAndSet(this, tail, currentTail);\n+            }\n+            // Best effort to update/clear the tail, and failure is OK because:\n+            // 1. Another thread is in offer and already patched up the tail pointer and we will read the new\n+            // tail on the next loop iteration.\n+        }\n+        return false;\n+    }\n+\n+    private void queuePop(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node head) {\n+        // This method maybe called multiple times on the same node, in which case next will be EMPTY_NODE and the run\n+        // method will be a noop.\n+        Node next = head.pop();\n+        if (next != null) {\n+            safeProcessSubscribers(next.delayedSource);\n+        } else {\n+            tailUpdater.compareAndSet(this, head, null);\n+            // Best effort to clear the tail, and failure is OK because:\n+            // 1. Another thread appended this head, but has not yet updated the tail. In this case the tail will be\n+            // stale (e.g. pointing to head node that has already been processed) and corrected by future inserts.\n+        }\n+    }\n+\n+    private void safeProcessSubscribers(Runnable delayedSource) {\n+        try {\n+            delayedSource.run();\n+        } catch (Throwable cause) {\n+            connection.closeAsync().subscribe();\n+            LOGGER.warn(\"closing connection={} due to unexpected error on subscribe\", connection, cause);\n+        }\n+    }\n+\n+    /**\n+     * Logically equivalent to {@link Publisher#afterFinally(Runnable)} but relies upon internal queue CAS operations\n+     * to prevent multiple executions (e.g. reduces a CAS operation).\n+     */\n+    private final class ReadPopNextOperator implements PublisherOperator<Resp, Resp> {\n+        private final Node readNode;\n+\n+        private ReadPopNextOperator(final Node readNode) {\n+            this.readNode = readNode;\n+        }\n+\n+        @Override\n+        public PublisherSource.Subscriber<? super Resp> apply(PublisherSource.Subscriber<? super Resp> subscriber) {\n+            return new PublisherSource.Subscriber<Resp>() {\n+                @Override\n+                public void onSubscribe(final PublisherSource.Subscription subscription) {\n+                    subscriber.onSubscribe(new PublisherSource.Subscription() {\n+                        @Override\n+                        public void request(final long n) {\n+                            subscription.request(n);\n+                        }\n+\n+                        @Override\n+                        public void cancel() {\n+                            try {\n+                                subscription.cancel();\n+                            } finally {\n+                                pollNext();\n+                            }\n+                        }\n+                    });\n+                }\n+\n+                @Override\n+                public void onNext(@Nullable final Resp t) {\n+                    subscriber.onNext(t);\n+                }\n+\n+                @Override\n+                public void onError(final Throwable t) {\n+                    try {\n+                        subscriber.onError(t);\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+\n+                @Override\n+                public void onComplete() {\n+                    try {\n+                        subscriber.onComplete();\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+\n+                private void pollNext() {\n+                    queuePop(readQueueTailUpdater, readNode);\n+                }\n+            };\n+        }\n+    }\n+\n+    /**\n+     * Logically equivalent to {@link Completable#afterFinally(Runnable)} but relies upon internal queue CAS operations\n+     * to prevent multiple executions (e.g. reduces a CAS operation).\n+     */\n+    private final class WritePopNextOperator implements CompletableOperator {\n+        private final Node writeNode;\n+\n+        WritePopNextOperator(final Node writeNode) {\n+            this.writeNode = writeNode;\n+        }\n+\n+        @Override\n+        public CompletableSource.Subscriber apply(final CompletableSource.Subscriber subscriber) {\n+            return new CompletableSource.Subscriber() {\n+                @Override\n+                public void onSubscribe(final Cancellable cancellable) {\n+                    subscriber.onSubscribe(() -> {\n+                        try {\n+                            cancellable.cancel();\n+                        } finally {\n+                            pollNext();\n+                        }\n+                    });\n+                }\n+\n+                @Override\n+                public void onComplete() {\n+                    try {\n+                        subscriber.onComplete();\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(final Throwable t) {\n+                    try {\n+                        subscriber.onError(t);\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+            };\n+        }\n+\n+        private void pollNext() {\n+            queuePop(writeQueueTailUpdater, writeNode);\n+        }\n+    }\n+\n+    private static final class Node {\n+        private static final Node EMPTY_NODE = new Node();\n+        private static final AtomicReferenceFieldUpdater<Node, Node> nextUpdater =\n+                newUpdater(Node.class, Node.class, \"next\");\n+        @Nullable\n+        private volatile Node next;\n+        final Runnable delayedSource;\n+\n+        Node(Runnable delayedSource) {\n+            this.delayedSource = requireNonNull(delayedSource);\n+        }\n+\n+        private Node() {\n+            this.next = this;\n+            this.delayedSource = () -> { };\n+        }\n+\n+        boolean append(Node next) {\n+            return nextUpdater.compareAndSet(this, null, next);\n+        }\n+\n+        @Nullable\n+        Node pop() {\n+            return nextUpdater.getAndSet(this, EMPTY_NODE);\n+        }\n+\n+        boolean isPopped() {\n+            return next == EMPTY_NODE;\n+        }\n+\n+        Node iterateToTail() {\n+            Node prev = this;\n+            Node next = prev.next;\n+            while (next != null) {\n+                prev = next;\n+                next = next.next;\n+            }\n+            return prev;\n+        }\n+    }\n+\n+    private static final class DelayedSubscribeCompletable extends Completable {", "originalCommit": "7469332830d536d9dc82b82bad56e4860a3caf7e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjgzNTM2Mg==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r396835362", "bodyText": "I wanted to keep the new API exposure for the NettyPipelinedConnection low for now, but I think this is worth revisiting as part of the larger \"how is state propagated on the server #981\" which may provide opportunities to clean this up.", "author": "Scottmitch", "createdAt": "2020-03-24T00:20:28Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/PipelinedStreamingHttpConnection.java", "diffHunk": "@@ -19,38 +19,35 @@\n import io.servicetalk.concurrent.api.Publisher;\n import io.servicetalk.http.api.HttpExecutionContext;\n import io.servicetalk.http.api.StreamingHttpRequestResponseFactory;\n-import io.servicetalk.transport.netty.internal.DefaultNettyPipelinedConnection;\n import io.servicetalk.transport.netty.internal.FlushStrategy;\n import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n \n import javax.annotation.Nullable;\n \n final class PipelinedStreamingHttpConnection\n-        extends AbstractStreamingHttpConnection<DefaultNettyPipelinedConnection<Object, Object>> {\n-\n-    private final NettyConnection<Object, Object> nettyConnection;\n-\n+        extends AbstractStreamingHttpConnection<NettyPipelinedConnection<Object, Object>> {\n     PipelinedStreamingHttpConnection(final NettyConnection<Object, Object> connection,\n                                      final H1ProtocolConfig config,\n                                      final HttpExecutionContext executionContext,\n                                      final StreamingHttpRequestResponseFactory reqRespFactory) {\n-        super(new DefaultNettyPipelinedConnection<>(connection, config.maxPipelinedRequests()),\n+        super(new NettyPipelinedConnection<>(connection),\n                 config.maxPipelinedRequests(), executionContext, reqRespFactory, config.headersFactory());\n-        this.nettyConnection = connection;\n     }\n \n     @Override\n     protected Publisher<Object> writeAndRead(Publisher<Object> requestStream,\n                                              @Nullable final FlushStrategy flushStrategy) {\n         if (flushStrategy == null) {\n-            return connection.request(requestStream);\n+            return connection.write(requestStream, connection::defaultFlushStrategy,", "originalCommit": "7469332830d536d9dc82b82bad56e4860a3caf7e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjgzNTY4Nw==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r396835687", "bodyText": "this is also related to the larger \"state management on the server\" discussion too #981", "author": "Scottmitch", "createdAt": "2020-03-24T00:21:33Z", "path": "servicetalk-transport-netty-internal/src/main/java/io/servicetalk/transport/netty/internal/DefaultNettyConnection.java", "diffHunk": "@@ -537,6 +503,8 @@ public void channelWritabilityChanged(ChannelHandlerContext ctx) {\n             if (ctx.channel().isWritable()) {\n                 connection.channelOutboundListener.channelWritable();\n             } else if (connection.flushStrategyHolder.currentStrategy().shouldFlushOnUnwritable()) {\n+                // TODO(scott): if we have a flush per write operation, shouldFlushOnUnwritable is more challenging.", "originalCommit": "7469332830d536d9dc82b82bad56e4860a3caf7e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzUzMDk3Nw==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r397530977", "bodyText": "shouldFlushOnUnwritable is to handle the case when we do not request more data to write because the channel buffer is full which in turn does not generate flush signals as there is no write activity. I think it still makes sense to consider that so that strategies like flush-on-end do not get deadlocked.", "author": "NiteshKant", "createdAt": "2020-03-24T23:52:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjgzNTY4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODQwNTkwNA==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r398405904", "bodyText": "more investigation is required, so wanted to make a mental note. however if this is the only thing preventing shifting to a model of flush-on-request I would be willing to compromise on this (assuming we can just always flush in this scenario or otherwise avoid deadlock).", "author": "Scottmitch", "createdAt": "2020-03-26T08:54:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjgzNTY4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzUzNjEzOQ==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r397536139", "bodyText": "nit:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public static WriteDemandEstimator newDefaultEstimator() {\n          \n          \n            \n                public static WriteDemandEstimator defaultEstimator() {", "author": "NiteshKant", "createdAt": "2020-03-25T00:09:12Z", "path": "servicetalk-transport-netty-internal/src/main/java/io/servicetalk/transport/netty/internal/WriteDemandEstimators.java", "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.transport.netty.internal;\n+\n+/**\n+ * Utility methods associated with {@link WriteDemandEstimator}.\n+ */\n+public final class WriteDemandEstimators {\n+    private WriteDemandEstimators() {\n+        // no instance\n+    }\n+\n+    /**\n+     * Returns a new instance of a default implementation of {@link WriteDemandEstimator}.\n+     *\n+     * @return A new instance of a default implementation of {@link WriteDemandEstimator}.\n+     */\n+    public static WriteDemandEstimator newDefaultEstimator() {", "originalCommit": "7469332830d536d9dc82b82bad56e4860a3caf7e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzUzNjc2NA==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r397536764", "bodyText": "Is the intent here to add utility methods or just have this as a static factory for WriteDemandEstimator as elsewhere?\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n             * Utility methods associated with {@link WriteDemandEstimator}.\n          \n          \n            \n             * Factory to create instances of {@link WriteDemandEstimator}s", "author": "NiteshKant", "createdAt": "2020-03-25T00:11:07Z", "path": "servicetalk-transport-netty-internal/src/main/java/io/servicetalk/transport/netty/internal/WriteDemandEstimators.java", "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.transport.netty.internal;\n+\n+/**\n+ * Utility methods associated with {@link WriteDemandEstimator}.", "originalCommit": "7469332830d536d9dc82b82bad56e4860a3caf7e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODcyOTQ3Nw==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r398729477", "bodyText": "the motivation was to decouple utility/factory methods from the interface definition. there is currently only a single factory method but if there are alternative implementations or utilities later this provides a place for them to be exposed.", "author": "Scottmitch", "createdAt": "2020-03-26T16:50:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzUzNjc2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU0MDAzMA==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r397540030", "bodyText": "Specify a FlushStrategy (eg: flushOnEnd()) here to be comparable to writeAndFlush before?", "author": "NiteshKant", "createdAt": "2020-03-25T00:21:50Z", "path": "servicetalk-tcp-netty-internal/src/test/java/io/servicetalk/tcp/netty/internal/TcpServerBinderConnectionAcceptorTest.java", "diffHunk": "@@ -147,7 +148,7 @@ public void testAcceptConnection() {\n         try {\n             NettyConnection<Buffer, Buffer> connection = client.connectBlocking(CLIENT_CTX, serverAddress);\n             final Buffer buffer = connection.executionContext().bufferAllocator().fromAscii(\"Hello\");\n-            connection.writeAndFlush(buffer).toFuture().get();\n+            connection.write(Publisher.from(buffer)).toFuture().get();", "originalCommit": "7469332830d536d9dc82b82bad56e4860a3caf7e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODczNDk2MQ==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r398734961", "bodyText": "flushOnEach() is the default strategy, and this test isn't trying to test flushing strategies, so I think it makes things simpler to not try to change the flush strategy.", "author": "Scottmitch", "createdAt": "2020-03-26T16:58:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU0MDAzMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU0MDI1NA==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r397540254", "bodyText": "Specify a FlushStrategy (eg: flushOnEnd()) here to be comparable to writeAndFlush before?", "author": "NiteshKant", "createdAt": "2020-03-25T00:22:37Z", "path": "servicetalk-tcp-netty-internal/src/test/java/io/servicetalk/tcp/netty/internal/TcpConnectorTest.java", "diffHunk": "@@ -58,7 +59,8 @@ public void testWriteAndRead() throws Exception {\n \n     private static void testWriteAndRead(NettyConnection<Buffer, Buffer> connection)\n             throws ExecutionException, InterruptedException {\n-        connection.writeAndFlush(connection.executionContext().bufferAllocator().fromAscii(\"Hello\")).toFuture().get();\n+        connection.write(", "originalCommit": "7469332830d536d9dc82b82bad56e4860a3caf7e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODczNTEzMQ==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r398735131", "bodyText": "(lets discuss above on #980 (comment))", "author": "Scottmitch", "createdAt": "2020-03-26T16:58:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU0MDI1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU0Mjc2MQ==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r397542761", "bodyText": "Do we know what changed here that made this more deterministic?", "author": "NiteshKant", "createdAt": "2020-03-25T00:31:20Z", "path": "servicetalk-http-netty/src/test/java/io/servicetalk/http/netty/ClientClosureRaceTest.java", "diffHunk": "@@ -122,76 +122,68 @@ public void stopServer() throws Exception {\n \n     @Test\n     public void testSequential() throws Exception {\n-        final HttpClient client = newClientBuilder().build();\n-        runIterations(() -> client.request(client.get(\"/foo\")).flatMap(\n-                response -> client.request(client.get(\"/bar\"))));\n+        try (HttpClient client = newClientBuilder().build()) {\n+            runIterations(() -> client.request(client.get(\"/foo\")).flatMap(\n+                    response -> client.request(client.get(\"/bar\"))));\n+        }\n     }\n \n     @Test\n     public void testSequentialPosts() throws Exception {\n-        final HttpClient client = newClientBuilder().build();\n-        runIterations(() -> client.request(client.post(\"/foo\").payloadBody(\"Some payload\", textSerializer())).flatMap(\n-                response -> client.request(client.post(\"/bar\").payloadBody(\"Another payload\", textSerializer()))));\n+        try (HttpClient client = newClientBuilder().build()) {\n+            runIterations(() ->\n+                    client.request(client.post(\"/foo\").payloadBody(\"Some payload\", textSerializer())).flatMap(\n+                    response -> client.request(client.post(\"/bar\").payloadBody(\"Another payload\", textSerializer()))));\n+        }\n     }\n \n     @Test\n     public void testPipelined() throws Exception {\n-        final HttpClient client = newClientBuilder()\n+        try (HttpClient client = newClientBuilder()\n                 .protocols(h1().maxPipelinedRequests(2).build())\n-                .build();\n-        runIterations(() -> collectUnordered(client.request(client.get(\"/foo\")),\n-                client.request(client.get(\"/bar\"))));\n+                .build()) {\n+            runIterations(() -> collectUnordered(client.request(client.get(\"/foo\")),\n+                    client.request(client.get(\"/bar\"))));\n+        }\n     }\n \n     @Test\n     public void testPipelinedPosts() throws Exception {\n-        final HttpClient client = newClientBuilder()\n+        try (HttpClient client = newClientBuilder()\n                 .protocols(h1().maxPipelinedRequests(2).build())\n-                .build();\n-        runIterations(() -> collectUnordered(\n-                client.request(client.get(\"/foo\").payloadBody(\"Some payload\", textSerializer())),\n-                client.request(client.get(\"/bar\").payloadBody(\"Another payload\", textSerializer()))));\n+                .build()) {\n+            runIterations(() -> collectUnordered(\n+                    client.request(client.get(\"/foo\").payloadBody(\"Some payload\", textSerializer())),\n+                    client.request(client.get(\"/bar\").payloadBody(\"Another payload\", textSerializer()))));\n+        }\n     }\n \n     private void runIterations(Callable<Single<?>> test) throws Exception {\n         int count = 0;\n         try {\n-            while (!receivedExpectedError && count < ITERATIONS) {\n-                try {\n-                    count++;\n-                    Object response = test.call().toFuture().get();\n-                    LOGGER.debug(\"Response {} = {}\", count, response);\n-                } catch (Exception e) {\n-                    if (isAllowableError(e)) {", "originalCommit": "7469332830d536d9dc82b82bad56e4860a3caf7e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODczNjkwMg==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r398736902", "bodyText": "The retry strategy changed [1]. We no longer expect exceptions and instead rely upon timeouts.\n[1]\n\nClientClosureRaceTest is intentionally closing the server connection\nabrubtley, which may result in writing a request that is not\nautomatically retryable. The retry strategy should always retry in this\ncase or else the test may hang/fail.", "author": "Scottmitch", "createdAt": "2020-03-26T17:00:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU0Mjc2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU0OTQ4MA==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r397549480", "bodyText": "Doesn't using connection::defaultFlushStrategy here means we will not use the strategy updated above using updateFlushStrategy()?", "author": "NiteshKant", "createdAt": "2020-03-25T00:55:04Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/PipelinedStreamingHttpConnection.java", "diffHunk": "@@ -19,38 +19,35 @@\n import io.servicetalk.concurrent.api.Publisher;\n import io.servicetalk.http.api.HttpExecutionContext;\n import io.servicetalk.http.api.StreamingHttpRequestResponseFactory;\n-import io.servicetalk.transport.netty.internal.DefaultNettyPipelinedConnection;\n import io.servicetalk.transport.netty.internal.FlushStrategy;\n import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n \n import javax.annotation.Nullable;\n \n final class PipelinedStreamingHttpConnection\n-        extends AbstractStreamingHttpConnection<DefaultNettyPipelinedConnection<Object, Object>> {\n-\n-    private final NettyConnection<Object, Object> nettyConnection;\n-\n+        extends AbstractStreamingHttpConnection<NettyPipelinedConnection<Object, Object>> {\n     PipelinedStreamingHttpConnection(final NettyConnection<Object, Object> connection,\n                                      final H1ProtocolConfig config,\n                                      final HttpExecutionContext executionContext,\n                                      final StreamingHttpRequestResponseFactory reqRespFactory) {\n-        super(new DefaultNettyPipelinedConnection<>(connection, config.maxPipelinedRequests()),\n+        super(new NettyPipelinedConnection<>(connection),\n                 config.maxPipelinedRequests(), executionContext, reqRespFactory, config.headersFactory());\n-        this.nettyConnection = connection;\n     }\n \n     @Override\n     protected Publisher<Object> writeAndRead(Publisher<Object> requestStream,\n                                              @Nullable final FlushStrategy flushStrategy) {\n         if (flushStrategy == null) {\n-            return connection.request(requestStream);\n+            return connection.write(requestStream, connection::defaultFlushStrategy,\n+                    WriteDemandEstimators::newDefaultEstimator);\n         } else {\n-            // Using the Writer abstraction here defers updating the flush strategy until just before this request is\n-            // written.\n-            return connection.request(() -> {\n+            // TODO(scott): if we can remove the flush state on the connection we can simplify the control flow here.\n+            return Publisher.defer(() -> {\n                 final Cancellable resetFlushStrategy = connection.updateFlushStrategy(\n                         (prev, isOriginal) -> isOriginal ? flushStrategy : prev);\n-                return nettyConnection.write(requestStream).afterFinally(resetFlushStrategy::cancel);\n+                return connection.write(requestStream, connection::defaultFlushStrategy,", "originalCommit": "7469332830d536d9dc82b82bad56e4860a3caf7e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODc2ODAxMQ==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r398768011", "bodyText": "the control flow for flushing is complicated, and something I want to explore improving as part of #981, but I wanted to keep the scope of this PR limited.\nthe flush strategy passed in will get conditionally applied via connection.updateFlushStrategy and may not always be applied depending upon the current connection level flush strategy which maybe set externally on the connection see FlushStrategyForClientApiTest#aggregatedApiShouldNotOverrideExplicit.", "author": "Scottmitch", "createdAt": "2020-03-26T17:43:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU0OTQ4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg1MDE4NA==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r403850184", "bodyText": "ok connection::defaultFlushStrategy returns the last updated strategy, nevermind.", "author": "NiteshKant", "createdAt": "2020-04-06T06:13:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU0OTQ4MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU1MDMzNg==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r397550336", "bodyText": "Can we provide connection.write(requestStream) also on the pipelined connection so that the defaults are left to the actual NettyConnection implementation?", "author": "NiteshKant", "createdAt": "2020-03-25T00:58:04Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/PipelinedStreamingHttpConnection.java", "diffHunk": "@@ -19,38 +19,35 @@\n import io.servicetalk.concurrent.api.Publisher;\n import io.servicetalk.http.api.HttpExecutionContext;\n import io.servicetalk.http.api.StreamingHttpRequestResponseFactory;\n-import io.servicetalk.transport.netty.internal.DefaultNettyPipelinedConnection;\n import io.servicetalk.transport.netty.internal.FlushStrategy;\n import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n \n import javax.annotation.Nullable;\n \n final class PipelinedStreamingHttpConnection\n-        extends AbstractStreamingHttpConnection<DefaultNettyPipelinedConnection<Object, Object>> {\n-\n-    private final NettyConnection<Object, Object> nettyConnection;\n-\n+        extends AbstractStreamingHttpConnection<NettyPipelinedConnection<Object, Object>> {\n     PipelinedStreamingHttpConnection(final NettyConnection<Object, Object> connection,\n                                      final H1ProtocolConfig config,\n                                      final HttpExecutionContext executionContext,\n                                      final StreamingHttpRequestResponseFactory reqRespFactory) {\n-        super(new DefaultNettyPipelinedConnection<>(connection, config.maxPipelinedRequests()),\n+        super(new NettyPipelinedConnection<>(connection),\n                 config.maxPipelinedRequests(), executionContext, reqRespFactory, config.headersFactory());\n-        this.nettyConnection = connection;\n     }\n \n     @Override\n     protected Publisher<Object> writeAndRead(Publisher<Object> requestStream,\n                                              @Nullable final FlushStrategy flushStrategy) {\n         if (flushStrategy == null) {\n-            return connection.request(requestStream);\n+            return connection.write(requestStream, connection::defaultFlushStrategy,", "originalCommit": "7469332830d536d9dc82b82bad56e4860a3caf7e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODc3MDQ1NQ==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r398770455", "bodyText": "done. minor clarification we are dealing with a NettyPipelinedConnection which wraps a NettyConnection but is not itself a NettyConnection. related discussion above #980 (comment)", "author": "Scottmitch", "createdAt": "2020-03-26T17:47:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU1MDMzNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzYxOTAzMA==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r397619030", "bodyText": "Hmm ... can this handle multiple requests in the same Publisher?", "author": "NiteshKant", "createdAt": "2020-03-25T05:38:12Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+\n+import io.netty.channel.Channel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Arrays;\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(NettyPipelinedConnection.class);\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            writeQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"writeQueueTail\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            readQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"readQueueTail\");\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node writeQueueTail;\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node readQueueTail;\n+\n+    private final NettyConnection<Resp, Req> connection;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} producing the request(s) to write.", "originalCommit": "7469332830d536d9dc82b82bad56e4860a3caf7e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODc3MzEyMQ==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r398773121", "bodyText": "reworded. ptal.", "author": "Scottmitch", "createdAt": "2020-03-26T17:51:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzYxOTAzMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzYyNzEyMQ==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r397627121", "bodyText": "Won't this cause overlapping subscribes to connection.read()?\nIt seems this path is not covered in tests too.", "author": "NiteshKant", "createdAt": "2020-03-25T06:09:58Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+\n+import io.netty.channel.Channel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Arrays;\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(NettyPipelinedConnection.class);\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            writeQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"writeQueueTail\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            readQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"readQueueTail\");\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node writeQueueTail;\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node readQueueTail;\n+\n+    private final NettyConnection<Resp, Req> connection;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} producing the request(s) to write.\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        return Publisher.defer(() -> {\n+            // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+\n+            // Setup read side publisher and nodes\n+            DelayedSubscribePublisher<Resp> delayedResponsePublisher = new DelayedSubscribePublisher<>(\n+                    toSource(connection.read()));\n+            Node readNode = new Node(delayedResponsePublisher::processSubscribers);\n+            Publisher<Resp> composedResponsePublisher =\n+                    delayedResponsePublisher.liftSync(new ReadPopNextOperator(readNode));\n+\n+            // Setup write side publisher and nodes\n+            DelayedSubscribeCompletable delayedRequestCompletable = new DelayedSubscribeCompletable(toSource(\n+                            connection.write(requestPublisher, flushStrategySupplier, writeDemandEstimatorSupplier)));\n+            Node writeNode = new Node(() -> {\n+                try {\n+                    queueOffer(readQueueTailUpdater, readNode);\n+                } finally {\n+                    delayedRequestCompletable.processSubscribers();\n+                }\n+            });\n+\n+            queueOffer(writeQueueTailUpdater, writeNode);\n+\n+            return delayedRequestCompletable.liftSync(new WritePopNextOperator(writeNode))\n+                    // If there is an error on the read/write side we propagate the errors between the two via merge.\n+                    .merge(composedResponsePublisher);\n+        });\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void queueOffer(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node node) {\n+        for (;;) {\n+            Node tail = tailUpdater.get(this);\n+            if (tail == null) {\n+                if (tailUpdater.compareAndSet(this, null, node)) {\n+                    // node has been inserted and is the only node, we initiate processing.\n+                    safeProcessSubscribers(node.delayedSource);\n+                    break;\n+                }\n+                // Another thread won the race to offer a node, loop around and try again.\n+            } else if (tail.append(node)) {\n+                // Make the newly appended node visible as the tail. This is a best effort CAS and may fail because:\n+                // 1. Another thread is also inserting, has a stale tail, followed its existing tail links, and updated\n+                // the tail reference via queueOfferPatchTail.\n+                // 2. The consumer thread has seen the link from the old tail to the new node, processed node,\n+                // popped node from the list (updated node's next to point to EMPTY_NODE), another producer thread\n+                // appends a new node, sees the tail is popped, and updates the tail reference via CAS.\n+                tailUpdater.compareAndSet(this, tail, node);\n+                break;\n+            } else if (tail.isPopped()) {\n+                // A previously appended node was processed, and popped before updating the tail after append. In that\n+                // case the tail maybe pointing to an invalid node and we clear it out.\n+                if (tailUpdater.compareAndSet(this, tail, node)) {\n+                    safeProcessSubscribers(node.delayedSource);\n+                    break;\n+                }\n+                // Best effort to clear the tail, and failure is OK because:\n+                // 1. Another thread is in offer and already patched up the tail pointer and we will read the new tail\n+                // on the next loop iteration.\n+            } else if (queueOfferPatchTail(tailUpdater, node, tail)) {\n+                break;\n+            }\n+        }\n+    }\n+\n+    private boolean queueOfferPatchTail(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node node,\n+            final Node tail) {\n+        Node currentTail = tailUpdater.get(this);\n+        if (currentTail == tail) {\n+            // tail is stale so attempt to iterate through the linked list and update tail.\n+            currentTail = tail.iterateToTail();\n+            if (currentTail.isPopped()) {\n+                if (tailUpdater.compareAndSet(this, tail, node)) {\n+                    safeProcessSubscribers(node.delayedSource);\n+                    return true;\n+                }\n+            } else {\n+                tailUpdater.compareAndSet(this, tail, currentTail);\n+            }\n+            // Best effort to update/clear the tail, and failure is OK because:\n+            // 1. Another thread is in offer and already patched up the tail pointer and we will read the new\n+            // tail on the next loop iteration.\n+        }\n+        return false;\n+    }\n+\n+    private void queuePop(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node head) {\n+        // This method maybe called multiple times on the same node, in which case next will be EMPTY_NODE and the run\n+        // method will be a noop.\n+        Node next = head.pop();\n+        if (next != null) {\n+            safeProcessSubscribers(next.delayedSource);\n+        } else {\n+            tailUpdater.compareAndSet(this, head, null);\n+            // Best effort to clear the tail, and failure is OK because:\n+            // 1. Another thread appended this head, but has not yet updated the tail. In this case the tail will be\n+            // stale (e.g. pointing to head node that has already been processed) and corrected by future inserts.\n+        }\n+    }\n+\n+    private void safeProcessSubscribers(Runnable delayedSource) {\n+        try {\n+            delayedSource.run();\n+        } catch (Throwable cause) {\n+            connection.closeAsync().subscribe();\n+            LOGGER.warn(\"closing connection={} due to unexpected error on subscribe\", connection, cause);\n+        }\n+    }\n+\n+    /**\n+     * Logically equivalent to {@link Publisher#afterFinally(Runnable)} but relies upon internal queue CAS operations\n+     * to prevent multiple executions (e.g. reduces a CAS operation).\n+     */\n+    private final class ReadPopNextOperator implements PublisherOperator<Resp, Resp> {\n+        private final Node readNode;\n+\n+        private ReadPopNextOperator(final Node readNode) {\n+            this.readNode = readNode;\n+        }\n+\n+        @Override\n+        public PublisherSource.Subscriber<? super Resp> apply(PublisherSource.Subscriber<? super Resp> subscriber) {\n+            return new PublisherSource.Subscriber<Resp>() {\n+                @Override\n+                public void onSubscribe(final PublisherSource.Subscription subscription) {\n+                    subscriber.onSubscribe(new PublisherSource.Subscription() {\n+                        @Override\n+                        public void request(final long n) {\n+                            subscription.request(n);\n+                        }\n+\n+                        @Override\n+                        public void cancel() {\n+                            try {\n+                                subscription.cancel();\n+                            } finally {\n+                                pollNext();\n+                            }\n+                        }\n+                    });\n+                }\n+\n+                @Override\n+                public void onNext(@Nullable final Resp t) {\n+                    subscriber.onNext(t);\n+                }\n+\n+                @Override\n+                public void onError(final Throwable t) {\n+                    try {\n+                        subscriber.onError(t);\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+\n+                @Override\n+                public void onComplete() {\n+                    try {\n+                        subscriber.onComplete();\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+\n+                private void pollNext() {\n+                    queuePop(readQueueTailUpdater, readNode);\n+                }\n+            };\n+        }\n+    }\n+\n+    /**\n+     * Logically equivalent to {@link Completable#afterFinally(Runnable)} but relies upon internal queue CAS operations\n+     * to prevent multiple executions (e.g. reduces a CAS operation).\n+     */\n+    private final class WritePopNextOperator implements CompletableOperator {\n+        private final Node writeNode;\n+\n+        WritePopNextOperator(final Node writeNode) {\n+            this.writeNode = writeNode;\n+        }\n+\n+        @Override\n+        public CompletableSource.Subscriber apply(final CompletableSource.Subscriber subscriber) {\n+            return new CompletableSource.Subscriber() {\n+                @Override\n+                public void onSubscribe(final Cancellable cancellable) {\n+                    subscriber.onSubscribe(() -> {\n+                        try {\n+                            cancellable.cancel();\n+                        } finally {\n+                            pollNext();\n+                        }\n+                    });\n+                }\n+\n+                @Override\n+                public void onComplete() {\n+                    try {\n+                        subscriber.onComplete();\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(final Throwable t) {\n+                    try {\n+                        subscriber.onError(t);\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+            };\n+        }\n+\n+        private void pollNext() {\n+            queuePop(writeQueueTailUpdater, writeNode);\n+        }\n+    }\n+\n+    private static final class Node {\n+        private static final Node EMPTY_NODE = new Node();\n+        private static final AtomicReferenceFieldUpdater<Node, Node> nextUpdater =\n+                newUpdater(Node.class, Node.class, \"next\");\n+        @Nullable\n+        private volatile Node next;\n+        final Runnable delayedSource;\n+\n+        Node(Runnable delayedSource) {\n+            this.delayedSource = requireNonNull(delayedSource);\n+        }\n+\n+        private Node() {\n+            this.next = this;\n+            this.delayedSource = () -> { };\n+        }\n+\n+        boolean append(Node next) {\n+            return nextUpdater.compareAndSet(this, null, next);\n+        }\n+\n+        @Nullable\n+        Node pop() {\n+            return nextUpdater.getAndSet(this, EMPTY_NODE);\n+        }\n+\n+        boolean isPopped() {\n+            return next == EMPTY_NODE;\n+        }\n+\n+        Node iterateToTail() {\n+            Node prev = this;\n+            Node next = prev.next;\n+            while (next != null) {\n+                prev = next;\n+                next = next.next;\n+            }\n+            return prev;\n+        }\n+    }\n+\n+    private static final class DelayedSubscribeCompletable extends Completable {\n+        private static final AtomicReferenceFieldUpdater<DelayedSubscribeCompletable, Object> stateUpdater =\n+                newUpdater(DelayedSubscribeCompletable.class, Object.class, \"state\");\n+        private static final Object ALLOW_SUBSCRIBE = new Object();\n+        private static final Object DRAINING_SUBSCRIBERS = new Object();\n+\n+        private final CompletableSource completable;\n+        /**\n+         * One of the following:\n+         * <li>\n+         *     <ul>{@code null} - initial state</ul>\n+         *     <ul>{@link #ALLOW_SUBSCRIBE} - {@link #handleSubscribe(CompletableSource.Subscriber)} methods will\n+         *     pass through to {@link #completable}</ul>\n+         *     <ul>{@link #DRAINING_SUBSCRIBERS} - set in {@link #processSubscribers()} while calling\n+         *     {@link CompletableSource#subscribe(CompletableSource.Subscriber)} on each {@link Completable}</ul>\n+         *     <ul>{@link CompletableSource.Subscriber} - if there is a single\n+         *     {@link #handleSubscribe(CompletableSource.Subscriber)} pending</ul>\n+         *     <ul>{@code Object[]} - if there are multiple {@link #handleSubscribe(CompletableSource.Subscriber)}\n+         *     calls pending</ul>\n+         * </li>\n+         */\n+        @Nullable\n+        private volatile Object state;\n+\n+        private DelayedSubscribeCompletable(final CompletableSource completable) {\n+            this.completable = requireNonNull(completable);\n+        }\n+\n+        void processSubscribers() {\n+            for (;;) {\n+                Object currentState = state;\n+                if (currentState == null) {\n+                    if (stateUpdater.compareAndSet(this, null, ALLOW_SUBSCRIBE)) {\n+                        break;\n+                    }\n+                } else if (currentState == ALLOW_SUBSCRIBE) {\n+                    break;\n+                } else if (currentState instanceof CompletableSource.Subscriber) {\n+                    CompletableSource.Subscriber currentSubscriber = (CompletableSource.Subscriber) currentState;\n+                    if (stateUpdater.compareAndSet(this, currentState, DRAINING_SUBSCRIBERS)) {\n+                        completable.subscribe(currentSubscriber);\n+                        if (stateUpdater.compareAndSet(this, DRAINING_SUBSCRIBERS, ALLOW_SUBSCRIBE)) {\n+                            break;\n+                        }\n+                    }\n+                } else if (stateUpdater.compareAndSet(this, currentState, DRAINING_SUBSCRIBERS)) {\n+                    assert currentState != DRAINING_SUBSCRIBERS;\n+                    CompletableSource.Subscriber[] queue = (CompletableSource.Subscriber[]) currentState;\n+                    for (CompletableSource.Subscriber next : queue) {\n+                        completable.subscribe(next);\n+                    }\n+                    if (stateUpdater.compareAndSet(this, DRAINING_SUBSCRIBERS, ALLOW_SUBSCRIBE)) {\n+                        break;\n+                    }\n+                }\n+            }\n+        }\n+\n+        @Override\n+        protected void handleSubscribe(final CompletableSource.Subscriber subscriber) {\n+            for (;;) {\n+                Object currentState = state;\n+                if (currentState == null || currentState == DRAINING_SUBSCRIBERS) {\n+                    if (stateUpdater.compareAndSet(this, currentState, subscriber)) {\n+                        break;\n+                    }\n+                } else if (currentState == ALLOW_SUBSCRIBE) {\n+                    completable.subscribe(subscriber);\n+                    break;\n+                } else if (currentState instanceof CompletableSource.Subscriber) {\n+                    // Ideally we can propagate the onSubscribe ASAP to allow for cancellation but this completable is\n+                    // designed to defer the subscribe until some other condition occurs, so no work will actually be\n+                    // done until that later time.\n+                    CompletableSource.Subscriber currentSubscriber = (CompletableSource.Subscriber) currentState;\n+                    if (stateUpdater.compareAndSet(this, currentState,\n+                            new Object[] {currentSubscriber, subscriber})) {\n+                        break;\n+                    }\n+                } else {\n+                    Object[] array = (Object[]) currentState;\n+                    // Unmodifiable collection to avoid issues with concurrent adding/draining with processSubscribers.\n+                    // The expected cardinality of the array will be low, so copy/resize is \"good enough\" for now.\n+                    Object[] newArray = Arrays.copyOf(array, array.length + 1);\n+                    newArray[array.length] = subscriber;\n+                    if (stateUpdater.compareAndSet(this, currentState, newArray)) {\n+                        break;\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    private static final class DelayedSubscribePublisher<T> extends Publisher<T> {\n+        @SuppressWarnings(\"rawtypes\")\n+        private static final AtomicReferenceFieldUpdater<DelayedSubscribePublisher, Object> stateUpdater =\n+                newUpdater(DelayedSubscribePublisher.class, Object.class, \"state\");\n+        private static final Object ALLOW_SUBSCRIBE = new Object();\n+        private static final Object DRAINING_SUBSCRIBERS = new Object();\n+\n+        private final PublisherSource<T> publisher;\n+        /**\n+         * One of the following:\n+         * <li>\n+         *     <ul>{@code null} - initial state</ul>\n+         *     <ul>{@link #ALLOW_SUBSCRIBE} - {@link #handleSubscribe(PublisherSource.Subscriber)} methods will\n+         *     pass through to {@link #publisher}</ul>\n+         *     <ul>{@link #DRAINING_SUBSCRIBERS} - set in {@link #processSubscribers()} while calling\n+         *     {@link PublisherSource#subscribe(PublisherSource.Subscriber)} on each {@link Publisher}</ul>\n+         *     <ul>{@link PublisherSource.Subscriber} - if there is a single\n+         *     {@link #handleSubscribe(PublisherSource.Subscriber)} pending</ul>\n+         *     <ul>{@code Object[]} - if there are multiple {@link #handleSubscribe(PublisherSource.Subscriber)}\n+         *     calls pending</ul>\n+         * </li>\n+         */\n+        @Nullable\n+        private volatile Object state;\n+\n+        DelayedSubscribePublisher(final PublisherSource<T> publisher) {\n+            this.publisher = requireNonNull(publisher);\n+        }\n+\n+        void processSubscribers() {\n+            for (;;) {\n+                Object currentState = state;\n+                if (currentState == null) {\n+                    if (stateUpdater.compareAndSet(this, null, ALLOW_SUBSCRIBE)) {\n+                        break;\n+                    }\n+                } else if (currentState == ALLOW_SUBSCRIBE) {\n+                    break;\n+                } else if (currentState instanceof PublisherSource.Subscriber) {\n+                    @SuppressWarnings(\"unchecked\")\n+                    PublisherSource.Subscriber<? super T> currentSubscriber =\n+                            (PublisherSource.Subscriber<? super T>) currentState;\n+                    if (stateUpdater.compareAndSet(this, currentState, DRAINING_SUBSCRIBERS)) {\n+                        publisher.subscribe(currentSubscriber);\n+                        if (stateUpdater.compareAndSet(this, DRAINING_SUBSCRIBERS, ALLOW_SUBSCRIBE)) {\n+                            break;\n+                        }\n+                    }\n+                } else if (stateUpdater.compareAndSet(this, currentState, DRAINING_SUBSCRIBERS)) {\n+                    assert currentState != DRAINING_SUBSCRIBERS;\n+                    @SuppressWarnings(\"unchecked\")\n+                    PublisherSource.Subscriber<? super T>[] queue =\n+                            (PublisherSource.Subscriber<? super T>[]) currentState;\n+                    for (PublisherSource.Subscriber<? super T> next : queue) {\n+                        publisher.subscribe(next);", "originalCommit": "7469332830d536d9dc82b82bad56e4860a3caf7e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODc3NzcwMA==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r398777700", "bodyText": "DelayedSubscribePublisher is meant to be a generic implementation which supports multiple subscribes, and lets the downstream Publisher determine how multiple subscribes are handled. In this case multiple subscribes are not expected.\ndiscussed in #980 (comment) ... I could extract this to concurrent.api.internal package and add tests targeted at this class but not sure it is worth the additional API exposure with just a single use case. wdyt?", "author": "Scottmitch", "createdAt": "2020-03-26T17:57:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzYyNzEyMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODc4MTg2Mw==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r398781863", "bodyText": "I will at least extract these delayed* classes and write tests for them ... we can then discuss if they should live in concurrent.api.internal or just stay local to http package for now.", "author": "Scottmitch", "createdAt": "2020-03-26T18:03:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzYyNzEyMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU4MTEyNQ==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r399581125", "bodyText": "(discussed offline with @NiteshKant and clarified control flow)", "author": "Scottmitch", "createdAt": "2020-03-27T23:26:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzYyNzEyMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzk5OTUyMw==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r397999523", "bodyText": "I think in this context it is OK because this is used with merge which will send the onSubscribe(). Also, even if we send the onSubscribe() eagerly we would not want to remove the subscriber from the queue as that may mess up the order: If response was cancelled after writes were done, removing the subscriber here would essentially give out of order responses. So, I think this is just a fine trade-off to reduce complexity of an eager onSubscribe()", "author": "NiteshKant", "createdAt": "2020-03-25T16:36:15Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+\n+import io.netty.channel.Channel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Arrays;\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(NettyPipelinedConnection.class);\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            writeQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"writeQueueTail\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            readQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"readQueueTail\");\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node writeQueueTail;\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node readQueueTail;\n+\n+    private final NettyConnection<Resp, Req> connection;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} producing the request(s) to write.\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        return Publisher.defer(() -> {\n+            // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+\n+            // Setup read side publisher and nodes\n+            DelayedSubscribePublisher<Resp> delayedResponsePublisher = new DelayedSubscribePublisher<>(\n+                    toSource(connection.read()));\n+            Node readNode = new Node(delayedResponsePublisher::processSubscribers);\n+            Publisher<Resp> composedResponsePublisher =\n+                    delayedResponsePublisher.liftSync(new ReadPopNextOperator(readNode));\n+\n+            // Setup write side publisher and nodes\n+            DelayedSubscribeCompletable delayedRequestCompletable = new DelayedSubscribeCompletable(toSource(\n+                            connection.write(requestPublisher, flushStrategySupplier, writeDemandEstimatorSupplier)));\n+            Node writeNode = new Node(() -> {\n+                try {\n+                    queueOffer(readQueueTailUpdater, readNode);\n+                } finally {\n+                    delayedRequestCompletable.processSubscribers();\n+                }\n+            });\n+\n+            queueOffer(writeQueueTailUpdater, writeNode);\n+\n+            return delayedRequestCompletable.liftSync(new WritePopNextOperator(writeNode))\n+                    // If there is an error on the read/write side we propagate the errors between the two via merge.\n+                    .merge(composedResponsePublisher);\n+        });\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void queueOffer(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node node) {\n+        for (;;) {\n+            Node tail = tailUpdater.get(this);\n+            if (tail == null) {\n+                if (tailUpdater.compareAndSet(this, null, node)) {\n+                    // node has been inserted and is the only node, we initiate processing.\n+                    safeProcessSubscribers(node.delayedSource);\n+                    break;\n+                }\n+                // Another thread won the race to offer a node, loop around and try again.\n+            } else if (tail.append(node)) {\n+                // Make the newly appended node visible as the tail. This is a best effort CAS and may fail because:\n+                // 1. Another thread is also inserting, has a stale tail, followed its existing tail links, and updated\n+                // the tail reference via queueOfferPatchTail.\n+                // 2. The consumer thread has seen the link from the old tail to the new node, processed node,\n+                // popped node from the list (updated node's next to point to EMPTY_NODE), another producer thread\n+                // appends a new node, sees the tail is popped, and updates the tail reference via CAS.\n+                tailUpdater.compareAndSet(this, tail, node);\n+                break;\n+            } else if (tail.isPopped()) {\n+                // A previously appended node was processed, and popped before updating the tail after append. In that\n+                // case the tail maybe pointing to an invalid node and we clear it out.\n+                if (tailUpdater.compareAndSet(this, tail, node)) {\n+                    safeProcessSubscribers(node.delayedSource);\n+                    break;\n+                }\n+                // Best effort to clear the tail, and failure is OK because:\n+                // 1. Another thread is in offer and already patched up the tail pointer and we will read the new tail\n+                // on the next loop iteration.\n+            } else if (queueOfferPatchTail(tailUpdater, node, tail)) {\n+                break;\n+            }\n+        }\n+    }\n+\n+    private boolean queueOfferPatchTail(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node node,\n+            final Node tail) {\n+        Node currentTail = tailUpdater.get(this);\n+        if (currentTail == tail) {\n+            // tail is stale so attempt to iterate through the linked list and update tail.\n+            currentTail = tail.iterateToTail();\n+            if (currentTail.isPopped()) {\n+                if (tailUpdater.compareAndSet(this, tail, node)) {\n+                    safeProcessSubscribers(node.delayedSource);\n+                    return true;\n+                }\n+            } else {\n+                tailUpdater.compareAndSet(this, tail, currentTail);\n+            }\n+            // Best effort to update/clear the tail, and failure is OK because:\n+            // 1. Another thread is in offer and already patched up the tail pointer and we will read the new\n+            // tail on the next loop iteration.\n+        }\n+        return false;\n+    }\n+\n+    private void queuePop(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node head) {\n+        // This method maybe called multiple times on the same node, in which case next will be EMPTY_NODE and the run\n+        // method will be a noop.\n+        Node next = head.pop();\n+        if (next != null) {\n+            safeProcessSubscribers(next.delayedSource);\n+        } else {\n+            tailUpdater.compareAndSet(this, head, null);\n+            // Best effort to clear the tail, and failure is OK because:\n+            // 1. Another thread appended this head, but has not yet updated the tail. In this case the tail will be\n+            // stale (e.g. pointing to head node that has already been processed) and corrected by future inserts.\n+        }\n+    }\n+\n+    private void safeProcessSubscribers(Runnable delayedSource) {\n+        try {\n+            delayedSource.run();\n+        } catch (Throwable cause) {\n+            connection.closeAsync().subscribe();\n+            LOGGER.warn(\"closing connection={} due to unexpected error on subscribe\", connection, cause);\n+        }\n+    }\n+\n+    /**\n+     * Logically equivalent to {@link Publisher#afterFinally(Runnable)} but relies upon internal queue CAS operations\n+     * to prevent multiple executions (e.g. reduces a CAS operation).\n+     */\n+    private final class ReadPopNextOperator implements PublisherOperator<Resp, Resp> {\n+        private final Node readNode;\n+\n+        private ReadPopNextOperator(final Node readNode) {\n+            this.readNode = readNode;\n+        }\n+\n+        @Override\n+        public PublisherSource.Subscriber<? super Resp> apply(PublisherSource.Subscriber<? super Resp> subscriber) {\n+            return new PublisherSource.Subscriber<Resp>() {\n+                @Override\n+                public void onSubscribe(final PublisherSource.Subscription subscription) {\n+                    subscriber.onSubscribe(new PublisherSource.Subscription() {\n+                        @Override\n+                        public void request(final long n) {\n+                            subscription.request(n);\n+                        }\n+\n+                        @Override\n+                        public void cancel() {\n+                            try {\n+                                subscription.cancel();\n+                            } finally {\n+                                pollNext();\n+                            }\n+                        }\n+                    });\n+                }\n+\n+                @Override\n+                public void onNext(@Nullable final Resp t) {\n+                    subscriber.onNext(t);\n+                }\n+\n+                @Override\n+                public void onError(final Throwable t) {\n+                    try {\n+                        subscriber.onError(t);\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+\n+                @Override\n+                public void onComplete() {\n+                    try {\n+                        subscriber.onComplete();\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+\n+                private void pollNext() {\n+                    queuePop(readQueueTailUpdater, readNode);\n+                }\n+            };\n+        }\n+    }\n+\n+    /**\n+     * Logically equivalent to {@link Completable#afterFinally(Runnable)} but relies upon internal queue CAS operations\n+     * to prevent multiple executions (e.g. reduces a CAS operation).\n+     */\n+    private final class WritePopNextOperator implements CompletableOperator {\n+        private final Node writeNode;\n+\n+        WritePopNextOperator(final Node writeNode) {\n+            this.writeNode = writeNode;\n+        }\n+\n+        @Override\n+        public CompletableSource.Subscriber apply(final CompletableSource.Subscriber subscriber) {\n+            return new CompletableSource.Subscriber() {\n+                @Override\n+                public void onSubscribe(final Cancellable cancellable) {\n+                    subscriber.onSubscribe(() -> {\n+                        try {\n+                            cancellable.cancel();\n+                        } finally {\n+                            pollNext();\n+                        }\n+                    });\n+                }\n+\n+                @Override\n+                public void onComplete() {\n+                    try {\n+                        subscriber.onComplete();\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(final Throwable t) {\n+                    try {\n+                        subscriber.onError(t);\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+            };\n+        }\n+\n+        private void pollNext() {\n+            queuePop(writeQueueTailUpdater, writeNode);\n+        }\n+    }\n+\n+    private static final class Node {\n+        private static final Node EMPTY_NODE = new Node();\n+        private static final AtomicReferenceFieldUpdater<Node, Node> nextUpdater =\n+                newUpdater(Node.class, Node.class, \"next\");\n+        @Nullable\n+        private volatile Node next;\n+        final Runnable delayedSource;\n+\n+        Node(Runnable delayedSource) {\n+            this.delayedSource = requireNonNull(delayedSource);\n+        }\n+\n+        private Node() {\n+            this.next = this;\n+            this.delayedSource = () -> { };\n+        }\n+\n+        boolean append(Node next) {\n+            return nextUpdater.compareAndSet(this, null, next);\n+        }\n+\n+        @Nullable\n+        Node pop() {\n+            return nextUpdater.getAndSet(this, EMPTY_NODE);\n+        }\n+\n+        boolean isPopped() {\n+            return next == EMPTY_NODE;\n+        }\n+\n+        Node iterateToTail() {\n+            Node prev = this;\n+            Node next = prev.next;\n+            while (next != null) {\n+                prev = next;\n+                next = next.next;\n+            }\n+            return prev;\n+        }\n+    }\n+\n+    private static final class DelayedSubscribeCompletable extends Completable {\n+        private static final AtomicReferenceFieldUpdater<DelayedSubscribeCompletable, Object> stateUpdater =\n+                newUpdater(DelayedSubscribeCompletable.class, Object.class, \"state\");\n+        private static final Object ALLOW_SUBSCRIBE = new Object();\n+        private static final Object DRAINING_SUBSCRIBERS = new Object();\n+\n+        private final CompletableSource completable;\n+        /**\n+         * One of the following:\n+         * <li>\n+         *     <ul>{@code null} - initial state</ul>\n+         *     <ul>{@link #ALLOW_SUBSCRIBE} - {@link #handleSubscribe(CompletableSource.Subscriber)} methods will\n+         *     pass through to {@link #completable}</ul>\n+         *     <ul>{@link #DRAINING_SUBSCRIBERS} - set in {@link #processSubscribers()} while calling\n+         *     {@link CompletableSource#subscribe(CompletableSource.Subscriber)} on each {@link Completable}</ul>\n+         *     <ul>{@link CompletableSource.Subscriber} - if there is a single\n+         *     {@link #handleSubscribe(CompletableSource.Subscriber)} pending</ul>\n+         *     <ul>{@code Object[]} - if there are multiple {@link #handleSubscribe(CompletableSource.Subscriber)}\n+         *     calls pending</ul>\n+         * </li>\n+         */\n+        @Nullable\n+        private volatile Object state;\n+\n+        private DelayedSubscribeCompletable(final CompletableSource completable) {\n+            this.completable = requireNonNull(completable);\n+        }\n+\n+        void processSubscribers() {\n+            for (;;) {\n+                Object currentState = state;\n+                if (currentState == null) {\n+                    if (stateUpdater.compareAndSet(this, null, ALLOW_SUBSCRIBE)) {\n+                        break;\n+                    }\n+                } else if (currentState == ALLOW_SUBSCRIBE) {\n+                    break;\n+                } else if (currentState instanceof CompletableSource.Subscriber) {\n+                    CompletableSource.Subscriber currentSubscriber = (CompletableSource.Subscriber) currentState;\n+                    if (stateUpdater.compareAndSet(this, currentState, DRAINING_SUBSCRIBERS)) {\n+                        completable.subscribe(currentSubscriber);\n+                        if (stateUpdater.compareAndSet(this, DRAINING_SUBSCRIBERS, ALLOW_SUBSCRIBE)) {\n+                            break;\n+                        }\n+                    }\n+                } else if (stateUpdater.compareAndSet(this, currentState, DRAINING_SUBSCRIBERS)) {\n+                    assert currentState != DRAINING_SUBSCRIBERS;\n+                    CompletableSource.Subscriber[] queue = (CompletableSource.Subscriber[]) currentState;\n+                    for (CompletableSource.Subscriber next : queue) {\n+                        completable.subscribe(next);\n+                    }\n+                    if (stateUpdater.compareAndSet(this, DRAINING_SUBSCRIBERS, ALLOW_SUBSCRIBE)) {\n+                        break;\n+                    }\n+                }\n+            }\n+        }\n+\n+        @Override\n+        protected void handleSubscribe(final CompletableSource.Subscriber subscriber) {\n+            for (;;) {\n+                Object currentState = state;\n+                if (currentState == null || currentState == DRAINING_SUBSCRIBERS) {\n+                    if (stateUpdater.compareAndSet(this, currentState, subscriber)) {\n+                        break;\n+                    }\n+                } else if (currentState == ALLOW_SUBSCRIBE) {\n+                    completable.subscribe(subscriber);\n+                    break;\n+                } else if (currentState instanceof CompletableSource.Subscriber) {\n+                    // Ideally we can propagate the onSubscribe ASAP to allow for cancellation but this completable is\n+                    // designed to defer the subscribe until some other condition occurs, so no work will actually be\n+                    // done until that later time.\n+                    CompletableSource.Subscriber currentSubscriber = (CompletableSource.Subscriber) currentState;\n+                    if (stateUpdater.compareAndSet(this, currentState,\n+                            new Object[] {currentSubscriber, subscriber})) {\n+                        break;\n+                    }\n+                } else {\n+                    Object[] array = (Object[]) currentState;\n+                    // Unmodifiable collection to avoid issues with concurrent adding/draining with processSubscribers.\n+                    // The expected cardinality of the array will be low, so copy/resize is \"good enough\" for now.\n+                    Object[] newArray = Arrays.copyOf(array, array.length + 1);\n+                    newArray[array.length] = subscriber;\n+                    if (stateUpdater.compareAndSet(this, currentState, newArray)) {\n+                        break;\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    private static final class DelayedSubscribePublisher<T> extends Publisher<T> {\n+        @SuppressWarnings(\"rawtypes\")\n+        private static final AtomicReferenceFieldUpdater<DelayedSubscribePublisher, Object> stateUpdater =\n+                newUpdater(DelayedSubscribePublisher.class, Object.class, \"state\");\n+        private static final Object ALLOW_SUBSCRIBE = new Object();\n+        private static final Object DRAINING_SUBSCRIBERS = new Object();\n+\n+        private final PublisherSource<T> publisher;\n+        /**\n+         * One of the following:\n+         * <li>\n+         *     <ul>{@code null} - initial state</ul>\n+         *     <ul>{@link #ALLOW_SUBSCRIBE} - {@link #handleSubscribe(PublisherSource.Subscriber)} methods will\n+         *     pass through to {@link #publisher}</ul>\n+         *     <ul>{@link #DRAINING_SUBSCRIBERS} - set in {@link #processSubscribers()} while calling\n+         *     {@link PublisherSource#subscribe(PublisherSource.Subscriber)} on each {@link Publisher}</ul>\n+         *     <ul>{@link PublisherSource.Subscriber} - if there is a single\n+         *     {@link #handleSubscribe(PublisherSource.Subscriber)} pending</ul>\n+         *     <ul>{@code Object[]} - if there are multiple {@link #handleSubscribe(PublisherSource.Subscriber)}\n+         *     calls pending</ul>\n+         * </li>\n+         */\n+        @Nullable\n+        private volatile Object state;\n+\n+        DelayedSubscribePublisher(final PublisherSource<T> publisher) {\n+            this.publisher = requireNonNull(publisher);\n+        }\n+\n+        void processSubscribers() {\n+            for (;;) {\n+                Object currentState = state;\n+                if (currentState == null) {\n+                    if (stateUpdater.compareAndSet(this, null, ALLOW_SUBSCRIBE)) {\n+                        break;\n+                    }\n+                } else if (currentState == ALLOW_SUBSCRIBE) {\n+                    break;\n+                } else if (currentState instanceof PublisherSource.Subscriber) {\n+                    @SuppressWarnings(\"unchecked\")\n+                    PublisherSource.Subscriber<? super T> currentSubscriber =\n+                            (PublisherSource.Subscriber<? super T>) currentState;\n+                    if (stateUpdater.compareAndSet(this, currentState, DRAINING_SUBSCRIBERS)) {\n+                        publisher.subscribe(currentSubscriber);\n+                        if (stateUpdater.compareAndSet(this, DRAINING_SUBSCRIBERS, ALLOW_SUBSCRIBE)) {\n+                            break;\n+                        }\n+                    }\n+                } else if (stateUpdater.compareAndSet(this, currentState, DRAINING_SUBSCRIBERS)) {\n+                    assert currentState != DRAINING_SUBSCRIBERS;\n+                    @SuppressWarnings(\"unchecked\")\n+                    PublisherSource.Subscriber<? super T>[] queue =\n+                            (PublisherSource.Subscriber<? super T>[]) currentState;\n+                    for (PublisherSource.Subscriber<? super T> next : queue) {\n+                        publisher.subscribe(next);\n+                    }\n+                    if (stateUpdater.compareAndSet(this, DRAINING_SUBSCRIBERS, ALLOW_SUBSCRIBE)) {\n+                        break;\n+                    }\n+                }\n+            }\n+        }\n+\n+        @Override\n+        protected void handleSubscribe(final PublisherSource.Subscriber<? super T> subscriber) {\n+            for (;;) {\n+                Object currentState = state;\n+                if (currentState == null || currentState == DRAINING_SUBSCRIBERS) {\n+                    if (stateUpdater.compareAndSet(this, currentState, subscriber)) {\n+                        break;\n+                    }\n+                } else if (currentState == ALLOW_SUBSCRIBE) {\n+                    publisher.subscribe(subscriber);\n+                    break;\n+                } else if (currentState instanceof PublisherSource.Subscriber) {\n+                    // Ideally we can propagate the onSubscribe ASAP to allow for cancellation but this publisher is", "originalCommit": "7469332830d536d9dc82b82bad56e4860a3caf7e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODA0NzM4OQ==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r398047389", "bodyText": "If this delayedSource represents read subscriber which happened to throw then closing the connection will not make sure that we terminate the read side (as the queuing of read might have failed). For such cases, we should make sure that the control flow is completed by propagating the exception to the respective subscribers.", "author": "NiteshKant", "createdAt": "2020-03-25T17:42:14Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+\n+import io.netty.channel.Channel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Arrays;\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(NettyPipelinedConnection.class);\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            writeQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"writeQueueTail\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            readQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"readQueueTail\");\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node writeQueueTail;\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node readQueueTail;\n+\n+    private final NettyConnection<Resp, Req> connection;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} producing the request(s) to write.\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        return Publisher.defer(() -> {\n+            // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+\n+            // Setup read side publisher and nodes\n+            DelayedSubscribePublisher<Resp> delayedResponsePublisher = new DelayedSubscribePublisher<>(\n+                    toSource(connection.read()));\n+            Node readNode = new Node(delayedResponsePublisher::processSubscribers);\n+            Publisher<Resp> composedResponsePublisher =\n+                    delayedResponsePublisher.liftSync(new ReadPopNextOperator(readNode));\n+\n+            // Setup write side publisher and nodes\n+            DelayedSubscribeCompletable delayedRequestCompletable = new DelayedSubscribeCompletable(toSource(\n+                            connection.write(requestPublisher, flushStrategySupplier, writeDemandEstimatorSupplier)));\n+            Node writeNode = new Node(() -> {\n+                try {\n+                    queueOffer(readQueueTailUpdater, readNode);\n+                } finally {\n+                    delayedRequestCompletable.processSubscribers();\n+                }\n+            });\n+\n+            queueOffer(writeQueueTailUpdater, writeNode);\n+\n+            return delayedRequestCompletable.liftSync(new WritePopNextOperator(writeNode))\n+                    // If there is an error on the read/write side we propagate the errors between the two via merge.\n+                    .merge(composedResponsePublisher);\n+        });\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void queueOffer(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node node) {\n+        for (;;) {\n+            Node tail = tailUpdater.get(this);\n+            if (tail == null) {\n+                if (tailUpdater.compareAndSet(this, null, node)) {\n+                    // node has been inserted and is the only node, we initiate processing.\n+                    safeProcessSubscribers(node.delayedSource);\n+                    break;\n+                }\n+                // Another thread won the race to offer a node, loop around and try again.\n+            } else if (tail.append(node)) {\n+                // Make the newly appended node visible as the tail. This is a best effort CAS and may fail because:\n+                // 1. Another thread is also inserting, has a stale tail, followed its existing tail links, and updated\n+                // the tail reference via queueOfferPatchTail.\n+                // 2. The consumer thread has seen the link from the old tail to the new node, processed node,\n+                // popped node from the list (updated node's next to point to EMPTY_NODE), another producer thread\n+                // appends a new node, sees the tail is popped, and updates the tail reference via CAS.\n+                tailUpdater.compareAndSet(this, tail, node);\n+                break;\n+            } else if (tail.isPopped()) {\n+                // A previously appended node was processed, and popped before updating the tail after append. In that\n+                // case the tail maybe pointing to an invalid node and we clear it out.\n+                if (tailUpdater.compareAndSet(this, tail, node)) {\n+                    safeProcessSubscribers(node.delayedSource);\n+                    break;\n+                }\n+                // Best effort to clear the tail, and failure is OK because:\n+                // 1. Another thread is in offer and already patched up the tail pointer and we will read the new tail\n+                // on the next loop iteration.\n+            } else if (queueOfferPatchTail(tailUpdater, node, tail)) {\n+                break;\n+            }\n+        }\n+    }\n+\n+    private boolean queueOfferPatchTail(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node node,\n+            final Node tail) {\n+        Node currentTail = tailUpdater.get(this);\n+        if (currentTail == tail) {\n+            // tail is stale so attempt to iterate through the linked list and update tail.\n+            currentTail = tail.iterateToTail();\n+            if (currentTail.isPopped()) {\n+                if (tailUpdater.compareAndSet(this, tail, node)) {\n+                    safeProcessSubscribers(node.delayedSource);\n+                    return true;\n+                }\n+            } else {\n+                tailUpdater.compareAndSet(this, tail, currentTail);\n+            }\n+            // Best effort to update/clear the tail, and failure is OK because:\n+            // 1. Another thread is in offer and already patched up the tail pointer and we will read the new\n+            // tail on the next loop iteration.\n+        }\n+        return false;\n+    }\n+\n+    private void queuePop(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node head) {\n+        // This method maybe called multiple times on the same node, in which case next will be EMPTY_NODE and the run\n+        // method will be a noop.\n+        Node next = head.pop();\n+        if (next != null) {\n+            safeProcessSubscribers(next.delayedSource);\n+        } else {\n+            tailUpdater.compareAndSet(this, head, null);\n+            // Best effort to clear the tail, and failure is OK because:\n+            // 1. Another thread appended this head, but has not yet updated the tail. In this case the tail will be\n+            // stale (e.g. pointing to head node that has already been processed) and corrected by future inserts.\n+        }\n+    }\n+\n+    private void safeProcessSubscribers(Runnable delayedSource) {\n+        try {\n+            delayedSource.run();\n+        } catch (Throwable cause) {\n+            connection.closeAsync().subscribe();", "originalCommit": "7469332830d536d9dc82b82bad56e4860a3caf7e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDM0MDA2OA==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r400340068", "bodyText": "discussed offline, added some additional comments, and exception handling.", "author": "Scottmitch", "createdAt": "2020-03-30T16:46:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODA0NzM4OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODA1MzU0Ng==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r398053546", "bodyText": "As queue and pop semantics implemented here are considerably complex, I am wondering about the motivation behind this special queue implementation as opposed to using one of the existing queues we use elsewhere? Consider adding the motivation in comments here.", "author": "NiteshKant", "createdAt": "2020-03-25T17:51:07Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+\n+import io.netty.channel.Channel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Arrays;\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(NettyPipelinedConnection.class);\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>", "originalCommit": "7469332830d536d9dc82b82bad56e4860a3caf7e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTE1ODA4MA==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r399158080", "bodyText": "+1... I would keep it simple if possible. At first look this looks like over-engineered imho.", "author": "normanmaurer", "createdAt": "2020-03-27T10:10:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODA1MzU0Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM5MzA4OA==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r399393088", "bodyText": "I don't believe the complexity in the PR is substantially increased/decreased from what was here previously. There are two high level components of this PR (both of which existed previously):\nA. relationship between read/write operations\nB. Mpmc (mc - bcz failure/cancellation/reentry) queue that only consumes and executes a single element at a time, and async completion of the current events triggers a pop of the current element and execution of the next element\n(A) This PR modifies the previous control flow in DefaultNettyPipelinedConnection to allow for full duplex, where previously the read could only start after the write completely finished.\n(B) This PR replaces SequentialTaskQueue which attempted todo the same thing (Mpmc Single Runnable Active, async completion starts the next Runnable). However the previous queue relied upon ThreadLocals and may not make progress if the completion thread is different than the thread that started the task. This PR fixes a potential correctness issue, and a nice side effect is no more dependance on ThreadLocals (and risk of not cleaning them up).\nThe interesting characteristics of the queue are:\n\noffer needs to know when the queue was previously empty -> the first element needs to be executed/run\npop needs to be correlated to the current active task (e.g. only a task that is executed/run should trigger pop, or else sequencing is off) and it also needs to execute the next task (if one exists)\n\nthis queue implementation achieves those characteristics with atomic operations to update linked nodes, and a tail pointer with trailing atomic updates. It could be done in other ways (e.g. synchronized) but using existing MPMC queues won't give us the trigger points to know when \"this offer was the first element\" and \"this specific element needs to be popped, and I need the next element in order relative to the related read/write\".", "author": "Scottmitch", "createdAt": "2020-03-27T16:34:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODA1MzU0Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODU3NjU5Mg==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r408576592", "bodyText": "custom queue implementation has since been removed ... thanks for the feedback!", "author": "Scottmitch", "createdAt": "2020-04-15T04:40:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODA1MzU0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODA1OTQ1MA==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r398059450", "bodyText": "Looks like .afterFinally(() -> queuePop(readQueueTailUpdater, readNode)) will have the same semantics as the ReadPopNextOperator\nSame for WritePopNextOperator", "author": "NiteshKant", "createdAt": "2020-03-25T17:59:21Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+\n+import io.netty.channel.Channel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Arrays;\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(NettyPipelinedConnection.class);\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            writeQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"writeQueueTail\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            readQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"readQueueTail\");\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node writeQueueTail;\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node readQueueTail;\n+\n+    private final NettyConnection<Resp, Req> connection;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} producing the request(s) to write.\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        return Publisher.defer(() -> {\n+            // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+\n+            // Setup read side publisher and nodes\n+            DelayedSubscribePublisher<Resp> delayedResponsePublisher = new DelayedSubscribePublisher<>(\n+                    toSource(connection.read()));\n+            Node readNode = new Node(delayedResponsePublisher::processSubscribers);\n+            Publisher<Resp> composedResponsePublisher =\n+                    delayedResponsePublisher.liftSync(new ReadPopNextOperator(readNode));", "originalCommit": "7469332830d536d9dc82b82bad56e4860a3caf7e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg0OTcwOQ==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r398849709", "bodyText": "Yes it should. Optimization which removes some state and CAS because the queue pop operation is safe to execute multiple times from different threads.\n    /**\n     * Logically equivalent to {@link Publisher#afterFinally(Runnable)} but relies upon internal queue CAS operations\n     * to prevent multiple executions (e.g. reduces a CAS operation).\n     */", "author": "Scottmitch", "createdAt": "2020-03-26T19:51:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODA1OTQ1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODA3NDU2Ng==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r398074566", "bodyText": "I haven't mapped myself but have we made sure that all previous tests from the previous test(DefaultNettyPipelinedConnectionTest) are represented here?", "author": "NiteshKant", "createdAt": "2020-03-25T18:22:18Z", "path": "servicetalk-http-netty/src/test/java/io/servicetalk/http/netty/NettyPipelinedConnectionTest.java", "diffHunk": "@@ -0,0 +1,379 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.concurrent.api.TestCollectingPublisherSubscriber;\n+import io.servicetalk.concurrent.api.TestPublisher;\n+import io.servicetalk.concurrent.api.TestSubscription;\n+import io.servicetalk.concurrent.internal.ServiceTalkTestTimeout;\n+import io.servicetalk.transport.api.ConnectionContext.Protocol;\n+import io.servicetalk.transport.netty.internal.DefaultNettyConnection;\n+import io.servicetalk.transport.netty.internal.FlushStrategies;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n+\n+import io.netty.channel.embedded.EmbeddedChannel;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.Timeout;\n+import org.mockito.stubbing.Answer;\n+\n+import java.nio.channels.ClosedChannelException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.concurrent.CyclicBarrier;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.SynchronousQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static io.servicetalk.buffer.netty.BufferAllocators.DEFAULT_ALLOCATOR;\n+import static io.servicetalk.concurrent.api.Executors.immediate;\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static io.servicetalk.concurrent.internal.DeliberateException.DELIBERATE_EXCEPTION;\n+import static io.servicetalk.http.api.HttpExecutionStrategies.defaultStrategy;\n+import static io.servicetalk.transport.netty.internal.CloseHandler.UNSUPPORTED_PROTOCOL_CLOSE_HANDLER;\n+import static io.servicetalk.transport.netty.internal.FlushStrategies.defaultFlushStrategy;\n+import static java.lang.Integer.MAX_VALUE;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.hasSize;\n+import static org.hamcrest.Matchers.instanceOf;\n+import static org.hamcrest.Matchers.is;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.ArgumentMatchers.anyLong;\n+import static org.mockito.ArgumentMatchers.eq;\n+import static org.mockito.Mockito.doAnswer;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+public class NettyPipelinedConnectionTest {", "originalCommit": "7469332830d536d9dc82b82bad56e4860a3caf7e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU1MDc3Ng==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r399550776", "bodyText": "Yes, the test sequences scenarios were adapted from DefaultNettyPipelinedConnectionTest and additional ones were added on top. However feel free to suggest additional tests if some where missed.", "author": "Scottmitch", "createdAt": "2020-03-27T21:39:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODA3NDU2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODE3ODU4Ng==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r398178586", "bodyText": "nit: misordered modifierns, shoud be @SuppressWarnings(\"rawtypes\") final", "author": "idelpivnitskiy", "createdAt": "2020-03-25T21:23:35Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+\n+import io.netty.channel.Channel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Arrays;\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(NettyPipelinedConnection.class);\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            writeQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"writeQueueTail\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            readQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"readQueueTail\");\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node writeQueueTail;\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node readQueueTail;\n+\n+    private final NettyConnection<Resp, Req> connection;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} producing the request(s) to write.\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        return Publisher.defer(() -> {\n+            // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+\n+            // Setup read side publisher and nodes\n+            DelayedSubscribePublisher<Resp> delayedResponsePublisher = new DelayedSubscribePublisher<>(\n+                    toSource(connection.read()));\n+            Node readNode = new Node(delayedResponsePublisher::processSubscribers);\n+            Publisher<Resp> composedResponsePublisher =\n+                    delayedResponsePublisher.liftSync(new ReadPopNextOperator(readNode));\n+\n+            // Setup write side publisher and nodes\n+            DelayedSubscribeCompletable delayedRequestCompletable = new DelayedSubscribeCompletable(toSource(\n+                            connection.write(requestPublisher, flushStrategySupplier, writeDemandEstimatorSupplier)));\n+            Node writeNode = new Node(() -> {\n+                try {\n+                    queueOffer(readQueueTailUpdater, readNode);\n+                } finally {\n+                    delayedRequestCompletable.processSubscribers();\n+                }\n+            });\n+\n+            queueOffer(writeQueueTailUpdater, writeNode);\n+\n+            return delayedRequestCompletable.liftSync(new WritePopNextOperator(writeNode))\n+                    // If there is an error on the read/write side we propagate the errors between the two via merge.\n+                    .merge(composedResponsePublisher);\n+        });\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void queueOffer(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,", "originalCommit": "7469332830d536d9dc82b82bad56e4860a3caf7e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODE3ODcxOQ==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r398178719", "bodyText": "nit: misordered modifierns, shoud be @SuppressWarnings(\"rawtypes\") final", "author": "idelpivnitskiy", "createdAt": "2020-03-25T21:23:52Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+\n+import io.netty.channel.Channel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Arrays;\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(NettyPipelinedConnection.class);\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            writeQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"writeQueueTail\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            readQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"readQueueTail\");\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node writeQueueTail;\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node readQueueTail;\n+\n+    private final NettyConnection<Resp, Req> connection;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} producing the request(s) to write.\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        return Publisher.defer(() -> {\n+            // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+\n+            // Setup read side publisher and nodes\n+            DelayedSubscribePublisher<Resp> delayedResponsePublisher = new DelayedSubscribePublisher<>(\n+                    toSource(connection.read()));\n+            Node readNode = new Node(delayedResponsePublisher::processSubscribers);\n+            Publisher<Resp> composedResponsePublisher =\n+                    delayedResponsePublisher.liftSync(new ReadPopNextOperator(readNode));\n+\n+            // Setup write side publisher and nodes\n+            DelayedSubscribeCompletable delayedRequestCompletable = new DelayedSubscribeCompletable(toSource(\n+                            connection.write(requestPublisher, flushStrategySupplier, writeDemandEstimatorSupplier)));\n+            Node writeNode = new Node(() -> {\n+                try {\n+                    queueOffer(readQueueTailUpdater, readNode);\n+                } finally {\n+                    delayedRequestCompletable.processSubscribers();\n+                }\n+            });\n+\n+            queueOffer(writeQueueTailUpdater, writeNode);\n+\n+            return delayedRequestCompletable.liftSync(new WritePopNextOperator(writeNode))\n+                    // If there is an error on the read/write side we propagate the errors between the two via merge.\n+                    .merge(composedResponsePublisher);\n+        });\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void queueOffer(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node node) {\n+        for (;;) {\n+            Node tail = tailUpdater.get(this);\n+            if (tail == null) {\n+                if (tailUpdater.compareAndSet(this, null, node)) {\n+                    // node has been inserted and is the only node, we initiate processing.\n+                    safeProcessSubscribers(node.delayedSource);\n+                    break;\n+                }\n+                // Another thread won the race to offer a node, loop around and try again.\n+            } else if (tail.append(node)) {\n+                // Make the newly appended node visible as the tail. This is a best effort CAS and may fail because:\n+                // 1. Another thread is also inserting, has a stale tail, followed its existing tail links, and updated\n+                // the tail reference via queueOfferPatchTail.\n+                // 2. The consumer thread has seen the link from the old tail to the new node, processed node,\n+                // popped node from the list (updated node's next to point to EMPTY_NODE), another producer thread\n+                // appends a new node, sees the tail is popped, and updates the tail reference via CAS.\n+                tailUpdater.compareAndSet(this, tail, node);\n+                break;\n+            } else if (tail.isPopped()) {\n+                // A previously appended node was processed, and popped before updating the tail after append. In that\n+                // case the tail maybe pointing to an invalid node and we clear it out.\n+                if (tailUpdater.compareAndSet(this, tail, node)) {\n+                    safeProcessSubscribers(node.delayedSource);\n+                    break;\n+                }\n+                // Best effort to clear the tail, and failure is OK because:\n+                // 1. Another thread is in offer and already patched up the tail pointer and we will read the new tail\n+                // on the next loop iteration.\n+            } else if (queueOfferPatchTail(tailUpdater, node, tail)) {\n+                break;\n+            }\n+        }\n+    }\n+\n+    private boolean queueOfferPatchTail(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,", "originalCommit": "7469332830d536d9dc82b82bad56e4860a3caf7e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODE3ODc5MA==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r398178790", "bodyText": "nit: misordered modifierns, shoud be @SuppressWarnings(\"rawtypes\") final", "author": "idelpivnitskiy", "createdAt": "2020-03-25T21:23:59Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+\n+import io.netty.channel.Channel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Arrays;\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(NettyPipelinedConnection.class);\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            writeQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"writeQueueTail\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            readQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"readQueueTail\");\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node writeQueueTail;\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node readQueueTail;\n+\n+    private final NettyConnection<Resp, Req> connection;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} producing the request(s) to write.\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        return Publisher.defer(() -> {\n+            // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+\n+            // Setup read side publisher and nodes\n+            DelayedSubscribePublisher<Resp> delayedResponsePublisher = new DelayedSubscribePublisher<>(\n+                    toSource(connection.read()));\n+            Node readNode = new Node(delayedResponsePublisher::processSubscribers);\n+            Publisher<Resp> composedResponsePublisher =\n+                    delayedResponsePublisher.liftSync(new ReadPopNextOperator(readNode));\n+\n+            // Setup write side publisher and nodes\n+            DelayedSubscribeCompletable delayedRequestCompletable = new DelayedSubscribeCompletable(toSource(\n+                            connection.write(requestPublisher, flushStrategySupplier, writeDemandEstimatorSupplier)));\n+            Node writeNode = new Node(() -> {\n+                try {\n+                    queueOffer(readQueueTailUpdater, readNode);\n+                } finally {\n+                    delayedRequestCompletable.processSubscribers();\n+                }\n+            });\n+\n+            queueOffer(writeQueueTailUpdater, writeNode);\n+\n+            return delayedRequestCompletable.liftSync(new WritePopNextOperator(writeNode))\n+                    // If there is an error on the read/write side we propagate the errors between the two via merge.\n+                    .merge(composedResponsePublisher);\n+        });\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void queueOffer(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node node) {\n+        for (;;) {\n+            Node tail = tailUpdater.get(this);\n+            if (tail == null) {\n+                if (tailUpdater.compareAndSet(this, null, node)) {\n+                    // node has been inserted and is the only node, we initiate processing.\n+                    safeProcessSubscribers(node.delayedSource);\n+                    break;\n+                }\n+                // Another thread won the race to offer a node, loop around and try again.\n+            } else if (tail.append(node)) {\n+                // Make the newly appended node visible as the tail. This is a best effort CAS and may fail because:\n+                // 1. Another thread is also inserting, has a stale tail, followed its existing tail links, and updated\n+                // the tail reference via queueOfferPatchTail.\n+                // 2. The consumer thread has seen the link from the old tail to the new node, processed node,\n+                // popped node from the list (updated node's next to point to EMPTY_NODE), another producer thread\n+                // appends a new node, sees the tail is popped, and updates the tail reference via CAS.\n+                tailUpdater.compareAndSet(this, tail, node);\n+                break;\n+            } else if (tail.isPopped()) {\n+                // A previously appended node was processed, and popped before updating the tail after append. In that\n+                // case the tail maybe pointing to an invalid node and we clear it out.\n+                if (tailUpdater.compareAndSet(this, tail, node)) {\n+                    safeProcessSubscribers(node.delayedSource);\n+                    break;\n+                }\n+                // Best effort to clear the tail, and failure is OK because:\n+                // 1. Another thread is in offer and already patched up the tail pointer and we will read the new tail\n+                // on the next loop iteration.\n+            } else if (queueOfferPatchTail(tailUpdater, node, tail)) {\n+                break;\n+            }\n+        }\n+    }\n+\n+    private boolean queueOfferPatchTail(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node node,\n+            final Node tail) {\n+        Node currentTail = tailUpdater.get(this);\n+        if (currentTail == tail) {\n+            // tail is stale so attempt to iterate through the linked list and update tail.\n+            currentTail = tail.iterateToTail();\n+            if (currentTail.isPopped()) {\n+                if (tailUpdater.compareAndSet(this, tail, node)) {\n+                    safeProcessSubscribers(node.delayedSource);\n+                    return true;\n+                }\n+            } else {\n+                tailUpdater.compareAndSet(this, tail, currentTail);\n+            }\n+            // Best effort to update/clear the tail, and failure is OK because:\n+            // 1. Another thread is in offer and already patched up the tail pointer and we will read the new\n+            // tail on the next loop iteration.\n+        }\n+        return false;\n+    }\n+\n+    private void queuePop(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,", "originalCommit": "7469332830d536d9dc82b82bad56e4860a3caf7e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODE3OTI0OQ==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r398179249", "bodyText": "The ordering of tags should be opposite:\n<ul>\n    <li>...</li>\n    ...\n</ul>", "author": "idelpivnitskiy", "createdAt": "2020-03-25T21:24:50Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+\n+import io.netty.channel.Channel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Arrays;\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(NettyPipelinedConnection.class);\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            writeQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"writeQueueTail\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            readQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"readQueueTail\");\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node writeQueueTail;\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node readQueueTail;\n+\n+    private final NettyConnection<Resp, Req> connection;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} producing the request(s) to write.\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        return Publisher.defer(() -> {\n+            // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+\n+            // Setup read side publisher and nodes\n+            DelayedSubscribePublisher<Resp> delayedResponsePublisher = new DelayedSubscribePublisher<>(\n+                    toSource(connection.read()));\n+            Node readNode = new Node(delayedResponsePublisher::processSubscribers);\n+            Publisher<Resp> composedResponsePublisher =\n+                    delayedResponsePublisher.liftSync(new ReadPopNextOperator(readNode));\n+\n+            // Setup write side publisher and nodes\n+            DelayedSubscribeCompletable delayedRequestCompletable = new DelayedSubscribeCompletable(toSource(\n+                            connection.write(requestPublisher, flushStrategySupplier, writeDemandEstimatorSupplier)));\n+            Node writeNode = new Node(() -> {\n+                try {\n+                    queueOffer(readQueueTailUpdater, readNode);\n+                } finally {\n+                    delayedRequestCompletable.processSubscribers();\n+                }\n+            });\n+\n+            queueOffer(writeQueueTailUpdater, writeNode);\n+\n+            return delayedRequestCompletable.liftSync(new WritePopNextOperator(writeNode))\n+                    // If there is an error on the read/write side we propagate the errors between the two via merge.\n+                    .merge(composedResponsePublisher);\n+        });\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void queueOffer(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node node) {\n+        for (;;) {\n+            Node tail = tailUpdater.get(this);\n+            if (tail == null) {\n+                if (tailUpdater.compareAndSet(this, null, node)) {\n+                    // node has been inserted and is the only node, we initiate processing.\n+                    safeProcessSubscribers(node.delayedSource);\n+                    break;\n+                }\n+                // Another thread won the race to offer a node, loop around and try again.\n+            } else if (tail.append(node)) {\n+                // Make the newly appended node visible as the tail. This is a best effort CAS and may fail because:\n+                // 1. Another thread is also inserting, has a stale tail, followed its existing tail links, and updated\n+                // the tail reference via queueOfferPatchTail.\n+                // 2. The consumer thread has seen the link from the old tail to the new node, processed node,\n+                // popped node from the list (updated node's next to point to EMPTY_NODE), another producer thread\n+                // appends a new node, sees the tail is popped, and updates the tail reference via CAS.\n+                tailUpdater.compareAndSet(this, tail, node);\n+                break;\n+            } else if (tail.isPopped()) {\n+                // A previously appended node was processed, and popped before updating the tail after append. In that\n+                // case the tail maybe pointing to an invalid node and we clear it out.\n+                if (tailUpdater.compareAndSet(this, tail, node)) {\n+                    safeProcessSubscribers(node.delayedSource);\n+                    break;\n+                }\n+                // Best effort to clear the tail, and failure is OK because:\n+                // 1. Another thread is in offer and already patched up the tail pointer and we will read the new tail\n+                // on the next loop iteration.\n+            } else if (queueOfferPatchTail(tailUpdater, node, tail)) {\n+                break;\n+            }\n+        }\n+    }\n+\n+    private boolean queueOfferPatchTail(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node node,\n+            final Node tail) {\n+        Node currentTail = tailUpdater.get(this);\n+        if (currentTail == tail) {\n+            // tail is stale so attempt to iterate through the linked list and update tail.\n+            currentTail = tail.iterateToTail();\n+            if (currentTail.isPopped()) {\n+                if (tailUpdater.compareAndSet(this, tail, node)) {\n+                    safeProcessSubscribers(node.delayedSource);\n+                    return true;\n+                }\n+            } else {\n+                tailUpdater.compareAndSet(this, tail, currentTail);\n+            }\n+            // Best effort to update/clear the tail, and failure is OK because:\n+            // 1. Another thread is in offer and already patched up the tail pointer and we will read the new\n+            // tail on the next loop iteration.\n+        }\n+        return false;\n+    }\n+\n+    private void queuePop(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node head) {\n+        // This method maybe called multiple times on the same node, in which case next will be EMPTY_NODE and the run\n+        // method will be a noop.\n+        Node next = head.pop();\n+        if (next != null) {\n+            safeProcessSubscribers(next.delayedSource);\n+        } else {\n+            tailUpdater.compareAndSet(this, head, null);\n+            // Best effort to clear the tail, and failure is OK because:\n+            // 1. Another thread appended this head, but has not yet updated the tail. In this case the tail will be\n+            // stale (e.g. pointing to head node that has already been processed) and corrected by future inserts.\n+        }\n+    }\n+\n+    private void safeProcessSubscribers(Runnable delayedSource) {\n+        try {\n+            delayedSource.run();\n+        } catch (Throwable cause) {\n+            connection.closeAsync().subscribe();\n+            LOGGER.warn(\"closing connection={} due to unexpected error on subscribe\", connection, cause);\n+        }\n+    }\n+\n+    /**\n+     * Logically equivalent to {@link Publisher#afterFinally(Runnable)} but relies upon internal queue CAS operations\n+     * to prevent multiple executions (e.g. reduces a CAS operation).\n+     */\n+    private final class ReadPopNextOperator implements PublisherOperator<Resp, Resp> {\n+        private final Node readNode;\n+\n+        private ReadPopNextOperator(final Node readNode) {\n+            this.readNode = readNode;\n+        }\n+\n+        @Override\n+        public PublisherSource.Subscriber<? super Resp> apply(PublisherSource.Subscriber<? super Resp> subscriber) {\n+            return new PublisherSource.Subscriber<Resp>() {\n+                @Override\n+                public void onSubscribe(final PublisherSource.Subscription subscription) {\n+                    subscriber.onSubscribe(new PublisherSource.Subscription() {\n+                        @Override\n+                        public void request(final long n) {\n+                            subscription.request(n);\n+                        }\n+\n+                        @Override\n+                        public void cancel() {\n+                            try {\n+                                subscription.cancel();\n+                            } finally {\n+                                pollNext();\n+                            }\n+                        }\n+                    });\n+                }\n+\n+                @Override\n+                public void onNext(@Nullable final Resp t) {\n+                    subscriber.onNext(t);\n+                }\n+\n+                @Override\n+                public void onError(final Throwable t) {\n+                    try {\n+                        subscriber.onError(t);\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+\n+                @Override\n+                public void onComplete() {\n+                    try {\n+                        subscriber.onComplete();\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+\n+                private void pollNext() {\n+                    queuePop(readQueueTailUpdater, readNode);\n+                }\n+            };\n+        }\n+    }\n+\n+    /**\n+     * Logically equivalent to {@link Completable#afterFinally(Runnable)} but relies upon internal queue CAS operations\n+     * to prevent multiple executions (e.g. reduces a CAS operation).\n+     */\n+    private final class WritePopNextOperator implements CompletableOperator {\n+        private final Node writeNode;\n+\n+        WritePopNextOperator(final Node writeNode) {\n+            this.writeNode = writeNode;\n+        }\n+\n+        @Override\n+        public CompletableSource.Subscriber apply(final CompletableSource.Subscriber subscriber) {\n+            return new CompletableSource.Subscriber() {\n+                @Override\n+                public void onSubscribe(final Cancellable cancellable) {\n+                    subscriber.onSubscribe(() -> {\n+                        try {\n+                            cancellable.cancel();\n+                        } finally {\n+                            pollNext();\n+                        }\n+                    });\n+                }\n+\n+                @Override\n+                public void onComplete() {\n+                    try {\n+                        subscriber.onComplete();\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(final Throwable t) {\n+                    try {\n+                        subscriber.onError(t);\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+            };\n+        }\n+\n+        private void pollNext() {\n+            queuePop(writeQueueTailUpdater, writeNode);\n+        }\n+    }\n+\n+    private static final class Node {\n+        private static final Node EMPTY_NODE = new Node();\n+        private static final AtomicReferenceFieldUpdater<Node, Node> nextUpdater =\n+                newUpdater(Node.class, Node.class, \"next\");\n+        @Nullable\n+        private volatile Node next;\n+        final Runnable delayedSource;\n+\n+        Node(Runnable delayedSource) {\n+            this.delayedSource = requireNonNull(delayedSource);\n+        }\n+\n+        private Node() {\n+            this.next = this;\n+            this.delayedSource = () -> { };\n+        }\n+\n+        boolean append(Node next) {\n+            return nextUpdater.compareAndSet(this, null, next);\n+        }\n+\n+        @Nullable\n+        Node pop() {\n+            return nextUpdater.getAndSet(this, EMPTY_NODE);\n+        }\n+\n+        boolean isPopped() {\n+            return next == EMPTY_NODE;\n+        }\n+\n+        Node iterateToTail() {\n+            Node prev = this;\n+            Node next = prev.next;\n+            while (next != null) {\n+                prev = next;\n+                next = next.next;\n+            }\n+            return prev;\n+        }\n+    }\n+\n+    private static final class DelayedSubscribeCompletable extends Completable {\n+        private static final AtomicReferenceFieldUpdater<DelayedSubscribeCompletable, Object> stateUpdater =\n+                newUpdater(DelayedSubscribeCompletable.class, Object.class, \"state\");\n+        private static final Object ALLOW_SUBSCRIBE = new Object();\n+        private static final Object DRAINING_SUBSCRIBERS = new Object();\n+\n+        private final CompletableSource completable;\n+        /**\n+         * One of the following:\n+         * <li>\n+         *     <ul>{@code null} - initial state</ul>", "originalCommit": "7469332830d536d9dc82b82bad56e4860a3caf7e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODE3OTM1OQ==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r398179359", "bodyText": "The ordering of tags should be opposite:\n<ul>\n    <li>...</li>\n    ...\n</ul>", "author": "idelpivnitskiy", "createdAt": "2020-03-25T21:25:05Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+\n+import io.netty.channel.Channel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Arrays;\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(NettyPipelinedConnection.class);\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            writeQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"writeQueueTail\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            readQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"readQueueTail\");\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node writeQueueTail;\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node readQueueTail;\n+\n+    private final NettyConnection<Resp, Req> connection;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} producing the request(s) to write.\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        return Publisher.defer(() -> {\n+            // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+\n+            // Setup read side publisher and nodes\n+            DelayedSubscribePublisher<Resp> delayedResponsePublisher = new DelayedSubscribePublisher<>(\n+                    toSource(connection.read()));\n+            Node readNode = new Node(delayedResponsePublisher::processSubscribers);\n+            Publisher<Resp> composedResponsePublisher =\n+                    delayedResponsePublisher.liftSync(new ReadPopNextOperator(readNode));\n+\n+            // Setup write side publisher and nodes\n+            DelayedSubscribeCompletable delayedRequestCompletable = new DelayedSubscribeCompletable(toSource(\n+                            connection.write(requestPublisher, flushStrategySupplier, writeDemandEstimatorSupplier)));\n+            Node writeNode = new Node(() -> {\n+                try {\n+                    queueOffer(readQueueTailUpdater, readNode);\n+                } finally {\n+                    delayedRequestCompletable.processSubscribers();\n+                }\n+            });\n+\n+            queueOffer(writeQueueTailUpdater, writeNode);\n+\n+            return delayedRequestCompletable.liftSync(new WritePopNextOperator(writeNode))\n+                    // If there is an error on the read/write side we propagate the errors between the two via merge.\n+                    .merge(composedResponsePublisher);\n+        });\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void queueOffer(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node node) {\n+        for (;;) {\n+            Node tail = tailUpdater.get(this);\n+            if (tail == null) {\n+                if (tailUpdater.compareAndSet(this, null, node)) {\n+                    // node has been inserted and is the only node, we initiate processing.\n+                    safeProcessSubscribers(node.delayedSource);\n+                    break;\n+                }\n+                // Another thread won the race to offer a node, loop around and try again.\n+            } else if (tail.append(node)) {\n+                // Make the newly appended node visible as the tail. This is a best effort CAS and may fail because:\n+                // 1. Another thread is also inserting, has a stale tail, followed its existing tail links, and updated\n+                // the tail reference via queueOfferPatchTail.\n+                // 2. The consumer thread has seen the link from the old tail to the new node, processed node,\n+                // popped node from the list (updated node's next to point to EMPTY_NODE), another producer thread\n+                // appends a new node, sees the tail is popped, and updates the tail reference via CAS.\n+                tailUpdater.compareAndSet(this, tail, node);\n+                break;\n+            } else if (tail.isPopped()) {\n+                // A previously appended node was processed, and popped before updating the tail after append. In that\n+                // case the tail maybe pointing to an invalid node and we clear it out.\n+                if (tailUpdater.compareAndSet(this, tail, node)) {\n+                    safeProcessSubscribers(node.delayedSource);\n+                    break;\n+                }\n+                // Best effort to clear the tail, and failure is OK because:\n+                // 1. Another thread is in offer and already patched up the tail pointer and we will read the new tail\n+                // on the next loop iteration.\n+            } else if (queueOfferPatchTail(tailUpdater, node, tail)) {\n+                break;\n+            }\n+        }\n+    }\n+\n+    private boolean queueOfferPatchTail(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node node,\n+            final Node tail) {\n+        Node currentTail = tailUpdater.get(this);\n+        if (currentTail == tail) {\n+            // tail is stale so attempt to iterate through the linked list and update tail.\n+            currentTail = tail.iterateToTail();\n+            if (currentTail.isPopped()) {\n+                if (tailUpdater.compareAndSet(this, tail, node)) {\n+                    safeProcessSubscribers(node.delayedSource);\n+                    return true;\n+                }\n+            } else {\n+                tailUpdater.compareAndSet(this, tail, currentTail);\n+            }\n+            // Best effort to update/clear the tail, and failure is OK because:\n+            // 1. Another thread is in offer and already patched up the tail pointer and we will read the new\n+            // tail on the next loop iteration.\n+        }\n+        return false;\n+    }\n+\n+    private void queuePop(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node head) {\n+        // This method maybe called multiple times on the same node, in which case next will be EMPTY_NODE and the run\n+        // method will be a noop.\n+        Node next = head.pop();\n+        if (next != null) {\n+            safeProcessSubscribers(next.delayedSource);\n+        } else {\n+            tailUpdater.compareAndSet(this, head, null);\n+            // Best effort to clear the tail, and failure is OK because:\n+            // 1. Another thread appended this head, but has not yet updated the tail. In this case the tail will be\n+            // stale (e.g. pointing to head node that has already been processed) and corrected by future inserts.\n+        }\n+    }\n+\n+    private void safeProcessSubscribers(Runnable delayedSource) {\n+        try {\n+            delayedSource.run();\n+        } catch (Throwable cause) {\n+            connection.closeAsync().subscribe();\n+            LOGGER.warn(\"closing connection={} due to unexpected error on subscribe\", connection, cause);\n+        }\n+    }\n+\n+    /**\n+     * Logically equivalent to {@link Publisher#afterFinally(Runnable)} but relies upon internal queue CAS operations\n+     * to prevent multiple executions (e.g. reduces a CAS operation).\n+     */\n+    private final class ReadPopNextOperator implements PublisherOperator<Resp, Resp> {\n+        private final Node readNode;\n+\n+        private ReadPopNextOperator(final Node readNode) {\n+            this.readNode = readNode;\n+        }\n+\n+        @Override\n+        public PublisherSource.Subscriber<? super Resp> apply(PublisherSource.Subscriber<? super Resp> subscriber) {\n+            return new PublisherSource.Subscriber<Resp>() {\n+                @Override\n+                public void onSubscribe(final PublisherSource.Subscription subscription) {\n+                    subscriber.onSubscribe(new PublisherSource.Subscription() {\n+                        @Override\n+                        public void request(final long n) {\n+                            subscription.request(n);\n+                        }\n+\n+                        @Override\n+                        public void cancel() {\n+                            try {\n+                                subscription.cancel();\n+                            } finally {\n+                                pollNext();\n+                            }\n+                        }\n+                    });\n+                }\n+\n+                @Override\n+                public void onNext(@Nullable final Resp t) {\n+                    subscriber.onNext(t);\n+                }\n+\n+                @Override\n+                public void onError(final Throwable t) {\n+                    try {\n+                        subscriber.onError(t);\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+\n+                @Override\n+                public void onComplete() {\n+                    try {\n+                        subscriber.onComplete();\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+\n+                private void pollNext() {\n+                    queuePop(readQueueTailUpdater, readNode);\n+                }\n+            };\n+        }\n+    }\n+\n+    /**\n+     * Logically equivalent to {@link Completable#afterFinally(Runnable)} but relies upon internal queue CAS operations\n+     * to prevent multiple executions (e.g. reduces a CAS operation).\n+     */\n+    private final class WritePopNextOperator implements CompletableOperator {\n+        private final Node writeNode;\n+\n+        WritePopNextOperator(final Node writeNode) {\n+            this.writeNode = writeNode;\n+        }\n+\n+        @Override\n+        public CompletableSource.Subscriber apply(final CompletableSource.Subscriber subscriber) {\n+            return new CompletableSource.Subscriber() {\n+                @Override\n+                public void onSubscribe(final Cancellable cancellable) {\n+                    subscriber.onSubscribe(() -> {\n+                        try {\n+                            cancellable.cancel();\n+                        } finally {\n+                            pollNext();\n+                        }\n+                    });\n+                }\n+\n+                @Override\n+                public void onComplete() {\n+                    try {\n+                        subscriber.onComplete();\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(final Throwable t) {\n+                    try {\n+                        subscriber.onError(t);\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+            };\n+        }\n+\n+        private void pollNext() {\n+            queuePop(writeQueueTailUpdater, writeNode);\n+        }\n+    }\n+\n+    private static final class Node {\n+        private static final Node EMPTY_NODE = new Node();\n+        private static final AtomicReferenceFieldUpdater<Node, Node> nextUpdater =\n+                newUpdater(Node.class, Node.class, \"next\");\n+        @Nullable\n+        private volatile Node next;\n+        final Runnable delayedSource;\n+\n+        Node(Runnable delayedSource) {\n+            this.delayedSource = requireNonNull(delayedSource);\n+        }\n+\n+        private Node() {\n+            this.next = this;\n+            this.delayedSource = () -> { };\n+        }\n+\n+        boolean append(Node next) {\n+            return nextUpdater.compareAndSet(this, null, next);\n+        }\n+\n+        @Nullable\n+        Node pop() {\n+            return nextUpdater.getAndSet(this, EMPTY_NODE);\n+        }\n+\n+        boolean isPopped() {\n+            return next == EMPTY_NODE;\n+        }\n+\n+        Node iterateToTail() {\n+            Node prev = this;\n+            Node next = prev.next;\n+            while (next != null) {\n+                prev = next;\n+                next = next.next;\n+            }\n+            return prev;\n+        }\n+    }\n+\n+    private static final class DelayedSubscribeCompletable extends Completable {\n+        private static final AtomicReferenceFieldUpdater<DelayedSubscribeCompletable, Object> stateUpdater =\n+                newUpdater(DelayedSubscribeCompletable.class, Object.class, \"state\");\n+        private static final Object ALLOW_SUBSCRIBE = new Object();\n+        private static final Object DRAINING_SUBSCRIBERS = new Object();\n+\n+        private final CompletableSource completable;\n+        /**\n+         * One of the following:\n+         * <li>\n+         *     <ul>{@code null} - initial state</ul>\n+         *     <ul>{@link #ALLOW_SUBSCRIBE} - {@link #handleSubscribe(CompletableSource.Subscriber)} methods will\n+         *     pass through to {@link #completable}</ul>\n+         *     <ul>{@link #DRAINING_SUBSCRIBERS} - set in {@link #processSubscribers()} while calling\n+         *     {@link CompletableSource#subscribe(CompletableSource.Subscriber)} on each {@link Completable}</ul>\n+         *     <ul>{@link CompletableSource.Subscriber} - if there is a single\n+         *     {@link #handleSubscribe(CompletableSource.Subscriber)} pending</ul>\n+         *     <ul>{@code Object[]} - if there are multiple {@link #handleSubscribe(CompletableSource.Subscriber)}\n+         *     calls pending</ul>\n+         * </li>\n+         */\n+        @Nullable\n+        private volatile Object state;\n+\n+        private DelayedSubscribeCompletable(final CompletableSource completable) {\n+            this.completable = requireNonNull(completable);\n+        }\n+\n+        void processSubscribers() {\n+            for (;;) {\n+                Object currentState = state;\n+                if (currentState == null) {\n+                    if (stateUpdater.compareAndSet(this, null, ALLOW_SUBSCRIBE)) {\n+                        break;\n+                    }\n+                } else if (currentState == ALLOW_SUBSCRIBE) {\n+                    break;\n+                } else if (currentState instanceof CompletableSource.Subscriber) {\n+                    CompletableSource.Subscriber currentSubscriber = (CompletableSource.Subscriber) currentState;\n+                    if (stateUpdater.compareAndSet(this, currentState, DRAINING_SUBSCRIBERS)) {\n+                        completable.subscribe(currentSubscriber);\n+                        if (stateUpdater.compareAndSet(this, DRAINING_SUBSCRIBERS, ALLOW_SUBSCRIBE)) {\n+                            break;\n+                        }\n+                    }\n+                } else if (stateUpdater.compareAndSet(this, currentState, DRAINING_SUBSCRIBERS)) {\n+                    assert currentState != DRAINING_SUBSCRIBERS;\n+                    CompletableSource.Subscriber[] queue = (CompletableSource.Subscriber[]) currentState;\n+                    for (CompletableSource.Subscriber next : queue) {\n+                        completable.subscribe(next);\n+                    }\n+                    if (stateUpdater.compareAndSet(this, DRAINING_SUBSCRIBERS, ALLOW_SUBSCRIBE)) {\n+                        break;\n+                    }\n+                }\n+            }\n+        }\n+\n+        @Override\n+        protected void handleSubscribe(final CompletableSource.Subscriber subscriber) {\n+            for (;;) {\n+                Object currentState = state;\n+                if (currentState == null || currentState == DRAINING_SUBSCRIBERS) {\n+                    if (stateUpdater.compareAndSet(this, currentState, subscriber)) {\n+                        break;\n+                    }\n+                } else if (currentState == ALLOW_SUBSCRIBE) {\n+                    completable.subscribe(subscriber);\n+                    break;\n+                } else if (currentState instanceof CompletableSource.Subscriber) {\n+                    // Ideally we can propagate the onSubscribe ASAP to allow for cancellation but this completable is\n+                    // designed to defer the subscribe until some other condition occurs, so no work will actually be\n+                    // done until that later time.\n+                    CompletableSource.Subscriber currentSubscriber = (CompletableSource.Subscriber) currentState;\n+                    if (stateUpdater.compareAndSet(this, currentState,\n+                            new Object[] {currentSubscriber, subscriber})) {\n+                        break;\n+                    }\n+                } else {\n+                    Object[] array = (Object[]) currentState;\n+                    // Unmodifiable collection to avoid issues with concurrent adding/draining with processSubscribers.\n+                    // The expected cardinality of the array will be low, so copy/resize is \"good enough\" for now.\n+                    Object[] newArray = Arrays.copyOf(array, array.length + 1);\n+                    newArray[array.length] = subscriber;\n+                    if (stateUpdater.compareAndSet(this, currentState, newArray)) {\n+                        break;\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    private static final class DelayedSubscribePublisher<T> extends Publisher<T> {\n+        @SuppressWarnings(\"rawtypes\")\n+        private static final AtomicReferenceFieldUpdater<DelayedSubscribePublisher, Object> stateUpdater =\n+                newUpdater(DelayedSubscribePublisher.class, Object.class, \"state\");\n+        private static final Object ALLOW_SUBSCRIBE = new Object();\n+        private static final Object DRAINING_SUBSCRIBERS = new Object();\n+\n+        private final PublisherSource<T> publisher;\n+        /**\n+         * One of the following:\n+         * <li>\n+         *     <ul>{@code null} - initial state</ul>", "originalCommit": "7469332830d536d9dc82b82bad56e4860a3caf7e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODE5ODM4Nw==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r398198387", "bodyText": "Since we have only a single implementation of WriteDemandEstimator atm, and both classes (this and MaxSizeBasedWriteDemandEstimator) are in the same io.servicetalk.transport.netty.internal package, can we just make MaxSizeBasedWriteDemandEstimator public instead of introducing new factory? Because the code is internal, we can add it later if necessary.", "author": "idelpivnitskiy", "createdAt": "2020-03-25T22:04:00Z", "path": "servicetalk-transport-netty-internal/src/main/java/io/servicetalk/transport/netty/internal/WriteDemandEstimators.java", "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.transport.netty.internal;\n+\n+/**\n+ * Utility methods associated with {@link WriteDemandEstimator}.\n+ */\n+public final class WriteDemandEstimators {\n+    private WriteDemandEstimators() {\n+        // no instance\n+    }\n+\n+    /**\n+     * Returns a new instance of a default implementation of {@link WriteDemandEstimator}.\n+     *\n+     * @return A new instance of a default implementation of {@link WriteDemandEstimator}.\n+     */\n+    public static WriteDemandEstimator newDefaultEstimator() {\n+        return new MaxSizeBasedWriteDemandEstimator();", "originalCommit": "7469332830d536d9dc82b82bad56e4860a3caf7e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "fe35d0926b95b6d3e5a49967fceb0dcd4e934fdd", "url": "https://github.com/apple/servicetalk/commit/fe35d0926b95b6d3e5a49967fceb0dcd4e934fdd", "message": "review comments\n\n- move the Delayed sources to their own files, and add tests\n- make error handling more explicit, and add tests\n- address various other review comments\n- move queue logic to independent file to make APIs more clear and allow\nfor easier documentation", "committedDate": "2020-03-27T23:22:43Z", "type": "forcePushed"}, {"oid": "7656d2486bce249c2f4d7b2f0eeed800d4893089", "url": "https://github.com/apple/servicetalk/commit/7656d2486bce249c2f4d7b2f0eeed800d4893089", "message": "review comments\n\n- move the Delayed sources to their own files, and add tests\n- make error handling more explicit, and add tests\n- address various other review comments\n- move queue logic to independent file to make APIs more clear and allow\nfor easier documentation", "committedDate": "2020-03-27T23:32:46Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDUxODczOA==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r400518738", "bodyText": "@NiteshKant - this exception handling was added for demonstration purposes but is somewhat superfluous bcz the queue offer doesn't do any allocations (e.g. node allocation done outside the scope), and we don't always exhaustively protect against OOME type errors.\nalso the try/catch around the insertions are also somewhat much, because the Publisher  (or completable) will catch exceptions thrown during subscribe (in the internal handleSubscribe method). Let me know if you think it is worth keeping all of these cases.", "author": "Scottmitch", "createdAt": "2020-03-30T21:56:48Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,353 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.api.AsyncCloseable;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.http.netty.MpmcSequentialRunQueue.Node;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n+\n+import io.netty.channel.Channel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(NettyPipelinedConnection.class);\n+\n+    private final NettyConnection<Resp, Req> connection;\n+    private final MpmcSequentialRunQueue writeQueue;\n+    private final MpmcSequentialRunQueue readQueue;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+        writeQueue = new MpmcSequentialRunQueue();\n+        readQueue = new MpmcSequentialRunQueue();\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher) {\n+        return write(requestPublisher, connection::defaultFlushStrategy, WriteDemandEstimators::newDefaultEstimator);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        return Publisher.defer(() -> {\n+            // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+\n+            // Setup read side publisher and nodes\n+            DelayedSubscribePublisher<Resp> delayedReadPublisher = new DelayedSubscribePublisher<>(\n+                    toSource(connection.read()));\n+            Node readNode = new Node() {\n+                @Override\n+                public void run() {\n+                    try {\n+                        delayedReadPublisher.processSubscribers();\n+                    } catch (Throwable cause) {\n+                        closeOnError(connection, delayedReadPublisher, cause);\n+                    }\n+                }\n+            };\n+            Publisher<Resp> composedReadPublisher = delayedReadPublisher.liftSync(new ReadPopNextOperator(readNode));\n+\n+            // Setup write side publisher and nodes\n+            DelayedSubscribeCompletable delayedWriteCompletable = new DelayedSubscribeCompletable(toSource(\n+                            connection.write(requestPublisher, flushStrategySupplier, writeDemandEstimatorSupplier)));\n+            Node writeNode = new Node() {\n+                @Override\n+                public void run() {\n+                    try {\n+                        try {\n+                            readQueue.offer(readNode);\n+                        } catch (Throwable cause) {\n+                            delayedWriteCompletable.failSubscribers(cause);\n+                            // We have not started the write at this point, and the above operation will:\n+                            // - fail the write subscriber (pop the next write). We haven't subscribed to\n+                            // Completable returned from connection.write(..) and therefore the connection hasn't\n+                            // subscribed to the requestPublisher so there is nothing to cancel on the write side.\n+                            // - fail the merge operator (pop the next read, if still in progress), cancel the\n+                            // connection.read() (which may close the connection if the read is still active), and\n+                            // deliver an error to the downstream read Subscriber.\n+                            return;\n+                        }\n+\n+                        delayedWriteCompletable.processSubscribers();\n+                    } catch (Throwable cause) {\n+                        closeOnError(connection, delayedWriteCompletable, cause);\n+                    }\n+                }\n+            };\n+\n+            try {\n+                writeQueue.offer(writeNode);\n+            } catch (Throwable cause) {\n+                // The writeNode's run method handles exceptions as a result of Subscribe/external calls. An Exception", "originalCommit": "18a1efba918d766936fffbdb75604b0162f90e93", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "5572e4898545e9e1288da4b74223b157cee00cbb", "url": "https://github.com/apple/servicetalk/commit/5572e4898545e9e1288da4b74223b157cee00cbb", "message": "adjust error handling and add comments", "committedDate": "2020-03-30T23:47:57Z", "type": "forcePushed"}, {"oid": "eda404ea0d6e3a6fcc88084a3cbc1aac10bbee12", "url": "https://github.com/apple/servicetalk/commit/eda404ea0d6e3a6fcc88084a3cbc1aac10bbee12", "message": "remove delayed sources", "committedDate": "2020-04-01T03:26:38Z", "type": "forcePushed"}, {"oid": "b18787edc146525dc2ecadf7ef8c0c6e887d46b2", "url": "https://github.com/apple/servicetalk/commit/b18787edc146525dc2ecadf7ef8c0c6e887d46b2", "message": "add benchmark for NettyPipelinedConnection", "committedDate": "2020-04-02T03:05:28Z", "type": "forcePushed"}, {"oid": "a0d21aaa1121c30ad55e674fe1e4ded9c53e18dc", "url": "https://github.com/apple/servicetalk/commit/a0d21aaa1121c30ad55e674fe1e4ded9c53e18dc", "message": "add benchmark for NettyPipelinedConnection", "committedDate": "2020-04-07T19:07:42Z", "type": "forcePushed"}, {"oid": "c53de34d09bf4dee72002aecfee5c160062ee1de", "url": "https://github.com/apple/servicetalk/commit/c53de34d09bf4dee72002aecfee5c160062ee1de", "message": "add benchmark for NettyPipelinedConnection", "committedDate": "2020-04-08T00:00:40Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMzNTM5Mw==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r405335393", "bodyText": "nit: s/maybe/may be/", "author": "normanmaurer", "createdAt": "2020-04-08T08:07:47Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/MpmcSequentialRunQueue.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import javax.annotation.Nullable;\n+\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * This queue allows for Muli-Producer Multi-Consumer (Mpmc) threading semantics while also invoking the head\n+ * {@link Node}'s {@link Node#run()} in a serial fashion. The {@link Node#run()} will eventually trigger a\n+ * {@link #poll(Node)} (possibly asynchronously on another thread) which will invoke {@link Node#run()} on the next head\n+ * (assuming one exists).\n+ * <p>\n+ * Below is the expected interaction pattern and lifecycle of a Node:\n+ *     <pre>{@link #offer(Node)} -> {@link Node#run()} -> {@link #poll(Node)}</pre>\n+ * <p>\n+ * Although this queue supports Multi-Consumer threading semantics the {@link #poll(Node)} is typically only invoked\n+ * from a single thread (assuming successful runnable completion), it maybe invoked multiple times (potentially from", "originalCommit": "c53de34d09bf4dee72002aecfee5c160062ee1de", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMzNjY0OQ==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r405336649", "bodyText": "nit: do we need to guard against null ? As otherwise we could end up updating the tail with null and then fail once we try to run node.run() (if node is null). I think at least we should add an assert.", "author": "normanmaurer", "createdAt": "2020-04-08T08:09:44Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/MpmcSequentialRunQueue.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import javax.annotation.Nullable;\n+\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * This queue allows for Muli-Producer Multi-Consumer (Mpmc) threading semantics while also invoking the head\n+ * {@link Node}'s {@link Node#run()} in a serial fashion. The {@link Node#run()} will eventually trigger a\n+ * {@link #poll(Node)} (possibly asynchronously on another thread) which will invoke {@link Node#run()} on the next head\n+ * (assuming one exists).\n+ * <p>\n+ * Below is the expected interaction pattern and lifecycle of a Node:\n+ *     <pre>{@link #offer(Node)} -> {@link Node#run()} -> {@link #poll(Node)}</pre>\n+ * <p>\n+ * Although this queue supports Multi-Consumer threading semantics the {@link #poll(Node)} is typically only invoked\n+ * from a single thread (assuming successful runnable completion), it maybe invoked multiple times (potentially from\n+ * different threads) with the same {@link Node} due to cancellation/failure.\n+ */\n+final class MpmcSequentialRunQueue {\n+    private static final AtomicReferenceFieldUpdater<MpmcSequentialRunQueue, Node>\n+            tailUpdater = newUpdater(MpmcSequentialRunQueue.class, Node.class, \"tail\");\n+\n+    @Nullable\n+    private volatile Node tail;\n+\n+    /**\n+     * Offer {@link Node} to this queue.\n+     * @param node The {@link Node} to append. Must only exclusively be offered to this queue instance.\n+     */\n+    void offer(final Node node) {", "originalCommit": "c53de34d09bf4dee72002aecfee5c160062ee1de", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMzODkwNQ==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r405338905", "bodyText": "nit: I think offer is a bit of an odd name for what is happening in this method as it may queue or may run the node. So why not call it execute(...) just as Executor is doing (Which is very similar in terms of behaviour).", "author": "normanmaurer", "createdAt": "2020-04-08T08:13:35Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/MpmcSequentialRunQueue.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import javax.annotation.Nullable;\n+\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * This queue allows for Muli-Producer Multi-Consumer (Mpmc) threading semantics while also invoking the head\n+ * {@link Node}'s {@link Node#run()} in a serial fashion. The {@link Node#run()} will eventually trigger a\n+ * {@link #poll(Node)} (possibly asynchronously on another thread) which will invoke {@link Node#run()} on the next head\n+ * (assuming one exists).\n+ * <p>\n+ * Below is the expected interaction pattern and lifecycle of a Node:\n+ *     <pre>{@link #offer(Node)} -> {@link Node#run()} -> {@link #poll(Node)}</pre>\n+ * <p>\n+ * Although this queue supports Multi-Consumer threading semantics the {@link #poll(Node)} is typically only invoked\n+ * from a single thread (assuming successful runnable completion), it maybe invoked multiple times (potentially from\n+ * different threads) with the same {@link Node} due to cancellation/failure.\n+ */\n+final class MpmcSequentialRunQueue {\n+    private static final AtomicReferenceFieldUpdater<MpmcSequentialRunQueue, Node>\n+            tailUpdater = newUpdater(MpmcSequentialRunQueue.class, Node.class, \"tail\");\n+\n+    @Nullable\n+    private volatile Node tail;\n+\n+    /**\n+     * Offer {@link Node} to this queue.\n+     * @param node The {@link Node} to append. Must only exclusively be offered to this queue instance.\n+     */\n+    void offer(final Node node) {", "originalCommit": "c53de34d09bf4dee72002aecfee5c160062ee1de", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMzOTcwMQ==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r405339701", "bodyText": "same as above... I think the method name is a bit odd as it may queue but also may run.", "author": "normanmaurer", "createdAt": "2020-04-08T08:14:47Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/MpmcSequentialRunQueue.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import javax.annotation.Nullable;\n+\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * This queue allows for Muli-Producer Multi-Consumer (Mpmc) threading semantics while also invoking the head\n+ * {@link Node}'s {@link Node#run()} in a serial fashion. The {@link Node#run()} will eventually trigger a\n+ * {@link #poll(Node)} (possibly asynchronously on another thread) which will invoke {@link Node#run()} on the next head\n+ * (assuming one exists).\n+ * <p>\n+ * Below is the expected interaction pattern and lifecycle of a Node:\n+ *     <pre>{@link #offer(Node)} -> {@link Node#run()} -> {@link #poll(Node)}</pre>\n+ * <p>\n+ * Although this queue supports Multi-Consumer threading semantics the {@link #poll(Node)} is typically only invoked\n+ * from a single thread (assuming successful runnable completion), it maybe invoked multiple times (potentially from\n+ * different threads) with the same {@link Node} due to cancellation/failure.\n+ */\n+final class MpmcSequentialRunQueue {\n+    private static final AtomicReferenceFieldUpdater<MpmcSequentialRunQueue, Node>\n+            tailUpdater = newUpdater(MpmcSequentialRunQueue.class, Node.class, \"tail\");\n+\n+    @Nullable\n+    private volatile Node tail;\n+\n+    /**\n+     * Offer {@link Node} to this queue.\n+     * @param node The {@link Node} to append. Must only exclusively be offered to this queue instance.\n+     */\n+    void offer(final Node node) {\n+        for (;;) {\n+            final Node currentTail = this.tail;\n+            if (currentTail == null) {\n+                if (tailUpdater.compareAndSet(this, null, node)) {\n+                    // node has been inserted and is the only node, we initiate processing.\n+                    node.run();\n+                    break;\n+                }\n+                // Another thread won the race to offer a node, loop around and try again.\n+            } else if (currentTail.append(node)) {\n+                // Make the newly appended node visible as the tail. This is a best effort CAS and may fail because:\n+                // 1. Another thread is also inserting, has a stale tail, followed its existing tail links, and updated\n+                // the tail reference via offerPatchTail.\n+                // 2. The consumer thread has seen the link from the old tail to the new node, processed node,\n+                // popped node from the list (updated node's next to point to EMPTY_NODE), another producer thread\n+                // appends a new node, sees the tail is popped, and updates the tail reference via CAS.\n+                tailUpdater.compareAndSet(this, currentTail, node);\n+                break;\n+            } else if (currentTail.isPopped()) {\n+                // A previously appended node was processed, and popped before updating the tail after append. In that\n+                // case the tail maybe pointing to an invalid node and we clear it out.\n+                if (tailUpdater.compareAndSet(this, currentTail, node)) {\n+                    node.run();\n+                    break;\n+                }\n+                // Best effort to clear the tail, and failure is OK because:\n+                // 1. Another thread is in offer and already patched up the tail pointer and we will read the new tail\n+                // on the next loop iteration.\n+            } else {\n+                // We failed to append to currentTail's next pointer, which means currentTail isn't the tail, and\n+                // currentTail hasn't been popped. This means the tail pointer is stale, so we re-read the reference\n+                // to see if it changed, and if not attempt to walk the list and update the tail pointer.\n+                final Node newTail = this.tail;\n+                if (newTail == currentTail && offerUpdateStaleTail(node, currentTail)) {\n+                    break;\n+                }\n+            }\n+        }\n+    }\n+\n+    private boolean offerUpdateStaleTail(final Node node, final Node oldTail) {", "originalCommit": "c53de34d09bf4dee72002aecfee5c160062ee1de", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMzOTg2MA==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r405339860", "bodyText": "same comment with the method name.", "author": "normanmaurer", "createdAt": "2020-04-08T08:15:04Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/MpmcSequentialRunQueue.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import javax.annotation.Nullable;\n+\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * This queue allows for Muli-Producer Multi-Consumer (Mpmc) threading semantics while also invoking the head\n+ * {@link Node}'s {@link Node#run()} in a serial fashion. The {@link Node#run()} will eventually trigger a\n+ * {@link #poll(Node)} (possibly asynchronously on another thread) which will invoke {@link Node#run()} on the next head\n+ * (assuming one exists).\n+ * <p>\n+ * Below is the expected interaction pattern and lifecycle of a Node:\n+ *     <pre>{@link #offer(Node)} -> {@link Node#run()} -> {@link #poll(Node)}</pre>\n+ * <p>\n+ * Although this queue supports Multi-Consumer threading semantics the {@link #poll(Node)} is typically only invoked\n+ * from a single thread (assuming successful runnable completion), it maybe invoked multiple times (potentially from\n+ * different threads) with the same {@link Node} due to cancellation/failure.\n+ */\n+final class MpmcSequentialRunQueue {\n+    private static final AtomicReferenceFieldUpdater<MpmcSequentialRunQueue, Node>\n+            tailUpdater = newUpdater(MpmcSequentialRunQueue.class, Node.class, \"tail\");\n+\n+    @Nullable\n+    private volatile Node tail;\n+\n+    /**\n+     * Offer {@link Node} to this queue.\n+     * @param node The {@link Node} to append. Must only exclusively be offered to this queue instance.\n+     */\n+    void offer(final Node node) {\n+        for (;;) {\n+            final Node currentTail = this.tail;\n+            if (currentTail == null) {\n+                if (tailUpdater.compareAndSet(this, null, node)) {\n+                    // node has been inserted and is the only node, we initiate processing.\n+                    node.run();\n+                    break;\n+                }\n+                // Another thread won the race to offer a node, loop around and try again.\n+            } else if (currentTail.append(node)) {\n+                // Make the newly appended node visible as the tail. This is a best effort CAS and may fail because:\n+                // 1. Another thread is also inserting, has a stale tail, followed its existing tail links, and updated\n+                // the tail reference via offerPatchTail.\n+                // 2. The consumer thread has seen the link from the old tail to the new node, processed node,\n+                // popped node from the list (updated node's next to point to EMPTY_NODE), another producer thread\n+                // appends a new node, sees the tail is popped, and updates the tail reference via CAS.\n+                tailUpdater.compareAndSet(this, currentTail, node);\n+                break;\n+            } else if (currentTail.isPopped()) {\n+                // A previously appended node was processed, and popped before updating the tail after append. In that\n+                // case the tail maybe pointing to an invalid node and we clear it out.\n+                if (tailUpdater.compareAndSet(this, currentTail, node)) {\n+                    node.run();\n+                    break;\n+                }\n+                // Best effort to clear the tail, and failure is OK because:\n+                // 1. Another thread is in offer and already patched up the tail pointer and we will read the new tail\n+                // on the next loop iteration.\n+            } else {\n+                // We failed to append to currentTail's next pointer, which means currentTail isn't the tail, and\n+                // currentTail hasn't been popped. This means the tail pointer is stale, so we re-read the reference\n+                // to see if it changed, and if not attempt to walk the list and update the tail pointer.\n+                final Node newTail = this.tail;\n+                if (newTail == currentTail && offerUpdateStaleTail(node, currentTail)) {\n+                    break;\n+                }\n+            }\n+        }\n+    }\n+\n+    private boolean offerUpdateStaleTail(final Node node, final Node oldTail) {\n+        // tail is stale so attempt to iterate through the linked list and get the current tail reference.\n+        Node currentTail = oldTail.iterateToTail();\n+\n+        // Best effort check to see if the node is popped, then we attempt to directly insert node.\n+        if (currentTail.isPopped()) {\n+            if (tailUpdater.compareAndSet(this, oldTail, node)) {\n+                node.run();\n+                return true;\n+            }\n+        } else {\n+            // It is possible the currentTail has been popped after our best-effort check above. That is OK because\n+            // the offer method accounts for stale tail replacement.\n+            tailUpdater.compareAndSet(this, oldTail, currentTail);\n+        }\n+        // Best effort to update/clear the tail, and failure is OK because:\n+        // 1. Another thread is in offer and already patched up the tail pointer and we will read the new\n+        // tail on the next loop iteration.\n+        return false;\n+    }\n+\n+    /**\n+     * Pop {@code node} from this queue. This will invoke {@link Node#run()} on the next head of the queue\n+     * (if one exists).\n+     * <p>\n+     * Typically invoked by a single thread but maybe invoked by multiple threads, and maybe invoked multiple times.\n+     * Re-entry from {@link Node#run()} from another thread is permitted.\n+     * @param head A {@link Node} which has been passed to {@link #offer(Node)}, and whose {@link Node#run()} has been\n+     * invoked by this queue.\n+     */\n+    void poll(final Node head) {", "originalCommit": "c53de34d09bf4dee72002aecfee5c160062ee1de", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTM0MDA3Mg==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r405340072", "bodyText": "nit: {@code head}.", "author": "normanmaurer", "createdAt": "2020-04-08T08:15:29Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/MpmcSequentialRunQueue.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import javax.annotation.Nullable;\n+\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * This queue allows for Muli-Producer Multi-Consumer (Mpmc) threading semantics while also invoking the head\n+ * {@link Node}'s {@link Node#run()} in a serial fashion. The {@link Node#run()} will eventually trigger a\n+ * {@link #poll(Node)} (possibly asynchronously on another thread) which will invoke {@link Node#run()} on the next head\n+ * (assuming one exists).\n+ * <p>\n+ * Below is the expected interaction pattern and lifecycle of a Node:\n+ *     <pre>{@link #offer(Node)} -> {@link Node#run()} -> {@link #poll(Node)}</pre>\n+ * <p>\n+ * Although this queue supports Multi-Consumer threading semantics the {@link #poll(Node)} is typically only invoked\n+ * from a single thread (assuming successful runnable completion), it maybe invoked multiple times (potentially from\n+ * different threads) with the same {@link Node} due to cancellation/failure.\n+ */\n+final class MpmcSequentialRunQueue {\n+    private static final AtomicReferenceFieldUpdater<MpmcSequentialRunQueue, Node>\n+            tailUpdater = newUpdater(MpmcSequentialRunQueue.class, Node.class, \"tail\");\n+\n+    @Nullable\n+    private volatile Node tail;\n+\n+    /**\n+     * Offer {@link Node} to this queue.\n+     * @param node The {@link Node} to append. Must only exclusively be offered to this queue instance.\n+     */\n+    void offer(final Node node) {\n+        for (;;) {\n+            final Node currentTail = this.tail;\n+            if (currentTail == null) {\n+                if (tailUpdater.compareAndSet(this, null, node)) {\n+                    // node has been inserted and is the only node, we initiate processing.\n+                    node.run();\n+                    break;\n+                }\n+                // Another thread won the race to offer a node, loop around and try again.\n+            } else if (currentTail.append(node)) {\n+                // Make the newly appended node visible as the tail. This is a best effort CAS and may fail because:\n+                // 1. Another thread is also inserting, has a stale tail, followed its existing tail links, and updated\n+                // the tail reference via offerPatchTail.\n+                // 2. The consumer thread has seen the link from the old tail to the new node, processed node,\n+                // popped node from the list (updated node's next to point to EMPTY_NODE), another producer thread\n+                // appends a new node, sees the tail is popped, and updates the tail reference via CAS.\n+                tailUpdater.compareAndSet(this, currentTail, node);\n+                break;\n+            } else if (currentTail.isPopped()) {\n+                // A previously appended node was processed, and popped before updating the tail after append. In that\n+                // case the tail maybe pointing to an invalid node and we clear it out.\n+                if (tailUpdater.compareAndSet(this, currentTail, node)) {\n+                    node.run();\n+                    break;\n+                }\n+                // Best effort to clear the tail, and failure is OK because:\n+                // 1. Another thread is in offer and already patched up the tail pointer and we will read the new tail\n+                // on the next loop iteration.\n+            } else {\n+                // We failed to append to currentTail's next pointer, which means currentTail isn't the tail, and\n+                // currentTail hasn't been popped. This means the tail pointer is stale, so we re-read the reference\n+                // to see if it changed, and if not attempt to walk the list and update the tail pointer.\n+                final Node newTail = this.tail;\n+                if (newTail == currentTail && offerUpdateStaleTail(node, currentTail)) {\n+                    break;\n+                }\n+            }\n+        }\n+    }\n+\n+    private boolean offerUpdateStaleTail(final Node node, final Node oldTail) {\n+        // tail is stale so attempt to iterate through the linked list and get the current tail reference.\n+        Node currentTail = oldTail.iterateToTail();\n+\n+        // Best effort check to see if the node is popped, then we attempt to directly insert node.\n+        if (currentTail.isPopped()) {\n+            if (tailUpdater.compareAndSet(this, oldTail, node)) {\n+                node.run();\n+                return true;\n+            }\n+        } else {\n+            // It is possible the currentTail has been popped after our best-effort check above. That is OK because\n+            // the offer method accounts for stale tail replacement.\n+            tailUpdater.compareAndSet(this, oldTail, currentTail);\n+        }\n+        // Best effort to update/clear the tail, and failure is OK because:\n+        // 1. Another thread is in offer and already patched up the tail pointer and we will read the new\n+        // tail on the next loop iteration.\n+        return false;\n+    }\n+\n+    /**\n+     * Pop {@code node} from this queue. This will invoke {@link Node#run()} on the next head of the queue", "originalCommit": "c53de34d09bf4dee72002aecfee5c160062ee1de", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTM0MDc3OA==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r405340778", "bodyText": "nit: you could just have Node extend AtomicReference<Node> and remove the whole updater dance. This will also remove some overhead in terms of access checks.", "author": "normanmaurer", "createdAt": "2020-04-08T08:16:44Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/MpmcSequentialRunQueue.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import javax.annotation.Nullable;\n+\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * This queue allows for Muli-Producer Multi-Consumer (Mpmc) threading semantics while also invoking the head\n+ * {@link Node}'s {@link Node#run()} in a serial fashion. The {@link Node#run()} will eventually trigger a\n+ * {@link #poll(Node)} (possibly asynchronously on another thread) which will invoke {@link Node#run()} on the next head\n+ * (assuming one exists).\n+ * <p>\n+ * Below is the expected interaction pattern and lifecycle of a Node:\n+ *     <pre>{@link #offer(Node)} -> {@link Node#run()} -> {@link #poll(Node)}</pre>\n+ * <p>\n+ * Although this queue supports Multi-Consumer threading semantics the {@link #poll(Node)} is typically only invoked\n+ * from a single thread (assuming successful runnable completion), it maybe invoked multiple times (potentially from\n+ * different threads) with the same {@link Node} due to cancellation/failure.\n+ */\n+final class MpmcSequentialRunQueue {\n+    private static final AtomicReferenceFieldUpdater<MpmcSequentialRunQueue, Node>\n+            tailUpdater = newUpdater(MpmcSequentialRunQueue.class, Node.class, \"tail\");\n+\n+    @Nullable\n+    private volatile Node tail;\n+\n+    /**\n+     * Offer {@link Node} to this queue.\n+     * @param node The {@link Node} to append. Must only exclusively be offered to this queue instance.\n+     */\n+    void offer(final Node node) {\n+        for (;;) {\n+            final Node currentTail = this.tail;\n+            if (currentTail == null) {\n+                if (tailUpdater.compareAndSet(this, null, node)) {\n+                    // node has been inserted and is the only node, we initiate processing.\n+                    node.run();\n+                    break;\n+                }\n+                // Another thread won the race to offer a node, loop around and try again.\n+            } else if (currentTail.append(node)) {\n+                // Make the newly appended node visible as the tail. This is a best effort CAS and may fail because:\n+                // 1. Another thread is also inserting, has a stale tail, followed its existing tail links, and updated\n+                // the tail reference via offerPatchTail.\n+                // 2. The consumer thread has seen the link from the old tail to the new node, processed node,\n+                // popped node from the list (updated node's next to point to EMPTY_NODE), another producer thread\n+                // appends a new node, sees the tail is popped, and updates the tail reference via CAS.\n+                tailUpdater.compareAndSet(this, currentTail, node);\n+                break;\n+            } else if (currentTail.isPopped()) {\n+                // A previously appended node was processed, and popped before updating the tail after append. In that\n+                // case the tail maybe pointing to an invalid node and we clear it out.\n+                if (tailUpdater.compareAndSet(this, currentTail, node)) {\n+                    node.run();\n+                    break;\n+                }\n+                // Best effort to clear the tail, and failure is OK because:\n+                // 1. Another thread is in offer and already patched up the tail pointer and we will read the new tail\n+                // on the next loop iteration.\n+            } else {\n+                // We failed to append to currentTail's next pointer, which means currentTail isn't the tail, and\n+                // currentTail hasn't been popped. This means the tail pointer is stale, so we re-read the reference\n+                // to see if it changed, and if not attempt to walk the list and update the tail pointer.\n+                final Node newTail = this.tail;\n+                if (newTail == currentTail && offerUpdateStaleTail(node, currentTail)) {\n+                    break;\n+                }\n+            }\n+        }\n+    }\n+\n+    private boolean offerUpdateStaleTail(final Node node, final Node oldTail) {\n+        // tail is stale so attempt to iterate through the linked list and get the current tail reference.\n+        Node currentTail = oldTail.iterateToTail();\n+\n+        // Best effort check to see if the node is popped, then we attempt to directly insert node.\n+        if (currentTail.isPopped()) {\n+            if (tailUpdater.compareAndSet(this, oldTail, node)) {\n+                node.run();\n+                return true;\n+            }\n+        } else {\n+            // It is possible the currentTail has been popped after our best-effort check above. That is OK because\n+            // the offer method accounts for stale tail replacement.\n+            tailUpdater.compareAndSet(this, oldTail, currentTail);\n+        }\n+        // Best effort to update/clear the tail, and failure is OK because:\n+        // 1. Another thread is in offer and already patched up the tail pointer and we will read the new\n+        // tail on the next loop iteration.\n+        return false;\n+    }\n+\n+    /**\n+     * Pop {@code node} from this queue. This will invoke {@link Node#run()} on the next head of the queue\n+     * (if one exists).\n+     * <p>\n+     * Typically invoked by a single thread but maybe invoked by multiple threads, and maybe invoked multiple times.\n+     * Re-entry from {@link Node#run()} from another thread is permitted.\n+     * @param head A {@link Node} which has been passed to {@link #offer(Node)}, and whose {@link Node#run()} has been\n+     * invoked by this queue.\n+     */\n+    void poll(final Node head) {\n+        // This method maybe called multiple times on the same node, in which case next will be EMPTY_NODE and the run\n+        // method will be a noop.\n+        Node next = head.pop();\n+        if (next != null) {\n+            next.run();\n+        } else {\n+            tailUpdater.compareAndSet(this, head, null);\n+            // Best effort to clear the tail, and failure is OK because:\n+            // 1. Another thread appended this head, but has not yet updated the tail. In this case the tail will be\n+            // stale (e.g. pointing to head node that has already been processed) and corrected by future inserts.\n+        }\n+    }\n+\n+    /**\n+     * Single linked node in the queue.\n+     * <p>\n+     * Instances are single use only! No re-use or sharing between queue instances!\n+     */\n+    abstract static class Node {\n+        /**\n+         * the EMPTY_NODE's next must point to itself so that attempts to {@link #append(Node)} on it will fail,\n+         * and also be detected as {@link #isPopped()} and not prevent any new nodes from being\n+         * {@link #offer(Node) offered}.\n+         */\n+        private static final Node EMPTY_NODE = new Node(false) {\n+            @Override\n+            void run() {\n+            }\n+        };\n+        private static final AtomicReferenceFieldUpdater<Node, Node> nextUpdater =", "originalCommit": "c53de34d09bf4dee72002aecfee5c160062ee1de", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTM0MjI0Mg==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r405342242", "bodyText": "nit: getClass.getSimpleName()", "author": "normanmaurer", "createdAt": "2020-04-08T08:19:14Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.PublisherSource.Subscriber;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.http.netty.MpmcSequentialRunQueue.Node;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n+\n+import io.netty.channel.Channel;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static io.servicetalk.concurrent.internal.SubscriberUtils.deliverTerminalFromSource;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private final NettyConnection<Resp, Req> connection;\n+    private final MpmcSequentialRunQueue writeQueue;\n+    private final MpmcSequentialRunQueue readQueue;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+        writeQueue = new MpmcSequentialRunQueue();\n+        readQueue = new MpmcSequentialRunQueue();\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher) {\n+        return write(requestPublisher, connection::defaultFlushStrategy, WriteDemandEstimators::newDefaultEstimator);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+        return new Publisher<Resp>() {\n+            @Override\n+            protected void handleSubscribe(final Subscriber<? super Resp> subscriber) {\n+                final WriteNode node;\n+                try {\n+                    node = new WriteNode(subscriber, requestPublisher, flushStrategySupplier,\n+                            writeDemandEstimatorSupplier);\n+                } catch (Throwable cause) {\n+                    deliverTerminalFromSource(subscriber, cause);\n+                    return;\n+                }\n+\n+                try {\n+                    writeQueue.offer(node);\n+                } catch (Throwable cause) {\n+                    // The queue offer is not expected to throw, but if it does we cannot poll the WriteNode to recover.\n+                    // It is only safe to poll from the queue from Node#run() (or after it executes), so close.\n+                    closeConnection(subscriber, cause);\n+                }\n+            }\n+        };\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getName() + '(' + connection + ')';", "originalCommit": "c53de34d09bf4dee72002aecfee5c160062ee1de", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg1MDc4OQ==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r403850789", "bodyText": "There is a code-path in this method which may make this method throw; if onSubcribe() throws and then a subsequent call to onError() also throws. In which case we will not call writeQueue.poll() below", "author": "NiteshKant", "createdAt": "2020-04-06T06:15:30Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.PublisherSource.Subscriber;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.http.netty.MpmcSequentialRunQueue.Node;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n+\n+import io.netty.channel.Channel;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static io.servicetalk.concurrent.internal.SubscriberUtils.deliverTerminalFromSource;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private final NettyConnection<Resp, Req> connection;\n+    private final MpmcSequentialRunQueue writeQueue;\n+    private final MpmcSequentialRunQueue readQueue;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+        writeQueue = new MpmcSequentialRunQueue();\n+        readQueue = new MpmcSequentialRunQueue();\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher) {\n+        return write(requestPublisher, connection::defaultFlushStrategy, WriteDemandEstimators::newDefaultEstimator);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+        return new Publisher<Resp>() {\n+            @Override\n+            protected void handleSubscribe(final Subscriber<? super Resp> subscriber) {\n+                final WriteNode node;\n+                try {\n+                    node = new WriteNode(subscriber, requestPublisher, flushStrategySupplier,\n+                            writeDemandEstimatorSupplier);\n+                } catch (Throwable cause) {\n+                    deliverTerminalFromSource(subscriber, cause);\n+                    return;\n+                }\n+\n+                try {\n+                    writeQueue.offer(node);\n+                } catch (Throwable cause) {\n+                    // The queue offer is not expected to throw, but if it does we cannot poll the WriteNode to recover.\n+                    // It is only safe to poll from the queue from Node#run() (or after it executes), so close.\n+                    closeConnection(subscriber, cause);\n+                }\n+            }\n+        };\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void closeConnection(final Subscriber<? super Resp> subscriber, final Throwable cause) {\n+        toSource(connection.closeAsync().concat(Publisher.<Resp>failed(cause))).subscribe(subscriber);\n+    }\n+\n+    private final class WriteNode extends Node {\n+        private final Subscriber<? super Resp> subscriber;\n+        private final Publisher<Req> requestPublisher;\n+        private final Supplier<FlushStrategy> flushStrategySupplier;\n+        private final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier;\n+\n+        private WriteNode(final Subscriber<? super Resp> subscriber,\n+                          final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+            this.subscriber = subscriber;\n+            this.requestPublisher = requestPublisher;\n+            this.flushStrategySupplier = flushStrategySupplier;\n+            this.writeDemandEstimatorSupplier = writeDemandEstimatorSupplier;\n+        }\n+\n+        @Override\n+        void run() {\n+            final PublisherSource<Resp> src;\n+            try {\n+                src = toSource(connection.write(requestPublisher, flushStrategySupplier, writeDemandEstimatorSupplier)\n+                        .liftSync(new WritePopNextOperator(this))\n+                        .merge(new Publisher<Resp>() {\n+                            @Override\n+                            protected void handleSubscribe(final Subscriber<? super Resp> rSubscriber) {\n+                                try {\n+                                    readQueue.offer(new ReadNode(rSubscriber));\n+                                } catch (Throwable cause) {\n+                                    // We started the write, but failed to setup the read. This is considered fatal as\n+                                    // we will be out of sync for delivering future read responses.\n+                                    closeConnection(rSubscriber, cause);\n+                                }\n+                            }\n+                        }));\n+            } catch (Throwable cause) {\n+                // We failed to setup the write operation, which means we also failed to setup the read operation.\n+                // This failure maybe recoverable as our internal state isn't corrupted, so just propagate the error.\n+                deliverTerminalFromSource(subscriber, cause);", "originalCommit": "b18787edc146525dc2ecadf7ef8c0c6e887d46b2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODUxMTg3OQ==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r408511879", "bodyText": "lets just close the connection as you suggested on your next comment.", "author": "Scottmitch", "createdAt": "2020-04-15T00:27:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg1MDc4OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg1Mjc1Ng==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r403852756", "bodyText": "It is arguable whether the internal state is corrupter or not since connection.write() may have thrown. Avoiding to assume implementation of connection.write() and just closing connection may just be a safer option here.", "author": "NiteshKant", "createdAt": "2020-04-06T06:21:24Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.PublisherSource.Subscriber;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.http.netty.MpmcSequentialRunQueue.Node;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n+\n+import io.netty.channel.Channel;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static io.servicetalk.concurrent.internal.SubscriberUtils.deliverTerminalFromSource;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private final NettyConnection<Resp, Req> connection;\n+    private final MpmcSequentialRunQueue writeQueue;\n+    private final MpmcSequentialRunQueue readQueue;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+        writeQueue = new MpmcSequentialRunQueue();\n+        readQueue = new MpmcSequentialRunQueue();\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher) {\n+        return write(requestPublisher, connection::defaultFlushStrategy, WriteDemandEstimators::newDefaultEstimator);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+        return new Publisher<Resp>() {\n+            @Override\n+            protected void handleSubscribe(final Subscriber<? super Resp> subscriber) {\n+                final WriteNode node;\n+                try {\n+                    node = new WriteNode(subscriber, requestPublisher, flushStrategySupplier,\n+                            writeDemandEstimatorSupplier);\n+                } catch (Throwable cause) {\n+                    deliverTerminalFromSource(subscriber, cause);\n+                    return;\n+                }\n+\n+                try {\n+                    writeQueue.offer(node);\n+                } catch (Throwable cause) {\n+                    // The queue offer is not expected to throw, but if it does we cannot poll the WriteNode to recover.\n+                    // It is only safe to poll from the queue from Node#run() (or after it executes), so close.\n+                    closeConnection(subscriber, cause);\n+                }\n+            }\n+        };\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void closeConnection(final Subscriber<? super Resp> subscriber, final Throwable cause) {\n+        toSource(connection.closeAsync().concat(Publisher.<Resp>failed(cause))).subscribe(subscriber);\n+    }\n+\n+    private final class WriteNode extends Node {\n+        private final Subscriber<? super Resp> subscriber;\n+        private final Publisher<Req> requestPublisher;\n+        private final Supplier<FlushStrategy> flushStrategySupplier;\n+        private final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier;\n+\n+        private WriteNode(final Subscriber<? super Resp> subscriber,\n+                          final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+            this.subscriber = subscriber;\n+            this.requestPublisher = requestPublisher;\n+            this.flushStrategySupplier = flushStrategySupplier;\n+            this.writeDemandEstimatorSupplier = writeDemandEstimatorSupplier;\n+        }\n+\n+        @Override\n+        void run() {\n+            final PublisherSource<Resp> src;\n+            try {\n+                src = toSource(connection.write(requestPublisher, flushStrategySupplier, writeDemandEstimatorSupplier)\n+                        .liftSync(new WritePopNextOperator(this))\n+                        .merge(new Publisher<Resp>() {\n+                            @Override\n+                            protected void handleSubscribe(final Subscriber<? super Resp> rSubscriber) {\n+                                try {\n+                                    readQueue.offer(new ReadNode(rSubscriber));\n+                                } catch (Throwable cause) {\n+                                    // We started the write, but failed to setup the read. This is considered fatal as\n+                                    // we will be out of sync for delivering future read responses.\n+                                    closeConnection(rSubscriber, cause);\n+                                }\n+                            }\n+                        }));\n+            } catch (Throwable cause) {\n+                // We failed to setup the write operation, which means we also failed to setup the read operation.\n+                // This failure maybe recoverable as our internal state isn't corrupted, so just propagate the error.", "originalCommit": "b18787edc146525dc2ecadf7ef8c0c6e887d46b2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODUxMTE2NA==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r408511164", "bodyText": "connection.close() sgtm", "author": "Scottmitch", "createdAt": "2020-04-15T00:24:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg1Mjc1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg1NDgyNw==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r403854827", "bodyText": "Hypothetically speaking if offer() threw after adding the node but without starting the write, this will basically mean that all subsequent writes will keep accumulating in the queue and will never be run as the Queue is technically having a node that has not completed write?", "author": "NiteshKant", "createdAt": "2020-04-06T06:27:31Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.PublisherSource.Subscriber;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.http.netty.MpmcSequentialRunQueue.Node;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n+\n+import io.netty.channel.Channel;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static io.servicetalk.concurrent.internal.SubscriberUtils.deliverTerminalFromSource;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private final NettyConnection<Resp, Req> connection;\n+    private final MpmcSequentialRunQueue writeQueue;\n+    private final MpmcSequentialRunQueue readQueue;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+        writeQueue = new MpmcSequentialRunQueue();\n+        readQueue = new MpmcSequentialRunQueue();\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher) {\n+        return write(requestPublisher, connection::defaultFlushStrategy, WriteDemandEstimators::newDefaultEstimator);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+        return new Publisher<Resp>() {\n+            @Override\n+            protected void handleSubscribe(final Subscriber<? super Resp> subscriber) {\n+                final WriteNode node;\n+                try {\n+                    node = new WriteNode(subscriber, requestPublisher, flushStrategySupplier,\n+                            writeDemandEstimatorSupplier);\n+                } catch (Throwable cause) {\n+                    deliverTerminalFromSource(subscriber, cause);\n+                    return;\n+                }\n+\n+                try {\n+                    writeQueue.offer(node);\n+                } catch (Throwable cause) {\n+                    // The queue offer is not expected to throw, but if it does we cannot poll the WriteNode to recover.", "originalCommit": "b18787edc146525dc2ecadf7ef8c0c6e887d46b2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODUxODg2Mw==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r408518863", "bodyText": "If a node is added and not removed yes the queue would accumulate. The queue/executor can be made more robust to catch exceptions when synchronously calling run() but if the \"poll\" method isn't called in the async control flow the same issue will occur. Do you see code paths which may lead to this? we are also closing the connection which should lead to the queues being discarded.", "author": "Scottmitch", "createdAt": "2020-04-15T00:52:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg1NDgyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODUzMDgzMg==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r408530832", "bodyText": "I adjusted the queue APIs to:\n\ncapture synchronous exceptions\nmake the \"execute next task\" condition more clear (e.g. provided as an argument to the run(..) method).", "author": "Scottmitch", "createdAt": "2020-04-15T01:38:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg1NDgyNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg1NzQ4OQ==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r403857489", "bodyText": "Should we be popping the next node here too?", "author": "NiteshKant", "createdAt": "2020-04-06T06:34:44Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.PublisherSource.Subscriber;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.http.netty.MpmcSequentialRunQueue.Node;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n+\n+import io.netty.channel.Channel;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static io.servicetalk.concurrent.internal.SubscriberUtils.deliverTerminalFromSource;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private final NettyConnection<Resp, Req> connection;\n+    private final MpmcSequentialRunQueue writeQueue;\n+    private final MpmcSequentialRunQueue readQueue;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+        writeQueue = new MpmcSequentialRunQueue();\n+        readQueue = new MpmcSequentialRunQueue();\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher) {\n+        return write(requestPublisher, connection::defaultFlushStrategy, WriteDemandEstimators::newDefaultEstimator);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+        return new Publisher<Resp>() {\n+            @Override\n+            protected void handleSubscribe(final Subscriber<? super Resp> subscriber) {\n+                final WriteNode node;\n+                try {\n+                    node = new WriteNode(subscriber, requestPublisher, flushStrategySupplier,\n+                            writeDemandEstimatorSupplier);\n+                } catch (Throwable cause) {\n+                    deliverTerminalFromSource(subscriber, cause);\n+                    return;\n+                }\n+\n+                try {\n+                    writeQueue.offer(node);\n+                } catch (Throwable cause) {\n+                    // The queue offer is not expected to throw, but if it does we cannot poll the WriteNode to recover.\n+                    // It is only safe to poll from the queue from Node#run() (or after it executes), so close.\n+                    closeConnection(subscriber, cause);\n+                }\n+            }\n+        };\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void closeConnection(final Subscriber<? super Resp> subscriber, final Throwable cause) {\n+        toSource(connection.closeAsync().concat(Publisher.<Resp>failed(cause))).subscribe(subscriber);\n+    }\n+\n+    private final class WriteNode extends Node {\n+        private final Subscriber<? super Resp> subscriber;\n+        private final Publisher<Req> requestPublisher;\n+        private final Supplier<FlushStrategy> flushStrategySupplier;\n+        private final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier;\n+\n+        private WriteNode(final Subscriber<? super Resp> subscriber,\n+                          final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+            this.subscriber = subscriber;\n+            this.requestPublisher = requestPublisher;\n+            this.flushStrategySupplier = flushStrategySupplier;\n+            this.writeDemandEstimatorSupplier = writeDemandEstimatorSupplier;\n+        }\n+\n+        @Override\n+        void run() {\n+            final PublisherSource<Resp> src;\n+            try {\n+                src = toSource(connection.write(requestPublisher, flushStrategySupplier, writeDemandEstimatorSupplier)\n+                        .liftSync(new WritePopNextOperator(this))\n+                        .merge(new Publisher<Resp>() {\n+                            @Override\n+                            protected void handleSubscribe(final Subscriber<? super Resp> rSubscriber) {\n+                                try {\n+                                    readQueue.offer(new ReadNode(rSubscriber));\n+                                } catch (Throwable cause) {\n+                                    // We started the write, but failed to setup the read. This is considered fatal as\n+                                    // we will be out of sync for delivering future read responses.\n+                                    closeConnection(rSubscriber, cause);\n+                                }\n+                            }\n+                        }));\n+            } catch (Throwable cause) {\n+                // We failed to setup the write operation, which means we also failed to setup the read operation.\n+                // This failure maybe recoverable as our internal state isn't corrupted, so just propagate the error.\n+                deliverTerminalFromSource(subscriber, cause);\n+                writeQueue.poll(this);\n+                return;\n+            }\n+            src.subscribe(subscriber);\n+        }\n+    }\n+\n+    private final class ReadNode extends Node {\n+        private final Subscriber<? super Resp> subscriber;\n+\n+        private ReadNode(final Subscriber<? super Resp> subscriber) {\n+            this.subscriber = subscriber;\n+        }\n+\n+        @Override\n+        void run() {\n+            final PublisherSource<Resp> src;\n+            try {\n+                src = toSource(connection.read().liftSync(new ReadPopNextOperator(this)));\n+            } catch (Throwable cause) {\n+                // We started the write, but failed to setup the read. This is considered fatal as we will be out of\n+                // sync for delivering future read responses.\n+                closeConnection(subscriber, cause);", "originalCommit": "b18787edc146525dc2ecadf7ef8c0c6e887d46b2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODUzMTE4MA==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r408531180", "bodyText": "yes! fixed.", "author": "Scottmitch", "createdAt": "2020-04-15T01:39:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg1NzQ4OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzE1NDk4OA==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r407154988", "bodyText": "Looks like this can race with poll() and run concurrent tasks.\ntail = node 1; (node1 currently running)\nThread 1:  \noffer (node 2)\n - node1.append(node2) <- success\n    - suspended\nThread 2 (concurrent with Thread 1):\n  offer(node3)\n  fails node1.append() as raced with Thread 1\n  suspended\n\nThread 3:\n  node 1 returns; node1.pop() returns node 2;\n     node 2.run();\n     returns;\n\nThread 2 resumes:\n    node1.isPopped() <- true\n    tailUpdater.cas(node1, node3) <- true\n      node3.run(); <-- we are running 2 nodes concurrently (Thread 2 => node 3, Thread 3 => node 2)", "author": "NiteshKant", "createdAt": "2020-04-12T06:44:42Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/MpmcSequentialRunQueue.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import javax.annotation.Nullable;\n+\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * This queue allows for Muli-Producer Multi-Consumer (Mpmc) threading semantics while also invoking the head\n+ * {@link Node}'s {@link Node#run()} in a serial fashion. The {@link Node#run()} will eventually trigger a\n+ * {@link #poll(Node)} (possibly asynchronously on another thread) which will invoke {@link Node#run()} on the next head\n+ * (assuming one exists).\n+ * <p>\n+ * Below is the expected interaction pattern and lifecycle of a Node:\n+ *     <pre>{@link #offer(Node)} -> {@link Node#run()} -> {@link #poll(Node)}</pre>\n+ * <p>\n+ * Although this queue supports Multi-Consumer threading semantics the {@link #poll(Node)} is typically only invoked\n+ * from a single thread (assuming successful runnable completion), it maybe invoked multiple times (potentially from\n+ * different threads) with the same {@link Node} due to cancellation/failure.\n+ */\n+final class MpmcSequentialRunQueue {\n+    private static final AtomicReferenceFieldUpdater<MpmcSequentialRunQueue, Node>\n+            tailUpdater = newUpdater(MpmcSequentialRunQueue.class, Node.class, \"tail\");\n+\n+    @Nullable\n+    private volatile Node tail;\n+\n+    /**\n+     * Offer {@link Node} to this queue.\n+     * @param node The {@link Node} to append. Must only exclusively be offered to this queue instance.\n+     */\n+    void offer(final Node node) {\n+        for (;;) {\n+            final Node currentTail = this.tail;\n+            if (currentTail == null) {\n+                if (tailUpdater.compareAndSet(this, null, node)) {\n+                    // node has been inserted and is the only node, we initiate processing.\n+                    node.run();\n+                    break;\n+                }\n+                // Another thread won the race to offer a node, loop around and try again.\n+            } else if (currentTail.append(node)) {\n+                // Make the newly appended node visible as the tail. This is a best effort CAS and may fail because:\n+                // 1. Another thread is also inserting, has a stale tail, followed its existing tail links, and updated\n+                // the tail reference via offerPatchTail.\n+                // 2. The consumer thread has seen the link from the old tail to the new node, processed node,\n+                // popped node from the list (updated node's next to point to EMPTY_NODE), another producer thread\n+                // appends a new node, sees the tail is popped, and updates the tail reference via CAS.\n+                tailUpdater.compareAndSet(this, currentTail, node);\n+                break;\n+            } else if (currentTail.isPopped()) {\n+                // A previously appended node was processed, and popped before updating the tail after append. In that\n+                // case the tail maybe pointing to an invalid node and we clear it out.\n+                if (tailUpdater.compareAndSet(this, currentTail, node)) {\n+                    node.run();", "originalCommit": "c53de34d09bf4dee72002aecfee5c160062ee1de", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODU1ODU1MQ==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r408558551", "bodyText": "great find \ud83d\udd25\ud83d\udd10! let me just use the simplified queue approach as you suggested offline. that way we can get this in and optimize the queue elements later if necessary.", "author": "Scottmitch", "createdAt": "2020-04-15T03:24:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzE1NDk4OA=="}], "type": "inlineReview"}, {"oid": "19e2d3dd9e4345332ef958382148c87915d818f4", "url": "https://github.com/apple/servicetalk/commit/19e2d3dd9e4345332ef958382148c87915d818f4", "message": "remove MpmcSequentialRunQueue, use MPSC compatible queues", "committedDate": "2020-04-15T04:35:42Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODU3NjA1MQ==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r408576051", "bodyText": "@NiteshKant - note these are utilities that are also shared with #1011 and #1014 ... which ever PR lands first will bring them in and I will rebase to avoid duplication.", "author": "Scottmitch", "createdAt": "2020-04-15T04:37:55Z", "path": "servicetalk-concurrent-internal/src/main/java/io/servicetalk/concurrent/internal/ConcurrentUtils.java", "diffHunk": "@@ -31,11 +31,46 @@\n \n     public static final int CONCURRENT_IDLE = 0;\n     public static final int CONCURRENT_EMITTING = 1;\n+    private static final int CONCURRENT_PENDING = 2;\n \n     private ConcurrentUtils() {\n         // No instances.\n     }\n \n+    /**\n+     * Acquire a lock that is exclusively held with no re-entry, but attempts to acquire the lock while it is\n+     * held can be detected by {@link #releasePendingLock(AtomicIntegerFieldUpdater, Object)}.\n+     * @param lockUpdater The {@link AtomicIntegerFieldUpdater} used to control the lock state.\n+     * @param owner The owner of the lock object.\n+     * @param <T> The type of object that owns the lock.\n+     * @return {@code true} if the lock was acquired, {@code false} otherwise.\n+     */\n+    public static <T> boolean acquirePendingLock(AtomicIntegerFieldUpdater<T> lockUpdater, T owner) {", "originalCommit": "19e2d3dd9e4345332ef958382148c87915d818f4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYwNDExNw==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r408604117", "bodyText": "nit: Should we enable it again after we are done with the benchmark ? IF so we may just do it in setup() and tearDown() methods", "author": "normanmaurer", "createdAt": "2020-04-15T06:17:00Z", "path": "servicetalk-benchmarks/src/jmh/java/io/servicetalk/http/netty/NettyPipelinedConnectionBenchmark.java", "diffHunk": "@@ -0,0 +1,268 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.api.AsyncContext;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.http.api.HttpProtocolVersion;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategies;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.GlobalExecutionContext;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+\n+import io.netty.channel.Channel;\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Fork;\n+import org.openjdk.jmh.annotations.Level;\n+import org.openjdk.jmh.annotations.Measurement;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.Scope;\n+import org.openjdk.jmh.annotations.Setup;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.TearDown;\n+import org.openjdk.jmh.annotations.Warmup;\n+\n+import java.net.InetSocketAddress;\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.CyclicBarrier;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.Cancellable.IGNORE_CANCEL;\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+\n+@Fork(value = 1)\n+@State(Scope.Benchmark)\n+@Warmup(iterations = 5, time = 3)\n+@Measurement(iterations = 5, time = 3)\n+@BenchmarkMode(Mode.Throughput)\n+public class NettyPipelinedConnectionBenchmark {\n+    static {\n+        AsyncContext.disable(); // reduce noise in benchmarks.", "originalCommit": "19e2d3dd9e4345332ef958382148c87915d818f4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODg3NDA5NQ==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r408874095", "bodyText": "we currently don't expose an \"enable\" it is just intended as a one-time \"disable\" ... I think this is OK for benchmarks.", "author": "Scottmitch", "createdAt": "2020-04-15T14:12:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYwNDExNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYwNDc0MQ==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r408604741", "bodyText": "nit: I wonder if unbounded may be risky here... But I guess it should be fine ?", "author": "normanmaurer", "createdAt": "2020-04-15T06:18:41Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.PublisherSource.Subscriber;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.concurrent.internal.ConcurrentUtils;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n+\n+import io.netty.channel.Channel;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static io.servicetalk.concurrent.internal.ConcurrentUtils.acquirePendingLock;\n+import static io.servicetalk.concurrent.internal.ConcurrentUtils.releasePendingLock;\n+import static io.servicetalk.concurrent.internal.SubscriberUtils.deliverTerminalFromSource;\n+import static io.servicetalk.utils.internal.PlatformDependent.newUnboundedMpscQueue;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicIntegerFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicIntegerFieldUpdater<NettyPipelinedConnection> writeQueueLockUpdater =\n+            newUpdater(NettyPipelinedConnection.class, \"writeQueueLock\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicIntegerFieldUpdater<NettyPipelinedConnection> readQueueLockUpdater =\n+            newUpdater(NettyPipelinedConnection.class, \"readQueueLock\");\n+    private final NettyConnection<Resp, Req> connection;\n+    private final Queue<WriteTask> writeQueue;\n+    private final Queue<Subscriber<? super Resp>> readQueue;\n+    @SuppressWarnings(\"unused\")\n+    private volatile int writeQueueLock;\n+    @SuppressWarnings(\"unused\")\n+    private volatile int readQueueLock;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+        writeQueue = newUnboundedMpscQueue();\n+        readQueue = newUnboundedMpscQueue();", "originalCommit": "19e2d3dd9e4345332ef958382148c87915d818f4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODg3MjY0Mg==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r408872642", "bodyText": "We apply limits at a higher level in the client.", "author": "Scottmitch", "createdAt": "2020-04-15T14:10:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYwNDc0MQ=="}], "type": "inlineReview"}, {"oid": "4e47b9196925fb08fdb54a2ef984428c546822c8", "url": "https://github.com/apple/servicetalk/commit/4e47b9196925fb08fdb54a2ef984428c546822c8", "message": "HTTP Client Pipelining fullduplex\n\nMotivation:\nThe queue which orders and sequences HTTP pipelining on the client side\nhas been shown to lead to duplicate subscribe exceptions and also\ndoesn't support full duplex read/write.\n\nModifications:\n- The first was related to DefaultNettyPipelinedConnection\nwhich may have enqueued out of order which lead to a duplicate subscribe\nexception on NettyChannelPublisher. The DefaultNettyPipelinedConnection\nwas rewritten to avoid using the SequentialTaskQueue (which relies upon\nthread locals for single item execution and async completion) and also\ndoesn't allow for full duplex (write must finish before read starts),\nand those issues are both fixed.\n- ClientClosureRaceTest is intentionally closing the server connection\nabrubtley, which may result in writing a request that is not\nautomatically retryable. The retry strategy should always retry in this\ncase or else the test may hang/fail.\n\nResult:\nHTTP client now support full duplex pipelining.", "committedDate": "2020-04-28T04:04:31Z", "type": "commit"}, {"oid": "020649cfd6585f30136c3107120e0146ed988252", "url": "https://github.com/apple/servicetalk/commit/020649cfd6585f30136c3107120e0146ed988252", "message": "review comments\n\n- move the Delayed sources to their own files, and add tests\n- make error handling more explicit, and add tests\n- address various other review comments\n- move queue logic to independent file to make APIs more clear and allow\nfor easier documentation", "committedDate": "2020-04-28T04:04:31Z", "type": "commit"}, {"oid": "ac819cf1983284bad77319ae2a3680caf929f34d", "url": "https://github.com/apple/servicetalk/commit/ac819cf1983284bad77319ae2a3680caf929f34d", "message": "adjust error handling and add comments", "committedDate": "2020-04-28T04:04:31Z", "type": "commit"}, {"oid": "02e5f2a44e058a2da4a22c337f213abcfd3b3476", "url": "https://github.com/apple/servicetalk/commit/02e5f2a44e058a2da4a22c337f213abcfd3b3476", "message": "more clarification of error flow, removal of unecessary code", "committedDate": "2020-04-28T04:04:31Z", "type": "commit"}, {"oid": "18523787d5acbf15b1519c4d0c34a64c53117fc8", "url": "https://github.com/apple/servicetalk/commit/18523787d5acbf15b1519c4d0c34a64c53117fc8", "message": "remove delayed sources", "committedDate": "2020-04-28T04:04:31Z", "type": "commit"}, {"oid": "83a1f5f347c418cb82066e7ea13fb0aefd8080ca", "url": "https://github.com/apple/servicetalk/commit/83a1f5f347c418cb82066e7ea13fb0aefd8080ca", "message": "update comment", "committedDate": "2020-04-28T04:04:31Z", "type": "commit"}, {"oid": "0218166d6a6caad6accdf9bc44e1413a675eb65a", "url": "https://github.com/apple/servicetalk/commit/0218166d6a6caad6accdf9bc44e1413a675eb65a", "message": "more clarification comments", "committedDate": "2020-04-28T04:04:31Z", "type": "commit"}, {"oid": "e31b7674a0f19a7b746286ab792522121fc9e52b", "url": "https://github.com/apple/servicetalk/commit/e31b7674a0f19a7b746286ab792522121fc9e52b", "message": "adjust methods and add comments for concurrent queue", "committedDate": "2020-04-28T04:04:31Z", "type": "commit"}, {"oid": "5e70d09f6e290f3f796351b6cd2a8f5ca612e22c", "url": "https://github.com/apple/servicetalk/commit/5e70d09f6e290f3f796351b6cd2a8f5ca612e22c", "message": "add benchmark for NettyPipelinedConnection", "committedDate": "2020-04-28T04:04:31Z", "type": "commit"}, {"oid": "48e60622d78c70c83cf4718473b609291e0c072e", "url": "https://github.com/apple/servicetalk/commit/48e60622d78c70c83cf4718473b609291e0c072e", "message": "remove MpmcSequentialRunQueue, use MPSC compatible queues", "committedDate": "2020-04-28T04:08:04Z", "type": "commit"}, {"oid": "912ff44a47c19d278a5c617a9e619542cee8453b", "url": "https://github.com/apple/servicetalk/commit/912ff44a47c19d278a5c617a9e619542cee8453b", "message": "adjust exception handling", "committedDate": "2020-04-28T04:09:05Z", "type": "commit"}, {"oid": "89e482ae0bd3e0828263149472c17bbe4b8a3daf", "url": "https://github.com/apple/servicetalk/commit/89e482ae0bd3e0828263149472c17bbe4b8a3daf", "message": "re-acquire lock during queue drain after releasing lock", "committedDate": "2020-04-28T04:09:56Z", "type": "commit"}, {"oid": "e67ddd3040b7d00c14ad7c8da5750ac327447447", "url": "https://github.com/apple/servicetalk/commit/e67ddd3040b7d00c14ad7c8da5750ac327447447", "message": "move try/catch in drain method", "committedDate": "2020-04-28T04:12:42Z", "type": "commit"}, {"oid": "e67ddd3040b7d00c14ad7c8da5750ac327447447", "url": "https://github.com/apple/servicetalk/commit/e67ddd3040b7d00c14ad7c8da5750ac327447447", "message": "move try/catch in drain method", "committedDate": "2020-04-28T04:12:42Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg3ODU2OQ==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r416878569", "bodyText": "nit: discrepancy b/w name and action here; either rename method to addTryAcquireLock or use queue.offer()", "author": "NiteshKant", "createdAt": "2020-04-28T19:48:24Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,362 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.PublisherSource.Subscriber;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.concurrent.internal.ConcurrentUtils;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n+\n+import io.netty.channel.Channel;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static io.servicetalk.concurrent.internal.ConcurrentUtils.releaseLock;\n+import static io.servicetalk.concurrent.internal.ConcurrentUtils.tryAcquireLock;\n+import static io.servicetalk.concurrent.internal.SubscriberUtils.deliverTerminalFromSource;\n+import static io.servicetalk.utils.internal.PlatformDependent.newUnboundedMpscQueue;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicIntegerFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicIntegerFieldUpdater<NettyPipelinedConnection> writeQueueLockUpdater =\n+            newUpdater(NettyPipelinedConnection.class, \"writeQueueLock\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicIntegerFieldUpdater<NettyPipelinedConnection> readQueueLockUpdater =\n+            newUpdater(NettyPipelinedConnection.class, \"readQueueLock\");\n+    private final NettyConnection<Resp, Req> connection;\n+    private final Queue<WriteTask> writeQueue;\n+    private final Queue<Subscriber<? super Resp>> readQueue;\n+    @SuppressWarnings(\"unused\")\n+    private volatile int writeQueueLock;\n+    @SuppressWarnings(\"unused\")\n+    private volatile int readQueueLock;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+        writeQueue = newUnboundedMpscQueue();\n+        readQueue = newUnboundedMpscQueue();\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher) {\n+        return write(requestPublisher, connection::defaultFlushStrategy, WriteDemandEstimators::newDefaultEstimator);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+        return new Publisher<Resp>() {\n+            @Override\n+            protected void handleSubscribe(final Subscriber<? super Resp> subscriber) {\n+                final WriteTask firstWriteTask;\n+                try {\n+                    firstWriteTask = offerTryAcquireLock(writeQueue, writeQueueLockUpdater,\n+                            new WriteTask(subscriber, requestPublisher, flushStrategySupplier,\n+                                    writeDemandEstimatorSupplier));\n+                } catch (Throwable cause) {\n+                    closeConnection(subscriber, cause);\n+                    return;\n+                }\n+\n+                if (firstWriteTask != null) {\n+                    firstWriteTask.run();\n+                }\n+            }\n+        };\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getSimpleName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void closeConnection(final Subscriber<? super Resp> subscriber, final Throwable cause) {\n+        toSource(connection.closeAsync().concat(Publisher.<Resp>failed(cause))).subscribe(subscriber);\n+    }\n+\n+    private void tryStartRead(@Nullable Subscriber<? super Resp> subscriber) {\n+        if (subscriber == null) {\n+            return;\n+        }\n+        final PublisherSource<Resp> src;\n+        try {\n+            src = toSource(connection.read().afterFinally(() ->\n+                    tryStartRead(pollWithLockAcquired(readQueue, readQueueLockUpdater))));\n+        } catch (Throwable cause) {\n+            handleReadSetupError(subscriber, cause);\n+            return;\n+        }\n+        src.subscribe(subscriber);\n+    }\n+\n+    private final class WriteTask {\n+        private final Subscriber<? super Resp> subscriber;\n+        private final Publisher<Req> requestPublisher;\n+        private final Supplier<FlushStrategy> flushStrategySupplier;\n+        private final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier;\n+\n+        private WriteTask(final Subscriber<? super Resp> subscriber,\n+                          final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+            this.subscriber = subscriber;\n+            this.requestPublisher = requestPublisher;\n+            this.flushStrategySupplier = flushStrategySupplier;\n+            this.writeDemandEstimatorSupplier = writeDemandEstimatorSupplier;\n+        }\n+\n+        void run() {\n+            final PublisherSource<Resp> src;\n+            try {\n+                src = toSource(connection.write(requestPublisher, flushStrategySupplier,\n+                        writeDemandEstimatorSupplier)\n+                        .afterFinally(() -> {\n+                            WriteTask nextWriteTask = pollWithLockAcquired(writeQueue, writeQueueLockUpdater);\n+                            if (nextWriteTask != null) {\n+                                nextWriteTask.run();\n+                            }\n+                        }).merge(new Publisher<Resp>() {\n+                            @Override\n+                            protected void handleSubscribe(final Subscriber<? super Resp> rSubscriber) {\n+                                final Subscriber<? super Resp> firstReadSubscriber;\n+                                try {\n+                                    firstReadSubscriber =\n+                                            offerTryAcquireLock(readQueue, readQueueLockUpdater, rSubscriber);\n+                                } catch (Throwable cause) {\n+                                    closeConnection(rSubscriber, cause);\n+                                    return;\n+                                }\n+\n+                                tryStartRead(firstReadSubscriber);\n+                            }\n+                        }));\n+            } catch (Throwable cause) {\n+                handleWriteSetupError(subscriber, cause);\n+                return;\n+            }\n+            src.subscribe(subscriber);\n+        }\n+    }\n+\n+    private void handleWriteSetupError(Subscriber<? super Resp> subscriber, Throwable cause) {\n+        try {\n+            closeConnection(subscriber, cause);\n+        } finally {\n+            // the lock has been acquired!\n+            do {\n+                WriteTask nextWriteTask;\n+                while ((nextWriteTask = writeQueue.poll()) != null) {\n+                    deliverTerminalFromSource(nextWriteTask.subscriber, cause);\n+                }\n+            } while (!releaseLock(writeQueueLockUpdater, this) && tryAcquireLock(writeQueueLockUpdater, this));\n+        }\n+    }\n+\n+    private void handleReadSetupError(Subscriber<? super Resp> subscriber, Throwable cause) {\n+        try {\n+            closeConnection(subscriber, cause);\n+        } finally {\n+            // the lock has been acquired!\n+            do {\n+                Subscriber<? super Resp> nextSubscriber;\n+                while ((nextSubscriber = readQueue.poll()) != null) {\n+                    deliverTerminalFromSource(nextSubscriber, cause);\n+                }\n+            } while (!releaseLock(readQueueLockUpdater, this) && tryAcquireLock(readQueueLockUpdater, this));\n+        }\n+    }\n+\n+    /**\n+     * Offer {@code item} to the queue, try to acquire the processing lock, and if successful return an item for\n+     * single-consumer style processing. If non-{@code null} is returned the caller is responsible for releasing\n+     * the lock!\n+     * @param queue The {@link Queue#offer(Object)} and {@link Queue#poll()} (assuming lock was acquired).\n+     * @param lockUpdater Used to acquire the lock via\n+     * {@link ConcurrentUtils#tryAcquireLock(AtomicIntegerFieldUpdater, Object)}.\n+     * @param item The item to {@link Queue#offer(Object)}.\n+     * @param <T> The type of item in the {@link Queue}.\n+     * @return {@code null} if the queue was empty, or the lock couldn't be acquired. otherwise the lock has been\n+     * acquired and it is the caller's responsibility to release!\n+     */\n+    @Nullable\n+    private <T> T offerTryAcquireLock(final Queue<T> queue,\n+          @SuppressWarnings(\"rawtypes\") final AtomicIntegerFieldUpdater<NettyPipelinedConnection> lockUpdater, T item) {\n+        queue.add(item);", "originalCommit": "e67ddd3040b7d00c14ad7c8da5750ac327447447", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjk1NzUzMQ==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r416957531", "bodyText": "switched to addAndTryPoll", "author": "Scottmitch", "createdAt": "2020-04-28T22:17:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg3ODU2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg4MTExNA==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r416881114", "bodyText": "This isn't necessarily the \"first write task\" rite? it can be the next write if the previous task completed concurrently.", "author": "NiteshKant", "createdAt": "2020-04-28T19:52:52Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,362 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.PublisherSource.Subscriber;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.concurrent.internal.ConcurrentUtils;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n+\n+import io.netty.channel.Channel;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static io.servicetalk.concurrent.internal.ConcurrentUtils.releaseLock;\n+import static io.servicetalk.concurrent.internal.ConcurrentUtils.tryAcquireLock;\n+import static io.servicetalk.concurrent.internal.SubscriberUtils.deliverTerminalFromSource;\n+import static io.servicetalk.utils.internal.PlatformDependent.newUnboundedMpscQueue;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicIntegerFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicIntegerFieldUpdater<NettyPipelinedConnection> writeQueueLockUpdater =\n+            newUpdater(NettyPipelinedConnection.class, \"writeQueueLock\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicIntegerFieldUpdater<NettyPipelinedConnection> readQueueLockUpdater =\n+            newUpdater(NettyPipelinedConnection.class, \"readQueueLock\");\n+    private final NettyConnection<Resp, Req> connection;\n+    private final Queue<WriteTask> writeQueue;\n+    private final Queue<Subscriber<? super Resp>> readQueue;\n+    @SuppressWarnings(\"unused\")\n+    private volatile int writeQueueLock;\n+    @SuppressWarnings(\"unused\")\n+    private volatile int readQueueLock;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+        writeQueue = newUnboundedMpscQueue();\n+        readQueue = newUnboundedMpscQueue();\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher) {\n+        return write(requestPublisher, connection::defaultFlushStrategy, WriteDemandEstimators::newDefaultEstimator);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+        return new Publisher<Resp>() {\n+            @Override\n+            protected void handleSubscribe(final Subscriber<? super Resp> subscriber) {\n+                final WriteTask firstWriteTask;", "originalCommit": "e67ddd3040b7d00c14ad7c8da5750ac327447447", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjk1ODIwNg==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r416958206", "bodyText": "I will change to \"next\"", "author": "Scottmitch", "createdAt": "2020-04-28T22:19:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg4MTExNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg4MjIxNw==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r416882217", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            return next; // lock must be released by caller!\n          \n          \n            \n                            return next; // lock must be released when the returned task completes!", "author": "NiteshKant", "createdAt": "2020-04-28T19:54:42Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,362 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.PublisherSource.Subscriber;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.concurrent.internal.ConcurrentUtils;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n+\n+import io.netty.channel.Channel;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static io.servicetalk.concurrent.internal.ConcurrentUtils.releaseLock;\n+import static io.servicetalk.concurrent.internal.ConcurrentUtils.tryAcquireLock;\n+import static io.servicetalk.concurrent.internal.SubscriberUtils.deliverTerminalFromSource;\n+import static io.servicetalk.utils.internal.PlatformDependent.newUnboundedMpscQueue;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicIntegerFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicIntegerFieldUpdater<NettyPipelinedConnection> writeQueueLockUpdater =\n+            newUpdater(NettyPipelinedConnection.class, \"writeQueueLock\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicIntegerFieldUpdater<NettyPipelinedConnection> readQueueLockUpdater =\n+            newUpdater(NettyPipelinedConnection.class, \"readQueueLock\");\n+    private final NettyConnection<Resp, Req> connection;\n+    private final Queue<WriteTask> writeQueue;\n+    private final Queue<Subscriber<? super Resp>> readQueue;\n+    @SuppressWarnings(\"unused\")\n+    private volatile int writeQueueLock;\n+    @SuppressWarnings(\"unused\")\n+    private volatile int readQueueLock;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+        writeQueue = newUnboundedMpscQueue();\n+        readQueue = newUnboundedMpscQueue();\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher) {\n+        return write(requestPublisher, connection::defaultFlushStrategy, WriteDemandEstimators::newDefaultEstimator);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+        return new Publisher<Resp>() {\n+            @Override\n+            protected void handleSubscribe(final Subscriber<? super Resp> subscriber) {\n+                final WriteTask firstWriteTask;\n+                try {\n+                    firstWriteTask = offerTryAcquireLock(writeQueue, writeQueueLockUpdater,\n+                            new WriteTask(subscriber, requestPublisher, flushStrategySupplier,\n+                                    writeDemandEstimatorSupplier));\n+                } catch (Throwable cause) {\n+                    closeConnection(subscriber, cause);\n+                    return;\n+                }\n+\n+                if (firstWriteTask != null) {\n+                    firstWriteTask.run();\n+                }\n+            }\n+        };\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getSimpleName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void closeConnection(final Subscriber<? super Resp> subscriber, final Throwable cause) {\n+        toSource(connection.closeAsync().concat(Publisher.<Resp>failed(cause))).subscribe(subscriber);\n+    }\n+\n+    private void tryStartRead(@Nullable Subscriber<? super Resp> subscriber) {\n+        if (subscriber == null) {\n+            return;\n+        }\n+        final PublisherSource<Resp> src;\n+        try {\n+            src = toSource(connection.read().afterFinally(() ->\n+                    tryStartRead(pollWithLockAcquired(readQueue, readQueueLockUpdater))));\n+        } catch (Throwable cause) {\n+            handleReadSetupError(subscriber, cause);\n+            return;\n+        }\n+        src.subscribe(subscriber);\n+    }\n+\n+    private final class WriteTask {\n+        private final Subscriber<? super Resp> subscriber;\n+        private final Publisher<Req> requestPublisher;\n+        private final Supplier<FlushStrategy> flushStrategySupplier;\n+        private final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier;\n+\n+        private WriteTask(final Subscriber<? super Resp> subscriber,\n+                          final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+            this.subscriber = subscriber;\n+            this.requestPublisher = requestPublisher;\n+            this.flushStrategySupplier = flushStrategySupplier;\n+            this.writeDemandEstimatorSupplier = writeDemandEstimatorSupplier;\n+        }\n+\n+        void run() {\n+            final PublisherSource<Resp> src;\n+            try {\n+                src = toSource(connection.write(requestPublisher, flushStrategySupplier,\n+                        writeDemandEstimatorSupplier)\n+                        .afterFinally(() -> {\n+                            WriteTask nextWriteTask = pollWithLockAcquired(writeQueue, writeQueueLockUpdater);\n+                            if (nextWriteTask != null) {\n+                                nextWriteTask.run();\n+                            }\n+                        }).merge(new Publisher<Resp>() {\n+                            @Override\n+                            protected void handleSubscribe(final Subscriber<? super Resp> rSubscriber) {\n+                                final Subscriber<? super Resp> firstReadSubscriber;\n+                                try {\n+                                    firstReadSubscriber =\n+                                            offerTryAcquireLock(readQueue, readQueueLockUpdater, rSubscriber);\n+                                } catch (Throwable cause) {\n+                                    closeConnection(rSubscriber, cause);\n+                                    return;\n+                                }\n+\n+                                tryStartRead(firstReadSubscriber);\n+                            }\n+                        }));\n+            } catch (Throwable cause) {\n+                handleWriteSetupError(subscriber, cause);\n+                return;\n+            }\n+            src.subscribe(subscriber);\n+        }\n+    }\n+\n+    private void handleWriteSetupError(Subscriber<? super Resp> subscriber, Throwable cause) {\n+        try {\n+            closeConnection(subscriber, cause);\n+        } finally {\n+            // the lock has been acquired!\n+            do {\n+                WriteTask nextWriteTask;\n+                while ((nextWriteTask = writeQueue.poll()) != null) {\n+                    deliverTerminalFromSource(nextWriteTask.subscriber, cause);\n+                }\n+            } while (!releaseLock(writeQueueLockUpdater, this) && tryAcquireLock(writeQueueLockUpdater, this));\n+        }\n+    }\n+\n+    private void handleReadSetupError(Subscriber<? super Resp> subscriber, Throwable cause) {\n+        try {\n+            closeConnection(subscriber, cause);\n+        } finally {\n+            // the lock has been acquired!\n+            do {\n+                Subscriber<? super Resp> nextSubscriber;\n+                while ((nextSubscriber = readQueue.poll()) != null) {\n+                    deliverTerminalFromSource(nextSubscriber, cause);\n+                }\n+            } while (!releaseLock(readQueueLockUpdater, this) && tryAcquireLock(readQueueLockUpdater, this));\n+        }\n+    }\n+\n+    /**\n+     * Offer {@code item} to the queue, try to acquire the processing lock, and if successful return an item for\n+     * single-consumer style processing. If non-{@code null} is returned the caller is responsible for releasing\n+     * the lock!\n+     * @param queue The {@link Queue#offer(Object)} and {@link Queue#poll()} (assuming lock was acquired).\n+     * @param lockUpdater Used to acquire the lock via\n+     * {@link ConcurrentUtils#tryAcquireLock(AtomicIntegerFieldUpdater, Object)}.\n+     * @param item The item to {@link Queue#offer(Object)}.\n+     * @param <T> The type of item in the {@link Queue}.\n+     * @return {@code null} if the queue was empty, or the lock couldn't be acquired. otherwise the lock has been\n+     * acquired and it is the caller's responsibility to release!\n+     */\n+    @Nullable\n+    private <T> T offerTryAcquireLock(final Queue<T> queue,\n+          @SuppressWarnings(\"rawtypes\") final AtomicIntegerFieldUpdater<NettyPipelinedConnection> lockUpdater, T item) {\n+        queue.add(item);\n+        while (tryAcquireLock(lockUpdater, this)) {\n+            // exceptions are not expected from poll, and if they occur we can't reliably recover which would involve\n+            // draining the queue. just throw with the lock poisoned, callers will propagate the exception to related\n+            // subscriber and close the connection.\n+            final T next = queue.poll();\n+            if (next != null) {\n+                return next; // lock must be released by caller!", "originalCommit": "e67ddd3040b7d00c14ad7c8da5750ac327447447", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg4NTIxNg==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r416885216", "bodyText": "Does it have to be afterFinally() or we can use beforeFinally()? A positive of using before*() here is that any exception will bubble up to the subscriber.", "author": "NiteshKant", "createdAt": "2020-04-28T20:00:02Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,362 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.PublisherSource.Subscriber;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.concurrent.internal.ConcurrentUtils;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n+\n+import io.netty.channel.Channel;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static io.servicetalk.concurrent.internal.ConcurrentUtils.releaseLock;\n+import static io.servicetalk.concurrent.internal.ConcurrentUtils.tryAcquireLock;\n+import static io.servicetalk.concurrent.internal.SubscriberUtils.deliverTerminalFromSource;\n+import static io.servicetalk.utils.internal.PlatformDependent.newUnboundedMpscQueue;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicIntegerFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicIntegerFieldUpdater<NettyPipelinedConnection> writeQueueLockUpdater =\n+            newUpdater(NettyPipelinedConnection.class, \"writeQueueLock\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicIntegerFieldUpdater<NettyPipelinedConnection> readQueueLockUpdater =\n+            newUpdater(NettyPipelinedConnection.class, \"readQueueLock\");\n+    private final NettyConnection<Resp, Req> connection;\n+    private final Queue<WriteTask> writeQueue;\n+    private final Queue<Subscriber<? super Resp>> readQueue;\n+    @SuppressWarnings(\"unused\")\n+    private volatile int writeQueueLock;\n+    @SuppressWarnings(\"unused\")\n+    private volatile int readQueueLock;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+        writeQueue = newUnboundedMpscQueue();\n+        readQueue = newUnboundedMpscQueue();\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher) {\n+        return write(requestPublisher, connection::defaultFlushStrategy, WriteDemandEstimators::newDefaultEstimator);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+        return new Publisher<Resp>() {\n+            @Override\n+            protected void handleSubscribe(final Subscriber<? super Resp> subscriber) {\n+                final WriteTask firstWriteTask;\n+                try {\n+                    firstWriteTask = offerTryAcquireLock(writeQueue, writeQueueLockUpdater,\n+                            new WriteTask(subscriber, requestPublisher, flushStrategySupplier,\n+                                    writeDemandEstimatorSupplier));\n+                } catch (Throwable cause) {\n+                    closeConnection(subscriber, cause);\n+                    return;\n+                }\n+\n+                if (firstWriteTask != null) {\n+                    firstWriteTask.run();\n+                }\n+            }\n+        };\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getSimpleName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void closeConnection(final Subscriber<? super Resp> subscriber, final Throwable cause) {\n+        toSource(connection.closeAsync().concat(Publisher.<Resp>failed(cause))).subscribe(subscriber);\n+    }\n+\n+    private void tryStartRead(@Nullable Subscriber<? super Resp> subscriber) {\n+        if (subscriber == null) {\n+            return;\n+        }\n+        final PublisherSource<Resp> src;\n+        try {\n+            src = toSource(connection.read().afterFinally(() ->\n+                    tryStartRead(pollWithLockAcquired(readQueue, readQueueLockUpdater))));\n+        } catch (Throwable cause) {\n+            handleReadSetupError(subscriber, cause);\n+            return;\n+        }\n+        src.subscribe(subscriber);\n+    }\n+\n+    private final class WriteTask {\n+        private final Subscriber<? super Resp> subscriber;\n+        private final Publisher<Req> requestPublisher;\n+        private final Supplier<FlushStrategy> flushStrategySupplier;\n+        private final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier;\n+\n+        private WriteTask(final Subscriber<? super Resp> subscriber,\n+                          final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+            this.subscriber = subscriber;\n+            this.requestPublisher = requestPublisher;\n+            this.flushStrategySupplier = flushStrategySupplier;\n+            this.writeDemandEstimatorSupplier = writeDemandEstimatorSupplier;\n+        }\n+\n+        void run() {\n+            final PublisherSource<Resp> src;\n+            try {\n+                src = toSource(connection.write(requestPublisher, flushStrategySupplier,\n+                        writeDemandEstimatorSupplier)\n+                        .afterFinally(() -> {", "originalCommit": "e67ddd3040b7d00c14ad7c8da5750ac327447447", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjk2MDg3Nw==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r416960877", "bodyText": "beforeFinally can trigger before write stream subscriber is cleaned up in some error situations so I'll just stick with after* for now.", "author": "Scottmitch", "createdAt": "2020-04-28T22:25:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg4NTIxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzQwOTc5Mw==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r417409793", "bodyText": "to provide more context ....\n\nin the event the write publisher terminates with an error WriteStreamSubscriber.AllWritePromise#terminateSubscriber closes the closeChannelOutbound before propagating exception to the subscriber which results in A write is already active on this connection. exception on DefaultNettyConnection. I think the sequencing in incorrect and closeChannelOutbound should be after the subscriber is terminated and I will fix this. however then merge triggers a cancellation which results in starting the next read task, which subscribes to the channel.read()  publisher before the previous subscriber is \"detached\" from NettyChannelPublisher which results in a DuplicateSubscribeException ... in this case we want an operator like \"do subscriber before, but subscription after\" to invoke tryStartRead.\nit is also a questioning of sequencing ... if we dequeue the next element before notifying the status of the current element, and there is a synchronous type of failure/completion we will notify completion in reverse order as the queue. we have a queue so \"cleaning up local state first\" may result in out of order notification", "author": "Scottmitch", "createdAt": "2020-04-29T15:33:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg4NTIxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg4NjUzNA==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r416886534", "bodyText": "firstReadSubscriber => nextReadSubscriber?", "author": "NiteshKant", "createdAt": "2020-04-28T20:02:23Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,362 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.PublisherSource.Subscriber;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.concurrent.internal.ConcurrentUtils;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n+\n+import io.netty.channel.Channel;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static io.servicetalk.concurrent.internal.ConcurrentUtils.releaseLock;\n+import static io.servicetalk.concurrent.internal.ConcurrentUtils.tryAcquireLock;\n+import static io.servicetalk.concurrent.internal.SubscriberUtils.deliverTerminalFromSource;\n+import static io.servicetalk.utils.internal.PlatformDependent.newUnboundedMpscQueue;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicIntegerFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicIntegerFieldUpdater<NettyPipelinedConnection> writeQueueLockUpdater =\n+            newUpdater(NettyPipelinedConnection.class, \"writeQueueLock\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicIntegerFieldUpdater<NettyPipelinedConnection> readQueueLockUpdater =\n+            newUpdater(NettyPipelinedConnection.class, \"readQueueLock\");\n+    private final NettyConnection<Resp, Req> connection;\n+    private final Queue<WriteTask> writeQueue;\n+    private final Queue<Subscriber<? super Resp>> readQueue;\n+    @SuppressWarnings(\"unused\")\n+    private volatile int writeQueueLock;\n+    @SuppressWarnings(\"unused\")\n+    private volatile int readQueueLock;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+        writeQueue = newUnboundedMpscQueue();\n+        readQueue = newUnboundedMpscQueue();\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher) {\n+        return write(requestPublisher, connection::defaultFlushStrategy, WriteDemandEstimators::newDefaultEstimator);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+        return new Publisher<Resp>() {\n+            @Override\n+            protected void handleSubscribe(final Subscriber<? super Resp> subscriber) {\n+                final WriteTask firstWriteTask;\n+                try {\n+                    firstWriteTask = offerTryAcquireLock(writeQueue, writeQueueLockUpdater,\n+                            new WriteTask(subscriber, requestPublisher, flushStrategySupplier,\n+                                    writeDemandEstimatorSupplier));\n+                } catch (Throwable cause) {\n+                    closeConnection(subscriber, cause);\n+                    return;\n+                }\n+\n+                if (firstWriteTask != null) {\n+                    firstWriteTask.run();\n+                }\n+            }\n+        };\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getSimpleName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void closeConnection(final Subscriber<? super Resp> subscriber, final Throwable cause) {\n+        toSource(connection.closeAsync().concat(Publisher.<Resp>failed(cause))).subscribe(subscriber);\n+    }\n+\n+    private void tryStartRead(@Nullable Subscriber<? super Resp> subscriber) {\n+        if (subscriber == null) {\n+            return;\n+        }\n+        final PublisherSource<Resp> src;\n+        try {\n+            src = toSource(connection.read().afterFinally(() ->\n+                    tryStartRead(pollWithLockAcquired(readQueue, readQueueLockUpdater))));\n+        } catch (Throwable cause) {\n+            handleReadSetupError(subscriber, cause);\n+            return;\n+        }\n+        src.subscribe(subscriber);\n+    }\n+\n+    private final class WriteTask {\n+        private final Subscriber<? super Resp> subscriber;\n+        private final Publisher<Req> requestPublisher;\n+        private final Supplier<FlushStrategy> flushStrategySupplier;\n+        private final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier;\n+\n+        private WriteTask(final Subscriber<? super Resp> subscriber,\n+                          final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+            this.subscriber = subscriber;\n+            this.requestPublisher = requestPublisher;\n+            this.flushStrategySupplier = flushStrategySupplier;\n+            this.writeDemandEstimatorSupplier = writeDemandEstimatorSupplier;\n+        }\n+\n+        void run() {\n+            final PublisherSource<Resp> src;\n+            try {\n+                src = toSource(connection.write(requestPublisher, flushStrategySupplier,\n+                        writeDemandEstimatorSupplier)\n+                        .afterFinally(() -> {\n+                            WriteTask nextWriteTask = pollWithLockAcquired(writeQueue, writeQueueLockUpdater);\n+                            if (nextWriteTask != null) {\n+                                nextWriteTask.run();\n+                            }\n+                        }).merge(new Publisher<Resp>() {\n+                            @Override\n+                            protected void handleSubscribe(final Subscriber<? super Resp> rSubscriber) {\n+                                final Subscriber<? super Resp> firstReadSubscriber;", "originalCommit": "e67ddd3040b7d00c14ad7c8da5750ac327447447", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg4Nzk4Mw==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r416887983", "bodyText": "nit: move this method to the WriteTask as thats where it is used.", "author": "NiteshKant", "createdAt": "2020-04-28T20:05:11Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,362 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.PublisherSource.Subscriber;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.concurrent.internal.ConcurrentUtils;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n+\n+import io.netty.channel.Channel;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static io.servicetalk.concurrent.internal.ConcurrentUtils.releaseLock;\n+import static io.servicetalk.concurrent.internal.ConcurrentUtils.tryAcquireLock;\n+import static io.servicetalk.concurrent.internal.SubscriberUtils.deliverTerminalFromSource;\n+import static io.servicetalk.utils.internal.PlatformDependent.newUnboundedMpscQueue;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicIntegerFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicIntegerFieldUpdater<NettyPipelinedConnection> writeQueueLockUpdater =\n+            newUpdater(NettyPipelinedConnection.class, \"writeQueueLock\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicIntegerFieldUpdater<NettyPipelinedConnection> readQueueLockUpdater =\n+            newUpdater(NettyPipelinedConnection.class, \"readQueueLock\");\n+    private final NettyConnection<Resp, Req> connection;\n+    private final Queue<WriteTask> writeQueue;\n+    private final Queue<Subscriber<? super Resp>> readQueue;\n+    @SuppressWarnings(\"unused\")\n+    private volatile int writeQueueLock;\n+    @SuppressWarnings(\"unused\")\n+    private volatile int readQueueLock;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+        writeQueue = newUnboundedMpscQueue();\n+        readQueue = newUnboundedMpscQueue();\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher) {\n+        return write(requestPublisher, connection::defaultFlushStrategy, WriteDemandEstimators::newDefaultEstimator);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+        return new Publisher<Resp>() {\n+            @Override\n+            protected void handleSubscribe(final Subscriber<? super Resp> subscriber) {\n+                final WriteTask firstWriteTask;\n+                try {\n+                    firstWriteTask = offerTryAcquireLock(writeQueue, writeQueueLockUpdater,\n+                            new WriteTask(subscriber, requestPublisher, flushStrategySupplier,\n+                                    writeDemandEstimatorSupplier));\n+                } catch (Throwable cause) {\n+                    closeConnection(subscriber, cause);\n+                    return;\n+                }\n+\n+                if (firstWriteTask != null) {\n+                    firstWriteTask.run();\n+                }\n+            }\n+        };\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getSimpleName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void closeConnection(final Subscriber<? super Resp> subscriber, final Throwable cause) {\n+        toSource(connection.closeAsync().concat(Publisher.<Resp>failed(cause))).subscribe(subscriber);\n+    }\n+\n+    private void tryStartRead(@Nullable Subscriber<? super Resp> subscriber) {", "originalCommit": "e67ddd3040b7d00c14ad7c8da5750ac327447447", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg5MzQ0OA==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r416893448", "bodyText": "Can we avoid calling external methods inside finally? eg: deliverTerminalFromSource can throw if both subscriber.onSubscribe()  and subscriber.onError() throw. Alternative:\nprivate void handleWriteSetupError(Subscriber<? super Resp> subscriber, Throwable cause) {\n    try {\n        closeConnection(subscriber, cause);\n    } catch (Throwable t) {\n        subscriber.onSubscribe(EMPTY_SUBSCRIPTION);\n        subscriber.onError(t);\n    }\n    // the lock has been acquired!\n    do {\n        WriteTask nextWriteTask;\n        while ((nextWriteTask = writeQueue.poll()) != null) {\n            deliverTerminalFromSource(nextWriteTask.subscriber, cause);\n        }\n    } while (!releaseLock(writeQueueLockUpdater, this) && tryAcquireLock(writeQueueLockUpdater, this));\n}\nOR just make sure closeConnection does not throw and remove the catch close above.", "author": "NiteshKant", "createdAt": "2020-04-28T20:14:53Z", "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,362 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.PublisherSource.Subscriber;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.concurrent.internal.ConcurrentUtils;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n+\n+import io.netty.channel.Channel;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static io.servicetalk.concurrent.internal.ConcurrentUtils.releaseLock;\n+import static io.servicetalk.concurrent.internal.ConcurrentUtils.tryAcquireLock;\n+import static io.servicetalk.concurrent.internal.SubscriberUtils.deliverTerminalFromSource;\n+import static io.servicetalk.utils.internal.PlatformDependent.newUnboundedMpscQueue;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicIntegerFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicIntegerFieldUpdater<NettyPipelinedConnection> writeQueueLockUpdater =\n+            newUpdater(NettyPipelinedConnection.class, \"writeQueueLock\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicIntegerFieldUpdater<NettyPipelinedConnection> readQueueLockUpdater =\n+            newUpdater(NettyPipelinedConnection.class, \"readQueueLock\");\n+    private final NettyConnection<Resp, Req> connection;\n+    private final Queue<WriteTask> writeQueue;\n+    private final Queue<Subscriber<? super Resp>> readQueue;\n+    @SuppressWarnings(\"unused\")\n+    private volatile int writeQueueLock;\n+    @SuppressWarnings(\"unused\")\n+    private volatile int readQueueLock;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+        writeQueue = newUnboundedMpscQueue();\n+        readQueue = newUnboundedMpscQueue();\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher) {\n+        return write(requestPublisher, connection::defaultFlushStrategy, WriteDemandEstimators::newDefaultEstimator);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+        return new Publisher<Resp>() {\n+            @Override\n+            protected void handleSubscribe(final Subscriber<? super Resp> subscriber) {\n+                final WriteTask firstWriteTask;\n+                try {\n+                    firstWriteTask = offerTryAcquireLock(writeQueue, writeQueueLockUpdater,\n+                            new WriteTask(subscriber, requestPublisher, flushStrategySupplier,\n+                                    writeDemandEstimatorSupplier));\n+                } catch (Throwable cause) {\n+                    closeConnection(subscriber, cause);\n+                    return;\n+                }\n+\n+                if (firstWriteTask != null) {\n+                    firstWriteTask.run();\n+                }\n+            }\n+        };\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getSimpleName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void closeConnection(final Subscriber<? super Resp> subscriber, final Throwable cause) {\n+        toSource(connection.closeAsync().concat(Publisher.<Resp>failed(cause))).subscribe(subscriber);\n+    }\n+\n+    private void tryStartRead(@Nullable Subscriber<? super Resp> subscriber) {\n+        if (subscriber == null) {\n+            return;\n+        }\n+        final PublisherSource<Resp> src;\n+        try {\n+            src = toSource(connection.read().afterFinally(() ->\n+                    tryStartRead(pollWithLockAcquired(readQueue, readQueueLockUpdater))));\n+        } catch (Throwable cause) {\n+            handleReadSetupError(subscriber, cause);\n+            return;\n+        }\n+        src.subscribe(subscriber);\n+    }\n+\n+    private final class WriteTask {\n+        private final Subscriber<? super Resp> subscriber;\n+        private final Publisher<Req> requestPublisher;\n+        private final Supplier<FlushStrategy> flushStrategySupplier;\n+        private final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier;\n+\n+        private WriteTask(final Subscriber<? super Resp> subscriber,\n+                          final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+            this.subscriber = subscriber;\n+            this.requestPublisher = requestPublisher;\n+            this.flushStrategySupplier = flushStrategySupplier;\n+            this.writeDemandEstimatorSupplier = writeDemandEstimatorSupplier;\n+        }\n+\n+        void run() {\n+            final PublisherSource<Resp> src;\n+            try {\n+                src = toSource(connection.write(requestPublisher, flushStrategySupplier,\n+                        writeDemandEstimatorSupplier)\n+                        .afterFinally(() -> {\n+                            WriteTask nextWriteTask = pollWithLockAcquired(writeQueue, writeQueueLockUpdater);\n+                            if (nextWriteTask != null) {\n+                                nextWriteTask.run();\n+                            }\n+                        }).merge(new Publisher<Resp>() {\n+                            @Override\n+                            protected void handleSubscribe(final Subscriber<? super Resp> rSubscriber) {\n+                                final Subscriber<? super Resp> firstReadSubscriber;\n+                                try {\n+                                    firstReadSubscriber =\n+                                            offerTryAcquireLock(readQueue, readQueueLockUpdater, rSubscriber);\n+                                } catch (Throwable cause) {\n+                                    closeConnection(rSubscriber, cause);\n+                                    return;\n+                                }\n+\n+                                tryStartRead(firstReadSubscriber);\n+                            }\n+                        }));\n+            } catch (Throwable cause) {\n+                handleWriteSetupError(subscriber, cause);\n+                return;\n+            }\n+            src.subscribe(subscriber);\n+        }\n+    }\n+\n+    private void handleWriteSetupError(Subscriber<? super Resp> subscriber, Throwable cause) {\n+        try {\n+            closeConnection(subscriber, cause);\n+        } finally {\n+            // the lock has been acquired!\n+            do {\n+                WriteTask nextWriteTask;\n+                while ((nextWriteTask = writeQueue.poll()) != null) {\n+                    deliverTerminalFromSource(nextWriteTask.subscriber, cause);", "originalCommit": "e67ddd3040b7d00c14ad7c8da5750ac327447447", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzQxNjAyOA==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r417416028", "bodyText": "closeConnection already shouldn't throw, but since there is a lock acquired the cleanup code is put in a finally block.\nI don't think deliverTerminalFromSource should throw. if it does it may result in duplicate notification from our sources. For example:\nNeverPublisher#subscribe()\nsubscriber.onSubscribe(..)\ncatch(cause)\nhandleExceptionFromOnSubscribe(..)\nsubscriber.onError(cause)\ncatch(cause2)  (in Publisher#handleSubscribe(..))\ndeliverTerminalFromSource(..)\nsubscriber.onSubscribe(..) // duplicate call introduced by our error recovery\ncatch(cause3)\nhandleExceptionFromOnSubscribe(..)\nsubscriber.onError(cause3) // duplicate call introduced by our error recovery\n\nI'll submit a PR: #1034", "author": "Scottmitch", "createdAt": "2020-04-29T15:41:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg5MzQ0OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzQzMzA3Mw==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r417433073", "bodyText": "closeConnection already shouldn't throw,\n\nUnless connection.closeAsync() itself throws? I think we should generally avoid calling external code in finally block, it complicates control-flow and hides exception if any code in try and in the finally block throws.", "author": "NiteshKant", "createdAt": "2020-04-29T16:05:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg5MzQ0OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzU0MDg5Ng==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r417540896", "bodyText": "I'll just remove the finally as it is defensive programming and is targeted at programming errors or runtime failures (e.g. OOME). However I don't think the \"don't call external code in finally block\" is a hard rule despite it potentially complicating control flow. The goal of \"finally\" is two independent code blocks need to execute regardless if the first throws. This can be particularly useful to guarantee asynchronous control flow is preserved if something unexpected happens. If exceptions aren't expected from either code block (e.g. programming error occurs as opposed to data flow error), I would argue it doesn't really matter which exception is propagated (if it did matter exceptions are no longer \"unexpected\"), but we achieved the goal of preserving async control flow. Granted this is a defensive, but if it does occur debugging in an async control flow will be challenging.\nIn this case if deliverTerminalFromSource throws then the control flow isn't correct here because we wouldn't propagate the exception to all pending subscribers, and we should use a safer alternative instead (not convinced this is the desired behavior though #1034). If the queue.poll() throws (isn't expect to) then we cannot reliably continue to drain the queue (may get another exception on the next poll attempt) so this is considered fatal and we let the exception propagate.\n\nUnless connection.closeAsync() itself throws?\n\nYes any method in closeConnection() could throw. However the method returns an async source and throwing isn't the expected way to propagate an error in this case, but may happen in extreme situations (e.g. OOME).The finally is intended to preserve async control flow in either case (normal completion, unexpected exceptional completion).", "author": "Scottmitch", "createdAt": "2020-04-29T18:57:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg5MzQ0OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzU1NjA4MQ==", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r417556081", "bodyText": "I'll just remove the finally\n\n\n\ud83d\udc4c thanks\n\n\nI don't think the \"don't call external code in finally block\" is a hard rule\n\n\nAgreed.", "author": "NiteshKant", "createdAt": "2020-04-29T19:24:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg5MzQ0OA=="}], "type": "inlineReview"}, {"oid": "1b990a298cc3d9f69425750b88df839f2f43e439", "url": "https://github.com/apple/servicetalk/commit/1b990a298cc3d9f69425750b88df839f2f43e439", "message": "review comments, correct ordering of error notification when write error occurrs", "committedDate": "2020-04-29T17:50:02Z", "type": "commit"}, {"oid": "1b990a298cc3d9f69425750b88df839f2f43e439", "url": "https://github.com/apple/servicetalk/commit/1b990a298cc3d9f69425750b88df839f2f43e439", "message": "review comments, correct ordering of error notification when write error occurrs", "committedDate": "2020-04-29T17:50:02Z", "type": "forcePushed"}, {"oid": "889a52be8b2504bb8beb3d8714ae3962463c6795", "url": "https://github.com/apple/servicetalk/commit/889a52be8b2504bb8beb3d8714ae3962463c6795", "message": "remove finally, release lock first", "committedDate": "2020-04-29T18:58:28Z", "type": "commit"}, {"oid": "08daca46a471e1dfeec88b9a2a6748c66c1c4ad0", "url": "https://github.com/apple/servicetalk/commit/08daca46a471e1dfeec88b9a2a6748c66c1c4ad0", "message": "move connection close up front", "committedDate": "2020-04-29T19:13:32Z", "type": "commit"}]}